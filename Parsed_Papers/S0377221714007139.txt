@&#MAIN-TITLE@&#Freight railway operator timetabling and engine scheduling

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Generate timetables based on infrastructure paths.


                        
                        
                           
                           Branch-and-Price approach implemented.


                        
                        
                           
                           Provides high quality integer solutions to real-life sized instances.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Freight railway

Timetabling

Branch-and-Price

Transportation

Scheduling

@&#ABSTRACT@&#


               
               
                  In this paper we consider timetable design at a European freight railway operator. The timetable is designed by choosing the time of service for customer unit train demands among a set of discrete points. These discrete points are all found within the a time-window. The objective of the model is to minimize cost while adhering to constraints regarding infrastructure usage, demand coverage, and engine availability. The model is solved by a column generation scheme where feasible engine schedules are designed in a label setting algorithm with time-dependent cost and service times.
               
            

@&#INTRODUCTION@&#

In this paper we consider the problem facing a freight railway operator who has to develop a yearly timetable that includes access to infrastructure. When developing the timetable, a railway operator has to apply for usage of railway infrastructure.

The problem is to schedule a set of unit trains. This is done by fixing the departure/arrival time and assigning an engine to each train. The schedule has to be feasible with respect to infrastructure access. The objective is to minimize driving related costs.

We formulate a model for the problem and solve it using a Branch-and-Price algorithm, which is tested on a set of test instances derived from a real-life case at a freight railway operator.

Deutsche Bahn Schenker Rail Scandinavia (DBSRS) is a railway operator managing transports that originate from and/or have destination in a Scandinavian country. The core business of DBSRS is to provide engines and engine drivers to move customers’ cars between stations according to long term contracts. More specifically DBSRS is assigned by its mother companies to handle timetabling and to allocate drivers and engines to the planned trips in the RailNetEurope (RNE) corridor 1 area from Maschen (Hamburg) in the south to Hallsberg (in southern Sweden) in the north.

In Section 2, we describe the problem in detail. In Section 3, we give a literature review. In Section 4.1, we present the modeling of the problem and we describe our solution approach. The case is described in detail in Section 5. Computational experiments are provided in Section 6, and conclusions are drawn in Section 7.

In this section, we describe the problem in general. In Section 5, we describe the case specific details from DBSRS and the network in which they operate.

The overall goal of the problem is to minimize the total costs for the railway operator. When designing a timetable, the total costs include both engine usage, track usage, and other driving related costs. The horizon for the timetable is weekly and has to be repeated for one year. Hence, the demands are serviced at the same time each week during the entire timetable which is valid for one year. The timetables are typically designed more than six months in advance. The contracts between DBSRS and their customers vary in length and scope, but, without loss of generality the contracts all last for at least a year, which covers the timetabling period of a year. Hence, at the time of planning the demand is known.

In Europe, the organization RailNetEurope (RNE) works to harmonize the access to infrastructure in their 38 member countries. When designing their timetables the operators can apply for a train path, which is an origin and destination pair with given departure time and transit times. The paths are designed either by RNE, in which case they are called catalogue paths, or the railway operator can design and apply for paths themselves, in which case they are called tailormade paths. By definition, the catalogue paths comply with the regulations such that the paths are feasible. This paper focuses on the (RNE designed) catalogue paths and thus the design of additional tailormade paths are not considered.

An overview of the model can be seen in Fig. 1
                     . In the following we consider the implementation of the constraints and how to handle them.



                     Demand coverage, the demands in this model are for unit trains, i.e., all demands are for a full train using a single engine, that has to drive from an origin to an arrival station. It is not possible to aggregate demand. All demand has to be serviced exactly once.


                     Availability of engines, the model allows for multiple engine types. These differ as regards the demands they can serve, e.g., costs, and safety margins. For each engine type, there is a finite number of engines available.


                     Replication of weekly schedule, the schedule is periodic at a weekly level, and thus it must be possible to replicate it week after week. Therefore we balance the engines in the beginning of the week with the engines at the end of the week. The individual engine does not necessarily start and end at the same station, but the sum of engines at the start and the end of the week must be balanced. How to perform this balance is not straightforward and hence it will be further explained in Section 4.1.

The network capacity allows only one train per time-slot. Hence two demands that use the same or have partially overlapping schedules would have to be planned such that no time-slot is used twice.


                     Path compliance, the trains can only be scheduled to start at times where a path exist.


                     Time-window compliance, the start of service of a demand has to be within the time-window and within this time-window we have to select a path which means that it is not enough just to be within the time-window. Therefore any time-window will have an associated set of paths that can be used.


                     Flow conservation ensures that the flows in and out of stations are balanced for all stations of the schedule except at the first and last.


                     Engine type compliance ensures that the correct engine type is used to service a given demand.


                     Waiting time after demands handles the safety margins that are planned after the completion of each demand to avoid propagation of delays. This waiting time is set according to the policy of the railway operator.


                     Transit time between demands is a minimum time that ensure that there is enough time to reposition the engine between servicing two demands. It also includes the necessary time to prepare for service of the latter of these demands. Hence, if it is not possible to reposition an engine between two demands, these cannot be assigned to the same engine.

The problem can be formally described as an engine scheduling problem where a set of heterogeneous engines have to serve a set of unit train demands that cannot be serviced simultaneously. Each demand has a time-window during which the service of the demand has to start. Within the time-window service can only start when a time-slot is available. The time-slots are laid out by the infrastructure manager who sets them in advance. There is approximately one time-slot every half hour and with time-windows of about 6 hours, there is a limited number of possible departure times. The planning horizon for the schedule is one week, whereas the rotation period of the engines can be as long as necessary.

General reviews of railway optimization methods can be found in Cordeau, Toth, and Vigo (1998); Huisman, Kroon, Lentink, and Vromans (2005); Lusby, Larsen, Ehrgott, and Ryan (2011). Recent work on railway timetabling can be found in Cacchiani and Toth (2012)
                  


                     Cacchiani, Caprara, and Toth (2008) consider timetabling in a similar corridor and Ziarati, Soumis, Desrosiers, Gélinas, and Saintonge (1997) solve an engine assignment problem with a heterogeneous fleet, but neither includes the path application concept considered in this paper.


                     Kuo, Miller-Hooks, and Mahmassani (2010) study the problem of implementing additional paths in a similar timetabling problem with elastic demands.


                     Nahapetyan and Lawphongpanich (2007) solve a dynamic traffic assignment problem where they use a circular approach as opposed to starting and ending with an empty system. Caimi, Fuchsberger, Laumanns, and Schüpbach (2011) use the Periodic Event Scheduling Model (PESP) on an infrastructure management level to generate feasible time-slot allocations. In the PESP, events are repeated over a time horizon, for instance 1 hour, such that a train is departing at the same minute every hour. Lindner and Zimmermann (2005) use the PESP model to create cost optimal train schedules for a railway operator. As the events in our case are periodic over a week, the time horizon in a PESP model would have to be set to one week. The PESP model considers the design of time-slots or at least the maximum time between different events such as two different trains departing from the same station and the headway between them. In our case this is handled by the choice of train paths and by avoiding overlaps.

Various problems with time-dependent costs have been studied over the past few years. Tagmouti, Gendreau, and Potvin (2007) study a variant of the Capacitated Arc Routing Problem (CARP) where the cost of a route depends on the start time of the service and no waiting is allowed between demands. The problem is transformed to a node routing problem and solved using a column generation scheme. Black, Eglese, and Wøhlk (2013) solve a Price-Collecting Arc Routing Problem (PARP) where transit-time is included in the objective; thus with transit-time being time-dependent the cost becomes so as well. The problem is solved using Variable Neighborhood Search and Tabu Search. Both applications forbid waiting time between demands, whereas our application allows for waiting between demands.

The problem is related to Vehicle Routing Problems with Time Windows (VRPTW). The problem at hand shares the time-window aspects of the VRPTW, but we allow only to service demand at discrete points during the time-window. The access to infrastructure is not considered by the VRPTW. For an introduction to the VRPTW, see Desrosiers, Dumas, Solomon, and Soumis (1995, chap. 2) and for a recent review of the VRPTW that focuses on heuristic methods to solve real-life instances we refer to Bräysy and Gendreau (2005a); 2005b). When not solved by heuristics, the VRPTW is often solved using column generation approaches, see e.g., Kallehauge, Larsen, Madsen, and Solomon (2005). We refer the interested reader to Baldacci, Mingozzi, and Roberti (2011) for a state of the art on solving the VRP and VRPTW. The Discrete Time Window Assignment Vehicle Routing Problem was introduced by Spliet and Desaulniers (2012) and this problem relates to our work as their model chooses among a discrete set of possible time-windows. They solve the problem using a Branch-Price-and-Cut algorithm.


We use a decomposition approach to split the problem into a master problem and a pricing problem. For more information on column generation, we refer the reader to Desrosiers and Lübbecke (2005) and Desrosiers et al. (1995). The pricing problem will be solved as a Shortest Path Problem with Resource Constraints, see Irnich and Desaulniers (2005), on a network representation of the demands. In Section 4.3.1 we explain the design of the network.

As described above, the problem of developing the weekly timetable is subject to multiple sets of constraints. To combine them into a joint formulation of the problem would result in a complex formulation. Instead we choose a column generation approach. Hereby the problem is decomposed in two, which reduces the complexity of the individual problems.

We split the model such that all constraints concerning the individual engines are dealt with in the pricing problem. In the master problem we consider the replication of weekly timetables, time-slot usage, availability of engines, and demand coverage, because these variables apply to multiple engines at once. By solving the pricing problem, we can generate engine schedules that are combined into a weekly timetable in the master problem.

The constraints shown in Fig. 1 are split into the master and sub-problems as follows. The first four constraints: demand coverage, availability of engines, replication of weekly timetable, and network capacity go into the master problem. The final six: time-slot compliance, time-window compliance, flow conservation,engine type compliance, waiting time after demands, and transit time between demands go into the sub-problem.

We use a delayed column generation approach and generate a column to enter the basis, i.e., the column with the most favorable reduced cost, each time we solve this restricted master problem to optimality. When solving the pricing problem we often get additional columns with negative reduced cost, these are also added to the master problem. We implement this with a branching method to form a Branch-and-Price setup.

We will handle two issues related to the replication of weekly timetables: Firstly, we need to define how to handle the circular nature of the weekly plan. Secondly, we have to decide on the design and length of the engine rotations. The engines rotation is the schedule/demands assigned to an engine before it returns to the same starting point, where the same can be repeated or another rotation with the same starting point can be started. The time a rotation takes to finish is referred to as the length of a rotation. The lack of weekly time-periods with all engines ’grounded’ presents a problem. The term ’engines grounded’ covers the scenario where we would have no activity during the night, i.e., all engines would be parked at a depot. This is more common in bus services or general passenger transportation in general. This forces the planning period to be circular in the sense that an engine departing at the very end of the week will arrive at the beginning of the week, see Fig. 2
                        (a).

The replication of weekly cycles is dealt with by by having a weekly timetable but a plan with a longer finite horizon for the individual engines, e.g., four weeks. Hence we have a weekly schedule that is not engine specific in the sense that it is not necessarily operated by the same engine every week.

For our approach to be viable we have to find a way to ensure that the different schedules fit together. We would like to avoid a complex formulation where we have to balance the weekly schedules with respect to both place and time. As regards place, there are no depots so therefore we treat all stations as depots such that we have a problem with multiple depots. This is important because an engine has to be ready at the end of one week at a place that fits with the starting place of the following week.

As the operation is continuous and does not have a fixed period without activity for engines or engine groups, there is no natural point that we could designate as the beginning of a week. To remove the time factor such that the start of the week can be kept fixed at the same time for all engines, we could choose a point during the week where no – or the least – demands cross and then balance the weekly schedules at this point.

Without the time factor we would face a problem related to defining the beginning/end of the week. In Fig. 2(a) we see an example of the end of week (eow) concept. It can be done in such a way that demands that start in the last part of a week continue into the next week which is essentially the beginning of the week. When we balance the number of weekly schedules that have a given station as their origin station with the number that have it as their destination station, the times of the origins must be before the times of the destinations in order to guarantee that engines are actually available.

To be able to remove the time factor we have to make sure that the first station on any schedule is serviced earlier than the last station on every schedule. To break the circularity of the weekly timetable we propose to find the point during a week that interferes with the least demands. At this point we split all demands that intersect it in two parts, one from the origin to the eow and one from the start of week until arrival. We call these two parts partial demands. These two partial demands are linked to a dummy station at the chosen eow as shown in Fig. 2(b). Each dummy station is unique for a demand that uses a specific time-slot.

The dummy station ensures that there will be one weekly schedule that starts with the first of the partial demands and one that ends with the last partial demand. Whether these two partial demands are on the same schedule is not important. If they are on the same schedule, there will be one circular schedule that will be driven by the same engine each week. If they are not in the same schedule, they will still be driven by the same engine but now they force the two weekly schedules involving them to be merged into a rotation of at least two weeks. At this point the other origin and destination stations are irrelevant as they will be balanced accordingly.

Demands that do not cross the eow remain unchanged as it is certain that the first station on a schedule is the origin and the last is the arrival and that they can never cross the eow. Thus when the flows in and out of ordinary and dummy stations are balanced, we ensure that all schedules are able to be part of an engine rotation. Any given engine will perform a subset of these schedules over several weeks. The rotation time for an engine is thus bounded by that number. These engine rotations are combined into the overall schedule.

In this section, we first show the formulation of the master problem. The master problem is formulated with the parameters given in Table 1
                        and Eqs. (1) to (6).

As columns in the master problem we use engine schedules generated in the pricing problem. Thus selecting a column represents using the corresponding schedule for an engine. The only variable in the model, xr
                        , represents choosing this column. Here xr
                         equals 1 if a given column is used, and 0 otherwise. The set Ω is the set of columns under consideration. Hence this set will be adjusted as we add and remove columns in the restricted master problem.

The objective function is given in Eq. (1) where cr
                         is the total cost for the column r, corresponding to a given schedule. Thus we seek to minimize the total cost which is composed by a fixed engine usage cost and driving costs, both engine type specific.

                           
                              (1)
                              
                                 
                                    minimize
                                    
                                    Z
                                    =
                                    
                                       ∑
                                       
                                          r
                                          ∈
                                          Ω
                                       
                                    
                                    
                                       c
                                       r
                                    
                                    
                                       x
                                       r
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    s.t.,
                                    
                                       ∑
                                       r
                                    
                                    
                                       α
                                       
                                          r
                                       
                                       d
                                    
                                    
                                       x
                                       r
                                    
                                    =
                                    1
                                    ,
                                    ∀
                                    d
                                    ∈
                                    D
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       ∑
                                       r
                                    
                                    
                                       β
                                       
                                          r
                                       
                                       n
                                    
                                    
                                       x
                                       r
                                    
                                    =
                                    0
                                    ,
                                    ∀
                                    n
                                    ∈
                                    N
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    
                                       ∑
                                       r
                                    
                                    
                                       γ
                                       
                                          r
                                       
                                       s
                                    
                                    
                                       x
                                       r
                                    
                                    ≤
                                    1
                                    ,
                                    ∀
                                    s
                                    ∈
                                    S
                                 
                              
                           
                        
                        
                           
                              (5)
                              
                                 
                                    
                                       ∑
                                       r
                                    
                                    
                                       δ
                                       
                                          r
                                       
                                       e
                                    
                                    
                                       x
                                       r
                                    
                                    ≤
                                    
                                       w
                                       e
                                    
                                    ,
                                    ∀
                                    e
                                    ∈
                                    E
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       x
                                       r
                                    
                                    ∈
                                    
                                       {
                                       0
                                       ;
                                       1
                                       }
                                    
                                    ,
                                    ∀
                                    r
                                    ∈
                                    Ω
                                 
                              
                           
                        
                     

In Eq. (2) we make sure that all demands are serviced by the engines. To ensure the necessary balance between the starting and ending stations of the engines we have the balance constraint (3). This constraint also balances the dummy stations such that an engine ending at a dummy station forces an engine to start at the same dummy station. In Eq. (4) we ensure that each time-slot is used at most once. Engine availability is ensured by Eq. (5), where we bound the number of each engine type used. Finally the binary constraint (5) forces each schedule to be used at most once.

To generate the columns in the pricing problem we have to find columns with negative reduced costs and therefore we determine the reduced costs by using the duals from the master problem to alter the costs in the pricing problem such that a minimization of the pricing problem results in the columns with the lowest reduced cost. Let 
                           π, ρ, σ
                        ,  and 
                           τ
                         represent the vectors of the dual variables defined by constraints (2), (3), (4), and (5) respectively, e.g., 
                           π
                         = [πd
                        ], ∀d ∈ D.

In the pricing problem, we handle the weekly schedule of a single engine. The goal is to choose a set of demands to form a schedule, subject to a set of constraints. The costs of the demands are original costs adjusted with the duals from the master problem. The total cost in the pricing problem then becomes the reduced cost for the corresponding column in the master problem.

The constraints in the pricing problem are: path compliance, time-window compliance, engine type compliance, flow conservation, transit, and waiting times between demands.

The pricing problem will be solved as a Shortest Path Problem with Resource Constraints, see Irnich and Desaulniers (2005), on a network representation of the demands. In Section 4.3.1 we explain the design of the network. For each demand i ∈ N, there is a time-window in which the service of the demand can be initiated. Within this time-window the demands can be serviced only at specific time-periods, i.e., where a path is available.

Sometimes it is necessary for the engine to drive from one station to another without servicing a demand, we refer to any such trip as a deadheading trip. In case of deadheading, we can choose to place waiting time either before deadheading at the destination of the previous demand and/or at the origin station of the following demand. Knowing that the deadheading cost is time-dependent, we must choose the optimal waiting time before starting the deadheading.

The pricing problem is defined with the parameters given in Table 2
                        . Define the variables ytij
                         ∈ {0; 1} where ytij
                         = 1 if demand j is serviced immediately after demand i at time t, and ytij
                         = 0 otherwise. Further define ze
                         ∈ {0; 1} as ze
                         = 1 if engine type e is used, and ze
                         = 0 otherwise. Then the objective function is defined as shown in Eq. (7).

                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             
                                                c
                                                r
                                             
                                             ¯
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   e
                                                   ∈
                                                   E
                                                
                                             
                                             
                                                (
                                                
                                                   (
                                                   
                                                      υ
                                                      e
                                                   
                                                   −
                                                   
                                                      τ
                                                      e
                                                   
                                                   )
                                                
                                                
                                                   z
                                                   e
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                                ∑
                                                
                                                   t
                                                   ∈
                                                   T
                                                
                                             
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   D
                                                
                                             
                                             
                                                (
                                                
                                                   (
                                                   
                                                      ψ
                                                      
                                                         t
                                                         j
                                                      
                                                   
                                                   −
                                                   
                                                      π
                                                      j
                                                   
                                                   −
                                                   
                                                      ∑
                                                      
                                                         s
                                                         ∈
                                                         
                                                            S
                                                            
                                                               j
                                                               t
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      σ
                                                      s
                                                   
                                                   )
                                                
                                                
                                                   ∑
                                                   
                                                      i
                                                      ∈
                                                      D
                                                   
                                                
                                                
                                                   y
                                                   
                                                      t
                                                      i
                                                      j
                                                   
                                                
                                                +
                                                
                                                   ∑
                                                   
                                                      i
                                                      ∈
                                                      D
                                                   
                                                
                                                
                                                   ϕ
                                                   
                                                      t
                                                      i
                                                      j
                                                   
                                                
                                                
                                                   y
                                                   
                                                      t
                                                      i
                                                      j
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                                ∑
                                                
                                                   
                                                      j
                                                      |
                                                   
                                                   
                                                      y
                                                      
                                                         (
                                                         arg
                                                         
                                                            min
                                                            
                                                               
                                                                  t
                                                                  |
                                                               
                                                               
                                                                  ∑
                                                                  
                                                                     j
                                                                     ∈
                                                                     D
                                                                  
                                                               
                                                               
                                                                  y
                                                                  
                                                                     t
                                                                     0
                                                                     j
                                                                  
                                                               
                                                               =
                                                               1
                                                            
                                                         
                                                         
                                                            {
                                                            t
                                                            }
                                                         
                                                         )
                                                         0
                                                         j
                                                      
                                                   
                                                   =
                                                   1
                                                
                                             
                                             
                                                ρ
                                                
                                                   o
                                                   j
                                                
                                             
                                             −
                                             
                                                ∑
                                                
                                                   
                                                      j
                                                      |
                                                   
                                                   
                                                      y
                                                      
                                                         (
                                                         arg
                                                         
                                                            max
                                                            
                                                               
                                                                  t
                                                                  |
                                                               
                                                               
                                                                  ∑
                                                                  
                                                                     i
                                                                     ∈
                                                                     D
                                                                  
                                                               
                                                               
                                                                  y
                                                                  
                                                                     t
                                                                     i
                                                                     0
                                                                  
                                                               
                                                               =
                                                               1
                                                            
                                                         
                                                         
                                                            {
                                                            t
                                                            }
                                                         
                                                         )
                                                         i
                                                         0
                                                      
                                                   
                                                   =
                                                   1
                                                
                                             
                                             
                                                ρ
                                                
                                                   a
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The first term determines the cost of using the engine and is modified by the dual vector 
                           τ
                        . Then we have the duals for servicing the demands 
                           π
                         and the duals for using the time-slots 
                           σ
                        . The costs for using a station as origin station and arrival station are represented by the dual 
                           ρ
                        . We find the origin station oj
                         by finding the first demand of the week. Then we take the appropriate cost ρn
                         for using this station n as origin station. We find the first time-period t where we start service for any demand by 
                           
                              arg
                              
                                 min
                                 
                                    
                                       t
                                       |
                                    
                                    
                                       ∑
                                       
                                          j
                                          ∈
                                          D
                                       
                                    
                                    
                                       y
                                       
                                          t
                                          0
                                          j
                                       
                                    
                                    =
                                    1
                                 
                              
                              
                                 {
                                 t
                                 }
                              
                           
                        . This is done by finding the first time-period, t, with y
                        
                           t0j
                         = 1 for any j. We set i = 0 to represent the source/sink. For the last time-period, we return to the sink, thus we have j = 0 and maximize t instead to find the last time-period with a demand.

The pricing problem is normally defined on a graph, G = (N, A), where N is the set of nodes (demands) and A is the set of arcs (transition between demands). Here, the constraints are handled by the graph where only feasible connections are possible. We solve the SPPRC using a labeling algorithm and hence we have a resource measuring time consumption. When extending from one demand to another we use the time consumption to determine the cost of the extension. As this cost is time-dependent and we can add waiting time before extending, we have different extension possibilities that – possibly – do not dominate each other. We do not know the optimal time within the time-window to service demands with time-dependent costs and therefore – as a worst case – we would have to explore all possible service times leading to huge numbers of combinations of service time at demand 1, waiting time before deadheading, and service time at demand 2.

We obtain the aforementioned network by transforming the original graph. The algorithm simply creates a copy of each demand for every time-period within the time-window with an available time-slot. Then finally, we update the successors for each demand. As we now have a fixed service time for each node, we can calculate the time when it is possible to make a feasible connection between any two nodes.

To allow for repositioning before the first demand and after the last demand serviced, we insert reposition nodes just after the source and before the sink. The source and sink are only connected to the repositioning nodes and thus any schedule will have to use a repositioning node at both ends; note, however, that the repositioning can be to the same node as when the schedule ends and thus constitute a free repositioning.

After transforming the network it appears to be an acyclic network where elementary paths can be obtained using a standard algorithm. But as multiple nodes represent the same demands, a path with more than one node representing the same demand constitutes a cycle and is thus a non-elementary path.

To find the elementary shortest path in this network we use the label correcting algorithm proposed in Feillet, Dejax, Gendreau, and Gueguen (2004). Note that due to the acyclic nature of the graph, we do not have a time resource. As the demands are tied to multiple nodes, the resources represent demands and therefore multiple nodes compete for the same resource. The use of this algorithm therefore guarantees an optimal solution.

This approach can be slow because having one resource for each demand causes many labels to be non-dominated. Instead, as suggested by Boland, Dethridge, and Dumitrescu (2006); Righini and Salani (2008), we focus on a subset of the resources. We do this by taking a non-elementary path and adding as resources the demands that cause it to be non-elementary. Then the problem is solved until an optimal elementary path is obtained. We denote this method Delayed Resource Constraints (DRC).

In most cases the cycles prove to be 2-cycles. As suggested by Houck, Picard, Queyranne, and Vemuganti (1980) it is relatively easy to remove them without deteriorating the asymptotic worst case running time. We denote this method 2-Cycle Elimination (2CE).

We have two branching rules. Rule A considers fixing the time of servicing a demand d by splitting the time-windows in two. Rule B is a follow-on branching that chooses a pair of demands, where one has to be performed immediately after the other.

We first consider branching rule A. For each column xr
                        , we have a vector 
                           v
                        
                        
                           r
                         corresponding to N′, indicating which nodes i in G′(N′, A′) we visit. Hence 
                           
                              
                                 v
                                 r
                                 i
                              
                              =
                              1
                           
                         if node i is visited by schedule r, and zero otherwise. From this vector, we define the disjoint subsets 
                           
                              
                                 N
                                 d
                                 ′
                              
                              ,
                              ∀
                              d
                              ∈
                              D
                           
                         of all the nodes i that serve the demand d. Thus 
                           
                              N
                              d
                              ′
                           
                         is the set of all the copies of a specific demand. We call this the node family of demand d. When splitting a time-window we remove a subset of the nodes in 
                           
                              N
                              d
                              ′
                           
                        . Instead of splitting it into two halves, we perform what we call a balanced split as follows:

From the master problem, we know that Eq. (8) must hold.

                           
                              (8)
                              
                                 
                                    
                                       ∑
                                       
                                          r
                                          ∈
                                          Ω
                                       
                                    
                                    
                                       ∑
                                       
                                          i
                                          ∈
                                          
                                             N
                                             d
                                             ′
                                          
                                       
                                    
                                    
                                       x
                                       r
                                    
                                    
                                       v
                                       r
                                       i
                                    
                                    =
                                    1
                                    ,
                                    ∀
                                    d
                                    ∈
                                    D
                                 
                              
                           
                        We define 
                           λ
                         as the set {λi
                        : i ∈ N′}. In Eq. (9), we define λi
                         as the fraction of the demand d that is serviced by a specific node i ∈ N′. For any solution to be feasible, 0 ≥ λi
                         ≤ 1 must be true for all i ∈ N′. If 0 < λi
                         < 1 for any i ∈ N′, then the solution must be fractional as there can be at most one 
                           
                              i
                              ∈
                              
                                 N
                                 d
                                 ′
                              
                           
                         serviced by any schedule r in an integer solution.

                           
                              (9)
                              
                                 
                                    
                                       λ
                                       i
                                    
                                    =
                                    
                                       ∑
                                       
                                          r
                                          ∈
                                          Ω
                                       
                                    
                                    
                                       x
                                       r
                                    
                                    
                                       v
                                       r
                                       i
                                    
                                    ,
                                    ∀
                                    i
                                    ∈
                                    
                                       N
                                       ′
                                    
                                 
                              
                           
                        In Eq. (10), we define 
                           λ
                        
                        
                           d
                         as disjoint subsets of 
                           λ
                         such that every λi
                         that serves the same demand d is present in exactly one 
                           λ
                        
                        
                           d
                        .

                           
                              (10)
                              
                                 
                                    
                                       
                                          λ
                                       
                                       d
                                    
                                    =
                                    
                                       {
                                       
                                          λ
                                          i
                                       
                                       :
                                       i
                                       ∈
                                       
                                          N
                                          d
                                          ′
                                       
                                       }
                                    
                                    ,
                                    ∀
                                    d
                                    ∈
                                    D
                                 
                              
                           
                        We know from Eq. (8) that Eq. (11) must be true.

                           
                              (11)
                              
                                 
                                    
                                       ∑
                                       
                                          i
                                          ∈
                                          {
                                          i
                                          :
                                          
                                             λ
                                             i
                                          
                                          ∈
                                          
                                             
                                                λ
                                             
                                             d
                                          
                                          }
                                       
                                    
                                    
                                       λ
                                       i
                                    
                                    =
                                    1
                                 
                              
                           
                        As an example of a fractional solution, we can have 
                           
                              
                                 
                                    λ
                                 
                                 15
                              
                              =
                              
                                 {
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 ,
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 ,
                                 
                                    1
                                    2
                                 
                                 ,
                                 0
                                 }
                              
                           
                        . The goal of splitting up the time-window, which is represented by 
                           λ
                        
                        
                           d
                        , is to equally divide the fractional values on the branches. Hence a left branch will be 
                           
                              
                                 
                                    λ
                                 
                                 15
                              
                              =
                              
                                 {
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 ,
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 }
                              
                           
                         and a right branch will be 
                           
                              
                                 
                                    λ
                                 
                                 15
                              
                              =
                              
                                 {
                                 
                                    1
                                    2
                                 
                                 ,
                                 0
                                 }
                              
                              ,
                           
                         which is what we call the balanced split. The corresponding nodes are then removed from 
                           
                              N
                              d
                              ′
                           
                         and N′ as well.

To choose the demand d ∈ D on which to perform this split, we find the 
                           λ
                        
                        
                           d
                         with the most non-zero λi
                        . This means that 
                           
                              
                                 
                                    λ
                                 
                                 15
                              
                              =
                              
                                 {
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 ,
                                 0
                                 ,
                                 
                                    1
                                    4
                                 
                                 ,
                                 
                                    1
                                    2
                                 
                                 ,
                                 0
                                 }
                              
                           
                         has three non-zero values.

The second branching rule, rule B, is a follow-on procedure. When the branching opportunities for rule A are exhausted, we know that all demands are serviced at a fixed time but possibly by different engines. In this situation, the solution can be fractional if two or more demands are serviced by different schedules. We therefore wish to force the demands into a given sequence that will be serviced by a single engine. As we know from rule A that all demands are fixed in time, we focus on the general network G(N, A). We define 
                           w
                        
                        
                           r
                         for the nodes serviced in G(N, A) by a schedule r. This corresponds to the vector 
                           v
                        
                        
                           r
                         for the nodes serviced in the graph G′(N′, A′). The relation is shown in Eq. (12) and Fig. 3
                        .

                           
                              (12)
                              
                                 
                                    
                                       w
                                       r
                                       d
                                    
                                    =
                                    
                                       ∑
                                       
                                          i
                                          ∈
                                          
                                             N
                                             d
                                             ′
                                          
                                       
                                    
                                    
                                       v
                                       r
                                       i
                                    
                                    ,
                                    ∀
                                    d
                                    ∈
                                    D
                                 
                              
                           
                        From Eq. (12), we observe that 
                           
                              w
                              r
                              d
                           
                         is the sum of the nodes in the node family of d. Notice that only one of these can be in a single schedule. We now have the vector 
                           w
                        
                        
                           r
                         for each r. Hence we know whether the demands are serviced or not, i.e., 
                           
                              
                                 w
                                 r
                                 d
                              
                              =
                              1
                           
                         if demand d is serviced by schedule r, and 
                           
                              
                                 w
                                 r
                                 d
                              
                              =
                              0
                           
                         otherwise.

We then construct a vector 
                           η
                        
                        
                           r
                         of the demand indices for demands with 
                           
                              
                                 w
                                 r
                                 d
                              
                              =
                              1
                           
                        . This can be seen in Eq. (13). The relationship between 
                           v
                        
                        
                           r
                        , 
                           w
                        
                        
                           r
                        , and 
                           η
                        
                        
                           r
                         is illustrated in Fig. 3.

                           
                              (13)
                              
                                 
                                    
                                       
                                          η
                                       
                                       r
                                    
                                    =
                                    
                                       [
                                       d
                                       :
                                       
                                          w
                                          r
                                          d
                                       
                                       =
                                       1
                                       ]
                                    
                                    ,
                                    ∀
                                    d
                                    ∈
                                    D
                                 
                              
                           
                        
                     

In the vector 
                           η
                        
                        
                           r
                        , the first demand serviced by schedule r will be the demand ηr
                        [i = 1] and the last will be 
                           
                              
                                 η
                                 r
                              
                              
                                 [
                                 i
                                 =
                                 
                                    ∑
                                    
                                       d
                                       ∈
                                       D
                                    
                                 
                                 
                                    w
                                    r
                                    d
                                 
                                 ]
                              
                           
                        . As shown by Ryan and Foster (1981) we know that in any fractional solution, there will be a pair of demands serviced by different schedules. Thus the sum of the xr
                         variables when they are serviced together must be between 0 and 1, see Eq. (14).

                           
                              (14)
                              
                                 
                                    0
                                    
                                    <
                                    
                                       ∑
                                       
                                          r
                                          ∈
                                          {
                                          r
                                          :
                                          
                                             w
                                             r
                                          
                                          
                                             [
                                             
                                                d
                                                1
                                             
                                             ]
                                          
                                          =
                                          
                                             w
                                             r
                                          
                                          
                                             [
                                             
                                                d
                                                2
                                             
                                             ]
                                          
                                          =
                                          1
                                          }
                                       
                                    
                                    
                                       x
                                       r
                                    
                                    <
                                    1
                                 
                              
                           
                        If all pairs of demand are 1 or 0, we have an integer solution. To get an integer solution, Ryan and Foster (1981) branch so that the Eq. (14) equals 1 or 0. If this holds for all pairs, it also holds for pairs that are serviced immediately after each other. We obtain the values for these immediately preceding pairs in Eq. (15), where pij
                         is the flow on the corresponding arc (ij) in G(N, A).

                           
                              (15)
                              
                                 
                                    
                                       p
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       ∑
                                       
                                          
                                             
                                                
                                                   r
                                                   ∈
                                                   {
                                                   r
                                                   |
                                                   ∃
                                                   k
                                                   :
                                                   
                                                      η
                                                      r
                                                   
                                                   
                                                      [
                                                      k
                                                      ]
                                                   
                                                   =
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   ∧
                                                   
                                                   
                                                      η
                                                      r
                                                   
                                                   
                                                      
                                                         [
                                                         k
                                                         +
                                                         1
                                                         ]
                                                      
                                                      =
                                                      j
                                                      }
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       x
                                       r
                                    
                                    ,
                                    ∀
                                    i
                                    ∈
                                    D
                                    ,
                                    j
                                    ∈
                                    D
                                 
                              
                           
                        When branching, we set 
                           
                              
                                 p
                                 
                                    
                                       d
                                       1
                                    
                                    ,
                                    
                                       d
                                       2
                                    
                                 
                              
                              =
                              1
                           
                         on the left branch and 
                           
                              
                                 p
                                 
                                    
                                       d
                                       1
                                    
                                    ,
                                    
                                       d
                                       2
                                    
                                 
                              
                              =
                              0
                           
                         on the right branch. This forces d
                        2 to be visited right after d
                        1 – if visited at all. Thus we remove all connections to other demands from d
                        1. On the other branch, we forbid this connection. What we effectively do is to merge these two demands into one new demand.

When we determine two demands to branch on, we select the pair with 
                           
                              p
                              
                                 
                                    d
                                    1
                                 
                                 
                                    d
                                    2
                                 
                              
                           
                         closest to 1.

A depth first search is often used in a Branch-and-Price algorithm to allow the master problem to remain as unchanged as possible when moving down the node tree. In a breadth first search, an additional number of columns has to be stored and reinserted at the nodes. This process increases the memory requirement significantly. Furthermore, the lower bound from the LP-relaxation in the root node to this particular problem is very strong and is either very close to the optimal integer solution or equal to. This indicates that it is favorable to look for an integer feasible solution with a depth first rather than a breadth first search.

To speed up the process we use a stronger branching rule until we have found the first integer feasible solution. This is a variation of the time-window split where instead of splitting the time-window evenly, we split it such that the single node with the highest fractional value is on one branch and the rest are on the other. This efficiently leads to the first integer solution, but yields an asymmetric branching tree. It takes very long time to close this tree because the remaining branches are very weak. Therefore we restart the branching tree after finding the first integer solution and return to the standard time-window split.

Experiments with alternative node selection strategies on a significant set of instances prove the superiority of the combined strategy.


@&#IMPLEMENTATION@&#

The overall Branch-and-Price algorithm can be seen in Fig. 4
                        . The algorithm starts preprocessing by finding a point during the week with the smallest number of possible activities. We designate this as the end of week. This is often in the early hours of Sunday. Then the LP-relaxation is solved with a set of columns allowing for an initial feasible solution. This set consists of expensive columns serving exactly one demand each and using no engines and time-slots. An initial solution from a heuristic is often used to speed up the solution of the root LP-relaxation for column generation. Time is not the most important factor here and the algorithm reaches the solution of the root node relatively fast and thus a good initial solution would not provide a significant overall speed up.

When the LP-relaxation has been solved, the dual values are passed to the pricing problem. In all cases, we solve the pricing problem with a labeling algorithm and use only elementary schedules. We first solve the pricing problem with a heuristic that only allows for a waiting time between demands of 12 hours and 24 hours for the engines, irrespective of whether they deadhead or not. This procedure significantly reduces the number of possible connections and thus provides a significant speed up with high quality columns. When we cannot find any more elementary columns with negative reduced costs, we run the exact algorithm with 2-cycle elimination to ensure optimality. If the best solution to the pricing problem is elementary and of non-negative reduced cost, we skip the next algorithm for the pricing problem as we have an optimal solution to the LP-relaxation. The final ESPPRC algorithm for the pricing problem ensures that we always find an elementary solution. The algorithm iteratively adds resource constraints to the problem depending on which nodes cause the schedule to be non-elementary. This process continues until the best solution is elementary. The algorithm is not used very often as the 2-cycle elimination is, in most cases, enough to avoid any length cycles.

If we have negative reduced cost schedules, we add columns to the master problem. As we do not dominate labels on the sink node, a large number of columns can be added. Experiments with addition of different percentages of the possible columns yielded no clear result, but the trade-off is between adding all, i.e., one per node in the pricing problem, and only the best. Adding all gives the best information for the duals, but over time the LP-relaxation becomes overburdened by the high number of columns added. On the other hand adding only the best columns results in a fast LP-relaxation, but adds a large number of additional calls of the pricing problem algorithm. Good results were obtained by adding a number of columns corresponding to at most 50% of the nodes in the pricing problem and removing unused columns in the LP. It is important to note that we only add the elementary columns with a negative reduced cost, thus we often add less columns than dictated by the maximum.

It is necessary to remove unused columns because we insert a relatively high number of columns after each LP iteration. Columns that have not entered the basis for the first 100 LP iterations are removed from the master problem. Experiments with different values did not lead to any decisive results. We still need to keep enough information in the LP but balance this against the size of the LP. Notice, that to ensure that we always have a feasible solution to the LP-relaxation, the columns representing the initial solution are never removed.

In the DBSRS case we have a given set of engines at hand and the opportunity costs for these engines are not fixed. Thus it is difficult to associate the engines with a fixed charge. The planning department at DBSRS currently has to cover approximately 230 demands per week. Each demand has a fixed time-window wherein the service has to start. The length of the time-windows can vary from customer to customer. The start of service also implies an end of service time-window. The DBSRS operates a network of 15 active stations that are connected in a tree like structure such that there is only one route between any two stations. The rail network is managed by a different infrastructure manager in each of the three countries in which DBSRS operates. Applications for time slots are handled by the infrastructure manager during the spring the year before the tracks are actually needed. Basically this requires contracts with clients to be made almost a year in advance. The cost structure for using the tracks differs from country to country in the region covered by DBSRS. The first cost category is quite simple and reflects the number of kilometers driven, whereas others involve fixed costs for passing specific points. The costs of using tracks vary over time in some areas and are subject to a capacity charge. Capacity costs are designed to reduce traffic at certain times and are enforced in Denmark and Sweden. In Denmark, the charge applies if the train uses any part of the sections covered by the capacity charge within the time-window from 7:00 to 18:59. In Sweden they have a similar system, but here the time-windows are from 7:00 to 9:00 and from 16:00 to 18:00 covering the passage of a number of sections. Each coverage of a demand is associated with some preparation time at the station of origin and finalization time at the destination. This time is mainly used for shunting cars, but there may also be a safety margin that serves to prevent propagation of delays. The transit times and time-slots in the DBSRS operational area on the main pathway of corridor 1 are identified using the information from RailNetEurope. This approach cannot be used to identify transit times and time-slots on legs outside the main pathway as the time-slots are not specified. Thus we design these by letting time-slots connect to the time-slots in the main pathway. The model does not consider maintenance. In the DBSRS case, maintenance is carried out at 10,000 kilometers intervals. Here the engines are taken out of service and replaced by spare engines that continue the engine rotations.

The paths are designed either by RNE, in which case they are called catalogue paths, or the railway operator can design and apply for path themselves, in which case they are called tailor-made paths. By definition, the catalogue paths comply with the regulations such that the paths are feasible. This paper focuses on choosing among the (RNE designed) catalogue paths. Thus the problem is to choose the set of paths that reduces the operating costs of the railway operator. We apply this problem to a case arising at a railway operator who manages the timetabling of unit trains.

Experiments have been carried out on an Intel Core i7 2.8  GHz and implemented with C++ as a sequential algorithm. We use ILOG CPLEX 12.4 to solve the LP-relaxation.

We have generated a set of 35 instances based on actual demand data from DBSRS. The instances with 228 total demands are the real case demands and all other instances are variations hereof. The network and path information are derived from RailNetEurope. Instances with less than 228 demands have had demands removed. This has been done in the following ways: In the instances marked (s), we have removed demands pair-wise, i.e., demands with opposite origin and destination. These are removed from the end of the week to preserve the density of the problem. In the instances marked (ex3) and (ex6), the time-windows have been extended by 3 and 6 hours respectively. These instances are based on the (s)-instances, such that they are similar in every way except for the time-window length.

In the (r)-instances, we randomly remove demands such that the symmetry is not kept and the demands are evenly spread over the week. Because the instances with 228 demands are the base case, they do not have an (r)-instance, therefore these are shaded in the result tables.

Instances with more than 228 demands are generated in the following way: the (s)-instances have had demands added pair-wise by randomly selecting a pair and a new time-window. The (ex3) and (ex6) are based on the (s)-instances, these have had the time-windows extended as previously described.

The (r)-instances have had single demands added, these are randomly selected and a new time-window is also generated at random for these.

A general feature of the (s),(ex3), and (ex6)-instances is that the demands are symmetric, i.e., all origin and destination pair are matched in the opposite direction. The (r)-instances does not share this feature.

@&#RESULTS@&#

The algorithm provides high quality integer solutions to real sized problem instances in about 4 hours (s-instances). This is highly satisfactory considering the time horizons involved in the planning process. As this is carried out on a yearly basis and with long deadlines we are willing to allocate even more time to this process if necessary.

The algorithm is applied in a version using three engine types; one diesel engine and two different electrical engines of which one has a greater pulling power and thus has to be used on some specific demands. Hence some demands can be serviced only by the diesel engine, by the strong electrical engine, by both electrical engines, or by all three engine types.

We have also carried out tests using only one engine type. The tests are performed on a representative set of the instances. When comparing the usage of one versus three engine types the runtime roughly doubles when we solve three pricing problems instead of one and add additional complexity to the model. Note, however, that we do not solve all pricing problems in every iteration unless necessary. Each individual pricing problem is smaller than the single pricing problem.

First we discuss the instances with 228 demands or less. Table 3
                        shows that for most instances the initial integer solution found is equal to the objective value of the root LP-relaxation and thus optimal. For some instances we find an integer solution very close to the root relaxation and thus have to continue branching. It takes considerable time to close the gap and prove optimality. The gap between the root node and the best integer solution is within the range of <0.2%, which is a relatively small gap. To use a solution that may be sub-optimal, but with a very small gap is not a critical worst case scenario in practice. In a few cases the algorithm does not prove optimality within the 12 hours preset time limit. However, it finds a high quality integer solution for all instances within the time limit.

As expected Table 3 clearly shows that the solution time decreases significantly as the instances get smaller. When we compare the (s)-instances with the (r)-instances, it appears that the latter have a shorter runtime. As expected the expanded time-window instances (ex3 and ex6) both take longer time to solve. This is mainly due to the fact that they result in much larger pricing problems that have to be called more often.

For the instances with 270 and 300 demands, the amount of engines available has also been increased. The instances larger than 228 demands define the limitations of the algorithm. It is clear that we do not find integer solutions for most larger instances where the time-windows are expanded. A feature that contributes to this is that the pricing problems becomes much larger when expanding the time-windows. However, the algorithm is also able to solve problems of up to 300 demands on occasions. Without expanding the time-windows we are able to find integer solutions to all but one instances with 240 and 270 demands. Please note that due to the availability of engines there is no guarantee that an integer solution exist. The test with larger instance size suggest that the algorithm is usable for larger instances, but it is sensitive to the size of the pricing problems.

For all instances the time to solve the root node is much shorter than acquiring a feasible integer solution. Combined with the fact that the root relaxation provides a very strong lower bound this means that we can evaluate the consequences of changes rapidly for practical instances and later get the actual solution, if necessary.

When we look at Table 4
                        it appear that it is often enough to solve the pricing problem using the heuristic algorithm. For solving the remaining pricing problems the 2-cycle elimination algorithm is very effective. For all reduced sized instances (s, ex3, ex6), the 2-cycle elimination always ensures elementary columns. The reason for this is that the time-window length compared to travel times does not allow for cycles longer than 2. In the remaining full size and (r)-instances, we have demands that cross the end of the week and therefore they are represented both in the beginning and in the end of the week. The demand can therefore be serviced either in the beginning of the period or toward the end. This could obviously be a cycle of much greater than length 2 and therefore it may be necessary to use the ESPPRC algorithm to ensure elementary columns in these cases.


                        Table 5
                        show that branching method A is used more often than B, which is expected as it has first priority. Branching method B is not used in some instances. Those instances are all small and capacity constraints are not as tight as in the large instances.

@&#CONCLUSIONS@&#

In this paper we have presented a model to solve the problem of creating a yearly timetable for a freight railway operator using the available infrastructure paths. We have proved that the model is able to provide high quality integer solutions to real-life sized instances. It solves relatively fast and thus leaves room for flexibility in problem size and time-window lengths for practical applications when considering that we have a fairly long planning horizon. We have analyzed the running time effects of reducing the number of available engines and of increased time-window sizes. The model also provides a fast lower bound that can be used to assess the consequences of changes in the timetable, the consequences of reducing the number of engines available to assess the marginal cost of this, or the possibility of serving additional demands.

@&#ACKNOWLEDGMENTS@&#

Part of this work has been carried out while Lukas Bach was visiting CIRRELT and we would like to thank CIRRELT for hosting this visit. We would also like to thank Deutsche Bahn Schenker Rail Scandinavia for providing real-life test data. This work is partly sponsored by the Nordic council, NordForsk project #259000. Finally, part of the data has been collected in cooperation with Anders Kastberg, whom we would like to thank for the collaboration.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Efficient 3D reflection symmetry detection: A view-based approach

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Propose a novel and efficient view-based symmetry detection algorithm.


                        
                        
                           
                           Demonstrate better accuracy and efficiency compared with two latest approaches.


                        
                        
                           
                           Dataset-level evaluation and two related applications validate good robustness and flexibility.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Symmetry detection

Reflection symmetry

View-based approach

Viewpoint entropy

Matching

@&#ABSTRACT@&#


               
               
                  Symmetries exist in many 3D models while efficiently finding their symmetry planes is important and useful for many related applications. This paper presents a simple and efficient view-based reflection symmetry detection method based on the viewpoint entropy features of a set of sample views of a 3D model. Before symmetry detection, we align the 3D model based on the Continuous Principal Component Analysis (CPCA) method. To avoid the high computational load resulting from a directly combinatorial matching among the sample views, we develop a fast symmetry plane detection method by first generating a candidate symmetry plane based on a matching pair of sample views and then verifying whether the number of remaining matching pairs is within a minimum number. Experimental results and two related applications demonstrate better accuracy, efficiency, robustness and versatility of our algorithm than state-of-the-art approaches.
               
            

@&#INTRODUCTION@&#

Symmetry is an important clue for geometry perception: it is not only in many man-made models, but also widely exists in the nature [1]. Symmetry has been used in many applications such as: 3D alignment [2], shape matching [3], remeshing [4], 3D model segmentation [5] and retrieval [6].

However, existing symmetry detection algorithms still have much room for improvement in terms of both simplicity and efficiency in detecting symmetry planes, as well as the degree of freedom to find approximate symmetry planes for a roughly symmetric 3D model. In addition, most of the existing symmetry detection methods are geometry-based, thus their computational efficiency will be tremendously influenced by the number of vertices of a model. Though sampling and simplification can be used to reduce the number of vertices, they also decrease the shape accuracy and cause deviations in geometry. Therefore, a symmetry detection algorithm often directly uses original models as its input, as can be found in many existing related papers.

Motivated by the symmetric patterns existing in the viewpoint entropy [7] distribution of a symmetric model, we propose a novel and efficient view-based symmetry detection algorithm (see Fig. 1
                     ) which finds symmetry plane(s) by matching the viewpoint entropy features of a set of sample views of a 3D model aligned beforehand using Continuous Principal Component Analysis (CPCA) [8]. Based on experimental results, we find that our symmetry detection algorithm is more accurate (in terms of both the positions of detected symmetry planes and sensitivity to minor symmetry differences), efficient, robust (e.g. to the number of vertices and parameter settings such as view sampling), and versatile in finding symmetry planes of diverse models.

In the rest of the paper, we first review the related work in Section 2. In Section 3, we present the viewpoint entropy distribution-based symmetry detection algorithm. Section 4 describes diverse experimental evaluation and comparison results of the detection algorithm. In Section 5, we show two interesting applications of our symmetry detection idea in 3D model alignment and best view selection. Section 6 concludes the paper and lists several future research directions. This paper is an extension of our prior publication [9].

@&#RELATED WORK@&#

Though there are different types of symmetry, reflection symmetry is the most important and commonly studied. Chaouch and Verroust-Blondet [2] introduced four types of reflection symmetries, which are cyclic (several mirror planes passing through a fixed axis), dihedral (several mirror planes passing through a fixed axis with one perpendicular to the axis), rotational symmetry (looks similar after rotation, e.g., different platonic solids, like tetrahedron, octahedron, icosahedron and dodecahedron) and unique symmetry (only one mirror plane, for instance, many natural and most man-made objects). Most symmetric objects are mirror rather than rotational symmetric [10].

Symmetry detection is to search the (partial or full) symmetry planes of a 3D object. The latest review on symmetry detection is available in [11]. We classify current symmetry detection techniques into the following four groups according to the features employed.

Symmetry detection based on pairing point features. This type of approach first samples points on the surface of a 3D model and then extracts their features. After that, it finds point pairs by matching the points. Based on the point pairs, symmetry evidences are accumulated to decide the symmetry plane. Two typical algorithms are [12] and [13]. To decide the symmetry plane, Mitra et al. [12] adopted a stochastic clustering and region-growing approach, while Calliere et al. [13] followed the same framework of pairing and clustering, but utilized 3D Hough transform to extract significant symmetries. In fact, the initial idea of this approach can be traced back to the symmetry distance defined in [14]. Podolak et al. [15] proposed a planar-reflective symmetry transform and based on the transform they defined two 3D features named center of symmetry and principal symmetry axes, which are useful for related applications such as 3D model alignment, segmentation, and viewpoint selection.


                              Symmetry detection based on pairing line features. Bokeloh et al. [16] targeted on the so-called rigid symmetries by matching feature lines. Rigid symmetries are the reoccurring components with differences only in rigid transformations (translation, rotation and mirror). They first extracted feature lines of a 3D model, then performed feature line matching, and finally validated the symmetry based on the feature correspondence information by adopting a region growing approach, as well.


                              Symmetry detection based on 2D image features. Sawada and Pizlo [10,17] performed symmetry detection based on a single 2D image of a volumetric shape. First, a polyhedron is recovered from the single 2D image based on a set of constraints including 3D shape symmetry, minimum surface area, maximum 3D compactness and maximum planarity of contours. Then, they directly compared the two halves of the polyhedron to decide its symmetry degree. From a psychological perspective, Zou and Lee [18,19] proposed one method to detect the skewed rotational and mirror symmetry respectively from a CAD line drawing based on a topological analysis of the edge connections.


                              Other symmetry detection approaches. Martinet et al. [20] proposed a 3D feature named generalized moments for symmetry detection. Rather than directly computing original moments features, they mapped them into another feature space by spherical harmonics transform and then searched for the global symmetry in the new feature space. Xu et al. [21] developed an algorithm to detect partial intrinsic reflectional symmetry based on an intrinsic reflectional symmetry axis transform. After that, a multi-scale partial intrinsic symmetry detection algorithm was proposed in [22]. There are also techniques to detect some other specific symmetries, such as curved symmetry [23] and symmetries of non-rigid models [24,25], as well as symmetry hierarchy of a man-made 3D model [26]. Kim et al. [27] detected global intrinsic symmetries of a 3D model based on Möbius Transformations [28], a stereographic projection approach in geometry. Recently, Wang et al. [29] proposed Spectral Global Intrinsic Symmetry Invariant Functions (GISIFs), which are robust to local topological changes compared to the GISIFs obtained from geodesic distances. Their generality and flexibility outperform the two classical GISIFs: Heat Kernel Signature (HKS) [30] and Wave Kernel Signature (WKS) [31].

All above and existing symmetry detection techniques can be categorized into geometry-based approach. However, distinctively different from them, we adopt a view-based approach to accumulate the geometrical information of many vertices together into a view in order to more efficiently detect the reflection symmetry of a 3D model, which also serves as the novelty and main contribution of our method.

As an important shape feature, symmetry is useful for many related applications. For example, they include symmetry plane detection for 3D MRI image [32], shape matching [3,15], 3D model alignment [6,33], shape processing and analysis [34] including remeshing [4], symmetrization [12], viewpoint selection [15], and subspace shape analysis [35], 3D segmentation [5,15,29], and curve skeleton extraction [36,37].

Properly normalizing a 3D model before symmetry detection can help us to minimize the searching space for symmetry planes to be some 2D planes that have certain common specific properties, i.e., passing the same 3D point. The process of 3D normalization includes three steps: 3D alignment (orientation normalization), translation (position normalization), and scaling (size normalization).

3D model alignment is to transform a model into a canonical coordinate frame, where the representation of the model is independent of its scale, orientation, and position. Two commonly used 3D model alignment methods are Principal Component Analysis (PCA) [38] and its descendant Continuous Principal Component Analysis (CPCA) [8] which considers the area of each face. They utilize the statistical information of vertex coordinates and extract three orthogonal components with largest extent to depict the principal axes of a 3D model. CPCA is generally regarded as a more stable PCA-based method. In addition, Johan et al. [39] proposed a 3D alignment algorithm based on Minimum Projection Area (MPA) motivated by the fact that many objects have normalized poses with minimum projection areas. That is, for many objects, one of their canonical views has a minimum projection area compared to the other arbitrary views of the objects. Therefore, they align a 3D model by successively selecting two perpendicular axes with minimum projection areas while the third axis is the cross product of the first two axes. It is shown in [39] that MPA can align most 3D models in terms of axes accuracy (the axes are parallel to the ideal canonical coordinate frame: front-back, left-right, or top-bottom view). It is also robust to model variations, noise, and initial poses. However, compared with the PCA-based approaches, MPA takes a longer time to align 3D models while for this research we want to detect symmetry fast.

After a comparison (see Section 4.3 for more details) of the influences of different 3D model alignment algorithms on the efficiency, accuracy and robustness of our view-based symmetry detection approach, we choose CPCA to align a model before performing symmetry detection. After the alignment with CPCA, we translate the model such that the center of its bounding sphere locates at the origin and scale the model such that its bounding sphere has a radius of 1. After this normalization, the symmetry plane(s) will pass the origin, which helps us to significantly reduce the searching space.

Vázquez et al. [7] proposed an information theory-related measurement named viewpoint entropy to depict the amount of information a view contains. It is formulated based on the Shannon entropy and incorporates both the projection area of each visible face and the number of visible faces into the definition. However, the original definition was developed based on perspective projection, thus we use its extended version defined in [40] for orthogonal projection.

For each model, we sample a set of viewpoints based on the Loop subdivision [41] on a regular icosahedron, denoted as L
                        0. We subdivide L
                        0 
                        n times and denote the resulting mesh as Ln
                        . Then, we set the cameras on its vertices, make them look at the origin (also the center of the model) and apply orthogonal projection for rendering. For a 3D model, to differentiate its different faces, we assign different color to each face during rendering. One example is shown in Fig. 2
                        .

The viewpoint entropy [40] of a view with m visible faces is defined as follows.

                           
                              (1)
                              
                                 
                                    E
                                    =
                                    −
                                    
                                       1
                                       
                                          
                                             log
                                             2
                                          
                                          
                                             (
                                             m
                                             +
                                             1
                                             )
                                          
                                       
                                    
                                    
                                       ∑
                                       
                                          j
                                          =
                                          0
                                       
                                       m
                                    
                                    
                                       
                                          
                                             A
                                             j
                                          
                                          S
                                       
                                       
                                          log
                                          2
                                       
                                       
                                          
                                             A
                                             j
                                          
                                          S
                                       
                                    
                                 
                              
                           
                        where, Aj
                         is the visible projection area of the jth (j=1, 2, 
                           
                              …
                              ,
                           
                         
                        m) face of a 3D model and A
                        0 is the background area. S is the total area of the window where the model is rendered: S=A
                        0+
                           
                              
                                 ∑
                                 
                                    j
                                    =
                                    1
                                 
                                 m
                              
                              
                                 A
                                 j
                              
                           
                        . Projection area is computed by counting the total number of pixels inside a projected face.


                        Fig. 3
                         shows the viewpoint entropy distributions of several models by using L
                        4 (2562 sample viewpoints) for view sampling and mapping their entropy values as colors on the surface of the spheres based on the HSV color model. We can see there is a perfect correspondence between the symmetry of a model and that of its viewpoint entropy distribution sphere: their symmetry planes are the same. Therefore, the symmetry of a 3D model can be decided by finding the symmetry in the entropy distribution, thus avoiding the high computational cost of direct matching among its geometrical properties. What’s more, since viewpoint entropy is computed based on the projection of each face, it is highly sensitive to small differences in the model. In addition, each viewpoint simultaneously captures the properties of many vertices and faces of a model as a whole, which also helps to significantly reduce the computational cost. We also find that it is already accurate enough based on a coarse view sampling, such as using L
                        1, as demonstrated in Section 4.2. Motivated by these findings, we propose to detect the symmetry of a 3D model based on its viewpoint entropy distribution.

Even only using L
                        1 (42 viewpoints) for view sampling, if based on a naive matching approach by first directly selecting half of the total viewpoints and then matching them with the remaining half, it will result in P(42, 21) 
                           
                              =
                              2.75
                              ×
                              
                                 10
                                 31
                              
                           
                         combinations. Thus, we develop a much more efficient symmetry detection method based on the following idea: iteratively select a matching pair of viewpoints to generate a symmetry plane and then verify all the rest matching pairs to see whether they are symmetric as well w.r.t the symmetry plane or at least in the symmetry plane. The method is listed in Algorithm 1.
                     

We need to mention the followings for the algorithm. The views corresponding to the viewpoints that are located on the symmetry plane do not need to match each other. While, according to the Loop rule [41], at most 
                           
                              2
                              
                                 n
                                 +
                                 2
                              
                           
                         vertices of Ln
                         are coplanar in a plane w.r.t a great circle. That is to say, at most 
                           
                              2
                              
                                 n
                                 +
                                 2
                              
                           
                         viewpoints could be in the real symmetry plane. An ideal algorithm is to perfectly match w.r.t the symmetry plane all the viewpoint pairs that are not in the symmetry plane. However, we have found that usually there are numerical accuracy problems related to 3D model rendering (e.g. aliasing), viewpoint entropy computation (usually the entropy values of two symmetric viewpoints are not completely the same), as well as possible (either big or minor) differences in mesh triangulation. Therefore, we propose to partially solve this issue by relaxing some of the conditions though it sometimes causes certain false positive detections: if the total number (matches) of matched viewpoints w.r.t a candidate symmetry plane is at least 
                           
                              N
                              −
                              
                                 2
                                 
                                    n
                                    +
                                    2
                                 
                              
                              ,
                           
                         then it is confirmed as a symmetry plane. δ is a threshold which can control the strictness of symmetry definition. For example, using a small threshold we detect more strictly defined symmetries while using a bigger threshold, we allow some minor differences and detect rough symmetry properties. T
                        1 and T
                        2 are the normals of the planes w.r.t two correspondence points (Pu
                         and Pv; Pi
                         and Pj
                        ). The condition ‖CT‖ > ϵ AND |DT| ≠ 0 means that T
                        1 and T
                        2 are neither parallel nor perpendicular to each other. In another word, the line between Pi
                         and Pj
                         is not perpendicular to the candidate symmetry plane since T
                        1 and T
                        2 are not parallel (otherwise, 
                           
                              
                                 ∥
                                 C
                                 T
                                 ∥
                              
                              =
                              0
                           
                        ); and Pi
                         and Pj
                         are also not in the symmetry plane (otherwise, 
                           
                              |
                              D
                              T
                              |
                              =
                              0
                           
                        ). Pm
                         is the midpoint of the line segment connecting points Pi
                         and Pj
                        . It is used to further assert the vertical symmetry property of Pi
                         and Pj
                         about the candidate symmetry plane by finding out whether the midpoint is in the plane, that is 
                           
                              
                                 |
                                 T
                              
                              
                                 
                                 1
                              
                              ·
                              
                                 P
                                 m
                              
                              
                                 |
                                 =
                                 0
                              
                           
                        . The computational complexity of the algorithm is 
                           O
                        (N
                        4), which is much faster than the combinatorial matching approach: e.g. there are only N
                        2 · 
                           
                              
                                 
                                    (
                                    N
                                    −
                                    1
                                    )
                                 
                                 2
                              
                              /
                              4
                              =
                              741
                              ,
                              321
                           
                         combinations based on L
                        1 (
                           
                              N
                              =
                              42
                           
                        ), which is 3.71 × 1025 faster than the naive method. In experiments, we select n to be 1.

We have tested our algorithm on the NIST benchmark [42] and selected models from the AIM@SHAPE Shape Repository [43] to compare with state-of-the-art approaches like the Mean shift [12] and 3D Hough transform [13] based methods, which are among the few papers that deal with global symmetry detection and at the same time provide a quantitative evaluation based on a common set of 3D models. 3D Hough transform [13] can only deal with global symmetry, while Mean shift [12] can deal with partial and approximate symmetry as well. Experiments show that our approach can stably detect the symmetry planes of diverse symmetric models and it also can detect a symmetry plane for a rough symmetric model with a bigger threshold δ.


                        Fig. 4 demonstrates several examples while Table 1
                         compares their timing information. We need to mention that due to the difference in the specifications of the CPUs used in the experiments, we do not directly compare the absolute running time, but rather we focus on the change of the running time with respect to the increase in the number of vertices of the 3D models. As can be seen, our method shows better computational efficiency property in terms of scalability to the number of vertices. This is mainly because the computational time does not increase linearly with the increase in the number of vertices of a 3D model since we just render the 3D model first and detect its symmetry only based on the rendered views. However, for the other two geometry-based approaches Mean shift and 3D Hough, their computational time is highly affected by the number of vertices of the model. This is because the computational complexity of Mean shift (in the best case) and 3D Hough is 
                           O
                        (NlogN), where N is the number of pairs when only one iteration is needed [13]. Since both of them are geometry-based approach, the value of N as well as their complexity are highly dependent on the number of vertices that a 3D model has. For our case, though the computational complexity of the viewpoint matching step (Section 3.3) is 
                           O
                        (N
                        4), the number of viewpoints N (
                           
                              N
                              =
                              42
                           
                         in our experiments) is a constant number. Therefore, this matching step has a constant running cost, that is, it is not dependent on the number of vertices.

To measure the accuracy of the detected symmetry planes, we adopt the mean (normalized by the surface area) and maximum (w.r.t the bounding box diagonal) distance errors developed in Metro [44] which is based on surface sampling and point-to-surface distance computation. Table 2
                         compares the mean and max errors of the four models in Table 1 (see Fig. 4 for the errors of other models) with the Mean shift [12] and 3D Hough transform [13] based methods. The errors are computed based on the original mesh and its reflected 3D model w.r.t the detected symmetry plane. As can be seen, our approach achieves much (4–6 times w.r.t 3D Hough transform and 11–44 times w.r.t Mean shift) better overall accuracy (see the mean errors), in spite that a few points may not be the most accurate but they still maintain a moderate accuracy (indicated by the max errors).

In addition, it is also very convenient to detect different degrees of symmetries via control of the entropy difference threshold δ. As shown in Fig. 4, there is a minor asymmetry on the tail part of the cow, while other parts are symmetric. If we want to obtain strict symmetry, a smaller threshold δ (e.g. by reducing it by half: 0.0075) will give the result that it is asymmetric. We also find that our approach can simultaneously detect multiple symmetry planes for certain types of meshes, such as the Eight, Skyscraper, Bottle, Cup, Desk Lamp, and Sword in [43] and [42], as shown in Fig. 5
                        . But we need to mention due to the limitation of CPCA and the sensitivity property to minor changes of the viewpoint entropy feature, there are a few fail cases or certain cases where the proposed method can only partially determine a set of reflection planes. Examples of such models are non-uniform cubes, butterflies, tori, and pears, as demonstrated in Fig. 6
                        (a) because of non-uniform triangulation, the cube model cannot be perfectly aligned with CPCA, resulting in the unsuccessful symmetry plane detection. However, we have found that for most symmetric models (e.g. Mug, NonWheelChair, and WheelChair classes) that cannot be perfectly aligned with CPCA [8], our approach can still successfully detect their symmetry planes (e.g. the detection rates of Algorithm 1 for those types of models mentioned above are as follows: Mug: 7/8, NonWheelChair: 18/19, and WheelChair: 6/7). Three examples can be found in Fig. 7(b) the symmetry plane of the butterfly cannot be detected if based on the default threshold 
                           
                              δ
                              =
                              0.015
                              ,
                           
                         and only after increasing it till 0.0166 we can detect the plane; (c) only the red symmetry plane of the torus is detected based on the default threshold value, while both the red and green planes will be detected if we increase the threshold δ to 0.02 and all the three symmetry planes can be detected if we further increase it till 0.0215; (d) a false positive (blue) symmetry plane of the pear model will appear under the condition of the default threshold, however the error will be corrected with a little smaller threshold of 0.0133. An adaptive strategy of threshold selection is among our next work plan.
                     

Finally, we evaluate the overall performance of our viewpoint entropy distribution-based symmetry detection algorithm based on the NIST benchmark [42]. In total, we have detected 647 symmetry planes for all the 800 models (some of them are asymmetric). To know the general performance of our algorithm, we manually observe the symmetry property of each of the first 200/300/400 models and label its symmetry plane(s)/degree(s) to form the ground truth. Then, we examine each detected symmetry plane to see whether it is a True Positive (TP) or False Positive (FP). Similarly, we set the True Negative (TN) value of a model to be 1 if it is asymmetric and our algorithm also does not detect any symmetry plane. While, if a symmetry plane of a symmetric model is not detected, we increase its False Negative (FN) by 1. Table 3 gives the evaluation results (177/277/386 detected symmetry planes) on the first 200/300/400 models (having 191/278/388 symmetry planes in total), which are uniformly divided into 10/15/20 classes. Here, for later analysis we successively list the names of the 20 classes: Bird, Fish, NonFlyingInsect, FlyingInsect, Biped, Quadruped, ApartmentHouse, Skyscraper, SingleHouse, Bottle, Cup, Glasses, HandGun, SubmachineGun, MusicalInstrument, Mug, FloorLamp, DeskLamp, Sword, and Cellphone.
                     

Based on the TP, FP, TN and FN values, we compute the following nine detection evaluation metrics [45], as listed in Table 4
                        : Tracker Detection Rate (TRDR, 
                           
                              
                                 T
                                 P
                              
                              
                                 T
                                 G
                              
                           
                        ), False Alarm Rate (FAR, 
                           
                              
                                 F
                                 P
                              
                              
                                 T
                                 P
                                 +
                                 F
                                 P
                              
                           
                        ), Detection Rate (DR, 
                           
                              
                                 T
                                 P
                              
                              
                                 T
                                 P
                                 +
                                 F
                                 N
                              
                           
                        ), Specificity (SP, 
                           
                              
                                 T
                                 N
                              
                              
                                 F
                                 P
                                 +
                                 T
                                 N
                              
                           
                        ), Accuracy (AC, 
                           
                              
                                 T
                                 P
                                 +
                                 T
                                 N
                              
                              
                                 T
                                 F
                              
                           
                        ), Positive Prediction (PP, 
                           
                              
                                 T
                                 P
                              
                              
                                 T
                                 P
                                 +
                                 F
                                 P
                              
                           
                        ), Negative Prediction (NP, 
                           
                              
                                 T
                                 N
                              
                              
                                 F
                                 N
                                 +
                                 T
                                 N
                              
                           
                        ), False Negative Rate (FNR or Miss Rate, 
                           
                              
                                 F
                                 N
                              
                              
                                 F
                                 N
                                 +
                                 T
                                 P
                              
                           
                        ), and False Positive Rate (FPR, 
                           
                              
                                 F
                                 P
                              
                              
                                 F
                                 P
                                 +
                                 T
                                 N
                              
                           
                        ), where the total number of symmetry planes in the 200/300/400 Ground Truth models 
                           
                              TG
                              =
                              19
                              
                                 1
                                 /
                                 278
                                 /
                                 388
                              
                           
                         and the total number of our detections (including both trues and falses) 
                           
                              TF
                              =
                              TP
                              +
                              FP
                              +
                              TN
                              +
                              FN
                              =
                              
                                 246
                                 /
                                 382
                                 /
                                 540
                              
                           
                        . As can be seen, besides the better accuracy in the detected symmetry planes as mentioned before, our detection performance (e.g., for the first 200/300/400 models, Detection Rate 
                           
                              DR
                              =
                              8
                           
                        1.50%/82.76%/79.13%, and Tracker Detection Rate 
                           
                              TRDR
                              =
                              7
                           
                        3.82%/77.70%/75.26%) is also good enough. What’s more, the minor difference among the detection performance of our algorithm on the 200, 300 and 400 models shows that the overall performance of our algorithm is stable and robust in terms of model type diversity and number of models evaluated.

In a word, as demonstrated by all the above evaluation results, better accuracy and efficiency than state-of-the-art approaches have been achieved by our simple but effective symmetry detection method. It also has good stability in dealing with various model types.

First, we also test our algorithm with different levels of subdivided icosahedron for the view sampling, e.g., L
                              2, L
                              3, and L
                              4. Table 5
                               compares the mean/max errors and running time for the four models listed in Table 1. As can be seen, increasing the view sampling often cannot increase the accuracy while the running time will be significantly increasing. Thus, we choose to sample the views based on L
                              1 which gives better overall performance in both the accuracy and efficiency.

We also test the robustness of our algorithm w.r.t the change of the (especially large) number of vertices (resolution) that a 3D model contains. We first subdivide a triangular mesh into its finer version based on several iterations of midpoint subdivision by utilizing the tool of MeshLab [46] and then use the resulting meshes for the test and comparison. We have tested the Elephant, Mannequin and Cube models, and found that our algorithm can stably and accurately detect their symmetry planes, independent of the number of vertices. Table 6
                               compares their mean/max errors and timings. We can see that the increase in computational time is often significantly slower (especially for models with an extremely large number of vertices; e.g. for Mannequin (467,587 vertices) and Cube (196,610 vertices) they are about 8 and 28 times slower, respectively) than the increase in the number of vertices since rendering the sampling views to compute their viewpoint entropy dominates the running time.

Finally, we want to test the versatility as well as sensitivity of our algorithm when processing a modified version of a symmetric model by adding a certain amount of noise. Due to certain factors such as creation, storage, transmission, and modification, 3D models can be noisy. A symmetry detection algorithm should be robust, thus still applicable in the case of small amounts of noise. We test the robustness of our symmetry detection algorithm against noise by randomly adding a small amount of displacement to the vertices of a 3D model.


                              Fig. 8
                               demonstrates the detected symmetry planes of three example models. Table 7
                               shows a comparative evaluation on the detection results w.r.t the mean/max errors and the minimum entropy difference threshold value, denoted by min δ, for a successful detection of the symmetry plane(s) of a model. The results show that our algorithm has a good robustness property against a small amount of noise: by choosing different levels of entropy difference threshold values δ, we will have different tolerant levels of noise to detect symmetry planes. That is, a symmetry detection will be possible if we choose a bigger threshold if there exists a bigger amount of noise. This is contributed to our utilization of the accurate viewpoint entropy feature with a threshold for the feature paring process, since in general viewpoint entropy is stable under small changes in the vertices’ coordinates of a 3D model.

Considering the apparent advantages of the Minimum Projection Area (MPA)-based 3D alignment algorithm in finding the ideal canonical coordinate frame of a model, besides CPCA, we also evaluate the performance of a variation of our algorithm by only replacing the CPCA algorithm module with MPA. However, we found that the results are not as stable as those of the original CPCA-based version in terms of the percentage of either true or false positives based on the same threshold (δ). Choosing the threshold is also more difficult and sensitive when employing MPA since bigger threshold usually results in more false positives.

An initial analysis based on the experimental results is as follows. Due to the viewpoint sampling precision in MPA, especially for the search of the second principle axis of a 3D model which is based on a step of 1 degree, the axes found by MPA is not precise enough for this viewpoint entropy-based symmetry detection purpose, though for the 3D model retrieval application, as mentioned in the paper, the accuracy is enough. However, since our algorithm directly uses the cameras’ locations to compute the symmetry plane(s) by just utilizing their correspondence relationships, it requires that the 3D model is as accurately as possible aligned w.r.t the three standard axes in order to reduce the search space and the number of viewpoints to achieve better efficiency.

What’s more, to align a 3D model, MPA usually takes around 30 s if based on 40 Particle Swarm Optimization (PSO) iterations while CPCA needs less than 1 s, which demonstrates another advantage of CPCA over MPA. In addition, we also have found that if based on CPCA, using bounding sphere for the 3D normalization can achieve more accurate results than the case of using bounding box. This should be due to the fact that we also sample the viewpoints on the same bounding sphere. However, if based on MPA, either using bounding sphere or bounding box has only trivial influence on the symmetry detection performance. The reason is that the accuracy of the found axes has much more direct and decisive influence on the symmetry detection performance. In conclusion, using CPCA is more stable, accurate and efficient than MPA, but we believe an improved MPA algorithm should be more promising in thoroughly solving existing errors in CPCA and achieving even better results, which is among our future work.

@&#LIMITATIONS@&#

Firstly, though in Section 4.1 we have performed an overall symmetry detection evaluation of our algorithm on the first 200/300/400 models of the NIST benchmark, we could not perform a comparative evaluation, similar to the one we did based on the four models in Section 4.1, in terms of the accuracy of the detected symmetry planes. The main difficulty is that: to the best of our knowledge, few prior symmetry detection papers evaluated their symmetry detection performance on a benchmark dataset, which is also not available till now. In addition, their code is not publicly available to facilitate such comparative evaluation.

Secondly, we mainly concentrated on global symmetry detection performance when we compared our algorithm with Mean shift [12] and 3D Hough transform [13], though as mentioned in Section 3.3 our approach can perform approximate symmetry detection as well: “using a bigger threshold, we allow some minor differences and detect rough symmetry properties”.

In fact, global approximate symmetry detection is one of the two research topics (another one is, partial and approximate symmetry detection) in Mean shift [12]. While, global symmetry detection is the only topic for 3D Hough transform [13], which also compares with Mean shift [12] in its experiment section, in terms of the performance of global symmetry detection accuracy and efficiency, based on the same model set as ours. All the available (for us) models selected from the model set have been tested and compared in Fig. 4 and Tables 1 and 2. We also referred to some of the evaluation results of 3D Hough transform [13] as well for a quantitative comparison.

Although we have noticed that there are other related global symmetry detection papers, such as [47] and [48], mainly due to the fact that their code/executable is not available, we have not performed a comparison with them. But, according to the above facts, we believe it is enough and even better to compare with the two more recent works: Mean shift [12] and 3D Hough transform [13].

Finally, we also explore two interesting applications of our symmetry detection algorithm: 3D model alignment and best view selection.

As we know, the main shortcoming of PCA-based approach is that the directions of the largest extent found based on the purely numerical PCA analysis are not necessarily parallel to the axes of the ideal canonical coordinate frame of a 3D model. This is because during the alignment process it lacks semantic analysis in a 3D model’s symmetry [2,15], or its stability [49] after the alignment.

Based on the detected symmetry planes and the basic idea of PCA, it is straightforward to apply our algorithm to 3D alignment: the first principal axis gives the maximum symmetry degree (that is, it has the smallest total matching cost in terms of viewpoint entropy for the symmetric viewpoint pairs w.r.t the axis) and the second principal axis is both perpendicular to the first axis and also has the maximum symmetry degree among all the possible locations within the perpendicular plane. Finally, we assign the orientations of each axis. This alignment algorithm is promising to achieve similar results as those in [15] which is based on a planar-reflective symmetry transform, while outperforms either PCA or CPCA for certain models with symmetry plane(s). However, our algorithm has better efficiency than [15], thus will be more promising for related real-time applications including 3D model retrieval.

Now we present some experimental results of the above alignment algorithm. As mentioned in Section 2, there are four reflection symmetry types: cyclic, dihedral, rotational, and unique. In fact, some of our previous experiments already demonstrate the main alignment results of several models which fall into three of the above four types. For instance, Fig. 5 shows the two/three principal planes (thus axes) of six models that have a cyclic reflection symmetry (see (c) bottle, (d) cup, and (e) desk lamp), or dihedral reflection symmetry (see (a) eight, (b) skyscraper, and (f) sword). Figs. 4 and7 demonstrate the first principle planes/axes of several example models with a unique symmetry based on our idea. It is a trivial task to continue to find other principle axes. For completeness, for example, in Fig. 9
                        , we demonstrate the complete alignment results of three models that have a rotational symmetry, or do not have any reflection symmetry (zero symmetry), or have an approximate symmetry. In a word, the alignment algorithm is promising to be used in dealing with diverse types of models with different degrees of symmetries.
                     

Here, we provide another option to define and search for the best view of a 3D model based on our algorithm. Our definition of symmetry is related to viewpoint entropy which indicates the amount of information that a view contains. In an analogy to 3D model alignment, we use the total viewpoint entropy matching cost, that is an indicator of asymmetry, to indicate the goodness of a candidate best view corresponding to a viewpoint: the bigger the summed matching cost is, the better (more asymmetry) the viewpoint is, since it indicates that there is less redundant information in the view. When we compute the viewpoint matching cost of a candidate view, we only consider visible viewpoints as seen from the candidate view, for instance, within 180°. Algorithm 1 targets finding the minimum viewpoint matching cost in terms of entropy, while we now want to find the viewpoint that gives a maximum viewpoint entropy matching cost. Thus, we develop our algorithm for this application by modifying Algorithm 1, including changing the “ > ”s or “ ≥ ”s to their inverses and setting a bigger threshold δ (e.g., 0.2 in our experiments). The complete best view selection algorithm is given in Algorithm 2. Fig. 10
                         demonstrates several promising informative example results based on the Algorithm 2 (using L
                        1 for view sampling).

@&#CONCLUSIONS AND FUTURE WORK@&#

In this paper, we have proposed an efficient and novel view-based symmetry detection algorithm based on viewpoint entropy distribution. We have compared with the two latest symmetry detection approaches based on a common set of selected models and demonstrated the better performance of our method in terms of accuracy and efficiency. A detailed evaluation of our approach on a dataset of 400 models and the promising results of two related applications also validate its good robustness, detection rate, and flexibility.

To further improve and explore the algorithm, we list several promising directions here as our next work. Firstly, traditional PCA-based approaches cannot guarantee that the directions of the largest extent are parallel to the axes of the ideal canonical coordinate frame of 3D models. One promising approach to achieve further improvement in terms of alignment accuracy is an improved version of the Minimum Projection Area (MPA) [39] alignment method. We can improve its accuracy to meet our precision requirement by applying the PSO-based method used in the first principle axis search in the search for the second principle axis as well. We are also interested in combining it with CPCA for the 3D alignment process: first performing CPCA for an initial alignment and then correcting possible tilt views (poses) by utilizing a similar idea as MPA. It is promising to help to achieve even better symmetry detection performance, especially for decreasing the percentage of False Negative (FN) since more symmetry planes can be successfully detected, thus avoiding the fail case like Fig. 6(a) because of the limitation of CPCA.

Secondly, to further improve the efficiency of our algorithm, we could consider Hough transform for symmetry evidence voting. For example, each pair of matched viewpoints casts a vote for their bisecting plane, while the peaks of the voting distribution correspond to prominent symmetry planes. We need to mention that directly applying Hough voting may not work because rather like geometric values, symmetric viewpoints do not perfectly match each other based on their viewpoint entropy values, which has been explained in Section 3.3.

Finally, an automatic and adaptive strategy to select an appropriate threshold δ for respective models or classes is another interesting research direction and deserves our further exploration.

@&#ACKNOWLEDGMENTS@&#

The work of Bo Li, Yuxiang Ye and Yijuan Lu is supported by the Texas State University Research Enhancement Program (REP), Army Research Office Grant W911NF-12-1-0057, and NSF CNS 1305302 to Dr. Yijuan Lu.

Henry Johan is supported by Fraunhofer IDM@NTU, which is funded by the National Research Foundation (NRF) and managed through the multi-agency Interactive & Digital Media Programme Office (IDMPO) hosted by the Media Development Authority of Singapore (MDA).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An entropy-based query expansion approach for learning researchers’ dynamic information needs

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Proposing an entropy-based query expansion with a reweighting (E_QE) approach.


                        
                        
                           
                           The E_QE used to learn the researchers’ evolving information needs at different levels of topic change.


                        
                        
                           
                           Adopting a simulation pseudo-relevance feedback process to evaluate the proposed approach.


                        
                        
                           
                           The results show that the proposed E_QE approach can achieve better search results than the TFIDF.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Query expansion

Pseudo-relevance feedback

Term weighting

Topic change

Entropy

@&#ABSTRACT@&#


               
               
                  Literature survey is one of the most important steps in the process of academic research, allowing researchers to explore and understand topics. However, novice researchers without sufficient prior knowledge lack the skills to determine proper keywords for searching topics of choice. To tackle this problem, we propose an entropy-based query expansion with a reweighting (E_QE) approach to revise queries during the iterative retrieval process. We designed a series of experiments that consider the researcher’s changing information needs during task execution. Three topic change situations are considered in this work: minor, moderate and dramatic topic changes. The simulation-based pseudo-relevance feedback technique is applied during the search process to evaluate the effectiveness of the proposed approach without the intervention of human effort. We measured the effectiveness of the TFIDF and E_QE approaches for different types of topic change situations. The results show that the proposed E_QE approach achieves better search results than the TFIDF, helping researchers to revise queries. The results also confirm that the E_QE approach is effective when considering the relevant and irrelevant pages during the relevance feedback process at different levels of topic change.
               
            

@&#INTRODUCTION@&#

Information overload is a common problem faced by scholars. Search engine techniques urgently require the means to assist researchers in efficiently exploring and extracting useful information from the massive volumes of scientific data. Hence, search engines such as Google scholar, IEEE explore, and ACM digital library have been launched to support researchers’ information needs. Despite the fact that keywords may not describe researchers’ information needs, such search engines primarily rely on keyword matching techniques to determine which documents to return. However, novice researchers without sufficient prior knowledge often lack the skills to determine the proper keywords for investigating their topics. Therefore, a single search session cannot accurately fulfill the user’s information needs.

The anomalous state of knowledge (ASK) hypothesizes posits that a searcher’s information needs arise from an anomaly in the state of knowledge, a gap between the searcher’s knowledge about a task and the perceived requirements of the task [5,6]. Generally speaking, the process of academic research can be divided into three stages: pre-focus, focus formulation, and post-focus [33]. Wu et al. [44] have conducted a small-scale empirical experimental study to confirm that incorporating the three task-stages into the search process model is a practical and effective means to enhance search results. However, previous studies did not present an automated approach to help researchers revise queries during the search process. In this work, we devise a query expansion technique that addresses researchers’ evolving information needs when retrieving articles at different stages of the research process.

Query expansion (QE) techniques can be exploited to help researchers better formulate their queries. QE supplements the original query with additional keywords. The core of QE comprises two fundamental steps: the selection of keywords to expand and a re-weighting scheme applied to the keywords in the query. QE techniques can compensate for user inability to determine suitable keywords (i.e., short and simple queries) that express their information needs, improving the quality of the search results by overcoming these shortcomings through a query reformulation process [11].

QE can be divided in two approaches: Automatic Query Expansion (AQE) and Interactive Query Expansion (IQE) [10]. AQE technique can achieve better performance when a user’s subject knowledge is high. In addition, it does not require users to evaluate the relevance of documents. In this work, we use the AQE technique to revise the user’s query during the relevance feedback process. For academic research, a proper QE should consider evolving information needs over the course of the process of academic research. For example, in the pre-focus stage, QE may include more synonyms of the query in order to broaden the scope of the survey, while a QE technique should eliminate keywords that deviate from the main direction of the research topic in the post-focus stage. Evolving information needs bring new challenges to QE techniques, including (1) how to automatically detect the evolution of information needs and (2) how to determine the keywords to be added, removed or reweighted. Accordingly, this paper has the following specific objectives:
                        
                           1.
                           To devise a QE scheme that delivers researchers’ queries based on their information-seeking behaviors.

To propose a QE technique with a reweighting approach that learns the evolving information needs of researchers through an entropy-based approach.

To simulate the evolution of information needs by changing from broader research subjects to a focused subject. The proposed framework is evaluated through this simulation.

Consequently, we propose an entropy-based query expansion with a reweighting (E_QE) approach that can consider the level of change in the researchers’ topics and learn their information needs effectively. We will evaluate whether the proposed E_QE approach can be incorporated into the relevance feedback process to design a better search system for academic researchers based on their problem stages.

The word mismatch problem is one of the most important and fundamental issues of information retrieval (IR) research [20]. That is, users and authors may use different words to describe the same concepts. Thus, it is hard to match queries with documents to retrieve the relevant documents. Global and local document analysis methods have been proposed to tackle this problem [47]. Query expansion (QE) is a global analysis method that can build a new query from the original one by adding synonyms, conceptually related terms, or semantically related terms, [9,20]. Relevance feedback technique (RF) is a local analysis method that adjusts a query relative to the documents that are retrieved in the initial query. The concept of the RF is that once the users have made their initial queries, the system will examine relevant and irrelevant documents guided by the RF technique to modify the original query to be the next query [22,41]. Both QE and RF techniques can compensate for users’ inability to input suitable keywords (i.e., short and simple queries) that express their information needs, improving the quality of the search results by overcoming these shortcomings through a query reformulation process [10,34].

Query expansion can be divided in two methods: Automatic Query Expansion (AQE) and Interactive Query Expansion (IQE) [1,11,34]. We can understand IQE as a half-automatic query expansion that requires users to manually evaluate the relevance of document sets and return feedback to the system before the system will modify the initial query according to the feedback. Users can keep interacting with the system until they are satisfied with the retrieval results or their information needs are met. The advantage of IQE is that users can give feedback directly to the system [3]. Since it requires time and effort for users to evaluate the relevance of the returned document sets. IQE will be most effective if a user’s subject knowledge is low and the search topic is complex [34]. However, with increasing subject knowledge, more specific query terms can be used and users will be more able to differentiate between relevant and irrelevant information. When a user’s subject knowledge is high, AQE technique is more effective. In addition, it does not require users to evaluate the relevance of documents. Therefore, QE techniques can be categorized into four types [21]: (1) use of co-occurrence data, (2) use of document classification, (3) use of syntactic context and (4) use of relevance feedback technique.

Relevance feedback (RF) improves the search effectiveness of the automatic query reformulation process [25,26]. The literature on information retrieval shows that relevance feedback applied in a vector model is an effective technique in a retrieval environment [25,27]. Compare to the traditional approach in which users need to determine the query for their own for information retrieval, there are three major advantages of RF:
                           
                              •
                              Users do not need to reformulate the query on their own. They only need to evaluate the documents that can modify and reformulate users’ query.

RF takes every search as a process of the whole search task, not a single search result. Thus, the search results are more precise after one or more iterations.

RF treats search as a controlled process, allowing users to evaluate the relevant and irrelevant documents.

The classic relevance feedback method proposed by Rocchio [26] and theIde_Dec_Hi (1971) method, which use a vector space model to derive the modified query 
                           
                              
                                 
                                    
                                       
                                          q
                                       
                                       
                                          →
                                       
                                    
                                 
                                 
                                    m
                                 
                              
                           
                        , are formulated in Eqs. (1) and (2) respectively [4].
                           
                              (1)
                              
                                 
                                    
                                       Standard
                                    
                                    
                                       -
                                    
                                 
                                 Rocchio
                                 :
                                 
                                    
                                       
                                          
                                             q
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       m
                                    
                                 
                                 =
                                 α
                                 
                                    
                                       q
                                    
                                    
                                       →
                                    
                                 
                                 +
                                 β
                                 
                                    
                                       1
                                    
                                    
                                       |
                                       
                                          
                                             D
                                          
                                          
                                             r
                                          
                                       
                                       |
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          ∀
                                          
                                             
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      →
                                                   
                                                
                                             
                                             
                                                j
                                             
                                          
                                          ∈
                                          
                                             
                                                D
                                             
                                             
                                                r
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             d
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                                 -
                                 γ
                                 
                                    
                                       1
                                    
                                    
                                       |
                                       
                                          
                                             D
                                          
                                          
                                             n
                                          
                                       
                                       |
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          ∀
                                          
                                             
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      →
                                                   
                                                
                                             
                                             
                                                j
                                             
                                          
                                          ∈
                                          
                                             
                                                D
                                             
                                             
                                                n
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             d
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       Ide
                                    
                                    
                                       -
                                    
                                 
                                 
                                    
                                       Dec
                                    
                                    
                                       -
                                    
                                 
                                 Hi
                                 :
                                 
                                    
                                       
                                          
                                             q
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       m
                                    
                                 
                                 =
                                 α
                                 
                                    
                                       q
                                    
                                    
                                       →
                                    
                                 
                                 +
                                 β
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          ∀
                                          
                                             
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      →
                                                   
                                                
                                             
                                             
                                                j
                                             
                                          
                                          ∈
                                          
                                             
                                                D
                                             
                                             
                                                r
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             d
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                                 -
                                 γ
                                 
                                    
                                       
                                          max
                                       
                                       
                                          non
                                          -
                                          relevant
                                       
                                    
                                 
                                 (
                                 
                                    
                                       
                                          
                                             d
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        where Dr
                         is the set of relevant documents and Dn
                         is the set of not relevant documents, both of which are determined by the user; |Dr
                        | and |Dn
                        | denote the number of documents in the sets Dr
                         and D, respectively; and α,
                        β,
                        γ are tuning constants. In Eq. (2), 
                           
                              
                                 
                                    max
                                 
                                 
                                    non
                                    -
                                    relevant
                                 
                              
                              (
                              
                                 
                                    
                                       
                                          d
                                       
                                       
                                          →
                                       
                                    
                                 
                                 
                                    j
                                 
                              
                              )
                           
                         denotes the highest non-relevant document. The two methods yield similar results [4]. The Rocchio method sets α
                        =1, Ide sets α
                        =
                        β
                        =
                        γ
                        =1, and Harman (1992) sets β
                        =0.75,
                        γ
                        =0.25. Salton and Buckley (1990) showed that the Ide_Dec_Hi algorithm performs slightly better than the Rocchio algorithm.

Generally, there are two approaches to the RF process. The first reweights terms based on the distribution of the terms in the relevant and irrelevant documents. The second involves adding or removing terms in the course of the query expansion process. The latter approach can more efficiently improve retrieval performance because the adjustment of terms can change the search results more significantly than by adjusting the weights of the original terms. These two approaches suggest three different kinds of RF techniques: (1) query expansion without term reweighting; (2) term reweighting without query expansion; and (3) query expansion with term reweighting. Each can be applied in different systems for different needs. In this work, we will adopt the third approach to RF processing in support of final QE.

To date, researchers in the field of Information Retrieval (IR) have focused on representations of documents for the retrieval of project-relevant information, search strategies, and assessing the relevance of retrieved documents. Comparatively little attention has been paid to users’ information needs and how to support their search activities. Information Seeking (IS) involves searching for and using information for a task when the user does not have sufficient prior knowledge. Several empirical studies have observed and analyzed users’ successive searches and connected them to the task complexities, relevance judgments, and situations of the subjects during the IS process [5–7,18,30,35,38,39]. Saracevic [28] proposes the broadest sense of IR, under which it is important to simultaneously consider messages for decisions, cognitive processing, and the context of search. Accordingly, the concept of the integration of user-oriented and system-oriented IR research is considered in IR. Recently, however, user-oriented Information Seeking (IS) research methods rooted in the social sciences have been integrated with computer science-based Information Retrieval (IR) approaches to capitalize on the strengths of both fields. This concept is called the Information Seeking and Retrieval (IS&R) framework. The IS&R framework provides a useful background for understanding the evolution of the IIR system and its evaluation approaches [13,17].

Kuhlthau’s search process model (1993) divides a task into six stages with their associated characteristics. It describes the information search process from the three perspectives which are thoughts, feelings, and actions as being experienced in six stages. The objective is to observe how users locate and interpret information to form a perspective on a topic. During the search process, thoughts evolve from unclear and vague to clear, more focused understanding. The actions taken in the search process also change with the formulation of the focus.

Vakkari [32] analyzed the evolution of theories of the information seeking process and task complexity. Vakkari et al. [35] concentrated on a user’s information seeking activities during the execution of a task (such as writing a proposal or completing a project). Vakkari et al., following Kuhlthau’s search process model (1993), divided information seeking activities into three stages: the pre-focus, focus-forming and post-focus stages [35]. Vakkari’s task-oriented IS study is also based on studies of search strategies and tactics [46] and the study of term choices [37]. These empirical studies reveal that users’ information needs vary across different task stages. For example, the types of information needs may vary from general to specific information, and the choice of search terms may vary from broader terms to related or specific terms. That is, a worker’s information needs and information-seeking process depends on their progress in the task performance, or task stages.

Byström and Järvelin’s information seeking surface model (1995) explicates the dependencies between task complexity, information needs and information sources via a qualitative empirical study. The authors model information seeking as a process that involves needs analysis, choices of actions, implementation of actions, and evaluations. The model is based on the assumption that personal factors (e.g., attitude, mood, motivation), situational factors (e.g., available time) and the perceived category of the task (e.g., genuine task, normal decision task, normal information processing task) influence the information seeking process. Note that Byström–Järvelin’s model is a static model that relates abstract concepts, i.e., the task’s complexity and the types of information needed. It does not model the search process explicitly [13].

Wang and Soergel [38] and Wang and White [39] proposed cognitive models of document usage during research projects conducted in 1992 and 1995, respectively. The results show that, during a research project, document usage is a decision-making process in which decisions are made at three points or stages: selecting, reading, and citing. The above studies contribute to research on the applications of intelligent information retrieval systems, and enhance the use of knowledge retrieval functions to support task execution by professionals. They also offer a comprehensive understanding of human judgment and decision-making during the search process.

The above studies also focus on observing users’ search behavior and provide useful suggestions for the design of effective search systems based on the IS&R models. Our objective is to provide an effective means of information search in professional task contexts.

The information retrieval (IR) field has evolved rapidly over the past decade, and the Internet is one of the biggest forces driving the development of search engine tools for helping people retrieve information [8]. In many cases, users may only have a general idea about a topic and convert their thoughts into a very short query. After analyzing logs of queries on the Web, Jansen et al. [16] found that the average query length is 2.21 keywords and that less than 4 percent of the queries exceed six terms. Users without sufficient prior knowledge lack the skills to determine proper keywords for their topics. Therefore, a single search session cannot accurately reflect the user’s information needs. To tackle the problem we propose an entropy-based query expansion with a reweighting approach to revise the queries during the iterative retrieval process.

Kuhlthau [18], Vakkari [32], and Wu et al. [44] showed that users’ information needs and search behavior patterns vary across different stages of the search process. Researchers believe that making a system aware of a searcher’s information seeking stage and tailoring the results to each stage has the potential to improve the search experiences [2]. Thus, we designed a series of experiments that considers the users’ changing degree of information needs by controlling the changes of topics in the proposed topic ontology. The pseudo-relevance feedback technique is adopted during the search process to evaluate the effectiveness of the proposed approach without the intervention of human efforts. The research problems are summarized below.
                           
                              •
                              Comparing the relative performance of the proposed entropy-based query expansion and reweighting approach with the basic TF-IDF term weighting approach.

Adopting a simulation-based pseudo-relevance feedback process to investigate the effectiveness of the proposed approach under different levels of change in the research topic.

Investigating the influence of proportions of relevant and irrelevant pages for query expansion under the level of change in the research topic.


                        Fig. 1
                         shows the research framework. There are three main modules: a search module, a relevance feedback module, and a query expansion module.

First, we simulate a researcher’s information needs for the assigned task. We test dramatic, moderate, and minor changes in the subject to investigate the effectiveness of the proposed approach. To search web pages, the search function of the system developed connections to Google’s AJAX search API, a JavaScript library that allows users to embed Google Search in applications or web pages. For academic searches, the system retrieves relevant academic articles from journals and conference proceedings from the Citeseer web site.

As motioned earlier, a simulation-based pseudo-relevance feedback process was designed as a component of this work. The pseudo-relevance feedback process relies on a topic ontology to determine the relevancy of the returned pages. Notably, our research topic ontology (Fig. 2
                           ) is constructed based on our previous work [45]. Generally, users will not read all of the pages retrieved and thus we only consider three pages, or 30 search results, in evaluating a given document as relevant or irrelevant [16]. To determine the degree of relevance between the retrieved pages and the researcher’s information needs (topic), the module will calculate the similarity between the pages and the topics, categorizing the retrieved pages into different levels of relevance based on their similarity values. We will detail this process in Section 5.1. A researcher simulator within the RF module is designed to simulate researchers’ behavior during the search process. Basically, the researcher simulator randomly picks a topic from the topic ontology as the initial concept.

The aim of this module is to revise the original query set based on the results of the simulation-based pseudo-relevance feedback process each time it is run. We adopt Discounted Cumulated Gain (DCG) measures [15]. The DCG measure evaluates an IR method’s ability to retrieve highly relevant documents as a ranked list.

The overall framework of the associated search process is illustrated in Fig. 1. There are three main modules: a web search module, a relevance feedback module, and a query expansion module, as introduced earlier. First, we simulate a researcher’s information needs for the assigned task. To search web pages, the search function of the system developed connections to Google’s AJAX search API. Furthermore, a simulation-based pseudo-relevance feedback process was designed as a component of this work. The pseudo-relevance feedback process relies on a topic ontology to determine the relevancy of the returned pages. A researcher simulator (RS) within the RF module is designed to simulate researchers’ behavior during the search process. Basically, the RS randomly picks a topic from the topic ontology as the initial concept. Finally, the aim of automatic QE module is to revise the original query set based on the results of the simulation process each time it is run.

We generated a domain topic ontology, which is adopted to evaluate the degree of relevance relating retrieved articles to topics. The proposed topic ontology is a simple hierarchical taxonomy that is structured into three levels: fields (broader topics), tasks (specific topics), and documents. A specific topic is also referred to as a task topic. Each topic has an associated corpus that is extracted from a set of task-related documents [44,45]. The topic ontology is used to organize documents around specific research domains ([31,36,45]). As mentioned earlier, an RS in the pseudo-relevance feedback module is designed to simulate the behavior of researchers during the search process. The simulator carried out two tasks: automatically determining whether a document is relevant or irrelevant, and simulating topic change behavior during the search process. The domain topic ontology is used to determine whether a document is relevant. To determine the degree of relevance between the retrieved pages and the researcher’s information needs (topic), the RS will calculate the similarity between the retrieved documents and the corpus of the topic, categorizing the retrieved pages into different relevance degree levels based on their similarity values. We calculated the similarity between the page and the topic by measuring the cosine. The similarity measure is shown in Eq. (3). Furthermore, the system can activate the following pseudo-relevance feedback process.
                           
                              (3)
                              
                                 sim
                                 (
                                 
                                    
                                       page
                                    
                                    
                                       →
                                    
                                 
                                 ,
                                 
                                    
                                       topic
                                    
                                    
                                       →
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             page
                                          
                                          
                                             →
                                          
                                       
                                       •
                                       
                                          
                                             topic
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       |
                                       
                                          
                                             page
                                          
                                          
                                             →
                                          
                                       
                                       |
                                       ×
                                       |
                                       
                                          
                                             topic
                                          
                                          
                                             →
                                          
                                       
                                       |
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              →
                              page
                           
                         is the content of the retrieved article (feature vector of weighted terms), and 
                           
                              →
                              topic
                           
                         is the corpus of the topic. We calculated the similarity between the article and the topic by measuring the cosine. We will determine the degree of relevance based on the similarity value which will be introduced in Section 5.4.

The well-known TFIDF approach often used for term (keyword) weighting assumes that terms with a higher frequency in one document and a lower frequency in another document are better discriminators for representing the first document [27]. In this work, we present an entropy-based query expansion with a reweighting (E_QE) approach according to the basic concept of the TFIDF approach. Basically, entropy can be used as a feature selection measure for selecting the best feature to discriminate or split data. The main purpose of entropy is to count the average amount of information needed to identify the class label of a training example in the data set. This is mainly based on Claude Shannon’s information theory [29]. The basic equation is listed below.
                        
                           (4)
                           
                              E
                              (
                              Ex
                              ,
                              
                                 
                                    attr
                                 
                                 
                                    j
                                 
                              
                              )
                              =
                              -
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                    
                                 
                              
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                              
                                 
                                    log
                                 
                                 
                                    2
                                 
                              
                              (
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                              )
                              ,
                           
                        
                     where pi
                      is the probability that an attribute, attrj
                     , is used to classify EX
                     , a set of training examples belonging to classci and is estimated by |Ci
                     
                     ,
                     
                        EX
                     |/|EX|. E(Ex, attrj
                     ) is also the entropy of Ex. Following this idea, the E_QE approach considers the distribution of a term as it appears in relevant and irrelevant documents to arrive at the discrimination value of the term. In addition, term frequency is also considered, as explained in the entropy-based term weighting approach. Specifically, during the relevance feedback (RF) iteration, if the term always appears in the set of relevant documents, it will have higher discrimination value. Here we consider the proportion of the term’s appearance in relevant and irrelevant documents and calculate the entropy values as shown respectively in (5) and (6). GR
                      indicates the amount of information in the relevant documents, whereasGRN
                      indicates the amount of information in irrelevant ones.
                        
                           (5)
                           
                              
                                 
                                    G
                                 
                                 
                                    R
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                -
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            O
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                
                                                   
                                                      log
                                                   
                                                   
                                                      2
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            O
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                -
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            q
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                
                                                   
                                                      log
                                                   
                                                   
                                                      2
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            q
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                ,
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            O
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                >
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                          
                                             
                                                1
                                                ,
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            O
                                                         
                                                      
                                                   
                                                   
                                                      R
                                                   
                                                
                                                ⩽
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (6)
                           
                              
                                 
                                    G
                                 
                                 
                                    RN
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                -
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            NO
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                   
                                                   
                                                      2
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            NO
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                -
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            Nq
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                   
                                                   
                                                      2
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            Nq
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                ,
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            NO
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                <
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                          
                                             
                                                1
                                                ,
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            NO
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                
                                                ⩾
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

In Eq. (5), R is the number of relevant documents, and RN
                      is the number of irrelevant documents. Ro denotes the number of relevant documents that include a specific term, and Rq denotes the number of irrelevant documents that do not include a specific term. Similarly, RNo
                      denotes the number of irrelevant documents that include a specific term, and RNq
                      denotes the number irrelevant documents that do not include a specific term. A key characteristic of entropy is that it can estimate the distribution of the examples. Thus, if a term appears in the relevant document 25 times, the entropy value will be the same as if the term appears in the relevant document 75 times. To resolve this problem, we set restrictions in Eqs. (5) and (6). That is, we set 
                        
                           
                              
                                 
                                    
                                       R
                                    
                                    
                                       o
                                    
                                 
                              
                              
                                 R
                              
                           
                           >
                           
                              
                                 1
                              
                              
                                 2
                              
                           
                        
                      in (5) to ensure the selection of the term that appears in most of the documents of the relevant document set. In addition, we set 
                        
                           
                              
                                 
                                    
                                       R
                                    
                                    
                                       No
                                    
                                 
                              
                              
                                 
                                    
                                       R
                                    
                                    
                                       N
                                    
                                 
                              
                           
                           <
                           
                              
                                 1
                              
                              
                                 2
                              
                           
                        
                      in (6) to ensure that the term does not appear in most of the documents of the irrelevant document set. The discrimination of a term is formulated in the following equation:
                        
                           (7)
                           
                              
                                 
                                    TG
                                 
                                 
                                    i
                                 
                              
                              =
                              1
                              -
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   G
                                                
                                                
                                                   R
                                                
                                             
                                             +
                                             
                                                
                                                   G
                                                
                                                
                                                   RN
                                                
                                             
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                              ,
                           
                        
                     
                  


                     TGi
                      means the discrimination value for the term i, and the value is between zero and one. Eq. (7) is a normalization process for Eqs. (5) and (6). For example, if a relevant term, i, appears fewer than or equal to half of relevant documents, the value ofGR
                      will be one. Similarly, if the relevant term, i, also appears in more than or equal to half of irrelevant documents, the value of GRN
                      will also be one. Based on the Eq. (7), the TGi
                      value will be zero, which means the term, i, will not be selected due to that fact that it may either belong to the term set of irreverent documents or has a low discrimination value. In addition to considering the discrimination value of each term, we also integrate the frequency of each term in a relevant document. Consequently, the entropy-based term weighting approach is shown in (8). Note thatfi
                      is the term frequency component.
                        
                           (8)
                           
                              TF
                              _
                              
                                 
                                    TG
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    f
                                 
                                 
                                    i
                                 
                              
                              ×
                              
                                 
                                    
                                       1
                                       -
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            G
                                                         
                                                         
                                                            R
                                                         
                                                      
                                                      +
                                                      
                                                         
                                                            G
                                                         
                                                         
                                                            RN
                                                         
                                                      
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

For Eq. (8), the idea is similar to a classic TFIDF term weighting approach [27]. The two factors, the discrimination value and the term frequency, are considered important in most of the term weighting approaches in information retrieval models, e.g., vector space and probabilities models [20].

@&#EXPERIMENTAL DESIGN@&#

The simulation-based pseudo-relevance feedback technique is adopted during the search process to evaluate the effectiveness of the proposed approach without the intervention of human effort. The simulator is divided into two main parts: the query engine and researcher simulator (RS). While the query engine retrieves the pages that match the user’s keywords and expand the queries with more keywords based on the relevance of the returned pages, the RS simulates the keywords that the researcher will key in, the changes in the researcher’s information needs, and the researcher’s decisions about the researcher on the relevance of the pages returned by the query engine. The simulation-based pseudo-relevance feedback and the search process are illustrated in Fig. 3
                        . The simulator process is divided into the following five steps:
                           
                              
                                 Step 1. Initially, the RS randomly selects a concept node from the topic ontology as the initial concept.


                                 Step 2. The RS then passes along the keywords presenting the most general concept from the subject of the selected concept nodes to indicate the researcher’s initial information needs. For example, if the initial information needs appears in the concept node whose subject is Towards a Framework for Discovering Project-Based Knowledge Maps, the keywords indicating the information needed will be “Knowledge Maps”.


                                 Step 3. The query engine retrieves the top 30 pages returned from the search engine.


                                 Step 4. The researcher simulator evaluates the relevance of the retrieved pages to the corpus of the current concept node, and categorizes the retrieved pages into a relevant set and an irrelevant set.


                                 Step 5. From the relevant and irrelevant sets of pages, the query engine will select six keywords from the keywords of the corpus of the current concept nodes. This selection will be made based on the proposed query expansion with reweighting method, i.e., E_QE or TFIDF methods. If the research simulator changes the current concept node because of a new information need, the simulation process will move to STEP 2 with the newly generated keyword set; if the researcher simulator maintains the same information needs, the simulation process will move to STEP 3 with the newly generated keyword set.

In real-world search behaviors, users may adjust their keywords in order to represent their information needs more precisely during the search process. In the experiment, a simulation-based pseudo-relevance feedback process will be executed in eleven rounds. In the first round, steps 1 to step 5 are executed in order to represent the initial stage of information seeking behaviors. In the second round to eleventh round, steps 3 to step 5 are executed with a change in search interest, which will specifically happen in step 5. In this work, we focus on the effectiveness of the proposed approach during the relevance feedback process. Thus, we simulated the search process such that users are assumed not to spontaneously adjust their query, using the keywords expanded by the query engine in the next round. Fig. 4
                         shows the changes of keywords when the simulated topic change conditions.

In this section, we detail how the researcher simulator simulates the degree of change in its information needs. The information needs of a researcher are subject to a concept node of the constructed topic ontology, in which the concepts are organized as a hierarchical structure. Given the information needs about a current concept, the degree of change in information needs is then categorized into three types as illustrated in Fig. 5
                        . Note the set of topics and the two degree of change listed in Table 1
                        .
                           
                              
                                 TYPE 1: Minor change (Change to the child concept): the researcher starts to seek information on a more specific concept.


                                 TYPE 2: Moderate change (Change to a broader concept in a different sub-tree): the researcher starts to seek information on a concept related to the original one.


                                 TYPE 3: Dramatic change (Change to a specific concept in a different sub-tree): the researcher starts to seek information from different concepts.

The researcher simulator determines the relevance of the pages returned by the query engine. The researcher simulator will inspect the top 30 pages returned by the query system and will compute the similarity between each page and the corpus of the subject that represents the current information need. Finally, the researcher simulator sorts these 30 pages by their similarity to the corpus and selects the first 10 pages as the relevant pages. For the run time for the pseudo-relevance feedback, we need to calculate the degree of relevance between the retrieved pages and the corpus of the subject, i.e. topics. Deriving the relevance degree will add additional time. The computation complexity of measuring similarity is O(nm), where n is the number of topics and m is the number of retrieved documents. Because we focused on the top 30 pages for interactive information retrieval environment, it will not take much time to compute the similarity values. In addition, when the entropy-based measurement (E_QE) requires the irrelevant page as well, the researcher simulator selects the last 20, 10, and 5 pages as the irrelevant pages in configuration A, B, and C respectively, as shown in Table 2
                        . The purpose of using three types of configuration is to investigate the influence of irrelevant pages for query expansion. Thus, we compare three different configurations for the information entropy-based query expansion with a term reweighting approach with different proportions of relevant and irrelevant pages, defined as E_QE(10-20), E_QE(10-10), and E_QE(10-5). In addition, the traditional term weighting approach is also evaluated to make comparisons between the proposed methods. We give explanations of each method below.
                           
                              •
                              
                                 TFIDF: In the relevance feedback, the query system weights the keywords using a TFIDF term weighting scheme.


                                 E_QE(10-20): In the relevance feedback, the query system weights the keywords using the entropy based model. The researcher simulator follows configuration A in Table 2 to select 10 relevant pages and 20 irrelevant pages.


                                 E_QE(10-10): The researcher simulator follows configuration B in Table 2 to select 10 relevant pages and 10 irrelevant pages.


                                 E_QE(10-5): The researcher simulator follows configuration C in Table 2 to select 10 relevant pages and 5 irrelevant pages.

We evaluate the effectiveness of the search results using discounted cumulated gain (DCG) measures. Unlike the precision and recall based evaluation, DCG additionally considers how well the system generates rankings for each page [14,15]. The evaluation metric is defined below.


                        Discounted Cumulated Gain: The DCG measure evaluates an IR method’s ability to retrieve highly relevant documents as a ranked list. If we sort the relevance scores (similarity values) of documents in decreasing order, then, the lower the ranked score of a relevant document, the more important it is for the user. The CG function, shown in Eq. (9), progressively sums the relevance scores of the documents from rank 1 to n meaning that each document has an associated accumulated gain value. Furthermore, the DCG function reduces a document’s score as its rank increases, but not as steeply as the CG function, by dividing the log of its rank, as shown in Eq. (10). In this work, we set b
                        =2.
                           
                              (9)
                              
                                 CG
                                 [
                                 i
                                 ]
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   G
                                                   [
                                                   1
                                                   ]
                                                
                                                
                                                   if
                                                   
                                                   i
                                                   =
                                                   1
                                                
                                             
                                             
                                                
                                                   CG
                                                   [
                                                   i
                                                   -
                                                   1
                                                   ]
                                                   +
                                                   G
                                                   [
                                                   i
                                                   ]
                                                   ,
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (10)
                              
                                 DCG
                                 [
                                 i
                                 ]
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   CG
                                                   [
                                                   i
                                                   ]
                                                
                                                
                                                   if
                                                   
                                                   i
                                                   <
                                                   b
                                                   ,
                                                
                                             
                                             
                                                
                                                   CG
                                                   [
                                                   i
                                                   -
                                                   1
                                                   ]
                                                   +
                                                   
                                                      
                                                         G
                                                         [
                                                         i
                                                         ]
                                                      
                                                      
                                                         
                                                            
                                                               log
                                                            
                                                            
                                                               b
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                   ,
                                                
                                                
                                                   i
                                                   ⩾
                                                   b
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

We determine the degree of relevance based on the similarity value and then quantize the similarities into 10 relevant levels (RLs) as shown in Table 3
                        . We adopt P@N (precision at N) which denotes that the DCG is calculated from the N first evaluated articles [19,40]. In this work, we evaluate P@10, P@20, and P@30.

During the simulation process, the researcher simulator will generate keywords using an initial information need (IN) in the 0th round, and then change the INs in the first round. Herein, we analyze whether the proposed methods can learn the user’s IN quickly, within a few iterations. That is, we analyze the learning trend (LT) of each method after changing the IN in the first round. The learning trend may be increasing, decreasing, or remaining the same. Furthermore, we also analyze whether the proposed methods can learn the user’s IN in the long run. Both results have implications for the design of an effective search system for academic researches.

We list observations from the experimental results below.


                        Observation 1: 
                        Table 4
                         shows that E_QE(10,20) has an increased learning trend (LT) for the two topic sets. However, it cannot achieve as high a quality of DCG as E_QE(10,5) after three rounds. It also shows that the learning trend (LT) of the TFIDF method decreases (shown by ↓) every round.


                        Observation 2: We summarize the performance of the four methods in the three rounds for two sets of topics, i.e. s1 and s2, with a minor degree of change. Apparently, E_QE(10,5) has the best learning ability and outperforms the other three methods for these two topic sets (DCG values of 89.34 and 85.59, respectively).


                        Observation 3: 
                        Fig. 6a
                         shows that the E_QE(10, 5) achieves better results than the other keyword weighting methods at each round for the topics of set one. For topics of the second set, the results are unstable for each method except E_QE(10, 5), which offers stable results at each round and achieves the best performance in the final round, as shown in Fig. 6b
                        . Figs. 6a and 6b both show that the TFIDF method has the poorest performance in nearly every round.

We list observations from the experimental results below.


                        Observation 1: We also analyze whether the proposed methods can learn the user’s information needs (IN) quickly, within a few iterations. Table 5
                         shows that the E_QE(10,10) can achieve good performance, learning the user’s IN within a few rounds for different topic sets. Moreover, the learning trend (LT) of the method increases (shown by ↑). Conversely, the TFIDF method displays the poorest performance and does not learn the user’s IN well.


                        Observation 2: We summarize the performance of the four methods in the three rounds for two sets of topics, i.e. s1 and s2, with a moderate degree of change. For the first three rounds, E_QE(10,10) achieved the best performance for the two sets of topics, with DCG values of 84.88 and 51.36, respectively. Moreover, TFIDF, E_QE(10,5), E_QE(10, 20) did not perform well for a moderate degree of change for the two sets of topics.


                        Observation 3: 
                        Figs. 7a and 7b
                        
                         show that no single method performed best in each round of the evaluation. However, it is apparent that E_QE(10, 10) can learn the topic change within a few runs. In addition, the performance of E_QE(10, 10) is stable from third to the final rounds for the first topic set. However, E_QE(10, 20) exhibits better performance after the third round for the second topic set. TFIDF method exhibits the poorest performance on both topic sets.


                        Observation 4: Examining the data more closely, Table 6
                         shows that the second set of data has lower similarity values on average than that of the first set of data. This may indicate that it is much better to use E_QE(10,10) when the dataset has a high similarity to the queries whereas it is much better to use E_QE(10,20) when the dataset has a low similarity to the queries for learning the information needs in the long-run.

We list observations from the experimental results below.


                        Observation 1: We also analyze whether the proposed methods can learn the user’s IN quickly, within a few iterations, for dramatic changes of topics. Table 7
                         shows that the learning trend (LT) of the proposed E_QE methods, the changes of new INs increases (shown by ↑) each round after the first round. By contrast, the TFIDF method does not learn the user’s IN well.


                        Observation 2: We summarize the performance of the four methods in the three rounds for two sets of topics, i.e. s1 and s2, with a dramatic degree of change. For the first three rounds, E_QE(10,10) achieved the best performance for the two sets of topics, with DCG values of 65.01 and 65.48, respectively. Moreover, E_QE(10,5) does not achieve as stable of a performance for a dramatic degree of change for the two sets of topics.


                        Observation 3: 
                        Figs. 8a and 8b
                        
                         show that no single method performed best in each round of the evaluation. However, it is apparently that E_QE(10, 10) can learn the topic change within a few rounds. For set one, the three entropy-based methods have better DCG values than those of the initial round. Specifically, E_QE(10, 10) can learn information needs quickly, within three rounds. However, it cannot maintain this performance through the end of the simulation, several iterations of RF. The E_QE(10, 20) can learn information needs after several iterations.

We make an overall comparisons and discussions for three different levels of topic changes under various P@N for the two topic sets.


                        Figs. 9a and 9b
                        
                         show the DCG values for the four query expansions with term reweighting methods under various P@N for the two topic sets. For both topic set one and topic set two, E_QE(10, 5) has the best DCG values for P@10, P@20 and P@30 on average. For both topic sets, the TFIDF has the lowest DCG values on average. The results indicate that we may consider fewer irrelevant documents when the degree of change between topics is minor.


                        Figs. 10a and 10b
                        
                         show the DCG values for the four query expansion with term reweighting methods under various P@N for the two topic sets. For topic set one, theE_QE(10, 10) has the best DCG values for P@10, P@20 and P@30 on average. For topic set two, the E_QE(10, 20) has the best DCG values for P@10, P@20 and P@30 on average. If we check the similarity value in Section 6.2 of Table 6, topic set one has a higher similarity value than topic set two. This indicates that we should consider a larger number of irrelevant documents when the queries (topic) have a low similarity to the search results. For both topic sets, the TFIDF has the lowest DCG values on average.


                        Figs. 11a and 11b
                        
                         show the DCG values for the four query expansion with term reweighting methods under various P@N for the two topic sets. For both topic set one and topic set two, the E_QE(10, 20) has the best DCG values for P@10, P@20 and P@30 on average. For both topic sets, the TFIDF has the lowest DCG values, on average. This indicates that we should consider a larger number of irrelevant documents when the degree of change between topics is major.

@&#CONCLUSIONS AND FUTURE WORK@&#

Classical RF techniques are designed to revise queries based on the user’s feedback on items without considering the degree of change in information needs. Accordingly, in this work, we considered different numbers of irrelevant documents for minor, moderate, and dramatic changes in the user’s level of interest in a topic. The results confirm that applying the proposed E_QE approach is much better than the traditionalTFIDF term weighting approach. We summarized the performance of each method and suggest the best strategy for query expansion and reweighting under different types of topic changes situations, as shown in Table 8
                     . In addition, we summarize the implications of the preliminary results of this study below.
                        
                           1.
                           We propose an effective approach to learning the user’s information needs depending on the degree of change in a user’s topic of interest. Classical relevance feedback techniques do not consider the user’s dynamic information needs. Thus, well known algorithms such as the Rocchio [26] and Ide [12] methods are designed to revise queries based on the user’s feedback on items without considering any degree of change in information needs. However, users’ information needs, often vague initially, evolve during the search process. Accordingly, minor, major, and dramatic change situations are considered in the proposed approach. The experimental results confirm that the proposed E_QE approach is more effective than the traditional TFIDF term weighting approach.

We propose an effective approach to learn the user’s short-term and long-term information needs. A single search session cannot accurately reflect changes in the user’s information needs during the problem-solving process. Information seeking (IS) involves searching for, extracting, and using information for a specific purpose when a person does not have sufficient prior knowledge. IR can be regarded as a process of IS, meaning that the latter may include one or more information retrieval activities [13,35,43,42]. Therefore, we conducted a simulation-based pseudo-relevance feedback process executed in eleven rounds to verify the learning capabilities of each method. The results show that it is important to consider different numbers of irrelevant documents depending on the degree of change in a user’s topic of interest for learning short- or long-term information needs. We summarized the results in Table 8. For minor topic changes, the E_QE(10-5) achieves the best performance for learning both short-term and long-term information needs. For moderate topic changes, the E_QE(10-10) achieves the best performance for learning short-term information needs. However, there is no single method that ensures the best result for learning long-term information needs when the change in topic is moderate. Based on our preliminary observations, the similarity between the query and search results may influence the results. For a dramatic change in topics, the E_QE(10-10) achieves the best performance for learning short-term information needs, while the E_QE(10-20) achieves the best performance for learning long-term information needs

We will implement the approach in an interactive information retrieval situation that allowed for interactive query expansion (IQE). Accordingly, we adopted the DCG method instead of the traditional precision and recall method to evaluate the performance of each approach. However, the results reveal that the performance of each topic is influenced by the degree of relevance to the target set. Thus, we will adopt normalized discounted cumulated gain (nDCG) metrics instead of DCG to overcome this problem and allow thorough comparisons across topics [14,15].

Several issues need to be investigated further. First, the results appear to show that the learning performance for differing degrees of change in topic needs is influenced by the degree of relevance to the search results (similarity between the topic and the search results). We will explore the issue of setting a strict threshold in Eqs. (5) and (6) of the proposed E_QE approach for increasing DCG values. That is, we will investigate whether adjusting the number of selection terms by varying the threshold influences the search results. Thus, we will investigate our findings by modifying the proposed approach in future work. Second, the proposed simulation-based pseudo-relevance feedback process relies on topic ontology to determine the relevancy of the returned pages. Accordingly, we will explore the ontology representation and data matching issues in formally describing the information semantics and modeling the user’s informational needs precisely [36]. Third, we will compare the proposed approach with the BM25 weighting scheme and the language model ([23,24]) for demonstrating the effectiveness of the proposed approach. Large scale experiments using an official dataset, TREC, will be considered in future work. Fourth, the experimental results show that no single method ensures better retrieval performance for learning moderate changes of information needs in the long run. We look forward to exploring this issue in the future. In our previous work [44], we took two years to evaluate the effectiveness of the proposed task-stage knowledge support model. Finally, an automatic task-stage identification technique is proposed and implemented for providing effective document support throughout the execution of a task. In our future work, we may incorporate a reweighting (E_QE) approach with the task-stage identification technique into the proposed entropy-based query expansion to support precise interactive document search activities for academic research.

@&#ACKNOWLEDGMENTS@&#

This research was supported by the National Science Council of Taiwan and Fu-Jen Catholic University under the Grant NSC 97-2410H-030-030-MY2 and No. 409931074078, respectively.

@&#REFERENCES@&#


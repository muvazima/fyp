@&#MAIN-TITLE@&#Dynamic texture segmentation based on deterministic partially self-avoiding walks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A video segmentation based on dynamic texture is proposed.


                        
                        
                           
                           The method uses deterministic partially self-avoiding walks and a k-means.


                        
                        
                           
                           The sequence of images is considered as a 3D matrix, which is split into blocks.


                        
                        
                           
                           A feature vector for each block is obtained using the deterministic walks algorithm.


                        
                        
                           
                           
                              k-Means algorithm clusters is used to obtain the video segmentation.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Dynamic texture segmentation

Deterministic partially self-avoiding walks




                     k-Means algorithm

@&#ABSTRACT@&#


               
               
                  Recently there has been a considerable interest in dynamic textures due to the explosive growth of multimedia databases. In addition, dynamic texture appears in a wide range of videos, which makes it very important in applications concerning to model physical phenomena. Thus, dynamic textures have emerged as a new field of investigation that extends the static or spatial textures to the spatio-temporal domain. In this paper, we propose a novel approach for dynamic texture segmentation based on automata theory and k-means algorithm. In this approach, a feature vector is extracted for each pixel by applying deterministic partially self-avoiding walks on three orthogonal planes of the video. Then, these feature vectors are clustered by the well-known k-means algorithm. Although the k-means algorithm has shown interesting results, it only ensures its convergence to a local minimum, which affects the final result of segmentation. In order to overcome this drawback, we compare six methods of initialization of the k-means. The experimental results have demonstrated the effectiveness of our proposed approach compared to the state-of-the-art segmentation methods.
               
            

@&#INTRODUCTION@&#

Due to the increasing number of multimedia databases and the great potential for applications, dynamic texture is lately receiving growing attention from computer vision community. Although texture has been usually described as a repeating pattern in its exact or with minor variation, texture is much more complex than that. Even a white image containing salt-and-pepper noise could be a texture pattern, for instance an image of marble. Thus, dynamic texture can be defined as visual phenomena that exhibit spatial and temporal regularity. Thus, they can be seen as an extension of static textures to the spatio-temporal domain. Examples of dynamic textures include real world scenes of traffic, moving escalators, boiling water, fire and steam. Various applications using dynamic textures have been reported in the literature, such as video retrieval [1,2], music [3], motion analysis [4], medical images [5,6], among others. There is, thus, an increasing demand for efficient and effective methods for dynamic texture representation.

Image or video segmentation is an important step in many computer vision systems. In particularly, dynamic texture segmentation consists of splitting the video into homogeneous regions in space and time. Video segmentation, including dynamic textures, faces a bigger challenge due to the need for consistency among segmentations of each frame, which is obtained by combining temporal and spatial information. Most of the existing approaches for dynamic texture segmentation are based on stochastic dynamical models [7–10]. The main difference between existing approaches relies on the manipulation of these models. In [7], the segmentation problem is managed as a level-set formulation using Martin distance [11] (a distance for non-Euclidean space) and Gauss-Markov model to represent each region. Second-order Ising descriptors governed by an autoregressive exogenous model were used in [10] to solve dynamic texture segmentation as a spatio-temporal variance minimization. Vidal and Ravichandran [4] proposed to model each dynamic texture as a linear dynamical system and a 2-D translational motion model. Then the segmentation is performed by clustering pixels with similar trajectories over time. Accurate segmentation on natural videos were obtained by Fazekas et al. in [12] by using a level set scheme that separates the video into regions obeying different motion assumptions. According to the authors, the motion assumptions based on the brightness conservation and color constancy assumption achieved the best results in segmenting dynamic textures. In [13], the dynamic texture is modeled by an autoregressive moving average model and the Kalman filter is used to estimate the parameters of the model (dynamic texture) and consequently the segmented video. Despite the promising results in dynamic texture segmentation, the methods described above are not able to model multiple regions that belong to different visual process [8] (e.g. video containing a river and grass, flag waving in the wind and a flock of birds flying, among others). To overcome this issue, Chan and Vasconcelos [8] proposed a method that estimates the parameters of k linear dynamical systems using the well-known Expectation Maximization (EM). Recently, an improved version was proposed in [9], which models dynamic textures as a collection of stochastic layers. Each layer models a dynamic texture sampled from a linear dynamical system. The reader can consult [14,15] for a review of dynamic texture methods.

In this paper, we propose a dynamic texture segmentation method based on deterministic partially self-avoiding walks [16] and the well-known k-means algorithm. Recently, a method for static textures based on these walks was proposed in [16–18]. Unlike these works, we extend the deterministic partially self-avoiding walks for dynamic textures by performing walks on three orthogonal planes of the video. The first plane (XY) models spatial features, while the two other ones (XT and YT) model motion features. Thus, the proposed extension is able to extract both spatial and motion features from dynamic textures. After the feature extraction, the vectors obtained for each pixel are clustered by the k-means algorithm. Although the k-means algorithm provides robust solutions, it is widely reported in the literature that its performance depends on the initial choice of centroids. To overcome this drawback, this paper also reports experiments using six k-means initialization methods. Experimental results illustrate that our method outperforms the existing ones as it makes feature extraction of dynamic textures more effective and more independent concerning the initial choice of centroids. The three main contributions of this paper are: (i) A robust and effective extension of deterministic partially self-avoiding walks for dynamic textures analysis. (ii) A new method for dynamic texture segmentation that compares favorably the state-of-the-art. (iii) Comparison of six k-means initialization methods for this particular problem of segmenting dynamic textures.

The rest of the paper is organized as follows. Image texture representation using deterministic partially self-avoiding walks is described in Section 2. Section 3 describes how to perform deterministic partially self-avoiding walks in sequence of images to extract features from dynamic textures. In Section 4, we present the proposed approach for dynamic texture segmentation. Section 5 describes six initialization methods for the k-means algorithm. Experiments and results are presented in Section 6, which is followed by the conclusion in Section 7.

Recently, an approach for grayscale image texture analysis, namely deterministic tourist walk – DTW, was proposed in [16]. Compared to the state-of-the-art, the method proposed by Backes et al. achieved promising results for static texture classification. Following the promising method, a new criterion of motion for the agent was proposed in [17] and a combination of graphs and deterministic partially self-avoiding walks was proposed in [18]. All these works were interested in representing static textures. In this work, we present a new method for dynamic texture representation based on an extension of these walks.

Next, we describe the use of deterministic partially self-avoiding walks in static textures since it is the basis for understanding our method of dynamic texture representation. Consider an image of W
                     ×
                     H pixels, where each pixel i has a gray-level I(i) that ranges from 0 to 255. Each pixel i has also a set of neighboring pixels η(i) composed by the 8-connected pixels. If j
                     ∈
                     η(i), then the weight of connection w
                     
                        ij
                      is given by the modulus of difference of intensity:
                        
                           (1)
                           
                              
                                 
                                    w
                                 
                                 
                                    ij
                                 
                              
                              =
                              |
                              I
                              (
                              i
                              )
                              -
                              I
                              (
                              j
                              )
                              |
                           
                        
                     
                  

The method for static texture representation considers independent agents walking through image pixels. Given that an agent is in pixel i, it moves to one of the neighboring pixels j that minimizes the weight w
                     
                        ij
                     . Moreover, the agent avoids returning to pixels visited recently, which are stored in a memory M of size μ. Considering η(i) as the set of neighbors of i, the iterative steps taken by the agent can be described in Eq. (2). The motions of the agent is governed by a criterion of motion din. In Eq. (2), the agent walks toward the neighboring pixel with lower weight w
                     
                        ij
                     . This criterion of motion will be referred to as din
                     =
                     min. The agent could also walk towards the maximum weight w
                     
                        ij
                      according to Eq. (3). This criterion of motion will be referred to throughout this paper as din
                     =
                     max. Since the criterion is chosen, it should not be changed during the walks
                        
                           (2)
                           
                              j
                              =
                              arg
                              
                                 
                                    
                                       min
                                    
                                    
                                       j
                                       ∈
                                       η
                                       (
                                       i
                                       )
                                    
                                 
                              
                              {
                              
                                 
                                    w
                                 
                                 
                                    ij
                                 
                              
                              
                              |
                              
                              j
                              
                              ∉
                              
                              M
                              }
                           
                        
                     
                     
                        
                           (3)
                           
                              j
                              =
                              arg
                              
                                 
                                    
                                       max
                                    
                                    
                                       j
                                       ∈
                                       η
                                       (
                                       i
                                       )
                                    
                                 
                              
                              {
                              
                                 
                                    w
                                 
                                 
                                    ij
                                 
                              
                              
                              |
                              
                              j
                              
                              ∉
                              
                              M
                              }
                           
                        
                     
                  

After a few steps, the agent produces a trajectory that can be divided into two parts: an initial transient part of size τ that ends in a cycle of period ρ called attractor. During the transient part, the agent walks freely to exploit texture features until it is trapped in an attractor. The attractor consists of a group of ρ pixels whose intensities form a pattern that the agent cannot escape from. Fig. 1
                      shows an example of the trajectory produced by an agent. The transient part of size τ
                     =3 is given by the three green pixels and the attractor of size ρ
                     =6 is given by the orange pixels.

To represent an image texture, each pixel is taken as an initial condition for a trajectory. If there are N image pixels, there will be N different trajectories initiated in each image pixel. The transient part and the attractor of each trajectory are combined into a joint distribution S
                     
                        μ,din
                     (τ,
                     ρ). The joint distribution defines the probability of a trajectory belonging to a transient part of size τ and an attractor of size ρ according to Eq. (4). From the study of these distributions, features able to discriminate image textures can be obtained [16]
                     
                        
                           (4)
                           
                              
                                 
                                    S
                                 
                                 
                                    μ
                                    ,
                                    din
                                 
                              
                              (
                              τ
                              ,
                              ρ
                              )
                              =
                              
                                 
                                    1
                                 
                                 
                                    N
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                1
                                                ,
                                             
                                             
                                                if
                                                
                                                
                                                   
                                                      τ
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                τ
                                                ,
                                                
                                                
                                                   
                                                      ρ
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                ρ
                                             
                                          
                                          
                                             
                                                0
                                                ,
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where τ
                     
                        i
                      and ρ
                     
                        i
                      are the sizes of transient part and attractor from a trajectory initiated in pixel i.

Dynamic texture segmentation is a very challenging problem, partly due to the need to extract appearance and motion features. The direct use of the previous method (e.g. 3D connection of the pixels) does not provide satisfactory results, due to lack of an explicit combination of appearance and motion features. For extracting both features from the dynamic texture, we propose to apply deterministic partially self-avoiding walks on three orthogonal planes. The three planes, namely XY, XT and YT planes, can be viewed in Fig. 2
                     . The XY plane enhances appearance features while XT and YT enhance motion features from the dynamic texture. Using this strategy of planes, the steps of the agent are directed to extract each feature, proving better results than considering a 3D connection of the pixels.

To apply the idea of the deterministic partially self-avoiding walks to dynamic texture, let I(i)∣i
                     =(x
                     
                        i
                     ,
                     y
                     
                        i
                     ,
                     t
                     
                        i
                     ) be a sequence of images, where x
                     
                        i
                      and y
                     
                        i
                      are the spatial indexes and t
                     
                        i
                      is the temporal index. The aim of the three orthogonal planes is to define the neighboring pixel η(i) and consequently to change and improve the agent’s behavior. The XY plane models the appearance features from the sequence of images. In this plane, the agent can only walk on image pixels belong to the same frame. Thus, the agent extracts the spatial variance of the dynamic texture using each frame independently. On the other hand, the XT and YT planes describe the temporal variation from the sequence of images. In these planes, the agent can walk between frames, so it extracts features related to motion. The definition of neighboring pixels for XY, XT and YT planes are presented in Eqs. (5)–(7), respectively. In previous works, we have evaluated the neighborhood set of pixels [16,17]. These experiments show that using other than this neighborhood (8-connected pixels) does not provide superior results as well as increase the computational time.
                        
                           (5)
                           
                              j
                              ∈
                              
                                 
                                    η
                                 
                                 
                                    XY
                                 
                              
                              (
                              i
                              )
                              
                              if
                              
                              
                                 
                                    
                                       
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                x
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          (
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              
                              ⩽
                              
                              
                                 
                                    2
                                 
                              
                              
                              and
                              
                              
                                 
                                    t
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    t
                                 
                                 
                                    j
                                 
                              
                           
                        
                     
                     
                        
                           (6)
                           
                              j
                              ∈
                              
                                 
                                    η
                                 
                                 
                                    XT
                                 
                              
                              (
                              i
                              )
                              
                              if
                              
                              
                                 
                                    
                                       
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                x
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          (
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              
                              ⩽
                              
                              
                                 
                                    2
                                 
                              
                              
                              and
                              
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                           
                        
                     
                     
                        
                           (7)
                           
                              j
                              ∈
                              
                                 
                                    η
                                 
                                 
                                    YT
                                 
                              
                              (
                              i
                              )
                              
                              if
                              
                              
                                 
                                    
                                       
                                          (
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          (
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              
                              ⩽
                              
                              
                                 
                                    2
                                 
                              
                              
                              and
                              
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                           
                        
                     
                  

To combine appearance and motion features, we propose to apply deterministic partially self-avoiding walks on each plane described above using the new definition of neighboring pixel. For this, consider that the agent is in pixel i and it is walking on the XY plane. The next step is to move to one of the neighboring pixels j
                     ∈
                     η
                     
                        XY
                     (i) that minimizes the weight w
                     
                        ij
                      and does not belong to the memory M of size μ. The iterative steps taken by the agent walking on the XY plane can be described in Eq. (8) for a criterion of motion din
                     =
                     min.
                        
                           (8)
                           
                              j
                              =
                              arg
                              
                                 
                                    
                                       min
                                    
                                    
                                       j
                                       ∈
                                       
                                          
                                             η
                                          
                                          
                                             XY
                                          
                                       
                                       (
                                       i
                                       )
                                    
                                 
                              
                              {
                              
                                 
                                    w
                                 
                                 
                                    ij
                                 
                              
                              
                              |
                              
                              j
                              
                              ∉
                              
                              M
                              }
                           
                        
                     
                  

Following this deterministic rule, the agent is trapped in an attractor 
                        
                           
                              
                                 ρ
                              
                              
                                 i
                              
                              
                                 XY
                              
                           
                        
                      after a transient part 
                        
                           
                              
                                 τ
                              
                              
                                 i
                              
                              
                                 XY
                              
                           
                        
                     . Taking each pixel i as an initial step of a walk, the joint distribution 
                        
                           
                              
                                 S
                              
                              
                                 μ
                                 ,
                                 din
                              
                              
                                 XY
                              
                           
                           (
                           τ
                           ,
                           ρ
                           )
                        
                      is obtained according to Eq. (9).
                        
                           (9)
                           
                              
                                 
                                    S
                                 
                                 
                                    μ
                                    ,
                                    din
                                 
                                 
                                    XY
                                 
                              
                              (
                              τ
                              ,
                              ρ
                              )
                              =
                              
                                 
                                    1
                                 
                                 
                                    N
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                1
                                                ,
                                             
                                             
                                                if
                                                
                                                
                                                   
                                                      τ
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      XY
                                                   
                                                
                                                =
                                                τ
                                                ,
                                                
                                                
                                                   
                                                      ρ
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      XY
                                                   
                                                
                                                =
                                                ρ
                                             
                                          
                                          
                                             
                                                0
                                                ,
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

In the method proposed here, deterministic partially self-avoiding walks are applied separately on each plane. Thus, three joint distributions are built as described above: 
                        
                           
                              
                                 S
                              
                              
                                 μ
                                 ,
                                 din
                              
                              
                                 XY
                              
                           
                           (
                           τ
                           ,
                           ρ
                           )
                           ,
                           
                           
                              
                                 S
                              
                              
                                 μ
                                 ,
                                 din
                              
                              
                                 XT
                              
                           
                           (
                           τ
                           ,
                           ρ
                           )
                        
                      and 
                        
                           
                              
                                 S
                              
                              
                                 μ
                                 ,
                                 din
                              
                              
                                 YT
                              
                           
                           (
                           τ
                           ,
                           ρ
                           )
                        
                     . From the analysis of these three distributions, our method is able to discriminate dynamic textures. Examples of joint distributions for the three planes are presented in Fig. 3
                     . As can be observed, the four classes of dynamic textures present different joint distributions.

Feature extraction from the joint distribution has been extensively studied in previous works [16,19,20]. The histogram of the joint distribution proved to achieve better results [16]. From a joint distribution, a histogram 
                           
                              
                                 
                                    h
                                 
                                 
                                    μ
                                    ,
                                    din
                                 
                                 
                                    ϕ
                                 
                              
                              (
                              τ
                              +
                              ρ
                              )
                           
                         is built to summarize the statistics (ϕ stands for one of the planes). This histogram represents the number of trajectories that has a size equal to (τ
                        +
                        ρ) in the joint distribution. It should be noted that τ
                        +
                        ρ is the number of visited pixels, but it does not match the number of different pixels visited since the trajectories can cross themselves. From the histogram, n features are selected to compose the feature vector 
                           
                              
                                 
                                    ψ
                                 
                                 
                                    μ
                                    ,
                                    din
                                 
                                 
                                    ϕ
                                 
                              
                           
                        . As there are no attractors of size smaller than μ
                        +1, the first descriptor selected has this size:
                           
                              (10)
                              
                                 
                                    
                                       ψ
                                    
                                    
                                       μ
                                       ,
                                       din
                                    
                                    
                                       ϕ
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                h
                                             
                                             
                                                μ
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          (
                                          μ
                                          +
                                          1
                                          )
                                          ,
                                          
                                             
                                                h
                                             
                                             
                                                μ
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          (
                                          μ
                                          +
                                          2
                                          )
                                          ,
                                          …
                                          ,
                                          
                                             
                                                h
                                             
                                             
                                                μ
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          (
                                          μ
                                          +
                                          n
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

The joint distribution and the feature vector 
                           
                              
                                 
                                    ψ
                                 
                                 
                                    μ
                                    ,
                                    din
                                 
                                 
                                    ϕ
                                 
                              
                           
                         depend on the memory size μ and the criterion of motion din (max or min). To capture information of different scales and sources, a feature vector φ
                        
                           ϕ
                         considering different values of μ is shown in Eq. (11). This feature vector is composed by concatenating the feature vectors 
                           
                              
                                 
                                    ψ
                                 
                                 
                                    
                                       
                                          μ
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    din
                                 
                                 
                                    ϕ
                                 
                              
                           
                        :
                           
                              (11)
                              
                                 
                                    
                                       φ
                                    
                                    
                                       ϕ
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                ψ
                                             
                                             
                                                
                                                   
                                                      μ
                                                   
                                                   
                                                      1
                                                   
                                                
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          ,
                                          
                                             
                                                ψ
                                             
                                             
                                                
                                                   
                                                      μ
                                                   
                                                   
                                                      2
                                                   
                                                
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                ψ
                                             
                                             
                                                
                                                   
                                                      μ
                                                   
                                                   
                                                      M
                                                   
                                                
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where din is the criterion of motion which can be max or min.

Using multiple memories helps to characterize texture patterns and has a great potential as a method of image classification [16]. In order to capture appearance and motion features, a strategy combining different planes is used. Thus, the feature vector φ (Eq. (12)) contains information extracted from three planes: XY, XT and YT.
                           
                              (12)
                              
                                 φ
                                 =
                                 [
                                 
                                    
                                       φ
                                    
                                    
                                       XY
                                    
                                 
                                 ,
                                 
                                    
                                       φ
                                    
                                    
                                       XT
                                    
                                 
                                 ,
                                 
                                    
                                       φ
                                    
                                    
                                       YT
                                    
                                 
                                 ]
                              
                           
                        
                     

In this section, we describe the proposed approach for dynamic texture segmentation. Fig. 4
                      summarizes the proposed approach: (1) The video is split into overlapping blocks. (2) For each block, a feature vector is obtained using deterministic partially self-avoiding walks applied in the three orthogonal planes. (3) k-Means algorithm clusters the vectors resulting in the video segmentation. The sections below describe the three steps of the proposed method.

Given a sequence of T images with w
                        ×
                        h pixels, it is split into N
                        = (w
                        ×
                        h
                        ×
                        T) blocks. For each pixel j, a block β
                        
                           j
                         of p
                        ×
                        p
                        ×
                        q pixels centered on pixel j is extracted to compose the set of blocks. It is important to note that p and q must be large enough to model texture and motion features, and small enough to not mix different textures. These values depend on the size of the images and usually the values for p varies from 5 to 10 (p
                        =9 in this work, p
                        =7 in [21] and p
                        =5 or 7 in [8,9]) and the values for q varies from 10 to T (− the number of frames.


                        Fig. 5
                        a shows examples of blocks of dimension p
                        ×
                        p
                        ×
                        q extracted from a sequence of image. If the segmentation boundaries do not change over time (e.g. dynamic textures from Fig. 6
                         do not change their segmentation boundaries), the temporal dimension can be set to the size of the sequence q
                        =
                        T (Fig. 5b). In this case, only the first frame of the sequence needs to be segmented because the boundaries of dynamic textures in the sequence do not move over time.

For each block β
                        
                           j
                        , a feature vector φ
                        
                           j
                         (Eq. (12)) is extracted using the proposed method described in Section 3. To extract the feature vector, we have to define three parameters: number of features from the histogram n, criterion of motion din and set of memories μ
                        1, …, μ
                        
                           M
                        .

Statistical analysis on the joint distribution (e.g. taking different elements of S
                        
                           μ,din
                         as feature vector in order to analyze the most discriminative and important elements) revealed that the important information for discriminating textures is concentrated in the first elements of the distribution [16]. Following these results, we have used five histogram descriptors n
                        =5:
                           
                              (13)
                              
                                 
                                    
                                       ψ
                                    
                                    
                                       μ
                                       ,
                                       din
                                    
                                    
                                       ϕ
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                h
                                             
                                             
                                                μ
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          (
                                          μ
                                          +
                                          1
                                          )
                                          ,
                                          …
                                          ,
                                          
                                             
                                                h
                                             
                                             
                                                μ
                                                ,
                                                din
                                             
                                             
                                                ϕ
                                             
                                          
                                          (
                                          μ
                                          +
                                          5
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

According to [20], the best results of dynamic texture representation are achieved for din
                        =
                        max. In this case, attractors are formed in heterogeneous regions of the block, i.e., regions, where the changes in intensity are more abrupt, thus characterizing the presence of high frequencies. The combination of memories diminishes the importance of individual value of memory μ and it provides more effective texture representation. Thus, the set of memories consists of five memories ranging from μ
                        =1 to 5 [16]. The feature vector using these parameters is presented in Eq. (14).
                           
                              (14)
                              
                                 
                                    
                                       φ
                                    
                                    
                                       ϕ
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                ψ
                                             
                                             
                                                1
                                                ,
                                                max
                                             
                                             
                                                ϕ
                                             
                                          
                                          ,
                                          
                                             
                                                ψ
                                             
                                             
                                                2
                                                ,
                                                max
                                             
                                             
                                                ϕ
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                ψ
                                             
                                             
                                                5
                                                ,
                                                max
                                             
                                             
                                                ϕ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Finally, we concatenate the feature vector for each orthogonal plane. Thus using these parameters, a feature vector of 75-dimensional is obtained for each block.

After feature extraction, the vectors φ
                        
                           j
                         are clustered by using the k-means algorithm. We have chosen this algorithm because it is a well-established clustering algorithm that is computationally efficient and does not require the specification of many parameters. Also, we have evaluated the Expectation Maximization algorithm which provided similar results but higher computational cost. The k-means is an iterative algorithm that minimizes the within-cluster sum of squared distances from the centroid 
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    ¯
                                 
                              
                           
                         by repeatedly moving 
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    ¯
                                 
                              
                           
                         to the arithmetic mean of its Voronoi set. The pseudo-code of the k-means algorithm is presented in Algorithm 1.
                           Algorithm 1
                           
                              k-Means algorithm 
                                 
                                    
                                       
                                       
                                          
                                             
                                                Input: Database X
                                                ={x
                                                
                                                   j
                                                }, Number of groups k
                                             
                                          
                                          
                                             
                                                Output: C
                                                1, C
                                                2, …, C
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             Initializes each centroid 
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                   
                                                ;
                                          
                                          
                                             
                                                repeat
                                             
                                          
                                          
                                             
                                                
                                                
                                                   
                                                      
                                                         
                                                            d
                                                         
                                                         
                                                            j
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      =
                                                      ‖
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      
                                                         
                                                            ‖
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      |
                                                      1
                                                      
                                                      ⩽
                                                      
                                                      j
                                                      
                                                      ⩽
                                                      
                                                      N
                                                      ,
                                                      1
                                                      
                                                      ⩽
                                                      
                                                      i
                                                      
                                                      ⩽
                                                      
                                                      k
                                                   
                                                ;
                                          
                                          
                                             
                                                
                                                
                                                   
                                                      
                                                         
                                                            n
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      =
                                                      arg
                                                      
                                                         
                                                            min
                                                         
                                                         
                                                            1
                                                            ⩽
                                                            i
                                                            ⩽
                                                            k
                                                         
                                                      
                                                      
                                                         
                                                            d
                                                         
                                                         
                                                            j
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                   
                                                ;
                                          
                                          
                                             
                                                Join the vector x
                                                
                                                   j
                                                 to the group 
                                                   
                                                      
                                                         
                                                            C
                                                         
                                                         
                                                            
                                                               
                                                                  n
                                                               
                                                               
                                                                  j
                                                               
                                                            
                                                         
                                                      
                                                   
                                                ;
                                          
                                          
                                             
                                                Calculate the new centroids 
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            1
                                                         
                                                         
                                                            |
                                                            
                                                               
                                                                  C
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                            |
                                                         
                                                      
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  m
                                                               
                                                            
                                                            ∈
                                                            
                                                               
                                                                  C
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            m
                                                         
                                                      
                                                   
                                                ;
                                          
                                          
                                             
                                                until No change occurs in groups C
                                                
                                                   i
                                                ;
                                          
                                       
                                    
                                 
                              
                           

Although k-means has been extensively used by the pattern recognition and computer vision community, it is known that its solution depends on the initial choice of centroids. Thus, the solution of the k-means may converge to a partition that is significantly inferior to the global optimum. Various heuristics have been proposed to find a robust initialization for the k-means. The following sections describe the main methods to initialize the k-means.

Despite having many limitations and usually providing a local solution, the Random method is one of the most used methods for k-means initialization due to its simplicity. In this method, k vectors of the database are randomly chosen as centroids. Each vector from the database has the same probability of being chosen as an initial centroid.

Astrahan [22] has proposed a k-means initialization method based on density. First, it defines a neighborhood radius 
                           
                              r
                              =
                              
                                 
                                    1
                                 
                                 
                                    N
                                    (
                                    N
                                    -
                                    1
                                    )
                                 
                              
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    N
                                    -
                                    1
                                 
                              
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                    =
                                    i
                                    +
                                    1
                                 
                                 
                                    N
                                 
                              
                              d
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              )
                           
                        , as the average pairwise distances. Then the density of each vector of the database is calculated. The density of a vector x
                        
                           i
                         is calculated by counting the number of vectors that are at a distance less than r. The vector with the highest density is chosen as the first initial centroid. The other k
                        −1 centroids are chosen in descending order of density, since they are at a distance r to all other centroids already chosen.

A strategy based on pairwise distances was proposed by Katsavounidis [23]. The idea behind the KKZ method is to select vectors that are further away from each other, following the premise that these vectors probably belong to different groups. The first centroid is the one that has the highest norm (
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          1
                                       
                                    
                                 
                                 
                                    ¯
                                 
                              
                              =
                              arg
                              max
                              ‖
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              ‖
                           
                        , where ∥·∥ is the vector norm). Then, it calculates the shortest distance d
                        
                           j
                         between each vector x
                        
                           j
                         and the centroids already defined. The vector j with the largest distance d
                        
                           j
                         is chosen as the next centroid. Repeat the above steps until the number of groups is equal to k.

A common method that presents an interesting solution is to initialize the k-means randomly M times and select the centroids which provide the best partition based on some internal measure. Following [24], a silhouette was chosen as an internal measure because it provides a high correlation with the optimal partition of the data.

The PCA method [25] is based on an iterative application of a principal component analysis to split the groups. The method starts with all vectors belonging to the same group. Then, we choose a group C
                        
                           i
                         (at first only one group is available) with the highest intra-group variance to perform the group division. For the group division, the vectors x
                        
                           j
                        
                        ∈
                        C
                        
                           i
                         are projected towards the first component λ obtained by the principal component analysis. The projected vector is called y
                        
                           j
                        . Then, it splits C
                        
                           i
                         into two subgroups 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                           
                         and 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                           
                         according to the rule: if 
                           
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                              ⩽
                              
                                 
                                    y
                                 
                                 
                                    ¯
                                 
                              
                           
                        , set x
                        
                           j
                         for 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                           
                        ; otherwise, set x
                        
                           j
                         for 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                           
                        . Repeat the above steps until the number of groups is equal to k.

In image segmentation, it is common to perform a semi-supervised segmentation. Thus, the user manually divides the regions and the algorithm uses this initial segmentation to refine the solution. In this work, the databases provide the initial segmented regions manually.

@&#EXPERIMENTS AND RESULTS@&#

Experiments using synthetic and natural videos were performed to evaluate the proposed method in dynamic texture segmentation. In all experiments, blocks of dimension p
                     =9 and q
                     =60 were used to extract the feature vectors using the proposed approach. It is important to emphasize that no additional strategy based on the spatial relationship of pixels was used to refine the solution obtained by the k-means.

To evaluate the proposed method and the six k-means initialization methods, experiments were conducted on 300 videos, each one consisting of dynamic textures [8]. All videos present high variability, thus presenting an interesting and hard challenge for the purpose of dynamic texture segmentation. The videos are composed by k
                        =2, 3, 4 groups (2, 3, 4 different dynamic textures). Each group was randomly chosen from a set of 12 dynamic textures, which include grass, sea, boiling water, moving escalators, fire, steam, water and plants. Videos had 60 frames with a resolution of 160×110 pixels. Examples of the real partition, the user segmentation regions used for the manual initialization, and databases with k
                        =2,3,4, can be visualized in Fig. 6.

In order to evaluate the proposed method in a natural context, we also perform experiments on dynamic textures from the Dyntex database [26], which present an interesting challenge for the purpose of segmentation. All the videos used in this experiment are 50 frames long with dimension of 720×576 pixels. Examples of natural dynamic textures can be seen in Fig. 7
                        .

In this section, we assess the quality of the final segmentation returned by the k-means algorithm using each of the six initialization methods. To quantify the segmentation results, the rand index [24] was used in all experiments. The rand index assesses the degree of agreement between the clustering solution obtained by the proposed approach and the real partition predefined. For the multiple runs of the k-means, the number of iterations M was set to 35 based on the plot of Fig. 8
                        . This plot presents the number of runs M versus the average of rand indexes for the database with k
                        =4. It can be observed that the average of rand indexes establishes for M
                        >30.


                        Table 1
                         presents the average and standard deviation of the number of iterations that k-means needs to converge. As expected, manual initialization lets the k-means algorithm run less iteration in all databases, which is followed by the multiple runs and PCA methods. Starting the k-means manually took on average 11.01, 12.90 and (12.74 iterations for the databases with 2–4 groups, respectively. It should be noted that the number of groups did not influence the number of iteration for manual initialization method, which did not happen for the other methods of initialization. The two other methods that deserve attention are: multiple runs and PCA, which took 18.52 and 21.26 iterations to converge for databases with k
                        =4, respectively. However, here we only present the average iteration numbers for the final k-means run. Therefore, using the PCA method usually requires less iteration than the multiple runs method. The remaining initialization methods achieved similar results, each taking an average of over 22 iterations for databases with k
                        =3 and k
                        =4.

The final partitions achieved by different methods of initialization are quantitatively evaluated using the rand index in Table 2
                        . As can be observed from the table, the manual initialization method achieved the highest rand index value. Disregarding the computational time due to multiple iterations, the multiple runs method achieved results comparable to the manual initialization method. Thus, the multiple runs method can be used as an automatic method for k-means initialization in dynamic texture segmentation. Although the PCA method does not achieve results comparable to the two best ones, it can be considered an automatic alternative for real-time dynamic texture segmentation. The other methods showed similar results to the random method, with a slight advantage over the Astrahan method.

To statistically compare the initialization methods, Friedman’s test [27] followed by the post hoc Nemenyi test were performed on the rand index. For all significance tests, we used α
                        =0.05. Tables 3 and 4
                        
                         present pairwise comparison of the initialization method for databases with 3 and 4 groups, respectively. The symbol of each position s
                        
                           ij
                         of the table has the following meanings: ⊙ – there was no significant difference between methods i and j, ◁ – there was a significant difference, which was method i better than method j, ▵ – there was a significant difference, which was method i worse than method j.

According to the tables, the Manual initialization method and the multiple runs method did not show significantly different results from each other. However, they showed to be significantly better than the other initialization methods in both numbers of groups k
                        =3 and k
                        =4. For databases with k
                        =3, the PCA method, Astrahan, KKZ and Random did not show results with significant differences. However, for databases with k
                        =4, the PCA method achieved results significantly better than the KKZ and Random method.

As an illustration, the final segmentations achieved by initialization methods are presented in Fig. 9
                        .

In addition to the results of initialization methods, we compare our results to four dynamic texture segmentation methods: Layered Dynamic Textures – LDT [9], Ising [10], Mixture of Dynamic Textures – MDT [8] and Generalized Principal Component Analysis – GPCA [4]. We briefly describe each method in the following paragraphs:


                        Generalized principal component analysis: each dynamic texture is modeled by a linear dynamical system and a 2D translational motion model. To estimate each LDS parameter, they propose to use a combination of Principal Component Analysis and Generalized Principal Component Analysis.


                        Ising: in this method, the spatial information of dynamic texture is modeled by a set of second order Ising descriptors. On the other hand, the temporal information is modeled by an autoregressive exogenous model. Then the dynamic texture segmentation problem is managed in a variational framework which minimize the spatial–temporal variance.


                        Mixture of dynamic textures: this method is a generative model which represents a video as samples from a set of dynamic textures. The parameters of the method are estimated using the expectation maximization algorithm.


                        Layered dynamic texture: in this method, each video is represented as a layered collection of dynamic textures. Each dynamic texture is modeled by a linear dynamical system. By means of expectation maximization algorithm, the method is able to estimate the model parameters from training video sequences.

In this comparison, the existing segmentation methods were initialized manually using the user segmentation provided in the databases, except for the LDT approach which was initialized using the results of the DTM segmentation [9]. The results of the existing approaches were obtained from the original papers and they are available on the website.
                           2
                           
                              http://www.svcl.ucsd.edu/projects/layerdytex/synthdb/.
                        
                        
                           2
                        
                     

In Table 5
                        , we show the average and standard deviation of rand index values for the dynamic texture segmentation methods. According to the original work, the Ising method can only segment videos composed by two dynamic textures. As can be observed, our approach using Manual initialization provides the best results for all databases. Improvements of 0.03, 0.06 and 0.02 were obtained by the proposed method compared to the LDT method for the databases with k
                        =2, 3, 4, respectively. In addition, our approach using the multiple runs method achieved excellent results compared to the other methods that are initialized manually. These experimental results demonstrate that our approach is an effective dynamic texture segmentation method compared to the state-of-the-art.

In this section, we show the segmentation results for dynamic textures in a natural context. Our method was applied using the multiple runs method for initialization of the k-means. In Fig. 10
                        , we analyze the segmentation results for different values of k in a natural dynamic texture − Fig. 10a. As can be observed, our method is able to segment the wall from the water using k
                        =2 (Fig. 10b). For k
                        =3 (Fig. 10c), the three classes are assigned to wall, calm water and water in motion. Finally for k
                        =4 (Fig. 10d), our method separates the four classes in the video, namely wall, calm water, water in motion and fountain. This way, our method provides a hierarchical segmentation of the video maintaining the adequacy of the classes.


                        Fig. 11
                         presents the results for videos of natural dynamic textures. The segmentation results for our method are presented in the left column. For comparison, we also present the results obtained by Fazekas et al. [12]
                        
                           3
                           The images were obtained from the website http://www.phy.bme.hu/fazekas/dtsegm/.
                        
                        
                           3
                         in the right column. Segmentation results show that our method is in agreement with perceptual categorization of the dynamic textures even in a challenge natural context.

In order to analyze non-informative parts of the video (i.e. no variation in time), we took samples of natural dynamic textures with different motion patterns. The classes of dynamic textures, shown in Fig. 12
                        a–c, are: Ground, Water 1, Tree, Wall, Water 2 and Smoke. From this set, the classes Water 1, Water 2 and Smoke present informative motion while the other ones are static in time. Fig. 12d shows the histogram curve 
                           
                              
                                 
                                    ψ
                                 
                                 
                                    μ
                                    =
                                    1
                                    ,
                                    din
                                    =
                                    max
                                 
                                 
                                    XT
                                 
                              
                           
                         of each sample. We can observe that there is a relation between the histogram and the motion pattern. In textures with motion, attractors close to each other are obtained by the agents. In this case, the histogram presents a higher peak in the beginning of the curve and decays rapidly because there are only a few long walks. On the other hand, for static textures in time, the probability of an agent to find an attractor varies according to the region of motion, thus making a more uniform histogram.

By applying a threshold on the entropy of histogram curves, we could discard static textures in time. Usually, the entropy of uniform histograms is higher than the entropy of histograms that presents a peak on the beginning of the curve. Thus, Fig. 13
                         presents an example of discarding regions whose the entropy of the histogram 
                           
                              
                                 
                                    ψ
                                 
                                 
                                    μ
                                    =
                                    1
                                    ,
                                    din
                                    =
                                    max
                                 
                                 
                                    XT
                                 
                              
                           
                         is higher than 1.42.

In [16] the computational complexity of the deterministic partially self-avoiding walks applied in N pixels is stated to O(N(τ
                        +
                        ρ)), where (τ
                        +
                        ρ) is the size of the walks. Our method applies these walks in three planes separately, thus the complexity is multiplied by 3−
                        O(3N(τ
                        +
                        ρ)). After the feature extraction, the k-means algorithm is applied to segment the video. It is known that the k-means computational complexity is O(Ndk), where d is the dimension of the features, k is the number of clusters and the number of iterations is fixed. Thus, the complexity of our method is stated to O(3N(τ
                        +
                        ρ)+
                        Ndk). It is shown in [16] that, for low values of μ, the size of the walks (τ
                        +
                        ρ) is in average 55, which leads to a good computational complexity.

@&#CONCLUSIONS@&#

In this paper, we proposed a new dynamic texture segmentation method based on deterministic partially self-avoiding walks and k-means algorithm. It first extracts a feature vector for each pixel using deterministic partially self-avoiding walks on three planes and then, these vectors are clustered using the k-means algorithm. The k-means algorithm experiences from the initial selection of centroids. Thus, this paper also presented a comparative study on six k-means initialization methods applied to the dynamic texture segmentation problem. Promising results on segmentation were achieved by the manual initialization and multiple runs of the k-means. Despite the underperformance, we suggest using the PCA initialization method for real-time applications. To estimate the suitable number of classes for the proposed method, we can perform the k-means using different values of k and taking the value of k which provides the highest silhouette measure as shown in the literature of data clustering [24].

Experimental results indicate that our method performs better than existing dynamic texture segmentation methods (e.g. compared with the LDT method, our method achieved a rand index of 0.97 against 0.94 for k
                     =2, 0.95 compared with 0.89 for k
                     =3, and 0.94 compared with 0.92 for k
                     =4). In addition, our method provided results significantly better than the results achieved by the Ising, MDT and GPCA methods.

@&#ACKNOWLEDGMENTS@&#

Odemir M. Bruno gratefully acknowledges the financial support of CNPq (National Council for Scientific and Technological Development, Brazil) (Grant Nos. #308449/2010-0 and #473893/2010-0) and FAPESP (The State of São Paulo Research Foundation) (Grant No. # 2011/01523-1). Wesley N. Gonçalves was supported by FAPESP Grant No. 2010/08614-0.

@&#REFERENCES@&#


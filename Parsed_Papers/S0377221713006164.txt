@&#MAIN-TITLE@&#Tabu-enhanced iterated greedy algorithm: A case study in the quadratic multiple knapsack problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Iterated greedy algorithms are tested on the quadratic multiple knapsack problem.


                        
                        
                           
                           A memory-enhanced destruction mechanism for iterated greedy is proposed.


                        
                        
                           
                           Problem-knowledge exploitation is identified in the iterated greedy proposal.


                        
                        
                           
                           Tabu-enhanced iterated greedy solves the problem effectively.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Iterated greedy search

Tabu search

Quadratic multiple knapsack problem

Destruction mechanism

@&#ABSTRACT@&#


               
               
                  Iterated greedy search is a simple and effective metaheuristic for combinatorial problems. Its flexibility enables the incorporation of components from other metaheuristics with the aim of obtaining effective and powerful hybrid approaches. We propose a tabu-enhanced destruction mechanism for iterated greedy search that records the last removed objects and avoids removing them again in subsequent iterations. The aim is to provide a more diversified and successful search process with regards to the standard destruction mechanism, which selects the solution components for removal completely at random.
                  We have considered the quadratic multiple knapsack problem as the application domain, for which we also propose a novel local search procedure, and have developed experiments in order to assess the benefits of the proposal. The results show that the tabu-enhanced iterated greedy approach, in conjunction with the new local search operator, effectively exploits the problem-knowledge associated with the requirements of the problem considered, attaining competitive results with regard to the corresponding state-of-the-art algorithms.
               
            

@&#INTRODUCTION@&#

Iterated greedy search (IG) is a simple metaheuristic for problems of combinatorial optimisation (Culberson & Luo, 1996; Fanjul-Peyro & Ruiz, 2010; Framinan & Leisten, 2008; Jacobs & Brusco, 1995; Lin, Lee, Ying, & Lu, 2011; Lozano, Molina, & García-Martínez, 2011; Ribas, Companys, & Tort-Martorell, 2011; Rodriguez, Lozano, Blum, & García-Martínez, 2013; Ruiz & Stützle, 2007; Urlings, Ruiz, & Stützle, 2010; Yuan et al., 2008). The IG model generates a sequence of solutions by iterating over greedy constructive heuristics, which are applied to a single solution, using two main phases: destruction and construction. During the destruction phase, some solution components are removed, producing a partial solution. The construction procedure then applies a greedy constructive heuristic to complete this partial solution. Then, an acceptance criterion is applied to decide whether the new candidate solution will replace the current solution. An optional local search phase for improving the initial solution and the reconstructed solution may be added before the main loop and the acceptance test, respectively. The flexibility of the IG framework enables the incorporation of components from other metaheuristics with the aim of obtaining effective and powerful hybrid metaheuristics (Lozano & García-Martínez, 2010; Talbi, 2002; Yuan et al., 2008).

Tabu search (Glover & Laguna, 1997) is a metaheuristic that pushes a local search to explore more widely in the solution space. A short-term memory, the tabu list, records recent changes to the solution; they cannot again be tried for a fixed number of steps. Ideas from tabu search are often combined with other metaheuristics (Cheang, Gao, Lim, Qin, & Zhu, 2012; Jarrah & Bard, 2012; Wu, Sun, & Srikanthan, 2012).

We explore the application of a tabu destruction mechanism to the IG algorithm as compared to the standard mechanism, which removes solution components completely at random. The Tabu-enhanced IG model (TIG) marks the removed solution components in a tabu list and prevents them from being removed again in the subsequent iterations. As in the basic tabu search scheme, the number of iterations that solution components are protected is defined by a user parameter, the tabu tenure.

We have considered the Quadratic Multiple Knapsack Problem (QMKP) (Hiley & Julstrom, 2006) as the application domain. It consists of assigning a set of objects disjunctively to a set of knapsacks with the aim of maximising the total sum of profits, subject to capacity constraints. However, profit values are assigned not only to individual objects but to pairs of them, too, so traditional approaches that do not consider the interactions between the objects are not expected to effectively address the problem (Julstrom, 2005). We also propose a novel local search operator for this problem that is analysed in conjunction with the TIG model. The experiments developed not only show that the resulting algorithm is able to effectively exploit the problem-knowledge associated with the QMKP requirements, but that it is competitive with the state-of-the-art approaches to this problem.

The rest of the article is structured as follows. In Section 2, we introduce the proposed TIG algorithm. In Section 3, we describe the QMKP, the application domain in which our proposal will be analysed, and the corresponding state-of-the-art approaches to its solution. In Section 4, we present the empirical studies, which are designed to: (1) analyse the influence of the parameters and settings associated with our proposal and the benefits derived from the application of the tabu-enhanced destruction mechanism, (2) compare the results of a tuned TIG instance with those of other approaches from the literature, and (3) detect the algorithmic components that effectively exploit the problem-knowledge associated with the QMKP. Finally, in Section 5, we discuss conclusions and further work.

We describe the proposed approach, TIG, which is an improved IG model applying a new destruction mechanism with a tabu list. The general description of the complete algorithm is presented in Section 2.1, and the motivation for tabu-enhanced destruction mechanism in Section 2.2.


                        Fig. 1
                         depicts the outline of an IG algorithm slightly adapted to apply the tabu-enhanced destruction mechanism. IG search starts from a single complete initial solution usually constructed from scratch by a greedy procedure (steps 1–3). Then, it iterates through a main loop in which first a partial solution S
                        
                           d
                         is obtained at the destruction phase (step 6), and second a complete candidate solution S
                        
                           c
                         is reconstructed by applying the greedy procedure to S
                        
                           d
                         (construction phase, step 7). A local search phase is added to improve the constructed solutions (steps 3 and 8). Before continuing with the next iteration, an acceptance criterion decides whether the solution returned by the local search procedure, S
                        
                           ls
                        , becomes the new current solution (step 12). The process iterates until some termination conditions have been met (e.g. maximum number of iterations, or maximum computation time allotted). The best solution, S
                        
                           b
                        , generated during the iterative process is kept as the overall result.

The specific features of the TIG method are:
                           
                              •
                              A novel tabu-enhanced destruction mechanism (Section 2.2) is invoked at the destruction phase (step 6).

We have explored the following two acceptance criteria:
                                    
                                       –
                                       
                                          Replace if better acceptance criterion (RB): The new solution is accepted only if it provides a better objective function value (Ying & Cheng, 2010).


                                          Random walk acceptance criterion (RW): An IG algorithm using the RB acceptance criterion may lead to the stagnation of the search due to insufficient diversification (Lozano et al., 2011; Ruiz & Stützle, 2007). At the opposite extreme is the random walk acceptance criterion, which always applies the destruction phase to the most recently visited solution, irrespective of its objective function value. This criterion clearly favours diversification over intensification, because it promotes a stochastic search in the space of local optima.

The greedy procedure, which provides the initial solution and reconstructs partial ones (steps 2 and 7, respectively), is specific to the problem at hand. For the QMKP we apply the approach proposed by Hiley and Julstrom (2006) (Section 3.2).

For the local search phase, we have investigated four specific improvement methods for the QMKP (described in Section 3.3). Two are from the literature and the two others are new. They are all based on exchanging objects from different knapsacks.

The destruction phase of the IG algorithm provides starting points for the construction phase, so that the search samples a variety of points in the search space. In its simplest form, destruction removes random components from the current solution (Ruiz & Stützle, 2007, 2008; Ying, 2008), though more elaborate procedures are possible. For example, Fanjul-Peyro and Ruiz (2010) proposed heuristic functions for the stochastic selection of the components to be removed for the unrelated parallel machine scheduling problem (Rodriguez, Blum, García-Martínez, & Lozano, 2012). They first defined several probability density functions for choosing a machine according to its workload, and then, jobs that could be processed faster in other machines than in that selected were considered for removal.

With the aim of improving the diversification production of the IG destruction phase, we propose the application of a short-term memory that prevents recently removed elements (which are probabilistically reinserted in the construction phase) from being deleted again in subsequent iterations. Every time a component is removed from the solution at the destruction phase, the tabu-enhanced procedure marks this component in a tabu list. Only unmarked solution components are allowed to be removed at the destruction phase. The number of iterations that a component remains marked is specified by a user parameter called tabu tenure.

The combination of tabu search elements with iteration methods has its beginnings in the strategic oscillation framework (Glover, 1977; Glover & Laguna, 1997), and has reported successful results in several application fields, such as binary quadratic programs (Glover, Kochenberger, & Alidaee, 1998), the multi-resource generalised assignment problem (Yagiura, Iwasaki, Ibaraki, & Glover, 2004), the maximally diverse grouping problem (Gallego, Laguna, Martí, & Duarte, 2013) and the linear ordering problem with cumulative costs (Duarte, Martí, Álvarez, & Ángel-Bello, 2012), among others. Strategic oscillation is a search strategy that, similarly to the IG model to a certain degree, operates by moves defined in relation to a critical boundary in regions of the search space that are expected to contain solutions of particular interest. This critical boundary is often associated with the problem’s constraints. One of the main differences between IG and strategic oscillation models is that the latter usually permit the critical boundary to be crossed whereas the former keep the search process within the region of feasible solutions.


                        Fig. 2
                         presents the pseudocode of the tabu-enhanced destruction mechanism. It receives the solution from where components are removed (S), the number of components to be removed (n
                        
                           d
                        ), the current state of the tabu list (L
                        
                           tabu
                        ), and the tabu tenure parameter (tt); and returns the new partial solution (S
                        
                           d
                        ) and the new state of L
                        
                           tabu
                        . Select-Unmarked-Component(S
                        
                           d
                        , L
                        
                           tabu
                        ) (step 6) chooses a component of the solution that is not marked in the short-term memory L
                        
                           tabu
                        . Function Mark-Component(L
                        
                           tabu
                        , j, tt) (step 8) marks component j in the short-term memory and sets its tabu tenure to the value tt. Finally, function Reduce-Tenure(L
                        
                           tabu
                        , i) (step 2) decrements the tenure value of component i in one.

The number of possible partial solutions that can be sampled from a complete candidate is equal to the binomial coefficient 
                           
                              
                                 
                                    C
                                 
                                 
                                    n
                                    -
                                    |
                                    
                                       
                                          L
                                       
                                       
                                          tabu
                                       
                                    
                                    |
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          d
                                       
                                    
                                 
                              
                           
                        , which is the number of ways, disregarding order, that n
                        
                           d
                         elements can be extracted from among (n
                        −∣L
                        
                           tabu
                        ∣) non-tabu components (with n
                        
                           d
                        
                        ⩽
                        n
                        −∣L
                        
                           tabu
                        ∣). Bearing in mind the direct correspondence between the value of parameter tt and ∣L
                        
                           tabu
                        ∣, once L
                        
                           tabu
                         contains the first tt elements, we realise that n
                        
                           d
                         and tt have a clear influence on the number of distinct partial solutions that can be sampled from the same complete one, which is the binomial coefficient 
                           
                              
                                 
                                    C
                                 
                                 
                                    n
                                    -
                                    tt
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          d
                                       
                                    
                                 
                              
                           
                        . Some comments are necessary in regard to the diversification provided by this mechanism. The possibility of sampling from a greater set of possible partial solutions enables the algorithm to increase its diversifying characteristics, and the size of this set is greater with higher n
                        
                           d
                         (in the range [0, ⌊(n
                        −
                        tt)/2⌋]) and lower tt settings. Furthermore, moderate tt values greater than 0 force the algorithm to lead the process to different regions of the space of partial solutions, by preventing previously removed elements from being extracted. The effect is that diversification is probabilistically increased by this guided sampling, which reduces the number of possible partial solutions. Then, the interaction between parameter tt and n
                        
                           d
                         determines the diversification that is promoted by the destruction mechanism: higher n
                        
                           d
                         values, in the aforementioned range, are expected to promote more diversification, but its effect can be elevated, with moderate tt values greater than 0, or reduced, with larger settings.

In the QMKP (Hiley & Julstrom, 2006), we are given a set of n objects and K knapsacks. Each object i
                     ∈{1,2,…,
                     n} has a profit p
                     
                        i
                      and a weight w
                     
                        i
                     , each pair of objects (i and j) has a profit p
                     
                        ij
                     , and each knapsack k
                     ∈{1,2,…,
                     K} has a capacity C
                     
                        k
                     . Objects and knapsacks will be referred to by their index positions in order to keep the notation as uncomplicated as possible. The profit p
                     
                        ij
                      associated with the pair of objects i and j is added to the total profit if both i and j belong to the same knapsack. The objective is to allocate each object to at most one knapsack in such a way that the total weight of the objects in each knapsack k does not exceed its capacity C
                     
                        k
                      and the total profit of all the objects included in the knapsacks is maximised. Formally, given the binary variables x
                     
                        ik
                     , which indicate whether the object i is included in the knapsack k, the QMKP is formulated as:
                        
                           (1)
                           
                              Maximise
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    ik
                                 
                              
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                              +
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                       -
                                       1
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                       =
                                       i
                                       +
                                       1
                                    
                                    
                                       n
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    ik
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    jk
                                 
                              
                              
                                 
                                    p
                                 
                                 
                                    ij
                                 
                              
                              ,
                           
                        
                     
                     
                        
                           (2)
                           
                              subject
                              
                              to
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                    
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    ik
                                 
                              
                              
                                 
                                    w
                                 
                                 
                                    i
                                 
                              
                              ⩽
                              
                                 
                                    C
                                 
                                 
                                    k
                                 
                              
                              ,
                              
                              ∀
                              k
                              ∈
                              {
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              K
                              }
                              ,
                           
                        
                     
                     
                        
                           (3)
                           
                              and
                              
                              
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    ik
                                 
                              
                              ⩽
                              1
                              ,
                              
                              ∀
                              i
                              ∈
                              {
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                              }
                              .
                           
                        
                     
                  

QMKP cases arise in real-world situations where resources with different levels of interaction among themselves have to be distributed to different tasks, for instance, assigning team members (potentials are considered both individually and in pairs) to different projects. The QMKP is an extension of two well known combinatorial optimisation problems, the multiple knapsack problem and the quadratic knapsack problem. As with its predecessors and many other knapsack problems (Florios, Mavrotas, & Diakoulaki, 2010; Leâo, Santos, Hoto, & Arenales, 2011; Sbihi, 2010), the QMKP is NP-hard (Hiley & Julstrom, 2006).


                        Hiley and Julstrom (2006) were the first to study this problem and they proposed three approaches to its solution: a greedy heuristic (commented upon in Section 3.2), which was able to provide feasible solutions from scratch; a hill-climbing method that consisted of removing some random objects from their corresponding knapsacks and applying the mentioned greedy heuristic to refill the solution; and a generational genetic algorithm. This latter comprised a population of solutions that were initialised by assigning iteratively objects to random knapsacks that could accommodate them. Afterwards, binary tournament selection and mutation and crossover operators were executed iteratively according to a crossover probability parameter. The mutation removed two random objects from their knapsacks and applied the greedy heuristic, and the crossover first copied into the offspring all the object assignments common to its two parents and then considered all the remaining objects in a random order for the knapsacks that could accommodate them. The best solution was preserved through the iterations.


                        Singh and Baghel (2007) addressed the QMKP with a grouping genetic algorithm. It was a steady-state model in which crossover and mutation produced a single child at each iteration (in a mutually exclusive manner), which replaced the least fit member of the population. Solutions were encoded as a set of knapsacks and multiple copies of the same solution were avoided by checking new ones against the existing population members. Initial solutions were created by the greedy heuristic in Hiley and Julstrom (2006) (Section 3.2), but assigning a random object to an arbitrary knapsack. Binary tournament was applied. The crossover operator iteratively selected one of the two parents, assigned the knapsack with the largest profit value to the child, and updated the remaining knapsacks in both parents; then unassigned objects were included in the knapsacks without violating their capacity constraints. Mutation removed some objects from knapsacks and refilled them randomly.


                        Saraç and Sipahioglu (2007) proposed another genetic algorithm. Initial solutions were generated by assigning random objects whose weights were smaller than the remaining capacity of the current knapsack, from the one with the smallest capacity to that with the largest. Binary tournament was applied to allow solutions to be copied to the next generation. The crossover operator interchanged the object assignments between two randomly selected parents. When a knapsack capacity was exceeded because of this interchange, the object was removed from the knapsack. Subsequently, unassigned objects were considered according to a heuristic rule (Hiley & Julstrom, 2006). Two mutation operators were included. One of them removed four objects from their knapsacks and refilled the solution, and the other tested interchanging objects assigned to different knapsacks. Elitism was applied to maintain the best solution from one generation to another.

Currently, the state-of-the-art for the QMKP is an artificial bee colony algorithm with local search presented by Sundar and Singh (2010). Bees were classified into employed, scouts and onlookers, and exploited food sources that represented solutions to the problem. Initially, each employed bee was associated with a randomly generated food source (candidate solution) generated in a manner similar to Singh and Baghel (2007). During each iteration, each employed bee determined a new food source in the neighbourhood of its currently associated food source and computed its nectar amount (fitness). If the nectar amount was higher than that of its current food source, the employed bee moved to the new food source, abandoning the old one, otherwise it continued with the old one. Subsequently, onlookers chose one of the food sources associated with employed bees by means of binary tournament selection, and determined a new food source in the neighbourhood that replaced the selected one if it was better. When a food source was not improved over a predetermined number of iterations, the associated employed bee abandoned it to become a scout. This scout drew a new random solution and became an employed bee associated with it. When exploring the neighbourhood of food sources, bees applied a knapsack replacement procedure between two solutions with a specific probability or otherwise a heuristic perturbation operator. An improvement method (described in Section 3.3) was executed when the difference between the fitness of the global best solution and the current one was inferior to a prespecified threshold. The artificial bee colony algorithm presented by Sundar and Singh was compared with the approaches mentioned above, obtaining better results in almost all the considered problem instances.


                        Hiley and Julstrom (2006) described a greedy constructive algorithm, which might be used to build feasible solutions for the QMKP. We firstly define the contribution (Δ(i, k)) and density (D(i, k)) of an object i with regards to knapsack k
                        ∈{1,…,
                        K}, as the sum of profit values associated with the object i and those already in the knapsack k, and its division by the weight of object i, respectively:
                           
                              (4)
                              
                                 Δ
                                 (
                                 i
                                 ,
                                 k
                                 )
                                 =
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                 
                                 +
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          ∈
                                          k
                                       
                                    
                                 
                                 
                                    
                                       p
                                    
                                    
                                       ij
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (5)
                              
                                 D
                                 (
                                 i
                                 ,
                                 k
                                 )
                                 =
                                 Δ
                                 (
                                 i
                                 ,
                                 k
                                 )
                                 /
                                 
                                    
                                       w
                                    
                                    
                                       i
                                    
                                 
                                 .
                              
                           
                        
                     

The greedy construction algorithm consists of performing iteratively the assignment of object i, from those not allocated to any knapsack yet, to knapsack k, maximising the value D(i, k) and subject to 
                           
                              
                                 
                                    w
                                 
                                 
                                    i
                                 
                              
                              +
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                    ∈
                                    k
                                 
                              
                              
                                 
                                    w
                                 
                                 
                                    j
                                 
                              
                              ⩽
                              
                                 
                                    C
                                 
                                 
                                    k
                                 
                              
                           
                        . This process is repeated until there is no other object with Δ(i, k)⩾0 that fits into any knapsack k. At each insertion, the fitness of the new solution is efficiently computed by adding up the corresponding contribution value Δ(i, k):
                           
                              (6)
                              
                                 f
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       ′
                                    
                                 
                                 )
                                 =
                                 f
                                 (
                                 S
                                 )
                                 +
                                 Δ
                                 (
                                 i
                                 ,
                                 k
                                 )
                                 .
                              
                           
                        
                     


                        Sundar and Singh (2010) proposed the application of a local search method that looked for an exchange between an unassigned object i and another j, already inside knapsack k, so that the exchange improved the solution quality (Δ
                        
                           ex
                        (i, j)>0) without violating the knapsack’s capacity:
                           
                              (7)
                              
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   Δ
                                                
                                                
                                                   ex
                                                
                                             
                                             (
                                             i
                                             ,
                                             j
                                             )
                                             =
                                             Δ
                                             (
                                             i
                                             ,
                                             k
                                             )
                                             -
                                             Δ
                                             (
                                             j
                                             ,
                                             k
                                             )
                                             -
                                             
                                                
                                                   p
                                                
                                                
                                                   ij
                                                
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             subject
                                             
                                             to
                                             
                                             
                                                
                                                   w
                                                
                                                
                                                   i
                                                
                                             
                                             -
                                             
                                                
                                                   w
                                                
                                                
                                                   j
                                                
                                             
                                             +
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      l
                                                      ∈
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   w
                                                
                                                
                                                   l
                                                
                                             
                                             ⩽
                                             
                                                
                                                   C
                                                
                                                
                                                   k
                                                
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        
                     

As soon as a profitable exchange was found, the local search performed that exchange, i.e., it implemented a first-improvement strategy. This local search is referred to as FirstLS. We also consider the application of the best-improvement strategy that searches for the pair of objects (i, j) that maximises Δ
                        
                           ex
                        (i, j). The corresponding improvement method is referenced as BestLS.

We have designed two other local search methods that consider the exchange of any two objects, whether they are assigned to a knapsack or not. We expect this to be beneficial for the QMKP because it considers additional possibilities that previous local optimisers do not, in particular, the case of exchanging two objects that are already included in two different knapsacks. We then define the following exchange contribution metric 
                           
                              
                                 
                                    
                                       
                                          
                                             Δ
                                          
                                          
                                             ex
                                          
                                          
                                             ∗
                                          
                                       
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                 
                              
                           
                        , which is general for any of the following cases:
                           
                              •
                              Exchanging two unassigned objects without effect 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      Δ
                                                   
                                                   
                                                      ex
                                                   
                                                   
                                                      ∗
                                                   
                                                
                                                (
                                                i
                                                ,
                                                j
                                                )
                                                =
                                                0
                                             
                                          
                                       
                                    
                                 .

Exchanging two objects assigned to the same knapsack without effect (
                                    
                                       
                                          
                                             Δ
                                          
                                          
                                             ex
                                          
                                          
                                             ∗
                                          
                                       
                                       (
                                       i
                                       ,
                                       j
                                       )
                                       =
                                       0
                                    
                                 ).

Exchanging an unassigned object and another included in a knapsack (
                                    
                                       
                                          
                                             Δ
                                          
                                          
                                             ex
                                          
                                          
                                             ∗
                                          
                                       
                                       (
                                       i
                                       ,
                                       j
                                       )
                                       =
                                       
                                          
                                             Δ
                                          
                                          
                                             ex
                                          
                                       
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                 ).

Exchanging two objects assigned to two different knapsacks (i and j from knapsacks k
                                 1 and k
                                 2, respectively). Here the contribution is composed of the contribution of object i in k
                                 2, plus the contribution of object j in k
                                 1, minus their contributions in k
                                 1 and k
                                 2, respectively, minus twice the profit of the pair (i, j).


                        Hiley and Julstrom (2006) described another hill-climbing method that removed a number of random objects from each knapsack and then refilled the knapsacks in a random order. Since the described procedure is somewhat similar to the basic operation of IG algorithms, this method has not been considered among the studied local search approaches.

@&#EXPERIMENTS@&#

We describe the experiments carried out in order to study the behaviour of a TIG algorithm adapted for the QMKP, which applies the greedy constructive heuristic proposed by Hiley and Julstrom (2006) (Section 3.2) and the local search methods in Section 3.3. The experimental setup and comparison methodology are described in Section 4.1. The rest of the sections show the results of the studies carried out. Our aims are to: (1) analyse the influence of the parameters and settings associated with the algorithm to obtain a tuned TIG instance that is able to show a robust operation (Section 4.2), (2) compare the results with those of other metaheuristic approaches to the QMKP from the literature (Section 4.3), and (3) detect the algorithmic components that effectively exploit the problem-knowledge associated with the QMKP (Section 4.4).

The algorithms were implemented in C++ and compiled with gcc 4.6.3.
                           1
                           The website http://www.uco.es/grupos/kdis/kdiswiki/index.php/TIG-QMKP provides the sourcecodes, instances, and results.
                        
                        
                           1
                         The experiments were conducted on a computer with a 2.8gigahertz Intel (R) Core (TM) i7-930 processor (8megabytes cache, 4 cores and 8 threads) with 12gigabytes of RAM running Fedora (TM) Linux V15. Each execution of an algorithm is performed sequentially, using a unique thread. We have developed experiments on the same 60 QMKP instances used in Hiley and Julstrom (2006), Singh and Baghel (2007), Saraç and Sipahioglu (2007), and Sundar and Singh (2010), which are characterised by their density d (proportion of non-zero profits p
                        
                           ij
                        ; {0.25,0.75}), number of objects n ({100,200}), and number of knapsacks K ({3,5,10}). Knapsacks’ capacities are set to 80% of the sum of the instances’ objects’ weights divided by the number of knapsacks.

All the algorithms were executed 40 times on each problem instance, each run consuming a maximum of 5seconds for problems with 100 objects and 30seconds for problems with 200 objects.

Non-parametric tests have been used to compare the results of different search algorithms (Garcia, Molina, Lozano, & Herrera, 2009). We have considered the average of the best objective function value found at the end of each run over the same number of runs for each algorithm and problem. Specifically, we have considered two alternative methods based on non-parametric tests to analyse the experimental results:
                           
                              •
                              The first method is the application of Iman and Davenport’s test (Iman & Davenport, 1980) and Holm’s method (Holm, 1979) as a post hoc procedure. The first test is used to see whether there are significant statistical differences among the results of a certain group of algorithms. If differences are detected, then Holm’s test is employed to compare the best algorithm (control algorithm) with the remaining ones.

The second method is the Wilcoxon matched-pairs signed-ranks test (Wilcoxon, 1945), which compares the results of two algorithms directly.

The aim of this section is to investigate the effect of the different parameters and strategies used in our proposal, in order to obtain a tuned TIG algorithm. We first attempt to obtain a competitive standard IG algorithm (Section 4.2.1) where the short-term memory L
                        
                           tabu
                         is not active, i.e. the destruction mechanism selects components completely at random from the entire set of assigned objects. Subsequently, we analyse the impact of the tabu mechanism on the best performing standard IG instance (Section 4.2.2).

We intend to find the combinations, under a full factory design, of acceptance criteria ({RB, RW}), improvement method ({NoLS, BestLS, FirstLS, BestLS∗, FirstLS∗}), and n
                           
                              d
                            ({0.2n, 0.4n, 0.6n, 0.8n}) (number of solution components that are removed from the current solution) that result in a better performance of a standard IG algorithm.


                           Table 1
                            shows the mean ranking of the best ten IG algorithms (out of 40) and the best one without an improvement method (NoLS), which are noted as IG-〈improvement method〉-〈n
                           
                              d
                           〉-〈acceptance criterion〉. Iman and Davenport’s test finds significant performance differences between the considered algorithms because the statistical value for a significance factor of 0.05 (475.584) is greater than the critical one (1.405). We apply Holm’s test in order to find significant performance differences between the best ranked configuration (IG-FirstLS∗-0.2-RW) and the others. The third column shows whether Holm’s test finds significant differences between the best ranked algorithm and the corresponding one (+), or significant differences were not found (∼). As shown in Table 1, Holm’s test finds significant performance differences between IG-FirstLS∗-0.2-RW and those variants that apply BestLS, FirstLS or no local search operator, and those with n
                           
                              d
                           
                           >0.4. Therefore, we may conclude that the key features to obtain an effective standard IG algorithm are the application of the enhanced improvement methods (FirstLS∗ and BestLS∗) and small n
                           
                              d
                            values. The utilisation of the first-improvement strategy (FirstLS∗) is noteworthy in most of the best algorithms.

We analyse the impact of the tabu destruction mechanism on the IG metaheuristic, i.e., the performance difference between TIG and standard IG algorithms. First, we take the best performing IG instance so far, IG-FirstLS∗-0.2-RW, as the base for tuning TIG instances, and afterwards, TIG and standard IG versions are statistically analysed.

We have performed experiments with three values for the tabu tenure parameter (tt
                           ∈{3,7,13}). In addition, some other values for n
                           
                              d
                            ({0.05n, 0.1n, 0.15n, 0.2n, 0.25n, 0.3n}) have been tested because of its interaction with tt (commented on Section 2.2). Table 2
                            shows the mean ranking of the best ten algorithms (out of 20), noted as TIG-〈n
                           
                              d
                           〉-T〈tabu tenure〉 if the tabu mechanism is applied, or IG-〈n
                           
                              d
                           〉 if they are standard IG instances (all of them apply the FirstLS∗ and RW acceptance criterion).

Iman and Davenport’s test finds significant performance differences between the considered algorithms because the statistical value for a significance factor of 0.05 (70.775) is greater than the critical one (1.596). Table 2 shows that the best algorithm applies the tabu enhancement with tabu tenure equal to 7. However, Holm’s test does not find possible differences with other IG instances that do not apply it. In order to analyse whether the tabu mechanism really provides any performance improvement on the IG algorithm, we apply Wilcoxon’s test between the best ranked tabu-enhanced variants (TIG-0.1-T7 and TIG-0.05-T13) and the corresponding best ranked standard IG versions (IG-0.1 and IG-0.05, respectively). Table 3
                            summarises the results of this procedure with 0.05 as the significance factor, where the values of R+ (associated with the TIG versions) and R− of the test are specified. The fourth column indicates whether Wilcoxon’s test found statistical differences between these algorithms. If R− is less than the critical value, the TIG version provides significantly better results than the corresponding standard IG approach. The opposite occurs if R+ is less than the critical value. No significant differences are found if neither R+ nor R− is less than the critical value.

According to the results in Table 3, the TIG versions provide statistically better results than their corresponding standard ones. Therefore, we may conclude that the tabu destruction mechanism provides significant advantages to the IG scheme in comparison to the standard one.

The best standard IG algorithm, which is equivalent to a TIG algorithm with tt equal to 0, has its n
                           
                              d
                            parameter set to a value (0.2) smaller than that for the best TIG instance (0.1). According to the comments in Section 2.2, we conjecture that the diversification enhancement promoted by the moderate tt value of 7 is better complemented with a diversification reduction by setting n
                           
                              d
                            to a smaller value (0.1).

We compare the TIG method with the results of an integer programming model (Hiley & Julstrom, 2006; Saraç & Sipahioglu, 2007) (Eqs. (1)–(3)) solved by CPLEX 12 and the metaheuristic approaches found in the literature for the QMKP (Section 3): HJ-SHC (Hiley & Julstrom, 2006), HJ-GCA (Hiley & Julstrom, 2006), SS-GA (Saraç & Sipahioglu, 2007), SB-SSGGA (Singh & Baghel, 2007), and SS-ABC (Sundar & Singh, 2010). The latter is the current state-of-the-art for the QMKP. We have selected the TIG configuration that provided the best results in the previous study (TIG-0.1-T7), which will be referred to as TIG from now on.


                        Tables 4 and 5
                        
                         present the average results of the algorithms on the QMKP instances with d
                        =0.25 and d
                        =0.75, respectively, collected from Sundar and Singh (2010) (unreported results for SS-GA are indicated with a dash ‘–’). The seventh column of Tables 4 and 5 only show the best result between the algorithms HJ-SHC and HJ-GGA because of space restrictions. Superscript values 1 and 2 indicate which algorithm provided these results, either HJ-SHC or HJ-GGA respectively. In order to perform a fair comparison, and in the absence of a maximum number of evaluations in Sundar and Singh (2010), we have appended the results of our proposal and CPLEX when executions were truncated at the mean time indicated in Sundar and Singh (2010) per problem instance(fifth column). CPLEX was run only once per problem instance, allowing compression and disk backup when more than 400megabytes RAM memory was required. Best results (Best) and standard deviation (SD) from 40 executions are included for the state-of-the-art and our proposal. The best average results among all the algorithms and the best maximum result and standard deviation between the SS-ABC and TIG methods are highlighted in bold.


                        Tables 4 and 5 show that the TIG approach obtains better average results than the other algorithms in 55 out of 60 problem instances. Moreover, with regards to SS-ABC, the best results of TIG are better in 46 problem instances and its standard deviations are always smaller, which proves that its operation is more effective and robust. CPLEX is unable to provide feasible solutions to several problem instances, finding those with 10 knapsacks particularly difficult, and obtaining poor results for the rest with regard to the other approaches. Table 6
                         summarises the results of Wilcoxon’s test for our proposal and the other algorithms for 0.05 as the significance factor, where the values of R+ are associated with the TIG model. The corresponding critical values are adapted according to the problem instances solved. Wilcoxon’s test finds significant differences between the TIG algorithm and every other approach. We may conclude that our proposal is competitive with regard to the state-of-the-art metaheuristics for the QMKP.

Our aim is to analyse whether the different TIG algorithmic components suit the requirements of the QMKP, showing profitable problem-knowledge exploitation. Section 4.4.1 presents the TIG characteristics and the algorithms considered in the study, together with the obtained results. Section 4.4.2 discusses the findings.

The following aspects of the TIG approach are studied:
                              
                                 1.
                                 
                                    Tabu-enhanced destruction mechanism: The diversification provided by the destruction mechanism is expected to provide performance improvements through the repetitive removal of diverse components from the current solution. In order to make this conjecture visible, we compare the generic performance of the TIG method and the tuned standard IG algorithm (IG-0.1; Section 4.2.2), which only differs from the former in the absence of the tabu-enhanced destruction mechanism, referred to as IG from now on.


                                    Solution improvement by means of FirstLS
                                    ∗: The application of local search methods in optimisation processes usually consumes considerable amounts of the computational resources allotted to the complete metaheuristic (García-Martínez & Lozano, 2010; Molina, Lozano, García-Martínez, & Herrera, 2010), particularly in terms of time. Practitioners often have to evaluate the tradeoff between improvement and consumption implied by these methods because their absence might be globally advantageous. In order to evaluate their benefits we compare the performance of the aforementioned algorithms (TIG and IG), which apply FirstLS∗, and the best standard IG approach that does not apply local search (IG-NoLS-0.2-RB; Section 4.2.1), referred to as IG-NoLS from now on.


                                    Iterative heuristic reconstruction of partial solutions: The core method of IG algorithms with which effectively explore the space of solutions is the repetitive application of partial destruction and reconstruction mechanisms. Among other possibilities, the iterative evaluation of solutions close to a particular solution, according to a specified neighbourhood structure, is the cornerstone of successful metaheuristics such as tabu search (TS) (Glover & Laguna, 1997) and simulated annealing (SA) (Kirkpatrick, Gelatt, & Vecchi, 1983). Though the statements of the no-free-lunch theorems (Wolpert & Macready, 1997) and the fact that these two general-purpose metaheuristics do not exploit problem-knowledge explicitly, a recent study proves that they may be sufficiently effective for problems of practical interest (García-Martínez, Lozano, & Rodriguez, 2012). Therefore, it is appropriate to analyse the key foundation of IG algorithms (TIG, IG, and IG-NoLS variants) with regard to other metaheuristics such as SA and TS. To this end, we have implemented both algorithms, which operate on an array of integer values (x
                                    1,…,
                                    x
                                    
                                       n
                                    ) where each variable x
                                    
                                       i
                                    
                                    ∈{0,1,…,
                                    K} represents the knapsack where object i has been allocated (0 is for unassigned objects). Their move operations assign new values to only one variable x
                                    
                                       i
                                     resulting in a feasible solution and Eq. (6) is applied to reduce the fitness calculation of the new solution. Regarding these two methods:
                                       
                                          •
                                          The implemented TS makes use of a short-term memory that remembers the variables whose values have been recently modified. The tabu tenure parameter specifies the number of iterations that solution components are in the short-term memory. The best move not involving a variable in the short term memory is applied at each iteration. Its aspiration criterion accepts new solutions better than the best one found so far even when it involves a variable in the short-term memory. In addition, if the best solution has not been improved after a maximum number of global iterations, the current solution is randomly reinitiated from scratch.

We have applied a standard SA that checks the move operation in every possible new assignment in a random order. As soon as one new assignment to a variable x
                                             
                                                i
                                              results in a feasible solution, it is checked according to the logistic acceptance criterion. The cooling scheme is the geometric one with a cooling factor α. The initial temperature is set in the following manner: first, two random solutions are generated; then a temperature value is computed according to the acceptance criterion and an initial desired probability of accepting the worse solution from the best one, which is specified by the user.


                                    Heuristic initial solution: By starting the search process from a heuristically constructed initial solution, IG algorithms have a clear advantage over other approaches that commence from random solutions such as most general-purpose metaheuristics, TS and SA in particular. We attempt to measure this favourable circumstance by including in our experimentation two versions of TS and SA that start from a heuristically constructed solution (Section 3.2), namely TS∗ and SA∗, respectively.

The parameters of TS, SA, TS∗, and SA∗ have been tuned, under a full-factory design, considering the values shown in Table 7
                           . The values reporting the best results are highlighted in bold.


                           Fig. 3
                            shows the behaviour of the search algorithms throughout the whole run. In order to obtain a convergence graph summarising algorithms’ behaviours, we have taken the following two steps:
                              
                                 1.
                                 Taking into consideration the highest and lowest fitness values achieved by the algorithms on each test problem, we have normalised every result throughout every run into the interval [0,1].

Subsequently, mean values, over the 60 problem instances and 40 runs, have been obtained for each algorithm, over the course of the execution.

@&#DISCUSSION@&#

Four design decisions exploit problem knowledge in the QMKP:
                              
                                 1.
                                 Initiating the search process from a heuristically constructed solution provides a significant improvement on the obtained results. This is the case because SA and TS, the approaches that do not start from a heuristic solution, are clearly unable to obtain high-quality results.

When comparing the graphs of the TIG and IG algorithms with regard to that of the IG-NoLS, we can see that the application of the enhanced local search method, FirstLS∗, elevates the quality of the solutions obtained without an appreciable worsening of the algorithms’ efficiency.

The progressive advance of the TIG, IG, and IG-NoLS algorithms with regard to TS∗ and SA∗ shows that the iterative heuristic reconstruction of partial solutions is more effective than the general-purpose neighbourhood explorations carried out by TS∗ and SA∗ (and TS and SA).

Finally, the application of the proposed tabu-enhanced destruction mechanisms allows the TIG search to further improve the results of a tuned standard IG algorithm. This enhancement reveals its benefits after the initial iterations of the algorithm, when the inner short-term memory has been properly initialised and the tabu-enhanced destruction mechanism exploits the contained information in order to produce diverse partial solutions.

@&#CONCLUSIONS@&#

We have proposed a tabu-enhanced destruction mechanism that improves the operation of standard IG algorithms with the production of diverse partial solutions. It makes use of a short-term memory that marks the components recently removed from the current solution and prevents the destruction mechanism from selecting them for removal in subsequent iterations. We have considered the QMKP as the application domain, for which a novel local search operator has been designed, and the influence of the different parameters and strategies of TIG have been analysed. From the experiments carried out, we have concluded that the proposed tabu destruction mechanism provides advantages to the IG algorithm in comparison to the standard destruction approach. Moreover, we have compared the results of the final proposal with those from the literature for the QMKP, showing that the TIG model is competitive with the state-of-the-art algorithms, emerging as the tool of choice for this problem. Finally, we have analysed the algorithmic components of the proposal, with regard to other IG versions and competitive general-purpose methods, in order to ensure that the TIG algorithm was able to effectively exploit the problem-knowledge associated with the requirements of the QMKP.

We believe that the Tabu-enhanced IG framework presented is a significant contribution, worthy of future study. We intend to explore two interesting avenues of research: (1) to adapt the TIG approach for its application to other challenging combinatorial problems, such as the demand-constrained multi-dimensional knapsack problem and (2) to build hybrid metaheuristics combining the proposed TIG model with other salient approaches for the QMKP (e.g., artificial bee colony algorithms), or classic models (e.g., applying a simulated annealing strategy as acceptance criterion).

@&#ACKNOWLEDGEMENTS@&#

This work was supported by the research Projects TIN2012-37930-C02-01 and P08-TIC-4173.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Efficient optimization of many objectives by approximation-guided evolution

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Our framework for multi-objective optimization uses a formal notion of approximation.


                        
                        
                           
                           Its runtime increases only linearly with the number of objectives.


                        
                        
                           
                           Our framework achieves a good approximation of the Pareto front across many problems.


                        
                        
                           
                           This is rarely the case for established algorithms such as NSGA-II, IBEA and SPEA2.


                        
                        
                           
                           Our approach now allows the optimization of problems with many objectives.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multi-objective optimization

Approximation

Comparative study

@&#ABSTRACT@&#


               
               
                  Multi-objective optimization problems arise frequently in applications, but can often only be solved approximately by heuristic approaches. Evolutionary algorithms have been widely used to tackle multi-objective problems. These algorithms use different measures to ensure diversity in the objective space but are not guided by a formal notion of approximation. We present a framework for evolutionary multi-objective optimization that allows to work with a formal notion of approximation. This approximation-guided evolutionary algorithm (AGE) has a worst-case runtime linear in the number of objectives and works with an archive that is an approximation of the non-dominated objective vectors seen during the run of the algorithm. Our experimental results show that AGE finds competitive or better solutions not only regarding the achieved approximation, but also regarding the total hypervolume. For all considered test problems, even for many (i.e., more than ten) dimensions, AGE discovers a good approximation of the Pareto front. This is not the case for established algorithms such as NSGA-II, SPEA2, and SMS-EMOA. In this paper we compare AGE with two additional algorithms that use very fast hypervolume-approximations to guide their search. This significantly speeds up the runtime of the hypervolume-based algorithms, which now allows a comparison of the underlying selection schemes.
               
            

@&#INTRODUCTION@&#

Real-world optimization problems are usually very complex and hard to solve due to different circumstances such as constraints, complex function evaluations that can only be done by simulations, or multiple objectives. Most real-world optimization problems are characterized by multiple objectives. As these objectives are often in conflict with each other, the goal of solving a multi-objective optimization (MOO) problem is to find a (not too large) set of compromise solutions. The so-called Pareto front of a MOO problem consists of the function values representing the different trade-offs with respect to the given objective functions. The set of compromise solutions that is the outcome of a MOO run is an approximation of this Pareto front, and the idea of this posteriori approach is that afterwards the decision maker selects an efficient solution from this set. Multi-objective optimization is regarded to be more (or at least as) difficult as single-objective optimization due to the task of computing several solutions. From a computational complexity point of view even simple single-objective problems on weighted graphs like shortest paths or minimum spanning trees become NP-hard when they encounter at least two weight functions (Ehrgott, 2005). In addition, the size of the Pareto front is often exponential for discrete problems and even infinite for continuous ones.

Due to the hardness of almost all interesting multi-objective problems, different heuristic approaches have been used to tackle them. Among these methods, evolutionary algorithms are frequently used. They work at each time step with a set of solutions called population. The population of an evolutionary algorithm for a MOO is used to store desired trade-off solutions for the given problem.

As the size of the Pareto front is often very large, evolutionary algorithms and all other algorithms for MOO have to restrict themselves to a smaller set of solutions. This set of solutions should be a good approximation of the Pareto front. The main question is now how to define approximation. The literature (see e.g. Deb, 2001) on evolutionary multi-objective optimization (EMO) just states that the set of compromise solutions (i) should be close to the true Pareto front, (ii) should cover the complete Pareto front, and (iii) should be uniformly distributed. There are different evolutionary algorithms for multi-objective optimization such as NSGA-II (Deb, Pratap, Agrawal, and Meyarivan, 2002), SPEA2 (Zitzler, Laumanns, and Thiele, 2002), or IBEA (Zitzler and Künzli, 2004), which try to achieve these goals by preferring diverse sets of non-dominated solutions.

However, the above notion of approximation is not a formal definition. Having no formal definition of approximation makes it hard to evaluate and compare algorithms for MOO problems. Therefore, we think that it is necessary to use a formal definition of approximation in this context and evaluate algorithms with respect to this definition.

Different formal notions of approximation have been used to evaluate the quality of algorithms for multi-objective problems from a theoretical point of view. The most common ones are the multiplicative and additive approximations (see Cheng, Janiak, and Kovalyov, 1998; Daskalakis, Diakonikolas, and Yannakakis, 2010; Diakonikolas and Yannakakis, 2009; Papadimitriou and Yannakakis, 2000; 2001; Vassilvitskii and Yannakakis, 2005). Laumanns, Thiele, Deb, and Zitzler (2002) have incorporated this notion of approximation in an evolutionary algorithm for MOO. However, this algorithm is mainly of theoretical interest as the desired approximation is determined by a parameter of the algorithm and is not improved over time. Another approach related to a formal notion of approximation is the popular hypervolume indicator (Zitzler and Thiele, 1999) that measures the volume of the dominated portion of the objective space. Hypervolume-based algorithms such as MO-CMA-ES (Igel, Hansen, and Roth, 2007) or SMS-EMOA (Beume, Naujoks, and Emmerich, 2007) are well-established for solving MOO problems. They do not use a formal notion of approximation but it has recently been shown that the worst-case approximation obtained by optimal hypervolume distributions is asymptotically equivalent to the best worst-case approximation achievable by all sets of the same size (Bringmann and Friedrich, 2010b; 2010c). The major drawback of the hypervolume approach is that it cannot be computed in time polynomial in the number of objectives unless P = NP (Bringmann and Friedrich, 2010a). It is even NP-hard to determine which individual gives approximately the least contribution to the total hypervolume (Bringmann and Friedrich, 2012).

We introduce an efficient framework of an evolutionary algorithm for MOO that works with a formal notion of approximation and improves the approximation quality during its iterative process. The algorithm can be applied to a wide range of notions of approximation that are formally defined. As the algorithm does not have complete knowledge about the true Pareto front, it uses the best knowledge obtained so far during the optimization process.

The intuition for our algorithm is as follows. During the optimization process, the current best set of compromise solutions (usually called “population”) gets closer and closer to the Pareto front. Similarly, the set of all non-dominated points seen so far in the objective space (we call this “archive”) is getting closer to the Pareto front. Additionally, the archive is getting larger and larger and becoming an increasingly good approximation of the true Pareto front. Assuming that the archive approximates the Pareto front, we then measure the quality of the population by its approximation with respect to the archive. In our algorithm

                        
                           •
                           any set of feasible solutions constitutes an (potentially bad) approximation of the true Pareto front, and

we optimize the approximation with respect to all solutions seen so far.

We introduce a basic approximation guided evolutionary algorithm which already performs very well for problems with many objectives. One drawback of the basic approach is that the archive size might grow tremendously during the run of the algorithm. In order to deal with this, we propose to work with an approximative archive which keeps at each time step only an ɛ-approximation of all solutions seen so far. We do this by incorporating the ɛ-dominance approach of Laumanns et al. (2002) into the algorithm. Furthermore, we introduce a powerful parent selection scheme which especially increases the performance of our algorithm for problems with just a few objectives by given the algorithm a stronger focus on the extreme points on the Pareto front.

We show on a set of well established benchmark problems that our approach is highly successful in obtaining high quality approximations according to the formal definition. Comparing our results to state of the art multi-objective algorithms such as NSGA-II, SPEA2, IBEA, and SMS-EMOA, we show that our algorithm typically gives better results, especially for high dimensional problems.

In our experimental study, we measure the quality of the results obtained not only in terms of the approximation quality but also with respect to the achieved hypervolume. Our experiments show that the examined hypervolume-based algorithms can sometimes achieve a larger hypervolume than our algorithm AGE, but AGE is the only one considered that finds a competitive hypervolume for all functions. Hence our algorithm not only performs better regarding our formal definition of approximation on problems with many objectives, but it is also competitive (or better, depending on the function) regarding the hypervolume.

This article is based on its previous conference publications. The based AGE algorithm has been introduced in Bringmann, Friedrich, Neumann, and Wagner (2011). The archive approximation has been presented in Wagner and Neumann (2013) and different parent selection schemes for AGE have been examined and discussed in Wagner and Friedrich (2013).

The outline of this paper is as follows. We introduce some basic definitions in Section 2. The main idea of approximation guided evolution and the basic AGE algorithm are presented in Section 3. In Section 6 we show how to speed up the approach by using an approximative archive and discuss different parent selection schemes in Section 5. We present our experimental results in Section 8 and finish with a summary and some concluding remarks.

Multi-objective optimization deals with the optimization of several (often conflicting) objective functions. The different objective functions usually constitute a minimization or maximization problem on their own. Optimizing with respect to all given objective functions, there is usually no single optimal objective function vector, but a set of vectors representing the different trade-offs that are imposed by the objective functions.

Without loss of generality, we consider minimization problems with d objective functions, where d ≥ 2 holds. Each objective function 
                        
                           
                              f
                              i
                           
                           :
                           S
                           ↦
                           R
                           ,
                        
                      1 ≤ i ≤ d, maps from the considered search space S into the real values. In order to simplify the presentation we only work with the dominance relation on the objective space and mention that this relation transfers to the corresponding elements of S.

For two points x = (x
                     1, …, xd
                     ) and y = (y
                     1, …, yd
                     ), with 
                        
                           x
                           ,
                           y
                           ∈
                           
                              
                                 R
                              
                              d
                           
                        
                      we define the following dominance relation:

                        
                           
                              
                                 
                                    
                                       
                                          x
                                          ⪯
                                          y
                                       
                                    
                                    
                                       
                                          
                                          :
                                          ⇔
                                          
                                          
                                             x
                                             i
                                          
                                          ≤
                                          
                                             y
                                             i
                                          
                                          
                                          for
                                          
                                          all
                                          
                                          1
                                          ≤
                                          i
                                          ≤
                                          d
                                          ,
                                       
                                    
                                 
                                 
                                    
                                       
                                          x
                                          ≺
                                          y
                                       
                                    
                                    
                                       
                                          
                                          :
                                          ⇔
                                          
                                          x
                                          ⪯
                                          y
                                          
                                          and
                                          
                                          x
                                          ≠
                                          y
                                          .
                                       
                                    
                                 
                              
                           
                        
                     
                  

The typical notions of approximation used in theoretical computer science are multiplicative and additive approximation. We use the following definition

                        Definition 1
                        For finite sets 
                              
                                 S
                                 ,
                                 T
                                 ⊂
                                 
                                    
                                       R
                                    
                                    d
                                 
                                 ,
                              
                            the additive approximation of T with respect to S is defined as

                              
                                 
                                    
                                       α
                                       
                                          (
                                          S
                                          ,
                                          T
                                          )
                                       
                                       :
                                       =
                                       
                                          max
                                          
                                             s
                                             ∈
                                             S
                                          
                                       
                                       
                                          min
                                          
                                             t
                                             ∈
                                             T
                                          
                                       
                                       
                                          max
                                          
                                             1
                                             ≤
                                             i
                                             ≤
                                             d
                                          
                                       
                                       
                                          (
                                          
                                             s
                                             i
                                          
                                          −
                                          
                                             t
                                             i
                                          
                                          )
                                       
                                       .
                                    
                                 
                              
                           
                        

In this paper, we only consider additive approximations. However, our approach can be easily adapted to multiplicative approximations. In this case, the term si
                      − ti
                      in Definition 1 has to be replaced by si
                     /ti
                     .

Our aim is to minimize the additive approximation value of the population P we output with respect to the archive A of all points seen so far, i.e., we want to minimize α(A, P). The problem is that α(A, P) is not sensitive to local changes of P. As its definition is based on maximum and minimum values, α(A, P) only measures the approximation of points that are worst approximated. Consequently, it does not take into account approximation values for points that are not “worst approximated”. We will illustrate this with a very simple example. Let us consider a two-dimensional space with an archive A = {(1, 2), (2, 1), (3, 0)} and a population P = {(2, 1)}. Then, α(A, P) = 1 due to archive points (1, 2) and (3, 0). Even if points such as (3, 0) or (2.5, 0.5) are added to the population, the approximation value will remain α(A, P) = 1 because of the worst approximated archive point (1, 2), even though the approximation of (3, 0) is significantly improved.

To get a sensitive indicator, which can be used to guide the search, we consider instead the set {α({a}, P)∣a ∈ A} of all approximations of the points in A. We sort this set decreasingly and call the resulting sequence

                        
                           
                              
                                 
                                    S
                                    α
                                 
                                 
                                    (
                                    A
                                    ,
                                    P
                                    )
                                 
                                 :
                                 =
                                 
                                    (
                                    
                                       α
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       α
                                       
                                          |
                                          A
                                          |
                                       
                                    
                                    )
                                 
                                 .
                              
                           
                        
                     The first entry α
                     1 is again α(A, P). Our new goal it then to minimize Sα
                     (A, P)lexicographically, meaning that we take the lexicographically smallest sequence when we face several sequences.
                        1
                     
                     
                        1
                        (a
                           1, …, a
                           |A|) < lex(b
                           1, …, b
                           |A|) ⇔ (a
                           1 < b
                           1) or ((a
                           1 = b
                           1) and (a
                           2, …, a
                           |A|) < lex(b
                           2, …, b
                           |A|)).
                     
Note that this is a refinement of the order induced by α(A, P): If we have α(A, P
                     1) < α(A, P
                     2) then we also have Sα
                     (A, P
                     1) < lex
                     Sα
                     (A, P
                     2). Moreover, this indicator is locally sensitive. Subroutine 1
                      states the pseudo-code for computing Sα
                     (A, P) for a given archive A and a population P.

We are now ready to describe the basic AGE algorithm. It works with the vector Sα
                     (A, P) and tries to minimize it with respect to the lexicographical order. Depending on the optimization process the archive A changes and stores at each point in time for each non-dominated objective vector one single solution.

The basic AGE algorithm shown in Algorithm 3
                      works with a parent population of μ individuals and produces in each generation λ offspring.

A newly produced offspring p is added to the archive A if it is not dominated by any other solution found so far. If it is added to the archive, all solutions that are dominated by p are removed from A (see Subroutine 2
                     ). In order to obtain the next parent population, the set consisting of the union of the parent and offspring is considered. From this set, the individual p for which Sα
                     (A, P∖{p}) is lexicographically smallest is removed iteratively until a population of size μ is obtained. Note that in contrast to many other evolutionary algorithms (like Laumanns et al., 2002 or all hypervolume-based algorithms), the basic AGE algorithm needs no meta-parameters besides the population sizes μ and λ.

We now analyze the runtime of the basic AGE algorithm in dependence of μ, λ, the archive size A, and the number of function evaluations N of the algorithm. One generation consists of producing and processing λ offspring. The main part of the runtime is needed for the 
                        
                           O
                           (
                           λ
                           (
                           μ
                           +
                           λ
                           )
                           )
                        
                      computations of Sα
                     (A, P∖{p}), each costing 
                        
                           O
                           (
                           d
                           
                           |
                           A
                           |
                           
                           (
                           μ
                           +
                           λ
                           )
                           +
                           |
                           A
                           |
                           log
                           |
                           A
                           |
                           )
                        
                     . Hence, we get a runtime of 
                        
                           O
                           (
                           λ
                           (
                           μ
                           +
                           λ
                           )
                           
                           |
                           A
                           |
                           
                           (
                           d
                           
                           (
                           μ
                           +
                           λ
                           )
                           +
                           log
                           |
                           A
                           |
                           )
                           )
                        
                      for generating an offspring population of λ individuals. This means for N function evaluations, that is, N generated points overall, we get a total runtime of

                        
                           (1)
                           
                              
                                 
                                    
                                    
                                       
                                          O
                                          (
                                          N
                                          
                                          (
                                          μ
                                          +
                                          λ
                                          )
                                          
                                          |
                                          A
                                          |
                                          
                                          (
                                          d
                                          
                                          (
                                          μ
                                          +
                                          λ
                                          )
                                          +
                                          log
                                          |
                                          A
                                          |
                                          )
                                          )
                                       
                                    
                                 
                              
                           
                        
                     As we can see, this basic algorithm becomes very slow due to the (μ + λ)2 factor when, e.g., μ + λ = 200 is chosen. However, this algorithm works well (in the sense of runtime) for very small population and offspring sizes.

The following three sections describe three successive improvements for this basic framework of approximation guided evolution.

It can be observed that the selection phase is the most costly step in one iteration of the basic AGE given in Algorithm 3 as it has to evaluate the points of the parent and offspring population against the archive. We can obtain a significant speed-up for each generation of the algorithm by cleverly updating the approximation value of the points in the archive that are affected by the removal of a point from the set consisting of the parents and offspring.

Let us first assume that the approximations α({a}, {p}) are distinct for all a ∈ A and p ∈ P. For all a ∈ A we denote the point p ∈ P that approximates it best by p
                     1(a) and the second best by p
                     2(a). The respective approximations we denote by αi
                     (a) ≔ α({a}, {pi
                     (a)}) for i ∈ {1, 2}. Now, let p ≠ q ∈ P and consider Sp
                      ≔ Sα
                     (A, P∖{p}) and Sq
                      ≔ Sα
                     (A, P∖{q}). Significant for the comparison of the two are only the positions a ∈ A where Sp
                      or Sq
                      differ from S ≔ Sα
                     (A, P). This is the case for all positions in B ≔ {a ∈ A∣p
                     1(a) ∈ {p, q}}. Now, if we delete p from the population P, then the worst approximation of one of the a ∈ B is the maximum of max {α
                     2(a)∣p
                     1(a) = p} and max {α
                     1(a)∣p
                     1(a) = q}. Now observe that if

                        
                           
                              
                                 β
                                 
                                    (
                                    p
                                    )
                                 
                                 :
                                 =
                                 
                                    max
                                    
                                       a
                                       ∈
                                       A
                                    
                                 
                                 
                                    {
                                    
                                       α
                                       2
                                    
                                    
                                       (
                                       a
                                       )
                                    
                                    ∣
                                    
                                       p
                                       1
                                    
                                    
                                       (
                                       a
                                       )
                                    
                                    =
                                    p
                                    }
                                 
                              
                           
                        
                     is smaller than the respective β(q), then also the larger term above is smaller, as max {α
                     1(a)∣p
                     1(a) = q} < max {α
                     2(a)∣p
                     1(a) = q}. Hence, we end up with the fact that we only have to compare β(p) and throw out the point p with minimal β(p). This is shown in Subroutine 4
                     , which replaces lines 12–15 of Algorithm 3.
                        2
                     
                     
                        2
                        AGE with this selection scheme was called “Fast AGE” in Bringmann et al. (2011).
                     
                  

Recall that we assumed that all approximations α({a}, {p}) with a ∈ A, p ∈ P are distinct. If this does not hold, we can simply change the indicator Sα
                     (A, P) slightly and insert symmetry breaking terms a · ɛ, where ɛ > 0 is an infinitesimal small number. This means that we treat equal approximations as not being equal and hence in some arbitrary order.

We now give an upper bound for the runtime of AGE with Subroutine 4. For one generation, i.e., for producing and processing λ offspring with one run of Subroutine 4, AGE needs a runtime of 
                        
                           O
                           (
                           d
                           
                           (
                           μ
                           +
                           λ
                           )
                           
                           |
                           A
                           |
                           )
                        
                      for computing the values p
                     1(a), p
                     2(a), α
                     1(a), α
                     2(a) and β(p) initially. Then we repeat λ times: We delete the point p* ∈ P with β(p) minimal in 
                        
                           O
                           (
                           μ
                           +
                           λ
                           )
                           ,
                        
                      after which we have to recompute the values p
                     1(a), p
                     2(a), α
                     1(a), α
                     2(a), but only for a ∈ A with p
                     1(a) = p*. Observe that we can store a list of these a’s during the initial computation and keep these lists up to date with no increase of the asymptotic runtime. Also note that we would expect to find 
                        
                           O
                           (
                           |
                           A
                           |
                           /
                           |
                           P
                           |
                           )
                        
                      points with p
                     1(a) = p*, while in the worst case there may be up to 
                        
                           O
                           (
                           |
                           A
                           |
                           )
                        
                      such points. Summing up, we can estimate the expected runtime for one generation by 
                        
                           O
                           (
                           d
                           
                           (
                           μ
                           +
                           λ
                           )
                           
                           |
                           A
                           |
                           +
                           λ
                           (
                           (
                           μ
                           +
                           λ
                           )
                           +
                           d
                           |
                           P
                           |
                           ·
                           |
                           A
                           |
                           /
                           |
                           P
                           |
                           )
                           )
                           ,
                        
                      which simplifies to 
                        
                           O
                           (
                           d
                           (
                           μ
                           +
                           λ
                           )
                           |
                           A
                           |
                           )
                        
                      as |A| ≥ μ + λ. In the worst case we replace 
                        
                           O
                           (
                           |
                           A
                           |
                           /
                           |
                           P
                           |
                           )
                        
                      by 
                        
                           O
                           (
                           |
                           A
                           |
                           )
                        
                      and get a runtime for one generation of 
                        
                           O
                           (
                           d
                           λ
                           (
                           μ
                           +
                           λ
                           )
                           |
                           A
                           |
                           )
                        
                     . For N fitness evaluations we, therefore, get a runtime of 
                        
                           O
                           (
                           d
                           (
                           1
                           +
                           μ
                           /
                           λ
                           )
                           |
                           A
                           |
                           N
                           )
                        
                      heuristically, and 
                        
                           O
                           (
                           d
                           (
                           μ
                           +
                           λ
                           )
                           |
                           A
                           |
                           N
                           )
                        
                      in the worst case. Note that |A| ≤ N. For any 
                        
                           λ
                           =
                           O
                           (
                           μ
                           )
                           ,
                        
                      e.g. λ = 1 or λ = μ, this can be simplified to 
                        
                           O
                           (
                           d
                           μ
                           |
                           A
                           |
                           N
                           )
                        
                      in both cases, while for λ = Ω(μ), e.g. λ = μ, we get a reduced estimate of the expected runtime of 
                        
                           O
                           (
                           d
                           |
                           A
                           |
                           N
                           )
                        
                     .

Quite interestingly, and despite the basic AGE’s good performance on problems with many objectives (as shown in Bringmann et al., 2011), it is clearly outperformed by other algorithms in several cases, when the problem has just two or three objectives. The key discovery is that the random parent selection of the basic AGE is free of any bias. For problems with many objectives, this is not a problem, and can even be seen as its biggest advantage. For problems with just a few objectives, however, it is well known that one can do better than random selection, such as selection based on crowding distance, hypervolume contribution, etc. Such strategies then select potential candidates based on their relative position in the current population. For the basic AGE, the lack of this bias means that solutions can be picked for parents that are not necessarily candidates with high potential. Consequently, it is not surprising to see that the basic AGE is outperformed by algorithms that do well with their parent selection strategy, if their strategy is effective in the respective d-dimensional objective space.

We improve the basic AGE’s performance, subject to the following conditions:

                        
                           1.
                           The introduced computation time required to select parents should be polynomial in the number of objectives d.

The selection mechanism should significantly improve the performance on problems with few objectives, while not influencing the performance on problems with many objectives.

The selection scheme should favor individuals that have the potential to improve the approximation quality.

Note that most hypervolume-based algorithms, such as SMS-EMOA and MO-CMA-ES, violate condition (1), as some of the computations that are associated with the selection process take time exponential in d. However, we have to note that it is possible to deal with this drawback by approximating the hypervolume, as shown and demonstrated in Bringmann, Friedrich, Igel, and Voß (2013). Nevertheless, as the maximization of the hypervolume can interfere with our goal of improving the approximative quality, we do not consider such approaches.

Also note that the exclusive use of domination based-criteria is problematic. Assuming a general d-dimensional unbounded space (with d ≥ 2), then a point in this space dominates 1/2
                        d
                      of the volume. Obviously then, a pure dominance check in high-dimensional spaces is extremely likely to fail. Or, when interpreted the other way around, this means that a check of the dominance relation between two solutions is extremely unlikely to bring up any additional information about the relative quality between these two solutions.

It is relatively easy to design algorithms that easily discover points at the fringe of the Pareto front. With these fringe points (or points that are very close to the fringe), the decision maker can get an idea about the achievable ranges for each objective. However, the problem of finding points “between” those fringe points proves to be much more difficult. Selection mechanisms for the (fitness-based) parent selection and the offspring selection tend to have different biases that result in different preferences for fringe points or central points, depending on the “shape” of the intermediate populations and on the shape of the true Pareto front. With an increasing number of dimensions, this problem becomes even more apparent, as solutions should evenly cover the front, while not concentrating only on extreme points.

We choose the best-performing selection scheme from Wagner and Friedrich (2013), which works as follows in each generation. In the first step, the population is “pre-processed” (see Algorithm 5
                     ): the population is split into fronts of non-dominating solutions,
                        3
                     
                     
                        3
                        Iteratively, all non-dominated solutions are identified and then removed (as one front), which results in potentially several fronts of dominating solutions—see NSGA and NSGA-II (Deb et al., 2002).
                      and then solutions in the front i have a probability of 1/i of staying in the population. Thus, we increase the selection pressure, and solutions that are dominated multiple times are less likely to be selected as a potential parent. Additionally, we determine the crowding distances for the points in the reduced population. In the second step of the selection scheme, a binary tournament is performed where solutions of higher crowding distance are preferred. The crowding distance helps to pick diverse parents when the number of objectives is low.

Note that the size of the pre-processed population is not deterministic. It is only guaranteed to contain the entire first front (see Line 5 of Algorithm 5).

The basic AGE algorithms stores all objective vectors into the archive that are currently not dominated by any other objective vector produced so far. It is common for multi-objective optimization problems that the number of such trade-offs can be very large, i.e. exponential with respect to the given input size in the case of discrete optimization or even infinite for continuous optimization problems. As, in the worst case, the archive size |A| can grow linearly in the number of fitness function evaluations, the runtime given in Eq. (1) becomes quadratic in the number of generated points N. We therefore want to work with an archive of reduced size which can lead to a significant speed up of the algorithm.

In this section, we show how we adapt the ɛ-dominance approach Laumanns et al. (2002) in order to approximate the different points seen so far during the run of the algorithm. This archive is significantly reduced and therefore leads to a faster algorithm.

In order to approximate the archive, we are facing a problem that is similar to the original problem of multi-objective optimization, namely a set of solutions is sought that nicely represents the true set of compromise solutions.

We reuse AGE’s own main idea of maintaining a small set that approximates the true Pareto front. By approximating the archive as well in a controlled manner, we can guarantee a maximum size of the archive, which directly translates into a bound with respect to the runtime of AGE when considering a fixed number of iterations.

Our archive approximation is based on the idea of ɛ-dominance introduced in Laumanns et al. (2002). Instead of using an archive At
                         that stores at any point in time t the whole set of non-dominated objective vectors, we are using an archive 
                           
                              A
                              
                                 
                                    ɛ
                                 
                                 grid
                              
                              
                                 (
                                 t
                                 )
                              
                           
                         that stores an additive ɛ-approximation of the non-dominated objective vectors produced until time step t.

In order to maintain such an approximation during the run of the algorithm, a grid on the objective space is used to pick a small set of representatives (based on ɛ-dominance, see Fig. 1
                        ). We reuse the update-mechanism from Laumanns et al. (2002), and thus can maintain the ɛ-Pareto set 
                           
                              A
                              
                                 
                                    ɛ
                                 
                                 grid
                              
                              
                                 (
                                 t
                                 )
                              
                           
                         of the set A
                        (t) of all solutions seen so far. Due to Laumanns et al. (2002), the size is bounded by

                           
                              
                                 
                                    
                                       |
                                       
                                          A
                                          
                                             
                                                ɛ
                                             
                                             grid
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                       
                                       |
                                    
                                    ≤
                                    
                                       ∏
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          d
                                          −
                                          1
                                       
                                    
                                    
                                       ⌊
                                       
                                          K
                                          
                                             
                                                ɛ
                                             
                                             grid
                                          
                                       
                                       ⌋
                                    
                                 
                              
                           
                        where

                           
                              
                                 
                                    K
                                    =
                                    
                                       max
                                       
                                          i
                                          =
                                          1
                                       
                                       d
                                    
                                    
                                       (
                                       
                                          max
                                          
                                             s
                                             ∈
                                             S
                                          
                                       
                                       
                                          f
                                          i
                                       
                                       
                                          (
                                          s
                                          )
                                       
                                       )
                                    
                                 
                              
                           
                        is the maximum function value attainable among all objective functions.

We parameterize our algorithm by the desired approximation quality ɛ
                           grid
                         ≥ 0 of the archive with respect to the seen objective vectors. AGE is shown in Algorithm 6
                        , and it uses the helper functions given in Subroutines 7
                         and 8
                        . The latter is used to perform a relaxed dominance check on the offspring p in Line 13. A strict dominance check here would require an offspring to be not dominated by any point in the entire archive. However, as the archive approximates all the solutions seen so far (via the flooring), it might very unlikely, or even impossible, to find solutions that pass the strict dominance test.

The algorithm works at each time step t with an approximation 
                           
                              A
                              
                                 
                                    ɛ
                                 
                                 grid
                              
                              
                                 (
                                 t
                                 )
                              
                           
                         of the set of non-dominated points At
                         seen until time step t. Note, that setting ɛ
                           grid
                         = 0 implies the basic AGE approach that stores every non-dominated objective vector. We now investigate the effect of working with different archives sizes (determined by the choice of ɛ
                           grid
                        ) in AGE. Our goal is to understand the effect of the choice of this parameter on the actual archive size used during the run of the algorithm as well as on the approximation quality obtained by AGE.

Next, we outline the results of our experimental investigation of the influence of approximative archives on the runtime and the solution qualities. Note, that the computational complexity of AGE is linear in the number of objectives. The algorithm was implemented in the jMetal framework (Durillo, Nebro, and Alba, 2010) and is publicly available.
                           4
                        
                        
                           4
                           
                              http://cs.adelaide.edu.au/~optlog/research/age.php.
                        
                     

The parameter setup of AGE is as follows. We use polynomial mutation and the simulated binary crossover (Agrawal and Deb, 1994) in order to create new offspring. Both variation operators are widely used in MOO algorithms (Deb et al., 2002; Gong, Jiao, Du, and Bo, 2008; Zitzler et al., 2002) and they are transformations of bit-string operators to bounded real-valued domains. The distribution parameters associated with the operators are ηm
                         = 20.0 and ηc
                         = 20.0. The crossover operator is biased towards the creation of offspring that are close to the parents, and is applied with pc
                         = 0.9. The mutation operator has a special explorative effect for MOO problems, and is applied with pm
                         = 1/(number of variables).
                           5
                        
                        
                           5
                           Note that other setups can be used, including different recombination and exploration operators. However, this is beyond the scope of this article as we focus on the comparison of the algorithms.
                         Population size is set to μ = 100 and λ = 100, and each run uses 100,000 fitness evaluations. We assess the quality of the final population using the additive approximation measure (Bringmann et al., 2011). First, we draw one million points of the mathematically described true Pareto front uniformly at random. Then we compute the additive approximation that the final population achieved for this sample of the true Pareto front.

Exemplary, we show in Fig. 2
                         the results averaged over 100 independent runs for DTLZ 2 with d = 3. Note that the archive grows very quickly in the case of ɛ
                           grid
                         = 0, where every non-dominated point is stored. Without sacrificing solution quality, a speed-up by a factor of 7.8 is achieved with ɛ
                           grid
                         = 0.01. Additional speed-ups can be achieved, but it is then up to the decision maker to balance the computation speed and the solution quality. More results can be found in Wagner and Neumann (2013). For example, for DTLZ 4 with 20 objectives: “a speed-up by a factor of over 250 can be achieved, while achieving even better quality solutions as well.”

The choice of ɛ
                           grid
                         can have a significant impact on the final approximation, which is why we consider several values in the final experiments. In particular, with “coarser” archives, the number of points that represent a particular region decreases. Since the fast approximation-guided selection will at first consider only the single best approximating solution per cuboid, fewer points will actually represent that region. If the cuboids end up very large with the choice of a larger value of ɛ
                           grid
                        , then the remaining solutions of the population (that are not the best approximating ones) are not necessarily distributed in way that results in a good approximation.

The AGE algorithm consists of different components that make the approach successful. It heavily relies on the used archive which guides the search as it contains information collected during the run of the algorithm with respect to the true Pareto front. In this section, we would like to discuss them further in detail such that practitioners become aware of the different contributions.

The framework of AGE has two components that speed up the computation. The first one is the faster approximation calculation described in Section 4 which gives a runtime speed-up compared to the basic approach without any impairment in terms of quality, i.e., the same set of solutions is computed. This improvement in terms of running time should always be incorporated as it does not come with any disadvantage compared to the basic framework (as described in Section 3).

A further significant speed-up is obtained by working with an approximative archive as outlined in Section 6. Here, the parameter ɛ
                        grid
                      determines the size of the archive during the run of the algorithm. This component imposes a trade-off in running time and approximation behavior as an increasing value of ɛ
                        grid
                      leads to a speed-up of the approach at the expense of a worsening in the approximation. Setting the parameter ɛ
                        grid
                      is crucial for the success of the algorithm and a good choice is dependent on the given multi-objective problem. Our experimental studies on ɛ
                        grid
                      have shown that the value can be chosen to gain very significant speed-ups with almost no impairment in terms of quality. Setting ɛ
                        grid
                      too large in relation to the range of the objective values would imply that the archive only consists of a few points which implies that there is almost no guidance for the selection process of the algorithm.

While the faster approximation calculation and the approximative archive mainly aim for a speed up of the algorithm, the improved parent selection introduced in Section 5 aims for a better spread of the population in the objective space. As the runtime of AGE is mainly determined by the size of its archive different methods can be exploited without having a huge impact on the running time. Different parent selection methods have been examined in Wagner and Friedrich (2013) and the best performing one is integrated into the final AGE algorithm.

In this section, we compare AGE to well-known evolutionary multi-objective algorithms on commonly used benchmark functions. We first study low-dimensional problems and later pay special attention to problems with many dimensions. We judge the algorithms by the approximation quality and the hypervolume that they achieve. AGE is investigated for different values of ɛ in order to study the effect of working with an approximative archive on the quality of the results.

In our first study, we investigate the performance of AGE on problems with few objectives. We use the jMetal framework (Durillo et al., 2010) to compare AGE with the established algorithms IBEA (Zitzler and Künzli, 2004), NSGA-II (Deb et al., 2002), SMS-EMOA (Emmerich, Beume, and Naujoks, 2005), and SPEA2 (Zitzler et al., 2002) on the benchmark families WFG (Huband, Barone, While, and Hingston, 2005) and LZ (Li and Zhang, 2009), and DTLZ (Deb, Thiele, Laumanns, and Zitzler, 2005). For each of the problems, the objective values are within “roughly” the same ranges. When facing a problem with significantly differing ranges, we recommend (as we do for other algorithms) to rescale the objectives for the algorithms into comparable ranges, as mechanisms like hypervolume or density computations will not necessarily produce “evenly spread” outcomes as intended by the respective algorithms’ authors.

It is important to note that we limit the calculations of the algorithms to a maximum of 50,000/100,000/150,000 fitness evaluations for WFG/DTLZ/LZ and to a maximum computation time of 4 hours per run, as the runtime of some algorithms increases exponentially with respect to the size of the objective space. The further parameter setup of the algorithms is as follows. Parents are selected through a binary tournament. We will present our results for population sizes μ = 100 and λ = 100 and average the results over 100 independent runs. The AGE test setup has been outlined in Section 6.2.

We assess the algorithms by examining their final populations. To measure the quality of the final population, we consider the additive approximation and the hypervolume (Zitzler and Thiele, 1999). The latter is very popular in the performance assessment of evolutionary multi-objective algorithms and measures the volume of the dominated portion of the objective space relative to a reference point r. For the quality assessment on the WFG and LZ functions, we compute the achieved additive approximations and the hypervolumes with respect to the Pareto fronts given in the jMetal package. For the DTLZ functions, we compute the additive approximations as described in Section 6.2. For the hypervolume computations for DTLZ 1 we choose r = 0.5
                           d
                        , and r = 1
                           d
                         for all other benchmark problems. We approximate the achieved hypervolume with an FPRAS (Bringmann and Friedrich, 2010a), which has a relative error of not more than 2 percent with probability at 1/1000. The volumes shown for DTLZ 1 are normalized by the factor 2
                           d
                        . As it is very hard to determine the minimum approximation ratio achievable or the maximum hypervolume achievable for all populations of a fixed size μ, we only plot the theoretical maximum hypervolume for μ → ∞ as a reference.

@&#RESULTS@&#

The benchmarking results for the different algorithms are shown in Figs. 3
                               and 4 and are a clear evidence for AGE’s excellent performance. AGE ranks among the best algorithms on the low-dimensional WFG and LZ functions (see Fig. 3
                              ). This holds for the additive approximation quality as well as for the achieved hypervolumes. Interestingly, NSGA-II (
                                 
                              ), which normally performs rather well on such problems, is beaten in almost all cases. AGE performs very similarly for the different used approximative archive settings (ɛ
                                 grid
                               = 0: 
                                 
                              , ɛ
                                 grid
                               = 0.1: 
                                 
                              , ɛ
                                 grid
                               = 0.01: 
                                 
                              ). This confirms that working with an approximative archive usually leads to a significant speed-up without a detrimental effect on the solution quality.

Our investigations on the DTLZ family (see Fig. 4) prove to be more differentiating between the different type of algorithms. The DTLZ family can be scaled with the number of objectives and therefore enables us to investigate the impact for problems with more than two objectives. With an increasing number of objectives, the benefits and drawbacks of the algorithms’ underlying mechanisms become more apparent. We can summarize the experimental results in the following way.

                                 
                                    •
                                    AGE (ɛ
                                          grid
                                        = 0: 
                                          
                                       , ɛ
                                          grid
                                        = 0.1: 
                                          
                                       , ɛ
                                          grid
                                        = 0.01: 
                                          
                                       ) shows a very good performance on all DTLZ variants. It is either the best performing algorithm, or in many cases, it shows at least competitive performance.

It is interesting to see that even though AGE incorporates the crowding distance idea from NSGA-II (
                                          
                                       ) for a fitness assignment, it is not influenced by its detrimental effects in higher dimensional objective spaces. This is a consequence of how the next generation is formed (i.e., based on contribution to the approximation quality achieved with respect to the archive, see Line 16 of Algorithm 6).

Remarkably, NSGA-II (
                                          
                                       ), SMS-EMOA (
                                          
                                       ), and SPEA2 (
                                          
                                       ) are unable to find the front of the higher-dimensional DTLZ 1 and DTLZ 3 variants. This results in extremely large approximation values and zero hypervolume values. In particular, the mechanisms used by NSGA-II (
                                          
                                       ) and SPEA2 (
                                          
                                       ) are inadequate for higher-dimensional spaces, and both algorithms push their population too far out to the boundaries for high dimensions.

For higher dimensions (d ≥ 5) IBEA (
                                          
                                       ) is AGE’s strongest competitor. However, its performance is not consistent for all functions and its runtime does not scale well with increasing dimension. The same holds for SMS-EMOA (
                                          
                                       ), which uses an exponential-time algorithm to internally determine the hypervolume. It did not finish a single generation for d ≥ 8 and only performs around 5000 iterations within 4 hours for d = 5.

Encouraged by the good performance of AGE on lower-dimensional test problems, we also study high-dimensional problems with dimensions d > 10. It is known that the classical algorithms SPEA2 and NSGA-II deteriorate with an increasing number of objectives. Also for SMS-EMOA we observed runtime issues for higher-dimensional spaces. For a meaningful comparison we therefore neglect these algorithms for higher-dimensional test problems and instead compare AGE with two recent EMOA specifically designed for high-dimensional problems. In particular, we compare AGE with two hypervolume-based algorithms that use fast approximations of the hypervolume to guide their search, namely MO-CMA-ES (Igel et al., 2007) and SMS-EMOA (Emmerich et al., 2005), which are both implemented in the Shark Machine Learning Library (Igel, Glasmachers, and Heidrich-Meisner, 2008). Note that we again include IBEA in this final comparison due to its good performance on DTLZ 2 and 4 for lower number of objectives.

Among the studied test problems, only DTLZ (Deb et al., 2005) allows scaling to an arbitrary number of objective space dimensions. We therefore study DTLZ 1–4 for up to 20 dimensions. The test setup remains unchanged, with the difference that we limit the calculations of the algorithms to a maximum of 250,000 fitness evaluations and to a maximum computation time of 24 hours per run, due to the increased difficulty. As this is our final test, we also compared the algorithms using the Wilcoxon–Mann–Whitney two-sample rank-sum test. If we call a comparison “statistically significant”, it is significant at the 99 percent confidence level. The results are shown in Fig. 5
                         and summarized as follows.

                           
                              •
                              On all higher-dimensional (d ≥ 6) test problems, AGE achieves (statistically significantly) the best approximation. MO-CMA-ES (
                                    
                                 ) and SMS-EMOA (
                                    
                                 ) fail at achieving good approximations on DTLZ 1 and 3. On these, IBEA (
                                    
                                 ) performs relatively well, but we observed runtime issues for the twenty-dimensional spaces.

AGE achieves statistically significantly better approximations than IBEA on all functions. Compared to MO-CMA-ES (
                                    
                                 ), AGE achieves statistically significantly better approximations on DTLZ 1/3 (all dimensions), DTLZ 2 (d ≥ 6), DTLZ 4 (d ≥ 4). The best competitor in low dimensions (d ≤ 5) is SMS-EMOA. However, also in low dimensions AGE is either competitive or still better than the other algorithms.

The hypervolume-based algorithms, MO-CMA-ES (
                                    
                                 ), SMS-EMOA (
                                    
                                 ) and IBEA (
                                    
                                 ), sometimes achieve slightly larger hypervolumes for DTLZ 2 and DTLZ 4, but fail completely on DTLZ 1 and DTLZ 3. AGE achieves statistically significantly higher hypervolume than IBEA (
                                    
                                 )and MO-CMA-ES (
                                    
                                 ) on DTLZ 1 and DTLZ 3 for all dimensions. The same holds compared to SMS-EMOA (
                                    
                                 ) for d ≥ 6.

All aforementioned observations hold for all three variants of AGE. The performance of AGE is very similar for the different used approximative archive settings (ɛ
                                    grid
                                  = 0: 
                                    
                                 , ɛ
                                    grid
                                  = 0.1: 
                                    
                                 , ɛ
                                    grid
                                  = 0.01: 
                                    
                                 ). While the grid size has a significant impact on the runtime of AGE (cf. Section 6.2), it apparently has little impact on the approximation quality. Counting the number of test functions where the achieved approximation of one variant statistically significantly outperforms another variant, we can still derive a total ordering: ɛ
                                    grid
                                  = 0.01 performed 75 × better (48 × worse, 21 × insignificant) than ɛ
                                    grid
                                  = 0, which performed 72 × better (51 × worse, 21 × insignificant) than ɛ
                                    grid
                                  = 0.1.

In the following, we show and comment about the distribution of the obtained solutions, in variable and objective space.

First, we investigate the diversity in the variable space. For the DTLZ functions, the variables x
                        1, …, x
                        30 ∈ [0, 1] of these problems are divided in diversity related variables (x
                        1, ..., x
                        
                           m − 1), and convergence related variables (xm
                        , ..., x
                        30). In Figs. 6
                         and 7
                         we show the distributions of several such variables on four DTLZ functions are shown. The data is based on 100 independent runs, from which we take from the populations the means and standard deviations of different variables. We then show the respective means and standard deviations of that data.

For most problems we can see that a wide range of values for the diversity related variables is achieved and maintained (see Fig. 6). For example, the standard deviations of x
                        1 within the individual populations is high (given the valid range x
                        1 ∈ [0, 1]) and the means of the populations are stable across multiple runs. During the runs, diversity is achieved and maintained, which is expressed in stable statistics along the x-axis. Interestingly, the diversity in the search space appears to decrease with a growing number of objectives. In particular, the final diversity in the search space for DTLZ 4, d = 20 is extremely low when compared to the other problems. The reasons for this are not entirely clear, however, it appears that for this problem AGE’s “not-so-diverse” solutions sets can still achieve better approximations of the Pareto front than all other algorithms (see Figs. 4 and 5).

The analysis of the convergence related variables reveals an entirely different, but expected, behavior (see Fig. 7). The initial diversity of these variables collapses very quickly and continues to decrease as optimization progresses. This can be seen best in the standard deviations that continue to plummet. Amongst different runs, there is little variation, as the small standard deviation of the standard deviations reveals. This behavior is independent of the investigated DTLZ function and its number of objectives.

Next, since diversity in the variable space not necessarily implies diversity in the objective space, we show in Figs. 8
                         and 9
                         randomly picked final populations in the objective space.

The solutions for the two-objective problems are very uniformly distributed. Note that “uniformity” is with respect to the additive approximation used: for example in the case of DTLZ 2, d = 2 a single solution near the bottom right corner can additively approximate a larger part of the true Pareto front than a single solution near the center of the true Pareto front (near 〈0.71, 0.71〉). The same effect can be observed for ZDT 3 and WFG 8. Similarly, we can often observe quite uniform distributions of the solutions for the three-objective problems.

Lastly, as objective spaces with more than three dimensions are difficult to visualize, we show the final solutions in the objective space as parallel coordinate plots in Fig. 10
                         (the individual axes stand for the different objectives). These plots nicely augment many of the figures in this article. First, diverse sets of solutions are responsible for AGE’s indicator values shown in Figs. 4 and 5. Second, even though the final diversity in the search space is low at times (e.g., DTLZ 4, d = 20 in Fig. 6) diverse sets of objective vectors can be found by AGE, and these sets achieve better approximations of the Pareto fronts than the other investigated algorithms for many-objective optimization problems.

@&#CONCLUSIONS@&#

Evolutionary algorithms are frequently used to solve multi-objective optimization problems. Often, it is very hard to formally define the optimization goal that current state-of-the-art approaches work with. We have presented an evolutionary multi-objective algorithm that works with a formal notion of approximation. The framework of our algorithm allows to work with various formal notions of approximations. The basic framework of AGE works with an archive which stores every non-dominated objective vector and uses this archive to judge the quality of newly produced solutions. In order to increase performance of this basic variant, we introduced an approximative archive and a parent selection scheme which increases performance for low dimensional problems.

The experimental results show that AGE efficiently solves problems with few and with many conflicting objectives.
                        6
                     
                     
                        6
                        The source code is available under http://cs.adelaide.edu.au/~optlog/research/age.php.
                      Its computation time increases only linearly with the number of objectives. Given a fixed time budget, AGE outperforms current state-of-the-art approaches (including those using fast hypervolume-approximations) in terms of the desired additive approximation on standard benchmark functions for more than four objectives. On functions with two and three objectives, it lies level with the best approaches. Additionally, it also performs competitive or better regarding the covered hypervolume, depending on the function. This holds in particular for problems with many objectives, which most other algorithms have difficulties dealing with. The choice of the approximative archive (determined by the choice of ɛ) mainly determines the computational cost of the algorithm but has no major effect on the quality of the outcome for the investigated choices of ɛ. Thus we can observe runtime reductions by a factor of up to 250 without sacrificing the final solution quality.

In summary, AGE is an efficient approach to solve multi-objective problems with few and many objectives. It enables practitioners now to add objectives with only minor consequences, and to explore problems for even higher dimensions.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A comprehensive model of development on the balance-scale task

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We present a new model of children’s performance on the balance-scale task.


                        
                        
                           
                           Constructive neural networks implement an intuitive and a torque-rule module.


                        
                        
                           
                           A selection module decides whether to use the intuitive or torque-rule solution.


                        
                        
                           
                           The model covers all 4 stages seen in children, ending with a genuine torque rule.


                        
                        
                           
                           The model also covers perceptual effects, response times, and overlapping waves.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Cognitive development

Balance scale

Constructive neural networks

Knowledge-based learning

KBCC

SDCC

@&#ABSTRACT@&#


               
               
                  We present a new model of children’s performance on the balance-scale task, one of the most common benchmarks for computational modeling of psychological development. The model is based on intuitive and torque-rule modules, each implemented as a constructive neural network. While the intuitive module recruits non-linear sigmoid units as it learns to solve the task, the second module can additionally recruit a neurally-implemented torque rule, mimicking the explicit teaching of torque in secondary-school science classrooms. A third, selection module decides whether the intuitive module is likely to yield a correct response or whether the torque-rule module should be invoked on a given balance-scale problem. The model progresses through all four stages seen in children, ending with a genuine torque rule that can solve untrained problems that are only solvable by comparing torques. The model also simulates the torque-difference effect and the pattern of human response times, faster on simple problems than on conflict problems. The torque rule is more likely to be invoked on conflict problems than on simple problems and its emergence requires both explicit teaching and practice. Overlapping waves of rule-based stages are also covered by the model. Appendices report evidence that constructive neural networks can also acquire a genuine torque rule from examples alone and show that Latent Class Analysis often finds small, unreliable rule classes in both children and computational models. Consequently, caution in using Latent Class Analysis for rule diagnosis is suggested to avoid emphasis on rule classes that cannot be replicated.
               
            

@&#INTRODUCTION@&#

Ongoing debates between symbolic and neural-network models of cognition have often focused on development of children’s performance on balance-scale problems, one of the most simulated tasks in developmental psychology. The symbolic view is that knowledge is represented in propositional rules referring to aspects of the world, that processing occurs as rules are selected and fired, and that knowledge is acquired by learning such rules. In neural-network accounts, active knowledge is represented in rapidly changing neuronal-unit activations and long-term knowledge by excitatory and inhibitory synaptic connections between units, processing involves activation passing from one layer of units to another, and knowledge acquisition results from adjustment of connection weights and perhaps recruitment of new units into the network. The symbolic approach has been referred to as rule use, and the neural-network approach as rule following (Shultz & Takane, 2007).

Although this may seem to be a subtle distinction, there are important differences between the two viewpoints that have consistently guided research over the last few decades. The rule-use approach assumes that people have and use rules to guide their reasoning and behavior, affording the perfect generalization that symbolic rules may allow. Rule-use is consistent with the idea that human cognition is often quite regular. In contrast, the rule-following approach assumes that such regularities may be naturally approximated by neural networks that adapt to regularities in the environment. This affords more graded generalizations whose regularity approximates the extent to which the environment is consistently regular, with the possible advantage that both regularities and exceptions can be accommodated within the same neural network. In rule-use systems, exceptions are instead typically memorized, and represented separately from the rules themselves. Such differences are highlighted in precise computational models of psychological phenomena (Shultz, 2003).

The balance-scale task is interesting because it is representative of the many problems requiring integration of information across two separate quantitative dimensions and because it provides well-replicated results with an interesting stage progression.

Here we present a new computational model of balance-scale acquisition that addresses a recent criticism affecting many of the balance-scale computational models – ensuring that the final stage consists of a genuine, multiplicative torque rule and not a simpler rule based on addition (Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007). After describing the balance-scale task and phenomena, we present our new computational model.

The task presents several pegs positioned on a rigid beam at regular distances to the left and right of a fulcrum (Siegler, 1976). An experimenter places some identical weights on a peg on the left side and some number of identical weights on a peg on the right side of the beam. The participant is asked to predict which side of the scale will drop, or whether the scale will remain balanced, when the beam is released from its supports, usually a block placed under each end of the beam. Archimedes’ principle of the lever describes a rule that yields a correct answer to all such problems: multiply the weight and distance from the fulcrum on each side and predict that the side with the larger product (or torque) to drop.

A neural-network simulation using the cascade-correlation (CC) algorithm (Shultz, Mareschal, & Schmidt, 1994) captured the four stages seen in children (Siegler, 1976): (1) predicting the side with more weights to descend, (2) when the weights are equal on both sides, also predicting the side with greater distance to descend, (3) predicting correctly when weight and distance cues both forecast the same result and performing at chance when these cues conflict, and (4) being correct on at least 80% of balance-scale problems.

If performance at Stage 4 is diagnosed as being correct on 80% of balance-scale problems, some of which are difficult problems in which weight and distance cues conflict with each other, then at least some computational models, both symbolic (Schmidt & Ling, 1996) and connectionist cascade-correlation networks (Shultz et al., 1994) reach Stage 4. But if Stage 4 is defined by possession of a genuine multiplicative torque rule, as opposed to say an addition rule, the modeling challenge remains open. Because many conflict problems can be solved by just adding weight and distance, documentation of a torque rule must be supported by success on problems that cannot alternately be solved by an addition rule (Boom, Hoijtink, & Kunnen, 2001; Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007).

With five pegs and five weights, the problem size often used in simulations of the balance scale (Shultz et al., 1994), there are 625 total problems, of which only 200 are relatively difficult conflict problems in which weight and distance information, used alone, predict different outcomes. Only 52 of these conflict problems are torque problems that cannot be solved by mere addition; the other 148 are addition problems that can be solved by adding distance and weight on each side and comparing these sums.

An addition rule was routinely ignored in computational models of balance-scale development, whether symbolic (Schmidt & Ling, 1996) or connectionist (McClelland, 1989; Schapiro & McClelland, 2009; Shultz et al., 1994), just as it had been ignored in many older psychology experiments on the balance scale. But with evidence that at least some people use or follow a genuine torque rule, solving balance-scale problems that addition cannot solve (Boom, Hoijtink, & Kunnen, 2001; Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007), it becomes important to test computational models for their ability to acquire and use a genuine torque rule.

This problem of accurately diagnosing a terminal stage does not arise in the many other developmental domains where constructive neural networks have been successfully applied: conservation (Shultz, 1998, 2006), seriation (Mareschal & Shultz, 1999), transitivity (Shultz & Vogel, 2004), integration of cues for moving objects (Buckingham & Shultz, 2000), shift learning (Sirois & Shultz, 1998), deictic pronouns (Oshima-Takane, Takane, & Shultz, 1999; Shultz, Buckingham, & Oshima-Takane, 1994), word stress (Shultz & Gerken, 2005), syllable boundaries (Shultz & Bale, 2006), morpho-phonology (Shultz, Berthiaume, & Dandurand, 2010), habituation of infant attention to auditory (Shultz & Bale, 2001, 2006) and visual (Shultz, 2011; Shultz & Cohen, 2004) information, false-belief (Berthiaume, Onishi, & Shultz, 2008; Berthiaume, Shultz, & Onishi, 2013; Evans, Berthiaume, & Shultz, 2010), and concept acquisition (Baetu & Shultz, 2010; Shultz, Thivierge, & Laurin, 2008).

Our experience teaching university students about psychological development on the balance scale suggests that those few students who spontaneously use the torque rule to solve balance problems admit that they learned this method in science classes, either in secondary school or college. When the remaining students are informed that balance-scale problems can be solved by computing and comparing torques, they too begin to sometimes use this torque rule to produce more correct answers. Thus, it seems likely that most people learn a torque rule from explicit verbal instruction that includes relevant examples (Siegler, personal communication). In contrast, people are unlikely to learn a torque rule from examples alone because problems requiring the torque rule are so rare.

Here, we attempt to achieve a successful and psychologically more valid model of balance-scale development by capturing all four stages, including a genuine torque rule at stage 4, and perceptual, problem-type, and timing effects. The new model combines and extends our initial balance-scale simulation (Shultz et al., 1994) and more recent work with knowledge-based learning (Shultz, Rivest, Egri, Thivierge, & Dandurand, 2007).

We posit two different processing modules to solve the task, an intuitive module and a torque-rule module. The intuitive module is a connectionist network that implicitly learns environmental regularities about balance-scale problems. It predicts which side of a balance scale will tip down, without any need to invoke a symbolic rule. The learning process is essentially bottom-up and stimulus driven. In contrast, the torque-rule module simulates explicit learning via teaching a torque rule, as in secondary-school science classes. Such a rule can be described in natural language, and coded in an appropriate manner in memory. In our model, we implement this as a neural module with torque-rule functionality. A meta-cognitive, selection module decides whether to use the prediction of the intuitive model or, if it determines that this prediction might be wrong, invokes the torque module to obtain a more definitive answer. All three modules are implemented as neural networks.

A dual-processing approach (e.g., automatic vs. deliberate) is rooted in a long and currently active emphasis in cognitive psychology (Evans, 2010; Kahneman, 2011; Stanovich, 2012). Our results are discussed in that context.

@&#METHODS@&#

Our model contains three key modules: intuitive, torque-rule, and selection. The intuitive and the torque-rule modules can compute separate predictions about the state of the scale balance after the beam is released from its supports. By learning to predict the correctness of the intuitive module on various balance-scale problems, the selection module decides whether to use the prediction of the intuitive module or invoke the torque module instead.

All three modules are implemented using cascade correlation variants. More specifically, the intuitive and selection modules use sibling-descendant cascade correlation (SDCC) (Baluja & Fahlman, 1994), whereas the torque module employs knowledge-based cascade correlation (KBCC) (Shultz & Rivest, 2001). We first describe these variants, and then their use.

Cascade correlation (CC) is a neural network algorithm characterized by network expansion as needed to solve some problem. This automated growth solves the difficult problem of selecting an appropriate topology of hidden units (number of units and their connectivity).

CC learns by alternating between two phases: input phase and output phase (Fahlman & Lebiere, 1990). CC begins in output phase without any hidden units. In output phase, CC learns by adjusting connection weights entering output units using gradient descent on output error. The function to minimize during output phase is error (E) at the output units:
                           
                              (1)
                              
                                 E
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          o
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          p
                                       
                                    
                                 
                                 
                                    
                                       (
                                       
                                          
                                             A
                                          
                                          
                                             op
                                          
                                       
                                       -
                                       
                                          
                                             T
                                          
                                          
                                             op
                                          
                                       
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        where A is actual output activation and T is target output activation for unit o and training pattern p. Error minimization is accomplished with the Quickprop algorithm (Fahlman, 1988), a fast variant of the generalized delta rule that uses both curvature and slope of the error surface to compute weight changes. Weight change varies in direct proportion to slope and inverse proportion to curvature.

If the current topology does not allow a sufficient error reduction, CC shifts to an input phase at the end of which a new hidden unit is recruited from a pool of candidate units. In input phases, connection weights between inputs and these candidate hidden units are trained in order to maximize the covariance (C) between unit activation and residual network error.
                           
                              (2)
                              
                                 C
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             o
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      p
                                                   
                                                
                                                (
                                                
                                                   
                                                      h
                                                   
                                                   
                                                      p
                                                   
                                                
                                                -
                                                〈
                                                h
                                                〉
                                                )
                                                (
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      op
                                                   
                                                
                                                -
                                                〈
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      o
                                                   
                                                
                                                〉
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             o
                                          
                                       
                                       
                                          
                                             ∑
                                          
                                          
                                             p
                                          
                                       
                                       
                                          
                                             (
                                             
                                                
                                                   e
                                                
                                                
                                                   op
                                                
                                             
                                             -
                                             〈
                                             
                                                
                                                   e
                                                
                                                
                                                   o
                                                
                                             
                                             〉
                                             )
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where hp
                         is activation of the candidate hidden unit for training pattern p, 〈h〉 is mean activation of the candidate hidden unit for all training patterns, eop
                         is residual error at output o for training pattern p, and 〈eo
                        〉 is mean residual error at output o across all training patterns.

At the end of an input phase, the candidate unit with the highest absolute covariance C is selected and installed into the network with frozen input weights and random output weights with sign opposite to the covariance, the other candidates are discarded, and there is a shift back to output phase. The algorithm shifts from one phase to the other when the current phase fails to improve the solution of the problem on which the network is being trained, by not reducing error or failing to improve covariances, for output- or input-phase, respectively. Alternation between phases continues until network error is sufficiently low, the problem is mastered, or a maximal network size is reached, the size of the network increasing by one hidden unit at the end of each input phase.

Two important innovations characterize variants of this algorithm: (1) where to install newly recruited hidden units in the existing network, and (2) complexity of the computation that these recruits perform.

Regarding installation location for hidden units, solutions vary from flat topologies in which all units are installed on a single hidden layer (Sjogaard, 1992) to deep topologies in which all recruited units are cascaded on new, progressively deeper layers (Fahlman & Lebiere, 1990). In our present model, we use a compromise approach called sibling-descendant cascade-correlation (SDCC) (Baluja & Fahlman, 1994) which flexibly installs a new recruit on the current deepest layer, or on a new, deeper hidden layer. Apart from network depth and number of connection weights (Shultz, 2006), choice of installation strategy has little impact on functionality. A systematic study of the effect of cascading weights and network depth shows that flat and deep variants generalize equally well (Dandurand, Berthiaume, & Shultz, 2007).

Regarding the kind of computations that hidden units perform, ordinary hidden units use a sigmoidal activation function (Fahlman & Lebiere, 1990) to compute output values given the weighted sum of input values to the unit. Knowledge-based cascade correlation (KBCC) generalizes the concept of recruits to any differentiable function, including previously-learned CC or SDCC networks (Shultz & Rivest, 2001) or human-designed networks or units that may have some symbolic-like functionality (Shultz et al., 2007). The computational device that gets recruited is the one whose output covaries best with residual network error. KBCC often speeds learning (Shultz & Rivest, 2001) and sometimes makes learning possible (Egri & Shultz, 2006), by capitalizing on existing knowledge.

A simple example of a KBCC network is shown in Fig. 1
                        , illustrating that a recruited source network or function can have multiple inputs and outputs, thus requiring connection-weight matrices rather than vectors. Mathematical details about KBCC are available elsewhere (Shultz & Rivest, 2001; Shultz, Rivest, Egri, Thivierge, & Dandurand, 2007).

As in our initial CC simulation of the balance scale task (Shultz et al., 1994), the intuitive module learns to predict balance-scale results from learning with examples only, and is implemented here as an SDCC network. The recruitment pool contains eight sibling and eight descendant units that each use a sigmoidal activation function whose outputs range from −0.5 to 0.5. The intuitive module receives four inputs representing distance and weight on the right and distance and weight on the left of the fulcrum. There are two outputs, whose target patterns are coded as follows: +0.5 +0.5 for balance, +0.5 −0.5 for left heavier, and −0.5 +0.5 for right heavier. This improved choice of coding values for the balance scale uses target values in the stable, saturated regions of the activation function, yielding somewhat faster learning. In the original CC simulation (Shultz et al., 1994), the target values for a balanced outcome were 0 0, which reside in the steep, transitional range of the activation function.

Training begins with 100 initial patterns, randomly selected from the 625 possible balance-scale problems allowed by five weights and five distances from the fulcrum. In the problem-selection process, there is a .9 bias toward equal-distance problems (in which the weights are placed equally distant from the fulcrum). This is to encourage early use of the weight rule (the side with more weights should descend) under the assumption that children have rather few experiences with physical devices that systematically vary distance from a fulcrum (McClelland, 1989). One new pattern is added in each output epoch, under this same .9 bias. In an epoch, each of the training patterns is encountered once. Because items are selected with replacement, random selection of duplicate patterns is permitted.

Exploratory simulations indicate that most of these networks are well into stage 3 by about 350 epochs (see confirming evidence in Results section). Thus, when a network reaches 350 epochs, we allow it to complete the current output phase, and then stop training. Thus, training stops after a relatively fixed period regardless of the level of error that is reached. All other parameters are the default values in CC.

After the intuitive module is trained, our simulation proceeds to training the torque-rule module. This involves a fresh KBCC network and training data that include the intuitive training set (at the end of training) plus a possible infusion of torque problems (see practice factor below). We manipulate two variables, in a two-way, independent-factors design. First, a teaching factor represents whether or not the torque rule is injected into the KBCC candidate pool (see details below). Second, a practice factor represents whether or not the intuitive training set is expanded with a randomly selected 26 of the 52 possible torque problems. The other 26 torque problems are reserved for testing generalization. This design allows systematic study the effect of teaching the torque rule and giving additional practice with torque problems, mimicking what transpires when torque is covered in secondary-school science classes.

The torque module uses KBCC. In the recruitment pool, eight sibling sigmoid and eight descendant sigmoid units are provided, and in addition eight sibling torque rules and eight descendant torque rules for the teaching conditions. The torque-rule network has the same inputs and outputs as the intuitive network.

To allow networks sufficient opportunity to fully exploit the error reduction possible with a complex unit like the torque rule, we allowed input and output phases to be longer by setting the patience parameter to 100 epochs, and the change threshold to 0.001. Training begins in input phase rather than the usual output phase, and ends when a standard score-threshold criterion of .4 on network error is met. Other simulation parameter settings are the same as for the intuitive network.

To simulate the teaching of a torque rule, we introduce into the recruitment pool a unit (hereafter referred to as the torque rule) which executes the following function on its four inputs:
                           
                              (3)
                              
                                 TR
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       1
                                       +
                                       
                                          
                                             e
                                          
                                          
                                             -
                                             4
                                             TD
                                          
                                       
                                    
                                 
                                 -
                                 0.5
                              
                           
                        
                        
                           
                              (4)
                              
                                 where
                                 
                                 TD
                                 =
                                 (
                                 
                                    w
                                    r
                                 
                                 
                                    d
                                    r
                                 
                                 )
                                 -
                                 (
                                 
                                    w
                                    l
                                 
                                 
                                    d
                                    l
                                 
                                 )
                              
                           
                        Here, TR is the torque rule, and TD is torque-difference, computed as the difference between the torque on the right side and the left side of the fulcrum. On each side of the fulcrum, torque is computed as the product of weight (w) and distance (d). TD is then passed through a sigmoid squashing function to obtain TR, as shown in Fig. 2
                         for points corresponding to discrete values of weight and distance. TR is also a differentiable function, which KBCC requires of potential recruits. The exponent of 4 increases the steepness of TR, emphasizing the binary judgments that humans are asked to make on this task, but results with the default exponent value of 1 were essentially the same as those we report here with an exponent of 4.

The selection module learns to predict the accuracy of the intuitive network and then decides, for each balance-scale problem, whether to use the intuitive response or invoke the torque-rule module. The selection module can thus be interpreted as a meta-cognitive system that monitors correctness of the intuitive module and decides whether to activate the torque-rule.

Implemented as an SDCC network, the selection module receives seven inputs. In addition to the usual four inputs describing a balance-scale problem, these include a torque-difference measure (the absolute value of Eq. (4)) and two binary inputs indicating symmetry of weights and symmetry of distances (1 if symmetrical, 0 otherwise). These additional inputs, which presumably can be easily extracted perceptually by humans, provide useful information in this rapid, heuristic estimation task. The training set consists of the balance scale problems that were presented to the intuitive network. The output target is the correctness value of the intuitive network on these problems (correct=1, error=0). An asigmoid output unit is used, ranging between 0 and 1. Parameter settings are all default values.

After the selection module is trained, the system’s prediction is generated according to a simple rule: if the intuitive module is expected to give a correct answer, then output the value it predicts, otherwise compute and output the prediction of the torque module.

We test the model with both of the leading methods for assessing rule-based stages in children: Siegler’s Rule-Assessment Method (RAM) and Latent Class Analysis (LCA) each of which uses patterns of responses across different problems to diagnose stages. We use appropriately distinct test sets for RAM and LCA, but the RAM method is supplemented by two additional test sets to distinguish between Addition and Torque rules. Each of these four test sets is described in turn.

To remain consistent with earlier RAM research, this test set contains 24 balance-scale patterns selected as in our original simulation (Shultz et al., 1994), inspired by Siegler’s (1976) test set but additionally balanced for torque-difference effects. It contains four randomly-selected problems of each of Siegler’s six types: balance, weight, distance, conflict-balance, conflict-weight, and conflict-distance problems. Except for balance and conflict-balance problem types that always have a torque difference of 0, other types of problems are represented at four different levels of torque difference: 1, 3–5, 6–9, or 10–19. This is an improvement over studies that ignore torque differences and thus risk confounding problem type with torque difference and studies that use only small torque differences and thus risk underestimating torque-difference effects.

This test set is used to diagnose stages 0–4 according to Siegler’s (1976) criteria, with the proviso that Stage 2 is given diagnostic priority over Stage 3 (Shultz et al., 1994). Rule diagnosis is conducted by software: diagnosis of Stage 4 requires 20 of 24 problems correct; diagnosis of stage 2 requires at least 13 correct on the 16 balance, weight, distance, and conflict-weight problems and less than 3 correct on the 8 conflict-distance and conflict-balance problems; stage 3 requires at least 10 correct on the 12 balance, weight, and distance problems and fewer than 10 correct on the 12 conflict problems; stage 1 requires at least 10 correct on the 12 balance, weight, and conflict-weight problems and fewer than 3 correct on the 12 distance, conflict-distance, and conflict-balance problems. Stage 2 is given scoring priority over Stage 3 because the criteria for Stage 2 are more specific, particularly on how to score conflict-weight problems.

The addition test set helps to distinguish a genuine torque rule from a mere addition rule. It contains all 148 addition problems (among all conflict problems), a few of which may be included in the training set when expanding by one pattern per epoch. Typically, no more than one or two such patterns get included in the training set.

The torque test set contains the 26 torque problems not randomly selected to expand the training set in torque-rule training. Recall that among all conflict problems, there are 52 torque problems, half of which are used in training. There is a small probability that these problems are selected when expanding the train set by one pattern per epoch, but in practice no more than a single pattern is included in this way. If a network performs well on torque problems, then it is diagnosed as following a genuine torque rule as opposed to solving balance-scale problems with the often successful addition rule.

This test set consists of six balance-scale problems selected from those used by Boom et al. (2001) with children. They had used 25 test problems, balanced for torque difference and documented four latent classes with strong similarity to weight, weight and distance, addition, and torque rules found in previous balance-scale studies. The weight-and-distance rule continues to use weight but uses distance when the weights are equal on both sides of the scale. LCA takes the frequencies of each possible response profile and searches for a small number of latent classes that can summarize the distribution of these profiles. Coding each response as wrong or correct, there are 2
                              n
                            possible response profiles, where n is the number of problems. With 25 test problems, this generates 33,554,432 response profiles, which we consider to be far more than necessary.

To simplify, and thus reduce the number of empty cells which can pose problems for LCA (see Appendix C), we select the six problems described in Table 1
                           , chosen because they allow for a unique response profile for each of the four anticipated rules: weight, weight and distance, addition, and torque. In Siegler’s (1976) terminology, 2 of these are distance (D) problems, 2 are conflict-weight (CW) problems, and 2 are conflict-distance (CD) problems. Torque differences are nearly equated across these three problem types. Specific rule predictions are provided in the last four columns of Table 1.

We also test for growth spurts in the acquisition curves with Automatic Maxima Detection (AMD). Such spurts often signal the transition between successive stages, which can be indicated by plateaus. AMD uses functional data analysis to distinguish statistically significant spurts from continuous development and mere noise (Dandurand & Shultz, 2010).

@&#RESULTS@&#

For the RAM analysis, we run 20 models, with each model containing distinct, randomly-selected, training sets and instances of the three modules just described.


                        Fig. 3
                         presents mean stage classification on the RAM test set for 20 intuitive networks over training epochs. Performance at stage 1 is evident around epochs 30–40, stage 2 at epochs 100–150, and stage 3 at epochs 200–350. Epoch 50 marks the transition between stages 1 and 2, and epoch 150 marks the transition from stage 2 to 3. Thus, these networks capture the first three balance-scale stages seen in children from about five years of age up through early adolescence.

We use AMD to determine if stage transitions are characterized by significant spurts in stage progression. Results, shown in Fig. 4
                        , show that the transition between stages 2 and 3 is characterized by a significant, p
                        <.05, performance spurt with maximal velocity at epoch 177. AMD identifies spurt locations by local maximal velocity (first derivative), decreasing acceleration (second derivative), and negative jerk (third derivative) (Dandurand & Shultz, 2010). The lambda parameter in AMD controls the amount of smoothing that is applied. We use a lambda of 108.

The present result is consistent with visual inspection of Fig. 3 where the clearest plateaus occur at stages 2 and 3, with a marked increase in performance between these two plateaus. In contrast, progression from stages 0 to 2, although bumpy, proceeds in a more gradual and steady fashion. Using different methodology, a back-propagation neural-network model was also shown to progress from stage 1 to 2 of the balance scale in a continuous fashion (Schapiro & McClelland, 2009). That model has not been shown to reach stage 4 by any measure.


                        Fig. 5
                         shows accuracy, in terms of mean proportion correct, in 20 intuitive networks on each of the three test sets over epochs. This confirms that intuitive networks learn to perform well on the RAM and addition test sets, but not on the torque test set. Model accuracy is consistently higher on the addition test set than on the torque set. In addition, around epochs 150–200, there is a rapid increase in accuracy on addition problems combined with a decrease of accuracy on torque problems. This supports the hypothesis that networks develop an addition strategy, and that addition characterizes stage-3 performance as argued by a number of researchers (Boom, Hoijtink, & Kunnen, 2001; Ferretti, Butterfield, Cahn, & Kerkman, 1985; Jansen & van der Maas, 1997, 2002; Normandeau, Larivee, Roulin, & Longeot, 1989; Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007).

We next investigate accuracy as a function of torque difference. Fig. 6
                         shows that the current model successfully replicates the torque-difference effect previously found (Shultz et al., 1994) over the 4 torque levels (where level 4=high, 1=low). This describes a perceptual effect, also observed in children (Ferretti & Butterfield, 1986; Ferretti, Butterfield, Cahn, & Kerkman, 1985), characterized by higher accuracy on problems with larger torque difference.


                        Fig. 7
                         shows accuracy of the torque module on balance-scale problems as a function of training. The four conditions correspond to the 2×2 independent-factors design: (1) teaching indicates whether the torque rule is available as prior knowledge for recruitment (2 levels: present or absent) and (2) practice indicates whether the training set is expanded with half of the torque problems to give additional, torque-problem-specific practice (2 levels: expanded or not). Both teaching and practice are necessary for achieving high performance (about 0.9 accuracy) on torque problems. We also see that the combination of teaching and practice results in a higher accuracy on all three data sets.

In conditions that include injection of the torque rule, networks recruit between 1.9 and 2.1 torque rules, but no sigmoid unit. In contrast, for conditions in which the torque rule is not available, between 3 and 7 sigmoid units are recruited.

The selection networks train for a mean of 443 epochs (SE
                           =33) and recruit 1.3 (SE
                           =0.1) hidden units on average. Fig. 8
                            presents mean global accuracies of the model on the three test sets, comparing the intuitive module alone with the combination of intuitive and torque answers as selected by the selection module and with an idealized symbolic torque rule. Although intuitive networks perform well on the RAM and addition test sets, they do badly on torque problems. In contrast, the combination strategy yields good performance on all three of these test sets, qualifying as stage 4 performance as described by Siegler (1976), requiring a success rate of at least .8. This result is robust whether we consider the connectionist or the symbolic torque rule module implementation.

The mean proportions of problems solved by the intuitive network under combination conditions are .75 (SE
                           =0.01), .64 (SE
                           =0.01), and .25 (SE
                           =0.03) on the RAM, addition, and torque test sets, respectively. That is, torque problems are less likely than other problems to be solved intuitively. We further investigate which problems get solved by the intuitive network and by the torque network. As noted in Fig. 9
                           , simple problems (balance, distance and weight) tend to be solved more often using the intuitive network module, while conflict problems tend to be solved using the torque network module.

We can make some predictions on response times of children as they solve the six kinds of problems in the RAM test set. When predicting balance-scale outcomes, we assume that the intuitive module is used first to generate a relatively quick intuitive assessment. Then this assessment is checked for probable accuracy by the selection module. If the intuitive assessment is deemed accurate by the selection module, then the intuitive response is provided and there is no need to invoke the torque-rule module. However, if the intuitive prediction is judged by the selection module to be possibly inaccurate, then the torque-rule is invoked to produce a more accurate response. Because the torque-rule module is only invoked after the intuitive and selection modules, a torque-rule response takes longer than an intuitive response. A conservative assumption is that the torque-rule module would take at least as long to process as the intuitive module. Because of the explicit computation and comparison of torques, the torque-rule could well take even longer than the intuitive module, but we can stick with this more conservative equality assumption. Thus, assuming that a torque-rule solution takes twice as long as an intuitive solution, we can predict, based on the proportions of problems solved intuitively presented in Fig. 9, that processing times for the often more difficult conflict problems are considerably longer than for the simpler, non-conflict problems, as plotted in Fig. 10
                           , computed after training is complete. This prediction fits well with human response times re-plotted in Fig. 11
                           .

To accommodate the large Ns required for valid LCA, we run 1500 fresh models, 375 at each of four ages, represented by training up to 50, 150, and 300 epochs in the intuitive module and at the end of training for the torque-rule module. We save test results for LCA test problems A-F. Frequencies of the 64 response profiles are subjected to exploratory LCA with the LEM program (Vermunt, 1997), using default settings throughout. Model fit is evaluated with the widely recommended BIC method, which combines model fit with penalization for number of parameters, such that the smallest BIC value indicates the preferred model (Nylund et al., 2007; Schwartz, 1978). We test models ranging from 2 to 5 classes, obtaining BIC values of 7767, 7331, 7299, and 7329, respectively. The best model with the smallest BIC statistic (7299) is the one with 4 classes. Numbers of parameters in these four models are 14, 21, 28, and 35, respectively.

Because conditional probabilities across wrong and correct answers for each problem always sum to 1, we can summarize these parameters in a plot of estimated probabilities of correct responses only (Fig. 12
                           ). This shows that each of the four identified latent classes corresponds to one of the four rules found in children by Boom et al. (2001) and replicated in other studies: weight, weight-and-distance, addition, and torque. (See Appendix C for a review of this literature.) The patterns of correctness correspond well with the rule predictions provided in Table 2
                           . The weight rule is correct on problems C and D, and wrong on problems A, B, E, and F. The weight-and-distance rule is more correct on problems A–D than on problems E and F. The addition rule is correct on problems A, B, D, and F and wrong on problems C and E. And finally, the torque rule is correct on all problems A–F.

Progression of these rules through age-related stages can be examined in several ways. The conventional method in LCA studies of development is to plot the frequencies of the discovered latent classes at each age-level sampled. Such a plot in Fig. 13
                            of the proportion frequencies of rules at each age level reveals that the weight rule peaks at the first age level and then diminishes as other rules emerge. The weight-and-distance rule emerges next and peaks at the second age level. Then the addition rule emerges and peaks at the third age level. The final age level is dominated by the torque rule. Interestingly, this pattern shows that our network model also captures the overlapping waves phenomenon found in children with both RAM (Siegler, 1996) and LCA (Boom & ter Laak, 2007) techniques.

A second way to assess rule progression is to plot the mean age per rule, as in Fig. 14
                           . This again shows a clear age progression from weight to weight-and-distance to addition to torque rules. Because of overlapping rules, these means do not hit the center of each age exactly, but they do come close. Pointedly, the weight rule rounds to age-level 1, the weight-and-distance rule to age-level 2, the addition rule to age-level 3, and the torque rule to age-level 4. Inclusion of SD bars in Fig. 14 again confirms that our model captures the overlapping waves phenomenon found in children with both RAM and LCA methods. The standard deviations of adjacent rules overlap with each other, at least until the final torque rule at the fourth age level where there is very little variation.

A third way to assess rule progressions with age is with chi-square analyses of the raw frequencies of the four rules at each age level, presented in Table 3
                           . The overall chi-square value, 1690, df
                           =9, is hugely significant, as is each of the 3-df chi-squares comparing each of the three pairs of adjacent columns in Table 3, p
                           <.0001. Again, there is a clear progression across age levels for these four rules.

@&#DISCUSSION@&#

Our new model of development of balance-scale knowledge progresses through all four balance-scale stages, including a third stage in which weight and distance information are added and a fourth stage in which these two sources of information are multiplied as in a genuine torque rule. Stage progressions are confirmed by both of the leading rule-diagnosis methods: RAM and LCA. Coverage of a genuine torque rule contradicts previous doubts about the inability of constructive neural networks to achieve that level of performance (Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007). A torque rule can be considered genuine if it generalizes well to problems that cannot be solved by a simpler rule that merely adds, rather than multiplies, weight and distance information. Our networks generalize correctly to such untrained torque problems with about 90% success. This is not perfectly correct performance, but then neither is that of human participants on these tasks. Our model also captures the overlapping waves phenomenon found in children with both RAM and LCA methods.

This model incorporates three constructive neural networks. It captures the first three balance-scale stages with an intuitive network that learns only from examples. Then a knowledge-based network with an injected torque rule in the source-knowledge pool and additional torque training builds on this early intuitive training by recruiting this taught torque rule and learning how to use it. This model is the only neural-network system to so far demonstrate progression through all four balance-scale stages finishing with a genuine torque rule.

Using automatic maxima detection (AMD), we find that the transition from stage 2 to 3 in the intuitive networks is the only significant spurt; earlier transitions are instead continuous. A symbolic rule-based model also ends with a genuine torque rule (van Rijn, van Someren, & van der Maas, 2003), but the ordering of stages 1 and 2 and the late appearance of addition and torque rules in that model were engineered by parameter settings; they were not an emergent result of learning and development as in our model.

Operation of our intuitive network covers the torque-difference effect by showing better accuracy on problems with high absolute torque difference from one side of the scale to the other. This simulates psychological evidence (Ferretti & Butterfield, 1986; Ferretti, Butterfield, Cahn, & Kerkman, 1985) and replicates our initial simulation (Shultz et al., 1994). The symbolic rule-based model showed a torque-difference effect only with respect to differences in distance but not weight and only in the vicinity of stage transitions (van Rijn, van Someren, & van der Maas, 2003), not throughout development as children apparently do.

Just as with secondary-school science students, a lesson on torque does not guarantee a torque solution. The taught torque rule must be practiced, stored, and recruited, and even then it is not required to solve simple balance-scale problems that can be solved intuitively. In our model, a selection network learns to predict whether the intuitive network is likely to be correct on any given balance-scale problem. If the tipping prediction is doubtful, the torque-rule network is invoked for a more accurate answer.

Our model predicts an interesting speed-accuracy trade-off. While the torque module is more accurate, it presumably takes longer to process. In contrast, the less accurate intuitive module is presumably grounded in automatic, unconscious processing for which answers emerge more quickly. For an intuitive processing module based on a rough estimate of torque extracted by the visual system, the greater the distance and or weight difference across the fulcrum, the more obvious the answer, accounting for the torque-difference effect. In contrast, the torque-rule solution is more deliberate and explicit, and takes longer because it is executed only if the intuitive module fails to produce a confident conclusion. Our model predicts distinct patterns of accuracy on different kinds of problems depending on which module is used to generate the answer. They could be further tested experimentally by explicitly manipulating the speed-accuracy trade-off, for instance, by forcing participants to answer quickly, and thus eliciting intuitive answers to complex problems.

Results presented in Appendix A confirm our earlier conjecture (Shultz & Takane, 2007) that even SDCC networks learning solely from examples can acquire a genuine torque rule, if enough of those examples can only be solved by comparing torques. The training patterns there contain equal numbers of addition and torque problems. RAM results show that these networks learn an addition rule early and a torque rule later on, a natural progression for networks that sum their inputs and recruit nonlinear hidden units as required. LCA results in Appendix B confirm this rule progression.

This again contradicts claims that constructive neural networks cannot cover a genuine torque rule (Quinlan et al., 2007). However, because those SDCC networks do not progress through the first two stages of balance-scale performance seen in children (using weight and weight and distance), they do not comprise our favored comprehensive balance-scale model. Progression through these first two stages requires a training set with a strong bias in favor of equal-distance problems in which there are the same numbers of weights placed equally distant from the fulcrum. This bias, coupled with the inherent rarity of torque problems, fails to provide sufficient experience to build a torque rule.

Insufficient practice with torque problems also explains why ordinary folks, unlike Archimedes, do not discover a torque rule on their own. Shepard (2008) provides a clever thought experiment on how Archimedes might have discovered the nature of torque from reasoning alone (c. 280 BC). Most of us would be unable to come up with this thought experiment spontaneously, and instead would need to be taught how torque works and then get some practice applying it. Our favored model of the balance scale works in that same fashion. Our experiments confirm that a combination of teaching (implemented by an injected torque rule) and practice is required for torque-like performance, after progressing through earlier stages of weight, weight-and-distance, and addition.

Our model correctly predicts that the torque-rule module is more likely to be invoked on the relatively difficult conflict problems than on simple problems that present no conflict between weight and distance information. On the simple assumption that the torque-rule module is only invoked after the intuitive and selection modules, the model also covers psychological evidence that response time is slower on conflict than simple problems (van der Maas & Jansen, 2003). The more effortful, deliberative process is not invoked until it is needed, i.e., when the intuitive solution is expected to be incorrect.

On this same basis, our model also predicts, so far uniquely, that response times would increase on problems with small absolute torque differences between the sides of the scale. This again is because the torque-rule module tends to be used more often when torque differences are small. In fact, for all the non-balanced problems in the RAM test set (weight, distance, conflict-weight, and conflict-distance problems), we find a positive point-biserial correlation between absolute torque difference and reliance on the intuitive network, r(318)=.47, p
                        <.001. This correlation is even larger when only non-balanced conflict problems (conflict-weight and conflict-distance problems) are included, r(158)=.73, p
                        <.001. On the well-supported assumption that intuitive solutions are faster than deliberative solutions, these correlations represent a relation between reaction time and torque difference – faster response to problems with a larger absolute torque difference. In humans, this prediction could be tested by computing the same correlations. If the prediction is confirmed in humans, it could be interpreted as relatively quick solutions to problems with large torque differences, on which it is easy to gain an intuitive impression of what transpires when the beam’s supports are removed, and longer response times to problems with such small torque differences that the torque rule is invoked.

Rule diagnosis with LCA finds substantial overlap of balance-scale rules across ages in our model. Such overlapping waves have been noted in several developmental domains, including the balance scale (Siegler, 1996). Despite this LCA evidence for the near disappearance of non-torque rules in the final age, we know that the three rules do not disappear in our model. As noted, the intuitive module, which contains the weight, weight-and-distance, and addition rules, is almost always invoked for simple problems and for many of the conflict problems which permit a relatively clear solution by intuitive means. In this respect, the LCA method is somewhat misleading in suggesting torque-rule dominance at the oldest age. This is due to exclusive reliance on correctness of responses and the use of torque problems in the test set. The mature version of our model invokes the torque rule on torque problems but uses intuitive rules on simpler problems. We know this because of our evidence on which module is used to make a response. There are no current rule-diagnosis methods capable of documenting such flexible choice of rules. This result with our model should serve as a caution that the same diagnostic limitations probably apply to psychological research.

This range of coverage and predictions of balance-scale phenomena is unprecedented in the computational modeling literature, and it is particularly noteworthy in a neural model where phenomena emerge naturally from underlying principles rather than being built in by a human programmer. Even the networks themselves are automatically constructed by the algorithm, although the assembly of the three network modules is currently designed.

The other principal criticism of our earlier balance-scale model (Shultz et al., 1994) was that it did not capture some small rule classes found in children (Quinlan et al., 2007). Our Appendix C, with an identified LCA model, confirms our previous conclusion with an unidentified model (Shultz & Takane, 2007) that LCA finds small and unreliable rule classes. Appendix C more precisely pinpoints and quantifies the extent of this problem, finding that the standard deviations of conditional probabilities are 65–70 times greater for the small, random classes than for the large, systematic classes. With such extraordinary variation, it is unsurprising to also find that the patterns of these small, random classes do not replicate across different LCA replications. When patterns across test items do not replicate, neither does their interpretation. Appendix C indicates that both class smallness and randomness contribute to increasing this variance, with smallness being more important than randomness.


                        Appendix C also reviews evidence that the only replicated balance-scale rules in neural-network simulations with cascade-correlation algorithms are precisely the same as those that replicate in children, namely weight, weight-and-distance, addition, and torque.

In addition to large replicable classes, LCA regularly finds some small random classes that do not replicate across studies. This tendency has been robust against variation in LCA software (Latent Gold, LEM, MATLAB, PANMARK), laboratory (Amsterdam, McGill, Utrecht, York), affinity for LCA (both advocates and skeptics), number of test items (a few vs. many), presence vs. absence of random input patterns, nature of subjects (both people and artificial networks), stopping criteria (AIC and BIC), and other details of LCA applications. Our evidence underscores the ability of constructive neural networks to cover all and only the documented and replicated four stages of balance-scale development (weight, weight-and-distance, addition, and torque). The reason that our model does not cover the small, random difficult-to-interpret classes found in Quinlan et al. (2007) is that such classes do not replicate across LCA applications to either children or computational models.

This is not a criticism of LCA as a whole but is just the identification of a current limitation of LCA. Acknowledging a limitation is an important first step in devising improvements that overcome the limitation. Then, as improvements are invented and tried, any continuing existence of unreliable classes can serve as a signal that the limitation is still present. In the meantime, we recommend that LCA be used with caution, both in psychology and in evaluating computational models. Just as non-replicable findings should be ignored in science, so should non-replicable classes be ignored in applications of LCA. In particular, computational models should not be discredited for failing to generate results that LCA does not replicate. Ability to replicate is one of the strongest principles in science, and it should be consistently applied.

The inherent ability of KBCC to incorporate differentiable functions into its source knowledge pool is a novel and promising way to integrate neural-network and symbolic approaches to cognitive modeling. Our use of a selection network indicates that neural networks also may be able to simulate aspects of meta-cognition or reflection. More generally, dual-process theories may also benefit from considering a selection module that adjudicates when a deliberative module is activated and whether it overrules an intuitive module.

Although we implemented a torque rule in thoroughly neural fashion, there is currently no conclusive evidence for how torque processing is done in people. We show that our overall model can accommodate other implementations of a torque module that provide good performance on torque problems, as evidenced by the robustness of the pattern of results obtained using an optimal symbolic rule-processing implementation. It may be overkill to implement a whole rule-based system for a single rule. Also, it seems reasonable to suppose that brains ultimately perform computations by passing activation signals among neurons.

Nonetheless we remain open to other possible implementations of rule-like processing. For instance, efficient computation of products can be accomplished with so-called sigma-pi units that multiply, rather than add, their inputs (Durbin & Rumelhart, 1989). Do this twice and compare the size of the products, and you have a torque rule. Also, a model called long short-term memory (LSTM) provides neurally-plausible modules of memory buffers and gates to retain representations over time (Hochreiter & Schmidhuber, 1997). Such features appear useful for neural implementation of symbolic processing. For now, it is worth noting that our overall results and conclusions remain consistent as long as implementation of the torque rule performs correctly on torque problems.

Our present model builds on, improves, and extends work presented earlier (Dandurand & Shultz, 2009). From that previous model, here we improve the coding of balance outcomes by not placing target outputs at the inflection points of sigmoid activation functions; use a selection network rather than a less-efficient confidence network to guide processing; extend the model to cover the torque-difference effect and reaction times; apply automatic maxima detection to detect growth spurts; employ LCA to detect network rules; isolate the effects of learning and practicing the torque rule; add appendices to report on learning from examples alone (A), diagnose stages with LCA and RAM techniques (B), and demonstrate reliability and decidability problems with LCA (C); and, in the next section, relate our model to previous work on dual and tripartite processing.

As noted, our modular approach to balance-scale phenomena is consistent with a long and still active emphasis in psychology. This work has been variously described in many different contrasts, such as heuristic vs. analytic (Evans, 2003, 2006, 2010), implicit vs. explicit (Reber, 1989; Reber & Lewis, 1977), automatic vs. controlled (Shiffrin & Schneider, 1977) or conscious (Posner & Snyder, 1975), adaptive vs. conscious (Wilson, 2002), intuitive vs. reasoned (Kahneman & Frederick, 2005), associative vs. rule-based (Sloman, 1996), and fast vs. slow (Kahneman, 2011). Perhaps because of this proliferation of semantically rich terminology, some have opted for more neutral, numerical terms such as types 1 and 2 (Evans & Wason, 1976; Stanovich, 2012; Thompson, Prowse Turner, & Pennycook, 2011; Wason & Evans, 1975) or systems 1 and 2 (Kahneman, 2011).

A few researchers propose adding a third, metacognitive module that decides whether to accept the response submitted by the faster, intuitive module or to inhibit that response and activate the more deliberate reasoning module for a more deeply considered response (Stanovich, 2012; Thompson et al., 2011). Some of this work on dual (Sun, Slusarz, & Terry, 2005) or tripartite (Hahn & Nakisa, 2000) systems has involved operative computational models, while other researchers have begun to explore, in some cases with the aid of computational models, the brain characteristics that might have led to these differences in processing (Frank, Cohen, & Sanfey, 2009).

Our current balance-scale model seems closest to that of Hahn and Nakisa (2000) on plural inflection of German nouns. Their model coupled a neural network with a single default rule to construct 15 different ways to form the plural form of 4000 German nouns. If the strength of the memory for an exception noun rose above a certainty threshold, default rule application was blocked. But if memory strength remained below this threshold, the default rule of adding an −s to the singular form was applied. This is similar to our model in having three modules implementing a rule, a network, and a selector, but the results were quite different. In their system, performance was always more correct when the default rule was not applied, regardless of threshold level, thus contradicting a dual-process hypothesis. In contrast, our model uses a torque rule to improve performance on the more difficult problems where intuitive decisions are not so obvious. Such variations in results may naturally correspond to task differences. For the German plural, the rule turns out to be superfluous because the network can handle this default case as well as the 14 exceptional forms. Whereas, for the balance scale, some problems have such similar torques on both sides of the scale that a superficial, intuitive solution is too error-prone to be trusted.

Another difference is that deciding whether to use the default plural rule was done exclusively in symbolic software, whereas our selection module contains a neural network to learn to monitor performance of the intuitive module. It is not widely appreciated that neural networks can serve a meta-cognitive role by predicting the performance of another neural network rather than events in the environment.

Finally, it is also interesting to note the successful use of multi-modular computational simulations in our neighboring field of molecular biology (Karr et al., 2012). A major open challenge is to devise algorithms to integrate the outputs of different modules.

@&#CONCLUSION@&#

In conclusion, we present a comprehensive model of the balance-scale task that successfully simulates the stage progressions, including the recently disputed torque-rule performance in the terminal stage, as well as the torque-difference effect and the pattern of response times observed in children. The model posits two distinct processing modules, an intuitive module and a torque-rule module, consistent with the well-supported dual-processing approach in cognitive psychology. A third, meta-cognitive module determines which of these two modules will produce the answer to any particular balance-scale problem. In the model, stage progression occurs as a natural consequence of learning (due to connection-weight adjustment) and development (due to recruitment of hidden units) in a fully connectionist fashion. Although the model uses a connectionist implementation of an explicitly-taught torque rule, it can accommodate any implementation that provides equivalent torque-comparison functionality, including symbolic versions. As with meta-cognition, it is not widely appreciated that neural networks can implement some symbolic functions.

@&#ACKNOWLEDGEMENTS@&#

This work was supported by a post-doctoral fellowship to F.D. and an operating grant to T.R.S., both from the Natural Sciences and Engineering Research Council of Canada. We are grateful to Yoshio Takane for discussions of LCA, some data analyses, and comments on earlier drafts. Thanks also to anonymous reviewers for several interesting questions and challenges.

@&#INTRODUCTION@&#

A recent critique argued that connectionist models of balance-scale development do not capture stage-4 performance (Quinlan et al., 2007), which on some theoretical accounts (Siegler, 1976) involves computation and comparison of torques. Torque is the rotational force applied to a lever, multiplied by its distance from the lever’s fulcrum. Because many conflict problems can be solved by adding (rather than multiplying) weight and distance, documentation of a torque rule needs to be supported by success on problems that cannot also be solved by addition.

With five pegs and five weights, the problem size used in our original cascade-correlation (CC) simulations of the balance scale (Shultz et al., 1994) and in many balance-scale psychology experiments, there are 625 total problems, of which just 200 are conflict problems. Only 52 of these conflict problems (dubbed torque problems) actually require a torque rule for correct solution because the other 148 conflict problems (dubbed addition problems) can be solved correctly by adding distance and weight on each side and comparing these sums.

Until recently, there was not much interest in using an addition rule to gage balance-scale performance and addition did not figure importantly in descriptions of balance-scale stages. Thus, addition was routinely ignored in both symbolic (Langley, 1987; Newell, 1990; Schmidt & Ling, 1996) and connectionist (McClelland, 1989; Schapiro & McClelland, 2009; Shultz, Mareschal, & Schmidt, 1994) simulations of balance-scale performance, and there was no attempt to distinguish addition from a genuine torque rule in these simulations.

Thus it is not surprising that researchers using sophisticated methods such as Latent Class Analysis (LCA) failed to find evidence of a torque rule, distinct from an addition rule, in replications of connectionist models (Jansen & van der Maas, 1997; Quinlan, van der Maas, Jansen, Booij, & Rendell, 2007).

Until recently none of balance-scale simulations ever tried to simulate or diagnose a genuine torque rule by distinguishing it from an addition rule. There is no reason to believe that a genuine torque rule will emerge in every neural network model. Although we show that a genuine torque rule does emerge in our KBCC model and in SDCC networks, this rule does not emerge, for example, in back-propagation networks. Indeed back-propagation networks do not even reach stage 4 when assessed with Siegler’s RAM technique. To our knowledge, we are the first to show that neural networks can achieve a genuine torque rule, and we confirm this result in two quite different constructive networks – SDCC networks alone and our favored three-part modular system.

However, the conclusion that connectionist models are unable to learn a true torque rule is premature. The definition of torque as a product of number of weights and distance from the fulcrum is a rather simple multiplicative function, even if it has to be computed on both sides of the fulcrum and the larger torque selected as marking the descending side of the scale. An obvious, but untried way to see if networks can learn to compute and compare torques is to ensure that there are sufficient torque problems to the training set. Otherwise, the relatively few available torque problems can be easily swamped by the much larger number of problems that can correctly be solved by addition or even simpler rules involving weight or distance. This is particularly true when there are biases in the training set favoring equal-distance problems, thought to be necessary for capturing the stage-1 tendency to focus on weight information to the exclusion of distance information (McClelland, 1989; Shultz et al., 1994).

Here we present simulations to test this hypothesis that prolonged training with sufficient numbers of torque problems can simulate learning to use torques. We apply several analyses of network responses to assess the use of torque and addition rules. We focus here on stages 3 and 4 and on the addition and torque rules thought to characterize those two stages, respectively (Boom et al., 2001; Jansen & van der Maas, 1997, 2002). We use newer sibling-descendant CC (SDCC) networks to study learning of a torque rule from prolonged exposure to torque problems.

@&#METHOD@&#

SDCC is an extension of the CC algorithm that allows a newly-recruited unit to be installed either on the current highest layer (as a sibling) or on its own higher layer (as a descendant) as in standard CC (Baluja & Fahlman, 1994). Sibling and descendant candidates compete with each other for recruitment. As in standard CC, the candidate whose activation correlates highest with network error during input phase is the one recruited. Because descendant candidates have extra, cascaded weights from the current highest layer of hidden units, they are typically penalized by having their correlations multiplied by .8. This tends to minimize network weights without harming generalization (Baluja & Fahlman, 1994). The basic idea of SDCC is to introduce more flexible network topologies and build whichever connectivity is most beneficial at the time of recruitment. Early simulations with SDCC have so far found that it creates smaller and more variable network topologies, but with the same functionality as standard CC (Shultz, 2006).

Because we focus here only on rules 3 and 4, we train SDCC networks only on conflict problems. For each of 20 networks, we randomly select without replacement 40 addition problems and 40 torque problems for the training set. From the remainder of unselected problems, we randomly select 12 addition problems and all of the remaining 12 torque problems for testing. After training to some epoch limit or to victory, whichever came first, we record the proportions correct of training problems and addition and torque test problems. Input and output coding and parameter settings are identical to the original CC simulation of balance-scale development (Shultz et al., 1994). For each network, the recruitment pool contains eight sibling and eight descendant sigmoid units.

@&#RESULTS@&#

We have some pilot testing to determine the epoch at which performance on the three measures reaches asymptote. To explore this, we set last-epoch limits of 100–1000, in steps of 100. Fig. A1
                         shows proportion correct on train, test-addition, and test-torque problems across these different levels of training. There are 20 SDCC networks in each run. It is apparent that proportion correct on all three sets of patterns peaks at about 800 epochs in these networks. The plots of performance on test problems suggest early success (across the first 100 epochs) on addition problems but not on torque problems which continue to improve up to about 800 epochs. The only region where the SD bars do not greatly overlap is at a 100-epoch limit. After that, the different kinds of patterns (training, addition, and torque) do not differ significantly – the networks achieve a high level of success on all three.

To focus more precisely on the difference between following addition and torque rules, we compare networks trained up to a 100-epoch limit against those trained up to an 800-epoch limit. Mean numbers of recruited hidden units per network are 0.20 at the 100-epoch limit and 5.45 at the 800-epoch limit. Only 4 of the 20 networks run at the 100-epoch limit recruit any hidden units, and they each recruit a single hidden unit. These proportions are given an arcsine transformation in order to stabilize the variances (Hogg & Craig, 1995). These transformed values are subjected to a 2×3 mixed ANOVA in which epoch limit (100 vs. 800) serves as a between-network factor and patterns (train, test-addition, and test-torque) serve as a repeated-measures factor. There is a main effect of epoch limit, F(1,38)=289, p
                        <.0001, a main effect of patterns, F(2,76)=144, p
                        <.0001, and an interaction between them, F(2,76)=80, p
                        <.0001. A follow-up repeated measures ANOVA of only test-addition problems shows no main effect of epoch limit, F(1,38)<1, indicating that networks master the addition problems during the first 100 epochs. Other simulations indicate that ordinary CC networks perform in a similar manner to these SDCC networks.

@&#DISCUSSION@&#

It seems as though an addition rule can be built without any (or many) hidden units, but a torque rule is more difficult thus requiring considerably more hidden units and epochs of training to recruit and consolidate the units. The fact that networks get 92% and 84% of addition and torque test problems, respectively, correct by 800 epochs suggests that they are following a torque rule by that point. In psychology experiments on the balance scale task, it has been conventional to consider 80% success on all problem types adequate for a diagnosis of rule 4 (Siegler, 1976). It is also relevant to note that, after 100 epochs, networks do as well on torque problems as on addition problems.

These results show that constructive networks can learn to perform in conformity with an addition and a torque rule if given sufficient examples of each type of problem. Furthermore, these two rules emerge in the proper order, addition before torque. This order is natural for constructive networks that recruit hidden units only as needed to reduce error (Shultz, 2003, 2012; Shultz & Fahlman, 2010). Indeed, such recruitments provide a computational explanation of this ordering in the sense that nonlinear hidden units underlie multiplication. The results also underscore that ANOVA applied to properly designed experiments can provide a valid diagnostic technique for rule-like performance.

@&#INTRODUCTION@&#

In this appendix, we apply two different diagnostic techniques to SDCC networks to test their ability to transition to a genuine torque rule: RAM and LCA.

The classic method of detecting rules on balance scale tasks is to test a participant with several problems of each of six types (Siegler, 1976). Three of these types are relatively simple problems with no conflict between weight and distance information: balance problems in which there are equal numbers of weights on each side of the scale placed equally distant from the fulcrum, weight problems in which one side has more weights than the other with the weights placed equally distant from the fulcrum, and distance problems with the same number of weights on each side placed at different distances from the fulcrum. There are also three kinds of conflict problems in which one side of the scale has more weights and the other side has greater distance, making the prediction of which side will descend more difficult. Conflict-weight problems have greater torque on the side with more weight, conflict-distance problems have greater torque on the side with more distance, and conflict-balance problems have equal torques on each side of the fulcrum.

The classic Rule-assessment Method (RAM) examines the pattern of performance across these six problem types (Siegler & Chen, 2002). Use of rule 1 (weight information) is indicated by a pattern of correct performance on the balance, weight, and conflict-weight problems and incorrect performance on the distance, conflict-distance, and conflict-balance problems. Rule 2 (weight information, but use of distance when the weights are equal across the two sides) is characterized by the same pattern as rule 1, but with additionally correct performance on distance problems. In rule 3, weight and distance information are both used, yielding correct performance on the simple problems, but confusion on conflict problems.

Although Siegler (1976) suggested that rule 3 users guess on conflict problems, several later researchers have emphasized the use of other rules, particularly the addition rule, in which the side with the larger sum of weight and distance is predicted to descend (Boom et al., 2001; Ferretti et al., 1985; Jansen & van der Maas, 1997, 2002; Normandeau et al., 1989; Quinlan et al., 2007). Rule 4 is characterized by successful performance on all six problem types, perhaps indicating use of the torque rule in which the side with the larger torque (weight x distance) is predicted to go down. To accommodate error variance in human performance, RAM users tolerate up to 20% deviant responses from these precise patterns of performance. Because these four rules tend to develop in order of their numerical designation, they are often taken as evidence that a child is in a particular stage of development.

More recently, several researchers have argued that Latent Class Analysis (LCA) is a methodologically sounder way to detect rules (Boom, Hoijtink, & Kunnen, 2001; Jansen & van der Maas, 1997, 2002; Quinlan et al., 2007). In exploratory LCA, estimated parameters of a statistically-fitting model differ across latent classes, typically designating homogeneous groups of participants that differ from each other (McCutcheon, 1987). Individuals can be sorted into the latent classes based on membership probabilities estimated from the model.

In balance-scale research, the test problems typically come from the same types used by RAM researchers. But because LCA requires large numbers of participants and does better with small numbers of problems (see Appendix C for explanation), non-diagnostic problems such as balance and weight problems are often omitted from the test set. Also, in this recent research, there is often a systematic attempt to distinguish the addition rule from the torque rule by including among the conflict test problems some that can solved by either addition or torque and others that can only be solved by torque.

Advantages and disadvantages of these two methods for detecting balance-scale rules have been noted and debated (Jansen & van der Maas, 1997, 2002; Siegler & Chen, 2002, 2008; van der Maas & Straatemeier, 2008). Both can test for the presence of pre-defined rules while LCA can as well identify previously unknown rules. Here we apply both techniques to the same dataset, produced by a large number of SDCC networks, in order to assess whether these networks can transition from an addition rule to a genuine torque rule. It was previously argued that such networks cannot achieve a genuine torque rule (Quinlan, et al., 2007).

@&#METHOD@&#

To approximate the number of cases used in recent LCA studies of human balance-scale development (Boom, Hoijtink, & Kunnen, 2001), we train 250 SDCC networks on randomly selected addition and torque problems for up to 100 epochs and 250 more SDCC networks for up to 800 epochs, as in the simulations of Appendix A. We replicate this five different times, for a total of 2500 networks. In each replication, we diagnose rule following with both LCA and RAM methods. Our test patterns are four problems taken from a larger set of 15 problems used in recent LCA balance-scale studies of humans (Boom et al., 2001), chosen because they distinguish addition from torque rules and possess a uniform absolute torque difference. It is now well known that problems with large absolute torque differences are easier for people and networks to solve at every stage (Ferretti & Butterfield, 1986; Ferretti, Butterfield, Cahn, & Kerkman, 1985; Shultz et al., 1994).

@&#RESULTS@&#

For each of the five replications, the frequencies of the various response vectors are subjected to exploratory LCA using the LEM program (Vermunt, 1997), using default settings throughout. Model fit is evaluated with the BIC statistic which combines model fit with penalization for number of parameters, such that the smallest BIC value indicates the preferred model (Schwartz, 1978; Nylund et al., 2007) (see Table B1
                        ). Following LCA conventions, we start with a 2-class model and increment classes by 1 until we obtain a minimum BIC value (indicating that the model fits the data) or run out of degrees of freedom, whichever comes first. For 2 classes, there are 6 df and 10 parameters; with 3 classes, 1 df and 15 parameters. Because lower BIC values occur with 3 classes than with 2 classes for most replications and overall, it can be concluded that LCA favors a 3-class model.

Because the sum of conditional probabilities across wrong and correct answers for each problem always sum to 1, we can summarize these parameters in a plot of estimated probabilities of correct responses (Fig. B1
                        ). The plots for torque and addition rules follow their expected patterns – mostly correct on all four problems for the torque class and correct only on the addition problems for the addition class. The unknown class shows correct performance on one addition and one torque problem, middling performance on the other torque problem and poor performance on the other addition problem. This difficult-to-explain pattern does not replicate well.

To provide an indication of variability across replications, Fig. B2
                         presents a similar plot for replication 2. All replications show the expected patterns for torque and addition classes, but a highly variable pattern for the rare class we label as unknown. In replication 2, this class is characterized by middling performance on all four problems but slightly better performance on the addition problems than on the torque problems.

Estimated class sizes for these two replications and all five replications together are shown in Table 5
                         for 2- and 3-class models. The extra classes identified in the 3-class models are both unreliable across replications and small in size. This underscores that, even though BIC can be useful, by itself it is no guarantee that small and unreliable classes are avoided.

Strict application of RAM to these data involves noting the frequencies of networks falling in the quintessential addition and torque patterns. Summing over all 5 replications, these two cells always hold the highest frequencies, containing 59% of the lightly-trained networks and 72% of the highly-trained networks. This also shows that the addition rule peaks early, at 100 epochs and the torque rule peaks later, at 800 epochs. Allowing some Sieglerian latitude by also counting the frequencies of networks with only one of the two addition problems correct, these percentages rise to 82% and 94%, respectively.

@&#DISCUSSION@&#

Confirming the results of the ANOVA technique for rule diagnosis in Appendix A, both LCA and RAM reveal an early addition rule and a later torque rule in SDCC networks trained on both addition and torque conflict problems. This further demonstrates that SDCC networks can learn a genuine torque rule from sufficiently informative examples and learn it later than a simpler addition rule, thus showing a natural progression from stage 3 to 4 on the balance scale. There is a strong tendency for LCA to also find a small third latent class that cannot be reliably identified as representing any particular rule. The problem of high variability in LCA solutions is studied in greater detail with simulated data in Appendix C.

@&#INTRODUCTION@&#

LCA was recently applied (Quinlan et al., 2007) to a replication of an early computational model of children’s development on the balance-scale task (Shultz et al., 1994). Quinlan and colleagues (2007) criticized this computational model, which had used constructive neural networks, for not capturing all of these stages. In an invited response to the Quinlan et al. paper, we argued among other points that LCA, as used by Quinlan et al., shows a strong tendency to identify small and unreliable classes (where each class represents a rule), and thus should be used cautiously in validating stages in both psychological and modeling studies (Shultz & Takane, 2007).

In their response to our rejoinder, our argument was dismissed because our demonstration used a 3-class model of 4 items, which yields an unidentified statistical model that does not converge during estimation (van der Maas, Quinlan, & Jansen, 2007). Here we present a 3-class model of 6 items, which yields an identified statistical model, to study the reliability problem in more detail. We confirm that this problem is indeed severe enough to warrant caution in using LCA to assess rule development. First, we present a brief recap of relevant background literature and issues.

The psychological literature on using LCA to assess balance-scale stages provides strong evidence of unreliability in rule identification. Independent LCA studies of human balance-scale performance produce a number of small, leftover classes with mutually inconsistent interpretations. For example, Boom and colleagues (Boom & ter Laak, 2007; Boom et al., 2001) found classes suggestive of Siegler’s four rules, the addition rule, and several infrequent and difficult-to-interpret classes. Likewise, Jansen and van der Maas (1997) found classes for Siegler’s first two rules, the addition rule, and a no-balance rule predicting that the scale would not balance, which was described as difficult to interpret. Jansen and van der Maas (2002) later reported classes consistent with Siegler’s four rules, addition, a smallest-distance-down rule, a distance-and-guessing-when-weights-are-unequal rule, a rule that seemed to combine Siegler’s rule 3 with the addition rule, and additional difficult-to-interpret classes. Tellingly, it is the smaller classes that tend to be the most difficult to replicate across these human studies.

The problem with these small extra classes is not difficulty of interpretation. Humans often exhibit behavior that is difficult to interpret in terms of rules. The real problem with extra LCA classes is that they are small and inconsistent, suggesting that they might be random and essentially meaningless. As such, they should not be used to characterize children’s performance or adjudicate among computational simulations of that performance.

Interesting in this context is Boom et al.’s (2001) distinction between classes and strategies. Classes are said to refer to a set of response patterns that are statistically similar, as revealed by say LCA. Strategies (or rules) refer to an interpreted procedure that could conceivably generate a statistical class. Classes that cannot be interpreted as being produced by sensible rules should not be treated as rules; they are merely statistical groupings that may not happen to fit a rule interpretation.

In summary, the only balance-scale rules to be reliably diagnosed by LCA in humans are weight, weight-and-distance, addition, and torque. Ignoring the small and difficult-to-interpret latent classes in Quinlan et al.’s (2007) study, it is noteworthy that their LCA found evidence for weight, weight-and-distance, addition rules in their replication of our original balance-scale simulation (Shultz et al., 1994). Apart from a torque rule, these are precisely the same rules consistently found with children using LCA. Moreover, our accompanying manuscript and Appendices A and B provide clear evidence of neural networks also following a genuine torque rule.

@&#METHOD@&#

To investigate the unreliability issue in LCA more deeply, we generate synthetic data from ideal addition and torque rules for six hypothetical conflict problems, three of which could be solved by either addition or torque comparisons and three of which could only be solved by comparison of torques. This transition from addition to torque rules is documented in our main paper and in Appendices A and B.

The present simulation uses class population sizes of .48 for a torque rule, .48 for an addition rule, and .04 for a small random class. There are 5000 replications of 500 cases each. There are six hypothetical balance-scale items, the first three of which can be solved by either an addition or a torque rule, and the remaining three of which can only be solved by a torque rule. For each of the ten replications, the frequencies of response patterns are subjected to exploratory LCA using Goodman’s (1974) iterative proportional fitting algorithm, which we implement in MATLAB software. We use the recommended BIC statistic to penalize the number of parameters.

@&#RESULTS@&#

The BIC statistic favors 3-class solutions among the 2-class, 3-class and saturated models in each of the 5000 replications, so we focus here on the 3-class model. The mean conditional probabilities of being correct are plotted in Fig. C1
                         for each item and latent class. As expected, the torque class is characterized by virtually perfect performance on each item, the addition class by virtually perfect performance on the first three items and failure on the last three items, and the random class by near chance performance.

Mean estimates of the class sizes are .484 (.022) for the torque class, .483 for the addition class (.022), and .033 (.008) for the random class. Standard deviations are presented in parentheses.

The 95% confidence bands for conditional probability estimates in the addition and random classes are plotted in Fig. C2
                        . They reveal far more variability in the random class than in the addition class. The torque class is excluded for visual clarity, but the confidence bands are as tight for that class as for the addition class, ranging between .9924 and 1.0.

The standard deviations of these conditional probabilities are plotted in Fig. C3
                        , again for each item and class. The standard deviations for the small, random class are about 65 times greater than those for the large, systematic classes based on the torque and addition rules.

These results approximately conform to the simplest binomial case. In the binomial distribution, the variance of frequency x is np(1−
                        p), where n is sample size and p is x/n. From this, we can derive that 
                           
                              variance
                              (
                              p
                              )
                              =
                              vrriance
                              (
                              x
                              )
                              /
                              
                                 
                                    n
                                 
                                 
                                    2
                                 
                              
                              =
                              p
                              (
                              1
                              -
                              p
                              )
                              /
                              n
                           
                        . If p is .5 (as in the random case) and n
                        =500×.04=20, the SD of p is sqrt(.25/20)=0.112. When p
                        =0 or 1 (as in the torque and addition cases), the SD is theoretically 0.

In further simulations, we find that roughly four times as many cases (N
                        =2000) are necessary to achieve the standard deviations that van der Maas et al. (2007) deemed to be acceptably low. Without any particular justification, they cited 0.035 as an acceptable overall mean standard deviation for conditional probabilities. We find a mean overall standard deviation of 0.022 for conditional probabilities with 2000 cases. However, the mean standard deviations for the small, random class is 70 times higher than the mean standard deviations for the two larger, systematic classes. Although 2000 participants may be feasible for computer simulations, it is unlikely that psychology researchers would run so many human participants in cognitive experiments, unless perhaps when running online experiments.

The relatively large variability for the small, random class is sufficient to produce many different patterns of performance across the six items, as shown in Fig. C4
                        , which plots conditional probabilities for the first five replications in an identical simulation, again with a more realistic 500 observations. In each replication, the pattern for the torque and addition classes is predictably regular – perfect performance for the torque class, and for the addition class perfect performance on the first three items and perfect failure on the last three items. However, the pattern for the small, random class (solid line) is highly variable, affording many different interpretations across the replications.

The small, random class in replication 1 can be interpreted as success on item 2, failure on items 1 and 3, and guessing on items 4–6. The same class in replication 2 looks like success on items 4–6 and failure on items 1–3. Replication 3 features an alternating pattern with somewhat better performance on odd than even items, while replication 5 shows the reverse alternating pattern with better performance on evens than odds. In replication 4, there is a peak performance at item 4. However, there is plenty of ambiguity in these interpretations. Such variability would be expected given the large standard deviations in conditional probabilities for the small, randomly-produced class.

An important question raised by these results is whether the variability of small, random latent classes is caused by the smallness of the class size or the random production of class members, or perhaps by both smallness and randomness. We study this issue by switching the population size of the small, random class with that of one of the large systematic classes, the addition class. Thus, the torque and random classes each have a population size of .48, and the addition class has a population size of .04. Again, there are 5000 replications of 500 cases each.

The plot of mean conditional probability estimates over all 5000 replications in Fig. C5
                            conforms to the expected pattern: for the torque class near perfect performance on all six items, for the addition class success only on the first three items and failure on the last three items, and for the random class random performance averaging to about .5.

However, the plot of SDs of these same conditional probabilities in Fig. C6
                            shows that variability is about 6.4 times greater in the large, random condition than in the torque condition, and about 12.3 times greater in the small addition condition than in the torque condition. This indicates that, at least for these parameter settings, both randomness and smallness are important determinants of variability in conditional probabilities, but smallness is about twice as important as randomness.

These results are summarized across the two foregoing simulations in Fig. C7
                           , which plots the mean SDs of conditional probabilities across items from Fig. C3 (solid line) and C6 (dashed line). Examination of Fig. C7 again indicates that both smallness and randomness contribute to the variability of conditional probabilities. Within the constraints of the present parameter settings, smallness has a larger impact than does randomness in that the small but systematic condition is more variable than the large but random condition. The results suggest that even systematic classes will be difficult to replicate when they are small, and that random classes will be difficult to replicate even when they are large. If a class is both small and random, as many of the disputed balance-scale classes are, it will be especially unreliable.

@&#DISCUSSION@&#

Our present results, with an identified LCA model, confirm our previous conclusion with an unidentified model (Shultz & Takane, 2007) that LCA has serious problems in identifying small and unreliable rule classes. The dismissal of our previous demonstration for not having an identified model (van der Maas, Quinlan, & Jansen, 2007) proves to be a red herring. A deeper analysis here more precisely pinpoints and quantifies the extent of this problem, finding that the standard deviations of conditional probabilities are 65–70 times greater for the small, random classes than for the large systematic classes. With such extraordinary variation, it is not surprising to also find that the pattern of these small, random classes do not replicate across different LCA replications. Of course, when the pattern across test items does not replicate, neither will its interpretation. Further investigation indicated that both class smallness and randomness contribute to increasing this variance, with smallness being more important under the current parameter settings.

Our critics argued that increased variation in small classes with larger samples is not a problem because the larger classes are unaffected by the additional smaller classes (van der Maas, Quinlan, & Jansen, 2007). We would agree that attention should be redirected from the unreliable, small classes to the reliable large classes, but it remains true that our balance-scale model was inappropriately criticized for not covering the small, unreliable classes of often non-sensible rules (Quinlan et al., 2007).

Some of these problems with LCA can be traced to the LCA method and the frequency data used as input. The common method for parameter estimation in LCA is Maximum Likelihood Estimation (MLE), partly because MLE provides several statistical advantages. However, these advantages are present only when all of the following conditions are satisfied: (1) the fitted model is correct, (2) the sample size is sufficiently large, and (3) other regularity conditions are met. We discuss each of these conditions in turn, and then an epistemological problem.

An LCA model consists of two parts, one statistical and the other parametric. The statistical part assumes independent trials and a multinomial probability distribution of multiple possible response patterns, only one of which occurs in each trial. The parametric part assumes several homogeneous groups in a heterogeneous population, with each group member responding to a set of items independently of other items (the Local Independence assumption, LI). Each group (represented as a latent class) is characterized by its size and a set of conditional probabilities of responses to particular items. To satisfy the LI assumption, a large number of latent classes typically must be assumed, but this tends to produce latent classes that are difficult to interpret (Bartholomew, 1987; Hagenaars, 1990; Qu, Tan, & Kutner, 1996).

The benefits of MLE emerge only with a sufficiently large sample. However, what constitutes a large sample is controversial (Hagenaars, 1990; Wickens, 1989). There are 2
                           n
                         possible response patterns when there are n dichotomous items, and reliably estimating the probabilities of these response patterns requires a large number of participants. There should be at least one, but preferably five or more cases in each response pattern. This condition can be difficult to satisfy, particularly when some response patterns rarely occur, which happens as the number of response patterns increases. Although this problem has been under active consideration (Bartholomew & Leung, 2002; Hoijtink, 1998; Reiser & Lin, 1999), there is currently no commonly-accepted solution.

One of the regularity conditions for the standard asymptotic properties of MLE is that LCA parameters must reside in the interior of the parameter space. However, it is often the case that important parameter values (like those representing crisp rules) are actually on the boundaries of the parameter space with conditional probabilities of 0 or 1, as exemplified throughout LCA analyses of balance-scale results. Although there are some attempts to extend asymptotic theory to cover cases in which estimates are subject to inequality constraints (Dijkstra, 1992; Shapiro, 1985, 1988), this complicates the theory enough to prevent integration of these efforts into LCA literature and software. The only known practical solutions are resampling methods, such as the parametric bootstrap (Aitkin, Anderson, & Hinde, 1981; Langeheine, Pannekoek, & van de Pol, 1996).

Moreover, even when all three conditions are met, there is an unresolved epistemological issue: there is no statistical method to determine the correct number of latent classes. Although one might argue that goodness-of-fit tests can determine the number of significant latent classes, such tests are not designed for this – they are instead designed to determine how many latent classes are needed to satisfy the LI assumption. The number of latent classes naturally increases with sample size because with a large sample even a small departure of the model from the data becomes significant, and in order to get a satisfactory fit, the number of latent classes has to be increased. With number of latent classes directly dependent on sample size, there is no correct number of latent classes in LCA. The number of latent classes to extract can also depend on the purpose of the analysis. There are typically some researchers wanting most of the variability in the data to be explained by a model and others who are satisfied with less explanatory power. The former will retain all the latent classes, while the latter retain only the most frequent classes.

These are the same reasons that a statistical approach to factor analysis, a related technique for finding latent structure, has never found the correct number of common factors defining human intelligence and other characteristics. With a large sample size, even small correlations become significantly different from zero, and a large number of factors are required to explain the correlations. Researchers seeking a simpler, more unified picture of intelligence can use smaller samples, whereas those convinced of the complexity of intelligence can support their position with larger samples. Unless and until such statistical problems are resolved, our recommendation is to confine interpretation of latent classes to those that are replicated across studies. In particular, computational modelers should not bother chasing all of the latent classes found in LCA of children’s responses, as some researchers have mandated (Quinlan et al., 2007).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Combining deep and shallow embedding of domain-specific languages

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We present a technique for combining deep and shallow embedding for embedded languages.


                        
                        
                           
                           The technique gives a more natural programming interface to embedded languages.


                        
                        
                           
                           The technique makes it easy to extend embedded languages.


                        
                        
                           
                           We give a plethora of examples demonstrating the advantages of the technique.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Domain specific languages

Shallow embedding

Deep embedding

Fusion

Monads

@&#ABSTRACT@&#


               
               
                  We present a technique to combine deep and shallow embedding in the context of compiling embedded languages in order to provide the benefits of both techniques. When compiling embedded languages it is natural to use an abstract syntax tree to represent programs. This is known as a deep embedding and it is a rather cumbersome technique compared to other forms of embedding, typically leading to more code and being harder to extend. In shallow embeddings, language constructs are mapped directly to their semantics which yields more flexible and succinct implementations. But shallow embeddings are not well-suited for compiling embedded languages.
                  Our technique uses a combination of deep and shallow embedding, which helps keeping the deep embedding small and makes extending the embedded language much easier. The technique also has some unexpected but welcome secondary effects. It provides fusion of functions to remove intermediate results for free without any additional effort. It also helps us to give the embedded language a more natural programming interface.
               
            

@&#INTRODUCTION@&#

Domain specific languages (DSLs) provide an effective means of increasing programmer productivity [25]. In order to lessen the initial cost of implementing the DSL, many implementors choose to embed the language in a host language. Embeddings can come in many shapes and forms [19], partly dictated by the purpose of the language. This paper focuses on DSLs which are designed to generate code. In this situation it is natural to use an algebraic data type to represent the abstract syntax tree (AST) of the DSL. This is known as a deep embedding. Deep embeddings can be cumbersome: the AST definition can grow large when each language construct has its own constructor. It is also laborious to add new language constructs as it requires changes to the AST as well as all functions manipulating the AST.

In contrast, shallow embeddings do not require an abstract syntax tree and all the problems that come with it. Instead, language constructs are mapped directly to their semantics. Nevertheless, there are many situations in which it is convenient to have access to an AST – especially when we wish to transform expressions and generate code from them.

In this paper we present a technique for combining deep and shallow embeddings in order to achieve many of the advantages of both styles. Concretely, we propose to define DSLs using shallow embeddings which generate a deeply embedded AST. This combination turns out to provide surprising but welcome secondary effects which we explore. In particular, our technique has the following advantages:


                     Simplicity: By moving functionality to shallow embeddings, our technique helps keep the AST small without sacrificing expressiveness.


                     Abstraction: The shallow embeddings are based on abstract data types leading to better programming interfaces (more like ordinary APIs than constructs of a language). This has important additional benefits:
                        
                           •
                           The shallow interfaces can have properties not possessed by the deep embedding. For example, our vector interface (Section 4.9) guarantees removal of intermediate structures (see Section 5).

The abstract types can sometimes be made instances of standard Haskell type classes, such as Functor and Monad, even when the deep embedding cannot (demonstrated in Sections 4.8, 4.9 and 6).


                     Extensibility: Our technique can be seen as a partial solution to the expression problem [43] as it makes it easier to extend the embedded language with new language constructs and functions.

The paper is organized as follows: In Section 2 we start by giving a more detailed introduction to shallow and deep embeddings, including a comparison of the two methods (Section 2.1). Section 3 gives a detailed description of our technique. Section 4 demonstrates the technique by defining a deep embedding and showing a number of examples of how it can be extended with new shallow language constructs. Section 5 describes how fusion comes for free as a consequence of our technique and explain in detail what guarantees it provides. Section 6 describes how to embed arbitrary monads and shows a monad for mutable data structures as an example. Finally, Section 7 discusses how the presented techniques can be scaled up to a full EDSL implementation.

Throughout this paper we will use Haskell [32] and some of the extensions provided by the Glasgow Haskell Compiler. Code from this paper can be found in the following repository: https://github.com/josefs/deep-shallow-paper.

This paper is an extended version of our paper “Combining Deep and Shallow Embedding for EDSL” which appeared in Trends in Functional Programming 2012 [38]. New material presented here includes Sections 6 and 7 which are completely new. Section 5 has been expanded with more examples of fusable data structures. The deep embedding in Section 4 has been changed in some ways: binding is now handled using the Lam and :$ constructors. We have included a Syntactic instance for functions, which simplifies the definition of smart constructors. Literals have been generalized to more closely match what an actual implementation would look like. We have also added a function for rendering the generated ASTs in Section 4.10. Finally, bugs have been fixed in the evaluator in Section 4 and the description of the Option type in Section 4.8.

To explain the meaning of “deep” and “shallow” we will use the following small embedded domain specific language (EDSL) by Carlson et al. [9] as an illustrating example. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     This piece of code defines a small language for regions, i.e. two-dimensional areas. It only shows the interface; we will give two implementations, one deep and one shallow.

The type Region defines the type of regions which is the domain we are concerned with in this example. We can interpret regions by using inRegion, which allows us to check whether a point is within a region or not. We will refer to functions such as inRegion which interpret values in our domain as interpretation functions. The function inRegion takes an argument of type Point and we will just assume that there is such a type together with the expected operations on points.

Regions can be constructed using circle which creates a region with a given radius (again, we assume a type Radius without giving its definition). The functions outside, 
                        (
                        ∩
                        )
                      and 
                        (
                        ∪
                        )
                      take the complement, intersection and union of regions, respectively. As an example of how to use the language, we define the function annulus which can be used to construct donut-like regions given two radii: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

The first implementation of our small region EDSL will use a shallow embedding. The code is shown below: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     Our concrete implementation of the type Region is the type 
                        Point
                        →
                        Bool
                     . We will refer to the type 
                        Point
                        →
                        Bool
                      as the semantic domain of the shallow embedding. It is no coincidence that the semantic domain is similar to the type of the function inRegion. The essence of shallow embeddings is this:
                        Definition 1
                        A shallow embedding represents language constructs as their semantics in the host language.

The implementation of the function inRegion becomes trivial; it simply uses the function used to represent regions. This is common for shallow embeddings; interpretation functions like inRegion can make direct use of the operations used in the representation. All the other functions encode what it means for a point to be inside the respective region.

We characterize deep embeddings as follows:
                        Definition 2
                        A deep embedding represents language constructs as constructors in an abstract syntax tree.

Writing the functions for constructing new regions becomes trivial. It is simply a matter of returning the right constructor. The hard work is instead done in the interpretation function inRegion which has to interpret the meaning of each constructor.

As the above example EDSL illustrates, a shallow embedding makes it easier to add new language constructs – as long as they can be represented in the semantic domain. For instance, it would be easy to add a function rectangle to our region example. On the other hand, since the semantic domain is fixed, adding a different form of interpretation, say, computing the area of a region, would not be possible without a complete reimplementation.

In the deep embedding, we can easily add new interpretations (just add a new function like inRegion), but it comes at the price of having a fixed set of language constructs. Adding a new construct to the deep implementation requires updating the Region type as well as all existing interpretation functions.

This comparison shows that shallow and deep embeddings are dual in the sense that the former is extensible with regards to adding language constructs while the latter is extensible with regards to adding interpretations. The holy grail of embedded language implementation is to be able to combine the advantages of shallow and deep in a single implementation. This is an instance of the expression problem 
                        [43].

One way to work around the limitation of deep embeddings not being extensible is to use “derived constructs”. An example of a derived construct is annulus, which we defined in terms of outside, circle and 
                           (
                           ∩
                           )
                        . Derived constructs are shallow in the sense that they do not have a direct correspondence in the underlying embedding. Shallow derived constructs of a deep embedding are particularly interesting as they inherit most advantages of both shallow and deep embeddings. They can be added with the same ease as constructs in a fully shallow embedding. Yet, the interpretation functions only need to be aware of the deep constructs, which means that we retain the freedom of interpretation available in deep embeddings. There are, of course, limitations to how far these advantages can be stretched. We will return to this point in the concluding discussion (Section 9).

The use of shallow derived constructs is quite common in deeply embedded DSLs. However, the technique presented in this paper is novel and goes beyond “simple” derived constructs to extensions with new interface types leading to drastically different interfaces.

One existing solution to the problem of extending deep embeddings is Data Types á la Carte [41]. It makes it possible to define several independent data types and combine them to a single deep embedding in a modular way. However, regardless of this modularity, extending a deep embedding makes the language larger and increases the number of cases that need to be handled when traversing expressions. In contrast, our approach allows the definition of rich languages on top of simple deep embeddings. It is often possible to extend the language with no or minimal changes to the compiler when using our approach.

To be clear, our technique is not in competition with Data Types á la Carte. The two techniques complement each other and can be combined just fine [2,31].

We assume a setting where we want an EDSL that generates code. Code generation tends to require intensional analysis of the AST, which is not directly possible with a shallow implementation. Hence, we will start with a deep embedding as a basis. Our technique can be summarized in the following steps:
                        
                           1.
                           Implement a deeply embedded core language. The aim of the core language is not to act as a convenient user interface, but rather to support efficient generation of common code patterns in the target language. For this reason, the core language should be kept as simple as possible.

Implement user-friendly interfaces as shallow embeddings on top of the core language. Each interface is represented by a separate type and operations on this type.

Give each interface a precise meaning by giving a translation to and from a corresponding core language program. In other words, make the deep embedding the semantic domain of the shallow embedding. This is done by means of type class instantiation. If such a translation is not possible, or not efficient, extend the core language as necessary.

In the sections that follow we will demonstrate our technique by defining a deep embedding and showing a number of examples of shallow extensions. For the sake of concreteness we have made some superficial choices which are orthogonal to our technique. In particular, we use a typed representation of the deep embedding and employ higher order abstract syntax to deal with binding constructs. Neither of these choices matters for the applicability of our technique.

To demonstrate our technique we will use a small embedded language called FunC as our running example.

The data type describing the FunC abstract syntax tree can be seen in Fig. 1
                        .
                           1
                        
                        
                           1
                           We use a serif font to refer to the language FunC, and sans serif to refer to the data type implementation FunC.
                         FunC is a low level, pure functional language which has a straightforward translation into C. It is meant for embedding low level programs and is inspired by the core language used in Feldspar [4]. We use a GADT to give precise types to the different constructors. We have also chosen Higher Order Abstract Syntax (HOAS) [33] for the Lam constructor.

The first two constructors, :$ and Lam, correspond to application and abstraction in the lambda calculus. Then there are a number of symbols for different language constructs: Lit introduces a literal; If introduces a function for testing booleans; While introduces a functional while loop (explained in Section 4.3); Pair, Fst and Snd are for constructing and eliminating pairs; Prim introduces a primitive function.

The last two constructors, Value and Variable, are not part of the language. They are used internally for evaluation and printing respectively (see Sections 4.4 and 4.10). It would be possible to avoid these odd constructors by using a parameteric HOAS representation [10], but we have opted for a simpler representation in this paper.

Instead of letting the user write explicit applications, we can define smart constructors corresponding to the different symbols: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The Prim symbol introduces a primitive function from a name (used for printing and code generation) and a semantic function (used for evaluation). We can use Prim and Lit to instantiate the Num class for FunC: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        Note that the arity of the semantic function passed to Prim determines the number of applications needed. With the above Num instance, we can write FunC expressions that look like ordinary Haskell; for example, 10 + 5 :: FunC Int.

While numeric literals are conveniently introduced using the Num instance, boolean literals are written using the following definitions: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

We will also be using comparison and integral operators in FunC. For tiresome reasons it is not possible to overload the methods of the corresponding type classes Eq, Ord and Integral: for example, the == operator returns a Haskell Bool and there is no way we can change that to fit the types of FunC. Instead we will simply assume that the standard definitions of the comparison and integral operators are hidden and we will use definitions specific to FunC.

The While symbol has a higher-order type: 
                           (
                           s
                           →
                           Bool
                           )
                           →
                           (
                           s
                           →
                           s
                           )
                           →
                           s
                           →
                           s
                        . Seen as an ordinary Haskell function, it is supposed to work as follows: the first argument is a function that determines whether or not to continue based on the current state (of type s); the second argument is the step function that computes the next state from the current state; the third argument is the initial state; the result is the final state. The reason for having a step function is that FunC is pure, so the body of the loop cannot perform side-effects.

A first attempt to make a smart constructor for While might lead to the following definition: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The problem with this function is that it expects FunC expressions of function types as argument. Such expressions can be created using Lam or some of the symbols of FunC. However, using symbols to construct the function expression is generally not a good idea, because when analyzing or compiling expressions we usually want the state of the while loop to be associated with a variable. So, since we always want to use Lam for these arguments, it is convenient to let the smart constructor insert Lam automatically for us: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        Now the while loop starts to look like an ordinary higher-order Haskell function, and we can even write some examples with it. The following toy program computes the smallest multiple of 2 that is greater than 100: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Being based on the lambda calculus, FunC can represent arbitrary higher-order expressions. This is problematic if we want to generate efficient low-level code from FunC. In Section 7, we will discuss how to restrict the use of higher-order expressions, so that efficient code can be generated.

@&#EVALUATION@&#

The exact semantics of the FunC language is given by the eval function which maps a FunC expression to the corresponding Haskell expression: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Evaluation of the Lam constructor uses a standard technique for folding HOAS terms [18]. The argument f is of type 
                           FunC
                           
                           a
                           →
                           FunC
                           
                           b
                         and we need to return something of type 
                           a
                           →
                           b
                        . This is done by using Value to convert a to FunC a, apply the function f, and finally use eval to convert the resulting b to FunC b. Our only use of the Value constructor is in eval.

There is no case for Variable in eval. This is because Variable is not part of the FunC language, but only a technicality used for inspecting AST (see Section 4.10).

Note that application maps to strict application in Haskell, reflecting the fact that FunC is meant to be compiled to targets without support for lazy evaluation.

So far our presentation of FunC has been a purely deep embedding. Our goal is to be able to add shallow embeddings on top of the deep embedding and in order to make that possible we will make our language extensible using a type class. This type class will encompass all the types that can be compiled into the FunC language. We call the type class Syntactic (inspired by a less general class of the same name in Pan [16]). 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

When making an instance of the class Syntactic for a type T one must specify how T will represented internally, in the already existing deep embedding. This is what the associated type Internal is for. The two functions toFunC and fromFunC translate back and forth between an element of type T and its FunC term representation.

It is generally not the case that toFunC and fromFunC are each other׳s inverses; however, they must preserve the semantics of the expression:
                           Law 1
                           For all types t in the Syntactic class and all expressions 
                                 a
                                 
                                 
                                 
                                 
                                 ::
                                 
                                 
                                 FunC
                                 
                                 (
                                 Internal
                                 
                                 t
                                 )
                               the following must hold:

The first instance of Syntactic is simply FunC itself, and the instance is completely straightforward. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

In Section 4.1, we defined smart constructors to make it easier to construct FunC expressions. Now that we have the Syntactic class we can give an even nicer extensible interface to the programmer. This interface will mirror the deep embedding and its constructors but will use the class Syntactic to overload the functions to make them compatible with any type that we choose to make an instance of Syntactic. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

When specifying the types in our new interface we note that base types are not overloaded, they are still on the form FunC Bool. The big difference is when we have polymorphic functions. The function ifC works for any a as long as it is an instance of Syntactic. The advantage of the type 
                           Syntactic
                           
                           a
                           ⇒
                           FunC
                           
                           Bool
                           →
                           a
                           →
                           a
                           →
                           a
                         over 
                           FunC
                           
                           Bool
                           →
                           FunC
                           
                           a
                           →
                           FunC
                           
                           a
                           →
                           FunC
                           
                           a
                         is two-fold: First, it is closer to the type that an ordinary Haskell function would have and so it gives the function a more native feel, like it is less of a library and more of a language. Second, it makes the language extensible. These functions can now be used with any type that is an instance of Syntactic. We are no longer tied to working solely on the abstract syntax tree FunC.

We have not yet given an interface for pairs. The reason for this is that they provide an excellent opportunity to demonstrate our technique. We simply instantiate the Syntactic class for Haskell pairs: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        In this instance, toFunC constructs an embedded pair from a Haskell pair, and fromFunC eliminates an embedded pair by selecting the first and second components and returning these as a Haskell pair.
                           2
                        
                        
                           2
                           Note that the argument p is duplicated in the definition of from6FunC. If both components are later used in the program, this means that the syntax tree will contain two copies of p. For this reason, having tuples in the language usually requires some way of recovering sharing (see Section 7.2). This issue is, however, orthogonal to the ideas presented in this paper.
                        
                     

The usefulness of pairs comes in when we need an existing function to operate on a compound value rather than a single value. For example, the state of the while loop is a single value. If we want the state to consist of, say, two integers, we use a pair. Since functions such as ifC and while are overloaded using Syntactic, there is no need for the user to construct compound values explicitly; this is done automatically by the overloaded interface.

As an example of this, here is a for loop defined using the while construct with a compound state: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The first argument to forLoop is the number of iterations; the second argument is the initial state; the third argument is the step function which, given the current loop index and current state, computes the next state. We define forLoop using a while loop whose state is a pair of an integer and a smaller state.

Note that the above definition only uses ordinary Haskell pairs: the continue condition and step function of the while loop pattern match on the state using ordinary pair syntax, and the initial state is constructed as a standard Haskell pair.

Another example of using the while loop and pairs together is the following implementation of the greatest common divisor algorithm: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The state of the while loop is two integers where the smaller integer is subtracted from the larger until they are equal.

Writing smart constructors such as ifC and while is quite a boring task, and it would be nice to be able to automate it. Consider the While symbol and the corresponding non−overloaded smart constructor: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        We can say that the purpose of the smart constructor is to move all function arrows from inside the parameter of FunC to the outside. This is done because it is more convenient for the user to deal with ordinary Haskell functions than using explicit application and abstraction in FunC.

However, from a semantic point of view, the types 
                           (
                           FunC
                           
                           a
                           →
                           FunC
                           
                           b
                           )
                         and 
                           FunC
                           
                           (
                           a
                           →
                           b
                           )
                         are equivalent: we can use :$ and Lam to convert between the two without changing the meaning of the program. This correspondence can be captured by declaring a Syntactic instance for functions: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Note that a and b can be any types in the Syntactic class. Somewhat magically, the above instance lets us derive the whole implementation of the smart constructor automatically: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        Not only that; since the instance works for any a and b in Syntactic, we can also derive the overloaded version in the same way: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

To see how this works, we show a stepwise expansion of the definition: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        We recognize the last step as the definition we gave for while in Section 4.5.

From now on, we will only use smart constructors derived from fromFunC, and there will be no need for explicit uses of :$ and Lam.

If we want to extend our language with optional values, one may be tempted to make a Syntactic instance for Maybe. Unfortunately, there is no way to make this work, because fromFunC would have to decide whether to return Just or Nothing when the Haskell program is evaluated, which is one stage earlier than when the FunC program is evaluated. Instead, we can use the following implementation: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

We have borrowed the name Option from ML to avoid clashing with the name of the Haskell type. The type Option is represented as a boolean and a value.
                           3
                        
                        
                           3
                           Larger unions can be encoded using an integer instead of a boolean.
                         The boolean indicates whether the value is valid or whether it should simply be ignored, effectively interpreting it as not being there. The Syntactic instance converts to and from the representation in FunC which is a pair of a boolean and the value.

The definition of Option may seem straightforward, but when we try to create an empty Option value, we run into problems. We need some value to put into the second component of the pair. It is not important what value we put there, since it is not going to be looked at anyway, but the problem is that we need a polymorphic value, because we want to be able to create empty Option values of arbitrary types. One alternative would be to extend FunC with a bottom value, analogous to Haskell׳s undefined, but that seems quite unsatisfactory. A better alternative is to introduce a type class that lets us construct arbitrary “example″values of different types:
                           4
                        
                        
                           4
                           Thanks to Phil Wadler for the idea to use a type class rather than a bottom value.
                         
                        
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The example method just has to produce an example value of each type. What specific value it produces is irrelevant.

Armed with the Inhabited class, we can now provide functions for constructing and eliminating optional values: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The some function creates an optional value which actually contains a value whereas none defines an empty value using the newly introduced example method. The function option acts as a case on optional values, allowing the programmer to test an Option value to see whether it contains something or not.

The functions above provide a nice programmer interface but the real power of the shallow embedding of the Option type comes from the fact that we can make it an instance of standard Haskell classes. In particular we can make it an instance of Functor and Monad. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Being able to reuse standard Haskell functions is a great advantage as it helps us to decrease the cognitive load of the programmer when learning our new language. We can map any Haskell function on the element of an optional value because we chose to let the element of the Option type to be completely polymorphic, which is why these instances type check.

The advantage of reusing Haskell׳s standard classes is particularly powerful in the case of the Monad class because it has syntactic support in Haskell which means that it can be reused for our embedded language. For example, suppose that we have a function 
                           divF
                           
                           
                           
                           
                           ::
                           
                           
                           FunC
                           
                           Float
                           →
                           FunC
                           
                           Float
                           →
                           Option
                           
                           (
                           FunC
                           
                           Float
                           )
                         which returns nothing in the case the divisor is zero. Then we can write a function for computing the resistance of two parallel resistors as follows: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Our language FunC is intended to target low level programming. In this domain most programs deal with sequences of data, typically in the form of arrays. In this section we will see how we can extend FunC to provide a nice interface to array programming.

The first thing to note is that FunC does not have any support for arrays at the moment. We will therefore have to extend FunC to accommodate this. The addition we have chosen is one constructor which computes an array plus two constructors for accessing the length and indexing into the array respectively: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The first argument of the Arr constructor computes the length of the array. The second argument is a function which given an index computes the element at that index. By repeatedly calling the function for each index we can construct the whole array this way. The meaning of ArrLen and ArrIx should require little explanation. The exact semantics of these constructors is given by the corresponding clauses in the eval function. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

We will use two convenience functions for dealing with length and indexing: len which computes the length of the array and the infix operator 
                           (
                           <
                           !
                           >
                           )
                         which is used to index into the array. As usual we have overloaded 
                           (
                           <
                           !
                           >
                           )
                         so that it can be used with any type in the Syntactic class. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Having extended our deep embedding to support arrays we are now ready to provide the shallow embedding. In order to avoid confusion between the two embeddings we will refer to the shallow embedding as vector instead of array. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The type Vector forms the shallow embedding and its constructor Indexed is strikingly similar to the Arr construct. The only difference is that Indexed is completely polymorphic in the element type. One of the advantages of a polymorphic element type is that we can have any type which is an instance of Syntactic in vectors, not only values which are deeply embedded. Indeed we can even have vectors of vectors which can be used as a simple (although not very efficient) representation of matrices.

The Syntactic instance converts vectors into arrays and back. It is mostly straightforward except that elements of vectors need not be deeply embedded so they must in turn be converted using toFunC. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        The above code listing shows some examples of primitive functions for vectors. The call zipWith f v1 v2 combines the two vectors v1 and v2 pointwise using the function f. The sumVec function computes the sum of all the elements of a vector using the for loop defined in Section 4.6. Finally, just as with the Option type in Section 4.8 we can define an instance of the class Functor.

Many more functions can be defined for our Vector type. In particular, any kind of function where each vector element can be computed independently will work particularly well with the representation we have chosen. However, functions that require sharing of previously computed results (e.g. Haskell׳s unfoldr) will yield poor code. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        An example of using the functions presented above we define the function scalarProd which computes the scalar product of two vectors. It works by first multiplying the two vectors pointwise using zipWithVec. The resulting vector is then summed to yield the final answer.


                        Fig. 2
                         shows the conversion from FunC to a tree (from the standard Haskell module Data.Tree). The helper function toTreeArgs uses the State monad to be able to generate fresh variable names, and it takes a list of children as arguments. The purpose of the list is to accumulate applications so that all arguments of a function expression become children to the same node. The only case where :$ shows up in the tree is when we have a Lam that is immediately applied. However, such expressions do not appear in the examples given in this paper.

Just like in eval, we need to pass an expression to the function in a Lam node in order to be able to examine the body. However, in this case we pass a Variable with a freshly generated name instead of a Value.


                        Fig. 3
                         shows the tree produced from the expression toFunC scalarProd. It has been rendered using the tree-view package.
                           5
                        
                        
                           5
                           
                              http://hackage.haskell.org/package/tree-view
                           
                         It is interesting to see that the generated tree is a simple expression with a single loop. In the next section we will see how this expression is obtained from the definition of scalarProd.

We note in passing that most other examples in this paper result in ASTs that are too large to present in the paper. The reason is lack of sharing in the generated expressions and lack of syntactic simplification. This problem is solved by a combination of common sub-expression elimination and a number of mostly trivial simplification rules. We return to this point in Section 7.

Choosing to implement vectors as a shallow embedding has a very powerful consequence: it provides a very lightweight implementation of fusion [23]. We will demonstrate this using the function scalarProd defined in the previous section. Upon a first glance it may seem as if this function computes an intermediate vector, the vector zipWithVec (⁎) a b which is then consumed by the sumVec. This intermediate vector would be quite bad for performance and space reasons if we ever wanted to use the scalarProd function as defined.

Luckily the intermediate vector is never computed as we see in Fig. 3. To see why this is the case consider what happens when we generate code for the expression scalarProd v1 v2, where v1 and v2 are defined as Indexed l1 ixf1 and Indexed l2 ixf2 respectively. Before generating an abstract syntax tree the Haskell evaluation mechanism will reduce the expression as follows: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     The intermediate vector has disappeared and the only thing left is a for loop which computes the scalar product directly from the two argument vectors.

In the above example, fusion happened because although zipWithVec constructs a vector, it does not generate an array in the deep embedding. In fact, all standard vector operations (fmap, take, reverse, etc.) can be defined in a similar manner, without using internal storage. Whenever two such functions are composed, the intermediate vector is guaranteed to be eliminated. This guarantee by far exceeds guarantees given by conventional optimizing compilers.

So far, we have only seen one example of a vector producing function that uses internal storage: fromFunC. Thus intermediate vectors produced by fromFunC (for example as the result of ifC or while) will generally not be eliminated.

There are some situations when fusion is not beneficial, for instance in a function which access an element of a vector more than once. This will cause the elements to be recomputed. It is therefore important that the programmer has some way of backing out of using fusion and store the vector to memory. For this purpose we can provide the following function: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     The function memorize can be inserted between two functions to make sure that the intermediate vector is stored to memory. For example, if we wish to store the intermediate vector in our scalarProd function we can define it as follows: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     Strong guarantees for fusion in combination with the function memorize gives the programmer a very simple interface which still provides powerful optimizations and fine grained control over memory usage.

The Vector type is very useful for writing array computations in a compositional style. Unfortunately, not all computations are efficiently implementable with the Vector type. One example is to compute the scan of a vector. The following is an inefficient implementation: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        This implementation will perform a lot of duplicate computations. An efficient implementation would avoid recomputations by linearly iterating through the array and use an accumulating parameter to store the intermediate results. The Vector type does not permit such an implementation because each element is computed and accessed independently; there is no way to impose a particular order in which the elements are traversed. We must turn to a different representation in order to implement scan efficiently.

The type of sequential vectors imposes a linear, left-to-right traversal order of the elements. We can construct a shallow embedding as follows: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The type Seq contains a hidden piece of state; the existentially bound type variable s. The first argument to the constructor is an initial state. The state is consumed by the stepper function, the second argument to Seq, which produces a new element in the vector and a new state. The last argument is the length of the vector.

The type Seq permits an efficient implementation of scan: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

We refrain from going into the full details about how to implement a full library for the Seq type. In summary, we make the following observations:
                           
                              •
                              To construct a Syntactic instance for Seq requires a new constructor in the deep embedding: 
                                    
                                       
                                          
                                             
                                                
                                             
                                          
                                       
                                    
                                 
                              

The type Seq provides a complementary set of operations compared to Vector. For example, scanning is provided for Seq while random access indexing is not.

Operations on Seq enjoy the same kind of fusion guarantees as the operations on Vector.

It is possible to convert from Vector to Seq while still preserving guaranteed fusion, using the following function: 
                                    
                                       
                                          
                                             
                                                
                                             
                                          
                                       
                                    
                                 Converting from Seq to Vector requires storing to memory (i.e. introducing a Sequential node in the deep embedding).

There is a third kind of vector which provides yet another, complementary set of operations; push vectors [13]. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The first argument to the Push constructor can be thought of as a program which writes an array to memory. Writing to memory is an inherently imperative operation and fits badly with the functional nature of the language wehave presented so far. The solution is to use monads, and the type M is a monad for writing to memory. We return to explaining push vectors once we have covered how to embed monads.

It is sometimes useful to include monads in a domain specific language, for the same reason they are useful in Haskell: to isolate effectful computations from pure computations using the type system. In Section 4.8 we saw that the Option could be made an instance of the typeclass Monad. This monad was constructed using building blocks already available in the deep representation of the language. In this section we will see how to build generic support for monads where the monadic operations are represented as new explicit constructors.

The first step in adding support for monads in our language is to enrich our deep embedding with the constructors Return and Bind, corresponding to the two operations in the standard Monad class. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

Although the types for these constructors are similar to the monad operations, they cannot be used directly as implementations in an instance for the Monad class, since they are merely symbols. We show how to get around that below.

Defining the semantics for Return and Bind is straightforward: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

The user interface for monads consists of the type Mon, which provides a shallow embedding which lifts an arbitrary monad in Haskell into the embedded language, and a Monad instance for Mon. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

Readers with prior knowledge about monads will recognize that Mon is similar to the continuation passing monad. The difference is that the answer type has been specialized to generate syntax trees.

Using the continuation monad on top of the deep embedding has a fortunate side effect: it normalizes monadic expression. Certain monads suffer an asymptotic slowdown if compositions of the 
                        
                      operator are associated to the left: writing e.g. 
                        
                      is more costly to evaluate than writing 
                        
                     . Luckily, the continuation monad transformer will associate 
                        
                      in the underlying monad to the right, ensuring efficient execution [42]. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

It is possible to provide a Syntactic instance for Mon as shown above. This makes monadic computations first class citizens in the DSL – a very powerful addition. Though, depending on what kind of target code we want to generate, we might not want to allow passing around monadic computations as that would entail creating closures. In Section 7.4, we elaborate on how to constrain the types of the symbols in FunC to rule out such problematic code.

The type Mon provides a generic building block for constructing particular monads in our DSL. As a concrete example, we will implement a monad which adds mutable arrays to our language. Haskell׳s standard library for mutable arrays will stand as a model for our extension. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

The construct NewArray allocates a new, uninitialized array. The length is determined by the first argument. GetArray and PutArray reads from and writes to an array (the semantics for using an out of bounds index is undefined), respectively. The length of an array is given by LengthArray. FreezeArray and ThawArray provide a way to convert back and forth between mutable and immutable arrays.

Compared to previous language features, this list of constructors is a big addition to our deep embedding. This is not surprising, given that references and arrays are primitive types that require special primitive operations. In the following sub-sections, we will see how these primitive operations enable the definition of shallow high-level data structures. It turns out that these extra primitive operations give us quite a lot in return!

The code below provides the user interface for the array constructs. We define a new type M which captures computations with mutable arrays. The type Marr is a convenient alias when using arrays. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

The result type M () of putArray requires the existence of a Syntactic instance for (), something which is trivial to define.

When working with arrays it is crucial to be able to perform loops over them. Since we have a Monad instance for our embedded monad, it is natural to think that we can use the standard control operators for loops provided by the standard library in Haskell. But these control operators would be evaluated at compile time and there would be no loops left in the generated code. For that reason, the loops could not depend on any runtime data, which would be overly restrictive. So we are left with using looping constructs defined in our deep representation. The existing while loop is not directly suited to represent monadic loops, so instead we add two new constructs. 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

The user interface for monadic loops is as follows: 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

An example of how to use the mutable array interface is the following implementation of in-place insertion sort (we assume the existence of mutable references implemented similar to mutable arrays). 
                        
                           
                              
                                 
                                    
                                 
                              
                           
                        
                     
                  

One might be worried about the fact that the FunC type keeps growing whenever we add new primitives. This problem can be alleviated by using Data Type á la Carte [41] to divide the primitive operations into several independent types. In fact, our earlier work on embedding monads was based on Data Type á la Carte [31].

As mentioned in the previous section, there is a form of vector which uses monads to write to memory: push vectors [13]. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The implementation of Push contains a monadic program which writes the array to memory. It is parameterized on a function of type 
                           FunC
                           
                           Int
                           →
                           a
                           →
                           M
                           
                           (
                           )
                        . This is the function that performs the actual writing, given an index and an array element. The monadic program is responsible for iterating over all the index-value-pairs of the array and call the writing function on each one of them. As a first example of how to construct push vectors we give a function which enumerates integers: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     


                        Push solves two problems which neither Vector nor Seq can handle: efficient concatenation and computing several elements at once. Here׳s how we can implement concatenation of two push vectors: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Concatenation is given two push vectors, containing two monadic programs for writing them to memory, f1 and f2. When constructing the program for the resulting push vector, f, we first run f1 to write that vector to memory. Then f2 is allowed to run, but the index where it writes its elements is adjusted so that they are written after the first vector.

An observation is that the two programs f1 and f2 write to completely separate memory locations. That means that they could be executed in parallel for increased speed. Push vectors support several operations which can be parallelized in this way [13,1].

As an example of computing several elements at once, we use the dup function below. It performs the same operation as concatenating a vector with itself, but makes sure not to duplicate the computation of the elements, which can otherwise happen. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Although dup is only meant as a pedagogical example, similar patterns happen in real life applications. For example, when scaling up an image to cover more pixels, several pixels are produced at every iteration in the computation. 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Storing a push vector means allocating a mutable array in memory, then make the push vector program write to that array by feeding it a function which performs the write. Finally, the mutable array is frozen and the result is an immutable array. The whole computation lives in the M monad, since there is no way to escape it. It is possible to provide an embedding like the ST monad, which can encapsulate imperative algorithms in a purely functional interface [29]. Such an embedding would enable a purely functional interface to store, and would enable a Syntactic instance.

In summary, push vectors provide yet another useful abstraction for array processing. Their implementation is particularly convenient thanks to the embedding of monads, it is almost as writing normal Haskell.

The data structures we have seen so far, such as pairs, Option, Vector, Seq, and even Push, have had purely functional interfaces (with the exception of the store function). The introduction of monads in the language opens up for the possibility of creating mutable data structures. When writing streaming applications it is common to use a mutable cyclic buffer. We can implement such a buffer in our language as a shallow embedding: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The implementation of this buffer is reminiscent of how classes are implemented in object oriented languages. The data type contains the public methods exposed to the programmer using the buffer. The hidden members and data are stored in the closure created when the buffer is constructed. The following function constructs a buffer: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

Constructing a Buffer begins with allocating a mutable array which will contain the payload, and a reference for keeping track of where the first element in the buffer is located in the array. The two functions get and put read and write to the appropriate locations in the mutable array using the reference, respectively.

As an example of how to use the circular buffer, the following program computes the nth fibonacci number: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

In this paper we have used a simple implementation to be able to focus on the basic ideas. In order to scale up the method to a full-blown EDSL implementation such as Feldspar [4], there are a few things that need to be taken care of:
                        
                           •
                           The front end needs to be extended with more primitive functions. For example, in Feldspar we have reimplemented many of Haskell׳s Prelude functions, including most methods of classes such as Eq, Ord, Integral, and Floating.

In order to avoid duplication of code and run-time computation, there has to be a way to discover and represent shared sub-expressions.

Despite high-level optimizations in the shallow embedding (such as fusion; see Section 5), there are often opportunities to simplify the generated ASTs in order to generate more efficient code.

We need a translator from expressions to C code (or similar). This requires making some changes to FunC to rule out higher-order terms that are not easily compiled to a low-level target.

The following sub-sections discuss the above points in a bit more detail.

The three latter points in the above list involve traversing and transforming FunC expressions in various ways. This turns out to be very inconvenient when using higher-order abstract syntax (HOAS), as in this paper. Instead a first-order representation is generally preferred when the AST needs to be examined. At the same time, HOAS comes with some definite advantages:
                           
                              •
                              It makes it easy to define higher-order front end functions (such as the while loop in this paper).

It makes evaluation both easy to define and very efficient due to the fact that substitution is performed directly by the function embedded in the AST.

One way to get the best of both worlds is to have two versions of the AST: a higher-order one and a first-order one with a function converting from the former to the latter. The higher-order one is used in the front end and possibly for evaluation, while the first-order one is used in the rest of the implementation. The disadvantage of this approach is that it requires two separate but very similar data types as representations of the same AST. Conversion from a higher-order to a first-order AST can be done using the same method as the rendering in Section 4.10.

Two EDSLs that use a combination of higher-order and first-order ASTs are Feldspar (until version 0.7) [4] and Accelerate [30].

In order to avoid having two separate representations of the same AST, it is possible to make a higher-order front end directly for a first-order AST by using a technique based on circular programming [3]. We plan to use this technique to get rid of the HOAS representation in future versions of Feldspar.

It is easy to write EDSL programs that result in duplicated sub-expressions. For example, the expression let a=bigExpr in a+a results in an AST that contains two copies of bigExpr. This is because Haskell bindings are inlined as part of Haskell׳s evaluation when generating an AST. This loss of sharing is problematic for two reasons: (1) it makes the AST larger which can slow down the compiler and lead to larger generated code, and (2) it leads to duplicated computations in the generated code which can increase its run time.

The problem with large ASTs is more severe than it may seem at first. An expression with nested duplications – for example 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        – generates an AST which is exponentially larger than the corresponding Haskell expression.

Such expressions do actually occur in practice. The following innocent-looking function from Feldspar׳s source uses bit manipulation to compute the number of leading zeros in a machine word: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        Here, foldl is the normal left fold for Haskell lists, which means that nlz builds up an unrolled expression by repeatedly applying the go function. The problem with this is that the b parameter is used twice in the body of go which means that the size of the resulting expression is 
                           O
                           (
                           
                              
                                 2
                              
                              
                                 n
                              
                           
                           )
                        , where n is the number of calls to go. (The function has now been fixed by inserting an explicit sharing construct for b.)

Several techniques can be used to handle sharing in EDSLs:


                        Implicit sharing: Standard common sub-expression elimination (CSE) can be employed to remove duplications in the generated code. However, it does not fix the problem with large ASTs slowing down the compiler. This is because CSE has to traverse the whole expression in order to know which sub-expressions to share.


                        Observable sharing: By observing how the AST is stored in the heap, it is possible to recreate the sharing structure of the Haskell expression that generated the AST [12,21]. The problem with observable sharing is that it is somewhat fragile: a Haskell compiler is free to store data structures as it likes, and the amount of sharing may very well depend on the implementation at hand, optimization flags, etc.


                        Explicit sharing: A different approach is to be completely explicit about sharing. In FunC, we could represent explicit sharing by the following construct: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

These three techniques can be combined in various ways. Kiselyov proposes using a combination of explicit and implicit sharing [28]. Hash-consing is used to introduce sharing of equal sub-expressions, and an explicit sharing construct can be used to manage the size of the expression. Similarly, it is possible to use observable sharing to speed up implicit sharing. This approach is taken by Elliott et al. in the Pan EDSL [16], and it has the advantage of not being sensitive to the unpredictable behavior of observable sharing.

There is a slight complication when using observable sharing together with HOAS: sharing has to be detected while converting the HOAS to a first-order representation [30]. It cannot be done before the conversion because a HOAS data structure is not easily inspectable, and it cannot be done after the conversion because by then the conversion has destroyed all sharing.

Despite high-level optimizations in the shallow embedding (such as fusion, see Section 5), there are often opportunities to simplify the generated ASTs in order to generate more efficient code.

Many simplification rules can be performed directly in the front end using “smart constructors” [16]. For example, the following definitions of (+) and 
                           (
                           <
                           !
                           >
                           )
                         can return simpler expressions depending on the form of the arguments: 
                           
                              
                                 
                                    
                                       
                                    
                                 
                              
                           
                        
                     

The disadvantage of simplification in the front end is that it is limited to context-free rules. More sophisticated optimizations must therefore be done as separate passes on the generated AST (after conversion to a first-order representation in the case of HOAS).

Elliott et al. [16] and McDonnel et al. [30] give more information on optimization of EDSL programs.

If we want to generate efficient low-level code from FunC we are faced with a problem: since FunC is based on the lambda calculus, we may need to compile arbitrary higher-order terms which generally do not map well to efficient low-level code. However, none of the examples in this paper involves such problematic terms. In particular, the only sub-expressions of higher-order type (i.e. of the form 
                           (
                           (
                           
                              
                                 t
                              
                              
                                 1
                              
                           
                           →
                           
                              
                                 t
                              
                              
                                 2
                              
                           
                           )
                           →
                           
                              
                                 t
                              
                              
                                 3
                              
                           
                           )
                        ) are higher-order symbols like While and Sequential.

Generating code for the higher-order symbols is unproblematic. For example, the expression While :$ Lam cont :$ Lam body :$ init can be handled as follows:
                           
                              •
                              Generate a fresh name s.

Recursively generate code for the sub-expressions cont (Variable s) and body (Variable s).

Put the resulting pieces of code together in a loop.

Here we see that the code generator does not view the function arguments of While as functions, but rather as expressions with one extra free variable – and this variable is the state of the loop. We can generate code for all the other higher-order symbols in a similar way.

We have seen that restricting programs so that higher-order types only appear for expressions that the code generator knows how to handle ensures that we can generate first-order code from FunC. This restriction can be enforced by constraining the type of Lam: 
                              
                                 
                                    
                                       
                                          
                                       
                                    
                                 
                              
                           The Type class captures simple types that can be stored in variables in the target language (e.g. Int, Bool, Float, and Array Int Int). This is a class without methods, and it is only used to restrict the set of expressions we can construct.

We will now argue for why the restricted type of Lam rules out arbitrary higher-order types.
                              Definition 3
                              A higher-order type is a type of the form 
                                    (
                                    (
                                    
                                       
                                          t
                                       
                                       
                                          1
                                       
                                    
                                    →
                                    
                                       
                                          t
                                       
                                       
                                          2
                                       
                                    
                                    )
                                    →
                                    
                                       
                                          t
                                       
                                       
                                          3
                                       
                                    
                                    )
                                 .

A compiler-known expression is a FunC symbol applied to zero or more arguments. We assume that the compiler knows how to translate a compiler-known expression, even if it has a higher-order type.


                                 For all expressions 
                                 e :: FunC a, if 
                                 a 
                                 is a higher-order type, then 
                                 e 
                                 is a compiler-known expression.

All symbols are trivially compiler-known. Lam cannot result in a higher-order expression due to the Type constraint. The only form of expression left to examine is e=(f :$ a) :: b, where 
                                    f
                                    
                                    
                                    
                                    
                                    
                                    ::
                                    
                                    
                                    FunC
                                    (
                                    a
                                    →
                                    b
                                    )
                                  and a :: FunC a. By induction, f is either a compiler-known expression, or 
                                    a
                                    →
                                    b
                                  is a first-order type. Hence, either e is a compiler-known expression, or b is a first-order type.□

The reasoning so far assumes that FunC has been designed so that all symbols can be handled by the code generator. For this to be the case, we also need to constrain the types of certain symbols. For example, Lit needs a Type constraint to ensure that we can only create literals of simple representable types: 
                              
                                 
                                    
                                       
                                          
                                       
                                    
                                 
                              
                           
                        

As mentioned in Section 6, we may need to rule out code that entails representing monadic actions as values in the host language. Again, we can do this by placing a Type constraint on polymorphic symbols like If and While: 
                              
                                 
                                    
                                       
                                          
                                       
                                    
                                 
                              
                           
                        

Note that the above constraints will also show up in the user interface. For example, ifC will get the type: 
                              
                                 
                                    
                                       
                                          
                                       
                                    
                                 
                              
                           
                        

@&#RELATED WORK@&#

The Feldspar EDSL [5] makes use of the techniques described in this paper. We have found that Feldspar׳s design with a simple core language extended with shallow high-level libraries makes it easy to explore new ideas without investing a lot of implementation effort.

The Lightweight Modular Staging framework [35] for Scala enables the implementation of deeply embedded DSLs and offers significant infrastructure for optimization and code generation. Rompf et al. note the benefit of implementing parts of an EDSL as shallow embeddings that expand to a simpler core language – something which they call “deep linguistic reuse” [34].

Gibbons and Wu [20] give an insightful overview of deep and shallow embeddings and discuss their relation in depth. Inspired by our work, they also consider “intermediate embeddings”, where a deeply embedded core language is extended using shallow embeddings.

A practical example of the combination of deep and shallow embedding is the embedded DSL Hydra which targets Functional Hybrid Modelling [24]. Hydra has a shallow embedding of signal relations on top of a deep embedding of equations. However, it does not have anything corresponding to our Syntactic class. Furthermore, it does not seem to take advantage of any fusion-like properties of the embedding nor make any instances of standard Haskell classes.

The work by Elliott et al. on compiling embedded languages [16] has been a great source of inspiration for us. In particular, they use a type class Syntactic whose name gave inspiration to our type class. However, their class is only used for overloading if expressions and not as a general mechanism for extending the embedded language. Just like Elliott et al., we note that deeply embedded compilation relates strongly to partial evaluation. The shallow embeddings we describe can be seen as a compositional and predictable way to describe partial evaluation.

The implementation of Kansas Lava [17] uses a combination of shallow and deep embedding. However, this implementation is quite different from what we are proposing. In our case, we use a nested embedding, where the deep embedding is used as the semantic domain of the shallow embedding. In Kansas Lava, the two embeddings exist in parallel – the shallow embedding is used for evaluation and the deep embedding for compilation. It appears that this design is not intended for extensibility: adding new interpretations is difficult due to the shallow embedding, and adding new constructs is difficult due to the deep embedding.

At the same time, Kansas Lava contains a type class Pack 
                     [22] that has some similarities to our Syntactic class. Indeed, using Pack, Kansas Lava implements support for optional values by mapping them to a pair of a boolean and a value. However, it is not clear from the publications to what extent Pack can be used to develop high-level language extensions and optimizations.

Deep embeddings have the disadvantage of leaking some implementation details to the user (e.g. a deeply embedded integer expression has type FunC Int while a Haskell integer is just an Int). In the Yin–Yang system, Jovanović et al. [26] use Scala macros to translate shallow EDSL programs to the corresponding deep EDSL programs. This allows the user to work in a friendlier shallow embedding while still reaping the benefits of the deep embedding (i.e. higher performance) when needed. Yin–Yang also simplifies EDSL development by automatically generating deep embeddings from shallow ones. In a similar line of work, Scherr and Chiba [36] propose a technique called implicit staging for Java which hides the implementation details of the deep embedding from the user.

While our work has focused on making shallow extensions of deep embeddings, it is also possible to have the extensions as deep embeddings. This approach was used by Claessen and Pace [11] to implement a simple language for behavioral hardware description. The behavioral language is defined as a simple recursive data type whose meaning is given as a function mapping these descriptions into structural hardware descriptions in the EDSL Lava [6].

Our focus in this paper has been on deep and shallow embeddings. But these are not the only techniques for embedding a language into a host language. Another popular method is the Finally Tagless technique [8]. The essence of Finally Tagless is to have an interface which abstracts over all interpretations of the language. In Haskell this is realized by a typeclass where each method corresponds to one language construct. Concrete interpretations are realized by creating a data type and making it an instance of the type class. For example, creating an abstract syntax tree would correspond to one interpretation and would have its own data type, evaluation would be another one. Since new interpretations and constructs can be added modularly (corresponds to adding new interpretation types and new interface classes respectively), Finally Tagless can be said to be a solution to the expression problem.

Our technique can be made to work with Finally Tagless as well. Creating a new embedding on top of an existing embedding simply amounts to creating a subclass of the type class capturing the existing embedding. However, care has to be taken if one would like to emulate a shallow embedding on top of a deep embedding and provide the kind of guarantees that we have shown in this paper. This will require an interpretation which maps some types to their abstract syntax tree representation and some types to their corresponding shallow embedding. Also, it is not possible to define general instances for standard Haskell classes for languages using the Finally Tagless technique. Instances can only be provided by particular interpretations.

As discussed in Section 2.1, Data Types á la Carte is a technique that enables modular definition of deep embeddings [41,14]. It is complementary to the technique presented in this paper, and the two techniques can be usefully combined [2,31].

The way we provide fusion for vectors was first used in the implementation of Feldspar [15]. The same technique was used in the language Obsidian [40] but it has never been documented that Obsidian actually supports fusion. The programming interface is very closely related to that provided by the Repa library [27], including the idea of guaranteeing fusion and providing programmer control for avoiding fusion. Although similar, the ideas were developed completely independently. It should also be noted that our implementation of fusion is vastly simpler than the one employed in Repa.


                     Section 6 presents a solution for the monad reification problem, i.e. observing the structure of monadic computations and converting them to a first order representation. Strictly speaking we do not solve the full problem here since we do not generate first order terms, but it is an easy step to add. The version presented here is a simplified and extended presentation of our previous work [31]. Other solutions include the so-called “Björn and Benny” method [39], which has a particularly simple implementation but where the types become somewhat more contrived, and the normalization method of Sculthorpe et al. [37], which has applications beyond the monadic reification problem. Compiled EDSLs which feature a Monad instance include Feldspar [31], Obsidian [40] and Sunroof [7].

@&#CONCLUSION@&#

The technique described in this paper is a simple, yet powerful, method that gives a partial solution to the expression problem. By having a deep core language, we can add new interpretations without problem. And by means of the Syntactic class, we can add new language types and constructs with minimal effort.

The method offers an advantageous power-to-weight ratio: each construct in the deep embedding typically enables several new functions in the shallow embedding. For example, the three constructs related to immutable arrays (Section 4.9) enable us to define wide range of operations for the Vector type (only a few of which are shown in the paper).

Shallow embeddings allow for utilizing evaluation in the host language for optimization purposes. For example, pairs can be removed statically, operations on Vector can be fused automatically and monadic computations are normalized. These advantages come simply due to the fact that we use shallow embeddings, we do not have to make any extra effort to enable these optimizations.

We have presented a diverse selection of language extensions to demonstrate the idea of combining deep and shallow embeddings. The technique has been used with great success by the Feldspar team during the implementation of Feldspar.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank the Feldspar team for comments and discussions on the ideas presented in this paper. The first author would like to thank the participants of the DSL conference 2011 for the their constructive feedback, when part of the material in this paper was presented as an invited tutorial. We also thank the anonymous reviewers for constructive feedback. Thanks to Philip Wadler for pointing out that the evaluator should be strict and for identifying bugs in our implementation of Option. This research is funded by Ericsson and the Swedish Foundation for Strategic Research (which funds the Resource Aware Functional Programming (RAW FP) Project).

@&#REFERENCES@&#


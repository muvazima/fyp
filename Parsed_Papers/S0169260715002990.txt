@&#MAIN-TITLE@&#Robust estimation of event-related potentials via particle filter

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We constructed a model describing event-related potential (ERP) by trend model.


                        
                        
                           
                           A 400-particle filter produced the best mean square error in the ERP estimation.


                        
                        
                           
                           The filter reduced an amount of average by 42.8% compared with simple averaging.


                        
                        
                           
                           The filter could estimate P300 robustly by application to EEG in P300 speller.


                        
                        
                           
                           Real-time processing is realized in any computer with an appropriate particle number.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Particle filter

Event-related potential

P300

Robust estimation

@&#ABSTRACT@&#


               
               
                  Background and objective
                  In clinical examinations and brain–computer interface (BCI) research, a short electroencephalogram (EEG) measurement time is ideal. The use of event-related potentials (ERPs) relies on both estimation accuracy and processing time. We tested a particle filter that uses a large number of particles to construct a probability distribution.
               
               
                  Methods
                  We constructed a simple model for recording EEG comprising three components: ERPs approximated via a trend model, background waves constructed via an autoregressive model, and noise. We evaluated the performance of the particle filter based on mean squared error (MSE), P300 peak amplitude, and latency. We then compared our filter with the Kalman filter and a conventional simple averaging method. To confirm the efficacy of the filter, we used it to estimate ERP elicited by a P300 BCI speller.
               
               
                  Results
                  A 400-particle filter produced the best MSE. We found that the merit of the filter increased when the original waveform already had a low signal-to-noise ratio (SNR) (i.e., the power ratio between ERP and background EEG). We calculated the amount of averaging necessary after applying a particle filter that produced a result equivalent to that associated with conventional averaging, and determined that the particle filter yielded a maximum 42.8% reduction in measurement time. The particle filter performed better than both the Kalman filter and conventional averaging for a low SNR in terms of both MSE and P300 peak amplitude and latency. For EEG data produced by the P300 speller, we were able to use our filter to obtain ERP waveforms that were stable compared with averages produced by a conventional averaging method, irrespective of the amount of averaging.
               
               
                  Conclusions
                  We confirmed that particle filters are efficacious in reducing the measurement time required during simulations with a low SNR. Additionally, particle filters can perform robust ERP estimation for EEG data produced via a P300 speller.
               
            

@&#INTRODUCTION@&#

Event-related potentials (ERPs) are electroencephalography (EEG) signals evoked by sensory stimuli. Currently, ERPs are applied to clinical diagnoses in various fields, including psychiatry, neurology, and clinical psychology. Among the ERP components, the P300 is a positive potential that appears approximately 300ms after a sensory stimulus. The P300 component is thought to correspond to recognition and judgment processes in the brain. Many researchers have published reports focused on the P300. For instance, Goodin et al. [1] reported that the P300 latencies of people with Alzheimer's disease, Parkinson's disease, and Huntington's disease are delayed in comparison with those of healthy individuals.

In addition to clinical investigations, the P300 has been widely used in brain–computer interface (BCI) research in recent years. BCI development has involved various modes of biological signal measurement, including EEG and electrocorticogram. Among these, EEG is the representative tool because it is relatively inexpensive and simple. In EEG-based BCI, ERPs are easy to comprehend and analyze because they can be synchronized with the stimulus.

Many researchers have published reports regarding the estimation of the P300 component. For instance, D’Avanzo et al. [2] attempted to extract single-trial ERPs, including the P300, using the multi-task learning method. In their model, they assumed that a single-trial ERP is the sum of an average component, common to all sweeps, and an individual shift, which varies from sweep to sweep. Turnip et al. [3] proposed a real-time feature extraction method for the P300 in which a nonlinear principal component was combined with a multilayer neural network. In this method, visual inspection was conducted for the extracted P300 waveform in lieu of quantitative evaluation.

Other P300 estimation techniques include those based on wavelet denoising [4], independent component analysis [5], the autoregression of exogenous input (ARX) model [6], and common spatial pattern (CSP) analysis [7]. Additionally, a recent report described an estimation method for compressed sensing using the property of ERP sparsity in the frequency domain [8].

In this study, we focused on optimizing and using a particle filter to estimate the P300. This filter was described as part of the general state space model approximately 20 years ago. It was proposed for estimating the distribution of high dimensional state vectors, which had a high computational cost, and thus, required many particles. Its implementation is simple and the filter is applicable to various fields. In contrast to the Kalman filter, the particle filter is expected to improve estimation accuracy because it enables a non-Gaussian distribution in state estimation. Vedel-Larsen et al. [9] compared the performance of a simplified Kalman filter with that of sliding window averaging for single trial P300s. They concluded that the simplified Kalman filter was better than sliding window averaging in terms of noise suppression. Regarding the use of a particle filter in single trial ERP estimation, Mohseni et al. [10] proposed a method based on recursive Bayesian estimation of wavelet coefficients corresponding to ERPs. They then compared the particle and Kalman filtering approaches. They found that the particle filter was more robust than the Kalman filter for processing non-Gaussian noise in EEG data. Although Ting et al. conducted several studies in which ERPs were estimated via particle filter, their target ERP component was different from that in the present study (i.e., P300). They proposed a time-varying AR model with non-Gaussian Cauchy noise to estimate event-related desynchronization [11] and a non-linear state-space model with a non-Gaussian stochastic volatility process and particle filter to estimate single-trial auditory brainstem responses [12]. They also constructed state-space dynamic models for single-trial ERPs such that the evolution of latencies and amplitudes was defined by a continuous-time AR process with trend components, and ERPs were estimated via a Rao-Blackwellized particle filter [13].

The appearance of the P300 depends on various factors. These are not only related to the physical properties of stimuli, but also to human circumstances, such as fatigue [14], motivation [15], and habituation [16]. That single sweep response may be considerably different from one another has been well established [17]. Accordingly, assuming that each response is independent, we did not make any special assumptions or incorporate information about past responses into our ERP estimation model. In this study, we focused on the idea that a probability distribution can be constructed from many particles. In this case, estimation accuracy and processing time can be modulated by the number of particles. Applying the filter, we can set the number of particles according to the desired performance of the computer used for analysis. This enables us to sacrifice estimation accuracy and save in terms of computation cost for instances in which a low level of specification is necessary.

We sought to develop a simple filter that would be applicable to cases in which the processing was conducted as preprocessing, prior to conventional averaging (the calculation of an average for measured responses). In this study, we demonstrated the application of this filter to simulated EEG data and attempted to apply the filter to actual EEG data generated using a P300 BCI speller. Additionally, we examined the possibility of using the filter for real-time processing, which is an ideal condition for analysis. Here, we define real-time processing as the execution of ERP estimation within the time required to collect the corresponding measurement. As accuracy is affected by computer performance, we evaluated the real-time properties using specific parameters on a computer in our laboratory.

@&#METHODS@&#

In this study, we assumed that a single measured response consisted of three kinds of components: ERPs approximated via a trend model; background EEGs generated via an autoregressive (AR) model; and noise. We constructed a state space model that incorporated these three components and estimated each component using a particle filter.

At an arbitrary time t, we express the original EEG signal, trend component (ERP), AR component (background wave), and noise as y(t), T(t), p(t), and n(t), respectively.
                           
                              (1)
                              
                                 
                                    y
                                    (
                                    t
                                    )
                                    =
                                    T
                                    (
                                    t
                                    )
                                    +
                                    p
                                    (
                                    t
                                    )
                                    +
                                    n
                                    (
                                    t
                                    )
                                 
                              
                           
                        
                     

The trend component, T(t), is formulated as follows when the model order is m.
                           
                              (2)
                              
                                 
                                    
                                       Δ
                                       m
                                    
                                    T
                                    (
                                    t
                                    )
                                    =
                                    
                                       v
                                       T
                                    
                                    (
                                    t
                                    )
                                    ,
                                     
                                    
                                       v
                                       T
                                    
                                    (
                                    t
                                    )
                                    ∼
                                    
                                       p
                                       c
                                    
                                    (
                                    x
                                    |
                                    0
                                    ,
                                    
                                       τ
                                       T
                                    
                                    )
                                 
                              
                           
                        
                     

Here, Δ is the time differential operator, defined as Δ
                        =
                        T(t)−
                        T(t
                        −1), and Δ
                        
                           m
                         represents the mth order differential equation. Moreover, the probability density function is defined as the following Cauchy distribution.
                           
                              (3)
                              
                                 
                                    
                                       p
                                       c
                                    
                                    (
                                    x
                                    |
                                    
                                       x
                                       0
                                    
                                    ,
                                    γ
                                    )
                                    =
                                    
                                       1
                                       
                                          π
                                          γ
                                          [
                                          1
                                          +
                                          
                                             
                                                (
                                                x
                                                −
                                                
                                                   x
                                                   0
                                                
                                                /
                                                γ
                                                )
                                             
                                             2
                                          
                                          ]
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

The Cauchy distribution has heavy-tailed density compared to the Gaussian distribution. Therefore, we used the distribution to estimate abrupt changes in amplitude included in the ERPs. The Cauchy distribution is used much when the distribution is not certain [11].

The AR component, p(t), is formulated as the following equation when the AR coefficient is a(i) and the model order is l.
                           
                              (4)
                              
                                 
                                    p
                                    (
                                    t
                                    )
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       l
                                    
                                    
                                       a
                                       (
                                       i
                                       )
                                       p
                                       (
                                       t
                                       −
                                       i
                                       )
                                    
                                    +
                                    
                                       v
                                       p
                                    
                                    (
                                    t
                                    )
                                    ,
                                     
                                    
                                       v
                                       p
                                    
                                    (
                                    t
                                    )
                                    ∼
                                    N
                                    (
                                    0
                                    
                                       ,
                                       
                                          T
                                          p
                                       
                                       2
                                    
                                    )
                                 
                              
                           
                        
                        v
                        
                           T
                        (t) and v
                        
                           p
                        (t) are prediction errors by trend and AR model, respectively. Measurement noise, n(t), is subject to N(0, σ
                        2).

The state space model is then constructed.
                           
                              (5)
                              
                                 
                                    
                                       x
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       Fx
                                    
                                    (
                                    t
                                    −
                                    1
                                    )
                                    +
                                    
                                       Gv
                                    
                                    (
                                    t
                                    )
                                    ,
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    y
                                    (
                                    t
                                    )
                                    =
                                    
                                       Hx
                                    
                                    (
                                    t
                                    )
                                    +
                                    u
                                    (
                                    t
                                    )
                                    ,
                                 
                              
                           
                        
                     

where x(t) is the state vector, v(t) is an error vector for prediction, system noise, and u(t) is measurement noise. They are expressed as
                           
                              (7)
                              
                                 
                                    
                                       x
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            T
                                                            (
                                                            t
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            T
                                                            (
                                                            t
                                                            −
                                                            1
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         ⋮
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            T
                                                            (
                                                            t
                                                            −
                                                            m
                                                            +
                                                            1
                                                            )
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            p
                                                            (
                                                            t
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            p
                                                            (
                                                            t
                                                            −
                                                            1
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         ⋮
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            p
                                                            (
                                                            t
                                                            −
                                                            l
                                                            +
                                                            1
                                                            )
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    ,
                                     
                                    
                                       v
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   v
                                                   T
                                                
                                                (
                                                t
                                                )
                                             
                                             
                                                
                                                   v
                                                   p
                                                
                                                (
                                                t
                                                )
                                             
                                          
                                       
                                    
                                    ,
                                     
                                    u
                                    (
                                    t
                                    )
                                    =
                                    n
                                    (
                                    t
                                    )
                                    .
                                 
                              
                           
                        
                     

The coefficient matrices are shown as follows with l
                        =2 and m
                        =3 as an example.
                           
                              (8)
                              
                           
                        
                     

A particle filter expresses the conditional distribution for estimating a state via Monte Carlo approximation with a maximal number of particles. Accordingly, this filter is a flexible time series filter, which is applicable to various state space models. As shown in Eq. (1), we adopted a linear, non-Gaussian-type state space model. We therefore constructed the particle filter based on the state space model in which system noise, v
                        
                           T
                        (t) and v
                        
                           p
                        (t), had non-Gaussian and Gaussian distributions, respectively.

In the following, we describe the rough scheme of the model. Here, the number of particles is N, the estimated time section is t
                        =1∼
                        T, and i indicates the ith response among N responses. The process of prediction, x
                        (i)(t|t
                        −1), and filtering, x
                        (i)(t|t), at a specific time can be obtained by the following algorithm.
                           
                              
                                 
                                 
                                    
                                       
                                          Algorithm
                                       
                                    
                                    
                                       The set of particles, 
                                             
                                                X
                                                (
                                                t
                                                |
                                                t
                                                −
                                                1
                                                )
                                                =
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                               
                                                                  (
                                                                  i
                                                                  )
                                                               
                                                            
                                                            (
                                                            t
                                                            |
                                                            t
                                                            −
                                                            1
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                             
                                          , 
                                             
                                                X
                                                (
                                                t
                                                |
                                                t
                                                )
                                                =
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                               
                                                                  (
                                                                  i
                                                                  )
                                                               
                                                            
                                                            (
                                                            t
                                                            |
                                                            t
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                             
                                           can be calculated iteratively by the following sequence.
                                    
                                    
                                       1.For i
                                          =1–N, generate the initial state vector at t
                                          =0, x
                                          (i)(0|0). In this experiment, t
                                          =0 denotes the stimulus onset and we assumed that only the AR component exists before the onset (t
                                          <0).
                                    
                                    
                                       2.For i
                                          =1–N, execute the following three steps from (a) to (c).
                                    
                                    
                                       (a) For i
                                          =1–N, execute the following three steps.
                                    
                                    
                                       (i) generate the v
                                          (i)(t). The trend and AR components in v
                                          (i)(t) are subject to p
                                          
                                             c
                                          (x|0,τ
                                          
                                             T
                                          ) and v
                                          
                                             p
                                          (t)∼
                                          N(0,
                                             Tp
                                          
                                          2), respectively.
                                    
                                    
                                       (ii) calculate x
                                          (i)(t|t
                                          −1)=
                                          
                                             F
                                          
                                          x
                                          (i)(t
                                          −1|t
                                          −1)+
                                          v
                                          (i)(t).
                                    
                                    
                                       (iii) calculate w
                                          (i)(t)=
                                          R(u(t)| x
                                          (i)(t|t
                                          −1)). Here, R is the probability density function of measurement noise in state space equations.
                                    
                                    
                                       (b) calculate the likelihood of the group, W(t), by 
                                             
                                                W
                                                (
                                                t
                                                )
                                                =
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   
                                                      w
                                                      
                                                         (
                                                         i
                                                         )
                                                      
                                                   
                                                   (
                                                   t
                                                   )
                                                   .
                                                
                                             
                                          
                                       
                                    
                                    
                                       (c) generate 
                                             
                                                X
                                                (
                                                t
                                                |
                                                t
                                                )
                                                =
                                                
                                                   
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            (
                                                            1
                                                            )
                                                         
                                                      
                                                      (
                                                      t
                                                      |
                                                      t
                                                      )
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            (
                                                            N
                                                            )
                                                         
                                                      
                                                      (
                                                      t
                                                      |
                                                      t
                                                      )
                                                   
                                                
                                             
                                           by resampling x
                                          (i)(t|t) from 
                                             
                                                X
                                                (
                                                t
                                                |
                                                t
                                                −
                                                1
                                                )
                                                =
                                                
                                                   
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            (
                                                            1
                                                            )
                                                         
                                                      
                                                      (
                                                      t
                                                      |
                                                      t
                                                      −
                                                      1
                                                      )
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            (
                                                            N
                                                            )
                                                         
                                                      
                                                      (
                                                      t
                                                      |
                                                      t
                                                      −
                                                      1
                                                      )
                                                   
                                                
                                             
                                           with the probability of 
                                             
                                                
                                                   
                                                      
                                                         w
                                                         ˜
                                                      
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                (
                                                t
                                                )
                                                =
                                                
                                                   w
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                (
                                                t
                                                )
                                                /
                                                W
                                                (
                                                t
                                                )
                                             
                                          .
                                    
                                 
                              
                           
                        
                     

Regarding the experimental parameters, we set the orders of trend (l) and AR (m) to 2 and 20, respectively. The condition l
                        =2 corresponds to the model in which the variation v
                        
                           T
                        (t) is allowed locally and changes occur linearly according to 
                           
                              T
                              (
                              t
                              )
                              =
                              2
                              T
                              (
                              t
                              −
                              1
                              )
                              −
                              T
                              (
                              t
                              −
                              2
                              )
                              +
                              
                                 v
                                 T
                              
                              (
                              t
                              )
                              ≈
                              0
                           
                        . By setting l at 2 to approximate the ERP with the linear trend, we determined m via the Akaike Information Criteria. The parameters of system noises, namely, (τ
                        
                           T
                        , τ
                        
                           p
                        ) of the trend and AR models, can be obtained by maximizing the logarithm likelihood, defined by the following equation:
                           
                              (9)
                              
                                 
                                    L
                                    ≡
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       T
                                    
                                    
                                       log
                                        
                                       W
                                       (
                                       t
                                       )
                                       −
                                       T
                                        
                                       log
                                        
                                       N
                                    
                                    .
                                 
                              
                           
                        Here, T is the interval containing the ERP component, 900ms.

In this study, the duration of time being analyzed was 900ms, i.e., the period from stimulus onset to 900ms after onset. Based on our above-mentioned definition, we judged whether real-time processing of ERP estimation could be completed within 900ms.

When reducing the processing time or applying the filter to a real-time processing system, experimenters generally avoid simultaneously acquiring experimental parameters during EEG measurements because of the high time requirement for calculating optimal parameters. We therefore assumed that EEG measurements for acquisition of parameters had been performed prior to actual EEG measurements. Thus, our measurements for parameter setting were meant to correspond to data collection for training in machine learning, which is frequently used to solve the classification problem in BCI systems. Having generated 45 responses, we separated them into 15 pieces of training data to obtain the best parameters and 30 pieces of test data to be used to evaluate our method in terms of optimal parameters. This process enabled optimal parameters to be obtained via the simplex method. As for σ
                        2, the optimal value was determined from the results of the training data.

We also evaluated the Kalman filter. We assumed that the system and measurement noise values would be subject to the Gaussian distribution when comparing this filter with a particle filter. We used the same state space model that we used to assess the particle filter. With respect to the system noise values corresponding to the trend and AR components, the averages were 0 and the variances were determined using the same method used to obtain the τ
                        
                           T
                         and τ
                        
                           p
                         of the particle filter.

In actual EEG experiments, it is not possible to completely measure accurate ERP waveforms; therefore, we attempted to evaluate the performance of the filter via computer simulation.

We generated EEG for the simulation by combining known P300 and background EEG waveforms, as shown in Fig. 1
                     . Background waves were extracted from EEG signals collected from six participants at rest. ERPs were obtained as the average of 30 target responses in a visual single-stimulus paradigm [18]. The oddball paradigm is an experimental design that is widely used in ERP research. Two types of stimuli are presented: a target stimulus, to which participants must attend to successfully perform a task, and an unexpected non-target stimulus. We used a paradigm in which there were no non-target stimuli, i.e., the oddball paradigm contained 100% target stimuli. A flash stimulus (light brightness: 30,000cd/m2, light intensity: 4.0lx/s, pulse width: 2ms, 10s inter-stimulus-interval) was generated. EEG data with a sampling frequency of 1000Hz were recorded from participants using an EEG device (EEG-1100, Nihonkoden, Tokyo, Japan). The experiment took place at Utsunomiya Hospital after obtaining informed consent from the participants and approval from the ethics committee at the hospital. We assumed that a single measured response encompassed the period 500ms before and 1400ms after the stimulus onset. The interval containing the ERP component ranged from the point of stimulus onset to a point 900ms after the stimulus. In this experiment, we prepared three kinds of EEG with different signal-to-noise ratios (SNR), −10dB, −5dB, and 0dB. Here, the SNR is defined as the power ratio between the known ERP and the background wave. We used the particle/Kalman filter to estimate the ERPs in both the forward and backward directions. The resulting ERPs were defined as the averages of the predicted waveforms for the two directions. For the forward and backward estimations, we used the prestimulus time section containing the 500ms prior to stimulus onset and the section from 900ms to 1400ms after the stimulus for setting initial vectors and coefficient matrices. We then processed 30 responses, which were the test data for each patient.

In the experiment, we first determined the number of particles. We then investigated the relationship between the processing time on the computer (CPU: Intel® core™ i3-4130 3.4GHz, RAM: 8GB) used in this experiment and the number of particles. Additionally, we examined the time complexity as a function of the number of particles, which does not depend on the computer used in analysis.

Next, to evaluate ERP estimation performance, we focused on the following three parameters of the P300: MSE, peak amplitude, and peak latency. Here, the MSE of the estimated ERP waveform was defined according to the following equation:
                        
                           (10)
                           
                              
                                 MSE
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             t
                                             =
                                             1
                                          
                                          T
                                       
                                       
                                          
                                             
                                                (
                                                T
                                                (
                                                t
                                                )
                                                −
                                                E
                                                R
                                                P
                                                (
                                                t
                                                )
                                                )
                                             
                                             2
                                          
                                       
                                    
                                    
                                       T
                                       ⋅
                                       
                                          
                                             (
                                             
                                                A
                                                
                                                   P
                                                   300
                                                
                                             
                                             )
                                          
                                          2
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where T(t) and ERP(t) are the estimated and known ERP amplitudes, respectively, at time t. The MSE is normalized with the peak amplitude of the P300, A
                     P300.

To evaluate the estimation accuracy of amplitude and latency, we defined the error of peak amplitude (EPA) and the error of peak latency (EPL) using the following equations:
                        
                           (11)
                           
                              
                                 EPA
                                 (
                                 %
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   A
                                                   ˜
                                                
                                                
                                                   P
                                                   300
                                                
                                             
                                             −
                                             
                                                A
                                                
                                                   P
                                                   300
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          A
                                          
                                             P
                                             300
                                          
                                       
                                    
                                 
                                 ×
                                 100
                                 ,
                              
                           
                        
                     
                     
                        
                           (12)
                           
                              
                                 EPL
                                 (
                                 %
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   L
                                                   ˜
                                                
                                                
                                                   P
                                                   300
                                                
                                             
                                             −
                                             
                                                L
                                                
                                                   P
                                                   300
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          L
                                          
                                             P
                                             300
                                          
                                       
                                    
                                 
                                 ×
                                 100
                                 .
                              
                           
                        
                     
                  

Here, 
                        
                           
                              
                                 A
                                 ˜
                              
                              
                                 P
                                 300
                              
                           
                        
                      and 
                        
                           
                              
                                 L
                                 ˜
                              
                              
                                 P
                                 300
                              
                           
                        
                      represent the estimated amplitude and latency, and A
                     P300 and L
                     P300 indicate the known amplitude and latency.

To validate our method, we applied it to real EEG data generated via the P300 BCI speller. The P300 speller [19] is a commonly used stimulus presentation method that involves character input to a computer. Participants in this experiment were two healthy 25- and 24-year-old males. The participants were instructed to count the number of times that a given character flashed on the screen. We analyzed the corresponding EEG responses. The conditions for data analysis, such as the parameters, were the same as those used in the simulation mentioned above.

@&#RESULTS@&#

To determine the number of particles needed for optimal performance of our method, we investigated the relationship between the MSE and the number of particles. As shown in Fig. 2
                     , MSE improvement did not continue when the analysis contained more than 400 particles.

We also investigated the relationship between the required processing time for forward/backward predictions with respect to the computer used in this experiment and the number of particles, as shown in Table 1
                     . We obtained the results using the incorporated “clock” function in C language. As shown in the table, real-time processing for 900ms of data is theoretically available if the number of particles is less than 400. In consideration of both the amount of MSE improvement and the required processing time, we fixed the number of particles to 400 for our study.


                     Fig. 3
                      shows the time complexity as a function of the number of particles, independent of the computer used in the analysis. The time complexity is expressed as a relative ratio given an analysis with 100 particles. This result indicates that the complexity increases with O(n
                     2). However, it increases in a near-linear fashion for analyses up to 1000 particles.

To evaluate the ERP estimation performance of the particle filter, Kalman filter, and conventional simple averaging, we focused on three parameters: MSE, peak amplitude, and the peak latency of the P300. These results were obtained as an average of the results for six participants. Fig. 4
                      shows the relationship between the MSE and the amount of averaging. Fig. 4(a)–(c) show the results when the original waveforms were −10dB, −5dB, and 0dB, respectively. We found that the MSEs of all methods decreased with the amount of averaging. The particle filter produced a stable MSE value around 0.4, irrespective of the SNR. The lower the SNR of the original waveform, the greater the effect of the particle filter in suppressing the background wave, compared with Kalman filter and the conventional averaging method. In this experiment, the conventional simple averaging method produced a smaller MSE compared with two kinds of filters at 0dB SNR, where P300 can be easily recognized by visual inspection. At −5dB, the particle filter and conventional averaging method performed similarly. At −10dB, we obtained better results using filters compared with conventional averaging. We observed significant error reduction for the particle filter.

In terms of clinical applications, a shorter measurement time could mean reduced physical and mental strain. In terms of BCI applications, a smaller amount of averaging is desirable for early target identification. Thus, we investigated the size of the reduction in averaging after applying the particle filter, compared with that produced by a conventional averaging method, at −10dB SNR. As shown in Table 2
                     , we compared the amount of averaging necessary with the particle filter with that of an equivalent conventional averaging method. We found a maximum reduction of 42.8%.

We examined the relationship between P300 peak amplitude, P300 peak latency, and the amount of averaging because amplitude and latency are important measures in the evaluation of ERP estimation [20]. The EPA and EPL are shown in Figs. 5 and 6
                     
                     , respectively. Both the EPA and EPL decreased as the amount of averaging increased for all three methods at all SNRs, although the EPL showed a large fluctuation across the amount of averaging. However, the EPA and EPL of the particle filter at −10dB tended to be smaller than that produced by the Kalman filter and by conventional averaging.


                     Fig. 7
                      contains examples of estimated ERP components produced by applying the particle filter to measured EEGs generated from the background waves of two participants, referred to as subject A and subject B. The results for subject A are shown in Fig. 7(a)–(c) and those for subject B are shown in Fig. 7(d)–(f). The figures for −10dB (Fig. 7(a) and (d)), −5dB (Fig. 7(b) and (e)), and 0dB SNR (Fig. 7(c) and (f)) are arranged from the top. When the measured EEG had a low SNR, that is, the amplitude of the background wave was large relative to the ERP, the estimated EEG expressed by the trend component was pulled toward the measured EEG. As the SNR increased, the estimated ERP approached the true ERP.


                     Fig. 8
                      shows the EEG results of two participants, referred to as subjects C and D, generated via the P300 speller. We calculated the estimated waveforms from the measured original waveforms by applying the proposed method to the original waveforms. The results for each participant are shown in Fig. 8(a)–(c) for subject C and Fig. 8(d)–(f) for subject D. The difference between the MSEs generated by conventional averaging and averaging after the application of a particle filter decreased as the amount of averaging increased (as shown in Fig. 4(a)) such that this difference became very small in the average of 10 responses. Therefore, we showed three kinds of waveforms: a single response (Fig. 8(a) and (d)), an average of five responses (Fig. 8(b) and (e)), and an average of 10 responses (Fig. 8(c) and (f)). We ascertained that a positive potential, which we believed to be the P300 component, could be estimated from a single response. The background EEG was increasingly suppressed as the amount of averaging grew.

@&#DISCUSSION@&#

In this section, we first discuss the three evaluation points (i.e., MSE and processing time; reduction of averaging times; and P300 peak amplitude and peak latency) separately. We then discuss the results of the P300 speller experiment.

In terms of the MSE, in contrast to the case with the Kalman filter and the conventional averaging method, the lower the SNR of the original waveform, the greater the effect of the particle filter in suppressing the background wave. It is possible that the particle filter is able to capture abrupt changes in ERP components due to utilization of non-Gaussian noises at a low SNR, where ERPs are often buried in high amplitude background waves. In contrast, the Kalman filter may pursue the original wave, thus yielding results similar to those obtained via the conventional averaging method.

Regarding the number of particles, Mohseni et al. [10] reported that the optimal number of particles was 10,000 in their model. High estimation accuracy requires a more complex model and a larger number of particles. However, the purpose of our research was to reduce EEG measurement time by decreasing the amount of averaging. We therefore adopted a simple model that necessitated a minimal number of particles. Moreover, although Mohseni et al. adjusted some parameters manually, we were able to automatically determine the optimal parameters using the simplex method. In our model, we found that more particles led to a better MSE, up to a maximum of 400 particles. As shown in Table 1, we demonstrated a relationship between processing time for forward/backward predictions and the number of particles using our personal computer. In this simulation, we processed 900 sampling points, ranging from 0ms to 900ms after the stimulus onset. Ignoring the time required for the EEG data acquisition system to transfer data to a personal computer for analysis, we suggest that a real-time system will be used if online processing can be completed within 900ms. However, the required analysis time depends on the sampling frequency. An increase in the sampling frequency elevates the time required to complete the analysis because the number of data points in the analysis increases. For the ERP measurements in our study, the sampling frequency was generally lower than 1000Hz (e.g., 256Hz in [3]). We therefore considered the sampling frequency to be sufficiently large. The time required for the analysis will be reduced if a smaller sampling frequency is used.

In this study, we estimated ERPs as the average of forward and backward predictions to obtain a higher estimation accuracy. The use of backward predictions requires the collection of EEG data up until 1400ms after the stimulus onset. In an oddball paradigm in a clinical examination, the inter-stimulus-interval is generally about 2s, which is long enough to include the P300. Therefore, real-time processing will not be impaired if the dual-directional prediction is executed. In contrast, only forward predictions will be desirable for the application of BCIs because of the reduction in processing time. However, results will depend on the degree of complexity of the model used for construction of the particle filter and on the calculation performance of the computer used. Generally, the number of particles used has an effect on the computational cost and estimation accuracy. Therefore, when using the particle filter, it is necessary to create a balance between processing time and performance. By decreasing the number of particles, we were able to use a computer with a low processing speed, although estimation accuracy was sacrificed.

In our experiment, we compared improvement in the MSE obtained using a particle filter with that obtained via Kalman filter and a conventional averaging method when the SNR of the original waveforms was −10, −5, and 0dB. The particle filter method was superior in terms of MSE improvement, irrespective of the amount of averaging, when the waveforms were at −10dB. In contrast, the filter showed equivalent or reduced performance compared with conventional averaging methods for waveforms over −5dB. This result indicates that conventional averaging is better than the particle filter for our simple model when the ERP amplitude is relatively large, for instance, in cases where the P300 can be easily seen by visual inspection. Conversely, the performance of the particle filter improves when the amount of background waves increases and the noise becomes more non-Gaussian, as suggested by Mohseni et al. [10]. The EEG measurement time in clinical examinations and the amount of averaging until target identification in BCI systems could be substantially reduced by the use of particle filters when the SNR of the original waveform is low. If the original waveform already has a high SNR, the benefit of the filter decreases.

In the case of the 0dB SNR (Fig. 7(c) and (f)), the P300 looked superficially estimated and the background wave appeared to have been sufficiently eliminated. However, conventional averaging without filtering showed a smaller MSE than that generated by averaging after the application of a particle filter in Fig. 4(a). Looking carefully at the estimated waveform in Fig. 7, several sample points indicate that the true ERP is closer to the measured EEG rather than the estimated ERP. Therefore, the suppression of the background wave by particle filter did not generate a prominent effect. Parameters (τ
                        
                           T
                        , τ
                        
                           p
                        ) contribute to the allocation of amplitude to ERP and background EEG data. Thus, accuracy may be improved by setting optimal parameters. Unfortunately, in the current situation, conventional averaging without a particle filter produced a better result for measured EEGs more than 0dB.

Of course, the estimation accuracy for ERPs depends on the model of the filter. Accordingly, more appropriate models, i.e., those reflecting the specific signal characteristics of ERPs, could be incorporated into the particle filter for further benefit. However, more complex models have higher computational costs. The balance between the simplicity of the model and the length of processing time should be carefully considered. We suggest that real-time processing might be made possible in different system environments by varying the number of particles.

In our experiment, in which we calculated averages several times, the effect of the particle filter was most strong with respect to the EPA at less than −5dB. Thus, this filter will be useful especially in BCI systems with a P300 peak amplitude, in which small amount of averaging is optimal.

Compared with the amplitude, the amount of averaging had an unstable modulatory effect on the latency. Especially for original waveforms with a low SNR, the P300 peak was easily affected by background waves, and the peak latency was very sensitive to variations in the amplitude of the background wave. Thus, a certain amount of averaging was needed to obtain an accurate peak latency.

We observed a positive potential in the estimated waveforms generated during the P300 speller experiment. We presumed this potential to be the P300, although the ERPs were buried in the background wave in the original waveform, as shown in Fig. 8. The estimated ERP seems to pursue the signal change associated with the appearance of the P300 in a single response. As shown in Fig. 7, the average of the measured EEG responses approaches that of the estimated ERPs as the amount of averaging increases. This is similar to the behavior of MSEs with conventional averaging and averaging after the application of a particle filter to the simulation data (Fig. 4). Applying the particle filter to the measured EEG responses, we were able to obtain an ERP waveform that was stable compared with that produced by conventional averaging, irrespective of the amount of averaging.

@&#CONCLUSIONS@&#

In this study, we considered the efficacy of a particle filter for the analysis of simulated and actual EEG generated via the P300 speller. A distinguishing feature of the particle filter is that it can be used to construct probability distributions based on a large number of particles. We constructed a simple model that recorded three components of EEG waveforms: ERPs, background waves, and noise. The former two components can be approximated via trend models and autoregressive models, respectively. We evaluated the filter performance based on the MSE of the estimated waveform, the peak amplitude, and the latency of the P300 component. In terms of the relationships between the number of particles and the MSE, we were able to achieve a satisfactory MSE, with only 400 particles, using this model. The particle filter yielded a better MSE for original waveforms with a low SNR compared with the Kalman filter and a conventional averaging method. The application of a particle filter to ERP estimation will be especially useful for data with a low SNR. We also investigated time complexity as a function of the number of particles. We found that the complexity increases in a near-linear fashion for up to 1000 particles, although it increases with O(n
                     2) when using our algorithm. We examined the relationship between MSE improvement and the amount of averaging, and determined that the optimal number of particles was 400. We found that the merit of the filter decreased when the original waveform already had a high SNR. Using a particle filter, we found that when the SNR of the original waveform was −10dB, the amount of averaging could be reduced by a maximum of 42.8% compared with the amount of averaging employed with a conventional method. In terms of processing time, real-time processing may be possible as we were able to execute ERP estimation in individual analysis sections within the measurement times corresponding to the chosen sections.

Regarding the relationship between P300 peak amplitude, P300 peak latency, and the amount of averaging, we found the following. In terms of peak amplitude, the particle filter showed the best performance for stimuli less than −5dB SNR. As for peak latency, we found that it was easily affected, especially when there was a low SNR. However, the particle filter was clearly advantageous for processing data with a lower SNR.

We applied the particle filter to measured EEG responses generated by a P300 speller. As a result, we were able to obtain stable estimated ERP waveforms compared to those obtained by conventional averaging, irrespective of the amount of averaging.

The outcome depends on the optimal parameter settings, which in this experiment, were set using the simplex method. The simplex method is limited in that it has a local maximum/minimum point. Thus, more investigation will be needed to obtain the best parameters.

In future research, we hope to test the application of this particle filter on clinical EEG measurements or real BCI systems.

@&#ACKNOWLEDGEMENT@&#

This work was supported in part by the Japan Society for the Promotion of Science KAKENHI (Grant Number 25330224).

@&#REFERENCES@&#


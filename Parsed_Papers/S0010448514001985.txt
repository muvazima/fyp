@&#MAIN-TITLE@&#Hybrid CAD/E platform supporting exploratory architectural design

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Hybrid CAD/E platform for early-stage exploratory architectural design is proposed.


                        
                        
                           
                           Platform supports human intuition-based and computation-based workflows.


                        
                        
                           
                           An experiment indicates the potential of the platform to yield creative designs.


                        
                        
                           
                           Technical aspects of CAD/E tool interoperability are presented.


                        
                        
                           
                           Features of platform-inspired future architectural software are pointed out.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Computer-aided conceptual design

CAD–CAE integration

Free-form modeling

Animation

Parametric modeling

Performance analysis and simulation

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

It is now commonly agreed that the computer can be a meaningful tool aiding creative design  [1–7]. However, there is still a striking lack of tools able to successfully assist the early-stage creative activities in various design disciplines  [8]. One of such under-supported disciplines is architectural design.

Current software systems for architecture include commercial packages and work-in-progress research solutions. When it comes to commercial tools, most of them are inadequate for early-stage design, because they are targeted to support the later design phases. They aid routine tasks, such as visualization and documentation drafting. They are not developed with creative activity support in mind.

On the other hand, the proposals put forward by academia are directly aimed at exploratory design support. They include two types of solutions: computer-driven and user-driven. The first group allows to generate designs automatically using algorithms, e.g. shape grammars  [9–12], cellular automata  [13,14], swarm intelligence  [15–17] and evolutionary techniques  [18–23]. However, those systems have not gained wide appreciation in the design practice because for most architects they are too abstract, too complex, too difficult to learn and too tedious to use  [24–28]. To be customized to the needs of individual design assignments, these systems often require advanced programming skills, which most architects do not possess  [29,30].

The second class of academic tools offers a more synergetic relationship between computation and typical human design activities. These tools acknowledge that creators are particularly successful in expressing their ideas through interaction with various design artifacts, such as sketches and models  [31]. Hence, this research field develops diverse software and hardware media which enrich the traditional undertakings of designers  [32–34]. Such solutions include e.g.: environments for individual and collaborative digital sketching  [35–37] and 3D model making through touch-screen interfaces  [38–40], freehand digital sculpting  [41,42], and 3D modeling using motion tracking and sensor inputs  [43,44]. Most of these mixed hardware–software systems, however, are not yet ready to be widely used in praxis. The technology needed for their efficient implementation is still under development.

In response to the lack of software tailored specifically for their explorative needs, architects adopted the already existing tools from other design disciplines. The tools include free-form surface modeling software from industrial product design, animation software from film and game industry, and parametric modeling and computational simulation software from engineering product design. Even though the acquired tools were made for other end-users, it is now clear that architects can benefit from employing them, too.

The adopted techniques introduced a new way of using the computer medium in architecture. It is no longer a documentation-drafting tool, employed when the architectural concept is already conceived. Rather, the computer becomes an active form-finding partner, stimulating the architect’s imagination from the beginning of creation  [45–49]. As recent studies show, the adopted tools let architects think out of the box and help them produce innovative solutions, characterized by increased variety and novelty  [50–52].

Owing to the acquisition of those tools, the architectural profession developed a new line of non-standard, sophisticated designs, now commonly known as ‘digital architecture’  [53,54]. These designs challenge the rectilinear styling standard, by proposing objects with unique organic forms. Owing to their curved shapes, optimized early in the conceptual design process, many of these buildings are much more resource-efficient and energy-efficient than classical orthogonal objects  [55]. One of the classic examples of such realized buildings is the office tower 30 St Mary Axe (also known as SwissRe or Gherkin) in London, UK (architects Foster + Partners).

Importantly, the trend to employ foreign tools in architectural design seems to have one drawback. Namely, most practitioners lose interest in previously used tools when a new type of software enters the market. This was the case with free-form surface modeling, popular throughout the 1990s, and currently superseded by parametric modeling. Consequently, the whole spectrum of computer tools is not employed by architects in the creative process  [56]. Usually, no more than two different techniques are used, as indicated e.g. in  [57–68]. This may suggest that some interesting potentials are lost with such selective tooling approaches.

In light of the fact that currently there is no single architectural software with the functionalities of all tool types adopted from outside of architecture, the goal of this work is to present a hybrid CAD/E design platform, bringing these various tools together into one design toolkit. By constructing the platform and demonstrating its use, we aim to show that these already existing tools, when clustered, can form a robust toolset, able to support various kinds of early-stage design activities. Each platform tool introduces a different possibility for creation. The grouped tools complement each other, which enriches the functionality of the hybrid platform as a whole.

Simultaneously, the ambition of constructing a platform containing a number of tools is to provide a design kit which introduces opportunities for architects to work differently than usual. Namely, different working styles can be interleaved, i.e. human intuitive ones with computation-based ones. The platform user can therefore on the one hand work algorithmically, by inventing the digital protocols that drive form-generation, and on the other, can also carry out fuzzy and manual actions, such as intuitive form-sculpting in the digital environment. What is more, the designer can also perform design tasks impossible to execute in traditional design, such as the quick generation, exploration and evaluation of large solution spaces.

The aim of proposing a design platform based on the existing software is also to take the first step towards the development of a new future CAD/E system for early-stage exploratory architectural design — an element that is missing in the current state of the art. The potentials and technical challenges associated with ready-made software integration can become useful as guidelines for the future studies regarding the construction of a completely new tool for architects.

Moreover, because our platform collects tools already known and tested in the architectural profession, the usual weaknesses of academic solutions, such as being too abstract, too difficult to learn and still being under development, are eliminated in our case. This increases the chances of a more widespread adoption among practitioners of not only the hybrid platform, but also any future tools based on its structure and functioning. To our best knowledge, no studies of this kind have yet been demonstrated.

Our platform is constructed from two categories of software systems: CAD and CAE. The new feature introduced by the hybrid platform framework is the specific collection of tool types included in the CAD and CAE blocks (Fig. 1
                        ). The specific architectural software, representing these tools, is gathered in Table 1
                        .

The cooperation between the CAD and CAE blocks in the platform is based on the classical model of CAD/E integration  [69], with data passages taking place in two directions: downstream and upstream (Fig. 1). The downstream passage encompasses the transfer of a specially-prepared (meshed) CAD 3D model for CAE examination, i.e. computational analysis or simulation. The upstream passage includes the return of CAE examination results, which are interpreted by the human designer and used as a basis for the manual alteration of the CAD 3D model. In a more advanced setting, the upstream passage can also encompass the automatic transfer of analysis data to the optimization algorithms, which use it to automatically alter the geometric parameters of the 3D model, to enhance its performance.

Each particular tool type in the platform can be linked to a particular computer-aided architectural design approach, as indicated in Table 2
                        . These approaches, distinguished in  [70,71], are important in the context of the platform construction, as they demonstrate how each tool type can be utilized for the purpose of exploratory architectural design. The approaches are further explained in relation to platform software in the following sections.

The free-form surface modeling tools are utilized in architectural design to facilitate an approach which can be termed as manual formation using the digital medium. 3D modelers enable creation of 3D objects based on intuitive operations, performed by the designer prevalently ‘by hand’, in the drawing space of the digital environment, using the computer mouse or a tablet pen. This method in some ways resembles traditional processes of sketching, sculpting and assembling architectural models. The manual workflow of the technique is attractive for architects, because they are used to working by hand in the conceptual design phases.

The interaction of the user with the 3D objects can take place through the direct manipulation interface, icon-based graphical user interface and the command line. More advanced users may also employ scripting. In our platform they can employ Rhinoscript in Rhinoceros®, MEL in Maya®  or MAXScript in 3ds Max®.

Free-form surface modeling tools, applied in architectural design, provide greater freedom in form creation than traditional drawing methods. They allow designers to create and edit complex geometrical objects, especially those with a streamlined appearance. The analysis of literature presenting architectural designs in which those tools were employed indicates that this technique is especially well-suited for generation of organic building forms (see e.g.  [59,72]) and local refinement of these forms, by reshaping, trimming and applying incisions to their surfaces (see e.g. [72,73]).

An important technical aspect of manual modeling, supported with 3D modelers, is the choice of a surface representation that will be used to model the desired shape. This selection will have a profound impact on how the shape can be created and manipulated, and how precise the dimensioning of the model will be. The free-form modeling software assigned to our platform operates on four different types of surface representations: NURBS, polygon meshes, subdivision surfaces and T-splines. An overview of some of the strengths and weaknesses of each of these surface representations, in the context of the manual modeling approach, is presented in Table 3
                           .

Because animation software allows to simulate dynamic phenomena, architects use it to facilitate the so-called motion-based 3D modeling approaches. In these approaches, the focus is on a bottom-up temporal process, in which the shape of an architectural object emerges gradually, as a result of a simulated action of forces, placed in its surroundings. Hence, in contrast to the typical free-form modeling approaches, the user does not focus on molding the 3D objects directly, through top-down manual manipulations. Rather, the design task is to invent the kinematic mechanism which will morph, deform or rearrange 3D objects according to a scenario designed by the architect. This approach was employed in architecture to design artificial terrains (see e.g.  [58,85]), building forms (see e.g.  [57,86]) and their volumetric surface details (see e.g.  [59,87]).

Importantly, animation introduces simultaneously a highly intuitive and a highly procedural workflow. The spatial effects of animation are spontaneous and unpredictable, produced entirely by the computer software. The designer can influence them only indirectly, by tweaking the parameters of objects in the animation scene, taking away forces, adding new ones and changing their properties. This tweaking and changes can be done many times and repeated in iterative cycles, up to the point where satisfactory effects are reached. Because animation includes the temporal aspect, the designer has at his/her disposal a large pool of possible design variants, visible in the animation frames. Therefore, employing animation automatically entails that the design space contains a number of solutions.

There are two ways of 3D modeling supported with animation  [88]. In both cases, the interaction of the user with the digital environment can take place using the same interfaces as in free-form modeling. In the first approach to motion-based modeling, the designer works with surfaces. The software calculates and represents the transformations of those surfaces under force action. This usually involves relocations of polygon mesh vertices or NURBS surface control points. As an effect, surfaces are deformed and gain complex, unique shapes, which would be difficult to model using the manual approach. The second way of working involves the employment of animation-specific systems, such as particles, inverse-kinematic (IK) chains or particle-spring systems. The location in space of these systems’ elements is affected by the action of forces in their proximity. When large numbers of elements, such as particles, are animated, complex compositions emerge. These are practically impossible to be created by hand. However, they often need additional 3D modeling operations, to transform them into surfaces suitable for further work.

Parametric modeling tools help to execute the algorithmic approaches to architectural design. In those approaches, 3D objects are modeled indirectly, using stepwise instructions of form generation, which the 3D modeling software executes and visualizes [89,90]. By employing the parametric modeling tools, the user gains mathematical control over geometrical objects, their properties and mutual linkages. This precise mode of working with geometry can be beneficial from the architectural point of view, in the context of complex shape generation, control and dimensioning. For this reason, parametric modeling is employed in architecture not only to design architectural forms (see e.g.  [91]) but also fine details of building skins, such as paneling elements, structural parts, connectors and ornamental components (see e.g. [92]).

The algorithmic definitions of geometry are usually created using object-oriented visual programming languages (VPLs)  [93]. VPLs are based on diagrammatic, hierarchical structures, containing programming objects represented graphically. Owing to their visual character, they allow users to work like programmers without knowing programming languages. The functionality of a VPL is strongly dependent on the types of objects made available to its user. For more advanced users this may be a limitation. Therefore, some designers broaden the capabilities of 3D modeling using VPLs by additionally employing textual programming languages (TPLs)  [94]. For example, in VPL Grasshopper™ one can program custom objects using the VB.net TPL.

There are three main features of parametric modeling, important in the context of algorithmic architectural design: associativity, generativeness and numerical control  [95]. Associativity guarantees undisturbed data flow throughout the whole 3D model definition. The connections between mutually-dependent programming objects, properly defined at the beginning of the modeling process, open up broad possibilities of automating changes applied to geometry later on. They eliminate the need to amend geometry by hand, as is often the case with free-form modeling. Associativity also allows to produce project variants, which share the same form-generation algorithm, but have different parameters and therefore different geometric features.

The generative character of algorithmic modeling gives its users the ability to automatically produce and spatially distribute complex geometrical effects, using relatively simple rules and relationships in geometry definitions. This could be for example the division of a curved surface into spatial compartments and the inscription of other 3D objects into those compartments. Finally, the numerical and mathematical control of 3D object definitions results in the flexibility of the whole 3D model and its proneness to precisely-controllable, non-accidental change. By working with lists of parameters and objects, the user has access to each element of the algorithmic definition. This helps to carry out modifications of 3D models at a very accurate, local level.

In architecture, the so-termed performance-based design is an approach in which shaping of spatial solutions is informed by their performance, related to form, structure and material  [94]. The aim is to produce architectural designs with passive solutions, conforming to sustainable design objectives. To carry out the process, usually parametric CAD tools are coupled with CAE tools for computational analyses and simulations. The design process contains several steps: parametric modeling, performance calculation, performance assessment, remodeling based on performance results, and again performance calculation, assessment, redesign etc.  [96]. Additionally, the process can be automated by incorporating an optimization mechanism. In this case, form-remodeling is automatically driven by performance results, related to costs, material use, structural safety, energy consumption, lighting conditions etc. If these processes are to have multiple goals and orientations, then multi-objective optimization (MOO) and multidisciplinary design optimization (MDO) are employed  [97–99].

The CAE part of performance-based design employs add-on tools or stand-alone software for computational analyses and simulations. These are prevalently based on finite element (FE) computational models, which require mesh inputs for calculations. The software targeted particularly at architects usually uses simplified calculation models and returns rough results, to suit the basic needs of conceptual design and small-scale projects. The aim is to quickly and approximately assess if the design is headed in the right direction. Much more detailed and accurate calculations are carried out by specialized engineers, using more powerful software in the advanced design stages.

Several popular types of analyses and simulations employed in early-stage conceptual architectural design can be distinguished, among others: solar, aerodynamic, structural and geometrical  [100,101]. The solar impact analyses include measuring of irradiation, irradiance and illuminance, as well as simulations of shadow casting. They are useful in refining the shapes of architectural forms, as well as designing building envelope details, customized to the needs of the particular location, as demonstrated e.g. in  [102]. An extension of these analyses, usually employed when designs are more concrete, are whole-building energy analyses, which help to evaluate the building life-cycle costs, by assessing the energy and water consumption levels, carbon emissions, thermal performance, solar radiation, shadows and reflections, daylighting levels and natural ventilation potentials.

The airflow and wind simulations, employing computational fluid dynamics (CFD) methods, include air pressure analyses, wind speed analyses and turbulence simulations. They help to streamline building forms for reduced air resistance, to design structural systems customized to local wind conditions, and to shape envelope details to enhance natural ventilation effectiveness, as shown e.g. in  [103].

The structural analyses help to assess stresses, displacements and bending moments in the loadbearing structures. They are especially useful in designing non-standard structural systems with complex double-curved geometry, as demonstrated e.g. in  [104]. These tools also encompass kinematic solvers, which allow users to simulate dynamic relaxation of structures and minimal surface formation, and for this reason can be employed not only for structural assessment and optimization, but also for form-finding purposes.

Finally, architectural geometry analyses focus on how shapes of buildings perform. Qualities of the building surface model can be assessed by employing various shape measure tools, such as Gaussian, mean and total curvature analyses  [105], and so-termed ‘zebra’ analysis for surface smoothness inspection  [106]. Such analyses are essential to optimize organic building skin solutions  [107], to determine which façade parts can be approximated into flat panels, and which will necessarily need to be single- or double-curved, as indicated e.g. in  [108].

To broaden the 3D modeling functionalities of our hybrid CAD/E platform, we included in it a number of different 3D modelers, which work with various surface representations, i.e. NURBS, T-splines, subdivision surfaces and polygon meshes. The CAE part of the platform demands polygonal mesh inputs. Particular surface representations, supported by the respective software in the platform, are presented in Table 4
                     . The interoperability issues related to surface representation exchanges and switches within the platform are presented below.

Because each 3D modeling package in our platform offers different possibilities of working with each surface representation, it is assumed that users should be able to transfer geometry between these programs, to get the best out of their functionalities. The passing of geometry of the same representation type between different software packages requires using dedicated data exchange formats, suitable for the particular surface representation that is being transferred. The user must export geometry from the native application to a specific data exchange file format, and then import this file into the target application. During such transfers, geometry is usually exported well. These typical formats, which can be utilized to migrate geometry between the software packages in our platform, are presented in Table 5
                        .

Changes of surface representations within our platform can be done using the conversion tools available in 3D modeling applications. Such changes necessarily involve geometrical data conversion. The types of surface representations between which data conversion takes place determine whether the data transfer is lossless.

All transfers between T-spline and NURBS representations, regardless of the direction in which the conversion is made, can be exact and no data will be lost in the conversion  [77]. However, the user can also set an approximation factor for the conversion. Single T-spline surfaces are converted into a collection of NURBS surfaces. Multiple NURBS patches are converted into single T-splines, mathematically watertight if the input model has a closed boundary  [75].

The transfers from meshes to T-splines involve data loss, as the conversion is based on the approximation of a faceted mesh model into a smooth T-spline model. Although the transfers can be done automatically, there are some recommendations for the input meshes. Firstly, the preference is to have a quad-dominant mesh. Although triangular meshes will also convert, the smoothness of the T-spline surface might be disturbed and the distribution of its control points might be irregular, obstructing further modeling operations. Secondly, for the process to be quick and efficient, the input meshes should not contain more than one hundred thousand faces. The conversions in a reverse direction, i.e. from T-splines to meshes, can currently be only done indirectly, firstly by converting T-splines to NURBS, and then NURBS to a mesh. Such conversions involve data loss, as described in the following subsection.

Switches between NURBS and polygon mesh representations involve approximations, and hence cause geometrical data loss. The direction of data transfer influences the level of data loss and the smoothness of the designer’s workflow.

Transfers from NURBS to meshes within the packages in our platform can be done automatically, usually with minor data loss. If the new mesh is dense enough, it is able to successfully represent the geometry of the original NURBS surface, even though some data is lost in the transfer. However, two problems may occur during transfers of complex surfaces. The first one is the occurrence of artifacts, such as holes, isles, singular vertices, overlaps, self-intersections and complex edges  [80]. These may be eliminated by using mesh repair algorithms. However the problem is often not solved entirely by automatic means, and requires manual interventions of the user.

The second problem involves the quality of the automatically-derived meshes. If these are to be further worked on or passed downstream to CAE environments, they require remeshing, i.e. simplification and quality improvement. Simplification involves the reduction of the number of mesh faces and hence shape approximation. Mesh quality improvement involves changes of the global and local structure of mesh elements  [80]. Global changes involve conversions to regular meshes, with vertex valances 6 for interior vertices or 4 for boundary vertices in triangle meshes, and valences 4 and 3, respectively, for quad meshes. Local changes involve among others alterations of mesh face type (triangle-only, quad-only), shape (isotropic faces, favored as input for FEA), and distribution (uniform or adaptive).

On the other hand, translating from polygon meshes to NURBS is a task which often requires the employment of add-on software for reverse-engineering, from outside of the standard modeling packages. That is because data conversion in this direction is much more difficult mathematically than from NURBS to meshes. It is a process of reconstruction, in which a set of mesh vertices must be streamed into mathematical representation, i.e. parametric equations of NURBS. For this reason, data loss may be greater compared to NURBS to mesh transfer, as it is impossible to represent all mesh points with equations.

Within our platform, to carry out transfers of meshes to NURBS, special dedicated reverse-engineering add-ons can be used, e.g. RhinoResurf for Rhinoceros®. This add-on performs surface-fitting operations, draping target NURBS surfaces over source mesh vertices, using tolerance values specified by the user. To get the best results, the operation should be a trial and error process, repeated iteratively with varying parameter settings, until a satisfactory result is obtained. The results proposed by the fitting algorithm will at times require additional manual modeling interventions, such as trimming of NURBS to get their desired outlines.

If the converted geometry is to be worked on further, the user must also bear in mind the issue of complexity of the new representation. NURBS surfaces obtained from meshes will often have a dense, unevenly distributed control point network. This will make such overcomplicated surfaces difficult to edit. Further reworking might require surface rebuilding and simplification, which might again be associated with geometric data loss. A solution to this problem is to convert such NURBS to T-splines. The conversion will automatically reduce the number of control points and hence make the editing process of the new surface easier  [77].

The conversions of NURBS to subdivision surfaces have certain limitations and involve data loss. For example, in software Maya®, present in our platform, some types of surfaces will not be converted, i.e. surfaces of degrees other than 3 (cubic), rational surfaces with weighted CVs, and trimmed regions of NURBS surfaces  [83]. Moreover, a subdivision base mesh created from NURBS will probably be very dense, and collections of NURBS surfaces will have to be converted one by one and then attached. One of the solutions to these drawbacks is to convert NURBS patches to meshes, connect them and reduce their polygon count before converting to a subdivision surface.

Data conversions in a reverse direction, i.e. from subdivision surfaces to NURBS, can be automatic, like in Maya®, or can be semi-automatic, with provided user conversion control parameters, as is the case with the tool called Subd to NURBS in the T-splines®  software. The conversions will yield a set of C2 smooth NURBS surfaces, which at extraordinary points are G1 continuous.

Conversions of arbitrary meshes to subdivision surfaces require pre-processing steps. Otherwise, extraordinary points which will be created will affect surface continuity, i.e. may deform the surface  [80]. Therefore, remeshing of arbitrary meshes to isomorphic meshes with subdivision connectivity should be done  [82]. This implies that data will be lost in the process. Moreover, the subdivision process involves not only data loss, but also new data gain, because meshes of a coarse level are subdivided into meshes of a finer level.

Conversions of subdivision surfaces to meshes, even though they involve approximations, are more straightforward than in a reverse direction. The user can decide about the quality of the conversion, i.e. whether the output mesh should closely match the input surface, and hence be more dense and accurate; or whether the output mesh should rather match the control vertices at the selected subdivision level, hence being less dense and more rough  [83].

Data loss and the need for non-automatic manual interventions associated with geometry representation switches can be considered as the most significant limitations of our hybrid platform.

However, it should also be noticed that the issue of data loss can be considered as a minor problem if it takes place in the earliest stages of exploratory architectural design. The reason for this is that conceptual architectural design at its very beginning does not require as high levels of detail, precision and dimensional accuracy, as is often the case in industrial and engineering product design. In these disciplines, the exactness of the shape of the product matters right from the start. Conversely, the architectural models can usually be kept rough at the early conceptual stage. This stage has an exploratory character, focused on form-finding and general styling of building silhouettes. Nevertheless, the more the conceptual architectural design becomes concrete and detailed, the more the data loss factor gains importance.

Hence, because the conversions between geometry representations in current CAD packages are not yet lossless and do not yet allow for quick, automated workflows, it is highly recommended for our platform users to switch representations only for simple models, models where the accuracy of approximation will not play a significant role, or when the model is finished and will not be further reworked. Another solution is to pre-plan the 3D modeling process and organize it into a systematic workflow that takes advantage of the strengths of various surface representations, despite data loss, as presented for instance in  [79].

One of the possible examples of how such a process could be carried out in our platform is as follows. The user may begin the work in 3ds Max®, starting with a low-poly quad-based mesh model, roughly representing the desired shape of a building. Optionally, to obtain a more refined shape, the subdivision of the model by one level could be done, using a quad-based subdivision algorithm, e.g. the Catmull–Clark one. The newly subdivided surface can be converted into an output mesh closely matching the input surface. Then, the OBJ file format can be used to export this refined mesh from 3ds Max®  to Rhinoceros®. Herein, the quad mesh can be converted into a single T-spline surface, and further manipulated to get a more refined general shape, including elements such as creases and extrusions. Then, the T-spline surface can be translated into several NURBS patches. Surface details can be added, using typical NURBS modeling operations. Using this workflow, the designer switches between surface representations most adequate for each design development level, gradually proceeding from a rough model to a more detailed one.

The issues of data exchange between CAD and CAE systems are the subject of interest of a vast research field on CAD/E interoperability. Here, we signal the main issues directly related to the functioning of our platform.

As already mentioned, the CAE tools for architects currently available on the software market require a polygonal mesh input. This input is then translated within the CAE software into a finite element (FE) mesh model, adequate for a particular type of computations. However, research challenging the necessity of using polygon meshes as CAE input is on the way, with iso-geometric proposals taking NURBS  [109] and T-splines  [110] as FE calculation input, as well as several entirely mesh-free approaches  [69]. Despite this fact, there is yet no ready-made architectural software which could use non-mesh native geometry for performance calculations.

The above fact implies that if the user of our platform wishes to evaluate the created objects, the CAE analysis step must be preceded with the conversion of the geometry representation into a mesh. Automatic conversions may yield unwanted artifacts and require mesh repair operations, as indicated in Section  3.2.2. Moreover, conversions of non-mesh objects will involve some data loss, but it is assumed acceptable for early-stage design. Additionally, isotropic elements are favored in numerical applications, because their uniform shape often leads to a better conditioning of the resulting systems  [111]. Therefore, the user may want to subject the mesh to remeshing operations  [80], further losing some data.

The majority of CAE analyses involve one-directional flow of geometrical data from CAD to CAE. In other words, geometry of the analyzed object does not undergo any changes during analysis, eliminating the need to transfer geometrical data back to the 3D modeling CAD environment. In this generate-and-test mode of working the designer himself/herself applies changes to geometry, after interpreting the analysis results.

Recently, however, a more automated approach was proposed, i.e. a generative approach involving optimization, in which the numerical results from CAE analyses drive 3D model redesign. This was signaled in Section  2.2.4. In those cases, the data flow between CAD and CAE proceeds downstream and then upstream, in a closed loop. The drivers of this process may be e.g. structural performance  [112–114] or energy performance  [115–118]. The necessary condition for such a system to work is not only a mesh representation, but also a parametric description of the 3D model. Only then can the optimization algorithm tweak the numerical parameters describing the geometry that is being enhanced. Nevertheless, one must remember that generative design by optimization is a programmed process, leaving little or no space for the designer’s direct interaction with the automatically generated 3D models.

Such a generative system is possible to be put into action within our platform. For example, we could imagine a design process aimed at optimizing a free-form roof so that minimum structural displacements under self-loads occur. The work would start by creating a Maya®  or 3ds Max®  mesh model of the initial free-form to be optimized. This 3D model could then be imported to Rhinoceros®  and parameterized using its add-on Grasshopper™.

The next step would be running structural analyses with the Karamba add-on for Grasshopper™. The displacements calculated by Karamba, expressed numerically, could be used as fitness values for Grasshopper™’s optimization algorithm Galapagos. It would search for the minimum values of the displacements for different variants of the modified initial roof shape. The shape, represented as a mesh, would be changed by altering the 
                           Z
                         axis coordinate value of each mesh vertex. Various configurations of 
                           Z
                         coordinate values would be generated by Galapagos, and each time the analysis results would return the structural displacement values for the particular roof variant. The evolutionary algorithm would search through the values to find the lowest ones. Within a number of gradually enhanced design generations, a close to optimum solution could be found. This simple mechanism could be used by the designer on the one hand to broaden the pool of considered design variants, and on the other to find the best solutions satisfying the design criteria.

As already mentioned, we intend this research to be the first step on the way to develop new software for architects, aiding early-stage exploratory design. The structure and functioning of our platform could serve as a conceptual framework for researchers to construct the new architectural software. Some of the most important technical features, which such future software should have, are listed below.
                           
                              1.
                              Operating on one or more surface representations which offer similar 3D modeling functionalities as polygon mesh modeling, subdivision modeling, T-spline modeling and NURBS modeling. If more than one representation is used, these should be automatically convertible and interoperable, preferably with low or no data loss during conversions.

Enabling various architectural form-finding methods: motion-based design, manual free-form modeling, algorithmic modeling, performance-based design and generative design through multi-objective design optimization (MOO).

Facilitating simplified and quick CAE analyses and simulations of common architectural performance issues, among others: geometrical, structural, solar, wind, energy, lighting conditions, acoustics and costs.

Containing interoperable CAD and CAE components, i.e. encompassing CAE analysis and simulation tools which can take any geometrical representation from CAD as input, among others polygon meshes, subdivision surfaces, T-splines and NURBS.

Having a versatile user interface (UI), offering several means of human–computer interaction, i.e. direct manipulation interface, icon-based graphical user interface (GUI), command-line interface (CLI), end-user programming interfaces: graphical, based on VPLs; and textual, based on popular object-oriented TPLs, such as Python, C# and VB.net. A touch screen 3D modeling interface and a digital sketching interface could also be added to extend the possibilities of designers to actively interact with the created design artifacts.

Being an open-ended software, i.e. able to accommodate third-party add-ons which extend its functionalities.

Being interoperable with other 3D modeling packages, i.e. being able to import and export 3D objects of various surface representations with minor or no data loss.

Being interoperable with BIM (Building Information Modeling) and CAM (Computer-Aided Manufacturing), i.e. allowing to easily and faultlessly transfer conceptual geometry to solid-based environments.

Research on the design, development and deployment of the future CAD systems is often grounded in cognitive studies [119,120]. This helps to relate the typical creative activities executed by human designers with the computational processes aimed at aiding such activities. Below we point out some of the most important cognition-related issues, relevant for the construction and practical application of our hybrid CAD/E platform in early-stage exploratory architectural design.

The conceptual stage is claimed to be one of the most important stages in the design process, affecting among others the cost, performance, reliability, safety and environmental impact of a product  [121]. This stage should be focused on the production of a number of different design concepts, which increases the chances of obtaining a successful final solution  [122,123].

According to Gero  [124], the act of generating solution spaces, containing multiple design variants, can be viewed as a form of creative design exploration. Navigation through these spaces to find solutions which satisfy the design criteria is known as search. With design exploration being a non-routine part of the design process, where creativity is essential for solution generation, and with search being the routine portion, where design knowledge is required for solution selection, the whole design process employing the two yields so-called emergent results. These are solutions with an added value which was not planned by the designer. Such emergent solutions are considered as creative solutions  [125]. However, Gero  [124] underlines that emergence will take place only if the solution spaces undergo modifications, i.e. if their existing parameters are changed, supplemented or substituted with new ones.

Our platform is meant to support creative design following Gero’s model of exploration. The tools in the platform aid the designer in the generation of solution spaces containing multiple solutions, in modifying the solution space variables, and in searching within the spaces, looking for the best design options.

According to Horváth  [8], it is now obvious that “an algorithmic formalization of conceptual design towards a complete automation does not have a strong rational basis, and does not even make sense from a practical point of view”. Studies of creativity indicate that people acting according to systematic instructions are less likely to engage in exploratory behavior and deviate from the structure of the imposed action scheme  [126]. Researchers studying creativity in the design disciplines agree that innovation is associated with non-routine behaviors  [127].

However, the potential of computation to aid design tasks difficult to carry out by humans should not be overlooked. Computers can aid designers in the quick production of multiple-solution spaces, navigation and systematic search through these spaces, information storage and retrieval, recognition of inconsistencies, analysis and evaluation of optimal solutions, management of design constraints etc. Humans, on the other hand, excel at tasks in which computers are weak, e.g. recognizing analogies, developing ideas through reflection and conversation, working with incomplete information, transferring ideas between different domains [128]. These discrepancies between the two systems, human and machinic, open up possibilities for a synergetic, reciprocal relationship, in which the computer is a partner to its human user.

Because conceptual design has a hybrid nature, with intuitive incidental phases, as well as rational systematic ones, a good design tool should allow for the execution of both types of tasks. That is, it should facilitate both human-driven and computation-driven design actions. We took this fact into account while selecting the tools in our hybrid platform. Some of the tools support ambiguous explorations and arbitrary design decisions, e.g. related to esthetics. Other tools in the platform facilitate algorithmic routines, numerical control of geometries and computational examination of designs.

In the cognitive studies of design it is widely accepted that experienced designers often solve the design problems by breaking them down into three main levels of abstraction: global, local and detailed  [129,130]. Each level conceptually represents a design space, containing a certain number of design solutions. The global level encapsulates the local level, while the local level contains the detailed one. The designer can move from one level to another, and–if necessary–go back to the previous level. There can be a number of design spaces generated in parallel at the global, local and detailed levels. This particular structuring of the design process has the potential to yield creative design solutions  [130].

In the composition of the toolset in our platform we took the abovementioned fact into account. Consequently, some of the tools in the platform will be most suitable for working on the global abstraction level, while others will be relevant for the local and detailed ones. Additionally, we propose to interpret the three abstraction levels in the context of architectural formation steps. Hence, the global level encompasses the creation of abstract and fuzzy compositional concepts of architectural form and/or site topography; the local level refers to building silhouette design; and the detailed level zooms in into particular architectural elements, such as building skin ornamentation, detailing, patterning, paneling etc.

In design cognition research it has been often suggested that the typical human problem-solving styles are dual, i.e. based on divergent and convergent activities  [131,132]. Divergent activities allow for vagueness and yield multiple design concepts. Convergent activities are based on restrictive evaluation, selection and narrowing down of the number of solutions. The divergent–convergent cycles are repeated a number of times, until the final solutions are reached. To generate the best designs, such approaches should adopt the strategy of a balanced search, proceeding through the divergent and convergent phases so that the solution space is gradually diminished as designs become more and more concrete  [133].

With our platform we wish to support such convergent–divergent creativity cycles based on balanced search. We facilitate those concepts through the assignment of particular platform tools to the divergent and convergent design phases. In the divergent phases we propose to employ tools that allow for easy generation of multiple solutions of architectural forms and details, i.e. animation and parametric modeling. For the convergent phases we propose to employ tools which aid the process of narrowing down of the number of considered solutions, i.e. computational performance analyses and simulations. Additionally, following Gero’s requirements for exploratory design  [124], we add to the divergence–convergence cycle a modification phase, which can be supported by free-form modeling, animation and parametric modeling, and is explained in more detail in Section  4.2.1.

Due to the fuzzy nature of creative design, it is difficult to devise a universal model of an exploratory process employing our platform. Such a process can be very generally illustrated using Horváth’s pathfinder model  [134], in which the designer moves back and forth between the design tasks, following a zigzagging path, in a manner difficult to predict and capture with one fixed scheme. The process has an infinite number of paths that can be possibly taken by the designer.

In the practical application of the platform, we would encourage its users to follow the strategy of lateral thinking  [135] instead of following one fixed pattern of behavior. This implies escaping from imposed frameworks in favor of constantly searching for new, unorthodox platform usage patterns. The variety of platform tools gives space for such non-standard explorations, and supports the organization of the design process according to an individual working style of the designer. Various user interfaces in the platform, including the direct manipulation interface, icon-based graphical user interface (GUI), and programming interfaces based on VPLs and TPLs, allow designers to adjust the toolset to their changing needs. How the platform will be exploited depends also on individual creativity in tool employment and on the requirements of the particular design assignment. We consider this ambiguity as the strength of the hybrid platform, giving its users the freedom necessary in creative design.

However, for the purpose of demonstrating the hybrid CAD/E platform’s application, below we present an example of an organizational model of the creative design process, supported by the platform. The key fact is that the model is exemplary. It shows one of the possibilities of how each tool within the platform can be employed, what the design sub-phases and their order can be, how many times each platform tool can be employed, and for what particular purpose.

We propose that the basic unit in the design process supported with our platform should contain interconnected tasks based on divergence (D), convergence (C) and modification (M) (Fig. 2
                           ). Those tasks can be executed any number of times on any level of design abstraction. The whole cycle can be repeated until a satisfactory quality of the solutions is reached, preferably following the strategy of a balanced search, with the gradual reduction of the number of solutions as designs become more concrete. Some of the tasks in the cycle are executed by the human user, some by the computer, while others require the human and the computer to work together. Below we describe each step of the cycle in more detail.

Divergence (D) is a stage in which the solution space is defined and multiple designs within that space are generated. Different tools of the platform require a different type of human–computer partnership. During the use of free-form modeling the human is superior in the process, while the computer is a drawing medium, allowing him/her to create designs. In contrast to this, when animation and parametric modeling are employed, a balanced partnership is required. The designer’s role is to invent the solution generation mechanism, while the computer’s role is to produce solutions according to this mechanism, and to visualize them. In this configuration, one system cannot work without the other.

Convergence (C) is a stage where navigation and search through the solution space take place. The solutions generated via divergent actions are analyzed and evaluated, and the best performing ones are selected. These tasks can either be done entirely by the human designer, based on his/her implicit knowledge, or aided computationally, i.e. supported with explicit numerical analyses. The aim of this phase is to reduce the number of solutions, and pick the best ones.

The criteria for analysis, evaluation and selection are established by the designer and can be changed after each analysis–evaluation round. Those criteria can be both qualitative, i.e. measured using the designer’s intuition, experience, taste, preferences and design knowledge, and quantitative, i.e. measured using computation. The qualitative criteria can be: composition quality, esthetics, proportions, rhythm, level of differentiation, functionality, potential to accommodate programmatic requirements etc. The quantitative criteria, expressed numerically, can include e.g. surface curvature radius, solar energy gain amount, light intensity, airflow speed, structural displacements etc. The character of criteria–qualitative or quantitative–will partly depend on the level of abstraction on which convergence takes place. For high abstraction it may be more natural for the designer to select solutions qualitatively, while for more concrete levels — quantitatively.

Modification (M) is understood as a step in which the variables of the solution space can be mutated, i.e. changed, supplemented or substituted. This step can take place for example if the convergent phase did not yield enough solutions that satisfy the design requirements. The design variables are tweaked with the aim to produce new properties of objects, enhancing their performance and/or bringing more diversity into the solution space.

The type of modification and the manner of its application is invented, managed and executed by the designer. The designer can act impulsively, under visual stimulation by the esthetic qualities of spatial solutions. This implies executing non-routine actions, such as manually reshaping objects using free-form modeling, or testing arbitrary parameter settings in animation, and observing the resultant spatial outcomes. Otherwise, the designer can modify the variables in a more rational way, according to the results of computational performance analyses, carried out in the convergent phase. Also, an automated generative process of design optimization, mentioned in Section  3.3, can be employed to execute this. After the tweaking of the variables, the design automatically enters the divergent phase, where the solutions with new variables are produced. The divergent phase should then be followed by a convergent phase, in which the new solutions’ performance is analyzed, to allow for their re-selection.

An exemplary scheme, according to which a creative early-stage design process using our platform could be executed, is presented as a flowchart in Fig. 3
                     . In this scheme we demonstrated in more detail how the design actions can be executed at each level of design abstraction, which actions are done by the human, which by the computer, and which by both. The scheme also suggests types of platform’s CAD/E tools assigned to abstraction levels and design cycle activities. This assignment is based on tool properties and their suitability for supporting particular design stages.

To test this platform-supported scheme in a real design situation, we carried out a design experiment. The design task was to create a fragment of an architectural wall with an organic appearance. This esthetics was chosen intentionally, to confirm the potential of the platform tools to support the design of complex, double-curved objects, practically impossible to be drawn and evaluated without computer aids. As shown in the flowchart in Fig. 3, the design process was divided into three sub-phases, according to three abstraction levels: form composition design (global level), surface design (local level) and ornamentation design (detail level). Below we describe the experiment in more detail.

In this step we took on the motion-based modeling approach, supported with animation tools, to work with particle systems and forces (space warps) in 3ds Max®. Our goal was to generate a solution space containing a number of particle arrangements, disturbed by the action of space warps. We needed those arrangements as compositional frameworks for wall surface construction in the later design stages.

We began by setting up a simple animation scene, containing: 500 particles emitted from a rectangular box, 5 dispersing vortex forces placed in the perimeter of the emitter, and 10 animation frames (Fig. 4
                           ). Our intention of employing space warps was to whirl the particles in certain areas of their rectangular framework, so that those areas are compositionally accentuated, and can later serve to generate tectonic variations of the wall’s surface. While locating the forces within the system, we worked freely and intuitively, arranging them evenly within the particle emitter’s perimeter. We finished the divergent step by running the automatic process of particle animation. Because animation was set to 10 frames, we obtained 10 different particle compositions.

In this step, we carried out a human-based search through our solution space. The search was done by firstly visually analyzing the 10 particle compositions, and then, based on this analysis, assessing if each design variant satisfies our qualitative criterion. The criterion was the level of particle dispersion in the proximity of each force. Our visual study of all 10 particle arrangements indicated that their compositions are only slightly affected by the action of forces. The particles in the proximity of the space warps were, according to our subjective qualitative assessment, not disturbed enough to serve as meaningful frameworks for further work. Therefore, we made a decision to carry out a solution space modification step, as described below.

Here, we mutated the solution space by tampering with the vortex force parameter settings. These settings control vortex speed and range of particle capture. Therefore, we intuitively increased these settings, hoping to obtain more visible effects of space warp actions. We then proceeded to the divergent step again, to generate the effects of our modifications.

In this step, we ran animation again, with the modified vortex force settings. As animation was set to 10 frames, we again obtained 10 different particle compositions (Fig. 5
                           ). To evaluate our solution space, we proceeded to the convergent step, as explained below.

In this second convergence step, human-based search was done again, by visual analysis of the 10 particle compositions, based on the same qualitative criterion as previously. Our study of the new particle arrangements indicated that the mutated animation parameters improved the solutions’ performance. Namely, in the proximity of the vortex forces the particles were strongly affected, which manifested itself as vast circular particle distributions. With the passing animation time, in each animation frame those circular whirlpools gradually changed their sizes and shapes, increasingly spreading in space. Our assessment led to the conclusion that particle arrangements in all animation frames satisfy our criterion and are eligible to be used for further work. We therefore exited our D–C–M loop, to proceed to the next design abstraction level.

This design stage was aimed to develop the design further, by turning the particle arrangements into surfaces. We decided to construct these surfaces in Rhinoceros®. Therefore, geometry transfer was necessary. To carry out the transfer, we first needed to instantiate each particle, which is a non-geometrical entity, into a geometrical construct, i.e. a planar polygon mesh surface. The Mesher tool in 3ds Max®  was used to do this. As a result, for each of the 10 animation frames we produced 500 geometrical entities. Those were now ready to be transferred to Rhinoceros®. To carry out the transfer, we followed the guidelines from Section  3.1 and Table 5, i.e. exported the 10 mesh arrangements to 10 DWG files. These 10 DWG files were imported into Rhinoceros®  with no data loss and no errors.

Then, in Rhinoceros®, for each polygon mesh surface we generated an area centroid point. All planar meshes were then deleted and we were left with sets of 10 point clouds, formed by the centroids, with each cloud containing 500 points. The point clouds were then used to automatically generate 10 polygon mesh surfaces, using the Mesh From Points plugin for Rhinoceros®, which creates polygon meshes from points, following the marching cubes algorithm (Fig. 6
                           ).

In this phase we analyzed and assessed the solutions’ performance, and based on the results of this evaluation, picked the best solutions, reducing the number of variants passed on to the next design abstraction level. Our selection criterion for this stage was quantitative. Because we wanted our wall to be coated with carbon nanotube paint, which absorbs sun energy, turning a surface into a solar battery, our criterion was the total mesh surface area. In particular, we were looking for surfaces with the highest area values.

To be able to evaluate the performance of each wall version, we parameterized each surface by inputting it into Grasshopper™. Here, we used the mesh area analysis tool, which calculated the total surface area of each mesh, returning 10 different values for the 10 wall variants. The comparison of values indicated that 3 out of the 10 surfaces have the highest and closest values (Fig. 7
                           ). Hence, we chose them as variants for subsequent work.

The aim of this phase was to modify the solutions in our solution space, so that they are more refined. The mutation of solution space parameters was based on subdividing the existing surfaces to get smoother meshes. This subdivision meant simultaneously data loss and addition of new data, as the coarse meshes were to be transformed into meshes of a finer level. Data loss and data gain were favorable for us in this design development stage, because our still very abstract design became more concrete. Loop’s recursive mesh subdivision algorithm was arbitrarily chosen to execute surface transition into a finer version.

To substitute our previous solution space with a new mutated one, using the modification strategy described above, we utilized the add-on Weaverbird in Rhinoceros®. This add-on executes subdivision algorithms on input polygon meshes. We approximated the mesh using the mentioned Loop’s subdivision algorithm, with subdivision level set to 1. As an effect, the 3 input meshes were replaced with 3 new ones. These new triangular meshes acquired a smoother appearance, an increased number of faces, and a more regular face distribution (Fig. 8
                           ).

To search through the solution space in order to narrow it down to one final solution of the wall surface, we set quantitative criteria again. This time our judgment was based on environmental performance, i.e. the total surface insolation value. As already mentioned, we were interested in solar gain potentials of our surface, so we were now looking for the wall surface variant with the highest insolation.

To analyze the solar factors, we employed the Vasari software. This software, in order to carry out the CAE computations, requires watertight mesh inputs. Therefore, we added thickness to our 3 meshes using the Weaverbird Thicken Mesh tool, so that each of the meshes would be a closed boundary representation. Because a geometry exchange between Rhinoceros®  and Vasari had to be done, we exported our 3 watertight meshes to a SAT file format, and imported these into Vasari. The surfaces were imported without errors and data loss.

We then set up the parameters for our solar radiation analysis. The simulation location was Gothenburg in Sweden, the date was August the 1st, and our wall surface was oriented towards the south. To numerically check which surface exhibits the highest values, we exported the analysis results into 3 spreadsheets (Fig. 9
                           ). This allowed us to estimate the total insolation value for each wall variant, calculated as a sum of insolation values from each of its faces. After comparing the values between the 3 design variants, we were able to pick the wall version exhibiting the highest total insolation value.

The goal of this step was to generate decoration variants on the surface of our wall. To differentiate the surface for ornamentation purposes, we cut it into parts. The final result of this operation was the main body of the mesh with 13 extracted smaller mesh parts (Fig. 10
                           ). Those smaller parts encompassed areas where the surface protruded the most. We assumed that due to the self-shadowing effect, those areas would be less effective in terms of sun energy absorption. Therefore, these 13 parts were decided to be permeable, while the rest of the wall’s body was planned to be solid and sun energy-absorbing, i.e. painted with the fluid solar battery coating, described earlier.

Those material and functional factors yielded two main types of ornamentation. The first type of decoration, applied to the main wall body, encompassed the elements increasing the overall surface area for sun energy absorption purposes. To produce such ornamentation, we employed Weaverbird’s tool called Stellate, which generates a pyramid of a given height on top of each mesh face, taking its boundary as the pyramid’s base. In this way, the main body gained a spiky appearance and a functional feature of increased overall surface area.

The second type of decorations, applied to the 13 cut-off wall parts, was produced in two variants. The first variant was generated using Weaverbird’s Picture Frame tool. The tool allowed us to offset the boundary of each mesh face inwards, in this way placing a ‘hole’ in the center of each face, turning it into a latticework. The second ornament version was generated using Weaverbird’s Catmull–Clark subdivision algorithm. It replaced each triangular face with three irregular quad faces. Next, we again utilized the Picture Frame tool to produce the final net-like effect.

The final result of this detailed design phase encompassed two wall versions, both containing the same spiky main body and differently perforated smaller zones (Fig. 11
                           ).

In this step we used the environmental performance simulation environment of Vasari. The goal was to select the final perforated ornament version, based on its environmental performance. We decided to carry out the wind tunnel analyses, to check the effectiveness of each latticework variant in terms of airflow transmittal. We simulated airflow on two fragments of our surface: one being an almost flat part, and the other being a convex part. The simulation environment was again set up in Gothenburg, Sweden, with the south-western direction of the winds, characteristic for the region. The wind velocity magnitude became our criterion for the selection of the desired ornament variant.

The results (Fig. 12
                           ) pointed out that in the case of the second ornamentation variant the partition lets less air flow through, with a considerable loss of the wind speed magnitude. As we wanted the wall to act as a wind-blocking partition, we selected this variant as our final ornament. Because the performance and the esthetic appearance of the wall artifact as a whole satisfied us, we exited the C–D–M loop without proceeding to the modification phase.

The conducted experiment indicates that it is possible to successfully utilize the hybrid CAD/E platform in the early-stage exploratory architectural design process. The user can work on each design abstraction level, executing cycles of divergence, convergence and modification, employing various tools at each level. The architect is able to work both intuitively and algorithmically. The specific configuration of platform tools allows for switches between the different surface representations and various software environments during the design process. These switches are not fully automatic and require user involvement, but this gives the designer a certain level of control over the geometric effect of the transition. In some cases, surface representation switches are also associated with data loss. However, this can be considered as acceptable in early-stage exploratory architectural design, due to its typically vague and incomplete nature.

The final architectural object (Fig. 13
                        ) inherited characteristic spatial features, strongly influenced by the specific functionalities of each platform tool. The wall’s overall appearance reflects the sequential character of its process of becoming. One can observe the traces of fluctuations and turbulences left in the structure by particle animation. The silhouette is globally continuous and streamlined, at the same time being locally torn open and divided into zones. Those features stem from the application of free-form surface modeling. The use of algorithmic modeling tools augmented the whole construct with complex ornamentation and thickness, important from the esthetic, functional and material point of view. The local clustering of surface perforations automatically produced an interesting effect of abundant decoration. The wall contains non-permeable energy-harvesting zones, intertwined with perforated light-transmitting zones. Finally, the whole wall system conforms to the performance criteria related to air transmittal.

The complex character of our wall results from the synthesis of the features of the hybrid digital toolset used in its generation process. This suggests that such a design would be impossible to obtain using a single tool. The resultant esthetic effect could not have been planned by the designer from the beginning. These facts further imply that the artifact is, according to Gero’s understanding  [124], emergent, and by bearing this feature could be classified as a highly creative, innovative design.

In this paper we investigated how the CAD/E platform can be constructed and how it can support creative conceptual explorations in architectural design. The results of the design experiment in which the platform was employed suggest that the diversification of the tool repertoire in the early design phases significantly aids explorations of multiple solution spaces, across all levels of design abstraction. The hybrid CAD/E platform proved to be a flexible design toolset, with tools that can be applied for divergent, convergent and modification activities. This gives the designer a high level of decisiveness about the form-finding process, a feature often lacking in systems dominated by computation. Although the platform has its limitations related to transfers of geometrical data between the different surface representations, as well as between the CAD and CAE tools, which may slow down the design process and may involve data loss, the emergent and hence innovative character of the produced design artifact suggests that the hybrid CAD/E platform is still a valid toolkit, highly relevant for early-stage architectural design.

The collection of tools in our platform guarantees that the power of computation is not underused for mere drafting. Rather, computation amplifies the designer’s imaginative, cognitive and forming capabilities, by introducing new workflows, which reach far beyond the manipulation of shapes, towards intellectually-demanding creative explorations, enriched with algorithmic routines. In such a human–computer synergy, both systems complement each other. At the intuitive, human end of the spectrum, the design process is spontaneous, arbitrary, chaotic and imaginative, whereas at the routine, computer end, the process is precise, rational, systematic and mathematical.

The computational system supplements the human weaknesses in data processing, calculations and complexity generation, while the designer performs tasks of intuitive nature, so far impossible for computers, i.e. creative reasoning, esthetic judgment and inferencing. In other words, the computer takes on all of the laborious tasks, while the designer directs and manages these processes, and invents the routines of their execution. For many designers this will be a more natural way to work in contrast to passing all design tasks completely to the computer.

We can see two main potentials for the development of our findings in the future research. Firstly, the hybrid CAD/E platform, due to its promising potential of producing complex and optimal initial concepts, could be developed into one commercial CAD system, containing the functionalities of all techniques: manual free-form modeling, animation, algorithmic modeling, and computational performance analyses and simulations. A similar work-in-progress attempt is Rhinoceros®  and its add-on Grasshopper™, supplemented with numerous third-party plug-ins, broadening the software’s 3D modeling and computational performance assessment functionalities. However, this system is limited to the algorithmic modeling workflow. Therefore, there is still room for further research, which can develop a more versatile and differentiated software.

The second direction for future research is to extend our platform by coupling it with tools for the advanced design stages, i.e. the building information modeling (BIM) software. The extended platform could then be developed into a powerful single environment, offering a range of ideation, creation and documentation possibilities across different design stages, from fuzzy conceptual design to explicit realization phases. The Revit®  platform is one such an attempt to merge some of the functionalities of BIM, parametric modeling, environmental performance analyses and simulations. However, this software is still under development, and it does not offer the functionalities of all of the tools contained in our platform. This leaves yet another vast space for further development.

@&#ACKNOWLEDGMENTS@&#

The author would like to acknowledge the Department of Architecture at Chalmers University of Technology (Gothenburg, Sweden) for the institutional support of the presented research, as well as for the financial support within the research grant Architecture in the Making: Architecture as a creative discipline and material practice, funded by the Swedish Research Council Formas.

The author also wishes to honor the Reviewers of this paper for their valuable and inspiring comments on the topic.

@&#REFERENCES@&#


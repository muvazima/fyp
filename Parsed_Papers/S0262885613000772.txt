@&#MAIN-TITLE@&#Empirical mode decomposition on skeletonization pruning

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Usage of Ensemble Empirical Mode Decomposition (EEMD) on object skeletonization


                        
                        
                           
                           Modeling of object contour with a 2D EEMD-like procedure


                        
                        
                           
                           The produced IMFs provide a very good and novel workspace for image skeletonization.


                        
                        
                           
                           The proposed method is fully automated and unsupervised.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Empirical mode decomposition

Ensemble empirical mode decomposition

Intrinsic mode

Skeleton

Skeletonization

Pruning

@&#ABSTRACT@&#


               
               
                  This paper presents a novel skeleton pruning approach based on a 2D empirical mode like decomposition (EMD-like). The EMD algorithm can decompose any nonlinear and non-stationary data into a number of intrinsic mode functions (IMFs). When the object contour is decomposed by empirical mode like decomposition (EMD-like), the IMFs of the object provide a workspace with very good properties for obtaining the object's skeleton. The theoretical properties and the performed experiments demonstrate that the obtained skeletons match to hand-labeled skeletons provided by human subjects. Even in the presence of significant noise and shape variations, cuts and tears, the resulted skeletons have the same topology as the original skeletons. In particular, the proposed approach produces no spurious branches as many existing skeleton pruning methods and moreover, does not displace the skeleton points, which are all centers of maximal disks.
               
            

@&#INTRODUCTION@&#

A skeleton of an object is consisted of thin lines which retain the connectivity of the original shape, containing both shape features and topological structure of the original object. Therefore, skeletons carry important information about the structure of an object by using only a small number of object pixels. The skeletonization of an image object is a frequently encountered task in image and video based applications, such as image retrieval and computer graphics, object representation and recognition, character recognition and animation and analysis of biomedical images. Thus, intensive research has been carried out in order to represent and measure different shapes in the literature [1–6].

Building a skeletonization pruning system is far from being a simple process due to boundary noise and digitization artifacts which contain many unwanted branches. Little noise or a variation of the boundary often generates redundant skeleton branches that may seriously disturb the topology of the skeleton's graph. So far, various skeletonization algorithms and implementations have been presented into the literature. These systems can be broadly divided in five categories:
                        
                           •
                           The thinning algorithms [7–9].

The discrete domain algorithms based on the Voronoi diagram [10,11].

Analytic computation of a skeleton based on an approximation of the object contour [12].

Ridge following algorithms based on a distance mapping of the object [8,13,14].

Algorithms based on mathematical morphology [15–17].

Unfortunately, these approaches have the aforementioned common drawback; their sensitivity to an object boundary deformation. A small branch on the boundary shape can dramatically change the derived skeleton. Therefore, it cannot be applied to more complex shapes like shapes in the MPEG-7 data set or other shape databases [18].

To overcome a skeleton's instability of boundary deformation, a variety of techniques have been suggested for skeleton pruning. Many researchers try to smooth the boundary of the object before the computation of the skeleton, in order to remove the unwanted boundary noise and discretization artifacts [16]. However, boundary smoothing may change the original shape of the object and consequently the derived skeleton which may significantly differ from the expected skeleton. Other researchers try to assign a distance measure to each skeleton point, and then the skeleton points are pruned when their significance values are less than a predefined threshold [19]. Zhu and Yuille [4] generate more than one possible skeleton graph to overcome unreliability. A similar shape descriptor based on the self-similarity of a smooth outline is presented in [5]. Aslan and Tari [6] introduce an unconventional approach to shape recognition using disconnected skeletons in a very coarse scheme. While their approach leads to stable skeletons, the skeletons do not represent any shape details and are extremely insensitive to boundary deformations.

Even in the case of skeleton pruning algorithms [20], there are a number of drawbacks. These algorithms often do not preserve the topological information of the original object [13], and moreover, they are not invariant under Euclidean transformations such as rotations and translations. Additionally, in cases where objects contain holes, the derived skeletons cannot represent significant visual parts of the initial objects [16]. Thus, method described in [16] produces stable connected skeletons free of redundant branches, but it could not handle objects containing holes.

In spite of the fact that the existing skeleton pruning methods have the aforementioned drawbacks, they are usually necessary in order to remove inaccurate or redundant skeleton branches. The skeleton generating approaches suffer from the fact that a small protrusion on the boundary may result in a large skeleton branch, which is an intrinsic problem of the skeleton definition, since the mapping of boundary points to the skeleton points is not continuous. An obvious solution to this problem is the removal of the protrusions on the boundary and then the computation of the skeleton. Various existing smoothing approaches are applied either to the contour or to the distance map before the skeleton procedure. The problem is that isotropic (e.g., gaussian), as well as, anisotropic smoothing only reduce and do not remove the protrusions [3]. A common characteristic of the above approaches is that they displace the boundary points and, consequently, displace the location of skeleton points [21].

This paper deals with the aforementioned problems. It presents a novel approach that produces connected skeletons free of redundant and spurious branches. The contour of the object under consideration is firstly decomposed using an empirical mode like decomposition (EMD-like) algorithm based on the original EMD method [22,23], which produces the contour IMFs. The IMFs of the object contour assign a new workspace with very good properties for obtaining object skeleton. Furthermore, the new workspace assists skeletons to be robust to missing contour data (noise, cropping, etc.), frequently inserted by adopted segmentation methods, as well as free of any redundant and spurious branches.

The proposed approach was motivated by the empirical mode decomposition (EMD) algorithm presented in [22,23] and extends the technique presented in [21], which aims at deriving skeletons of image objects based on the Modal Analysis of a deformable model that parameterizes the object shape. EMD decomposition algorithm can decompose any nonlinear and non-stationary 1D data into a number of IMFs. However, the proposed method expanded the 1D EMD algorithm to a 2D EMD-like producing the object contour IMFs. Those IMFs assign a workspace that assists to remove protrusions without displacing the boundary points and, therefore, without displacing the remaining skeleton points. Thus, inaccurate or redundant branches are completely removed, while the main branches are not shortened. Also, the new workspace produced by IMFs assists the proposed method to be robust to missing contour data and variations.

The remainder of the paper is organized as follows. The 2D empirical mode like decomposition (EMD-like) with its ensemble mode (EEMD-like) is presented in Section 2. In Section 3, the skeleton pruning algorithm is introduced. Experimental results are presented in Section 4 and conclusions are drawn in Section 5.

In this section, the 2D empirical mode like decomposition (EMD-like) and the derived intrinsic mode functions (IMFs), which are used as a new workspace for the proposed object skeleton pruning algorithm, will be briefly reviewed. More details regarding the original decomposition process, its properties and all the adopted assumptions are presented in [22–25].

The basic idea embodied in the EMD analysis is the decomposition of any complicated data set into a finite and often small number of intrinsic mode functions, which have different frequencies, one superimposed on the other. The main characteristic of the EMD, in contrast to almost all previous decomposition approaches, is that EMD works directly in temporal space, rather than in the frequency space. The EMD method, as Huang et al. pointed out [22], is direct intuitive and adaptive with an a-posteriori defined basis based on and derived from the data and therefore, highly efficient. Since the decomposition of the input signal is based on the local characteristic time scale of the data, the EMD is applicable to nonlinear and non-stationary process.

The IMFs obtained by the decomposition method, constitute an adaptive basis, which satisfies the majority of properties for a decomposition method, i.e., the convergence, completeness, orthogonality and uniqueness. Moreover, EMD algorithm copes with stationarity (or the lack of it) by ignoring the concept and embracing non-stationarity as a practical reality [22].

The possibly non-linear signal, which may exhibit varying amplitude and local frequency modulation, is linearly decomposed by EMD into a finite number of (zero mean) frequency and amplitude modulated signals. The remainder signal, called as a residual function, is a monotonic trend or is simply a constant.

Furthermore, Flandrin et al. [24] and Wu and Huang [25] have shown that, when the data consists of white noise, the EMD behaves as a dyadic filter bank. One of the major drawbacks of EMD is mode mixing. In order to overcome the scale mixing problem, a new noise-assisted data analysis method was proposed, named as the ensemble EMD (EEMD) [23]. The EEMD defines the true IMF components as the average of an ensemble of trials, each one consisting of the signal with white noise of finite amplitude.

The mode mixing is largely eliminated using EEMD, and the consistency of the decompositions of slightly different pairs of data is greatly improved. Indeed, EEMD represents a major improvement over the original EMD. Furthermore, since the level of the added noise is not of critical importance and of finite amplitude, EEMD can be used without any significant intervention. Thus, it provides a truly adaptive data analysis method. The EMD, with the ensemble approach (EEMD), has become a more mature tool for nonlinear and non-stationary time series (and another one dimensional data) analysis.

In the 2D EMD-like algorithm, the data set is consisted by the points lying on the object contour and it is not consisted by interior object regions. The coordinates of the object under examination are stacked in the vector:
                           
                              (1)
                              
                                 
                                    v
                                    =
                                    
                                       
                                          v
                                          1
                                       
                                       
                                          v
                                          2
                                       
                                       …
                                       
                                          v
                                          M
                                       
                                    
                                    ,
                                 
                              
                           
                        where v
                        
                           i
                        
                        =[x
                        
                           i
                        ,y
                        
                           i
                        ]
                           T
                         denotes the i-th object contour point, and M is the number of contour points. Local minima and maxima are defined as the object contour points that have large (minima) or small (maxima) angle. In 2D EMD-like algorithm, the data v is decomposed in terms of IMFs ci
                        , as follows:
                           
                              (2)
                              
                                 
                                    v
                                    =
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          
                                             c
                                             i
                                          
                                          +
                                          
                                             r
                                             N
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where rN
                         is the residue of data v, after N number of extracted IMFs. In practice, the 2D EMD-like is implemented through a “sifting process” that uses only local extrema. From any data r
                        
                           i
                           −1, the procedure is as follows:
                           
                              1.
                              Identify all the local extrema (the combination of both maxima and minima), connect all these local maxima (minima) with lines as the upper (lower) envelope, completing at the same time the missing points with a linear interpolation method, and calculate the local mean mi
                                  of the two envelopes. Thus, all envelopes have the same number of points as the initial object contour v.

Obtain the first component h
                                 =
                                 r
                                 
                                    i
                                    −1
                                 −
                                 m
                                 
                                    i
                                  by taking the difference between the data and the local mean of the two envelopes.

Treat h as the data and repeat steps 1 and 2 as many times as required.

The final h is designated as ci
                        . The procedure can be repeatedly applied to all subsequent ri
                        , and the result is:
                           
                              (3)
                              
                                 
                                    
                                       
                                          v
                                          −
                                          
                                             c
                                             1
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             r
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             r
                                             1
                                          
                                          −
                                          
                                             c
                                             2
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             r
                                             2
                                          
                                       
                                    
                                    
                                       
                                       
                                          ⋯
                                       
                                       
                                    
                                    
                                       
                                          
                                             r
                                             
                                                N
                                                −
                                                1
                                             
                                          
                                          −
                                          
                                             c
                                             N
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             r
                                             N
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     

The decomposition process finally stops when the residue, rN
                        , becomes a monotonic-like function. This happens, as experimentally has been proven, when the total number of extracted IMFs is close to log
                        2
                        M, with M being the number of total object contour points. By summing up Eq. (3), one can derive the basic decomposition in Eq. (2). That is, a signal v is decomposed to N IMFs (ci
                        ) and a residual rN
                         signal.

The very first step of the sifting process is depicted in Fig. 1
                        . Fig. 1(a) depicts the original input data, while Fig. 1(b) and (c) shows the extrema (maxima and minima) of the data with their corresponding (upper and lower) envelopes. Fig. 1(d) depicts the average of the two (upper and lower) envelopes. This procedure is repeated, as mentioned above, and all the IMFs are extracted from the original input object contour. An example of the 2D EMD-like algorithm and the extracted IMFs for the input data shown in Fig. 1(a), is presented in Fig. 2
                        .

As in the original 1D EMD, the total number (N
                        +1) of IMFs of the data set in the 2D EMD-like algorithm is very close to log
                        2
                        M, with M being the number of total object contour points. In practice the number M of object contour points is calculated after the removal of all the collinear points.

Furthermore, the EMD drawback of mode mixing also existed in the described above 2D EMD-like case. Thus, an Ensemble EMD-like (EEMD-like) algorithm is inserted by defining the true IMF components as the mean (ensemble) of an ensemble of trials, each one consisting of the signal with white noise of finite amplitude.

The ensemble EMD-like (EEMD-like) algorithm could be summarized as follows:
                           
                              1.
                              add a white noise series w to the original input data v
                                 
                                    i
                                 
                                 =
                                 v
                                 +
                                 w
                                 
                                    i
                                 ,

decompose the data with added white noise into IMFs cjk
                                 ,

repeat steps 1 and 2 but with different white noise series each time, and

obtain the (ensemble) means of corresponding IMFs 
                                    
                                       
                                          c
                                          j
                                       
                                       =
                                       
                                          lim
                                          
                                             L
                                             →
                                             ∞
                                          
                                       
                                       
                                          1
                                          L
                                       
                                       
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             L
                                          
                                          
                                             
                                                c
                                                jk
                                             
                                          
                                       
                                    
                                  of the decomposition as the final result.

In this section, a method which exploits 2D EEMD-like algorithm, in order to extract the skeleton of the binary image (object) under consideration, is introduced.

The 2D EEMD-like algorithm is firstly applied on the contour of the object under examination extracting its contour IMFs. In other words, the contour of the object is treated as a shape with M nodes, as described in the above procedure.

One can easily see from the aforementioned examples that the first and foremost IMFs 
                        
                           
                              c
                              1
                           
                           …
                           
                              c
                              
                                 
                                    N
                                    A
                                 
                                 −
                                 1
                              
                           
                        
                      mainly carry the object contour “noise”, missing data or outliers (contour noise, cropping, etc.), while the latest IMFs 
                        
                           
                              c
                              
                                 
                                    N
                                    B
                                 
                                 +
                                 1
                              
                           
                           …
                           
                              c
                              N
                           
                        
                      and the residue rN
                      mostly describe the trend of the object contour. Hence, intermediate IMFs 
                        
                           
                              c
                              
                                 N
                                 A
                              
                           
                           …
                           
                              c
                              
                                 N
                                 B
                              
                           
                        
                      describe the initial object contour with simple and uniform curves.

A problem that should be firstly solved is the definition of the turn angle at the common vertex of all the adjacent contour segments. In the proposed approach, a complete different direction in comparison to other methods has been followed. The computation of the turn angle is based on the average angle that is created by the local node neighborhood, as shown in Fig. 3
                      and especially by the middle node (θ
                     3). The angle that is created in one node neighborhood is composed of the node under consideration and its neighbor nodes, while the angle in two node neighborhood is created by the considered node and the nodes next to its neighbors (Fig. 3). The angle in a three nodes neighborhood is created in the same sense, but exploiting the nodes lying after the next to its direct neighbor nodes. This methodology for vertex angle calculation can be proven robust and accurate, since the angles are not computed based on the rounded object contour, as it happens with skeletons which are based on distance transform and on morphological elements, but they are based on the exact IMF position, avoiding probably contour rounding inaccuracies. A local node neighborhood designated to only one node, probably, is more susceptible to contour cuts, tears and generally to shape variations, but as a neighborhood is getting larger, the angle determination algorithm becomes more robust to boundary noise and artifacts. However, a local node neighborhood should not become large enough, since the danger of losing contour detail becomes also larger. The average angle θ
                     
                        i
                     
                     
                        k
                      of a node p
                     
                        i
                     
                     
                        k
                      of the k-th object contour IMF is given by:
                        
                           (4)
                           
                              
                                 
                                    θ
                                    i
                                    k
                                 
                                 =
                                 
                                    1
                                    3
                                 
                                 
                                    
                                       ∑
                                       
                                          m
                                          =
                                          1
                                       
                                       3
                                    
                                    
                                       
                                          θ
                                          i
                                          k
                                       
                                       
                                          m
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where θ
                     
                        i
                     
                     
                        k
                     (m) is the angle created in a local neighborhood of m nodes.

Having calculated each node's average angle of each IMF produced by the 2D EEMD-like algorithm, the proposed method proceeds to the computation of the average angle θ
                     
                        i
                      of each contour point exploiting all produced IMFs. Thus, the final angle map of the object contour is given by:
                        
                           (5)
                           
                              
                                 
                                    θ
                                    i
                                 
                                 =
                                 
                                    1
                                    N
                                 
                                 
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       N
                                    
                                    
                                       
                                          θ
                                          i
                                          k
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where N is the total number of extracted IMFs. Afterwards, the method validates the most important nodes by truncating the nodes with no significant information. As important contour nodes are considered the nodes have a large angle value, while the rest are considered as trivial. The selection of the important nodes is performed by dynamically thresholding the candidate nodes. Thus, the set D of the important nodes is defined as follows:
                        
                           (6)
                           
                              
                                 D
                                 =
                                 
                                    
                                       
                                          
                                             
                                                θ
                                                i
                                             
                                             ≥
                                             μ
                                             −
                                             ασ
                                             ,
                                          
                                          
                                             important
                                             
                                             node
                                          
                                       
                                       
                                          
                                             otherwise
                                             ,
                                          
                                          
                                             trivial
                                             
                                             node
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where μ
                     =
                     E{θ
                     
                        i
                     } is the average angle value of all contour points, 
                        
                           σ
                           =
                           
                              
                                 E
                                 
                                    
                                       
                                          
                                             
                                                θ
                                                i
                                             
                                             μ
                                          
                                       
                                       2
                                    
                                 
                              
                           
                        
                      is their standard deviation and α is a constant value.

The influence of the participant IMFs derived by the 2D EEMD-like algorithm is depicted in Fig. 4
                     , tested on a shape from the shape database used by Sebastian et al. [18]. Fig. 4a depicts the skeleton pruned by the proposed method using only the first IMF. However, the extracted skeleton contains five redundant branches. The exploitation of the first two IMFs (Fig. 4b), leads to the removal of one redundant branch, while by exploiting the first four IMFs (Fig. 4d) all redundant branches are removed, except for one. Finally, after the usage of the first five IMFs (Fig. 4e and f) the produced object skeleton is free of any redundant branch.

When the object under consideration contains holes, a slightly more complex implementation is required. Essentially, one should separately apply the 2D EEMD-like algorithm at all object boundaries (exterior and interiors). For each internal contour of a region, i.e., each contour delimiting a hole, the application of the 2D EEMD-like method is necessary. Therefore, given a 2-D object limited by one external boundary and possibly K internal contours, the 2D EEMD-like algorithm should be applied K times, one for each internal contour position. Then, all extracted IMFs are exploited by the proposed approach (as in the case of regions without holes) in order to extract the desired pruned object skeleton.

The overall object skeleton pruning algorithm is summarized as follows:
                        
                           •
                           step 1: Extract the IMFs of the contours (exteriors and interiors) of the object under examination by applying the 2D EEMD-like algorithm.

step 2: Compute average angles θ
                              
                                 i
                              
                              
                                 k
                               based on a local node neighborhood (Eq. (4)) for each produced IMF.

step 3: Compute the angle map (Eq. (5)) of the object contour.

step 4: Determine the important angle set D (Eq. (6)).

step 5: Prune the object skeleton so as to hold only the nodes carrying an important angle using the important angle set D (Eq. (6)).

@&#EXPERIMENTAL RESULTS@&#

To evaluate the proposed skeletonization algorithm, its performance is tested in three parts: 1) stability in relation to noise and shape variances, 2) an analysis and comparison of skeletons produced by the proposed and well known skeletonization algorithms, and 3) a discussion of the potential for the skeleton matching procedure.

In all experiments, the initial skeleton (input to the proposed algorithm) is obtained exploiting Choi et al. algorithm [13], which produces skeletons with a very large number of branches and details. Furthermore, parameter α in Eq. (6) was set equal to α
                     =2.2. The IMFs used in all the experiments are the intermediate IMFs, except the first and last two IMFs which mainly carry the object contour “noise” and its trend respectively. Furthermore, all the parameters of the approaches compared with the proposed algorithm in this section were experimentally set using the trial-and-error method achieving the best visual results for each tested object.

The first part of the Experimental results section dealt with the evaluation of the stability of the proposed algorithm under scale, rotation and shape variations of the tested image objects.

Some results on selected image objects from the Sebastian image database [18] are shown in Fig. 5
                        . For each tested image object, a “pruned” skeleton is produced by the proposed algorithm which matches to hand-labeled skeleton.

In many computer vision applications, the adopted pre-processing steps, such as rotations, scaling, interpolation methods, segmentation, etc., insert a “noise”-like variation in the image and as a consequence to the contour of the depicted objects (e.g. in most of the objects in Fig. 5). Those contour missing data and outliers make difficult and inaccurate the computation of the skeletons even for the same objects. However, the exploitation of the average angles of the IMFs produced by the 2D EEMD-like algorithm, enforces the proposed method to bypass the above difficulties, rendering, proportional to application, rigid skeletons, proving the robustness of the method to contour loss data, outliers and variations.

The first set of experiments aims at testing the ability of the proposed skeletonization method to correctly produce the skeleton of image objects with boundary noise “inserted” by geometrical transformations, such as rotations and scaling. Figs. 6 and 7
                        
                         demonstrate some of these results. Figs. 6(a) and 7(a) depict the initial images under examination. Figs. 6(b) and 7(b) show the skeletons produced after a 45° rotation of the initial image. Figs. 6(c), (d) and 7(c), (d) illustrate the skeletons produced after object's uniform scaling with 0.5 and 1.5 scaling factors respectively, while Figs. 6(e), (f) and 7(e), (f) depict the results of the proposed method after non-uniform image scaling with 1.5, 1.0 and 0.75, 0.5 scaling factors on X and Y axes respectively. Moreover, Figs. 6(g) and 7(g) show the skeletons after image uniform scaling with 0.75 scaling factor and 45° rotation, and Figs. 6(h) and 7(h) illustrate the skeletons after object's rotation of 120° and uniform scaling with scaling factor equal to 1.5. The application of the two aforementioned transformations in the last two cases of the experiments, is performed with the order they referred. The proposed algorithm bypasses the “noise” inserted by the geometrical transformations and produces stable skeletons, proving its robustness and stability to the contour noise variations.

The previous set of experiments was also repeated, but this time the proposed algorithm was applied on images with artificially inserted noise on their boundary, i.e. the boundary of the image objects has been manually “enriched” with noise (gaussian and uniform). The aim of this experiment was to illustrate that the proposed skeletonization algorithm can offer satisfying results even in the presence of severe boundary noise on the image object under examination. Fig. 8
                         presents some examples. Fig. 8(a) depicts the initial images (first column), while Fig. 8(b) and (c) shows the same images with gaussian (1,0) and (0,1.5) noise added respectively on the object boundary. Fig. 8(d) depicts the initial images with uniform noise (1.2) inserted on the objects contour. The proposed algorithm proved to be robust to artificial boundary noise producing stable skeletons.

Also, to evaluate the proposed method over boundary noise, a simple shape (a rectangular region) with known skeleton was used in the following set of experiments, due to lack of ground databases. The skeletonization results for this shape were compared to a variable amount of boundary noise (Fig. 9
                        ). Fig. 9(a) depicts the initial object and its skeleton, while Fig. 9(b) and (c) shows the skeletons of the object with gaussian noise (0,1) and (0,1.5), respectively, on its boundary. Also, Fig. 9(d)–(f) depicts the skeleton of the object with uniform noise (1.0), (1.2) and (1.5), respectively, on its contour. One can notice, that, despite the existence of the object boundary noise, the extracted skeletons are very similar to the ground truth (Fig. 9(a)). This can be, also, seen by the difference error between the computed skeleton and the zero-noise skeleton presented in Table 1
                        . The difference E between two skeletons was computed as the mean square error between their points, defined as:
                           
                              (7)
                              
                                 
                                    
                                       E
                                       
                                          S
                                          ,
                                          D
                                       
                                    
                                    =
                                    
                                       1
                                       N
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            S
                                                            
                                                               x
                                                               ,
                                                               i
                                                            
                                                         
                                                         −
                                                         
                                                            D
                                                            
                                                               x
                                                               ,
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                   2
                                                
                                                +
                                                
                                                   
                                                      
                                                         
                                                            S
                                                            
                                                               y
                                                               ,
                                                               i
                                                            
                                                         
                                                         −
                                                         
                                                            D
                                                            
                                                               y
                                                               ,
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where S is the skeleton under consideration, D is the zero-noise skeleton, N is the number of skeleton points and S
                        
                           i
                        
                        =[S
                        
                           x,i
                        ,S
                        
                           y,i
                        ]
                           T
                         is the i-th skeletal point of S. In practice, the two skeletons may not have the same number of points, so the Euclidean distance transformation [26] of the skeleton D is calculated. Afterwards, the skeleton S is mapped on the distance transformation map and the average skeleton point distance (error) is computed. Table 1 shows that the average, as well as, the maximum error of skeletons depicted in Fig. 9 are much less than half a pixel, proving the robustness of the proposed method.

In the second part of the Experimental results section, a comparison of the proposed algorithm with other existing skeletonization methods will be presented. Skeletons of almost all the existing methods [7,8,10,11,13] contain a large number of branches. Besides, these methods suffer from other problems, since they cannot cope with object containing holes [16]. The proposed approach can produce, as we already show (Figs. 5, 8 and 9), connected and “pruned” from spurious branches skeletons.


                        Fig. 10
                         depicts some skeletons of four objects obtained by different methods. Method described in [13] produces detailed skeletons (Fig. 10a) with a large number of branches, which, in most cases, are redundant and of no significant importance. On the contrary, skeletons (Fig. 10b) obtained by the approach presented in [16] have much less spurious branches but, still cannot cope with objects containing holes. However, method described in [27] cannot handle objects whose contours have points with no significant convexity (last example of Fig. 10c). Method presented in [21] produces skeletons with much less spurious branches (Fig. 10d) but, it is a very slow algorithm, since it requires a large number of deformations in order to achieve the required skeleton. Methods exploiting morphological elements [28,29] in order to generate skeletons (Fig. 10e) have no problems of connectivity or objects carrying holes, but they usually produce a lot of spurious branches, either large or small. Finally, skeletons obtained by the method presented in this paper (Fig. 10f) are always connected and have no spurious and unimportant branches.

Furthermore, to quantitatively evaluate the proposed method against the aforementioned algorithms, the noisy rectangular regions used in the previous subsection (Fig. 9) were used by all tested methods. The skeletonization results extracted by all methods, were compared with the ground truth using the difference E(⋅) in Eq. (7) and the produced errors are presented in Table 1. Table 1 verifies the robustness of the proposed algorithm to noisy boundaries.

Skeletons produced by the proposed algorithm have strong potential for shape similarity. A contour-based shape similarity measure, as the one introduced by Latecki et al. [30], can be used to match the obtained skeletons. All these matching methods are very sensitive to the quality and to the branch number of the skeletons of the objects under examination. There are very complex graph matching algorithms in the literature [5], in order to establish correspondences of skeleton branches, thus, the quality of the skeletons obtained by the proposed approach makes possible the appliance of existing contour similarity measures to problems with the structural similarity of skeletons.

The Empirical Mode Decomposition has a complexity of O(NlogN) [31], where N is the number of the vertices on the object contour. Assuming that the number of contour vertices N is much larger than the number of iterations M used in the ensemble method, the complexity of the Ensemble Empirical Mode Decomposition (EEMD) is still O(NlogN). On the other hand, if the number of iterations M used in the ensemble approach is similar to the contour points N, then the complexity of the EEMD is O(N
                     2
                     logN). The computation of the skeleton by the proposed algorithm has a complexity of O(N), thus the overall complexity of the proposed algorithm is O(N
                     2
                     logN).

@&#CONCLUSION@&#

A novel approach for object skeleton pruning was presented. The contours of the objects under consideration were decomposed by a 2D empirical mode like decomposition (EMD-like) algorithm. The produced contour intrinsic mode functions (IMFs) provide a workspace with very good properties for pruning the skeleton of the object, which contains no spurious (redundant) branches and is similar to hand-labeled skeleton retaining all the necessary visual branches. The results show that the proposed method produces superior skeletons of the image objects under examination, free from redundant branches, even in the presence of severe noise and shape variations, cuts, tears and holes, preserving the topology of the original skeletons. All the produced skeletons are connected demonstrating high stability even for object with extremely complex shapes. The stability of the skeletons is the key property required to measure the shape similarity of objects using their skeletons.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Gold-standard and improved framework for sperm head segmentation

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We use three different color spaces for detection and segmentation of human sperm head, acrosome and nucleus.


                        
                        
                           
                           We propose a gold-standard built with the cooperation of a referent expert in the field, aiming to create a benchmark set methods for detecting and segmenting sperm cells.


                        
                        
                           
                           We achieve notable improvement in sperm head detection and fewer false positives compared to the state-of-the-art method.


                        
                        
                           
                           Our segmentation approach obtains over 80% overlapping against hand-segmented gold-standard.


                        
                        
                           
                           Our method achieves higher Dice coefficient, lower Hausdorff distance and less dispersion with respect to the results achieved by the state-of-the-art method.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Infertility

Morphological analysis

Sperm head detection

Sperm head segmentation

Acrosome segmentation

Nucleus segmentation

@&#ABSTRACT@&#


               
               
                  Semen analysis is the first step in the evaluation of an infertile couple. Within this process, an accurate and objective morphological analysis becomes more critical as it is based on the correct detection and segmentation of human sperm components. In this paper, we present an improved two-stage framework for detection and segmentation of human sperm head characteristics (including acrosome and nucleus) that uses three different color spaces. The first stage detects regions of interest that define sperm heads, using k-means, then candidate heads are refined using mathematical morphology. In the second stage, we work on each region of interest to segment accurately the sperm head as well as nucleus and acrosome, using clustering and histogram statistical analysis techniques. Our proposal is also characterized by being fully automatic, where a user intervention is not required. Our experimental evaluation shows that our proposed method outperforms the state-of-the-art. This is supported by the results of different evaluation metrics. In addition, we propose a gold-standard built with the cooperation of a referent expert in the field, aiming to compare methods for detecting and segmenting sperm cells. Our results achieve notable improvement getting above 98% in the sperm head detection process at the expense of having significantly fewer false positives obtained by the state-of-the-art method. Our results also show an accurate head, acrosome and nucleus segmentation achieving over 80% overlapping against hand-segmented gold-standard. Our method achieves higher Dice coefficient, lower Hausdorff distance and less dispersion with respect to the results achieved by the state-of-the-art method.
               
            

@&#INTRODUCTION@&#

Infertility is a problem that affects up to 15% of couples worldwide [1]. This condition has emotional and physiological implications including stress, depression or sexual dysfunction [2]. A semen analysis according to standard criteria [3], is the first step in the evaluation of the male factor and sets the basis for all posterior steps for medical treatment of the couple [4]. A typical spermiogram considers concentration, motility, vitality, and/or the fragmentation of the spermatic DNA. In addition, the morphology of the sperm cells is considered as an important parameter to elucidate the potential fertility of a sample [5]. The classification of abnormal sperm morphology is a difficult task since the spectrum of possible malformations is considerably wide [6].

Therefore, it is important to objectively quantify abnormalities, such as double-headed or multiple-tailed sperm, due to implications of the presence of these abnormalities in the semen sample [5]. However, there has been evidence for many decades that the aforementioned quantification is a challenging task. In 1966, a comparative study in 47 laboratories dedicated to human sperm morphological analysis showed that the traditional method of performing the analysis was personality oriented, as well as subjective, qualitative, non repeatable and difficult to teach to students and technicians 
                     [5,7]. Despite of the fact that the classification rules for morphological semen analysis have been simplified [3], the visual analysis of sperm morphology still presents a substantial challenge concerning reproducibility and objectivity, and inter and intra observer variability still presents a well known problem [8–11]. There are many authors revealing a lack of standardization of the methods used in laboratories in many countries [12,13]. A sophisticated computational analysis might help to overcome these problems.

Overall, the evaluation of cellular and sub-cellular regions (size of the sperm head, tail length, residual cytoplasm area, etc.) and pattern recognition (multiple heads or tails, absent tail, coiled tail, etc.) are required for categorizing defects according to normal and abnormal sperm definitions in visual sperm classification under the microscope [14].

In this paper, we present an improved framework for detecting and segmenting human sperm heads, since a reliable detection and segmentation presents the first step for all posterior classification algorithms. This fully automatic approach is based on a clustering method as well as on image processing techniques especially adapted for this application. In addition, we propose to combine different color spaces, instead of using only RGB color space. We also introduce a gold-standard
                        1
                     
                     
                        1
                        Available in http://morfologia.cedai.cl/public/.
                      for head sperm parts segmentation. This dataset was built with the cooperation of a referent expert in the field and contains twenty images with more than two hundred sperm cells plus hand-segmented masks. This gold-standard has been used to evaluate and compare our results with the only reproducible method that has been published in the past and therefore presents our state-of-the-art reference method.

Our main contribution is the application of a clustering algorithm for detecting sperm heads, combining different color spaces. Another contribution is the proposal of a novel algorithm to determine which direction the sperm head points. This is a very important issue for posterior stages in the quest for an accurate morphological analysis.

This paper is organized as follows. In Section 2 we review the research work in the area, focusing on scientific papers and commercial applications whose main goal is segmentation of sperm cells. Our proposed framework as well as the gold-standard, are presented and described in detail in Section 3. In Section 4 we present the description of the results of applying our approach and the state-of-the-art method to the proposed gold-standard, which we discuss in more depth in Section 5. The conclusions can be found in Section 6.

@&#RELATED WORK@&#

In this section, the most prominent approaches for partially automated sperm detection and analysis are discussed, though none of them presents a full morphological analysis of sperm. The characteristics of the three major commercial applications for the morphological analysis of sperm are also described.

The computer assisted sperm morphology assessment has been fueled by the inherent lack of objectivity in the evaluation of human sperm morphology, the difficulty in standardizing, implementing and controlling manual methods, and the high degree of variation within and between laboratories and technicians [10]. With the aim of providing more objective results, semi-automatic methods based on image analysis have been developed [15,16,5,17,18], some of them applied to the veterinary field [19–21].

There are few approaches to evaluate semen samples automatically, even though none of them proposes a complete framework. The work of Park et al. [22] presents an approach for segmentation of sperm heads using the strategic Hough Transform. For each sperm in the image, the authors use the intensity difference between the sperm head and background to select the region of interest (ROI) for the segmentation of the sperm head. The boundary of the sperm head was approximated with an ellipse. The resulting ellipse is represented by a number of parameters that have been investigated by applying the Hough Transform strategically. Finally, the authors use the derived boundary to calculate morphological parameters of the estimated sperm head.

Nafisi et al. [4] proposed an algorithm for finding sperm cells in low contrast images, with the added value of detection of the sperm tail for discarding or not some particles in the image that could be similar in size with a sperm head. The algorithm fits ellipses for detecting the sperm heads.

A two-stage method for segmentation of sperm heads and mid-pieces was presented by Carrillo et al. [23,24] looking for an objective analysis of human sperm morphology. At the first stage, the objects obtained by thresholding using the Otsu method [25] are classified through histogram analysis. Then, some particles are removed according to their size. After that, each sperm cell detected (head and mid-piece) is enclosed in a bounding box. Then, each sperm cell is extracted from the original RGB color image. At the second stage, the authors proposed to segment the head and mid-piece by applying a nth-fusion method to the enhanced image. The nth-fusion method is based on nth-level thresholding of an image followed by intersection with n special growing masks, constructed using prior object morphological models. To the best of our knowledge, this proposal is the state-of-the-art method, and other research works compare their results with it [26,27].

Abbiramy et al. [28] proposed a method for morphological classification of sperm cells either as normal or abnormal using Matlab. One of the steps in their proposal is regarding object segmentation in microscopic images, using sobel edge detector.

Bijar et al. [27] proposed a method for segmentation of sperm acrosome, nucleus, mid-piece and identification of tails. The segmentation step is performed by means of a Bayesian classifier which uses entropy based expectation maximization and a Markov random field. For sperm tail identification, the authors proposed to use a structural similarity index and local entropy techniques. The paper presented results that outperformed those of Carrillo et al., however the experimental framework is so weak that it makes the validation of those results very difficult.

In the context of commercial applications, companies in the interface of research and development offer computer assisted systems for semen analysis, usually referred to as CASA (Computer Aided/Assisted Sperm Analysis). CASA systems are used for research and routine analysis in the area of reproductive medicine (human or animal). It was in the 1990s when the first CASA systems appeared on the market [29,6]. In order to guarantee that the repeatability and validity of CASA systems are higher than any subjective morphological evaluation, it is required that the quality of the preparation, choice and quality of fixing, thickness of the preparation, choice of dyes, type of light and adjustment of optics are carefully chosen [30–33,14].

Common CASA systems that offer morphological analysis tools of human sperm are IVOS – Integrated Visual Optic System (Hamilton-Thorne Biosciences, Beverly, MA, USA), SCA – Sperm Class Analyzer (Microptics, Barcelona, Spain) and medeaLAB (Medical Technology MTG, Altdorf, Germany). IVOS reports sperm head parameters such as elongation and area, while SCA also reports information about mid-piece and tail anomalies. medeaLAB offers the most complete morphological analyzer, reporting the length of the sperm tail. It is subsequently the most expensive CASA on the market and has very restrictive requirements for microscopic and camera equipment. Difficulties in rendering the sperm tail, the cost of these systems, and the specialized equipment and technicians required to operate them limited the introduction of the techniques into andrological practice.

@&#MATERIAL AND METHODS@&#

In this section, we first introduce the proposed gold-standard. We then introduce our two-stage framework, describing each stage in detail. Finally, we discuss the evaluation metrics that we use to assess the quality of our results.

Sperm samples
                              2
                           
                           
                              2
                              Sperm samples obtained from: (1) Laboratory of Spermiogram, Program of Anatomy and Developmental Biology (ICBM), Faculty of Medicine, U-Chile, Santiago, Chile, and (2) Maternal Child Research Institute (IDIMI), San Borja Arriaran Hospital, Santiago, Chile.
                            were stained with a modified hematoxylin/eosin assay, in order to distinguish different parts of sperm morphology (Fig. 1
                           ). Briefly, the sperm smear was fixed with Ethanol 70% and immersed in Harris’ hematoxylin for 10s for nuclear staining. Slides were washed with tap water for ten minutes to remove residual staining. Later, slides were immersed in 1% eosin for two minutes to stain the acrosome in a pink-orange color, mid-piece and tail. Finally, the sample was washed with distilled water for 1min. Then, samples were air dried and fixed. This staining procedure allows using samples for more than one year.

Digital images were acquired using an optical microscope (Axiostar Plus, Carl Zeiss Inc., Wetzlar, Germany), a 63× objective (oil, NA 1.4) with an adapter of 0.63× and a digital camera (scA780-54gc, Basler AG, Ahrensburg, Ger). Twenty images with more than two hundred sperm cells were captured and segmented with the cooperation of an expert.

The proposed framework consists of two stages. In the first, our goal is to identify the ROIs of sperm heads (Fig. 2
                        a). In the second stage, we work on each ROI to accurately segment the sperm head as well as the nucleus and acrosome.

First, we transform the RGB color space to L*a*b*. We choose RGB and L*a*b* after experimental evaluation of the impact of different color spaces such as RGB, L*a*b*, YCbCr, and YQM (Algorithm 1, step 2). We evaluate Hausdorff distance and Dice coefficient values for each color space combination against hand-segmented masks. Then, we apply the k-means clustering algorithm looking for separation of the sperm cells from the background (Fig. 2b). We separate the pixels belonging to sperm cells (heads, mid-piece and/or residual cytoplasm, and tails) in one cluster, and the pixels belonging other structures and background in a second cluster (Algorithm 1, step 3). The resulting image contains the ROIs that we need for the second stage in the cluster of a smaller area (Algorithm 1, step 4).

Considering that our detection and segmentation algorithm aims for an accurate morphological analysis, there are some conditions that we must meet. Therefore, these regions need to be refined. This refinement includes eliminating sperm cells which touch the border of the image (Algorithm 1, step 5).

In order to eliminate most of the pixels that are not part of sperm heads, we use a binary morphology-based idea. We propose to use a convolution process with a disk-shape kernel of size r and unitary weight (Algorithm 1, step 6). After convolution, we remove all pixels with a resulting value below a threshold sumV. We refer to this procedure as eraseTails (Fig. 2c).


                           
                              Algorithm 1
                              Detection of sperm heads.


                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                imRgb: original image
                                             
                                             
                                                
                                                r: size of neighborhood for eraseTails
                                                
                                             
                                             
                                                
                                                sumV: threshold value for sum inside neighborhood in eraseTails
                                                
                                             
                                             
                                                1:
                                                imLab ← transformRGBtoLAB(imRgb)
                                             
                                             
                                                2:
                                                data ← [imRgb(1) imRgb(2) imRgb(3) imLab(1) imLab(2) imLab(3)]
                                             
                                             
                                                3:
                                                [cluster1,cluster2] ← kmeans(data,2)
                                             
                                             
                                                4:
                                                cluster ← chooseMinorCluster(cluster1,cluster2)
                                             
                                             
                                                5:
                                                noBorderImage ← eraseBorderSperms(cluster)
                                             
                                             
                                                6:
                                                noTailImage ← eraseTails(noBorderImage,r,sumV)
                                             
                                             
                                                7:
                                                return finalImage
                                             
                                          
                                       
                                    
                                 
                              

In the next section, we present our approach to segment sperm heads. After the ROI detection, we individualize each sperm head and work separately with each one. We segment the whole head and then process to identify the regions of nucleus and acrosome. Afterward, we describe the algorithm that we propose for each step.

For each individual sperm head (Fig. 3
                           a), we first refine the detected candidate head by means of applying morphological opening and discarding objects whose size are out of range between minTs1 and maxTs1 (Algorithm 2, step 2). We work with the color-opponent dimensions of L*a*b* color space and with the Cr component of the YCbCr color space (Algorithm 2, step 3). We then apply k-means only in the particular ROI (Fig. 3b) to separate the darkest part of the head from the rest (that could be acrosome and residual cytoplasm). As this portion of the head is smaller than the real head (Fig. 3c), we need to enlarge it, up to the region of interest, but without residual cytoplasm or mid-piece. Thus, it is important to determine the front direction of the head (Algorithm 2, step 7). We use maxTc as a maximum size threshold (Algorithm 2, step 6) to consider a set of pixels as a candidate head whose pointing direction is important.

To determine the direction in which the head points, we propose a two-step method (Algorithm 3). First, we determine the orientation of the sperm head as the angle between the X axis and the major axis of the ROI, and using this angle, we rotate the head to a horizontal position in which the major axis of the fitted ellipse is parallel to the X axis (Algorithm 3, step 2). We then divide this major axis in three similar portions (Fig. 3d) and calculate a fitness value [34] of the two extreme portions with the fitted ellipse (Algorithm 3, steps 10/11). The portion corresponding to the lowest fitness value indicates the direction to where the head points. The pointing direction allows us to build a growing mask for segmenting the whole head, and not only the darkest part of the head (Algorithm 2, step 8). So, the next step consists in setting a growing mask according to head pointing direction and angle ∈[0, 2π) and apply it to the part of the head previously segmented (Algorithm 2, step 9). As a final refinement, we eliminate the small and big objects according to minTs2 and maxTs2 threshold values (Fig. 3e).


                           
                              Algorithm 2
                              Segmentation of one sperm head.


                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                white: binary image with a candidate sperm detected
                                             
                                             
                                                
                                                minTs1: minimum number of pixels of a sperm head before k-means
                                             
                                             
                                                
                                                maxTs1: maximum number of pixels of a sperm head before k-means
                                             
                                             
                                                
                                                maxTc: maximum number of pixels of a candidate head after kmeans
                                                
                                             
                                             
                                                
                                                minTs2: minimum number of pixels of a sperm head after growing
                                             
                                             
                                                
                                                maxTs2: maximum number of pixels of a sperm head after growing
                                             
                                             
                                                1:
                                                white ← opening(white)
                                             
                                             
                                                2:
                                                white ← eraseBySize(white,minTs1,maxTs1)
                                             
                                             
                                                3:
                                                data ← [imLab(2) imLab(3) imYCbCr(3)]
                                             
                                             
                                                4:
                                                [cluster1,cluster2] ← kmeans(data,2)
                                             
                                             
                                                5:
                                                smallHead ← chooseMinorCluster(cluster1,cluster2)
                                             
                                             
                                                6:
                                                smallHead ← eraseBySize(smallHead,0,maxTc)
                                             
                                             
                                                7:
                                                [angle,direction] ← getPointingDirection(white,smallHead)
                                             
                                             
                                                8:
                                                mask ← generateGrowingMask(white,angle,direction)
                                             
                                             
                                                9:
                                                head ← makeHeadBigger(white,mask,smallHead)
                                             
                                             
                                                10:
                                                finalImage ← eraseBySize(head,minTs2,maxTs2)
                                             
                                             
                                                11:
                                                return finalImage
                                             
                                          
                                       
                                    
                                 
                              


                           
                              Algorithm 3
                              Sperm head direction.


                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                white: binary image with a candidate sperm detected
                                             
                                             
                                                1:
                                                angle ← getOrientation(white)
                                             
                                             
                                                2:
                                                whiteRot ← rotateImage(white,angle)
                                             
                                             
                                                3:
                                                imgBorder ← getPerimeter(whiteRot)
                                             
                                             
                                                4:
                                                maximum ← number of columns of imgBorder
                                             
                                             
                                                5:
                                                x1 ← ceil(maximum/3)
                                             
                                             
                                                6:
                                                x2 ← 2*x1
                                             
                                             
                                                7:
                                                [xc,yc] ← getCentroid(whiteRot)
                                             
                                             
                                                8:
                                                majorAxis ← getMajorAxis(whiteRot)
                                             
                                             
                                                9:
                                                minorAxis ← getMinorAxis(whiteRot)
                                             
                                             
                                                10:
                                                value1 ← fitnessFunction([xc,yc,majorAxis,minorAxis,0],imgBorder,a,x1)
                                             
                                             
                                                11:
                                                value2 ← fitnessFunction([xc,yc,majorAxis,minorAxis,0],imgBorder,x2,maximum)
                                             
                                             
                                                12:
                                                
                                                   if value1 < value2 then
                                                
                                             
                                             
                                                13:
                                                direction ← 0
                                             
                                             
                                                14:
                                                
                                                   else
                                                
                                             
                                             
                                                15:
                                                direction ← 1
                                             
                                             
                                                16:
                                                
                                                   end if
                                                
                                             
                                             
                                                17:
                                                return angle and direction
                                             
                                          
                                       
                                    
                                 
                              

The parameters returned by Algorithm 3 can be used to generate eight different growing masks, according to all the possible orientations that a sperm head could present. The growing mask is created using angle and direction, as the following.


                           
                              
                                 
                              
                           
                           
                              
                                 
                              
                           
                        

The segmented sperm head is used for the posterior segmentation of nucleus and acrosome. To this end, we performed a statistical analysis to determine the intensity characteristics of both head components, working on the red channel of RGB color space. We use the R channel of the RGB color space because R offers a better differentiation between sperm nucleus and acrosome, compared to the G or B channels. The Otsu threshold calculated in this region allows us to separate pixels of the nucleus from pixels of the acrosome (Algorithm 4, step 2).

The nucleus region is darker than the acrosome region because of a staining effect. Therefore, we pick the biggest ROI in the lighter region as the acrosome (Fig. 4
                           c). The segmented regions are obtained as a difference set operation between the pixels in the acrosome and pixels in the nucleus (Fig. 4d). We use our proposed procedure eraseTails to smooth the resulting acrosome and nucleus.


                           
                              Algorithm 4
                              Segmentation of nucleus and acrosome.


                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                white: binary image with a segmented sperm head
                                             
                                             
                                                
                                                imRGB: rgb image with a segmented sperm head
                                             
                                             
                                                
                                                r: size of neighborhood for eraseTails
                                                
                                             
                                             
                                                
                                                sumV: threshold value for sum inside neighborhood in eraseTails
                                                
                                             
                                             
                                                1:
                                                imRed ← imRGB(:,:,1)
                                             
                                             
                                                2:
                                                threshold ← OtsuThreshold(imRed)
                                             
                                             
                                                3:
                                                acrosome ← pixels in imRed whose value is > threshold
                                             
                                             
                                                4:
                                                acrosome ← eraseTails(acrosome,r,sumV)
                                             
                                             
                                                5:
                                                acrosome ← getBiggestROI(acrosome)
                                             
                                             
                                                6:
                                                nucleus ← imageDifference(white,acrosome)
                                             
                                             
                                                7:
                                                nucleus ← eraseTails(nucleus,r,sumV)
                                             
                                             
                                                8:
                                                return acrosome and nucleus
                                             
                                          
                                       
                                    
                                 
                              

Given a gold-standard, we have four possible scenarios to evaluate our algorithm: true positives (TPs), the number of correctly detected objects, true negatives (TNs), the number of correctly detected non objects, false positives (FPs), the number of wrongly detected non objects, and false negatives (FNs), the number of wrongly non detected objects.

To evaluate detection algorithms, we use true-positive rate, false-positive rate and precision as follows.


                           
                              
                                 
                                    True-positive rate
                                    =
                                    
                                       TP
                                       
                                          TP
                                          +
                                          FN
                                       
                                    
                                 
                              
                           
                           
                              
                                 
                                    False-positive rate
                                    =
                                    
                                       FP
                                       
                                          FP
                                          +
                                          TN
                                       
                                    
                                 
                              
                           
                           
                              
                                 
                                    Precision
                                    =
                                    
                                       TP
                                       
                                          TP
                                          +
                                          FP
                                       
                                    
                                 
                              
                           
                        

Given a gold-standard segmentation, we can use different methods to evaluate the quality of segmentation. In general, the idea is that the automatic segmentation S has to be compared to the manually segmented image (gold-standard) G, by computing some evaluation metrics. These metrics can be based on spatial overlap measures (e.g. Dice coefficient [35]) and on distance measures (e.g. Hausdorff distance [36]). Table 1
                            summarizes the evaluation metrics used in this paper.

@&#RESULTS@&#

This paper presents a gold-standard, aiming to compare our method to previously published methods [24] or methods that could improve our approach in the future. This represents a significant contribution of our work, because at present there is not a public standard ground-truth, so the few existing methods cannot be evaluated properly.

We implemented Carrillo's method [24], since it is not availably as a source code by the authors to compare our detection and segmentation precision. We obtain a significant improvement as shown in the following sections.

We have conducted experiments for parameter estimation, and for comparison of our approach and Carrillo's method using Matlab.
                        3
                     
                     
                        3
                        Matlab R2013a 8.1.0.604.
                     
                  

So far, a gold-standard data set for detecting and segmenting human sperm heads does not exist. Our gold-standard data set consists of 20 images with 264 sperm cells, where 210 (70 tapered, 45 pyriform, 52 amorphous, 15 small, 2 round, and 26 normal) are valid sperm cells (not at the border of image, without noise on it, etc.). Each image has 780×580 pixels (Fig. 2a). For each of these images, hand-made ground-truths have been designed under supervision of a referent expert in the field. We generated segmentation masks for each sperm cell, considering the nucleus and acrosome, among others.

In order to choose the best set of parameters, we have performed different experiments varying the values of seven parameters that are described as following. The first two are referred to the procedure eraseTails, related to the neighborhood size (r) and the threshold value for the sum in the underlying neighborhood (sumV). This procedure is called from the Algorithms 1 and 3. The remaining five parameters are used in Algorithm 2 and are related to the allowed size of sperm heads at different stages of the segmenting process. The parameters minTs1 and maxTs1 are used for a refinement step before applying k-means, while maxTc indicates the maximum size of sperm heads allowed to grow with a growing mask. The last two parameters, minTs2 and maxTs2 indicate size threshold values for the final segmented heads. In Table 2
                         the variation of parameters is shown. The final values were chosen according to the best tradeoff between true positive and false negative values, as well as Dice coefficient.

In addition, we have evaluated parameter values for Carrillo's method. There are five free parameters in our implementation. The first two parameters, aMin and aMax are referred to the minimum and maximum size in pixels, to be allowed for a head of a sperm cell. The parameter gIntensity is used as a maximum threshold value. The two last parameters, tMin and tMax, represent a range for sperm cell validation. In this sense, if the sum of pixel values of a candidate sperm cell falls within the range [tMin, tMax], the candidate is considered a sperm cell, in other case it is discarded. In Table 3
                        , we show the variation of parameters for Carrillo's method in our experiments.

The performance of our detection results was determined by ROC curve. ROC curve takes into account the area under the curve (AUC) as a quality measure. The higher the AUC, the better the quality of a method. The ROC curve determines the cost in terms of false positives when a high correct detection is desired (Fig. 5
                        ). To create each point of the ROC curve, we calculated the percentage of correct detection (according our gold-standard) and the number of false positives for a given instance of the parameter values.

Our approach achieves an AUC value of 0.88 while Carrillo's method accomplishes 0.81. In addition, our proposal achieves a correct detection rate over 97% at the expense of having only 23 false positives. To achieve a comparable result with a correct detection rate over 97%, Carrillo's method achieves 41 false positives. Carrillo's method reports a correct rate over 95% [24,26]. According to our experiments, this rate is achieved with 39 false positives. In Table 4
                         the relationship between false positives and correct detection is shown for both evaluated methods.

We performed different experiments to assess segmentation of sperm head, acrosome and nucleus. In each case, we calculate two quality measures for our results: the Dice coefficient to assess the accuracy of our results with hand-segmented masks and the Hausdorff distance (considering d as Euclidian distance) to assess the disagreement of segmentation against hand-segmented mask.

As mentioned before, we compare our segmentation results with the results obtained by implementation of Carrillo's method. We also calculate Dice coefficient and Hausdorff distance, using the same testing images in order to compare the results.


                        Fig. 6
                         shows an image gallery with some segmentation results, considering head, acrosome and nucleus segmentation. For each segmentation (head, acrosome and nucleus), we present our best, average and worst result, in terms of Dice coefficient. For each image, we show the result of applying Carrillo's method to the same sperm head.


                        Fig. 7
                         shows Dice coefficients for both segmentation results (our proposed method and Carrillo's method). The Dice coefficient assesses quality of sperm head segmentation as well as acrosome and nucleus segmentation, by means of measuring the overlap with ground-truth. We applied our proposed method to the testing images and calculated Dice's coefficients for each segmented sperm head. The same procedure was followed in the case of acrosome and nucleus. Then, we applied Carrillo's method to the same data set and calculated the Dice coefficient for each segmented sperm head, acrosome and nucleus. For every component (head, acrosome and nucleus), the Dice coefficients of our proposed method are significantly better than those achieved by Carrillo's method. Our average results have more than 80% of overlapping against hand-segmented masks, with average Dice coefficients of 0.88, 0.83 and 0.82 for head, acrosome and nucleus segmentation, respectively.


                        Fig. 8
                         shows a graphical representation of the probability density function (PDF) for Dice coefficients, corresponding to acrosome, nucleus and sperm head segmentation, together. This is a comparison between the PDF corresponding to our results and the one corresponding to the results achieved by Carrillo's method. As we can observe, the distribution of values for Dice coefficient achieved by our method (with σ
                        =0.06) is shifted to higher Dice coefficients and provides smaller variance than that of Carrillo's method (with σ
                        =0.08).

Additionally, we present a comparison of Hausdorff distance corresponding to our proposed framework and results of Carrillo's method, in Fig. 9
                        . As in the previous case, our aim is to assess quality of segmentation of sperm heads and sperm head parts (acrosome and nucleus), but now by means of measuring the disagreement with ground-truth. We followed the same procedure as in Dice coefficients case. For every component (head, acrosome and nucleus), the Hausdorff distance values of our proposed framework are better than those achieved by Carrillo's method, because ours show a smaller distance (in average) between perimeters of hand-segmented mask and segmentation results. Our average results have less than 25% of disagreement with hand-segmented masks, with average Hausdorff distance values of 0.15, 0.20 and 0.24 for head, acrosome and nucleus segmentation, respectively.

@&#DISCUSSION@&#

In this paper we have presented a framework for sperm cell segmentation achieving significant improvement with respect to Carrillo's method. Our approach is different from the proposals so far known (Section 2) in three different aspects:
                        
                           1
                           
                              Use of color space combinations. Choices of color space have significant influences on the result of image segmentation. Cheng et al. [37] compared several color spaces including RGB and L*a*b* for color image segmentation purposes, and they stated that the selection of a color space for image processing is image/application dependent. All the research works cited in Section 2 use RGB color space to segment sperm cells, including Carrillo's method. However, RGB is not suitable for color segmentation and analysis because of the high correlation among the R, G, B components [38,39]. Besides, it is impossible to evaluate the similarity of two colors from their distance in RGB space because RGB space does not represent color differences in a uniform scale.

In this proposal, we choose to work with a hybrid color space combining RGB, YCbCr and L*a*b* color spaces. Therefore, for detection stage (Section 3.2.1) we used six redundant color features in RGB and L*a*b* color spaces. L*a*b* color space represents perceptual uniformity, and it is especially efficient in the measurement of small color difference, because this can be calculated as the Euclidian distance between two color points [37], and particularly as ΔE distance between two color points [40]. For us, it was important that L*a*b* space can control color and intensity information more independently and simply than RGB. Also, it has been shown that L*a*b* color space gives better results than others in color segmentation [41]. We decided to keep RGB along with L*a*b* color space after intensive experimental evaluation, and regarding related work techniques. In addition, for segmentation stage (Section 3.2.2) we choose to combine L*a*b* and YCbCr color spaces. A chromatic component of YCbCr was introduced due to two reasons: (a) the color difference of human perception can be directly expressed by Euclidean distance in the color space, and (b) the intensity and chromatic components can be easily and independently controlled. In general, YCbCr color space has been extensively used for skin color segmentation [42,43].


                              Use of clustering method. All the existing color image segmentation approaches are ad hoc, because they are strongly application-dependent. Among several segmentation methods, clustering has been widely used for color image segmentation [44–47]. This is due to the fact that for color images, a color space is a natural feature space, and colors tend to form clusters in the color space. From the viewpoint of color clustering, it is desired that the image is represented by color features which constitute a space possessing uniform characteristics such as the L*a*b* color space [44]. We choose to apply k-means clustering in both stages of our proposal: detection and segmentation of sperm heads. As a traditional clustering algorithm, k-means is popular for its simplicity for implementation, and also, it can be adopted to solve illumination variation problem. This, combined with YCbCr and L*a*b* color spaces, provide us an exceptional tool for illumination invariant segmentation approach, outperforming the state-of-the-art.


                              Identification of sperm head direction. One of the key contribution of our work is the proposal of a novel algorithm to determine which direction the sperm head points. This has not been considered before in any of the research works reviewed in Section 2. Properly identification of the head front direction could serve to accurately segment the sperm head and to discard mid-piece regions or residual cytoplasm areas that may have been included in the result of the detection. In related works [22,48,4,20], it has been observed that authors proposed ellipse fitting for head morphological analysis and experimental evaluation, but they have not used it to refine the segmentation itself. Our proposal generates eight types of different growing masks, regarding all possible positions in which a sperm head may appear. To our knowledge, none of the proposed approaches (including Carrillo's method) have taken into account the head front direction, however, it is a very important issue that could help in many other stages in the quest for an accurate morphological analysis.

Our results have shown that our approach, based on those aspects described above, outperforms the results achieved by Carrillo's method. In fact, we showed that our method achieves a higher Dice coefficient, lower Hausdorff distance and less dispersion with respect to the results achieved by Carrillo's method. This is clearly shown in gallery presented in Fig. 6. We believe that this outperforming occurs mainly because of the results of the first stage of our proposed method (Algorithm 1), combining RGB and L*a*b* color spaces. This stage result is extremely accurate to segment sperm heads. However, as part of the heads, we also segmented mid-piece areas, residual cytoplasm areas, and even tails. This pixel separation is probably due to the higher Euclidean distance between color pixels corresponding to the cells and background, incorporating L*a*b* color space. It is important to note that non-coiled tails are removed (though not all of their extension) by the procedure empheraseTails (Fig. 2). In addition, when including a YCbCr chromatic component for separating sperm nucleus, our proposed approach removes mid-piece and residual cytoplasm areas, as well as rests of tails and coiled tails (Fig. 6, first row of nucleus segmentation). This is a substantial difference against Carrillo's method that discards such cells because overcome size threshold. It should be noted that individualize each sperm head for a more accurate segmentation, makes it possible to work with spatially close cells and we obtain significantly better results than Carrillo's method (Fig. 6, first row of head segmentation). We believe that this contributes to have an average Dice coefficient greater than the state-of-the-art method (Fig. 8), observing that most of our Dice coefficients are greater than the average Dice coefficient obtained by the Carrillo's method.

It is expected that no detection method could achieve detection rate of 100%. Our method is able to correctly detect up to 206 sperm cells (98%), while the method proposed by Carrillo et al. is able to correctly detect 208 sperm cells (99%) (Fig. 5). There are specific situations in test images that are affecting our detection rate (Fig. 10
                     ). We observe few sperm cells with excessive residual cytoplasm area, whose front head direction is erroneously detected (because cytoplasm area fits better with an ideal ellipse than frontal region of its head). Then, in size validation of candidate head, this head is removed by having a larger area than maxTs2 threshold (Section 4.2). Also, we observed a particular sperm cell overlapping an incomplete tail of another sperm cell. Thus, as they both are connected, the eraseTails procedure would remove both (overlapped head and incomplete tail) as if it were only one tail.

There is a tradeoff between correct detection rate and number of false positives. Our method provides 25 false positives with detection rate of 98%, while the method proposed by Carrillo et al. provides 49 false positives with detection rate of 99% (Fig. 5). It is a very significant difference, in terms of false positives number that we believe is due to three factors. First, we validate pixels of the object/background using Euclidean distance to not include objects with a darker intensity than that of a sperm head, and combining RGB, L*a*b*, and YCbCr color spaces (Algorithms 1 and 2), better than using only RGB space color, as Carrillo's method does. Second, our proposed method removes objects according to their size and roundness, after applying k-means (Algorithm 2), while Carrillo's method only regards size validation. Therefore, Carrillo's method is more likely to report strangely shaped objects but with a size similar to a sperm head. Third, our method removes incomplete sperm cells which touch the border of the image (Algorithm 1). Carrillo's method does not take this into account, and reports heads of incomplete sperm cells as correct detected heads. It is important to note that all the false positives reported by our approach are actually sperm heads, however they are not drawn in the gold-standard because they do not present a complete tail in the image.

@&#CONCLUSIONS@&#

We have presented a two-stage improved framework for detection and segmentation of human sperm head characteristics (including acrosome and nucleus). The usage of color space combinations (RGB, L*a*b* and YCbCr), together with the usage of a clustering method, provides us an exceptional tool for illumination invariant segmentation approach. In addition, our method proposed an ellipse fitting based algorithm to identify the head front direction. This is a very relevant issue to increase the accuracy of the segmentation.

Our experimental evaluation shows that our proposed framework outperforms the state-of-the-art, with a higher Dice coefficient, lower Hausdorff distance and less dispersion with respect to the results achieved by Carrillo's method [24]. Our results achieve notable improvement in the detection rate with fewer false positives and an accurate head, acrosome and nucleus segmentation achieving over 80% overlapping against hand-segmented mask.

To tackle the problem of lacking a public gold-standard for evaluating sperm head segmentation methods, we have introduced a gold-standard for head sperm parts segmentation, built with the cooperation of a referent expert in the field. This gold-standard has been used to evaluate and compare our results with the state-of-the-art method, and can be used to compare not only known techniques but also future improvements to present approaches. This is a very significant contribution to the scientific community.

In our ongoing work, we are analyzing the impact of adding active contours as a third segmentation stage. For the future work, we will focus on both mid-piece and tail segmentation in order to provide a complete sperm parts segmentation tool.

@&#ACKNOWLEDGEMENTS@&#

The authors thank E. Labbe for support with the drawings of gold-standard. The authors thank A. Garcia for support with Fig. 1. Research in SCIAN-Lab (S. Härtel) is funded by FONDECYT (1120579), FONDEF (D11I1096), and the Biomedical Neuroscience Institute (BNI, ICM P09-015-F). SCIAN-Lab is a selected member of the German-Chilean Center of Excellence Initiative (DAAD). Violeta Chang was partially funded by CONICYT (NAC-DoctoradoLatin 57090057/NAC-ApoyoTesis 24100118) and she is partially funded by FONDECYT (1020579). Jose M. Saavedra is partially funded by CONICYT (PAI-78120425). Victor Castañeda is funded by FONDECYT (3140444) and U-Redes BioMedHPC.

@&#REFERENCES@&#


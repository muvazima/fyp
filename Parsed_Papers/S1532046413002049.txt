@&#MAIN-TITLE@&#Reuse of termino-ontological resources and text corpora for building a multilingual domain ontology: An application to Alzheimer’s disease

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Method which exploits corpora and existing ontological resources for ontology construction.


                        
                        
                           
                           Used for building a bilingual ontology dedicated to Alzheimer’s disease.


                        
                        
                           
                           Ontology enriched by integrating new entities through a parallel corpus and syntactic dependencies.


                        
                        
                           
                           The resulting ontology was validated by domain experts.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Ontology development

Alzheimer’s disease

Ontological resource reuse

Term alignment

Parallel corpus

@&#ABSTRACT@&#


               
               
                  Ontologies are useful tools for sharing and exchanging knowledge. However ontology construction is complex and often time consuming. In this paper, we present a method for building a bilingual domain ontology from textual and termino-ontological resources intended for semantic annotation and information retrieval of textual documents. This method combines two approaches: ontology learning from texts and the reuse of existing terminological resources. It consists of four steps: (i) term extraction from domain specific corpora (in French and English) using textual analysis tools, (ii) clustering of terms into concepts organized according to the UMLS Metathesaurus, (iii) ontology enrichment through the alignment of French and English terms using parallel corpora and the integration of new concepts, (iv) refinement and validation of results by domain experts. These validated results are formalized into a domain ontology dedicated to Alzheimer’s disease and related syndromes which is available online (http://lesim.isped.u-bordeaux2.fr/SemBiP/ressources/ontoAD.owl). The latter currently includes 5765 concepts linked by 7499 taxonomic relationships and 10,889 non-taxonomic relationships. Among these results, 439 concepts absent from the UMLS were created and 608 new synonymous French terms were added. The proposed method is sufficiently flexible to be applied to other domains.
               
            

@&#INTRODUCTION@&#

Among the many challenges that Public Health is faced with, Alzheimer’s disease and related disorders appear as one key issue. In France, the number of people suffering from Alzheimer’s disease is estimated at 860,000. Every year, 220,000 new cases are identified in this country. Nearly 350,000 people benefit from care for the long-term complaint of Alzheimer’s-type illness and related disorders. The French Alzheimer’s Plan has been launched in this context. The 2008–2012 Plan included 44 measures related to three main objectives: (i) improving the quality of life for patients and caregivers, (ii) knowing how to act better and (iii) raising awareness around the social issue. Among these measures, number 32 in particular addresses the training in clinical epidemiology.
                           1
                           
                              http://www.plan-alzheimer.gouv.fr/measure-no32.html.
                        
                        
                           1
                         More practically, the aims are to improve the quality of medical practice by educating practitioners in clinical epidemiology and evidence-based medicine and to increase the number of medical practitioners capable of participating in clinical investigation and taking part in research protocols. To develop research and to involve a larger number of physicians either in including patients in protocols or conducting studies, they must be offered training using different incentives from those of observational medicine, reading the medical literature critically and analyzing the variability of practice.

Conversely, rapid and efficient decision making is a crucial issue in the public health domain and especially in the Alzheimer’s disease domain. Decision-makers should refer to various experts’ opinions as they cannot screen themselves all the scientific facts reported in different sources including online scientific literature and results of clinical trials.

Within this framework, the BiblioDem Digital Library (referred as BiblioDem in this paper)
                           2
                           
                              http://www.isped.u-bordeaux2.fr/CDD/FR_HTML_BIBLIONET.aspx.
                        
                        
                           2
                         was launched in January 2004. It provides a critical review of scientific papers dealing with Alzheimer’s disease and related diseases coming from reference journals in the topic. Thus, it is an expert review (written in French) of Alzheimer’s disease related international literature. A bibliographic foresight is manually performed by a librarian and the BiblioDem advisory board selects between 30 to 50 papers among the average 1000 retrieved each month. A critical analysis of each selected article is then carried out by a domain research expert. All the papers which have been reviewed are integrated into an online bibliographic database, BiblioDem. Note that the papers which are too theoretical are discarded because the main objective is to help daily practice of healthcare workers and caregivers. Finally, the 15 most relevant and original papers are included in a monthly newsletter, called BiblioDémences.

BiblioDem currently contains over 1500 documents, each of them being recorded with the title, the abstract, the critical analysis in French, and the name of the expert who carried out the analysis. The search engine associated with BiblioDem remains simple as only an exact match is performed: papers are retrieved only if the term(s) constituting the query is (are) present as such in the title and/or abstract of papers. Moreover, the variety of users and their level of expertise are not taken into account. The users may be medical students, research scientists, clinical investigators, general practitioners, administrative people from the French Department of Health, experts from the French National Authority for Health and neophytes (including caregivers). These users have different access preferences to BiblioDem.

The Semantic BiblioDem Portal (SemBiP) was proposed in this context. It aims at addressing the above mentioned limitation by delivering a semantic portal which provides advanced features for improving decision making in Alzheimer’s disease and related disorders. More precisely, the main objective of SemBiP is to provide semantic web-based technologies enabling users to easily find papers in BiblioDem with the corresponding critical reports according to their needs and to access to educational content.

The SemBiP project is designed to offer a semantic access to scientific resources on Alzheimer’s disease and related disorders. Its objectives are: (i) providing a multilingual (English and French, at first) knowledge resource dedicated to the description of Alzheimer’s disease and related diseases supporting both content indexing and educational purpose. The evolution of this vocabulary has to be managed; (ii) providing a semantic portal enabling semantic search and browsing of approved available evidence about Alzheimer’s disease and related disorders; (iii) taking into account the specificity and variety of users. According to the user profile, adapted search functionalities should be offered; (iv) allowing multilingual access of both the original abstract (and the full paper if freely available) and their critical analysis in order to improve decision making. The multilingual aspects are very important for supporting both indexing and cross-lingual information retrieval in the portal.

The aforementioned objectives will be achieved by respecting a set of requirements that SemBiP must fulfill in order to efficiently serve its purpose. The main requirement to ensure added-value for BiblioDem as described previously is the availability of an Alzheimer’s disease (and related illnesses) knowledge resource. This knowledge will serve as the backbone for semantic indexing, searching and resource browsing. It should hold synonymous terms in French and English, which have to be clustered into concepts. Taxonomic
                           3
                           In this paper, we use the term “taxonomic” to denote the subsumption relation.
                        
                        
                           3
                         and non-taxonomic relations
                           4
                           The term “relation” is used for the relation name and relationship to denote the triple using that relation to relate concepts.
                        
                        
                           4
                         should be defined between concepts. These characteristics are necessary for efficient medical resource annotation and semantic information retrieval [1]. Building this knowledge resource is the object of the present paper.

Although many terminologies and ontological resources have been developed in the biomedical domain [2], there is still a need to cover emerging subdomains such as Alzheimer’s disease of which domain knowledge is regularly enriched. Therefore, modeling relevant knowledge about the domain is an important issue for a better understanding of the disease and a better support for patients. The focus of this paper is the reuse of existing knowledge resources and the exploitation of parallel corpora for building a bilingual domain ontology of Alzheimer’s disease.

The proposed approach is based on representative and domain specific corpora and reuses a wide specialized resource (UMLS) to assist the task of structuring knowledge. Concretely, it uses NLP tools to identify candidate terms from texts. The conceptualization process is based on the UMLS and consists of clustering these terms into concepts and organizing them through semantic relations. In addition, since we exploit a particularly abundant resource (UMLS), we used its Semantic Network (extraction of semantic types), specific non-taxonomic relations of the Metathesaurus to structure the concepts better. The resulting ontology is then enriched semi-automatically with new relevant terms absent from the UMLS, concepts and relationships using syntactic dependencies.

@&#RELATED WORK@&#

An ontology is defined as “an explicit specification of a conceptualization” [3], which is an important tool for modeling, sharing and reuse of domain knowledge. It allows domain knowledge to be represented explicitly through concepts and relations between them and hence to manipulate it automatically. Given its promising nature, it is used in different fields of research in computer science such as knowledge management, data integration and information retrieval. However, ontology construction by hand is a complex and time-consuming task [4], which requires a lot of human effort. Although many approaches have been proposed to guide this process [5], most of these methodologies are manual [6]. This makes their application difficult and time-consuming. For these reasons, semi-automatic approaches try to automate certain steps to facilitate the ontology construction process. Among these approaches, ontology learning from texts has been widely used in ontological engineering during the last fifteen years [4,7,8]. These approaches consider texts as primary sources of knowledge and rely on natural language processing (NLP) methods for (semi) automatic extraction of knowledge from textual resources.

Faced with the challenge of ontologies construction and the required effort for this task, the reuse of existing termino-ontological
                        5
                        We use this adjective to designate both structured vocabularies and ontologies.
                     
                     
                        5
                      resources remains a very important issue especially in the biomedical domain where large resources are available. Thus, approaches can benefit from these resources to ease and speed up the ontology building process. These techniques often try to capture the implicit semantics of these resources. In the literature, many studies have focused on the reuse of existing resources for ontology engineering [9]. A general methodology proposed in [10] defines a technique for reusing ontological and non-ontological resources to facilitate the ontology building process. It provides a procedure for converting these knowledge resources into ontologies using WordNet
                        6
                        
                           http://wordnet.princeton.edu/.
                     
                     
                        6
                      to acquire explicit relationships. In [11], authors also propose a generic methodology for transforming classifications, thesauri, and informal taxonomies into consistent ontologies. In their approach, the human intervention is limited but original hierarchies of source terminologies are always preserved and considered as taxonomic relationships in the target ontology. Chrisment and al. [12] used a thesaurus and a reference corpus to build an ontology in the astronomy domain. For structuring concepts, they consider the relations<
                     narrower than
                     >and<
                     broader than
                     >which are less specific than the taxonomic relations. In addition, they do not provide automatic mechanisms to disambiguate these relations.

In the biomedical domain, Hahn and Schulz [13] also proposed a similar methodology to build a formal ontology from UMLS resources. Authors reused knowledge contained in this resource to develop a formal model with a more detailed level of conceptualization. They especially focused on reasoning based on taxonomic and meronymic relations. Their approach requires additional modeling efforts and a manual validation. In [14], authors experiment an ontology reuse methodology in the domains of eRecruitment and medicine and discuss the challenges related to this process. They show, from their experiments, that benefits of ontology reuse depend on the nature of the sources reused and their particular domain. Their approach examines different aspects of ontology reuse, but the enrichment phase by integration of specific knowledge not contained in knowledge sources is performed manually. In [15], authors reuse the NCI thesaurus and the GALEN ontology as reference ontologies for building a domain ontology related to Juvenile Rheumatoid Arthritis. They propose an approach which only extracts the relevant parts of these ontologies and integrates them in the target ontology. To extract the relevant fragments of knowledge sources, a set of core concepts are often used and matched to the latter. The extracted entities are then refined (i.e., sub-concepts are added) or generalized by the ontology developer in a safe way which ensures the ontology consistency. In this work, the (semi-automatic) ontology enrichment aspect (from domain specific corpus) is not addressed. Moreover, it assumes that reused ontologies are consistent (i.e., the meaning of the imported fragments is not changed) and do not provide mechanism to deal with inconsistencies in the latter. A reuse based method is equally proposed in [16] for building an ontology of cardiovascular diseases for information retrieval purpose. The authors rely on valuable existing resources, principally the UMLS and the MeSH (Medical Subject Headings) thesaurus, but enrichment by entities which do not belong to these resources was not performed.

As regards term alignment, methods from parallel corpora are widely used particularly for the acquisition and the enrichment of multilingual terminologies. Several alignment approaches are proposed in the literature: (i) statistical approaches [17] which model the translation probability between a source language term and a target language term; (ii) heuristic approaches [18] which are based on specific association measures (e.g., Dice Coefficient [19]); (iii) linguistic approaches [20] which include the use of lexical, morphological and syntactic analysis, linguistic rules; (iv) hybrid approaches [21] which combine heuristic (or statistical) and linguistic models. The statistical methods are particularly effective in the alignment of terms highly frequent in the corpora but fail to align terms with low frequency. The advantage of the heuristic methods compared to the statistical methods remains their simplicity but the latter often give better alignment results [17]. The linguistic methods, on the other hand, are less effective but enable to align infrequent terms in the corpora. In the biomedical domain, many studies have contributed to the development of multilingual terminologies using term alignment techniques [22,23]. We have previously proposed a hybrid method, TermAlign [24], which follows the alignment approaches from parallel corpora. In the present work, TermAlign is combined with a statistical aligner to enhance results of term alignment.

Regarding the domain knowledge modeling, the SWAN ontology [25] and its associated application system have been developed in order to manage information related to Alzheimer’s disease but represents mainly hypotheses and statements formulated by experts of neurodegenerative diseases. The SWAN ontology thus describes only a subset of the medical concepts related to Alzheimer’s disease, which are even essential elements for indexing resources of the BiblioDem database. On the other hand, an attempt to structure and formalize relevant knowledge about Alzheimer’s disease was recently carried out [26]. The resulting ontology, known as Alzheimer’s disease ontology (ADO), integrates the basic formal ontology (BFO) [27] upper level concepts, which assist in the organization and integration of biomedical information and guarantees its interoperability with other biomedical ontologies. However, the Alzheimer’s disease ontology does not cover the domain completely, its structure is limited and it is monolingual (in English language). In particular, relevant concepts like Euphoric mood, Vascular dementia and Elderly are not defined; Dementia, Memory impairment and Cognitive decline terms are defined as synonyms of Mental disorder, which is even more general. Therefore, it is insufficient to cover all the aspects treated in the BiblioDem database.

In summary, there is a lack of formal knowledge modeling (even less bilingual) which covers specifically and sufficiently the Alzheimer’s disease and related illnesses domain. Our present work aims at filling this gap.

The different resources and tools used in this work are summarized in Table 1
                     . We distinguish resources used as input of our approach from the tools, which we use to process terminological resources.

BiblioDem is a cumulative bibliographic database which currently contains (as of July 2013) 1556 scientific papers on Alzheimer’s disease and related syndromes. This database contains abstracts of scientific papers selected from worldwide literature on Alzheimer’s disease and their associated critical analysis, thus constituting a rich knowledge. It is enriched each month with documents selected from literature databases, such as PubMed/MEDLINE,
                              7
                              
                                 http://www.ncbi.nlm.nih.gov/pubmed.
                           
                           
                              7
                            together with their critical analysis. For our purpose, two corpora were built from this representative database: an English corpus consisting of papers’ abstracts and a French corpus gathering syntheses and comments of these papers (see details in Table 2
                           ). French syntheses are not translations of the English abstracts but a translation of the paper’s title is available in French. Thus, the corpus is not fully parallel.

From the BiblioDem database, we created parallel corpora aligned at the sentence level which contains a set of papers’ titles in English and their French translations (performed manually by domain experts). We thus obtain parallel corpora whose quality is guaranteed. To extend these corpora, additional bilingual (English–French) parallel corpora are collected from the Alzheimer Society Web site
                              8
                              
                                 http://www.alzheimer.ca/.
                           
                           
                              8
                            which concerns Alzheimer’s disease. In this general public site, most of the web page contents are expressed in both languages and are generally translations of each other. To identify pairs of parallel pages, the uniform resource locators (URL) and the document language indicators are used. Thus, a collection of 705 pairs of parallel documents is retained after filtering the initial corpora. Then, the textual content of web pages is extracted and cleaned using the HTML Parser.
                              9
                              
                                 http://htmlparser.sourceforge.net.
                           
                           
                              9
                            It is a simple tool which easily parses, extracts, and filters contents of web pages. Because titles in an English document match titles in the French corresponding document, they are aligned directly.

The UMLS® (Unified Medical Language System®) is mainly composed of two semantic resources: the Metathesaurus® and the Semantic Network [2]. The UMLS Metathesaurus is a large graph containing more than two million concepts, built by integration of 161 (in the 2012AA version) biomedical terminologies and ontologies (including MeSH, SNOMED CT, etc.). Each Metathesaurus concept is a cluster of synonymous terms, possibly defined in different languages (the Metathesaurus is multilingual), with a unique identifier (Concept Unique Identifier – CUI) and which is sometimes associated with textual definitions. These concepts are linked by various types of relations, most of which are derived from source terminologies. These semantic relations are either taxonomic or non-taxonomic and some of them are “defined” from a logical point of view (i.e., they are labeled as is_a, finding_site_of, part_of, etc.). The Semantic Network is composed of a hierarchy of 133 semantic types (broad categories). The latter are also linked by taxonomic and non-taxonomic relations. Each Metathesaurus concept is categorized by one or more semantic types (e.g., Alzheimer’s disease (C0002395) is categorized by the semantic type Disease or Syndrome itself belonging to the semantic group DISORDERS).

The UMLS provides numerous services in order to easily exploit its content. In particular, through the UMLS Terminology Services (UTS), a dynamic access to the UMLS content is possible. They are useful tools for mapping terms to their corresponding concepts in the UMLS by providing multiple search modes according to selected source vocabularies, semantic types, etc. In addition to the exact matching mode, a normalized one exists, which takes into account the lexical variations of terms (flexion and derivation) based on the Lexical Variant Generation program.
                              10
                              
                                 https://uts.nlm.nih.gov//doc/devGuide/index.html.
                           
                           
                              10
                            The input string is first normalized to a set of variants which are then compared with the Metathesaurus terms in order to find the corresponding concepts. For example, with this method, Parkinson’s disease dementia and older adults terms are respectively associated to Dementia in Parkinson’s disease (C0349081) and Older adulthood (C1999167) UMLS concepts.

Syntex [28] is a syntactic parser that builds a terminological network of noun, verb and adjectival phrases from both English and French text corpora. It is based on morpho-syntactic patterns for detecting candidate terms (e.g., with the pattern Noun-Noun, the term Risk factors is extracted). Thus, it takes as input a text previously normalized (lemmatized) and tagged grammatically (by a tool such as TreeTagger
                              11
                              
                                 http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/.
                           
                           
                              11
                           ) and provides a terminological network in which each term is connected to its head and its expansion. For example, Cognitive decline is head of Mild cognitive decline and Alzheimer’s disease pathology is an expansion of Alzheimer’s disease. Each candidate term is associated with its frequency and other relevance measures.

Moses [29] is an open source toolkit for phrase-based statistical machine translation. It includes a “training pipeline” component which allows training translation models for any language pair. Thus, from parallel corpora prepared beforehand (tokenization, conversion of tokens to a standard case), translation models are generated using this component. For this, Moses relies on Giza++ [17], the best known aligner, for establishing word alignments and uses co-occurrences of words and segments (continuous sequences of words) to produce translation correspondences between phrases. It thus allows producing in an automated way, from parallel corpora, translation tables in which phrases pairs are associated with their translation probabilities.

@&#METHODS@&#

Before detailing the proposed ontology construction method, we provide a formal definition of the notion of ontology as referred in this paper. This definition is a formal definition of ontology primarily proposed by Maedche and Staab [30] and widely agreed by the semantic Web community. It has been adapted to cope with our particular situation of termino-ontology and to define some important properties used in this work.
                        Definition 1
                        An ontology is a 7-tuple O={C,H,R,HR,T,F,A} [30], where:

C, a set of concepts.

H⊆C×C, a taxonomy of concepts. h
                              =(c
                              1,
                              c
                              2)∈H means c
                              1 subsumes c
                              2.

R⊆C×C×L, a set of non-taxonomic relationships where L is a set of relations labels.

HR
                              ⊆R×R, a taxonomy of non-taxonomic relations.

T, a set of strings that are concepts labels (terms).

F: T→C, a function which associates concepts with their labels.

A, a set of axioms that describe constraints on the ontology.

From the definition 1, we introduce the following definitions.
                        Definition 2
                        H+ is the transitive closure of a binary relation H means that H+ is the smallest set of relationships such as:

H+ is transitive and

H ⊆ H+.

A set of relationships H is cyclic if ∃c
                           ∊C such as (c,
                           c)∊H+.

The taxonomic relationship (cs
                           ,
                           ct
                           )∊H is redundant
                           
                              12
                              In this paper, we refer to this technical sense of “redundancy”.
                           
                           
                              12
                            if 
                              
                                 ∃
                                 c
                                 ∈
                                 C such as
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       s
                                    
                                 
                                 ,
                                 c
                                 )
                                 ∧
                                 (
                                 c
                                 ,
                                 
                                    
                                       c
                                    
                                    
                                       t
                                    
                                 
                                 )
                                 ∈
                                 
                                    
                                       H
                                    
                                    
                                       +
                                    
                                 
                              
                           .

The proposed ontology construction method consists of four steps (Fig. 1
                     ). The first one, Term extraction (Section 4.1), performs the automatic extraction of relevant terms from representative corpora of the domain. Candidate terms are extracted automatically from these corpora using the Syntex extractor. Then, the candidate terms are filtered to remove non-relevant ones. The second step, Ontology building (Section 4.2), focuses on the clustering and conceptualization of terms using a domain-specific resource, the UMLS. An enrichment technique is proposed in the third step, Ontology enrichment (Section 4.3), to enrich the French knowledge. This enrichment step includes a term alignment phase (4.3.1) and the integration of new concepts extracted from corpora but absent from the UMLS (Section 4.3.2). As a final step, Ontology validation (Section 4.4), the results are validated by domain experts.

The terminology extraction tool, Syntex [28], is used to extract candidate terms from the BiblioDem corpus. As part of this work, we run it on English texts, then on French texts to automatically extract nouns and noun phrases that are considered as candidate terms. Then, we use it to extract dependency relations between these terms, which can be useful to identify taxonomic relationships.

This extractor provides significant results but irrelevant information appears in the lists of candidate terms, which requires an automatic filtering to select only the relevant terms of the domain. Thus, firstly, stop words
                           13
                           
                              http://nlp.cs.nyu.edu/GMA/docs/resources.html.
                        
                        
                           13
                         and terms constituted exclusively of numbers are removed. Finally, we only consider the most frequent candidate terms (here, number of occurrences > =7 selected in agreement with domain experts).

This step aims at grouping synonymous terms into concepts and to structure them through semantic relations. For each of the candidate terms retained in the previous step (Term extraction), we look for corresponding concepts in the UMLS. To do this, we first perform an exact search on all the terms and for those which are not found, a normalized matching is carried out. In addition to the concepts, direct subsumption relationships are recovered, i.e. taxonomic relationships which are labeled as is_a within the UMLS. Indirect subsumption relationships obtained through intermediate concepts (Fig. 2
                           ), which do not belong to the initial list of concepts, are also extracted. These intermediate concepts and all sub-concepts of nine domain specific concepts selected manually (Table 3
                           ) linked to the latter by subsumption relations, are also integrated. For concepts which are not associated with other concepts through subsumption relations, the more general hierarchical relationships (Child, Narrower) are recovered and considered as candidate taxonomic relationships, which have to be validated. Different types of non-taxonomic relations are also extracted (e.g., may_treat, cause_of, anatomical_part_of). To do so, we use the whole UMLS (the Metathesaurus and the Semantic Network) to cover better the various aspects of the domain. Indeed, the resources addressed include various aspects of Alzheimer’s disease which can be preclinical, clinical, or etiological.

The variety of source vocabularies and the wide coverage of the UMLS lead to redundancies and cycles [31]. A simple algorithm is used for removing automatically the redundant taxonomic relationships (Fig. 3
                           ). In addition to these redundancies, cycles automatically detected are examined manually. For pairs of concepts connected through different types of relations, only the most specific semantic relations are preserved. Toward this end, the taxonomy of the concerned relations is established manually considering the most specific is_a link. For example, the anatomical_part_of relation is more specific than the part_of relation, Then, if a pair of concepts is linked by both relations, only anatomical_part_ is kept.

The result of the conceptualization phase is a bilingual domain ontology of Alzheimer’s disease. The latter is encoded in a formal and expressive representation language. For this, the reference Web Ontology Language (OWL)
                              14
                              
                                 http://www.w3.org/TR/owl-ref/.
                           
                           
                              14
                            is used in order to express some complex properties like inversion (e.g., part_of is inverse of has_part), transitivity but also because it facilitates the interoperability of the ontology with the existing ones. It is combined with the Simple Knowledge Organization System (SKOS)
                              15
                              
                                 http://www.w3.org/TR/skos-reference/.
                           
                           
                              15
                           , which is particularly useful to support multilinguism [32]. Each concept is represented by a class with the following properties: a code, an URI, a preferred term in English, and, when available a preferred term in French, synonymous terms and definitions in both languages. The semantic types categorizing each concept of the ontology are also included and represented as top-level concepts. Fig. 4
                            shows the model which describes the entities of the ontology.

The resulting ontology is enriched at the next step by integrating new concepts and synonymous terms which are absent from the UMLS.

The ontology enrichment step consists of two stages: term alignment (Section 4.3.1) and new concepts integration (Section 4.3.2).

Because the UMLS predominantly contains English terms (45% compared with 34% for French terms), we used a technique of term alignment to constitute a richer bilingual biomedical resource (Fig. 5
                           ). This technique is based on alignment approaches from parallel corpora that are widely used in multilingual terminology development [17,22,23]. They consist of matching extracted terminological units (i.e., for us the terms) from parallel texts by first aligning sentences (Section 4.3.1.1) and then terms (Section 4.3.1.2).

In order to align textual contents of the parallel documents at the sentence level, the corpora are initially segmented into sentences using the OpenNLP
                                 16
                                 
                                    http://opennlp.apache.org/.
                              
                              
                                 16
                               sentence detector. Afterwards, a sentence alignment method is used to align these sentences. For aligning sentences from parallel documents, the approaches used in the literature are often based on the length of sentences [33] or exploit a bilingual lexicon and the morphological similarity of words [34]. In this work, we use the GMA
                                 17
                                 
                                    http://nlp.cs.nyu.edu/GMA/.
                              
                              
                                 17
                               (Geometrical Mapping and Alignment) tool, which is based on the latter methods, combined with different matching methods, which exploit the computation of orthographic cognates or the longest common subsequence between tokens. A bilingual lexicon extracted from the UMLS Metathesaurus is merged with the one obtained previously in [24] from the papers titles of the BiblioDem corpus. The parallel corpora and this bilingual lexicon are provided as input to GMA. From these parallel documents, we then get a bilingual corpus constituted of 10,122 pairs of aligned sentences. Note that one sentence from a source document can correspond to one (commonly) or more sentence(s) into a target document or can simply be omitted.

To align the terms identified in the source text with their equivalents in the translated (target) one, we have previously proposed the TermAlign approach which combines a heuristic technique and a linguistic method [24]. The heuristic technique is based on the co-occurrence measure between a source term and a target term to calculate their association score. This method is based on the assumption that terms appearing in portions of aligned parallel texts are more likely to be in translation relation. The linguistic method, for its part, is based on morphological similarity of terms in both languages. In practice, we combined the Jaccard [35] measure with the normalized Levenshtein distance [36] for identifying corresponding English-French terms. The Jaccard measure is simple to implement and reliable to determine the pairs of terms more strongly associated in the parallel corpus while the Levenshtein distance has been proved effective and has achieved good performance for computing the similarity between two strings.

While this method gave good results (precision of 73%) for titles of the BiblioDem corpus, its performances decrease for the parallel corpora constituted from the Alzheimer Society Web site. Therefore, the initial method is combined with the statistical aligner, Moses [29], to process this larger corpora. Moses [29] establishes word alignments and uses co-occurrences of words and phrases to produce automatic translation correspondences between phrases. Moreover, in addition to being the most widely used open-source statistical machine translation, Moses achieved good performances in experiments performed on standard benchmarks [37,38]. Thus, we used this aligner to improve our initial alignment method. First, the parallel corpora are tokenized and cleaned to better perform the words alignment. Then, from these corpora, a phrase translation table (i.e., containing the alignments) is automatically generated. Finally, alignments are filtered to select the ones constituted only by terms previously retained in the first step (Section 4.1). In addition, only pairs of terms for which these translation probabilities exceed a minimal threshold (chosen empirically based on experiments) are selected to optimize simultaneously the precision and recall values but also to facilitate the validation by domain experts.

The second step of the enrichment phase is the integration of new concepts in the ontology. Indeed, some relevant domain specific terms not included in the source vocabularies of the UMLS need to be added for guaranteeing a better coverage of the domain. For this, the English terms retained in the previous phases and not found in the UMLS are considered as candidate terms to extend the initial ontology. The validated candidate terms are then grouped into the same concept when they correspond to lexical variations or synonymous terms (acquired by alignment) in both languages. For example, the term Cognitive test scores and Scores aux tests cognitifs are grouped into a same concept (AD000087). Then, dependency relationships provided by Syntex are used for connecting new concepts to the ontology concepts. For instance, Severe Alzheimer disease (AD000390) is a sub-concept of Alzheimer disease (C0002395) because the latter is head of the former. Fig. 6
                            shows examples of head dependency relationships.

Two specialists of the Alzheimer’s disease domain (FD and a junior researcher supervised by JFD, both members of the Epidemiology and neuropsychology of brain aging team; JFD being head of the team) have evaluated all the results. These domain experts were asked to validate the following elements:
                           
                              •
                              A list of the concepts found in the UMLS, with their associated terms and their context of appearance in the corpus so that they can judge more efficiently their relevance.

The taxonomic candidate relationships, which are useful to complete the organization of concepts.

A list of non-taxonomic relations extracted from the UMLS sources.

The English–French term pairs, which are not found in the UMLS and obtained during the alignment method.

A list of filtered terms not found in the UMLS Metathesaurus so that they can subsequently be integrated in the UMLS.

Both experts examined the results of the different tasks (see Table 4
                        ). If their validation differs, they have to discuss their point of view until they reach an agreement. Thie whole process of validation has taken one month (51h/person of work).

@&#RESULTS@&#

This section describes the results obtained at the different steps of the ontology construction method.

With Syntex, a set of 49,390 noun phrases and 8,844 simple terms for the English corpus and 69,505 noun phrases and 11,688 simple terms for the French corpus were extracted. Table 5
                         displays the 20 most frequent terms in the corpus. After filtering, 2,916 English terms and 3,152 French terms were retained. Examples of pruned terms are Effect, Years, Information, and Importance.

During the conceptualization phase, most simple terms (65%) were retrieved in the UMLS Metathesaurus while only one third of noun phrases (32%) was found in this resource. This result can be explained by the fact that noun phrases are domain-specific terms and are therefore less present in this more general resource. For example, relevant terms such as Cognitive tests and Neuropsychiatric symptoms were not found in the UMLS. Finally, the predominance of English terms in the UMLS has been clearly shown (45% compared with 34% for French terms).

The fusion of these different elements results a set of 3,871 distinct concepts. After validation by experts, 2,421 concepts were retained. For example, the concepts Physical activity (C0026606), Physiological stress (C0449430), Risk factors (C0035648) were considered as valid. On the contrary, the concepts Scientific control (C1882979), Science of anatomy (C0002808) and Number of patients (C2360800) have not been retained. Table 6
                         shows the predominant semantic types associated with the concepts of the ontology. In addition to these retained concepts, 2,905 supplementary concepts have been integrated in order to structure better the concepts in the ontology. For example, using the concepts Dementia (C0497327) and Mental disorders (C0004936) initially found, the intermediate concept Organic psychiatric disorderss (C2013984) was also added.

All these concepts are structured by 7,499 taxonomic relationships and 10,889 non-taxonomic relationships. Indeed, from the 8,125 taxonomic relationships extracted from the UMLS, 903 redundant (in the sense of definition 4) relationships were removed, and two cycles (in the sense of definition 3) were corrected. Then, 279 additional taxonomic relationships obtained through Syntex dependencies were added. In addition, several types of non-taxonomic relations of source vocabularies (SNOMED, FMA, etc.) were conserved. Hence, among 221 relations between concepts extracted from the UMLS, 178 relations are validated by domain experts. Among these retained relations, 82 are inverse relations. Although the number of retained relations is high, experts judged them relevant for the target application domain. Table 7
                         displays the 20 most frequent non-taxonomic relations in the ontology. As an illustration, the first line of the table means that Hypertensive disease is 
                           clinically associated with Dementia and that 1684 pairs of concepts are linked though this relation.

With Moses, a phrase table translation of 492,556 lines was generated. After removal of the terms not present in the initial list constituted of filtered terms (provided by the Syntex extractor) and their synonyms in the UMLS Metathesaurus, a set of 1,959 alignments was obtained. The alignment results depend on filtering; by increasing the threshold value, the precision becomes higher whereas the recall decreases and vice versa. Table 8
                         illustrates this behavior according to two different thresholds. The higher the translation probability is, the more likely the terms are to be in a translation relation. Then, fixing a minimum threshold of translation probability of 0.5 and 0.6 (chosen based on experiments described in [37]) resulted in 1,013 and 727 pairs of terms, respectively.

Since we did not have a set of alignments to use as a reference, the recall was not evaluated. Although less relevant, the number of alignments is provided instead. Table 9
                         gives examples of alignments generated by Moses with their corresponding probabilities. With this aligner, any sequence of words is considered as a phrase. Moreover, since translations in the parallel text are not symmetric (due to synonymy issues, partial or wrong translations), the gap between conditional probabilities varies considerably. For example, the French phrase aphasie primaire progressive (noted f) can be translated into the English phrases (noted e) primary progressive alphasia, of progressive aphasia, progressive aphasia, etc. with respectively the probabilities that f is the translation of e, P(f|e): 0.09, 0.5, 0.33 and so on. Inversely P(f|e) are respectively 1, 0.5, 0.5 and so on. Thus, we firstly filtered the results of Moses by the lists of terms extracted previously by Syntex and the ones extracted from the UMLS. Then, alignments were filtered to retain terms pairs having one of their conditional probabilities (P(f|e) or P(e|f)) equal or greater than minimum threshold. We have empirically chosen the 0.5 threshold having an overall precision of 74.23% so that more alignments were generated. These alignments were merged with the ones found by TermAlign [24]. Overall, 1,527 valid alignments were obtained. However, a part of the French synonyms were already contained either in the UMLS. Thus the ontology was subsequently enriched by the integration of 608 additional French synonyms. Examples of new synonyms obtained by alignment are rapid cognitive decline/déclin cognitif rapide, psychological distress/détresse psychologique, behavioral disturbances/troubles comportementaux.

Finally, 439 new concepts were integrated to extend the initial ontology. An example is Episodic memory impairment that has been integrated as a sub-concept of Memory impairment using syntactic dependencies supplied by Syntex.

Overall, according to our previous definition, the ontology has the following characteristics:
                           
                              |C|=5765 concepts (where |X| is the cardinality of the set X). Among them, 3283 (56.0%) have a French synonymous term.

|H|=7499 taxonomic relationships between concepts.

|R|=10,889 non-taxonomic relationships between concepts.

|HR|=178 non-taxonomic relations among which 82 are inverse relations and two symmetric relations.

|T|=35,855 labels of concepts (11,921 French terms and 23,934 English terms).

|A|=Ø.

The ontology is available online (http://lesim.isped.u-bordeaux2.fr/SemBiP/ressources/ontoAD.owl).


                        Fig. 7
                         presents a screenshot of a portion of the final ontology edited in the Protégé editor tool.
                           18
                           
                              http://protege.stanford.edu/.
                        
                        
                           18
                        
                     

@&#DISCUSSION@&#

The reuse of existing ontological resources has been widely investigated in ontology engineering. However, most ontology construction methods based on this approach only exploit the knowledge contained in the resources themselves [13]. For those which include an enrichment phase, the integration of new entities (concepts or relationships) is often performed manually [14,15]. In addition, some of these methods assume the knowledge sources are consistent and therefore do not address inconsistencies processing. Moreover, these approaches sometimes use only sets of core concepts selected manually for extracting relevant parts from knowledge sources [14]. We used additionally relevant terms extracted automatically from corpora. On the other hand, approaches consider original hierarchical relations of sources as subsumption relations [12] while the latter are not always real taxonomic relations [11]. In our work, algorithms were developed to process inconsistencies which exist in the reused resource (Section 4.2). In addition, unlike approaches which only use knowledge contained in the original resources, our method includes an enrichment step with the integration of new entities. The latter is performed semi-automatically using syntactic dependencies provided by the Syntex extractor and an alignment method based on parallel corpora. However, a limitation of our method remains the acquisition of suitable parallel corpora, which is not a trivial task.

Because BiblioDem corpora consist of scientific papers, this results in domain-specific concepts (Dementia, Mild cognitive impairment) are represented in the ontology but also concepts which are not specific to the domain but indeed relevant for the SemBiP purpose. These concepts can be related to epidemiology, such as Statistical prevalence and Cohort studies, which are methodological concepts usually used in biomedical studies. The ontology also contains general biomedical concepts like Human body structure, Blood pressure, which are useful to organize more specific concepts. Finally, more general concepts, such as Risk factors and Educational status, also appear in the ontology just as they do in many scientific papers. The use of the more general Society Alzheimer Web site (i.e., at the term extraction step) would probably have resulted in fewer of these concepts. We believe however that using BiblioDem corpora provides a better coverage of the different aspects related to the Alzheimer’s disease domain and could be very useful for information retrieval purpose.

With the alignment method, new French synonyms were associated with concepts which do not have French synonyms in the UMLS. We increased the percentage of concepts having at least a French synonym from 34% to 57%. However, many concepts in the ontology still do not have any French synonym because our alignment method was not applied to the intermediate and additional concepts (added to structure better the ontology). Indeed, this method relies on the parallel corpus while most of these supplementary concepts are not contained in this latter. When considering only ontology concepts having a term extracted from the BiblioDem corpus, 71% are associated with French terms. An interesting perspective would be to extend the parallel corpus in order to take into account these concepts.

The different tools used (Syntex, Moses) in our proposed approach are independent of any specific domain and can therefore be used in any domain. Thanks to that, the proposed approach could be used in the ontology construction and enrichment processes of any biomedical subdomain. It could also be applied to other domains wherein specific temino-ontological resources of the particular domain are available, as underlined in [14]. However, while the method itself is domain-independent, the input resources (vocabularies, corpora) must be tailored to the target domain in order to apply our approach. On the other hand, since the UMLS covers largely the biomedical domain, our method could be easily applied in any biomedical subdomain as far as it is covered by the UMLS.

Term alignment is an interesting step for constructing bilingual resources such as bilingual terminologies, thesaurus or ontologies. Our previous method, TermAlign [24], achieved good performance (precision of 73%) on parallel corpora constituted of titles of BiblioDem papers, but it was combined, in this work, with a statistical aligner (Moses) to enhance results of term alignment on wider corpora. The combination of these different techniques is effective as shown by the promising results obtained (1,527 alignments obtained). The overall precision (74%) shows as good or exceeded performance compared with related work [22,23]. In addition, it does not require manual alignments for training the aligner as in [23]. In [20], the alignment method proposed, based on syntactic propagation, achieved high precision (94%) but its recall was low (56%) applied to agricultural corpora; Moreover, in the medical domain, its precision decreased up to 70% [39]. Finally, unlike our method, this approach requires deep syntactic analysis of the corpora.

Overall, a general limitation of these alignment approaches is the acquisition of suitable parallel corpora which is not trivial, in particular for a specific domain.

@&#CONCLUSION@&#

In this paper, we have proposed a method based on the reuse of textual information and existing termino-ontological resources for building a bilingual domain ontology. Our approach first consisted in the extraction of terms from bilingual corpora of scientific papers. A large resource, the UMLS, has then been exploited to cluster terms into concepts and structure the latter. However, the variety of the UMLS source vocabularies and its wide coverage have led to redundancies, cycles and sometimes to inconsistencies. Thus, mechanisms have been developed for pruning redundant relationships, for correcting inconsistencies and for providing an explicit specification of relationships. Finally, an enrichment phase has been performed in order to integrate new concepts and synonyms in the ontology. All these results have been refined and validated by domain experts.

An important issue addressed in this work is term alignment where the combination of different techniques has been proven to be an effective choice. Indeed, the term alignment method used has enabled to enrich the multilingual and terminological aspects of the ontology with new synonyms. Moreover, we have observed that the use of general public corpora for extending the terminology was an important issue in this work since doing so took into account the heterogeneity of users. The validation of resulting ontology by domain experts has shown that our method is efficient. The resulting ontology is mainly lightweight in contrast to heavyweight ontology but this is not problematic because it is used to support the semantic portal SemBiP for semantic annotation and information retrieval purposes [22].

@&#FUTURE WORK@&#

Although the resulting ontology has been refined and validated by domain experts, it has not yet been evaluated in a real application or by external Alzheimer’s disease experts. It is currently used to support the SemBiP semantic portal for which a prototype has been recently made available at http://lesim.isped.u-bordeaux2.fr/Sembip/. The primary users are the BiblioDem advisory board and experts disseminated in different geographical areas and involved in the review process of articles. Our aim is to gather users’ logs in order to perform a usage-oriented evaluation of the ontology and to answer questions such as: do the users find easier and faster information thanks to the use of the ontology? Are we able to cope efficiently with the variety of the users and their level of expertise within the portal? This evaluation will be completed by a qualitative survey among the users of the portal. In addition, we intend to use users’ logs for identifying new terms in order to enrich the ontology and therefore improve its coverage. Indeed, since domain knowledge constantly evolves, the ontology has to be kept up to date regularly. Moreover, in order to enrich the ontology structure, a deeper parser like the Stanford parser
                           19
                           
                              http://nlp.stanford.edu/software/lex-parser.shtml.
                        
                        
                           19
                         could be used in order to extract taxonomic and non-taxonomic relationships from texts.

We plan also to improve the degree of formalization of the ontology and its interoperability with other biomedical ontologies. Hence, aligning the resulting ontology with an upper level ontology like BFO as in [26] is an important perspective of our work. Indeed, BFO is based on the distinction between “entities that endure through time” (continuants) and “entities that occur through a period of time” (occurents). Based on this principle, it defines a set of domain-independent categories (e.g., object, function, process) which could be linked to topmost concepts of our ontology (e.g., disorder, diagnosis, behavior).

Finally, the resulting ontology could be extended to support other languages. Since the external resource (the UMLS) is multilingual, it could be exploited to this end. In addition, the proposed term alignment method is not specific to particular languages; it can align terms from parallel corpora for any pair of languages. Therefore, it could be used to extend our ontology with other languages, thus making it multilingual rather than bilingual. This aspect is very important in this work for allowing the large scientific community and experts in the field to easily exchange knowledge about Alzheimer’s disease and related disorders.

@&#ACKNOWLEDGMENTS@&#

This work is supported by the French Fondation Plan Alzheimer and realized in collaboration with the Epidémiologie et Neuropsychologie du Vieillissement Cérébral team of the Inserm Research Center U897.

@&#REFERENCES@&#


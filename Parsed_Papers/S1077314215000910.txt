@&#MAIN-TITLE@&#Head detection using motion features and multi level pyramid architecture

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A two-stage head detection system using motion features is proposed.


                        
                        
                           
                           A multi-level histograms architecture targeting low-resolution images is developed.


                        
                        
                           
                           State of the art motion features including HOOF and MBH have been employed.


                        
                        
                           
                           HOOF has been extended to Relative Motion Distance for better head representation.


                        
                        
                           
                           The results are validated using PETS 2009 dataset and compared to other existing schemes with excellent results.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Head detection

Histogram of oriented optical flow (HOOF)

Support vector machine (SVM)

Motion boundary histogram

Multi level pyramid architecture

@&#ABSTRACT@&#


               
               
                  Monitoring large crowds using video cameras is a challenging task. Detecting humans in video is becoming essential for monitoring crowd behavior. However, occlusion and low resolution in the region of interest hinders accurate crowd segmentation. In such scenarios, it is likely that only the head is visible, and often very small. Most existing people-detection systems rely on low-level visual appearance features such as the Histogram of Oriented Gradients (HOG), and these are unsuitable for detecting human heads at low resolutions. In this paper, a novel head detector is presented using motion histogram features. The shape and the motion information, including crowd direction and magnitude, is learned and used to detect humans in occluded crowds. We introduce novel features based on a multi level pyramid architecture for Motion Boundary Histogram (MBH) and Histogram of Oriented Optical Flow (HOOF), derived from the TV-L1 optical flow. In addition, a new feature, called Relative Motion Distance (RMD) is proposed to efficiently capture correlation statistics. For classification distinguishing human head from similar features, a two-stage Support Vector Machine (SVM) is used, and an explicit kernel mapping on our motion histogram features is performed using Bhattacharyya-distance kernels. A second stage of classification is required to reduce the number of false positives. The proposed features and system were tested on videos from the PETS 2009 dataset and compared with state-of-the-art features, against which our system reported excellent results.
               
            

@&#INTRODUCTION@&#

Security and safety is of paramount importance in large arenas where people gather, such as train stations, stadium, and other public places. There is an urgent need to create new video surveillance technologies for understanding crowd behavior. In addition to live surveillance, understanding crowd behavior will aid off-line simulations that contribute to better architectural designs and emergency managment strategies. Crowds are characteristically dense and objects of interest are frequently occluded (that is, partially hidden). Based on visual observation, accurate detection and tracking of the head of people in crowds is the only viable option in such scenarios. Recently, some work has been carried out in head detection in crowds and there seems to be enough scope for improvement. Working with the popular Caltech Pedestrian Dataset, researchers have found that the head is the only visible part in 97% of occlusions [1]. Therefore, extracting features from the head and shoulder is more appropriate and feasible than trying to model the entire human body in crowds.

Recently, various methods for modeling human movement have been developed by the video surveillance community. Researchers have proposed numerous object-related features with extrinsic and intrinsic properties [2]. The extrinsic properties include color, intensity, and motion information, and the intrinsic properties include curvature information. A multi-level representation framework, which uses a sliding-window technique, has become a fundamental tool in building low-level feature descriptors. These descriptors are applied in human detection, tracking, and behavior modeling. Selecting appropriate features is the key in successful people detection [3], and researchers frequently utilise local features that are invariant to illumination and small deformations.

Since Dalal et al. [4] proposed the Histogram of Oriented Gradients (HOG), human detection using HOG features has gained a lot of attention. However, there are several limitations when HOG is applied for detecting human heads [5]. The HOG does not offer enough variations for accurate discrimination, and it often causes the learning algorithm to mistakenly report other head-like objects as heads. However, based on the detailed argument presented in Dollar et al. [1], HOG and its extension to part models [6] is the preferred feature due to its robustness to model the local shape, relation between parts, and appearance of the target object in static environments. Generally, classifiers such as the Support Vector Machine (SVM) and cascade boosting [4,7] are employed to map these low-level features into an interpretable score (representing the likelihood of a human is present). However, there are weakness in determining the humans when only appearance features are extracted [3], where they also promote to use more features instead of using only one channel of feature. Extending earlier work [5], the Motion Boundary Histogram computed from optical flows, accompanied with the Histogram of Optical Flow (HOOF) are included in the multiple motion feature sets. A new feature, called Relative Motion Distance, by computing the statistical correlation of HOOF, is proposed and added to enrich the motion features set.

To discover different behavior in a variety of spatial resolutions, the Spatial Pyramid Matching (SPM), a multi-level histogram feature, was introduced by Lazebnik [8] and is applied widely in tasks relating to human action recognition and human detection [9,10]. The resolution of the input image where features are computed is kept fixed, whereas the spatial resolution in which they aggregate into block features is varied. Eventually, it produces a higher dimensional feature representation, containing discriminative information over and above the raw video. In this work, we report a multi-level classification scheme based on motion histogram features.

Kernel selection is among the most important factors in SVM learning [11]. Thus, the key to successfully train an SVM model is to construct an appropriate kernel to map the data into a linearly separable feature space. General-purpose kernels are available, but the use of an appropriate kernel which corresponds to the target features can substantially improve the generalization ability of the learning system [12]. Ablavsky et al. [13] and Vemulapalli et al. [14] note that the space where histograms lie is in a Riemannian manifold rather than Euclidean space. Therefore, the need for a corresponding kernel arises for such data in the form of finite probability distributions, normalised histograms, and other computer vision descriptors [15]. One way to achieve this is by mapping the manifold to a Reproducing Kernel Hilbert Space (RKHS) with the help of a kernel and an appropriate distance metric. Another way is to directly perform classification on tangent space of the manifold [2]. Two popular kernels– the Bhattacharyya kernel and the Histogram Intersection kernel, employed in [13] are applied and compared in this work. Interestingly, by simple arithmetic operations these two kernels are capable of faster performance and result in better classification accuracy.

The main contributions in this paper are: 1) the use of high-level motion features and kernel machines for head detection in occluded scenarios; 2) new features are proposed based on the statistical relations between motion histogram features (i.e. the RMD) and a combination of various motion features, including the multi level MBH and HOOF; 3) the motion features based on a combination of HOOF and MBH lie in the simplex manifold making it appropriate to implement the Bhattacharyya-distance kernels to gain better results than the linear and RBF kernels traditionally employed; and 4) the proposed method is evaluated with successful results using the publicly available PETS 2009 dataset for people-counting in surveillance, and the proposed method is compared with other state-of-the-art features.

@&#BACKGROUND@&#

In this section, background for this work and other state-of-the-art histogram based methods and appropriate kernel selection is presented. Proposed methods thus far have come a long way—from grappling with complex methods for detecting the entire body, to more sophisticated approaches for detecting the head in occluded scenarios. Some of the earliest work in tracking groups of people was carried out by McKenna et al. [16], making use of color as a dominant feature. A detailed survey of crowd analysis can be found in Zhan et al. [17].

Most prior work has targeted pedestrian detection where an entire or partially occluded body is visible. The Histograms of Oriented Gradients (HOG) feature proposed by Dalal et al. [4] is a one-dimensional histogram shape descriptor consisting of gradient orientations of pixel intensity in the local region. It is invariant to local light conditions and changes in geometry, and it has become the most popular image feature used in people detection. Progressively, a few schemes based on combination of features have been subsequently proposed. Wojek et al. [3] presented a combination of Haar, Shapelet and HOG features, and showed that multiple features result in better detection than individual-feature methods. Dollar et al. [18] proposed another integration of multiple features, where Haar-like features are computed over multiple channels of visual data, resulting in better detection. Other methods based on multiple feature include Wu et al. [19], where HOG, Edgelet and covariance features are combined. Similarily, Shapelet descriptors [20] and covariance descriptors [2] have been employed for pedestrian detection. They have further shown that the still images can be represented as Riemannian manifold and by learning the LogitBoost classifier in a cascade, their system has achieved impressive performance on Inria benchmark. Local color self-similarity and the motion features are used in Walk et al. [21]. In Park et al. [22], temporal difference of optical flow to HOG is added to enhance detection for weakly stabilised video.

Recently, the focus on crowd detection and tracking has shifted to accurate head detection due to a better understanding of occluded scenarios. In Dollar et al. [1], the public Caltech dataset has been analyzed and a miss rate of 73% in current state-of-the-art detectors is reported in full-body detection under occluded scenarios. Rodriguez et al. [23] have reported head detection results by adding a global density constraint. Zeng et al. [24] proposed a head and shoulder detection system by boosting the multi-level Histogram of Oriented Gradient and Local Binary Pattern (LBP). In Li et al. [25], HOG and Haar features are used to describe the omega-shape of the head and shoulders. More recently, in [26], information gained by applying head detection in the early stage using HOG has shown promising results in gaze estimation between two people in television video. In contrast to our work, the resolution of the head in this work is higher and hence Histogram of Gradient features result in good performance.

Using motion features for video-based analysis extends the feature space from the features in a purely static image to the integration of temporal information. Laptev et al. [27] presented a combination of HOG and Histogram of Flow (HOF) to capture shape and local motion. HOF is a popular feature and has been applied in many action recognition tasks [27–29]. In Wang et al. [29], a combination of HOG, HOF, and Motion Boundary Histogram (MBH) is used in order to create a dense motion descriptor. Chaudhry et al. [28] mapped HOF through the Binet–Cauchy kernel to learn human actions. Mota et al. [30] presented a tensor motion descriptor using optical flow and HOG-3D information. Walk et al. [21] proposed a lower-dimensional variant of Haar wavelet-like operators to encode differences in flows. Maki et al. [10] have applied multi-layer HOG and co-occurrence flow (COF) for pedestrian detection. The COF computes the pairwise comparison of histograms across exhaustive combinations through the L1-distance.

Some problems are reported in HOG-based head detection approaches [31] 
                        [32]. First, using a HOG-based feature to detect heads results in a degraded performance in terms of accuracy. Therefore, adding more features, such as motion features, complements and enhances the detection strength to differentiate moving heads from static head-like objects. Second, low-quality video consists of low-resolution targets, noise, blur, and different video encoding algorithms that makes detecting heads by HOG features even more complicated [5]. In order to address these two problems, it is logical to ask whether meaningful features can be extracted using motion features only. Motion is an intrinsic property of the world and it integrates well with our visual experience. Several researchers have based their work upon this fact [3,33]. Dalal et al. [34] have proposed a family of internal motion histograms to extend the ability to discriminate objects by motion features. Among these internal motion features, the MBH computes an oriented histogram of differential flow. It captures motion while being more robust to the the noise in optical flow. The motion boundary usually represented by optical flow has been widely applied to the field of action recognition [29]. However, the MBH has not been applied to head detection, as the head is relatively small in video clips. This usually requires methods such as multi-resolution detection [35]. In this paper, we deal with this problem by increasing the spatial information using a multi-level pyramid approach.

From our own observation (as seen in Fig. 1), shape or silhouette of moving people can be clearly observed in the histogram magnitude map. To overcome the problem of blurred motion caused by the original design of the MBH, a hierarchical pyramid design is developed to preserve the motion structure from coarse to fine. A second feature, known as the Relative Motion Distance (RMD) is introduced as an extension to the Histogram of Oriented Optical Flow (HOOF), developed in [5]. The leading feature of the HOOF is the ability to extract local dominant orientations and group these orientations into blocks, under the assumption that the human head is rigid during movement. In occluded scenarios, the orientation of the rigid part of the individual is a distinctive feature. However, the HOOF depends on the dominant flow direction and the dominant orientation changes in successive frames. To overcome this, a new scheme based on correlating local HOOF block, namely RMD is proposed. Hanani et al. [36] proposed Motion Interchange Patterns (MIP), a framework similar to our RMD design. The difference lies in the input space, where motion patterns by pixels are compared. Because of this, the MIP framework risks bottlenecking system performance whenever video resolution is high.

Chapelle et al. [37] first found that using χ
                        2 and Laplacian distance in Radial Basis Function (RBF) kernels lowers the error rate in histogram-based image classification. For most people-detection systems, linear kernel in SVM is the common choice for histogram features [4]. Chaudhry et al. [28] proposed a generalization of the Binet–Cauchy kernels on HOOF in action recognition. Caputo et al. [38] applied the Bhattacharyya kernel, comparing it with other kernels, on a local image descriptor and found that it performed best in terms of object categorization. The kernels above are either susceptible to problems with computing speed, or they consider input vectors in the Euclidean space exclusively. Maji et al. [9] showed that the intersection kernel is efficient for histogram-based features. Bhattacharyya’s kernel, or known as Hellinger’s kernel, comes from the family of the Probabilistic Product Kernel (PPK) [39]. Such kernels naturally imply symmetric and invariant characteristics, and have been applied to tasks ranging from image classification to object detection [15,40–42]. In this work, proposed features based on HOOF and MBH have been shown to lie in a simplex manifold. As a result, Bhattacharyya kernel is implemented to discriminate the proposed features as described.

@&#METHODOLOGY@&#

The overall methodology is described in Fig. 2
                     . As can be seen, the raw video is first subjected to low level motion feature extraction using optical flow. A high-level feature is then extracted based on the histogram of motion features. A discriminative feature in the form of relative motion distance is then derived, and used as the final feature for classification. At the training stage, the extracted features are shown to lie in the simplex manifold space and the appropriate kernel is chosen. Finally, a scheme for multiple-cues head detection is reported.

The optical flow estimation is used to compute the approximation to the motion field from the time-varying image intensity. The 2-D image of optical flows U and V, and their derivatives, Ux, Uy, Vt
                        , and Vy
                        , corresponds to the differential flow image in x and y directions. For instance, 
                           
                              
                                 V
                                 y
                              
                              =
                              
                                 δ
                                 
                                    δ
                                    y
                                 
                              
                              V
                           
                         denotes the y-derivative for the V component of flow. Horn and Schunck (HS) [43] is the most popular optical flow method adopted by researchers in the literature. It has the advantage of dense flow vectors and assumes global smoothness to solve the aperture problem. However, videos of crowds have highly illumination variation and the ubiquitous presence of shadows. Hence, we adopt the TV-L1 algorithm developed by Chambolle et al. [44]. The TV-L1 algorithm has the advantage of regulating varying illumination and the traditional optical flow constraints. The primal formulation of the TV-L1 optical flow is:

                           
                              
                                 
                                    
                                       F
                                       
                                          T
                                          V
                                          −
                                          L
                                          1
                                       
                                    
                                    =
                                    
                                       min
                                       
                                          U
                                          ,
                                          V
                                       
                                    
                                    
                                       ∫
                                       Ω
                                    
                                    
                                       |
                                       D
                                       u
                                       |
                                    
                                    +
                                    
                                       ∫
                                       Ω
                                    
                                    
                                       |
                                       D
                                       v
                                       |
                                    
                                    +
                                    
                                       λ
                                       ∥
                                       ρ
                                       
                                          (
                                          u
                                          ,
                                          v
                                          )
                                       
                                       ∥
                                    
                                 
                              
                           
                        where the term 
                           
                              
                                 ∫
                                 Ω
                              
                              
                                 |
                                 D
                                 v
                                 |
                              
                           
                         is the total variation of the expected flow v, Dv is the distributional derivatives, u is used to model varying illumination, ρ(u, v) is the optical flow constraint, and λ denotes the regularization term. The result from both algorithms are divided into U and V flow, denoting the horizontal and the vertical components.

The problem with the direct application of low level motion features in the form of raw optical flow is its sensitivity to both noise and variations in illumination. Further processing is required if a scenario invariant feature is required. For head detection in high density crowds, a new multi-level pyramid scheme has been developed with a combination of features.

Computing the gradient for each flow using the spatial derivatives of the mask ([ − 1, 0, 1]) is the same as with the static HOG. Given the cell P and the flow in U direction, the MBHU
                         is formulated as:

                           
                              
                                 
                                    M
                                    B
                                    
                                       H
                                       U
                                    
                                    
                                       (
                                       P
                                       )
                                    
                                    =
                                    C
                                    *
                                    
                                       ∑
                                       
                                          f
                                          ∈
                                          P
                                       
                                    
                                    
                                       M
                                       
                                          (
                                          
                                             f
                                             U
                                          
                                          )
                                       
                                       O
                                       
                                          (
                                          δ
                                          
                                             (
                                             
                                                f
                                                U
                                             
                                             )
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        The magnitude function M and the orientation function O are defined as: 
                           
                              M
                              
                                 (
                                 
                                    f
                                    U
                                 
                                 )
                              
                              =
                              
                                 
                                    ∥
                                    
                                       (
                                       
                                          U
                                          x
                                          
                                             (
                                             f
                                             )
                                          
                                       
                                       ,
                                       
                                          U
                                          y
                                          
                                             (
                                             f
                                             )
                                          
                                       
                                       )
                                    
                                    ∥
                                 
                                 2
                              
                              ,
                           
                         where the m bin d dimensional indicator O is O(δ(fU
                        )) = [δ
                        1(fU
                        ), …, δm
                        (fU
                        )]. The soft binning function δ is defined as: 
                           
                              
                                 δ
                                 i
                              
                              
                                 (
                                 
                                    f
                                    U
                                 
                                 )
                              
                              =
                              max
                              
                                 (
                                 cos
                                 
                                    (
                                    arctan
                                    
                                       (
                                       
                                          (
                                          
                                             U
                                             x
                                             
                                                (
                                                f
                                                )
                                             
                                          
                                          ,
                                          
                                             U
                                             y
                                             
                                                (
                                                f
                                                )
                                             
                                          
                                          )
                                       
                                       )
                                    
                                    −
                                    
                                       a
                                       i
                                    
                                    )
                                 
                                 ,
                                 0
                                 )
                              
                              ,
                           
                         where i denotes the bin index and ai
                         is the median angle in the ith bin interval. Soft binning is capable of lowering the quantization error caused by hard binning. The normalization constant C imposes the condition 
                           
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 m
                              
                              
                                 M
                                 B
                                 
                                    H
                                    U
                                 
                                 
                                    (
                                    P
                                    )
                                 
                                 *
                                 
                                    (
                                    i
                                    )
                                 
                              
                              =
                              1
                           
                        . The MBHV
                        (P) follows the same formulation as MBHU
                        (P). In this paper, the size of the unit cell inside the block is 4 × 4. It should be noted that normalization comes after the construction of the multi-level histogram.

In contrast to calculating gradient histogram in color domain, gamma correction is not performed. Similarly, in place of the tri-linear interpolation proposed by Dalal et al. [34], only angular interpolation among the flow vectors is performed in a cell. The reason for implementing angular interpolation is to avoid the blurring effect on the motion boundary by spatial interpolation. The MBH in both directions (U and V) are used in this paper. To improve speed, the integral histogram approach from [5] has been considered.

The HOOF computes magnitude and orientation directly from flow U and V. The orientation for the HOOF is different from the orientation of the motion boundary. From a geometric view, the vector for the motion boundary between two distinct flow vectors constitutes the MBH. By treating U and V as the original intensity image in HOG, one can take their local gradients (Ux, Uy
                        ) and (Vx, Vy
                        ) separately. Similar to the MBH, the HOOF is formulated as:

                           
                              
                                 
                                    H
                                    O
                                    O
                                    F
                                    
                                       (
                                       P
                                       )
                                    
                                    =
                                    C
                                    *
                                    
                                       ∑
                                       
                                          f
                                          ∈
                                          P
                                       
                                    
                                    
                                       M
                                       
                                          (
                                          
                                             U
                                             
                                                (
                                                f
                                                )
                                             
                                          
                                          ,
                                          
                                             V
                                             
                                                (
                                                f
                                                )
                                             
                                          
                                          )
                                       
                                       δ
                                       
                                          (
                                          
                                             (
                                             
                                                U
                                                
                                                   (
                                                   f
                                                   )
                                                
                                             
                                             ,
                                             
                                                U
                                                
                                                   (
                                                   f
                                                   )
                                                
                                             
                                             )
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

The magnitude and the orientation function is similar to the MBH. The size of each cell is equal to the size of an MBH cell. Besides being a very popular feature in action recognition, HOOF has been applied, in [5], to detect heads of moving people. After converting the flow vectors into histograms, the quality of the motion data increases while the feature becomes scale-invariant such that it will not degrade in a changing environment. For each rigid part connected with joints in the human body, the moving pattern includes the direction and the strength from unique parts and can be modeled by the HOOF.

The motion histogram features (MBH, HOOF) in this work are constructed based on a multi-level histogram designed to extract more spatial information [8]. For each level l ∈ {1, 2, 3, …, N}, the motion images are segmented into cells of a fixed size hl
                         × wl
                        . Different from Maji et al. [9], the global cells image are computed at the motion-pixel level (l
                        1) first. The feature of level l + 1 is ∑
                           c ∈ P
                        
                        c, where c is the cell’s pooling response in a 2 × 2 patch from level l. Each layer can follow the method and quickly build up the features through a simple indexing method. In this paper, the highest level is set to 4, and hence, the vector set {hl
                         × wl
                        } = {4 × 4, 8 × 8, 16 × 16, 32 × 32}. After all layers are set, L1-normalization is performed. All the features in the multi-level MBH and HOOF are then concatenated together as a 1*765 vector represented as [MBH
                        4, MNH
                        8, MBH
                        16, MBH
                        32] and [HOOF
                        4, HOOF
                        8, HOOF
                        16, HOOF
                        32].

During consecutive frames, the amplitude of a local cell in the HOOF does not vary significantly. The mean of the distribution, however, will gradually shift towards the direction of the object’s movement. Therefore, we propose a feature more invariant to the heading direction but one that cathchs the relative statistics of the local cells in the streaming video. The new feature proposed here has the ability to portray the relative motion within the moving objects such as the head. The RMD is extracted for every layer of the hierarchical HOOF, except in the HOOF
                        32. We compute pairwise distance between local HOOF cells to construct the RMD vectors. The distance metric plays an important role in histogram comparison, and the Bhattacharyya distance has been chosen as the measure due to its simplicity. Instead of comparing the HOOF cells one by one, the Bhattacharyya distance is computed with the advantage of using one matrix multiplication and could be easily vectorised as discussed below. Given C, the patch block consists of HOOF cells, the RMD(C) is:

                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             R
                                             M
                                             
                                                D
                                                i
                                             
                                             
                                                (
                                                C
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                {
                                                
                                                   ∥
                                                   H
                                                   O
                                                   O
                                                
                                                
                                                   F
                                                   a
                                                   i
                                                
                                                −
                                                H
                                                O
                                                O
                                                
                                                   F
                                                   b
                                                   i
                                                
                                                
                                                   
                                                      ∥
                                                   
                                                   
                                                      B
                                                      H
                                                      A
                                                   
                                                
                                                |
                                                ∀
                                                a
                                                ,
                                                b
                                                ∈
                                                C
                                                }
                                             
                                             ,
                                             
                                             and
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                ∥
                                                H
                                                O
                                                O
                                             
                                             
                                                F
                                                a
                                                i
                                             
                                             −
                                             H
                                             O
                                             O
                                             
                                                F
                                                b
                                                i
                                             
                                             
                                                
                                                   ∥
                                                
                                                
                                                   B
                                                   H
                                                   A
                                                
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                
                                                   (
                                                   H
                                                   O
                                                   O
                                                   
                                                      F
                                                      a
                                                      i
                                                   
                                                   )
                                                
                                                
                                                   (
                                                   H
                                                   O
                                                   O
                                                   
                                                      F
                                                      b
                                                      i
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                
                                                   (
                                                   H
                                                   O
                                                   O
                                                   
                                                      F
                                                      a
                                                      i
                                                   
                                                   )
                                                
                                             
                                             
                                                
                                                   (
                                                   H
                                                   O
                                                   O
                                                   
                                                      F
                                                      b
                                                      i
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        and i denotes the level in the pyramid histograms. First, we build a matrix M from n-dimensional HOOF square-root vectors, and perform matrix multiplication of MMT
                         to reduce the time consumption while computing the pair-wise distance. The computation complexity of the RMD therefore is cubic of n. Next, we collect RMD for the first three layers [RMD
                        4, RMD
                        8, RMD
                        16] and concatenate them into a 1 × 2142 vector from a 32 × 32 optical flow patch. A schematic is shown in Fig. 3
                        .

Support Vector Machines are known to be an effective classifier and have evolved from the concepts of Structural Risk Minimization (SRM) and regularization theory. SVMs perform classification by constructing an N-dimensional hyperplane that optimally separates data into two categories. By combining max-margin classification and empirical risk minimization, using structural risk minimization, and also by applying the kernel trick to achieve nonlinearity, SVMs are able to tackle highly complex classification tasks and generalise well without suffering from over-fitting [45].

For both histograms defined in Section 3.2, the bins correspond to the orientations. Moreover, in a given image patch, the frequencies in both histograms are the magnitude of two motion features. The values of these motion features are bounded but the maximum and minimum values of the flows may vary. The edges revealed by the MBH could be considered as the relative motion strength of two movements. Therefore, the magnitude values are normalised by their L2-distance in a small image patch that results in a normalised histogram of relative movements. Such histograms have the following characteristics: firstly, all the values of the histograms are greater than or equal to zero; and secondly, the sum of the histogram values is equal to one due to our definition. Based on Ablavsky et al. [13], this form of histogram belongs to the set of geometric p-Simplex manifold. In Appendix A, the proof that the proposed features belong to the family of Simplex Manifold is presented. It is a M-dimensional smooth manifold with corners smoothly embedded in 
                           
                              
                                 R
                                 
                                    M
                                    +
                                    1
                                 
                              
                              ,
                           
                         which is equivalent to an M-ball, will be shown below by re-parametrization. The points v
                        1, …, vM
                        , denoted as the orientations of the motion features, form the vertices of the simplex which are any M points in 
                           
                              R
                              
                                 M
                                 +
                                 1
                              
                           
                        . The distances on 
                           
                              P
                              
                                 M
                                 −
                                 1
                              
                           
                         are defined as a pullback for a mapping 
                           
                              g
                              ,
                           
                         where 
                           
                              g
                              :
                              x
                              →
                              (
                              
                                 
                                    x
                                    ^
                                 
                                 1
                              
                              ,
                              ⋯
                              ,
                              
                                 
                                    x
                                    ^
                                 
                                 M
                              
                              )
                           
                        . The similarity measure in such space can be established by computing the Bhattacharyya kernel measures. Therefore, we can map the Simplex manifold explicitly to the Euclidean space using kernel measures popularly used to the histogram family.

As discussed above, the histogram is a discrete value of the frequency occurrence for quantised visual features. Among histograms, popular similarity metrics or kernels include the Kullback-Leibler divergence, the Fisher kernel, the χ
                        2 kernel, and the intersection kernel. Besides these kernels, Bhattacharyya kernel is applied most widely for computer vision applications such as tracking. The Bhattacharyya kernel in the discrete space is given by

                           
                              (2)
                              
                                 
                                    
                                       
                                          
                                             
                                                K
                                                
                                                   B
                                                   H
                                                   A
                                                
                                             
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   d
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   x
                                                   (
                                                   d
                                                   )
                                                   y
                                                   (
                                                   d
                                                   )
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   d
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   x
                                                   (
                                                   d
                                                   )
                                                
                                             
                                             
                                                
                                                   y
                                                   (
                                                   d
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             〈
                                             φ
                                             (
                                             x
                                             )
                                             ,
                                             φ
                                             (
                                             y
                                             )
                                             〉
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where the x and y are D-dimensional vectors. φ(x) is equivalent to square root of the inner product, which is the linear kernel in SVM. The cost of mapping is merely the square root inner product for two histogram vectors. It is therefore fast and practical for high-dimensional data learning. The KBHA
                         is positive semi-definite due to the characteristic of the Probabilistic Product Kernel (PPK) [39]. Another kernel that is suitable for a histogram feature, and also a Mercer kernel, is the Bhattacharyya-mapping of intersection kernel (KBIK
                        ) [9]. Given two histogram vectors x and y, the KBIK
                         is:

                           
                              
                                 
                                    
                                       K
                                       
                                          B
                                          I
                                          K
                                       
                                    
                                    
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    =
                                    
                                       ∑
                                       
                                          d
                                          =
                                          1
                                       
                                       D
                                    
                                    min
                                    
                                       (
                                       φ
                                       
                                          (
                                          x
                                          
                                             (
                                             d
                                             )
                                          
                                          )
                                       
                                       ,
                                       φ
                                       
                                          (
                                          y
                                          
                                             (
                                             d
                                             )
                                          
                                          )
                                       
                                       )
                                    
                                 
                              
                           
                        Mapping φ above in two Bhattacharyya kernels spans a subspace in Hilbert space 
                           H
                         that captures the complex structure in the original input space. LibSVM 
                        [46], a popular SVM software suite, then trains the output vectors for each feature after mapping.

Due to the complexity of the problem, it is clear that a single feature like HOG or HOOF, will prove to be insufficient for describing the object [3]. In the literature on multiple-features learning, two popular fusion methods are discussed—viz., feature-level and decision-level fusion. Feature-level fusion is a simple strategy for addressing this issue and involves concatenating different cues into a single vector. Another method is decision-level fusion. This method votes or averages the results from multiple single classifiers and depends on the complementary properties of various features. In this paper, we address the problem with an all-agree voting system among the decision labels from the individual SVM classifiers in all four features—MBHU, MBHV, HOOF, RMD. The method is tantamount to the intersection of all decision values. We believe such a setting can help to reduce false positives produced by some features.

To extract heads from crowds, the window size in the sliding-window framework is set to a 32 × 32 square. The parameters in the SVM are learned through a ten-fold cross-validation on our validation data sampled from the training data. We empirically set the histogram bin-size for each cell to nine. The workflow of each feature is computed according to the architecture in Fig. 2. In the first round of classification, a large number of false positives remain. Most false positives are from other body parts, or head-like object. In order to reduce the number of these false positives, we run a second round of classification to differentiate so-called hard negatives. The training at the second stage collects a new set of heads as positive samples and other non-head patches from the first stage are hard-negative samples. For each individual feature, the positive predictions from the first-stage model are sent to the second-stage model to refine the false positives estimation. After the results are collected from the second-stage classifier, a standard Non-Maximum Suppression (NMS) [6] method is performed to merge overlapping responses. The overlapping area threshold is set to 50%, as suggested in most literature.

In this section, we discuss the evaluation of the proposed motion features for detecting heads in a public-crowd video dataset. Different combinations of motion features were tested: the results of votes from all the features in Stage 1 and Stage 2, from combinations of shape and relative motion (MBHU, MBHV, RMD), and from each respective feature individually. The results from explicit mapping kernels selection—includeing the linear, intersection, linear-Bhattacharyya, and the intersection-Bhattacharyya kernel—are shown below. To compare the proposed method with other, the state-of-the-art features on head detection, we used Wojek’s multiple motion/static features and Dollar’s static multiple channel features [3,18]. Finally, the proposed head detector was compared with a whole-body pedestrian detector that applies a similar multi-level pyramid and intersection kernel on histograms, as proposed by Maji et al. [9].

The evaluation process follows the same pattern: first, for extracting the motion histograms, the dense optical flow were extracted in consecutive images. Second, the features were extracted in 8 × 8-sized local regions throughout the image. Third, a sliding window is run from the top-left to the bottom-right to collect all possible 32 × 32-sized candidates consisting of heterogeneous features in steps of 8 pixels. Finally the testing candidates are vectored and inputted to the SVM for classifying heads and non-heads. The results of the SVMs are then passed to the scoring module and compared with ground-truth data.

The evaluation dataset used was PETS 2009 S1-L1-View1-1357. This dataset was chosen due to the presence of high occlusion and far-away targets (equivalent to low resolution), which persist as two challenging issues for pedestrian detection. The number of people in the dataset ranges from 1 to 40. The video was captured at seven frames per second and has a resolution of 768 × 576. Robustness for head detection models requires that the training data contain a high number of positive heads and negative non-heads. The positive samples were collected from manual annotations. In the experiment 1000 positive samples and 1000 negative samples were randomly selected. In the first stage, models were trained with LibSVM using different features. At the second stage, the model were trained using positive samples from the first stage along with a new set of negative samples consisting of some unused negative samples and about 500 hard-negative samples that were false positives in Stage 1 (falsely classified as heads).


                        Fig. 4
                         shows the performance of the combined motion features and the individual motion histogram features by plotting the miss rate (False Negatives) versus the number of False Positives Per Image (FPPI). Lower curves close to the axes represent better performance. From Fig. 4, we observe that voting through all the features for the Stage 2 detector produced the best results. This implies that the false positives caused when a single feature is used and has been effectively removed by other features in the voting stage. As shown in Fig. 5
                        , it is observed that the proposed feature - RMD outperforms HOOF features in terms of number of false alarms per image. The proposed RMD is not only being more robust over HOOF, but also competitive as compared to the other motion features.

In Hanini et al. [36], a motion dynamic texture feature, the Motion Interchange Patterns (MIP) has been proposed, which produces a coding of relative movement in a neighborhood. As shown in Fig. 6
                        , the proposed RMD features outperforms MIP features with drop in False-Positives-Per-Image (FPPI). In order to maintain consistency in comparison, both features are run on a single-scale extraction instead of the multi-pyramid. Further, the proposed system was found to be more computationally efficient due to the patch-wise feature extraction rather than pixel-wise.

The performance of Bhattacharyya mapping applied to linear SVMs (BHA-Linear and Linear) and Histogram Intersection SVMs (BHA-HIK and HIK) using the proposed two stage head detector were compared. The popular RBF kernel SVM was not reported here because of its heavy computation time, caused by the non-linearity property. The experiment was performed on PETS 2009 dataset and the evaluation metric for kernel comparison was comparatively False Positive Per Image (FPPI). From Fig. 7
                        , it is clear that the BHA-HIK performs best and obtain the lowest curve. Further, it shows that Bhattacharyya mapping significantly reduces the error rate in linear SVM. The false-positive errors for the linear SVM detector after we perform the mapping have decreased by approximately 0.5 FPPI. However, we have found that Bhattacharyya mapping did not improve much in the HIK. One possibility explaining this is that the HIK kernel itself provides a considerable improvement, implying that the intersection kernel is an explicit mapping kernel that has mapped the features into Euclidean space. Therefore, further mapping did not result in any improvement. Similar results have been reported in [41] for full-body detection, where a 12% improvement over linear SVM by Bhattacharyya mapping is achieved with only a 3% improvement using an intersection kernel.

To evaluate the effectiveness of the proposed approach, we compared it with state-of-the-art pedestrian detectors by Dollar et al. [18] and Wojek et al. [3]. The channel features were computed using the packages from Dollar et al. [18] with slight modifications to make it appropriate for detecting heads. Multiple static and motion features proposed by Wojek et al. [3] were re-implemented following all the settings provided by the authors. To ensure fairness, the two features compared are implemented in the multi-level pyramid as well as the proposed system. Further, in order to test the results of the proposed approach for human detection within crowds, we used the full-body detection proposed by Maji et al. [9] (allowing it to run on full-body human detection). The metrics that were used to evaluate the performance were the following: Recall, Precision and F-score as defined in equation (3).

                           
                              (3)
                              
                                 
                                    
                                       
                                          Recall
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                T
                                                P
                                             
                                             
                                                T
                                                P
                                                +
                                                F
                                                N
                                             
                                          
                                       
                                    
                                    
                                       
                                          Precision
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                T
                                                P
                                             
                                             
                                                T
                                                P
                                                +
                                                F
                                                P
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             F
                                             -
                                             score
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             2
                                             ×
                                             
                                                [
                                                
                                                   
                                                      P
                                                      r
                                                      e
                                                      c
                                                      i
                                                      s
                                                      i
                                                      o
                                                      n
                                                      ×
                                                      R
                                                      e
                                                      c
                                                      a
                                                      l
                                                      l
                                                   
                                                   
                                                      P
                                                      r
                                                      e
                                                      c
                                                      i
                                                      s
                                                      i
                                                      o
                                                      n
                                                      +
                                                      R
                                                      e
                                                      c
                                                      a
                                                      l
                                                      l
                                                   
                                                
                                                ]
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where, TP, FP, FN denotes True Positives, False Positives, False Negatives. The number of false-positives indicates the selection of non-heads as heads, and the number of false-negatives indicates heads that were not detected. However, it should be noted that researchers in the field of machine learning normally use is not appropriate for applications based on the sliding-window technique. The reason for this is that most of the candidate windows are non-heads and the results would be ambiguous. Table 1
                         gives the comparison. Relatively, our systems achieved both high precision and recall as compared to other multi-feature detectors. In the category of recall, we found that using motion features achieves a high discriminability as compared with static appearance features. Moreover, our system performed significantly better in the metric of precision. This is mainly due to following reasons: (a) the heads given were too small and did not provide enough information to distinguish them from head-shaped object; (b) the proposed voting strategy among multiple features reduces the false positives while most systems train and detect using a single vector which is concatenated by all the features. Interestingly, despite the low precision of channel and static/motion features in head detection, the method targeting the head performed better in terms of recall when compared with the full-body detection method. This confirms our hypothesis that using head detection in occluded scenarios is a better choice for crowd tracking. The F-score that gives a harmonic mean of precision and recall is a good indicator of performance and the proposed system clearly performs better than other methods tested, having a score of over 69%. Although the proposed method’s F-score is similar to that of the two alternatives approaches, based on a visual inspection of the results, the reduction in false positives is significant. For the sake of comparison, the popular radial basis function (RBF) kernel is also tested. It is worth to note that the performance of RBF kernel, which is also a non-linear kernel, has poorer performance in head detection. The precision obtained is very much lower compared to to the one stage BHA-HIK detector is observed. Further, the computational complexity is much higher. To provide a comprehensive understanding of the issues relating to false positives with respect to other methods tested, the detection results using various techniques are shown in Fig. 8
                        .

There are a few interesting aspects in the comparison presented in Table 1. The static features used in full body scan by Maji et al. [9] resulted in the least number of false positives. However, the total number of false negatives using Maji et al. [9] is significantly higher compared to the proposed approach. The classifier appears to be highly biased with low recall rate and lower F-scores. It further emphasises the importance of combining static and motion features effectively as they tend to offer contrasting advantages in head detection. The table also indicates that the methods by Dollar et al. [18] and Wojek et al. [3] do not perform well when the resolution of the target is very low as in the case of crowd monitoring. The proposed head detector captured more heads in occluded crowds and is, as a result, more accurate (with higher F-scores than any other method). Considering the single stage and two stage approaches of the proposed classifier, it is clear that the two stage classifier results in better F-score with improved recall and precision rates. The second stage of the classifier not only ensures fewer false positives, which was the original intention, but it results in higher true positives improving the precision. Further, it was observed that the the second stage ensures consistent results across all frames of video with comparable F-score unlike single stage algorithm that had a tendency to have many false positives in certain frames. This justifies the use of second stage of classification in spite of minimal difference in F-score between the two approaches. Fig. 9
                         shows, the detailed head-detection results from the proposed two-stage head detector, using Bhattacharyya-HIK kernel (and PETS 2009 S1-L1-View1-1357 from frame-index 15 to 45, skipping one frame). It is worth noting that, because our detector learns to detect heads, some extra false positives or multiple detections of a single human object are often inevitable. The primary reason for this is that objects such as backpacks appear to the algorithm as head-like. Another observation is that the partial occlusion of the lower back resulted in the false detection of a head. Despite these hard scenarios, our detector is able to detect results in the regions where persons were located while producing clean results for the background regions.

Calculation of motion features and their derivatives is a computationally intensive task. In most surveillance operations, there are several processes that are running in parallel and most of them use motion as well as static features. Due to the advantages provided by motion features, particularly in dense videos, it is inevitable to use them. Further, it is important to ensure that the overall system implementation is feasible in real-time with state-of-the-art hardware. The proposed algorithm has been implemented on a NVIDIA GeForce 7800 GS graphic card GPU as calculation of TV-L1 in real time is computationally intensive. In order to benchmark against industry standards, we choose a static feature (HOG) [4], a motion feature using Horn and Schunk optical flow [43] and the proposed method that uses TV-L1 optical flow. All algorithms are compared using a CPU initially and finally the proposed algorithm is implemented using GPU to demonstrate feasibility in real-time. The overhead of HOG feature extraction process is considered as base for comparison and set to one. For the other methods, the overhead is their process time with respect to the time taken for HOG calculation. The results of the benchmark test is shown in Table 2
                        . As it can be seen, the proposed method is computationally intensive on a CPU as expected due to the calculation of TV-L1 optical flow. It should also be noted that the overhead is mainly due to optical flow calculation and not feature extraction itself. However, using a GPU, the complexity in calculating TV-L1 reduced from 37.6212X to 1.1512X. Further, feature calculation using the proposed method is only a marginally higher than the static HOG features using a GPU demonstrating the feasibility of implementation in real-time.

@&#CONCLUSION@&#

In this paper, a head detector that uses motion features exclusively was presented with excellent results. The specific targets for this technology include crowd monitoring and the detection of heads in the presence of occluded environment. A new motion feature, the relative motion distance (RMD), is proposed to combines two other motion histogram features (HOOF and, MBH) using a two-stage SVM head detector. Further, we demonstrated the increasing discriminability of linear and intersection kernels in SVMs when mapping with Bhattacharyya kernel. The results of the proposed method were compared with two state-of-the-art head detectors and a full body detector. The F-score for the proposed system is shown to be around 69%, which is at least 12% better than the nearest head detector reported in previous research.

@&#ACKNOWLEDGMENT@&#

This work is partially supported by the ARC linkage project LP100200430, partnering the University of Melbourne, Melbourne Cricket Club and ARUP. Authors would like to thank representatives and staff of ARUP and MCG. We also thank Mr. Aravinda S. Rao for his valuable feedback.


                     
                        Proof
                        Let 
                              
                                 x
                                 ∈
                                 
                                    R
                                    
                                       +
                                    
                                    M
                                 
                                 ,
                              
                            with the simplex 
                              
                                 P
                                 M
                              
                            denoted as follows:

                              
                                 
                                    
                                       
                                          P
                                          M
                                       
                                       =
                                       
                                          {
                                          
                                             x
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             x
                                             M
                                          
                                          |
                                          
                                             ∑
                                             
                                                m
                                                =
                                                1
                                             
                                             M
                                          
                                          
                                             
                                                x
                                                m
                                             
                                             =
                                             1
                                          
                                          ,
                                          
                                             x
                                             m
                                          
                                          ≥
                                          0
                                          }
                                       
                                    
                                 
                              
                           where, m is the numbers of the bins in the histogram. As discussed earlier, each element in the histogram is greater than zero, that is xm
                            ≥ 0. Subsequently, we re-parametrise the motion histogram to square root representation
                           
                              
                                 
                                    
                                       
                                          X
                                          ^
                                       
                                       =
                                       
                                          [
                                          
                                             
                                                x
                                                1
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                x
                                                m
                                             
                                          
                                          ]
                                       
                                    
                                 
                              
                           such that

                              
                                 
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          
                                             (
                                             
                                                
                                                   X
                                                   ^
                                                
                                                i
                                             
                                             )
                                          
                                          2
                                       
                                       =
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          
                                             (
                                             
                                                
                                                   x
                                                   i
                                                
                                             
                                             )
                                          
                                          2
                                       
                                       =
                                       1
                                    
                                 
                              
                           The projection turns L2-histogram into the unit M-dimensional hyper-sphere. It is Hausdroff and second countable due to its property that it is a subspace of 
                              
                                 R
                                 
                                    M
                                    +
                                    1
                                 
                              
                           . To show such histogram is locally Euclidean, let Ui
                            denote the subset of simplex 
                              P
                           
                           
                              
                                 
                                    
                                       
                                          U
                                          i
                                       
                                       =
                                       
                                          
                                             (
                                             
                                                
                                                   x
                                                   ^
                                                
                                                1
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   x
                                                   ^
                                                
                                                
                                                   m
                                                   +
                                                   1
                                                
                                             
                                             )
                                          
                                          ∈
                                          
                                             P
                                             M
                                          
                                       
                                       :
                                       
                                          
                                             x
                                             ^
                                          
                                          i
                                       
                                       >
                                       0
                                    
                                 
                              
                           For each i, define maps 
                              
                                 
                                    ψ
                                    i
                                 
                                 :
                                 
                                    U
                                    i
                                 
                                 →
                                 
                                    R
                                    M
                                 
                              
                            by following:

                              
                                 
                                    
                                       
                                          ψ
                                          i
                                       
                                       
                                          (
                                          
                                             
                                                x
                                                ^
                                             
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                x
                                                ^
                                             
                                             
                                                m
                                                +
                                                1
                                             
                                          
                                          )
                                       
                                       =
                                       
                                          (
                                          
                                             
                                                x
                                                1
                                             
                                             ^
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                x
                                                i
                                             
                                             ˜
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                x
                                                
                                                   m
                                                   +
                                                   1
                                                
                                             
                                             ^
                                          
                                          )
                                       
                                    
                                 
                              
                           The tilde over x indicates that xi
                            is omitted due to linear dependency. The continuous inverse given by:

                              
                                 
                                    
                                       
                                          
                                             (
                                             
                                                ψ
                                                i
                                             
                                             )
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          (
                                          
                                             u
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             u
                                             m
                                          
                                          )
                                       
                                       =
                                       
                                          (
                                          
                                             u
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             u
                                             
                                                i
                                                −
                                                1
                                             
                                          
                                          ,
                                          ±
                                          
                                             
                                                1
                                                −
                                                
                                                   u
                                                   2
                                                
                                             
                                          
                                          ,
                                          
                                             u
                                             i
                                          
                                          ,
                                          …
                                          
                                             u
                                             n
                                          
                                          )
                                       
                                    
                                 
                              
                           is homeomorphic onto its image, the unit sphere, since every point in 
                              
                                 R
                                 
                                    m
                                    +
                                    1
                                 
                              
                            is in the domain of histograms. Thus it is a smooth topological manifold with corner by the fact of the greater-than-zero boundary.□

@&#REFERENCES@&#


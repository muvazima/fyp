@&#MAIN-TITLE@&#Hierarchical segmentation and identification of thoracic vertebra using learning-based edge detection and coarse-to-fine deformable model

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A New supervised learning based bone edge detectors using efficient features and classification.


                        
                        
                           
                           A New hierarchical, coarse-to-fine deformation strategy for vertebra segmentation.


                        
                        
                           
                           Vertebrae mean shapes based effective identification of different thoracic vertebra.


                        
                        
                           
                           State-of-the-art performance on vertebra segmentation accuracy and identification success rate.


                        
                        
                           
                           Extended to other orthopedic structures, e.g., manubrium.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Supervised edge detection

Coarse-to-fine shape deformation model

Shape based medical image segmentation

Vertebra segmentation

Vertebra identification

Computed tomography

@&#ABSTRACT@&#


               
               
                  Precise segmentation and identification of thoracic vertebrae is important for many medical imaging applications though it remains challenging due to the vertebra’s complex shape and varied neighboring structures. In this paper, a new method based on learned bone-structure edge detectors and a coarse-to-fine deformable surface model is proposed to segment and identify vertebrae in 3D CT thoracic images. In the training stage, a discriminative classifier for object-specific edge detection is trained using steerable features and statistical shape models for 12 thoracic vertebrae are also learned. For the run-time testing, we design a new coarse-to-fine, two-stage segmentation strategy: subregions of a vertebra first deform together as a group; then vertebra mesh vertices in a smaller neighborhood move group-wise to progressively drive the deformable model towards edge response maps by optimizing a probability cost function. In this manner, the smoothness and topology of vertebrae shapes are guaranteed. This algorithm performs successfully with reliable mean point-to-surface errors 0.95±0.91mm on 40 volumes. Consequently a vertebra identification scheme is also proposed via mean surface mesh matching. We achieve a success rate of 73.1% using a single vertebra, and over 95% for 8 or more vertebra which is comparable or slightly better than state-of-the-art [5].
               
            

@&#INTRODUCTION@&#

A precise vertebra segmentation and identification method is in high demand due to its importance in many orthopaedic, neurological and oncological applications. In this paper, we focus on thoracic vertebra where accurate segmentation and identification can directly eliminate false findings on lung nodules in computer aided diagnosis (Lung CAD) system [14,25,6]. However, this task remains challenging due to the significant complexity of vertebrae, i.e., within-class shape variation and different neighboring structures. An illustration of our motivation is shown in Fig. 1
                     .

Several methods have been reported addressing segmentation and/or identification of vertebra under different modalities [24,17,4,13,15,5], e.g., magnetic resonance imaging (MRI) or computed tomography (CT). Yao et al. [24] present a method to automatically extract and partition the spinal cord in CT images, and a surface-based registration approach for automatic lumbar vertebra identification is described in [4], where no identification was carried out in either work. A hierarchical 3D segmentation method of the lumbar spine in CT images with the definition of vertebral body coordinate systems is described in [13]. In [15], Peng et al. propose a vertebra detection and segmentation algorithm processing 2D slices of MRI images, instead of the 3D volume as a whole. Recently, Klinder et al. [5] propose a model-based solution for vertebra detection, segmentation and identification in CT images. They achieved very competitive identification rates of >70% for a single vertebra and 100% for 16 or more vertebrae. However, their identification algorithm is based on vertebrae active appearance model (i.e., an averaged intensity volume block) for spatial registration and matching which is very computationally expensive (20–30min).

In this paper, we present a new automatic vertebra segmentation and identification method. Although this work mainly focuses on thoracic vertebra (for potential lung applications), our approach can be easily extended to cervical and lumbar vertebrae. The main contributions of this paper are summarized as follows. First, we introduce a learning based bone structure edge detection algorithm, including efficient and effective gradient steerable features and robust training data sampling. Second, we propose a hierarchical, coarse-to-fine deformable surface based segmentation method based on the response maps from the learned edge detector, followed with an efficient vertebra identification method using mean shapes. Finally, promising results of both segmentation and identification are presented, compared with the state-of-the-art [5]. An earlier version of this paper appears in [11].

@&#METHOD@&#

Due to complex neighboring structures around vertebra and imaging noise, common edge detectors (e.g., Canny operator) often produce leaking and spurious edge. To achieve robust edge detection, we develop a learning-based object specific edge detection algorithm similar to semantic object-level boundary lineation in natural and medical images [2,12,28,10].

Bone-structures normally show high intensity/attenuation in CT images. However, due to complex neighboring structures around vertebra and imaging noise, common edge detectors (e.g., Canny operator) do not perform well, often with leaking and spurious edge.

We manually segmented 12 thoracic vertebrae from 20 CT volumes for training, and generated corresponding triangulated surfaces using the Marching Cube algorithm [8], with about 10,000 triangular faces per vertebra model. It is observed that along the normal direction of the bone boundary, the intensity values roughly form a ridge pattern. Our new set of steerable features are designed to describe the characteristics of boundary appearance, which make it feasible for statistical training.

For each triangle face of the surface mesh, we take 5 sampling points (called a sampling parcel) along the face normal direction with one voxel interval. Specifically, given x as a point on the normal line and n the unit normal vector, the sampling parcel associated with x is
                              
                                 
                                    P
                                    (
                                    x
                                    )
                                    =
                                    {
                                    x
                                    -
                                    2
                                    n
                                    ,
                                    x
                                    -
                                    n
                                    ,
                                    x
                                    ,
                                    x
                                    +
                                    n
                                    ,
                                    x
                                    +
                                    2
                                    n
                                    }
                                 
                              
                           For each of the 5 sampling points we compute three features: (1) intensity I, (2) and (3) projections of gradient onto the normal direction ∇1
                           I
                           ·
                           n and ∇2
                           I
                           ·
                           n, where ∇1
                           I and ∇2
                           I are gradient vectors computed using derivative of Gaussian with two different kernel scales. In total, the feature vector of a point x, denoted by 
                              
                                 F
                                 (
                                 x
                                 )
                              
                           , has 15 elements:
                              
                                 
                                    F
                                    (
                                    x
                                    )
                                    =
                                    {
                                    I
                                    (
                                    y
                                    )
                                    ,
                                    
                                       
                                          ∇
                                       
                                       
                                          1
                                       
                                    
                                    I
                                    (
                                    y
                                    )
                                    ·
                                    n
                                    ,
                                    
                                       
                                          ∇
                                       
                                       
                                          2
                                       
                                    
                                    I
                                    (
                                    y
                                    )
                                    ·
                                    n
                                    |
                                    y
                                    ∈
                                    P
                                    (
                                    x
                                    )
                                    }
                                 
                              
                           
                           Fig. 2
                            illustrates the sampling parcel and its associated features. Our steerable features are indeed oriented-gradient pattern descriptor with easy computation.

The training samples of positive and negative boundary voxels are obtained from manually segmented vertebra meshes. For a triangle face center c, we define the boundary parcel as
                              
                                 
                                    P
                                    (
                                    c
                                    )
                                    =
                                    {
                                    c
                                    -
                                    2
                                    n
                                    ,
                                    c
                                    -
                                    n
                                    ,
                                    c
                                    ,
                                    c
                                    +
                                    n
                                    ,
                                    c
                                    +
                                    2
                                    n
                                    }
                                 
                              
                           interior parcel as
                              
                                 
                                    P
                                    (
                                    c
                                    -
                                    3
                                    n
                                    )
                                    =
                                    {
                                    c
                                    -
                                    5
                                    n
                                    ,
                                    c
                                    -
                                    4
                                    n
                                    ,
                                    c
                                    -
                                    3
                                    n
                                    ,
                                    c
                                    -
                                    2
                                    n
                                    ,
                                    c
                                    -
                                    n
                                    }
                                 
                              
                           and exterior parcel as
                              
                                 
                                    P
                                    (
                                    c
                                    +
                                    3
                                    n
                                    )
                                    =
                                    {
                                    c
                                    +
                                    n
                                    ,
                                    c
                                    +
                                    2
                                    n
                                    ,
                                    c
                                    +
                                    3
                                    n
                                    ,
                                    c
                                    +
                                    4
                                    n
                                    ,
                                    c
                                    +
                                    5
                                    n
                                    }
                                 
                              
                           That is, the interior parcel is three voxels away backward from boundary parcel while exterior parcel is the three voxels forward, where 3 is adjustable. The corresponding feature vectors 
                              
                                 F
                                 (
                                 c
                                 )
                                 ,
                                 
                                 F
                                 (
                                 c
                                 -
                                 3
                                 n
                                 )
                                 ,
                                 
                                 F
                                 (
                                 c
                                 +
                                 3
                                 n
                                 )
                              
                            can be also computed. Then we label 
                              
                                 F
                                 (
                                 c
                                 )
                              
                            as positive (i.e., boundary), and label both 
                              
                                 F
                                 (
                                 c
                                 -
                                 3
                                 n
                                 )
                              
                            and 
                              
                                 F
                                 (
                                 c
                                 +
                                 3
                                 n
                                 )
                              
                            as negative (i.e., non-boundary), as Fig. 3
                            (top-left). Thus, each triangle face provides one positive data example and two negative examples. Given one vertebra surface mesh with about 10,000 faces, sufficient and adequate training feature vectors are obtained. Note that a single and unified bony edge detector will be learned for all 12 thoracic vertebrae. Compared with implicit object “inside–outside” learning
                              1
                              The boundary has to be further inferred from the transition of (object) internal positives and external negatives in prostate or polyp segmentation [27,10] which may not be trivial.
                           
                           
                              1
                            
                           [27,10,16], our boundary/non-boundary delineation strategy directly focuses on modeling the runtime boundary localization process (i.e., explicitly moving towards classified boundary positives), and is expected to have higher precision.

The feature vectors depend on the normal direction of triangle faces and consequently the edge detector is sensitive to the initialization of the surface template. In our experimental setup, the surface model is first roughly registered with images by automatic detection [9,28,23] or manual alignment, thus the normal direction of the surface model cannot perfectly coincide with the true bony normal. To make the detector more robust to mis-alignment errors and the later deformable model convergent, it is important that we synthesize some “noisy” training samples by stress testing. Particularly, we add some random perturbations to the orientations and scales of the template model so that the template surface model does not accurately overlap with the manual segmentation. Considering a similarity transform, a random number between 0.9 and 1.1 for each of the three scales, and a random angle between 
                              
                                 -
                                 
                                    
                                       π
                                    
                                    
                                       10
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       π
                                    
                                    
                                       10
                                    
                                 
                              
                            for each of the three orientation angles are used. The true boundary parcels, as well as interior and exterior parcels are defined using ground truth positions but with perturbed template surface normals. Refer to Fig. 3 (top-right) for an illustrative example. Their corresponding feature vectors are consequently calculated (with the disturbed face normals) and added into our training sets. The random perturbation process is repeated 10 times for each training mesh to guarantee sufficient noisy training samples. We then train a Linear or Quadratic Discriminant (LDA,QDA) classifier [3] based on the combined non-perturbed and perturbed feature vectors. Both LDA and QDA are evaluated and we find that LDA yields more robust results. The experiment results are computed with LDA. Finally, given a voxel x and its feature vector 
                              
                                 F
                                 (
                                 x
                                 )
                              
                           , our classifier assigns a value 
                              
                                 L
                                 (
                                 x
                                 )
                                 ∈
                                 [
                                 0
                                 ,
                                 1.0
                                 ]
                              
                            which indicates the likelihood of x being boundary point.

Our method is conceptually simple and easy to compute compared with boundary detectors learned using tens of thousands of 3D Haar features [20] or steerable features [28,10,7] with hierarchical boosting framework [22,19]. Due to our effective coarse-to-fine deformable model, it also alleviates the requirement or burden of generating perfect boundary response maps where even more sophisticated methods [28,10,7] still produce noisy responses. In general, per-voxel class conditional labeling is non-trivial and needs spatial regularization for smooth results. Note that here we only need to train one classifier for detecting all 3D (thoracic) vertebra bone boundaries coupled with our deformation model (Non-Gaussian), while active shape model [1] based deformation (Gaussian) needs to build several individual boundary detectors for successive organ parts of 3D liver segmentation in CT images [7].

In this work, our research is focused on providing an automatic vertebra segmentation and identification module instead of detecting the pose of vertebra. We manually initialize the position and orientation of the template surface using landmarks so that the surface model roughly coincides with the vertebrae to be segmented in the 3D volume. The automatic algorithm for detection and localizing vertebra [30,18] is also used for evaluation later, using similar strategies as sparse redundant anatomical landmark detections [29] or marginal space learning [9,28] in the full 3D volumetric domain.

The main idea of segmentation is to deform the surface template mesh towards boundary points detected by the learned edge detector. After the surface template is initially positioned in a new volume (the template can be initialized using similar strategies as marginal space learning [9,28] for 3D organ localization), the edge detector calculates the edge likelihoods 
                           
                              L
                              (
                              x
                              )
                           
                         for voxels along the normal directions of all mesh faces so that a response map is generated. As shown in Fig. 3 (bottom-right), this response map is informative but unavoidably noisy. If we just deform each face toward its most-likely boundary position independently, the shape of vertebrae may not be retained. Hence some constraints to guarantee the surface shape topology and smoothness during deformation/segmentation must be enforced. To guarantee the surface shape topology and smoothness during deformation/segmentation, we propose a hierarchical deformation scheme of first performing deformation of subregions; then performing patch-wise deformation (i.e., points in the same neighborhood move together).

We manually divide the surface mesh into 12 subregions, as indicated by Fig. 4
                           . In order to maintain the shape of these subregions, a similarity transformation to each subregion is applied such that the total response of edge detection is maximum in the transformed configuration. For a subregion S and some face center f on S, we intend to find a similarity transformation 
                              
                                 
                                    
                                       T
                                    
                                    
                                       ^
                                    
                                 
                              
                            satisfying
                              
                                 (1)
                                 
                                    
                                       
                                          T
                                       
                                       
                                          ^
                                       
                                    
                                    =
                                    arg
                                    
                                       
                                          
                                             max
                                          
                                          
                                             T
                                             ∈
                                             T
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             f
                                             ∈
                                             S
                                          
                                       
                                    
                                    L
                                    (
                                    T
                                    (
                                    f
                                    )
                                    )
                                 
                              
                           where T is the set of similarity transformations T:
                              
                                 (2)
                                 
                                    T
                                    =
                                    R
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            x
                                                         
                                                      
                                                   
                                                   
                                                   
                                                
                                                
                                                   
                                                   
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            y
                                                         
                                                      
                                                   
                                                   
                                                
                                                
                                                   
                                                   
                                                   
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            z
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    +
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            x
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            y
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            z
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           Here R is a rotation matrix parameterized by three angles θ
                           
                              x
                           , θ
                           
                              y
                           , θ
                           
                              z
                           . Searching the optimal T involves the 9-dimensional parameters space of (T
                           
                              x
                           ,
                           T
                           
                              y
                           ,
                           T
                           
                              z
                           ,
                           S
                           
                              x
                           ,
                           S
                           
                              y
                           ,
                           S
                           
                              z
                           ,
                           θ
                           
                              x
                           ,
                           θ
                           
                              y
                           ,
                           θ
                           
                              z
                           ). If we perform a exhaustive search with 5 grid steps for each parameters, then possible transformation is 59 which is computationally prohibitive. To reduce the search space, we perform a three-stage search. First, search for (T
                           
                              x
                           ,
                           T
                           
                              y
                           ,
                           T
                           
                              z
                           ) with displacement {−4,−2,0,2,4} voxels for each translation; second, with fixed 
                              
                                 (
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             ^
                                          
                                       
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             ^
                                          
                                       
                                    
                                    
                                       y
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             ^
                                          
                                       
                                    
                                    
                                       z
                                    
                                 
                                 )
                              
                           , search for (S
                           
                              x
                           ,
                           S
                           
                              y
                           ,
                           S
                           
                              z
                           ) with discretization grids of {0.8,0.9,1.0,1.1,1.2} for each scaling; third, with fixed optimal translation and scaling, search for (θ
                           
                              x
                           ,
                           θ
                           
                              y
                           ,
                           θ
                           
                              z
                           ) with intervals of {−π/10,−π/20,0,
                           π/20,
                           π/10} for each orientation. In this way, we need to only consider 53
                           ×3=375 possible poses and select the one with the strongest response as 
                              
                                 
                                    
                                       T
                                    
                                    
                                       ^
                                    
                                 
                              
                           . This heuristic searching strategy turns out to be effective in capturing the true pose of subregions though it might be suboptimal. Fig. 5
                           a illustrates the searching process.

After the optimal similarity transformation is found for each subregions, a smooth deformation of the whole surface can be obtained using simple Gaussian smoothing. Let S
                           1,
                           S
                           2,…,
                           S
                           12 denote the twelve subregions, and T
                           1,
                           T
                           2,…,
                           T
                           12 be the corresponding optimal transform. Denote v to be an arbitrary vertex in the template surface and u a vertex in a certain subregion. Then the new position of v is
                           
                              
                                 
                                    
                                       
                                          v
                                       
                                       
                                          ′
                                       
                                    
                                    =
                                    v
                                    +
                                    λ
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             12
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             w
                                             ∈
                                             
                                                
                                                   S
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                    (
                                    
                                       
                                          T
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    w
                                    )
                                    -
                                    w
                                    )
                                    K
                                    (
                                    w
                                    -
                                    v
                                    )
                                 
                              
                           where 
                              
                                 K
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       e
                                    
                                    
                                       -
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             2
                                             
                                                
                                                   σ
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                            is the Gaussian kernel and λ is a regulation parameter. Fig. 5b shows the result of “deformation of subregion” stage. One can see the surface mesh is more closely aligned with the true boundary through “articulated” similarity moves, although in several areas, the surface mesh still has a certain distance from the true boundary. This will be solved by the finer-scale deformation strategy described below.

After deforming the subregions, the surface mesh is approximately overlapped with the vertebra’s boundary in CT volume. Next, we perform deformation on local neighborhoods of 200 patches divided from each vertebra mesh surface (each patch may contain approximately 50 faces). For each patch (denoted as PT), we compute its mean normal by this formula:
                              
                                 (3)
                                 
                                    
                                       
                                          n
                                       
                                       
                                          ¯
                                       
                                    
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          N
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             f
                                             ∈
                                             PT
                                          
                                       
                                    
                                    n
                                    (
                                    f
                                    )
                                 
                              
                           where f is a face in the patch and n(f) is the unit normal of the face. Then the patch is moved along its mean normal direction in search of the strongest response, that is, we optimize this term:
                              
                                 (4)
                                 
                                    
                                       
                                          i
                                       
                                       
                                          ˆ
                                       
                                    
                                    =
                                    arg
                                    
                                       
                                          
                                             max
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             f
                                             ∈
                                             S
                                          
                                       
                                    
                                    L
                                    (
                                    f
                                    +
                                    i
                                    
                                       
                                          n
                                       
                                       
                                          ¯
                                       
                                    
                                    )
                                 
                              
                           where the search range is limited in i
                           =−6,−5,…,5,6. Fig. 5c shows the a patch is displaced along its mean normal direction in search of the boundary. After all patches find their optimal displacement, a smooth deformation of the surface is again obtained by Gaussian smoothing. Fig. 5d shows the segmentation result of the “deformation of patches” stage. Clearly, the surface mesh now can accurately capture the true boundary of the vertebra. The two-stage, coarse-to-fine deformation of surface model guarantees the accuracy of segmentation as well as the smoothness of the shapes, using articulated similarity transforms and nonrigid transform respectively. In practice, we execute multiple rounds of Part- and Patch-based deformation schemes. The iteration numbers are empirically calibrated using cross-validation. In this paper, we choose the iteration numbers as Pt
                           =3 (Part) and Ph
                           =4 (Patch) by default.
                              Remark
                              Though the 12 subregions and patches are selected manually during the model building, this does not require much time (e.g., takes about 30min for each thoracic vertebra 3D mesh model). Once these models are selected, all other surface meshes can be generated by deforming the first template against other vertebra instances (i.e., 12 thoracic vertebra models are learned by fitting one template mesh on one exemplar case and then deforming on the other 9 instances
                                    2
                                    In our fourfold cross validation setting, ten volumes are used to learn the mean mesh shape model for each thoracic vertebra. Then these fitted models are applied on other 30 volumes for deformable segmentation. This is that we use onefold for training and three folds for testing.
                                 
                                 
                                    2
                                 ; each of the 12 vertebra models has 12 subgroups). Hence, the subregions and patches are inherited.

We applied the segmentation algorithm to 40 volumes at 1mm by 1mm by 1mm resolution, and 31–40 surface meshes are obtained per thoracic vertebra, due to missing vertebrae in some volumes. Vertex correspondence across meshes for each vertebra is also directly available since surface meshes are deformed by the same template. Therefore we can compute the mean vertebra shapes by simply taking the arithmetic mean of corresponding vertices’ positions. There are 12 thoracic vertebrae, namely T1,T2,…,T12. Vertebra identification is to label a segmented vertebra to be one of the twelve. In this context, given a single vertebra subvolume, we carry out the identification process by testing which mean shape has the maximum response. Specifically, we feed the 12 mean shapes to the vertebra volume one after another, and calculate the supervised edge response scores without deformation. The mean shape with the strongest response is determined as the label of this vertebra.

Let M
                        1,
                        M
                        2,…,
                        M
                        12 denote the twelve mean shapes and f, an arbitrary face center in the mean shapes. One way to calculate the responses is computing the overall likelihood of boundary:
                           
                              (5)
                              
                                 
                                    
                                       i
                                    
                                    
                                       ˆ
                                    
                                 
                                 =
                                 arg
                                 
                                    
                                       
                                          max
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 L
                                 (
                                 f
                                 )
                              
                           
                        Another way is to count the number of faces with high probability values as valid boundary points:
                           
                              (6)
                              
                                 
                                    
                                       i
                                    
                                    
                                       ˆ
                                    
                                 
                                 =
                                 arg
                                 
                                    
                                       
                                          max
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       1
                                    
                                    
                                       L
                                       (
                                       f
                                       )
                                       >
                                       α
                                    
                                 
                              
                           
                        where α is a threshold. We find the second method is more robust against outliers and noise, by tolerating up to (1−
                        α) portion of data being polluted at the correct spatial configuration where α
                        =0.8 is used for following experiments. We also extend the identification method to multiple vertebrae (i.e., a vertebra string). By using more context, multiple vertebrae identification is expected to have higher success rate. Refer to Fig. 7
                         for the mean shapes. This process is illustrated in Fig. 8
                        .

The algorithm flowcharts of our proposed deformable vertebra segmentation and identification algorithms are summarized in Fig. 6.

@&#RESULTS@&#

We apply our automatic segmentation algorithm to 40 volumes of thoracic scans and the evaluation is performed using fourfold cross validation. These 40 volumes are randomly sampled from our Lung CAD dataset [6] that was collected from multiple hospitals in Asia, Europe and United States. Many types of Siemens, GE, Philips and Toshiba scanners were used for the original data acquisition. All 40 volumes have slice thickness ranging from 1.00mm to 1.25mm, with 512 by 512 (voxel) axial-slice resolution. The voxel size in axial-planes ranges from 0.782mm to 1.12mm. In Fig. 9
                        , we illustrate the process for single vertebra manual annotation and building surface mesh models of the ground truth generation. From an original 3D Lung CT scan, we manually localize and crop any thoracic vertebra. This step can be replaced by the recent development of highly robust and fully automatic spine labeling system (FAST-Spine) [18,30,23]. Then the ITK Snap Tool is used to annotate or “paint” all vertebra voxels, followed by surface generation M and smoothing from the annotated vertebra mask. Optional mesh editing is used to fit the image boundary as accurately as possible. The manual annotation proximately takes 1h per vertebra by a medical student. The mesh models M (generated using the Marching Cubes algorithm [8] from the annotated binary volume masks) of the same vertebra across CT volumes (or different patients) do not have mesh correspondence, but can be used for training our supervised bone boundary detector (as in Section 2.1). We further select one M
                        0 per vertebra from an anchor volume and deform M
                        0 to align or register with M
                        
                           k
                         of the same vertebra in another volume k to obtain 
                           
                              
                                 
                                    M
                                 
                                 
                                    k
                                 
                                 
                                    ′
                                 
                              
                           
                        , via our coarse-to-fine deformation method. Therefore the mesh correspondence relationships are set up from M
                        0 to any 
                           
                              
                                 
                                    M
                                 
                                 
                                    k
                                 
                                 
                                    ′
                                 
                              
                           
                         where we also treat them as ground truth. The mean mesh model per vertebra can be further computed using the collection of 
                           
                              
                                 
                                    
                                       
                                          
                                             M
                                          
                                          
                                             0
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             M
                                          
                                          
                                             k
                                          
                                          
                                             ′
                                          
                                       
                                    
                                 
                              
                           
                        .

In implementation, we run the subregion deformation step multiple (m) times followed by patch-based deformation n times, where m and n are empirically optimized to be 3 and 4, respectively. The supervised edge detection is performed at each iteration to reflect the runtime vertebra mesh surface configuration. In Figs. 10 and 11
                        
                        , we show some segmentation examples in axial, sagittal or coronal views, for visual inspection. To quantitatively evaluate our segmentation algorithm, we use the distance of a vertex on the fitted mesh to the closest mesh point (not necessarily a vertex) of the ground truth mesh which is generated from manual segmentation. The mean point-to-surface error and the standard deviation for individual vertebra is shown in Table 1
                        . Highly reliable and accurate segmentation results have been achieved, with the overall final mean error of 0.95±0.91mm [5] reports a comparable accuracy level at 1.12±1.04mm.

For identification, we have an average success rate of 73.1% using single vertebra. This success rate also varies regarding to a specific vertebra where the rates for T5, T6, T7, T8 as ⩽60% are especially lower than others because these four vertebrae look alike. Furthermore, when exploiting the vertebra strings or chains for identification, the success rates are improved to increase with longer string lengths. With a string of 7 or 8 and more vertebrae, we achieve over 91% or >95% success rates, whereas rates are ≈73.1% for one vertebra, ≈87%, 89% for 7 or 8 vertebra strings in [5]. The success rates of individual and stringed vertebra identification (via mean mesh shapes) are comparable or better than [5] using intensity based matching, as shown in Fig. 12
                        .

A volumetric mean appearance model is used for vertebra identification in [5], which seems more comprehensive than our shape information alone. However we observe that in real cases, the variability of neighboring structures is quite large due to patients’ pose variation. The adjacent vertebrae can be so close to each other where the boundary is difficult to be clearly distinguished; or, successive vertebrae are apart from each other with a large distance. Thus, the neighboring structures are not necessarily positive factors in the identification procedure. A clean shape model without surrounding structures may be advantageous and our identification results are indeed slightly better. Lastly, our vertebra segmentation method is applicable to other orthopedic bone structures as well, e.g., manubrium, as shown in Fig. 13
                        .

We evaluate our vertebra segmentation and identification based on the initialization of the Siemens Fast Spine [18,30] software application. Fast Spine is developed using Learning Ensembles of Anatomical Patterns (LEAP) framework [29] through redundant anatomy feature detection, parsing and fusion [30,23]. An illustrative example is shown in Fig. 14
                        . Its extension from CT spine labeling to MR is shown in [26]. Fast Spine can achieve high robustness and accuracy on 3D localization of the center origins C
                        
                           T
                        (x,
                        y,
                        z), C
                        
                           B
                        (x,
                        y,
                        z) of each vertebra body top plane and bottom plane, and the three orthogonal axes ϒ
                           T
                        (x,
                        y,
                        z), ϒ
                           B
                        (x,
                        y,
                        z) representing its local vertebra anatomy coordinates [5]. This anatomical information can uniquely determine the position and pose or orientation of each individual vertebra. In practice, we use translation+uniform scaling transformation to align the vertebra mesh model onto a new detection by Fast Spine. The geometry of vertebra detection is defined as the centroid point C
                        
                           C
                        (x,
                        y,
                        z)=(C
                        
                           T
                        (x,
                        y,
                        z)+
                        C
                        
                           B
                        (x,
                        y,
                        z))/2 and mean local anatomical coordinates ϒ
                           C
                        (x,
                        y,
                        z)=(ϒ
                           T
                        (x,
                        y,
                        z)+ϒ
                           B
                        (x,
                        y,
                        z))/2. Note that Fast Spine also identifies and labels vertebra with very high accuracy ∼100%, as it always uses the full length of vertebra string information. Our vertebra identification is based on very different cues of robust shape matching, not landmark detection and counting in Fast Spine. Our method achieve about 100% identification accuracy when having strings of 9 vertebra or longer (Fig. 12). Therefore the performances of two methods are comparable and complementary for further enhanced robustness.

To increase the robustness, as discussed in Section 2.1, we add random perturbations on manually initialized vertebra pose variations in the range of [−π/10; π/10] during training the edge response classifier and corresponding vertebra edge response map. This largely assures that our coarse-to-fine deformation scheme will converge correctly even under moderate to large perturbations on initialization. Using Fast Spine software application for automatic initialization (i.e., replacing our manual initialization), we achieve consistently more accurate segmentation results (Table 2
                        ) and comparable identification performance. In summary, we take the stratified, divide-and-conquer approach by solving vertebra detection via Fast Spine and segmentation problems in this paper.

We study and compare different learning based boundary detectors through ROC analysis, specifically comparing our method with [28,10,7]. Note that 3D Haar based supervised edge detection does not work well in general since it cannot be steered efficiently in 3D space to fit edges with different orientations [21]. Thus, as in [28,10,7], the organ boundary detectors are learned by boosted 3D steerable features using probabilistic boosting tree (PBT) classifier [19]. In brief, 3D Haar features [21] are generally believed to be unsuitable for voxel-level boundary learning with varying orientations, but are more common for global scale organ localization [28,7].

In our experiments, the very simple steerable gradient feature vector+LDA classifier performs slightly worse than 3D steerable features+PBT scheme in [28,10,7], for vertebra bone edge detection task via ROC analysis,
                           3
                           It could be significantly worse for low-contrast organ boundaries (e.g., liver, heart), which is not the focus of this paper.
                        
                        
                           3
                         as shown in Fig. 15
                        . The testing and training ROC curves appear similar and only testing curves are shown for better clarity. Even the area under ROC curve (AUC) measurements are both reasonably high at 0.9781 and 0.9690 respectively, which still represents noisy edge responses in run time. On the other hand, our version of steerable feature+LDA classifier has only 15 computed features with a linear classifier, thus it has much lower model and computational complexity which may also indicate good generality to unseen data. As discussed in this paper, our deployed deformable model is sufficiently comprehensive and robustly designed to handle imperfect, noisy bone edge response maps. For segmentation purpose, the accuracy results are statistically different using the current detector or detectors in [28,10,7]. However it slightly helps improve the identification performance, especially for lower order vertebra strings, e.g., comparing 74.6% from 73.1% for one vertebra, 76.7% for strings of two vertebrae from Fig. 12.

As mentioned in Section 2.2, we perform multiple rounds of Part- and Patch-based deformable processes. The numerical relationship between segmentation accuracy (in terms of Mean point-to-surface error (mm) of all vertebrae averaged) and these iteration numbers (Pt
                        =1,2,3,4; Ph
                        =1,2,3,4,5) are given in Table 3
                        . We find that, with more iterations in both Pt and Ph, the averaged segmentation accuracy improves gradually until the respective iteration numbers reach Pt
                        =3 (Part) and Ph
                        =4 (Patch). There are no iterations in the vertebra identification task.

In this paper, a hierarchical thoracic vertebra segmentation and identification method is presented. We propose steerable gradient features for learning based edge detection with intended mis-alignment perturbations for training dataset construction, to ensure robustness and convergence. The segmentation applies a surface deformable model by adopting a new two-stage “coarse-to-fine” deformation scheme: first subregion based articulated similarity deformation and then nonrigid local patch deformation. The segmentation result is highly competitive with the point-to-surface error 0.95±0.91mm. We also use the generated mean shape model of each thoracic vertebra for identification process, where success rates of 73.1% for a single vertebra, and over 95% for 7 or more vertebra are achieved. Both our segmentation and identification performance compare favorably with the state-of-the-art [5], as surface based versus intensity based approach [5].

Our proposed hierarchical thoracic vertebra segmentation and identification method is directly extensible to other cervical or lumbar vertebrae or bone structures. For example [23], utilizes 2D Curved Multi-planar projection of CT images and Orthogonal Matching Pursuit (OMP) classification to distinguish thoracic versus lumbar Vertebrae. Therefore thoracolumbar vertebrae modeling can be solved in a divide-and-conquer manner.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An accurate and effective FMM-based approach for freehand 3D ultrasound reconstruction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We detail and unify a two-stage freehand 3D ultrasound reconstruction framework.


                        
                        
                           
                           A fast marching method (FMM) based reconstruction algorithm is proposed to interpolate the missing voxels.


                        
                        
                           
                           A direction-weighted function is designed to ensure that the structural details around the empty voxel could be well propagated from its surrounding local neighborhood.


                        
                        
                           
                           The FMM reconstruction algorithm could preserve relatively sharper edges and more texture patterns in the reconstructed image slices.


                        
                        
                           
                           The FMM reconstruction algorithm runs efficiently and requires less computation time.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

3D ultrasound imaging

Interpolation

Fast marching method

@&#ABSTRACT@&#


               
               
                  Freehand three-dimensional ultrasound imaging is a highly attractive research area because it is capable of volumetric visualization and analysis of tissues and organs. The reconstruction algorithm plays a key role to the construction of three-dimensional ultrasound volume data with higher image quality and faster reconstruction speed. However, a systematic approach to such problem is still missing. A new fast marching method (FMM) for three-dimensional ultrasound volume reconstruction using the tracked and hand-held probe is proposed in this paper. Our reconstruction approach consists of two stages: bin-filling stage and hole-filling stage. Each pixel in the B-scan images is traversed and its intensity value is assigned to its nearest voxel in the bin-filling stage. For the efficient and accurate reconstruction, we present a new hole-filling algorithm based on the fast marching method. Our algorithm advances the interpolation boundary along its normal direction and fills the area closest to known voxel points in first, which ensure that the structural details of image can be preserved. Experimental results on both ultrasonic abdominal phantom and in vivo urinary bladder of human subject and comparisons with some popular algorithms are used to demonstrate its improvement in both reconstruction accuracy and efficiency.
               
            

@&#INTRODUCTION@&#

Conventional two-dimensional (2D) ultrasound imaging has been widely used for many clinical applications, such as medical diagnosis, imaged-guided surgery. In comparison with computed tomography (CT) and magnetic resonance imaging (MRI), ultrasound imaging is non-invasive, non-ionizing, real-time, portable, and low-cost. However, 2D ultrasound fails to offer physicians a whole volume data of tissues and organs for visualization and analysis. Thus, three-dimensional (3D) ultrasound imaging system has been developed to overcome such limitations by constructing various 3D datasets of anatomies for diagnosis in recent years [1–4].

A number of approaches for constructing 3D ultrasound volume data have been reported and empirically evaluated in [5]. These approaches can be grouped into three categories: dedicated 3D probes, mechanical scanning approach, and freehand scanning approach. Although the systems using 3D probes usually equip an oscillating mechanism to sweep a predefined region of interested (ROI) and can provide 3D volume data in real-time, they are expensive and have limitation on scanning large volume organs [3]. The mechanical scanning based systems usually use the conventional 2D transducer, which is translated or rotated by a stepping motor whose position and orientation data are recorded synchronously in the scanning heads [6–8]. However, the mechanical scanning devices are usually limited by their scanning range [3]. For freehand 3D ultrasound, conventional 2D probe is integrated with a positioning sensor for labeling position and orientation of each B-scan image [1]. Freehand 3D ultrasound has received increasing attention for its low-cost, inherent flexibility nature in comparisons with the dedicated 3D probes and mechanical scanning approaches. Freehand scanning allows the user to manipulate the transducer and view the desired anatomical section freely. During freehand scanning, the 2D probe is manipulated by hand in an arbitrarily manner. A sequence of B-scan images are then captured along with its corresponding position and orientation. The collection of irregularly sampled B-scan images is then used to reconstruct 3D regular grids (i.e. volume data) by various interpolation or approximation algorithms.

Volume reconstruction is the key procedure in the freehand 3D ultrasound systems. Various types of reconstruction algorithms for compounding 3D ultrasound volume data from sequences of 2D B-scans have been reported and evaluated in [9], where these reconstruction algorithms are grouped into three categories: voxel nearest neighbor (VNN) interpolation, pixel nearest neighbor (PNN) interpolation, and distance weighted (DW) interpolation. VNN interpolation method is the most intuitive one and its implementation is straightforward. It traverses on each voxel, finds its nearest pixel by computing the shortest distance between the voxel and the sampled B-scan image planes, and inserts the nearest pixel value to the voxel [10]. Although VNN method can preserve the most original texture patterns from B-scan images (i.e. ultrasonic echo corrupted with speckle noise), it also trends to generate large reconstruction artifacts when the distance of the voxel to the B-scan image plane is large. PNN interpolation method is the most popular reconstruction algorithm, which traverses on each pixel in the B-scan images and assigns the pixel value to its nearest voxel [11]. The basic algorithm consists of two stages: bin-filling stage and hole-filling stage. In the bin-filling stage, each input pixel is traversed and its pixel value is assigned to its nearest voxel. For a voxel with multiple pixel contribution, its value is usually the average of all assigned pixel intensities. In the hole-filling stage, the algorithm traverses on each voxel and fills empty voxels by local neighborhood averaging. Although the bin-filling technique can preserve the most original texture pattern from the B-scan images, obvious artifacts can be observed on the boundaries between the highly detailed bin-filled region and the smoothed hole-filled region. Meanwhile, most hole-filling algorithms usually depend on the interpolation gaps. If the distance among sampled B-scan images is too far apart or the radius of interpolation neighborhood is too small, there are still a few holes in the reconstructed volume data. Similar to the VNN interpolation, DW interpolation proceeds voxel by voxel. But, instead of using the nearest pixel, each voxel value is assigned with the weighted average of a set of pixels from nearby B-scans [12]. The parameters to choose are the weighting function and the size and shape of the neighborhood. The simplest approach employs a spherical neighborhood around each empty voxel. All pixels in the sphere are weighted by the inverse distance to the voxel and then averaged. However, the determination of interpolation radius for the spherical neighborhood is very empirical and subjective. If radius is too small, it results in gaps. Yet if radius is too large, the reconstructed volume will be highly smoothed due to the effect of average operation. These methods are designed to reduce computation time. More elaborated methods are based on radial basis function, such as spline interpolation function [13] or statistical Bayesian model with Rayleigh distribution [14]. Even though the elaborated method has demonstrated its unique capability in image interpolation, speckle suppression, and edges preservation, it requires extremely computation time due to the need to estimate the local parameters for each piecewise radial basis function.

This paper aims to develop a fast marching method (FMM) [15] to the problem of freehand 3D ultrasound reconstruction. We implement our reconstruction framework with two-stage procedure to unify the VNN, PNN, and DW interpolation methods. For the bin-filling stage, voxels are filled with the data obtained from the irregularly sampled B-scan images. Most texture pattern can be well preserved in this stage as demonstrated in the VNN and PNN interpolation. For the hole-filling stage, we propose the FMM interpolation algorithm [16,17] to interpolate empty voxels. During the marching procedure, direction-weighted function is used to interpolate the nearby empty voxel. The marching direction ensures that the interpolation propagates gray value in the normal direction. Thus, the sharp edges in the image can be well preserved and the averaging tendency of the PNN and DW interpolation can be avoided. Although the FMM-based hole-filling technique has been published before to the image inpainting domain, the application of such a method for 3D ultrasound reconstruction is new.

The rest of the paper is organized as follows. We detail the freehand 3D ultrasound imaging system and the two-stage reconstruction procedure in Sections 2.1–2.3.1. The new FMM interpolation method is presented in Section 2.3.2. The experimental studies and related evaluation results and discussions are described in Section 3. The conclusions are made in Section 4.

The freehand 3D ultrasound imaging system consists of three modules: a conventional 2D ultrasound scanner (DC-7, Mindray Medical International Ltd., Shenzhen, China), an electromagnetic spatial sensing device (Aurora, NDI, Ontario, Canada), and a workstation with custom-designed software for data acquisition, volume reconstruction, and visualization. Fig. 1
                         illustrates the freehand 3D ultrasound imaging system. The receiver of the spatial sensing device is attached to the 4.5MHz hand-held probe of the ultrasound scanner. The spatial information (i.e. position (x, y, z) and orientation (R
                        
                           x
                        , R
                        
                           y
                        , R
                        
                           z
                        )) between the receiver and transmitter are recorded and transferred from the Aurora system control unit to the workstation through its USB port. The real-time video stream of the ultrasound scanner is digitalized by a video capture card (RGB-133, VTimage Inc., Shenzhen, China) installed in the workstation.

During data acquisition, spatial data and digitalized 2D B-scan images are simultaneously recorded and collected in our custom-designed software programmed in C++ language. Since the devices for the collection of 2D B-scans and spatial data are independent, the temporal delay between the two data streams cannot be avoided. Meanwhile, the spatial relationship between the B-scan image plane and magnetic position sensor needs to be determined. The temporal and spatial calibrations are performed using the custom-designed phantoms for the feasibility and accuracy of the freehand 3D ultrasound imaging system as described in [18,19].

The output from the video capture card is a real-time video stream and each frame is a full screen view of the ultrasound scanner. Due to the undesirable boundary (i.e. description information like patient's name and exam date) in the full screen image, it is necessary to crop the undesirable boundary using the rectangle cropping tools provided in our data acquisition software system before performing the procedure of data acquisition. The selected area defines a ROI region for our following data acquisition. The ROI represents a mask in our implementation and all other regions in the following video frames are masked out by the selected ROI. Fig. 2
                         demonstrates the selection of ROI in our software system. From Fig. 2 we can see that the collected B-scans for following volume reconstruction are the cropped images but not the full screen image frames.

Such cropped ROI has its own logical size in pixel denoted as L
                        
                           x
                        *L
                        
                           y
                        . But B-scans with only dimension information are not sufficient for image representation. In our system, each B-scan is treated as a physical plane with its origin O
                        =(0,0). And its physical size in millimeter P
                        
                           x
                        
                        *P
                        
                           y
                         can be read from the ultrasound scanner and further be set as an important parameter in our software system. Under such circumstance, the pixel spacing can be calculated and denoted by S
                        
                           x
                        
                        =
                        P
                        
                           x
                        /L
                        
                           x
                         and S
                        
                           y
                        
                        =
                        P
                        
                           y
                        /L
                        
                           y
                        , respectively. Such physical coordinate configuration for the B-scan image is illustrated in Fig. 3
                        . Now the physical position of each pixel in its local physical coordinate system can be calculated as the following formulas:
                           
                              (1)
                              
                                 
                                    
                                       X
                                       m
                                    
                                    =
                                    
                                       M
                                       
                                          model
                                       
                                    
                                    ×
                                    
                                       X
                                       p
                                    
                                 
                              
                           
                        where X
                        
                           p
                        
                        =[x
                        
                           p
                        , y
                        
                           p
                        , 0, 1]
                           T
                         is a homogeneous vector which defines the logical position of each pixel with 2D coordinate (x
                        
                           p
                        , y
                        
                           p
                        ) in the B-scan image, X
                        
                           m
                         is the physical position transformed by the model transformation M
                        model which is defined as follows:
                           
                              (2)
                              
                                 
                                    
                                       M
                                       
                                          mod
                                          e
                                          l
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         S
                                                         x
                                                      
                                                   
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   
                                                      
                                                         O
                                                         x
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      
                                                         S
                                                         y
                                                      
                                                   
                                                
                                                
                                                   0
                                                
                                                
                                                   
                                                      
                                                         O
                                                         y
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   1
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where O
                        =[O
                        
                           x
                        , O
                        
                           y
                        ] is the origin of the B-scan, S
                        
                           x
                         and S
                        
                           y
                         are the pixel spacing, as illustrated in Fig. 3. Once the ROI is selected, the procedure of data acquisition is performed. During data acquisition, the hand-held probe integrating with the positioning sensor is moved steadily with relatively slow and constant speed over the surface of the scanned subject. Spatial data and B-scan images are simultaneously collected. The block diagram for the procedure of data acquisition is demonstrated in Fig. 4
                        . The collection of sampled image data consists of the sequence of irregularly located B-scan images denoted by {I
                        
                           i
                        }. The corresponding collection of position information for each B-scan is denoted by {T
                        
                           i
                        }, which is used to register the image plane to the regularly arranged voxel grids in the following volume reconstruction procedure.

After the 2D B-scan images and its corresponding spatial information are collected, the next procedure is to reconstruct them into a 3D volume data. The general main steps of the volume reconstruction procedure are illustrated in Fig. 5
                        .

Data pre-processing of the freehand 3D ultrasound imaging system includes position filtering and B-scan image filtering [2,20]. Since the electromagnetic position sensor device is susceptible to the interference from metals and electronic devices, the variation of probe position between consecutive slices cannot be avoided. Therefore, a position filtering is necessary to be performed to suppress high-frequency artifacts. We use the smoothing method introduced by Raul et al. [20] to conduct position filtering by smoothing the measures given by the position sensor. To improve the B-scan image captured directly from video capture card, we conduct B-scan image filtering using equalization, a 2D Gaussian filter, and a median filter [2].

The second step in the reconstruction procedure is the establishment of coordinate system configuration for the reconstructed volume (i.e. its origin, dimension, and volume grid spacing). Different to those methods [2,12,20], where key frame or elaborated principal component analysis (PCA) methods are used to predefine the volume coordinate configuration, our system is no need to predefine the reconstruction volume before data acquisition. Instead, we use the bounding box technique for fast and simple determination to the volume coordinate configuration. A bounding box is only defined by its min-point (X
                        min, Y
                        min, Z
                        min) and max-point (X
                        max, Y
                        max, Z
                        max). Fig. 6(a) sketches out the pseudo code for the construction of bounding box. Once the bounding box of volume is constructed, the intrinsic parameters of the volume are determined. The origin of the volume is the min-point of the bounding box. The x-axis, y-axis, and z-axis of the volume are defined by calculating the vectors from point 0 to point 1, point 0 to point 4, and point 0 to point 3, respectively, according to the illustration in Fig. 6(b). In this study, the volume grid spacing comes from the pixel spacing illustrated in Fig. 3. Thus, the dimension of the volume is defined by dividing the grid spacing by bounding box size.

After the volume grid is constructed, the next step is the critical volume filling step for every reconstruction technique, which is the key step of the most reconstruction algorithms for freehand 3D ultrasound imaging system. And the image quality and reconstruction speed are greatly determined by the performance of the reconstruction algorithms. In this study, the basic algorithm for volume filling is generalized as two stages: bin-filling and hole-filling.

The bin-filling stage is to map the pixel in 2D B-scans into the voxel in 3D volume data based on its corresponding positional information. In the freehand 3D ultrasound system, the mapping of the coordinate system from the 2D B-scans to 3D volume is named as the forward mapping and is defined by
                              
                                 (3)
                                 
                                    
                                       u
                                       =
                                       M
                                       ×
                                       
                                          X
                                          m
                                       
                                    
                                 
                              
                           where X
                           
                              m
                            is the physical position defined in (1), M is the forward transformation matrix, and u is the resulting voxel location in the reconstructed 3D volume data.

The coordinate configuration used in our 3D ultrasound reconstruction system is depicted in Fig. 7
                           , where the forward transformation matrix M can further be decomposed into the coordinate relationship between the pixel coordinate of the 2D B-scan plane (P), electromagnetic position sensor receiver (R), transmitter (T), and the voxel coordinate of the reconstructed volume (C). The overall forward transformation can be written as:
                              
                                 (4)
                                 
                                    
                                       u
                                       =
                                       
                                          M
                                          
                                             C
                                             T
                                          
                                       
                                       
                                          M
                                          
                                             T
                                             R
                                          
                                       
                                       
                                          M
                                          
                                             R
                                             P
                                          
                                       
                                       
                                          X
                                          m
                                       
                                    
                                 
                              
                           where M
                           
                              RP
                            denotes a transformation from P to R. M
                           
                              RP
                            is unknown and therefore a calibration process must be implemented to find an accurate matrix for this transformation. For a detailed discussion for this issue, the readers can refer to Mercier et al. [21]. In this study, M
                           
                              RP
                            is determined by a simple calibration method similar to the one described in [18], and remains constant throughout the reconstruction. M
                           
                              TR
                            is a transformation from R to T, which is known as the B-scan position T
                           
                              i
                            as demonstrated in Fig. 4 and can be recorded directly and dynamically from the position sensor tracking system. M
                           
                              CT
                            is an alignment transformation between T and C that allows us to achieve the best representation of the reconstructed volume. It also remains constant throughout the reconstruction. In this study, the reconstructed volume is translated from its coordinate C to the transmitter coordinate T by subtracting the min-point of the bounding box for better visualization and manipulation. All of these measurements are 4×4 homogeneous transformation matrixes.

The above forward mapping traverses on each pixel in the B-scans and assigns the pixel value into the nearby voxel. The reconstruction algorithm based on the PNN interpolation method follows the forward mapping mechanism to finish the filling of each voxel.

Conversely, we can reverse the forward mapping direction. The reversed mapping is named as the backward mapping and is written as:
                              
                                 (5)
                                 
                                    
                                       
                                          X
                                          m
                                       
                                       =
                                       
                                          
                                             (
                                             
                                                M
                                                
                                                   C
                                                   T
                                                
                                             
                                             
                                                M
                                                
                                                   T
                                                   R
                                                
                                             
                                             
                                                M
                                                
                                                   R
                                                   P
                                                
                                             
                                             )
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       u
                                    
                                 
                              
                           The backward mapping traverses on each voxel and fills its voxel value with a set of nearby pixels in B-scans. Such backward mapping is adopted by the VNN interpolation and DW interpolation methods to fill its voxel value. The disadvantage of the backward mapping is that the interpolation error may be more serious if the distance between the voxel and the pixel is large. Conversely, the forward mapping only assign the pixel value into its nearest voxel and leave the voxel empty if the voxel is far away from the pixel. Therefore, the error rate for the bin-filled voxel can be controlled in the bin-filling stage. Moreover, we can obtain a fast reconstruction speed for the volume filling using the forward mapping mechanism.

Due to the inadequate sampling in the data acquisition process, the bin-filling process results in the occurrence of gaps in the reconstructed volume. It is necessary to determine (or mask) the hole-filling region before performing our following FMM interpolation algorithm. For this, an effective volume mask is constructed by computing the convex hull from the bin-filled volume data. For the detailed implementation of the convex hull algorithm, readers can refer to Chazelle [22]. Once the effective volume mask is constructed, the hole-filling regions can be simply determined. Each voxel is traversed and tested. If the voxel is in the convex hull but has not been filled, then this voxel needs hole-filling. The determination of the hole-filling region is illustrated in Fig. 8
                           . The dark region represents the mark for hole-filling region in Fig. 8(c) corresponding to the bin-filled slice in Fig. 8(b).

Inadequate sampling nature for the irregularly sampled B-scans leaves some gaps in the reconstructed volume after the bin-filling stage, just as addressed in Fig. 8. The goal of the hole-filling stage is to fill the gaps using available information from its surrounding known voxels.

In this study, we denote V in R
                           3 to the entire volume domain, x
                           ∈
                           V a general voxel, Ω the hole-filling domain where voxel value is missing, ∂Ω the boundary of unknown region, and u
                           0 the bin-filling domain of the volume on V/Ω.

To the whole hole-filling domain Ω, the traversing direction is linear in the conventional interpolation algorithms as is illustrated in Fig. 9(a). The drawback of this information propagation scheme is that interpolation error may be accumulated along the traversing direction and the size of the interpolation neighborhood should be large enough to contain sufficient known voxel. But large interpolation neighborhood leads to blurred effect in the reconstructed image.

To overcome the drawback of linear traversing direction, we introduce a new traversing method that starts traversing from the discrete voxel of ∂Ω, in increasing distance from ∂Ω’s initial position ∂Ω
                           0, and advance the boundary inside Ω until the whole unknown region is interpolated. Fig. 9(b) demonstrates the new traversing scheme. During the marching process, empty voxel is filled in increasing distance order from ∂Ω
                           0 along the normal direction of boundary. Such marching scheme ensures that the areas closest to known voxel points are filled in first and the structural details around its local neighborhood can be well propagated to its nearest empty voxel. Further, it is no longer need to consider the size of averaging window due to the intrinsic nature of this marching process.

The implementation for the above marching process requires that propagates the structural information from ∂Ω into Ω by advancing the known voxels of ∂Ω in order of their distance to the initial boundary ∂Ω
                           0. Thus, the distance map of the Ω voxels to the boundary ∂Ω is required to be computed for the marching process. For this, we use the FMM algorithm [15–17] to compute the distance map to a boundary ∂Ω. FMM is a numerical scheme for computing solution to the Eikonal equation of the form:
                              
                                 (6)
                                 
                                    
                                       |
                                       ∇
                                       T
                                       |
                                       =
                                       1
                                          
                                       in
                                          
                                       Ω
                                       ,
                                        
                                       with
                                          
                                       T
                                       =
                                       0
                                          
                                       on
                                          
                                       ∂
                                       Ω
                                       .
                                    
                                 
                              
                           
                        

The solution T of (6) is the distance map of the Ω voxels to the boundary ∂Ω. FMM explicitly maintains a narrow band for its surface evolution. Moreover, the gradient of T (i.e. ▿T) is exactly the normal to ∂Ω.

Following the idea of upwind approximation for the gradient, the finite difference equation of (6) is written as:
                              
                                 (7)
                                 
                                    
                                       max
                                       
                                          
                                             (
                                             
                                                D
                                                
                                                   −
                                                   x
                                                
                                             
                                             T
                                             ,
                                             
                                                D
                                                
                                                   +
                                                   x
                                                
                                             
                                             T
                                             ,
                                             0
                                             )
                                          
                                          2
                                       
                                       +
                                       max
                                       
                                          
                                             (
                                             
                                                D
                                                
                                                   −
                                                   y
                                                
                                             
                                             T
                                             ,
                                             
                                                D
                                                
                                                   +
                                                   y
                                                
                                             
                                             T
                                             ,
                                             0
                                             )
                                          
                                          2
                                       
                                       +
                                       max
                                       
                                          
                                             (
                                             
                                                D
                                                
                                                   −
                                                   z
                                                
                                             
                                             T
                                             ,
                                             
                                                D
                                                
                                                   +
                                                   z
                                                
                                             
                                             T
                                             ,
                                             0
                                             )
                                          
                                          2
                                       
                                       =
                                       1
                                    
                                 
                              
                           
                        

where D
                           −x
                           
                           T(i, j, k)=
                           T(i, j, k)−
                           T(i
                           −1, j, k) and D
                           −x
                           
                           T(i, j, k)=
                           T(i
                           +1, j, k)−
                           T(i, j, k) are the backward and forward operators in x direction. The operators D
                           −y
                           
                           T, D
                           +y
                           
                           T, D
                           −z
                           
                           T, and D
                           +z
                           
                           T in the y and x coordinate directions are similar to those defined in the x direction. Using the upwind scheme, each new T value u in the evolving boundary ∂Ω is updated by solving (7) for its eight octants and retains the smallest solution. Fig. 10
                            gives the illustrative formulas of the updating computation in each octant configuration with its volume grid representation.

The aim of hole-filling stage is to estimate the empty voxel value based on its neighborhood voxels. We consider now how to interpolate a newly discovered empty voxel as a function of the known voxels around it during the fast marching process. The general interpolation formulas can be written as:
                              
                                 (8)
                                 
                                    
                                       G
                                       (
                                       p
                                       )
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                
                                                   ω
                                                   i
                                                
                                                G
                                                (
                                                
                                                   q
                                                   i
                                                
                                                )
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                
                                                   ω
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where G(p) is the gray value of the empty voxel p situated on the evolving boundary ∂Ω of the hole-filling region, n the number of voxels situated within the predefine spherical region centered about voxel p, G(q
                           
                              i
                           ) the gray value of the known voxel at the i-th volume coordinate q
                           
                              i
                           , and ω
                           
                              i
                            the weight for the i-th voxel. The design of the weight ω
                           
                              i
                            is crucial to propagate the sharp details for the hole-filling process. For example, we can employ the local averaged weighting function, the inverse distance weighting function, and the squared distance weighting function.

To preserve the sharp structure details better, a new direction-weighted function is introduced. Fig. 10 illustrates the direction-weighted interpolation principle. The gray estimation on p should be determined by the values of the known voxels close to p, i.e. in B
                           
                              ɛ
                           (p), which denotes a spherical region with radius ɛ around p. For a known voxel q in the spherical region, i.e. q
                           ∈
                           B
                           
                              ɛ
                           (p), we use the following Euclidian distance between p(x
                           
                              p
                           , y
                           
                              p
                           , z
                           
                              p
                           ) and q(x
                           
                              q
                           , y
                           
                              q
                           , z
                           
                              q
                           ):
                              
                                 (9)
                                 
                                    
                                       d
                                       =
                                       
                                          
                                             
                                                
                                                   (
                                                   
                                                      x
                                                      p
                                                   
                                                   −
                                                   
                                                      x
                                                      q
                                                   
                                                   )
                                                
                                                2
                                             
                                             +
                                             
                                                
                                                   (
                                                   
                                                      y
                                                      p
                                                   
                                                   −
                                                   
                                                      y
                                                      q
                                                   
                                                   )
                                                
                                                2
                                             
                                             +
                                             
                                                
                                                   (
                                                   
                                                      z
                                                      p
                                                   
                                                   −
                                                   
                                                      z
                                                      q
                                                   
                                                   )
                                                
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           And the vector v from q to p is written as:
                              
                                 (10)
                                 
                                    
                                       
                                          v
                                       
                                       =
                                       (
                                       
                                          v
                                          x
                                       
                                       ,
                                       
                                          v
                                          y
                                       
                                       ,
                                       
                                          v
                                          z
                                       
                                       )
                                       =
                                       (
                                       
                                          x
                                          p
                                       
                                       −
                                       
                                          x
                                          q
                                       
                                       ,
                                       
                                          y
                                          p
                                       
                                       −
                                       
                                          y
                                          q
                                       
                                       ,
                                       
                                          z
                                          p
                                       
                                       −
                                       
                                          z
                                          q
                                       
                                       )
                                    
                                 
                              
                           Denote n the normal to ∂Ω and ▿u the gradient value of the given point q. Then the angles are defined from these vectors as:
                              
                                 (11)
                                 
                                    
                                       cos
                                       α
                                       =
                                       |
                                       |
                                       
                                          n
                                       
                                       ⋅
                                       
                                          v
                                       
                                       |
                                       |
                                       /
                                       (
                                       |
                                       |
                                       
                                          n
                                       
                                       |
                                       |
                                       ⋅
                                       |
                                       |
                                       
                                          v
                                       
                                       |
                                       |
                                       )
                                    
                                 
                              
                           
                           
                              
                                 (12)
                                 
                                    
                                       cos
                                       β
                                       =
                                       |
                                       |
                                       ∇
                                       u
                                       ⋅
                                       
                                          v
                                       
                                       |
                                       |
                                       /
                                       (
                                       |
                                       |
                                       ∇
                                       u
                                       |
                                       |
                                       ⋅
                                       |
                                       |
                                       
                                          v
                                       
                                       |
                                       |
                                       )
                                    
                                 
                              
                           Thus, we define the weighting function as follows:
                              
                                 (13)
                                 
                                    
                                       
                                          ω
                                          i
                                       
                                       =
                                       
                                          1
                                          
                                             1
                                             +
                                             
                                                d
                                                2
                                             
                                          
                                       
                                       (
                                       1
                                       +
                                       |
                                       cos
                                        
                                       α
                                       |
                                       )
                                       (
                                       1
                                       +
                                       |
                                       cos
                                        
                                       β
                                       |
                                       )
                                    
                                 
                              
                           
                        

The weighting function consists of three components: the geometric distance component 1/(1+
                           d
                           2), the normal direction component 1+|cos
                           α|, and the gradient direction component 1+|cos
                           β|. The geometric distance component decreases the contribution of the voxels geometrically farther from p. The normal direction component ensures that the contribution of the voxels close to the normal direction n
                           =∇
                           T, i.e. close to the FMM's information propagating direction, is higher than for those farther from n. And the gradient direction component ensures that the contribution of the voxels close to the gradient direction ▿u is higher than for those farther from v. As the anisotropic weights offer a non-linear assignment, the interpolated voxels are expected to be less blurred in comparison with the distance-weighted method. Meanwhile, it is expected to reduce reconstruction time because of the use of FMM solution (Fig. 11
                           ).

@&#EXPERIMENTAL RESULTS@&#

To evaluate the performance of our proposed FMM interpolation algorithm for 3D freehand ultrasound reconstruction, an ultrasound phantom and in vivo urinary bladder of human subject are scanned with our freehand reconstruction system. The proposed method is compared with the popular VNN [10], PNN [11], and DW [12] interpolation methods. The accuracy of the reconstruction results is evaluated via average interpolation error. Average running times of different methods on all scanned datasets are given for their efficiency comparison. For an image size of 500×500 pixels with a depth setting of 160mm, the system can collect ultrasound images in a frame rate up to 50 frames per second. According to the requirements of different applications, the image size and frame rate can be adjusted by the operator. A typical volume of 220×202×145voxels can be reconstructed from 138 B-scan images within 30s using the present system. All of the methods are implemented with VC 6.0, and the computer is equipped with a Xeon-3.00GHz CPU and 4 GB RAM.

The first experiment is conducted on an abdominal phantom (CIRS Model 057 [23]), which is made from proprietary materials to accurately mimic human tissues under MRI, CT, and ultrasound. The phantom mainly contains simulated lungs, liver, hepatic vessels, ribs, vertebra, kidneys, and abdominal aorta. The freehand scan of the phantom is performed with a 4.5MHz probe. Each B-scan is cropped to 500×500 pixels. A depth setting of 160mm is used giving a resolution of 0.32mm/pixel. Fig. 12
                         shows the phantom picture, its inner structure, and the reconstructed volume data with our freehand 3D ultrasound reconstruction system.

The second experiment is an in vivo examination, which is performed on a healthy human subject with a full urinary bladder for better visualization. The scan setting of the urinary bladder examination is the same as the abdominal phantom. A single sweep of the organ with a slow and steady motion resulted in a dense set of 189 nearly parallel B-scans. Figs. 13 and 14
                        
                         show the outlines of the collection of B-scans, the bin-filled volume without interpolation, and the hole-filled volume with our FMM reconstruction algorithm.

The typical reconstructed slices of the phantom and urinary bladder using the VNN, PNN, DW, and our FMM algorithm are showed in Figs. 15 and 16
                        
                        . Several small regions (marked out with blue, pink, green, and yellow rectangle, respectively) are magnified on the figures to illustrate the image content more clearly. From the qualitative comparisons, it is obvious that the reconstructed slices using our FMM algorithm can preserve relatively sharper edges and more texture patterns in comparison with the PNN and DW algorithms, as demonstrated in Figs. 15(b)–(d) and 16(b)–(d). Although the reconstructed slices using the VNN algorithm look sharp and present more texture patterns, the anatomical structure is actually distorted due to the misalignments of the pixels, as addressed by Rohling et al. [9] and can be obvious observed in Figs. 15(a) and 16(a). Such inherent problem is more serious when the image gap is relatively large.

The quantitative evaluation [9] can be used in our method. The idea of the evaluation is to measure the ability of a reconstruction algorithm in preserving true intensity values at the locations where a part of original data is removed. A good reconstruction algorithm should interpolate the removed data with values very close to the original data. Following this measure approach, the quantitative analysis to the former datasets of phantom and human subject is investigated. A percentage of pixels in B-scan images are removed randomly from the collection of B-scans, creating gaps of various sizes. The rest B-scans in the reconstruction is used in the interpolation to fill in all voxels in the reconstructed volume. The average absolute differences between the interpolated and the original data over all missing data points is calculated using the following equation:
                           
                              (14)
                              
                                 
                                    V
                                    =
                                    
                                       1
                                       N
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       N
                                    
                                    
                                       |
                                       
                                          p
                                          i
                                       
                                       −
                                       
                                          v
                                          i
                                       
                                       |
                                    
                                 
                              
                           
                        where p
                        
                           i
                         is the removed original pixel intensity, v
                        
                           i
                         is the interpolated intensity at the location of p
                        
                           i
                        , and N is the number of removed pixel. A smaller V indicates a better performance of interpolation algorithm.

The evaluation test is performed with eight different percentages of removed data, i.e. 0%, 25%, 50%, 75%, 100%, 300%, 500%, 700%. For the 0% test alone, V is calculated over all pixels of the selected B-scan. For the 25%, 50%, 75%, 100% tests, pixels are removed from the selected B-scan n. For the 300% test, the pixel from B-scan n and B-scan n
                        ±1 are totally removed. The 500% and 700% tests further remove B-scans n
                        ±2 and n
                        ±3 respectively. The measure test with the data removing ratio of 25%, 50% and 75% aims to estimate the interpolation performance of various algorithms when the gaps between B-scans are very small. The 100%, 300%, 500% and 700% experiments aim to mimic the large gaps existing in the sampling collection of B-scans.


                        Tables 1 and 2
                        
                         summarize the averaged interpolation errors and the standard deviations of the evaluation tests using the VNN, PNN, DW, and our FMM reconstruction algorithms. Fig. 17
                         shows the over trend of the average interpolation error of the different reconstruction algorithms. From Table 1, we can conclude that for the phantom our method makes a reduction by 25.35–47.27% compared with VNN method, 19.60–41.80% compared with PNN method, and 16.65–38.24% compared with DW method. And from Table 2, we can observe that the average interpolation errors of the urinary bladder are reduced by 38.03–68.78%, 24.83–50.33%, and 18.80–37.72%, respectively, as compared with VNN, PNN, and DW methods.

The efficiency is crucial for the 3D freehand ultrasound reconstruction in clinical usage. Most of algorithms [9,24] provide their accurate running time (e.g. in seconds) that conduct on different experimental platforms. When it comes to computation time, there are lots of possible implementations, improvements, and running contexts (i.e. compiler, CPU, RAM, etc.). Thus, such comparison among algorithms is usually subjective. In order to perform an objective and theoretical estimations to the computation time, the complexity function using the big O notation is introduced in our paper. Table 3
                         lists the computational time complexity of VNN, DW, PNN, and our FMM approaches. From the pseudo-code described in [24], it is noticeable that the VNN, PNN, and DW approaches traverse on each voxel to assign voxel value. Thus, the loop number is the total number of the reconstructed volume grids. Even worse, the VNN and DW approaches require finding the shortest distance to each B-scan for each voxel in each loop. Such shortest-distance-finding process in the inner loop dramatically increased the computation time because the size of sampled B-scans is usually several hundreds. On the contrary, the loop number of our FMM interpolation algorithm is O(M
                        ·log(M)·
                        R) (see [15] for more details).

The practical time costs are demonstrated in Table 4
                         for the phantom test (with a dimension of 421×425×131) and Table 5
                         for the urinary bladder test (with a dimension of 220×202×145). From Tables 4 and 5, we observe that it is highly time demanding for the VNN and conventional DW interpolation algorithm to find the shortest distance for each voxel among hundreds of sampled B-scan images. Several hours are needed to complete the reconstruction in our test. Such expensive computation time is usually unbearable in most clinical applications. After adopting our two-stage reconstruction procedure, the time complexity for the DW algorithm is dramatically reduced from O(N
                        ·
                        N
                        
                           p
                        
                        ·
                        R) to O(N
                        ·
                        R). And the computation time is reduced from 15523.3 to 151.4 for the phantom test, and from 9368.5 to 29.3 for the bladder test in our running context, respectively. Our method should obtain the fastest implementation theoretically, but the dynamic space requirement is ignored. In fact, the space requirement for VNN, PNN, and DW algorithms is static and invariable. While the space requirement for our FMM algorithm is dynamic because a sorted heap is needed to maintain the narrowband boundary. Even though, the computation time is still comparable to the PNN interpolation method. And the image quality from the FMM reconstruction result is much better than the PNN's, as demonstrated in the previous qualitative and quantitative results. More importantly, the time complexity of the PNN and DW methods is affected by the size of the spherical interpolation region. For large gaps or sparse sampled B-scans, these algorithms require a large neighborhood size, which will greatly increase the computation time. Such problem can be avoided elaborately due to the intrinsic nature of the fast marching process (i.e. always marching from the boundary along the normal direction) in our FMM algorithm.

@&#CONCLUSIONS@&#

In this paper, we develop a new FMM interpolation algorithm for 3D volume reconstruction in a freehand 3D ultrasound imaging system. To validate our reconstruction algorithm, we compare our proposed method with other popular methods, such as VNN, PNN, and DW interpolation methods. In terms of reconstruction speed, although two steps are needed in the imaging system, each step enjoys a light computational burden and the time complexity can be dramatically decreased. By the time complexity analysis, the FMM algorithm can greatly reduce the loop steps and thus improve greatly the algorithm efficiency. In terms of the quality of the reconstructed image, the FMM algorithm also performs much better than the other popular reconstruction algorithms. The proposed marching process ensures that the direction of information propagation is the normal direction of the evolving boundary. Thus, the structural details around the empty voxel can be well propagated from its local neighborhood. And experimental results demonstrated a fabulous performance in edge preservation due to the use of a new direction-weighted interpolation scheme.

@&#ACKNOWLEDGMENTS@&#

This work is supported in part by grants from National Natural Science Foundation of China (NSFC: 61103165, 81171402), the National 863 Program of China (Grant No. 2012AA02A604), the National 973 Program of China (Grant No. 2010CB732606), the Next generation communication technology Major project of National S&T (Grant No. 2013ZX03005013), the Key Research Program of the Chinese Academy of Sciences, the Guangdong Innovation Research Team Funds for Low-cost Healthcare and Image-Guided Therapy, Shenzhen Key Laboratory Project (CXB201005260056A), Shenzhen Distinguished Young Scholars Fund (JC201005260248A).

@&#REFERENCES@&#


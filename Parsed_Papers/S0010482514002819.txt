@&#MAIN-TITLE@&#Establishing the macular grading grid by means of fovea centre detection using anatomical-based and visual-based features

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The paper has been reviewed again by an experienced native English speaker.


                        
                        
                           
                           Comments of reviewer 3 have been addressed.


                        
                        
                           
                           Comments of the editor have been addressed.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Retinal diseases

Early diagnosis

Retinal imaging

Establishing macular grading grid

Fovea segmentation

@&#ABSTRACT@&#


               
               
                  This paper presents a methodology for establishing the macular grading grid in digital retinal images by means of fovea centre detection. To this effect, visual and anatomical feature-based criteria are combined with the aim of exploiting the benefits of both techniques. First, acceptable fovea centre estimation is obtained by using a priori known anatomical features with respect to the optic disc and the vascular tree. Second, a type of morphological processing is employed in an attempt to improve the obtained fovea centre estimation when the fovea is detectable in the image; otherwise, it is declared indistinguishable and the first result is retained. The methodology was tested on the MESSIDOR and DIARETDB1 databases making use of a distance criterion between the obtained and the real fovea centre. Fovea centres in the brackets between the categories Excellent and Fair (fovea centres primarily accepted as valid in the literature) made up for 98.24% and 94.38% of the cases in the MESSIDOR and DIARETDB1, respectively.
               
            

@&#INTRODUCTION@&#

Diabetic retinopathy (DR) is a disease of the retina of the eye, derived from complications caused by diabetes mellitus, which is the leading cause of blindness among working age humans in developed countries [1]. The estimated prevalence of diabetes for all age groups worldwide is forecasted to rise from 171 million in 2000 to 366 million in 2030 [2]. Although DR is incurable, laser photocoagulation can prevent major vision loss if the illness is detected in early stages [1], [3]. However, diabetic patients unfortunately do not undergo DR symptoms until visual loss develops, usually in its later stages, when treatment is less effective. In effect to ensure that treatment is received on time, diabetic patients are examined annually by their public health systems [4–6]. Within this context and due to the huge number of patients needing this periodical revision, the use of computer-aided DR diagnosis by means of digital retinal image analysis can improve the effectiveness of the early detection of the illness.

The macula plays a key role in assessing DR and other ophthalmic pathology conditions such as age-related macular degeneration or macular edema (ME). Since the macular zone is responsible for sharp central vision, the location of lesions with respect to this influences their clinical relevance. Therefore, successful identification of the macula is of vital importance for the development of systems for the automated diagnosis of DR and other diseases.

This paper proposes a new highly reliable methodology for detecting the macula centre and ultimately establishing the macular grading grid. To detect the macula centre, previous studies have usually employed the following approaches: segmentation of the macula centre, or macula centre estimation by means of its a-priori known positional features on the retinal surface. Using the first approach, the macula centre can be obtained more accurately than using the second. However, since the macula centre is not occasionally visible (discussed later) the second approach is more reliable. For these reasons, the work presented in this paper attempts to exploit and combine the benefits of both approaches. The methodology proposes the obtainment of acceptable macula centre location estimation for all cases, and the replacement of this first result with an accurate location when it is safe and possible; this is, when the macula centre is visible.

The rest of the paper is structured as follows: characterization of the macula can be found in Section 2. Section 3 reviews the state of art of methods for automated macula centre detection. Section 4 defines the material used in this study. The new methodology is described in Section 5; whereas Section 6 presents the achieved results. Finally, this paper ends with the author’s discussion and conclusion.

The macula is a round area in the central region of the retina, which measures about 3 to 4mm in diameter. As commented before, the macula provides the most distinct vision and is responsible for central vision. There is a small depression in the centre of the macula measuring around 1mm in diameter and appears as a round dark area called the fovea. The whole macula is not generally distinguishable in retinal colour images. It exhibits non-specific structure and varies greatly across individuals due to variations in the levels of pigment associated to factors such as ethnicity, age, diet and disease conditions. In spite of this, the fovea is often recognizable as a round region darker than its surrounding retinal tissue (
                     Fig. 1(a)). However, this mark may not be visible due to, for example, the presence of lesions (Fig. 1(b)). Anatomically, the fovea centre is located at 2.5 optic disc (OD) diameters on the average from the OD centre [7]. The fovea location follows the horizontal raphe of the retina, which is a line roughly passing through the OD and the fovea, or more generally separating the superior and inferior regions of the retina determined by the superior and inferior vessels of the vascular tree. This raphe is rotated a few degrees with respect to an imaginary horizontal raster passing through the OD centre. The fovea radius is between one third and one fourth of the macula radius, and the macula radius is approximately equal to one OD diameter [8] (
                     Fig. 2).

As the literature points out, two types of criteria for macula segmentation can be clearly recognized. These can be identified as visual and anatomical feature-based criteria. The former criterion includes techniques that attempt to find the macula by exploiting the visual appearance of the fovea. In contrast, the latter criterion involves techniques to obtain an estimation of the fovea centre location making use of its known anatomical features regarding its position on the retinal surface.

Sinthanayothin et al. [15] presented a methodology for fovea recognition in which it was assumed to be the darkest area of the fundus image. First, the fovea was correlated to a template of intensities. Then, the location of the maximum response was selected as the location of the fovea as if it was at approximately 2.5 times the diameter of the OD from the OD centre. Gagnon et al. [12] used a similar approach to detect the macula centre. A coarse resolution image was generated in which the darkest pixel was selected. Then, by searching its vicinity for the darkest pixel on the original image, the exact macula centre was found. However, Li and Chutatape [13] combined this approach with the use of the vascular arch to constrain the search area. As a result, a model-based approach was presented in which an active shape model was used to extract the main course of the vasculature based on the location of the OD. This course and the distance criterion of the fovea were used to decide on an area of interest. Finally, the fovea centre was acquired by applying a thresholding scheme to the region of interest. Tobin et al. [10] proposed the automatic location of the fovea using the distance criterion and the vascular arch exclusively. The method started by locating the OD and estimating the vascular arch by using a parabolic model. Based on these two anatomical landmarks, the location of the fovea was ultimately inferred. A similar method for fovea recognition was presented by Fleming et al. [11]. The method found the locations of the OD and the fovea by modelling the major retinal blood vessels. Finally, the position of the fovea was refined based on its local darkening. Then again, Niemeijer et al. [9] proposed a method to model the distribution of all retinal features. The method used an optimization technique to fit a point distribution model to the fundus image. After fitting, the points of the model indicated the location of the normal anatomy. These same authors later presented another paper on fovea detection [14]. First the OD was found and, based on its location, an area of interest for the fovea was determined. Subsequently, after blurring the image, the location was decided as being the pixel with the lowest value within the restricted area. Welfer et al. [16] proposed the fovea centre detection by making use of anatomical knowledge and mathematical morphology. Initially the centre and diameter of the OD were calculated with the aim of extracting a fovea-containing region of interest. Next, a morphological processing was applied with which a set of fovea candidates was obtained. Finally, the fovea centre was selected as being the centroid of the darkest candidate located below an imaginary horizontal line passing through the OD centre. Narasimha-Iyer et al. [17] staged a two-step approach method for locating the fovea centre. Making use of the known distance between the OD and the fovea, a region of interest was extracted and an adaptive threshold was applied to segment the target. A visual-feature based methodology was proposed by Singh et al. [18]. Essentially, a local contrast enhancement was carried out and a dark structure that was identified as the fovea was found. Sagar et al. [19] combined visual and anatomical features to decide on the location of the fovea centre. Primarily, a region of interest in the image was detected using the distance rule between the OD and the fovea. Afterwards blood vessels pixels were masked out in this subimage using morphological operations. Subsequently, the darkest pixels were identified and clustered. The centroid of the largest cluster was selected as being the fovea centre. Sopharak et al. [20] used a similar approach to find the fovea. First, the fovea position was estimated by using the OD diameter and, finally, the high contrast vessels were masked out using morphological processing. Conversely, Sekhar et al. [21] employed morphological processing and thresholding to detect the fovea. Predominantly, the OD centre and its boundary were calculated using morphological processing and the Hough transform. Thenceforth, using the spatial relationship between the OD diameter and the fovea region, a region of interest was extracted. Finally, the fovea centre was attained by applying thresholding and morphological operators. Qureshi et al. [22] proposed the combination of a set of methods for detecting the macula centre. Concretely, the result of all individual methods was calculated to create a map of partial outcomes. Then, the results were weighted according to different principles and combined to decide on the final macula centre. On the other hand, Giachetti et al. [23] made use of the Fast Radial Symmetry transform for fovea-centre detection. Concretely, the centre of symmetry of dark regions was localized applying the transform on vessel-unpainted and coarsened images. Then, they were combined with a vascular density estimator to decide the final result. Gegundez et al. [24] used a-priori known anatomical features to extract a ROI fovea-containing subimage. Subsequently, vessels removal, image smoothing and a multi-thresholding scheme were applied. The fovea centre was finally calculated on a contour map created from the application of the multi-thresholding scheme using gray-level values criteria.

The MESSIDOR and DIARETDB1 databases were used for the development and testing of the study presented herein.

The MESSIDOR database [25], kindly provided by the MESSIDOR program partners, contains 1200 RGB eye fundus colour images of the posterior pole acquired by the Hôpital Lariboisière Paris, the Faculté de Médecine St. Etienne and the LaTIM—CHU de Brest (France). Eight hundred of these images were captured with pupil dilation (one drop of Tropicamide at 10%) and 400 without dilation using a Topcon TRC NW6 non-mydriatic retinograph with a 45° FOV. The images are 1440×960, 2240×1488 or 2304×1536pixel in size, 8 bits per colour plane and are provided in TIFF format. DR and risk of ME diagnoses were provided by medical experts for each image. Five hundred and forty correspond to healthy patients while 600 images are from patients affected by DR with or without risk of ME.

Alternatively, the DIARETDB1 database [26] is composed of 89 RGB colour retinal images of which 84 show DR affection. The images were taken at the Kuopio University Hospital and selected by medical experts. Database’s partners inform that the dataset is biased, so the distribution of cases does not correspond to any “natural” cases distribution. Images were captured using a 50° field-of-view and are 1500×1152pixel in size.

@&#METHODOLOGY@&#

A new methodology to establish the macular grading grid in retinal images by means of fovea centre detection is described at this point. It combines the use of both anatomical and visual feature-based criteria for maximizing the benefits of both approaches: reliability and accuracy. Respectively, the philosophy of the methodology is, primarily, to obtain a provisional and reliable result based on acceptable estimation of the macula centre using its known positional features with respect to the OD and vascular tree. Thus, once the estimation is acquired it is then replaced with an accurate macular centre location by means of the fovea segmentation when visible; if the fovea is not detectable then the first result is not replaced. The methodology is divided into three main stages: (A) obtaining macula centre location estimation; (B) obtaining accurate fovea centre location; and (C) final decision on the macula centre location and macular grading grid establishment. The whole process for detecting the macula centre is illustrated by the flowchart in 
                     Fig. 3.

The primary approach for estimating the macula centre is determining the horizontal raphe of the retina, or in other words, the line delimiting the superior and inferior vessels. The fovea centre is assumed to reside at a fixed distance along this line at 2.5 OD diameters from the OD centre [7]. Therefore, to obtain the retinal raphe estimation, and ultimately estimate the fovea location, the segmentations of the OD and vascular tree are required. The methodologies presented in [27,
                        28] for segmenting these landmarks are used throughout this work. D
                        OD and (x
                        OD
                        , y
                        OD) will denote the diameter and the coordinates of the OD centre, respectively, and b
                        
                           t
                         (x, y) will stand for the segmentation of the vasculature structure skeletonized using a homotopic skeletonization method [29] (see 
                        Fig. 4, images (a) and (b)).

To estimate the horizontal raphe of the retina, a parabolic model with origin in (x
                        OD
                        , y
                        OD) is applied to b
                        
                           t
                         (x, y). Thus, the angle between the horizontal raster and the line of symmetry separating the superior and inferior retinal regions is identified (see illustration in Fig. 4). In essence, the model proposed by Tobin et al. [10] is used.

Once the raphe of the retina is obtained, most of works in the literature estimate the fovea centre as being at 2.5×D
                        OD pixels from (x
                        OD
                        , y
                        OD) following the raphe. Generally speaking, this measurement is valid; however, certain cases were identified in the study’s dataset of 1200 images for which this rule was unaccomplished due to their abnormally large and small OD sizes. Indeed, this is a consequence of 2.5×D
                        OD pixels being an average distance, since it is known that the OD size varies substantially from one tenth to one fifth of the retina [30]. To overcome this difficulty, a criterion for detecting and discarding D
                        OD values in the extremes of the interval of OD size values was introduced. To define this criterion, first the maximum OD diameter was measured in each gold standard of the MESSIDOR OD gold standard set available at [31]. Then, the ratios between these OD diameters and the diameters of their corresponding field-of-view masks (FOVs) were calculated. Thus, the distribution of the relative OD size measured in the whole set independently of image resolution was obtained. The distribution of these calculated ratios normalized to the interval [0, 1] is presented in 
                        Fig. 5. The figure shows that normalized ratios follow a Gaussian distribution whose average and standard deviation are 0.1382 and 0.0149, respectively (note that the obtained distribution corroborates that OD size is between one tenth and one fifth of the retina). Therefore, the criterion to discard a D
                        OD value is to consider it as extreme if its value is out of the average of the distribution plus/minus 2 times the standard deviation (i.e., out of the 95% of the distribution approximately). In this case, the discarded OD diameter value is replaced by the average value of the normal distribution.


                        
                        Fig. 6 shows some examples of the application of the described methodology for estimating the fovea centre. The first row shows results of images from patients affected by DR with no risk of ME; the images in the second row are from patients affected by DR with risk of ME; and the last row shows results of images from healthy patients. The parabolic fit to the vasculature is drawn on the images. The drawings on the images also include the position of the located OD centre, the segmented OD boundary and the placement of the estimated macula centre along the raphe.

The aim at this stage is to attempt finding an accurate fovea centre location by taking advantage of the estimation obtained in the previous step. Since the fovea is not always discernible, the main idea is to detect if there is a dark object in the image having a certain depth; and decide, according to its shape and size, whether it matches with a typical fovea. If the object exists and is validated, its centroid is set as the new accurate fovea centre location. Otherwise, the fovea is considered undetectable and the result of the present stage is null.

The processing described in this section works on an RGB subimage, which was extracted from the original retinography using the fovea location estimation acquired in the previous stage. Centred on this location, a 2×D
                        OD×2×D
                        OD fovea-containing subimage is extracted for processing.

Although it is known that the green channel of an RGB retinography is the one with highest contrast [32], upon observing the imagery it was revealed that when the fovea is visible in the colour image it is also often present in the red channel. Therefore, the processing described in this section is performed in parallel on the red and green components and the “better” of the two results is ultimately selected.

The fovea is visible as a round dark region delimited by a soft frontier when this is discernible. This region is usually darker in its centre and gradually brighter as its frontier is approached. Therefore, the fovea can be seen conceptually as a soft valley, which is recognizable if it is deep enough.


                           I will stand for the fovea-containing subimage from the red or the green field (
                           Fig. 7, images R and G). In order to filtrate from I those minima that are too shallow to be considered the fovea, the H-minima transform [33] is used. This transform suppresses all minima in the image whose depth is less than a scalar h (Fig. 7, images R-1 and G-1):
                              
                                 (1)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          F
                                       
                                    
                                    =
                                    H
                                    m
                                    i
                                    n
                                    (
                                    I
                                    ,
                                    h
                                    )
                                 
                              
                           
                        

The choice of the value for parameter h is not especially critical. Tests made with the study’s imagery indicate that the best h value is 16, although values slightly higher or lower may be also valid since they do not produced outstanding performance degradation (discussed in Section 6.2).

Once irrelevant minima in I have been suppressed, the surviving regional minima in I
                           
                              F
                            are segmented. In order to perform the segmentation, regional minima is considered to be a connected component of pixels with the same intensity value, whose external boundary pixels all have a higher value. Thus, assigning the value 255 (for 8-bit images) to those pixels in regional minima and the value 0 to the rest of pixels in I
                           
                              F
                           , a binary image I
                           
                              RM
                            of relevant regional minima is obtained (Fig. 7, images R-2 and G-2):
                              
                                 (2)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          R
                                          M
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                
                                                
                                                   
                                                      if
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ∈
                                                      R
                                                      M
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where RM is regional minima.

The following step aims at removing vessels that could have been segmented in the previous step. This is done because, when those segmented vessels and the segmented fovea belong to the same connected component, they distort its circular shape (feature that is exploited later on in this paper). This vessel removal is carried out by taking the minimum of the openings of the image with linear structuring elements with many different rotations (Fig. 7, images R-3 and G-3):
                              
                                 (3)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          V
                                          R
                                       
                                    
                                    =
                                    ∨
                                    
                                       {
                                       
                                          
                                             
                                                γ
                                             
                                             
                                                
                                                   
                                                      L
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          (
                                          
                                             
                                                I
                                             
                                             
                                                R
                                                M
                                             
                                          
                                          )
                                          |
                                          i
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          12
                                       
                                       }
                                    
                                 
                              
                           where 
                              γ
                           represents the opening operation and L
                           
                              i
                            the linear structuring element at rotation i; 12 rotations from 0° to 180° taken each 15° apart were used. Moreover, the length of L must be enough allowing for at least one rotation in which the vessels do not completely contain L (10pixel in length were proven to be enough for images of 2240×1488 in size).

After the previous processing, it is possible that I
                           
                              VR
                            does not contain any segmented connected component. This is due to two possible causes: the first being that there was no valley in image I with a depth higher or equal to h and, therefore, there was no surviving valley in I
                           
                              F
                           ; the second cause is when, although there were surviving valleys in I
                           
                              F
                           , they were not regional minima and, therefore, were not segmented. In the case that I
                           
                              VR
                            does not contain connected components, it is considered that the fovea is not discernible or, at least, not contrasted enough to be safely segmented and, finally, the rest of the processing is aborted. In contrast, I
                           
                              VR
                            can contain more than one segmented connected component if there were more than one regional minima in I
                           
                              F
                           . In this case, the largest connected component in I
                           
                              VR
                            has the highest probability of being the fovea and therefore is selected as the fovea candidate, resulting from this operation the image I
                           
                              FC
                            (Fig. 7, images R-4 and G-4):
                              
                                 (4)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          F
                                          C
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                
                                                
                                                   
                                                      if
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ∈
                                                      C
                                                      
                                                         
                                                            C
                                                         
                                                         
                                                            MAX
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where CC
                           MAX is the connected component in I
                           
                              VR
                            with the maximum number of elements.

In summary, if this point is reached, I
                           
                              FC
                            contains a connected component that is considered as a fovea candidate to be validated. This validation is performed in the following section by analysing its size and shape. With respect to this last feature, since the fovea has a circular shape, the circularity of the candidate will be thoroughly analyzed. This analysis supposes a problem if it is directly performed on the connected component in I
                           
                              FC
                           , since this component tends to have an irregular contour. To resolve this issue, a new connected component composed of the inner points of a polyhedron surrounding the candidate connected component is finally calculated. To obtain this polyhedron, first, the centroid of the component is calculated. Then, the hyperplanes supporting the component defined by the normal vectors taken each 5° apart from 0° to 360° are calculated. Finally, inner points of the calculated polyhedron are extracted (Fig. 7, images R-5 and G-5). This process is illustrated in 
                           Fig. 8.

This stage is reached if at least one fovea candidate of the possible two, one from each of the two considered channels, has been produced in the previous stage. The aim here is to analyse the size and circularity of the obtained candidates to validate or discard them. If a candidate is validated, i.e., if it satisfies the size and circularity criteria, an accurate fovea centre location is calculated; otherwise, the fovea is considered undetectable (Fig. 7, images R-6 and G-6). The following set of rules precisely describes the fovea candidate validation process:
                              
                                 •
                                 If two fovea candidates were obtained: the candidates from the red and green channel are analyzed in terms of size and circularity. There are three possible outcomes:
                                       
                                          ○
                                          The two candidates are validated: a new accurate fovea centre location is calculated as being the centroid of the candidate with the higher circularity.

Only one candidate is validated: a new accurate fovea centre location is calculated as being the centroid of the validated candidate.

No candidate is validated: the fovea is considered undetectable.

If only one fovea candidate was obtained: the candidate is analyzed in terms of size and circularity. If it is validated, a new accurate fovea centre location is calculated as being the centroid of the candidate. Otherwise, the fovea is considered undetectable.

If no candidate was obtained: the fovea is considered as being undetectable.

The size and circularity criteria used for validating candidates are described below.

The size evaluation criterion determines a candidate as valid if its maximum radius is between one half and one fourth of the OD diameter. Anatomically, the fovea radius is between one third and one fourth of the OD diameter; however, the applied processing can increase its size and that is why the radius upper limit is increased from one third to one half of the OD diameter. With respect to the circularity evaluation criterion, classic options available in the literature were tested. Nevertheless, a new approach developed for this purpose was the one providing better results (discussed in Section 6.2). This new approach is based on comparing areas of the candidate object and a representative circle of this. This circle is centred on the centroid of the candidate object; its radius is calculated as the average distance of each boundary pixel to the centroid. The quotient between non-overlapping area of both objects and the area of the candidate object is then calculated. If C denotes the described circle and FC the fovea candidate object, this operation can be mathematically described as:
                              
                                 (5)
                                 
                                    C
                                    i
                                    r
                                    c
                                    =
                                    
                                       
                                          #
                                          (
                                          C
                                          ∪
                                          F
                                          C
                                          )
                                          −
                                          #
                                          (
                                          C
                                          ∩
                                          F
                                          C
                                          )
                                       
                                       
                                          #
                                          (
                                          F
                                          C
                                          )
                                       
                                    
                                 
                              
                           where # denotes the cardinal operation, i.e., the area of an object in the image. Note that Circ is equal to 0 is FC is a circle. Once the circularity criterion is defined, a threshold to decide whether an object is circular enough has to be established. In order to achieve this, 100 object samples were subjectively classified as being circular or not and their circularity values were calculated according to Eq. (4). Then, these samples were represented in the feature space to be analyzed. A circularity value of 0.25 resulted in providing great class separability. Therefore, an object was definitely determined as circular if its circularity value according to Eq. (5) was lower or equal to 0.25, and not circular otherwise. The process described above to assess the circularity of an object is illustrated in 
                           Fig. 9.

The final stage of the methodology consists of establishing the macular grading grid making use of the obtained fovea centre location. Fovea centre location estimation and an accurate fovea centre location could also have been previously acquired. If an accurate fovea centre location was found, it is finally the selected fovea centre location. Otherwise, the final selected fovea centre location is, undoubtedly, the obtained estimation.

The grading grid widely used by ophthalmologists consists of a coordinate system centred on the fovea centre location. The coordinate system is set up based on the Early Treatment Diabetic Retinopathy Study Report Number 10 [34]. A retinal image is divided into ten subfields as presented in 
                        Fig. 10. The radii of the three fovea-centred circles from the innermost to the outermost correspond to (1/3) OD, 1 OD, and 2 OD, respectively. The 10 subfields are defined as:
                           
                              1.
                              Central subfield: area within the inner circle.

Four inner subfields (superior, nasal, inferior and temporal): areas between the inner and middle circles.

Four outer subfields (superior, nasal, inferior and temporal): areas between the middle and outer circles.

Far temporal subfield: area temporal to the outer circle and between 225° and 135° for the right eyes or between 45° and 315° for the left eyes.

The described system is used by ophthalmologists to assess illness conditions by labelling lesions in each subfield. The illness diagnosis is made by counting detected lesions, taking into account that their relevance varies according to where they are located. This relevance decreases from the most relevant location, the central subfield (threat for central vision loss), to the less relevant location, the far temporal subfield (threat for peripheral vision loss).


                        
                        Fig. 11 shows application examples of the presented methodology for establishing the macular grading grid. The first row shows results obtained from images affected by DR with no risk of ME; the second row shows results from images from patients affected by DR with risk of ME; and the last row shows results of healthy patient images.

@&#EXPERIMENTAL RESULTS@&#

The results obtained with the presented methodology are presented in this section. In the first subsection, the measures for performance evaluation are defined. The second subsection presents the results obtained with the proposed approach. Finally, the third subsection compares the obtained results with those presented in other relevant studies found in the literature.

The literature was revised to search for criteria previously used by others to determine an appropriate evaluation criterion. Most of the published papers have used the Euclidean distance between the obtained fovea centre location and the real fovea centre location as an evaluation measure [9–11,14,16]. This has been justified by the lack of border definition of the fovea region. Therefore, this distance-based criterion was selected to evaluate the presented work, although some changes were introduced. Most of the publications have established that an obtained fovea centre location is correct if the distance between it and the real fovea centre location is less than 1 times the OD radius (1R criterion). This distance is also accepted here but, in order to perform a more precise evaluation, two additional distances were considered. These distances are 0.5 times the OD radius (0.5R criterion) and 0.25 times the OD radius (0.25R criterion). Therefore, these distances are used to create a quality scale for automatically acquired fovea centre locations described as follows:
                           
                              •
                              Excellent: an obtained fovea centre location is considered “Excellent” if it satisfies the 0.25R criterion, i.e., if it is at a distance less or equal to 0.25 times the OD radius from the real fovea centre location.

Good: an obtained fovea centre location is considered “Good” if it does not satisfy the 0.25R criterion but satisfies the 0.5R criterion. This is, if it is at a distance greater than 0.25 and less or equal to 0.5 times the OD radius from the real fovea centre location.

Fair: an obtained fovea centre location is considered “Fair” if it does not satisfy the 0.5R criterion but satisfies the 1R criterion. This is, if it is at a distance greater than 0.5 and less or equal to 1 times the OD radius from the real fovea centre location.

Poor: an obtained fovea centre location is considered “Poor” if it does not satisfy any of the previous criteria. This is, if it is at a distance greater than 1 times the OD radius from the real fovea centre location.

Thus, the interval “Excellent–Fair” is equivalent to the 1R criterion and can be used for comparison with other methods. In addition, the study of all categories provides a more precise method evaluation than that provided exclusively by the 1R criterion.

It is important to point out that, since the OD size presents a substantial variation, using the OD radius measured in each image in the application of the distance criteria described above can distort results. To minimize trouble, a constant OD radius value (R) is defined as follows:
                           
                              (6)
                              
                                 R
                                 =
                                 0.15
                                 ×
                                 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             FOV
                                          
                                       
                                    
                                    2
                                 
                              
                           
                        where 0.15 is the mean ratio between OD and FOV diameters measured in Section 5.1 and 
                           
                              
                                 D
                              
                              
                                 FOV
                              
                           
                         represents the FOV diameter. By doing so, the OD radius in the described distance criteria goes from being a variable to becoming a constant.

Besides the defined quality scale for distances, the average Euclidean distance (
                           
                              
                                 E
                                 D
                              
                              
                                 ¯
                              
                           
                        ) and the “normalized localization error” (
                           
                              D
                              ¯
                           
                        ) were also calculated. The latter was calculated by dividing the distance between computed and real fovea centre positions by the mean OD radius.

The methodology was tested using the MESSIDOR and DIARETDB1 databases. With regard to the MESSIDOR dataset, the single-expert annotations of fovea centres created and published by the University of Huelva [24] for 1136 images were used for performance evaluation. The use of these annotations allows for rigorously comparing the presented algorithm to other published methods. The rest of the 64 images not included in the expert’s annotation could not be therefore mathematically evaluated. Even so, visual inspection of results found with these images was very positive and corroborated expected robustness and reliability of the methodology. In contrast, since there are no public available annotations offered by the DIARETDB1 database, fovea centres were annotated to make performance evaluation feasible in this database. Using an image editing software, an expert identified and labelled fovea centre coordinates in all images in the database.


                        
                        Table 1 shows the results obtained with the presented algorithm for the 1136 rigorously evaluated images in the MESSIDOR database and for the 89 images in DIARETDB1. Regarding the MESSIDOR database results, the table shows the average percentage of obtained fovea centres according to the quality scale defined in the previous section for each case diagnosed of DR Grade—Risk of ME (cases identified by specialists of the MESSIDOR project; DR condition from 0 to 4 and risk of ME from 0 to 2). The fovea centre location was Excellent in 83.01% of the cases; Good in 8.27% of the cases; Fair in 6.95% of the cases; and Poor in the rest of 1.76% of the cases. These figures show that the algorithm appropriately established the macular grading grid in 98.24% of images (quality range Excellent–Fair), which means success in 1116 cases out of the whole set of 1136 images. The success percentage for retinas affected by DR and for healthy retinas was 97.68% and 98.87%, respectively. In terms of images from patients affected by DR, the success rate was 96.0% for images diagnosed with risk of ME and 98.5% for those images with no risk. After consulting these results, there is no observable pattern associated to illness condition producing remarkable algorithm performance degradation. Another interesting point is that 23.65% of final fovea candidates were selected from the R channel. This issue strengthens the hypothesis of using both channels in the way proposed hereby.

With regard to results obtained from the DIARETDB1 database, figures are also presented in terms of the average percentage of obtained fovea centres in each defined quality interval; although it was not possible to detail them in terms of illness condition since this information was not available. Obtained fovea centres were distributed into the following intervals: 44.94% of the cases in the Excellent category; 25.84% of the cases were Good; 23.60% of the cases resulted to be Fair; and 5.62% of the cases were Poor. These results indicate success in establishing the macular grading grid in 94.38% of cases, i.e., the process was successful in 84 out of the 89 images. Finally, it is important to highlight that the percentage of fovea candidates finally selected from the R channel reaches 50.0% for this database.

The value of parameter h in Eq. (1) was set by finding maximum performance on the MESSIDOR database and then this value was used for DIARETDB1. It should be stressed that h is not a usual gray-level thresholding value, but it conceptually represents the minimum depth the fovea, as connected component, should have with respect to its surrounding to segment it safely. 
                        Table 2 displays results from the MESSIDOR database. As shown, the best performance was obtained for h=16, although values slightly different do not produce outstanding degradation.

Concerning the circularity criterion used in this study (
                           C
                           i
                           r
                           c
                        ), it provided better result improvement with respect to the first step of the methodology among the three tested criteria. Besides the one presented here, the following two classic criteria were also tested:
                           
                              
                                 
                                    
                                       
                                          C
                                          i
                                          r
                                          
                                             c
                                             ′
                                          
                                          =
                                          
                                             
                                                min
                                                
                                                   {
                                                   
                                                      F
                                                      
                                                         
                                                            C
                                                         
                                                         
                                                            
                                                               
                                                                  d
                                                               
                                                               
                                                                  i
                                                                  j
                                                               
                                                            
                                                         
                                                      
                                                      :
                                                      
                                                         
                                                            d
                                                         
                                                         
                                                            i
                                                            j
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            
                                                               
                                                                  (
                                                                  
                                                                     
                                                                        
                                                                           x
                                                                        
                                                                        
                                                                           i
                                                                        
                                                                     
                                                                     −
                                                                     
                                                                        
                                                                           x
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  )
                                                               
                                                               2
                                                            
                                                            +
                                                            
                                                               
                                                                  (
                                                                  
                                                                     
                                                                        
                                                                           y
                                                                        
                                                                        
                                                                           i
                                                                        
                                                                     
                                                                     −
                                                                     
                                                                        
                                                                           y
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  )
                                                               
                                                               2
                                                            
                                                         
                                                      
                                                      ,
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            y
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      )
                                                      ∧
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            y
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      )
                                                      ∈
                                                      F
                                                      C
                                                   
                                                   }
                                                
                                             
                                             
                                                max
                                                
                                                   {
                                                   
                                                      F
                                                      
                                                         
                                                            C
                                                         
                                                         
                                                            
                                                               
                                                                  d
                                                               
                                                               
                                                                  i
                                                                  j
                                                               
                                                            
                                                         
                                                      
                                                      :
                                                      
                                                         
                                                            d
                                                         
                                                         
                                                            i
                                                            j
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            
                                                               
                                                                  (
                                                                  
                                                                     
                                                                        
                                                                           x
                                                                        
                                                                        
                                                                           i
                                                                        
                                                                     
                                                                     −
                                                                     
                                                                        
                                                                           x
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  )
                                                               
                                                               2
                                                            
                                                            +
                                                            
                                                               
                                                                  (
                                                                  
                                                                     
                                                                        
                                                                           y
                                                                        
                                                                        
                                                                           i
                                                                        
                                                                     
                                                                     −
                                                                     
                                                                        
                                                                           y
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  )
                                                               
                                                               2
                                                            
                                                         
                                                      
                                                      ,
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            y
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      )
                                                      ∧
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            y
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      )
                                                      ∈
                                                      F
                                                      C
                                                   
                                                   }
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          C
                                          i
                                          r
                                          
                                             
                                                c
                                             
                                             ″
                                          
                                          =
                                          
                                             
                                                4
                                                ×
                                                π
                                                ×
                                                #
                                                (
                                                F
                                                C
                                                )
                                             
                                             
                                                #
                                                
                                                   
                                                      (
                                                      
                                                         {
                                                         
                                                            F
                                                            
                                                               
                                                                  C
                                                               
                                                               
                                                                  
                                                                     
                                                                        p
                                                                     
                                                                     
                                                                        i
                                                                        j
                                                                     
                                                                  
                                                               
                                                            
                                                            :
                                                            
                                                               
                                                                  p
                                                               
                                                               
                                                                  i
                                                                  j
                                                               
                                                            
                                                            ∈
                                                            F
                                                            C
                                                            ∧
                                                            ∃
                                                            (
                                                            
                                                               
                                                                  p
                                                               
                                                               
                                                                  k
                                                                  l
                                                               
                                                            
                                                            ∉
                                                            F
                                                            C
                                                            )
                                                            ,
                                                            k
                                                            =
                                                            i
                                                            −
                                                            1
                                                            ,
                                                            i
                                                            ,
                                                            i
                                                            +
                                                            1
                                                            ;
                                                            l
                                                            =
                                                            j
                                                            −
                                                            1
                                                            ,
                                                            j
                                                            ,
                                                            j
                                                            +
                                                            1
                                                         
                                                         }
                                                      
                                                      )
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Summarizing, 
                           C
                           i
                           r
                           
                              c
                              ′
                           
                         is the quotient between the minimum and the maximum axis length of the fovea candidate; while 
                           C
                           i
                           r
                           
                              
                                 c
                              
                              ″
                           
                         is the quotient between 4π times its area and its square perimeter. Note that, contrary to 
                           C
                           i
                           r
                           c
                        , higher values of 
                           C
                           i
                           r
                           
                              c
                              ′
                           
                         and 
                           C
                           i
                           r
                           
                              
                                 c
                              
                              ″
                           
                         indicate higher circularity of the object. 
                        Table 3 shows a performance comparison of the methodology using the three tested criteria.

The presented algorithm was experimentally implemented in Matlab with a computational complexity of O(n
                        3). Tests for computational efficiency of this implementation were performed using a PC equipped with an Intel Core2Duo CPU at 2.13GHz and 2GB of RAM capacity. For 1136 executions of the algorithm, the measured average computational time was 10.88s with a standard deviation of 0.19s. It should be stressed that a future enhanced implementation using a more proper programming language such as C++ will drastically decrease these figures as well as surely the computational complexity as well. Special attention is given to the fact that there are two independent computational lines after obtaining the ROI in Fig. 3, which could be easily parallelized using threads.

Results of the presented methodology are compared with those of other relevant published papers in this section from two differing points of view. On the one hand, results obtained from the MESSIDOR dataset are compared with the following methods: Fleming et al. [11]; those of Niemeijer et al. [9,14]; Tobin et al. [10]; Giachetti et al.[23]; and Gegúndez-Arias et al. [24]. However, the studies presented in [9–11,
                        14] were tested on local and not public databases. This means that it is impossible to perform a comparison under identical conditions. Despite this, the image description provided by the corresponding authors (images from screening programs of DR) indicates that the nature of the used datasets for testing is similar to the nature of the images in the MESSIDOR database. Therefore, this author considers that information provided with the comparison may be of interest to get a good idea about the behaviour and competitiveness of the presented paper. In contrast, the studies in [23,
                        24] were tested on the MESSIDOR database using the same gold standard set used in the present study, which allows for performing rigorous comparison.

Conversely, results obtained with the DIARETDB1 database are compared with the following set of studies: Welfer et al. [16]; Sinthanayothin et al. [15]; Narasimha-Iyer et al. [17]; Singh et al. [18]; Sagar et al. [19]; Sopharak et al. [20]; and Sekhar et al. [21]. Although in most of cases these studies were not originally tested on DIARETDB1, Welfer et al. [16] implemented them and published their results on this database. Finally, results obtained with the first stage of the proposed methodology are also compared. This comparison provides a precise idea of improvement achieved with its integration in the complete methodology.

Fleming et al. [11], Giachetti et al.[23] and Gegúndez-Arias et al. [24] evaluated their results according to the 1R criterion (Gegúndez-Arias et al. [24] also used the 0.25R and 0.5R criteria). Niemeijer et al. [9,14] used in their studies a distance in the number of pixels to decide whether the obtained fovea centre was correct. Despite this, the distance used by such authors is approximately equal to the distance established by the 1R criterion, according to the image resolution and FOV size used. In opposition, Tobin et al. [10] considered an obtained fovea centre as valid if it was located at a distance less or equal to 2 times the OD radius from the true fovea centre (2R criterion). Therefore, the study described here was also evaluated using the 2R criterion with the aim of comparing both approaches. On the other hand, Welfer et al. [16] considered as valid those computed fovea centres within a distance of 34pixel from the hand-labelled fovea centres (slightly lower than the corresponding 1R criterion), for images of 640×480pixel in size (they resized images in DIARETDB1). In order to compare under the same conditions, this distance was also used but scaled to the original image resolution of 1500×1152, since images were not resized in this work; the corresponding scaled value is that of 82pixel. The same occurs with the algorithms developed by Sinthanayothin et al. [15], Narasimha-Iyer et al. [17], Singh et al. [18], Sagar et al. [19], Sopharak et al. [20] and Sekhar et al. [21], since their results from DIARETDB1 were calculated and published by Welfer et al. [16].


                        
                        Tables 4 and 5
                         show the results of the above mentioned methodologies compared with the one used in the present paper (referred to as “Morphological Method“) and its first stage solely (referred to as “First stage of this study“) on the MESSIDOR and similar private databases, and the DIARETDB1 database, respectively. As observed, results obtained with the presented methodology from both datasets can at least be measured up to the best analyzed studies.

@&#DISCUSSION AND CONCLUSION@&#

Two types of criteria have been historically employed for segmenting the fovea: anatomical and visual feature-based criteria. The methodology presented in this paper takes advantage of both approaches. It is divided into three main stages: (A) obtaining fovea centre estimation by using anatomical feature-based criteria; (B) obtaining an accurate fovea centre location if this is detectable by applying visual feature-based criteria; and (C) final fovea centre decision and macular grading grid establishing.

The main contribution of the present study is the processing applied in stage (B). Published methodologies based on visual features of the fovea usually perform processing in which the fovea is assumed to always be present. In contrast, the morphological processing applied in this paper discards the accurate location of the fovea if no valid candidates are found. The fovea centre estimation obtained in stage (A) is used to identify the macular zone in this case. This approach makes the process safer and more stable. In addition, the study presented in Section 5.1 shows that some errors estimating the fovea may be prevented by previously checking the size of the segmented OD. As was pointed out, for OD sizes in the extremes of the distribution, the standard distance between the OD centre and the fovea centre given by the expression 2.5×D
                     OD (D
                     OD is the OD diameter) pixels may be inaccurate. This situation was solved by replacing the D
                     OD value with the average value of the normal distribution of OD diameters.

To test the proposed methodology, a quality scale based on the distance of the obtained fovea centre to the true fovea centre was defined. This scale contains four categories: Excellent; Good; Fair; and Poor. Table 1 summarizes the obtained results according to the preconceived quality scale. The methodology obtained valid fovea centres, those in the range between Excellent and Fair, in 98.24% of the 1136 rigorously evaluated images in the MESSIDOR database; and 94.38% of the 89 images in the DIARETDB1 dataset. Furthermore, the methodology acquired fovea centres in the range between Excellent and Good in 91.29% and 70.79% of the cases in the MESSIDOR and DIARETDB1 dataset, respectively. The reason why this outstanding algorithm’s behaviour is worse in the case of the DIARETDB1 database may be understood by studying the nature of the images. The dataset was collected to include lesions mainly near the macula and great image variability in terms of noise, illumination and other technical aspects. These issues seem to moderately affect the finer accuracy. Conversely, Tables 4 and 5 show the competitiveness of the presented results when comparing them with other relevant published methods. Analysing Table 4, only the study carried out by Giachetti et al. [23] obtains slightly higher outcome than the one presented here (less than 1%). However, it should be taken into account that the algorithm was only tested on the MESSIDOR database, which includes just a few cases of images with strong maculopathy or other aspects that eliminates macula’s visibility. No wonder, the authors claim in their paper: “failures occur when the fovea is actually not visible in the images. In this case additional constraints related to the relative position of OD and fovea candidates could, for example, fix the results.“This indicates that the behaviour of their algorithm on the DIARETDB1 could not be adequate and that the addition of constraints like the ones found in the present study is on the correct path.

Regarding limitations of the presented work, it should be stressed that there is not performance degradation related to the position of the fovea in the image. To this respect, the only requirement is its presence within the FOV of the image under processing. In the contrary case, the algorithm would surely give an inaccurate estimation of its location.

The algorithm computational efficiency should also be mentioned since it is also related to testing. It has a complexity of O(n
                     3) and tests made on a mid-range PC gave a mean computational time of 10.88s with a standard deviation of 0.19s. Although these figures are already acceptable, since the method implementation is experimental, they can easily be improved.

In the context of computer-aided detection of DR and other retinal pathologies, robust macular zone identification by establishing grading grid is of vital importance since relevance of lesions is related to their location regarding the macula. In this respect, since the present methodology is fully automatic, it may be useful in a great amount of environments. No wonder, the final objective is to put professional screening software in the hands of the scientific community as the one included in this paper. For instance, it could help decrease workload in the context of preventive screening programs or in the context of illness condition assessment by specialists. Then again, since this methodology segments the fovea only when visible and, in the other case provides an estimation of its location, it could also be helpful in surgical environments for treatment of, for instance, maculopathy. In essence, the software could provide the ophthalmologists with the macular grading grid for laser application guidance. Furthermore, the software could even allow for the grid interactive movement in case the specialist would like to modify its position. The reliability, robustness and efficiency obtained with the methodology presented in this paper evidences that its integration in such kinds of situations may be successful.

There is not any conflict of interest.

@&#SUMMARY@&#

The paper presents a methodology for establishing the macular grading grid in digital retinal images by means of fovea centre detection. To segment the fovea, visual and anatomical feature-based criteria have been employed in the literature. Using the first approach, the macula centre can be obtained more accurately than using the second. However, since the macula centre is not occasionally visible, the second approach is more reliable. For these reasons, the methodology proposed in this paper attempts to exploit and combine the benefits of both approaches.

The proposed methodology is divided into two main stages: first, acceptable fovea centre estimation is obtained by using a priori-known anatomical features with respect to the optic disc and the vascular tree; second, a type of morphological processing is used in an attempt to improve the obtained fovea centre estimation when the fovea is detectable in the image; otherwise it is declared indistinguishable and the first result is retained.

The methodology was tested on the MESSIDOR and DIARETDB1 database. On the one hand, the MESSIDOR database is a set of 1200 images (64 of them were not valuable) collected in three different hospitals in France within the frame of periodical revisions for the early detection of diabetic retinopathy. In contrast, the DIARETDB1 is composed of 89 images taken at the Kuopio university hospital. Images were selected by medical experts to include lesions mainly near the macula and great image variability in terms of noise, illumination and other technical aspects. Results from both databases were evaluated using a widely used distance criterion between the obtained and the real fovea centre. Fovea centres in the range between Excellent–Fair (fovea centres primarily accepted as valid in the literature) made up 98.24% and 94.38% of all cases in the MESSIDOR and DIARETDB1, respectively. These results show evidence that the integration of the methodology presented in this paper for systems of automated or computer-aided diagnosis of macular diseases may be successful.

@&#ACKNOWLEDGMENT@&#

The author would like to thank the MESSIDOR and DIARETDB1 program partners for facilitating their database.

@&#REFERENCES@&#


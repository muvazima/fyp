@&#MAIN-TITLE@&#Effective composite image detection method based on feature inconsistency of image components

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Feature inconsistency of image components is used to obtain tampering detection.


                        
                        
                           
                           The proposed method can obtain accurate tampered regions in composite images.


                        
                        
                           
                           Image-component-based composite image detection is first proposed.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Composite image

Tampering detection

Image component

Feature inconsistency

Sensor pattern noise

@&#ABSTRACT@&#


               
               
                  This paper proposes an effective composite image detection method that uses the feature inconsistency of image components of the composite image to detect tampered regions. The composite image is first divided into image components. Next, the variance of the noise remaining after de-noising in each image component is calculated and used as a feature. Finally, tampered regions are detected using this feature based on a tampering detection rule. Experimental results show that the proposed method has good composite image detection performance.
               
            

@&#INTRODUCTION@&#

Digital images have become ubiquitous. With the availability of powerful image processing technology and digital image editing tools, digital images have become easier to duplicate and manipulate without degrading quality or leaving obvious visual clues. Image forgery has become a serious problem, and thus the authentication of images has become increasingly important. Therefore, accurate and robust detection of image forgery is desirable.

Image forensic methods can be roughly divided into those based on active and passive technologies [1–3]. The active forensic approach is a non-blind approach that extracts prior inserted information from a digital image (e.g., digital watermarks or signatures) to determine authenticity. The image is recognized as having been tampered when the embedded information has changed. Image watermarking [4–6] is a popular active technique among non-blind approaches. Image watermarking embeds a hidden watermark at recording time that is extracted later to verify image authenticity. Hu et al. [7] proposed a novel image forgery detection method that uses the difference of singular values based on discrete wavelet transform (DWT)-discrete cosine transform (DCT)-singular value decomposition (SVD)-based image watermarking [8] and alpha mattes [9,10] to determine the tampered foreground or background image. This method works well for images manipulated using image matting.

The passive forensic approach is a blind approach with no supplementary information used. That is, blind approaches determine the feature consistency of an image without the use of embedded information. Region duplication detection, a common type of image forgery detection, includes copy–move forgery detection [11–14] and composite image detection [15–21]. Compared to active forensic approaches, passive ones can authenticate an image without a priori knowledge. Therefore, passive forensic approaches are more practical.

In passive forensic approaches, copy–move forgery detection and composite image detection are commonly considered. Copy–move forgery detection usually uses a block-based scheme to detect image forgery. An image is first divided into fixed-size overlapping blocks and then features of the blocks are extracted and represented as feature vectors. Next, the feature vectors are sorted in lexicographical order to make similar blocks close to each other. Finally, duplicate blocks are filtered out using a similarity measure. Chang et al. [22] proposed a forgery detection algorithm that uses a multi-region relation for copy–move forgery detection. It works well for images manipulated using image inpainting.

Composite image detection has no reference regions for checking duplicate regions. In general, a composite image is created by taking a region from a source image and pasting it into a target image after performing geometric operations (such as scaling, rotation, and morphing). The composite image contains tampered and untampered regions. Feature inconsistency is used for the tampering detection, such as feature inconsistency based on noise [15,16,29], JPEG compression [17–20], and shadows [21]. Composite image detection is more difficult than copy–move forgery detection.

Mahdian and Saic [15] proposed a composite image detection method based on local noise level inconsistencies. One-level DWT is first applied to the composite image to obtain the HH sub-band image. Next, the obtained HH sub-band image is divided into fixed-size non-overlapping blocks. The noise standard deviation of each block is calculated using the widely used median-based method. The homogeneity condition is used to segment the image into several homogeneous sub-regions based on the obtained noise standard deviation of each block. Finally, the region merging algorithm is applied to neighboring blocks based on block similarity with a given threshold to detect tampered regions. Compared to the method proposed by Popescu [16], the method in [15] uses a more precise estimation of noise level. The main drawback of Popescu's method is that in order to estimate the local noise variance of a single-channel image, the local kurtosis values of the noiseless image need to be known. The estimation of kurtosis introduces numerical errors and decreases performance. However, in the method in [15], additive white Gaussian noise is necessary, and the accuracy of tampering detection is influenced by the given threshold and additive noise level. Furthermore, based on the authors' suggestion [15], this method is useful as a supplement to other forgery detection methods rather than a standalone forgery detector.

Fan et al. [29] proposed a new tool for manipulation detection, which correlates statistical image noise features with selected features from three EXchangeable Image File format (EXIF) header features. Each EXIF feature is formulated as a weighted sum of selected statistical image noise features based on sequential floating forward selection, the weights are then solved as a least squares solution for modeling the correlation between the intact image and the corresponding EXIF header. Image manipulations like brightness and contrast adjustment can affect these noise features and lead to enlarged numerical difference between each actual and its estimated EXIF feature from the noise features. However, EXIF-noise-based tampering detection method is only useful on EXIF images.

Zuo et al. [17] proposed a composite image detection method based on the traces of re-sampling and JPEG compression. An image is first divided into overlapping blocks. Next, a block measure factor is defined and evaluated. The block measure factor contains both the re-sampling characteristics and JPEG compression characteristics of each block. Finally, the block measure factor is applied to detect tampered regions. Unlike other JPEG image forgery detection methods [18–20], when the quality factor of double compression is smaller than the primary quality factor, the method in [17] can still work well. However, based on the authors' suggestion [17], this method becomes ineffective when the composite image is composed of two uncompressed images, and the tampered regions are not subjected to geometric operations.

Liu et al. [21] proposed a composite image detection method based on the photometric consistency of illumination in shadows. The color characteristics of shadows measured in terms of the shadow matte value are first formulated. Next, the shadow boundaries and the penumbra shadow region of the image are extracted. Then, the shadow matte values for each of the sampled shadows in an image are estimated and tested. Finally, the feature consistency is used to detect image tampering. Because this method assumes a single distant light source, its application is limited. Furthermore, this method fails when the composite shadows are consistent with the real target shadows. Moreover, based on authors' suggestion [21], although this method can identify whether an image is tampered, it cannot determine which part of the composite image has been doctored.

Compared to above mentioned methods based on feature inconsistency with noise, JPEG compression, or shadows, sensor pattern noise (SPN) is the result of the imperfection of digital image acquisition equipment and it is relatively stable feature. SPN can be considered as a sort of camera fingerprint and used as such to accomplish forgery detection or image identification tasks. SPN can be estimated using the method developed by Lukáš et al. [23]. SPN is the difference between the original image and its de-noised version. Therefore, SPN-based feature inconsistency is used to obtain tampering detection in this paper.

The noise calculation is an important issue in SPN-based tampering detection methods. It is crucial for the detection performance. However, in the presented SPN-based tampering detection methods, the non-overlapping blocks are usually used as image segmentation, but they would obtain tampered regions with jagged shapes. To obtain more accurate tampered regions, a suitable form of image segmentation is necessary to obtain more relational regions for detecting fine contours of tampered regions. Image component is a kind of image segmentation. Therefore, image-component-based tampering detection method is proposed in this paper to obtain fine contours of tampered regions. It is worth mentioning that image-component-based composite image detection is first proposed.

The present study proposes an effective composite image detection method based on the feature inconsistency of image components. In the proposed method, an image is first divided into image components using the adaptive component detection method [10]. Next, the variance of the noise remaining after de-noising in each image component is evaluated. The variance of the remaining noise is a kind of SPN. Finally, tampered regions are detected using the variance of the remaining noise of image components based on a tampering detection rule. The proposed method can obtain fine contours of tampered regions, unlike methods based on non-overlapping blocks, which obtain rough contours. Experimental results show that the proposed method performs well in terms of composite image detection.

The rest of this paper is organized as follows. The proposed image-component-based composite image detection method is described in Section 2. Section 3 presents experimental results and their evaluations. Finally, conclusions are given in Section 4.

Because composite image detection has no reference regions for checking duplicate regions, feature inconsistency is usually used to detect tampered regions. Sensor pattern noise (SPN) is the result of the imperfection of digital image acquisition equipment and is relatively stable. Therefore, the variance of the remaining noise is used as the feature to obtain the tampering detection, where the variance of the remaining noise is a kind of SPN. Image-component-based tampering detection is proposed to obtain fine contours of tampered regions. Fig. 1
                      shows a block diagram of the proposed composite image detection method.

In the proposed method, the image components are obtained using the adaptive component detection method [10]. The mean shift algorithm [24] and spectral segmentation with the k-means algorithm based on the eigenvectors of the matting Laplacian matrix [25] are used for adaptive component detection.

The mean shift algorithm is briefly described below. A special class of radially symmetric kernels satisfying 
                        K
                        (
                        x
                        )
                        =
                        
                           
                              c
                           
                           
                              k
                              ,
                              d
                           
                        
                        k
                        (
                        
                           
                              ‖
                              x
                              ‖
                           
                           
                              2
                           
                        
                        )
                      is used, where 
                        
                           
                              c
                           
                           
                              k
                              ,
                              d
                           
                        
                        >
                        0
                      is chosen such that:
                        
                           (1)
                           
                              
                                 ∫
                                 0
                                 ∞
                              
                              K
                              (
                              x
                              )
                              d
                              x
                              =
                              
                                 ∫
                                 0
                                 ∞
                              
                              
                                 
                                    c
                                 
                                 
                                    k
                                    ,
                                    d
                                 
                              
                              k
                              
                                 (
                                 
                                    
                                       ‖
                                       x
                                       ‖
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                              d
                              x
                              =
                              1
                           
                        
                     
                  


                     
                        k
                        (
                        x
                        )
                     , the profile of the kernel, is a monotonically decreasing function defined only for 
                        x
                        ≥
                        0
                     . Given the function 
                        g
                        (
                        x
                        )
                        =
                        −
                        
                           
                              k
                           
                           
                              ′
                           
                        
                        (
                        x
                        )
                      for a profile, the kernel 
                        G
                        (
                        x
                        )
                      is defined as 
                        G
                        (
                        x
                        )
                        =
                        
                           
                              c
                           
                           
                              k
                              ,
                              d
                           
                        
                        g
                        (
                        
                           
                              ‖
                              x
                              ‖
                           
                           
                              2
                           
                        
                        )
                     .

For n data points 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , 
                        i
                        =
                        1
                        ,
                        …
                        ,
                        n
                     , in the d-dimensional space 
                        
                           
                              R
                           
                           
                              d
                           
                        
                     , the mean shift is defined as in (2), where x is the center of the kernel (window) and h is a bandwidth parameter.
                        
                           (2)
                           
                              
                                 
                                    m
                                 
                                 
                                    h
                                    ,
                                    G
                                    (
                                    x
                                    )
                                 
                              
                              =
                              
                                 (
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 g
                                 
                                    (
                                    
                                       
                                          ‖
                                          
                                             
                                                x
                                                −
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             h
                                          
                                          ‖
                                       
                                       
                                          2
                                       
                                    
                                    )
                                 
                                 /
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    n
                                 
                                 g
                                 
                                    (
                                    
                                       
                                          ‖
                                          
                                             
                                                x
                                                −
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             h
                                          
                                          ‖
                                       
                                       
                                          2
                                       
                                    
                                    )
                                 
                                 )
                              
                              −
                              x
                           
                        
                     
                  

The mean shift method is guaranteed to converge to a nearby point where the estimate has the zero gradient. The center position of kernel G can be updated iteratively using (3), where 
                        
                           
                              y
                           
                           
                              1
                           
                        
                      is the center of the initial position of the kernel.
                        
                           (3)
                           
                              
                                 
                                    y
                                 
                                 
                                    j
                                    +
                                    1
                                 
                              
                              =
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 n
                              
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              g
                              
                                 (
                                 
                                    
                                       ‖
                                       
                                          
                                             
                                                
                                                   y
                                                
                                                
                                                   j
                                                
                                             
                                             −
                                             
                                                
                                                   x
                                                
                                                
                                                   i
                                                
                                             
                                          
                                          h
                                       
                                       ‖
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                              /
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 n
                              
                              g
                              
                                 (
                                 
                                    
                                       ‖
                                       
                                          
                                             
                                                
                                                   y
                                                
                                                
                                                   j
                                                
                                             
                                             −
                                             
                                                
                                                   x
                                                
                                                
                                                   i
                                                
                                             
                                          
                                          h
                                       
                                       ‖
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                              ,
                              
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                           
                        
                     
                  

The number of clusters in the image is used to obtain the image components by using spectral segmentation with the k-means algorithm based on the eigenvectors of the matting Laplacian matrix. The matting Laplacian matrix is defined as a sum of matrices 
                        L
                        =
                        
                           
                              ∑
                           
                           
                              q
                           
                        
                        
                           
                              A
                           
                           
                              q
                           
                        
                     , each of which contains the affinities among pixels inside a local window 
                        
                           
                              w
                           
                           
                              q
                           
                        
                     , where 
                        
                           
                              δ
                           
                           
                              i
                              j
                           
                        
                      is the Kronecker delta; 
                        
                           
                              μ
                           
                           
                              q
                           
                        
                      is a 
                        3
                        ×
                        1
                      mean color vector in the window 
                        
                           
                              w
                           
                           
                              q
                           
                        
                      around pixel q; 
                        
                           
                              ∑
                           
                           
                              q
                           
                        
                      is a 
                        3
                        ×
                        3
                      covariance matrix in a given window; 
                        |
                        
                           
                              w
                           
                           
                              q
                           
                        
                        |
                      is the number of pixels in a given window; 
                        
                           
                              I
                           
                           
                              3
                              ×
                              3
                           
                        
                      is a 
                        3
                        ×
                        3
                      identity matrix; 
                        
                           
                              I
                           
                           
                              i
                           
                        
                      and 
                        
                           
                              I
                           
                           
                              j
                           
                        
                      are 
                        3
                        ×
                        1
                      color vectors in the window 
                        
                           
                              w
                           
                           
                              q
                           
                        
                     ; and ε is a small positive constant.
                        
                           (4)
                           
                              
                                 
                                    A
                                 
                                 
                                    q
                                 
                              
                              (
                              i
                              ,
                              j
                              )
                              =
                              
                                 {
                                 
                                    
                                       
                                          
                                             
                                                δ
                                             
                                             
                                                i
                                                j
                                             
                                          
                                          −
                                          
                                             1
                                             
                                                |
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      q
                                                   
                                                
                                                |
                                             
                                          
                                          (
                                          1
                                          +
                                          
                                             
                                                (
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      i
                                                   
                                                
                                                −
                                                
                                                   
                                                      μ
                                                   
                                                   
                                                      q
                                                   
                                                
                                                )
                                             
                                             
                                                T
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      q
                                                   
                                                
                                                +
                                                
                                                   ε
                                                   
                                                      |
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            q
                                                         
                                                      
                                                      |
                                                   
                                                
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      3
                                                      ×
                                                      3
                                                   
                                                
                                                )
                                             
                                             
                                                −
                                                1
                                             
                                          
                                          (
                                          
                                             
                                                I
                                             
                                             
                                                j
                                             
                                          
                                          −
                                          
                                             
                                                μ
                                             
                                             
                                                q
                                             
                                          
                                          )
                                          )
                                          ,
                                       
                                       
                                          (
                                          i
                                          ,
                                          j
                                          )
                                          ∈
                                          
                                             
                                                w
                                             
                                             
                                                q
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                          0
                                          ,
                                       
                                       
                                          otherwise
                                       
                                    
                                 
                              
                           
                        
                     
                  

The adaptive component detection method has an accuracy of about 94% under low-, medium-, and high-complexity image segmentation [10], where accurate component detection is defined as each detected component being only a part of the foreground or background. Fig. 2
                      shows the image components obtained using adaptive component detection. As can be seen, the eagle was accurately segmented.

The algorithm of the proposed image-component-based composite image detection is given below.
                        
                           Step 1:
                           Transform image I from the RGB color space into the HSV color space to obtain image.

Apply adaptive component detection to image 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                    
                                 
                               to obtain image components 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                    
                                    
                                       k
                                    
                                 
                              , 
                                 k
                                 ∈
                                 [
                                 1
                                 ,
                                 n
                                 ]
                              .

Apply down-sampling to 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                    
                                    
                                       k
                                    
                                 
                               to obtain 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                       ,
                                       
                                          down
                                       
                                    
                                    
                                       k
                                    
                                 
                              .

Apply the one-level DWT to image 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                    
                                 
                               to obtain sub-band image 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                       ,
                                       
                                          HH
                                       
                                    
                                 
                              .

Apply the lower–upper–middle (LUM) filter [26] to image 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                       ,
                                       
                                          HH
                                       
                                    
                                 
                               to obtain the de-noised image 
                                 
                                    
                                       (
                                       
                                          
                                             I
                                          
                                          
                                             V
                                             ,
                                             
                                                HH
                                             
                                          
                                       
                                       )
                                    
                                    
                                       denoise
                                    
                                 
                              .

Calculate the remaining noise using (5).
                                 
                                    (5)
                                    
                                       
                                          
                                             (
                                             
                                                
                                                   I
                                                
                                                
                                                   V
                                                   ,
                                                   
                                                      HH
                                                   
                                                
                                             
                                             )
                                          
                                          
                                             R
                                          
                                       
                                       =
                                       
                                          
                                             I
                                          
                                          
                                             V
                                             ,
                                             
                                                HH
                                             
                                          
                                       
                                       −
                                       
                                          
                                             (
                                             
                                                
                                                   I
                                                
                                                
                                                   V
                                                   ,
                                                   
                                                      HH
                                                   
                                                
                                             
                                             )
                                          
                                          
                                             denoise
                                          
                                       
                                    
                                 
                              
                           

Calculate the variance of the remaining noise in each image component 
                                 
                                    
                                       Var
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                               based on 
                                 
                                    
                                       I
                                    
                                    
                                       V
                                       ,
                                       
                                          down
                                       
                                    
                                    
                                       k
                                    
                                 
                               and 
                                 
                                    
                                       (
                                       
                                          
                                             I
                                          
                                          
                                             V
                                             ,
                                             
                                                HH
                                             
                                          
                                       
                                       )
                                    
                                    
                                       R
                                    
                                 
                              .

Calculate the measure quality (MQ) using (6), where 
                                 max
                                 ⁡
                                 (
                                 
                                    
                                       Var
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                                 )
                               is the maximum one within all 
                                 
                                    
                                       Var
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                              . If 
                                 
                                    MQ
                                 
                                 ≥
                                 
                                    
                                       Th
                                    
                                    
                                       Q
                                    
                                 
                              , then the tested image is a tampered image and go to Step 9; otherwise it is not a tampered image and go to Step 13.
                                 
                                    (6)
                                    
                                       
                                          MQ
                                       
                                       =
                                       max
                                       ⁡
                                       
                                          (
                                          
                                             
                                                Var
                                             
                                             
                                                
                                                   re
                                                
                                                _
                                                
                                                   noise
                                                
                                             
                                             
                                                k
                                             
                                          
                                          )
                                       
                                       /
                                       
                                          1
                                          n
                                       
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          n
                                       
                                       
                                          
                                             Var
                                          
                                          
                                             
                                                re
                                             
                                             _
                                             
                                                noise
                                             
                                          
                                          
                                             k
                                          
                                       
                                    
                                 
                              
                           

Apply the normalization to the obtained variances of the remaining noise of image components to obtain 
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 
                                    
                                       ar
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                              , that is, 
                                 0
                                 ≤
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 a
                                 
                                    
                                       r
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                                 ≤
                                 1
                              . Fig. 3
                               shows the 
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 a
                                 
                                    
                                       r
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                               for Fig. 2(b).

Select the image component with maximum 
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 a
                                 
                                    
                                       r
                                    
                                    
                                       r
                                       e
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                               
                              
                                 (
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 a
                                 
                                    
                                       r
                                    
                                    
                                       r
                                       e
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 1
                                 )
                               as the tampered image component, and select image components with 
                                 
                                    
                                       V
                                    
                                    
                                       ˜
                                    
                                 
                                 a
                                 
                                    
                                       r
                                    
                                    
                                       
                                          re
                                       
                                       _
                                       
                                          noise
                                       
                                    
                                    
                                       k
                                    
                                 
                                 ≥
                                 
                                    
                                       Th
                                    
                                    
                                       C
                                    
                                 
                               as candidate tampered image components.

If candidate tampered image components are adjacent to tampered image components, mark them as tampered and removed them from the list of candidate tampered image components.

Collect all the tampered components and then apply up-sampling to obtain the tampered regions in image I.

Show the result of composite image detection.

In the proposed algorithm of image-component-based composite image detection, down-sampling operation in Step 3 is applied to obtain the same size of sub-band image obtained using one-level DWT operation in Step 4. And, up-sampling operation in Step 12 is applied to obtain the original size of tested image I. Furthermore, the reason of calculating 
                        
                           
                              Var
                           
                           
                              
                                 re
                              
                              _
                              
                                 noise
                              
                           
                           
                              k
                           
                        
                      using 
                        
                           
                              I
                           
                           
                              V
                              ,
                              
                                 down
                              
                           
                           
                              k
                           
                        
                      and 
                        
                           
                              (
                              
                                 
                                    I
                                 
                                 
                                    V
                                    ,
                                    
                                       HH
                                    
                                 
                              
                              )
                           
                           
                              R
                           
                        
                      is that these two images are with same size (that is, they are both 1/4 tested image I) and it can effectively reduce computational cost. Besides, thresholds 
                        
                           
                              Th
                           
                           
                              Q
                           
                        
                        =
                        4.0
                      and 
                        
                           
                              Th
                           
                           
                              C
                           
                        
                        =
                        0.3
                      are set from experience, where the value of 
                        
                           
                              Th
                           
                           
                              C
                           
                        
                      is decided the numbers of candidate tampered image components.

Because the image components are obtained using spectral segmentation with the k-means algorithm based on the eigenvectors of the matting Laplacian matrix, there will be broken or incomplete tampered regions. Therefore, a refinement scheme is proposed to obtain more complete tampered regions. Object region refinement with a 
                        3
                        ×
                        3
                      mask is used to scan the results of tampering detection. Each pixel of untampered regions is checked for whole image to obtain 
                        
                           
                              M
                           
                           
                              1
                           
                        
                      image if the up and down pixels of tested pixel are both the pixels of tampered regions, and this pixel is remarked as a pixel of tampered regions. Each pixel of untampered regions is checked for whole image to obtain 
                        
                           
                              M
                           
                           
                              2
                           
                        
                      image if the left and right pixels of tested pixel are both pixels of tampered regions, and this pixel is remarked as a pixel of tampered regions. Next, 
                        
                           
                              M
                           
                           
                              1
                           
                        
                      and 
                        
                           
                              M
                           
                           
                              2
                           
                        
                      are merged using the “OR” operator. Next, a hole-filling scheme is used to fill the holes in tampered regions. The results of this procedure contain only tampered regions and residual small regions. In this paper, the residual small regions are defined as noise regions. The fast 4-connected component labeling method [27] is used to label each isolated region, whose size is calculated. An isolated region is removed if its area is smaller than the given threshold 
                        
                           
                              Th
                           
                           
                              r
                           
                        
                     . The residual small regions are thus removed, leaving only tampered regions. Fig. 4
                      shows the results obtained using the proposed tampering detection method. As shown, the proposed refinement scheme effectively produces more complete tampered regions.

@&#EXPERIMENTAL RESULTS@&#

Performance of the proposed method was evaluated using the own dataset, JPEG compression dataset, and CASIA v1.0 dataset [30]. The algorithm was implemented in Matlab R2011a.

In the experiments, six composite images were used to evaluate the performance of the proposed tampering detection method. These six composite images look like realistic images, and human inspection may fail.

In order to illustrate the performance of the proposed method, several criteria, namely sensitivity 
                           
                              
                                 S
                              
                              
                                 e
                              
                           
                        , specificity 
                           
                              
                                 S
                              
                              
                                 p
                              
                           
                        , and spatial accuracy 
                           
                              
                                 S
                              
                              
                                 a
                              
                           
                         
                        [28], were adopted. The sensitivity 
                           
                              
                                 S
                              
                              
                                 e
                              
                           
                         (true positive rate), specificity 
                           
                              
                                 S
                              
                              
                                 p
                              
                           
                         (true negative rate) and spatial accuracy 
                           
                              
                                 S
                              
                              
                                 a
                              
                           
                         are defined in (7)–(9), respectively, where TP is the total number of true positive pixels, FP is the total number of false positive pixels, TN is the total number of true negative pixels, and FN is the total number of false negative pixels. Perfect tampering detection would produce sensitivity, specificity, and spatial accuracy values of 1. The ground truth of the tested composite image was segmented manually.
                           
                              (7)
                              
                                 
                                    
                                       S
                                    
                                    
                                       e
                                    
                                 
                                 =
                                 
                                    TP
                                 
                                 /
                                 (
                                 
                                    TP
                                 
                                 +
                                 
                                    FN
                                 
                                 )
                              
                           
                        
                        
                           
                              (8)
                              
                                 
                                    
                                       S
                                    
                                    
                                       p
                                    
                                 
                                 =
                                 
                                    TN
                                 
                                 /
                                 (
                                 
                                    TN
                                 
                                 +
                                 
                                    FP
                                 
                                 )
                              
                           
                        
                        
                           
                              (9)
                              
                                 
                                    
                                       S
                                    
                                    
                                       a
                                    
                                 
                                 =
                                 1
                                 −
                                 
                                    (
                                    (
                                    
                                       FP
                                    
                                    +
                                    
                                       FN
                                    
                                    )
                                    /
                                    (
                                    
                                       TP
                                    
                                    +
                                    
                                       FN
                                    
                                    )
                                    )
                                 
                              
                           
                        
                     


                        Figs. 5–10
                        
                        
                        
                        
                        
                         show the tampering detection of various images. Fig. 5 is the tampering detection of image with eagle, where Fig. 5(a) is the target image with JPEG format; Fig. 5(b) is the source image with JPEG format; Fig. 5(c) is the composite image with BMP format; Fig. 5(d) is the image components; Fig. 5(e) is the normalization of variances of remaining noise of image components; and Fig. 5(f) is the obtained result of tampering detection using the proposed method.


                        Fig. 6 is the tampering detection of image of beach, where Fig. 6(a) is the target image with JPEG format; Fig. 6(b) is the source image with BMP format; Fig. 6(c) is the composite image with BMP format; Fig. 6(d) is the image components; Fig. 6(e) is the normalization of variances of remaining noise of image components; and Fig. 6(f) is the obtained result of tampering detection using the proposed method.


                        Fig. 7 is the tampering detection of Pyramid image, where Fig. 7(a) is the target image with JPEG format; Fig. 7(b) is the source image with JPEG format; Fig. 7(c) is the composite image with JPEG format; Fig. 7(d) is the image components; Fig. 7(e) is the normalization of variances of remaining noise of image components; and Fig. 7(f) is the obtained result of tampering detection using the proposed method. Besides, the tampered region is about 50% area of the composite image and the foreground in the target image is entirely covered by tampered region.


                        Fig. 8 is the tampering detection of image with sky, where Fig. 8(a) is the target image with BMP format; Fig. 8(b) is the source image with BMP format; Fig. 8(c) is the composite image with BMP format; Fig. 8(d) is the image components; Fig. 8(e) is the normalization of variances of remaining noise of image components; and Fig. 8(f) is the obtained result of tampering detection using the proposed method.


                        Fig. 9 is the tampering detection of image with highway, where Fig. 9(a) is the target image with BMP format; Fig. 9(b) is the source image with JPEG format; Fig. 9(c) is the composite image with JPEG format; Fig. 9(d) is the image components; Fig. 9(e) is the normalization of variances of remaining noise of image components; and Fig. 9(f) is the obtained result of tampering detection using the proposed method. Besides, the source image was deformed and rotated and then copied into the target image to form the composite image.


                        Fig. 10 is the tampering detection of image with butterfly, where Fig. 10(a) is the target image with BMP format; Fig. 10(b) is the source image with BMP format; Fig. 10(c) is the composite image with JPEG format; Fig. 10(d) is the image components; Fig. 10(e) is the normalization of variances of remaining noise of image components; and Fig. 10(f) is the obtained result of tampering detection using the proposed method.


                        Table 1
                         shows the image formats of the target, source, and composite images in own dataset (Figs. 5–10). The proposed tampering detection method works well for both compressed (JPEG) and uncompressed (BMP) formats. Table 2
                         shows the results of the performance evaluation in own dataset. The proposed method has good composite image detection performance.

Experimental results show that the proposed method can work well for composite images whose target and source images are in either compressed or uncompressed format or a mixture, and for tampered regions subjected to geometric operations (such as scaling, rotation, and morphing).

Compared to the tampering detection method based on local noise level inconsistency proposed by Mahdian and Saic [15], the method proposed here does not use additive Gaussian noise and works well as a standalone forgery detector for composite images.

Compared to the shadow-based tampering detection method proposed by Liu et al. [21], the method proposed here is not limited to a single distant light source and accurately determine which part of the composite image is doctored.

For evaluating the feasibility of proposed method under JPEG compression, an image dataset composed 50 images (highway and butterfly images in Figs. 9–10) saved with double JPEG compression was built (JPEG compression dataset). In this dataset, target image is JPEG compressed with a given quality factor 
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                        , and composite image is JPEG compressed with a given quality factor 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                        , where 
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                           =
                           [
                           50
                           ,
                           60
                           ,
                           70
                           ,
                           80
                           ,
                           90
                           ]
                         and 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           =
                           [
                           50
                           ,
                           60
                           ,
                           70
                           ,
                           80
                           ,
                           90
                           ]
                        . Tables 3–4
                        
                         show the spatial accuracy 
                           
                              
                                 S
                              
                              
                                 a
                              
                           
                         of highway and butterfly images in JPEG compression dataset, respectively. The average spatial accuracy 
                           
                              
                                 S
                              
                              
                                 a
                              
                           
                         is 0.9601 in JPEG compression dataset. The average sensitivity 
                           
                              
                                 S
                              
                              
                                 e
                              
                           
                         is 0.9796 in JPEG compression dataset. The average specificity 
                           
                              
                                 S
                              
                              
                                 p
                              
                           
                         is 0.9997 in JPEG compression dataset. Experimental results were shown that the proposed tampering detection has good performance in the feasibility of JPEG compression.

Two state-of-the-art methods, JPEG-compression-based tampering detection method [20] and block posterior probability map (BPPM)-based tampering detection method [31], were used to compare with the proposed method to evaluate the performance in JPEG compression dataset.

JPEG-compression-based tampering detection method, proposed by Bianchi and Piva [20] was used to compare with the proposed method. The source code was downloaded from the author's website (http://lesc.det.unifi.it/en/node/187). Figs. 11(a) and 11(b)
                         are the tampering detection of butterfly image saved with double JPEG compression (
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                           =
                           80
                           ,
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           =
                           90
                        ) and (
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                           =
                           90
                           ,
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           =
                           50
                        ) using JPEG-compression-based tampering detection method [20], respectively, where red/blue areas correspond to high/low probability of being doubly compressed and they can be further used to check tampered regions. The left side of Figs. 11(a) and 11(b) are the results using aligned double JPEG (A-DJPG) compression. The right side of Figs. 11(a) and 11(b) are the results using nonaligned double JPEG (NA-DJPG) compression. Experimental results show that the tampered regions are not accurately detected. Besides, the identification of tampered images needs to be decided manually by the user because the identification rule was not given in the literature [20]. Furthermore, based on authors' suggestion [20], their method is able to correctly identify traces of A-DJPG compression unless 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           =
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                         or 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           ≪
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                        , and it is able to correctly identify traces of NA-DJPG compression whenever 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           >
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                         and there is a sufficient percentage of doubly compressed blocks.

The detection accuracy of JPEG-compression-based tampering detection method [20] in JPEG compression dataset is 76% and 42% using A-DJPG compression and NA-DJPG compression, respectively, where detection accuracy is defined as accurate identification of tampered images.

In JPEG compression dataset, BPPM-based tampering detection method [31] makes tampering detection fail for all tampered images. Based on the author's (Prof. Zhouchen Lin) suggestion [31], three working conditions of BPPM-based tampering detection method are: (1) The unchanged region (un-tampered region) is from a JPEG image and its DCT grid does not change after tampering; (2) The quality of second JPEG compression is higher than that of the original JPEG of the unchanged region (that is, 
                           
                              
                                 QF
                              
                              
                                 2
                              
                           
                           >
                           
                              
                                 QF
                              
                              
                                 1
                              
                           
                        ); and (3) The area of changed region (tampered region) should be moderate. If it is too large or too small, the DW effect is not salient. The ideal proportion of changed region should be within 30%–70% of the image. Because the tampered region is not within 30%–70% of the composite image in JPEG compression dataset, detection capability of BPPM-based tampering detection method is ineffective in JPEG compression dataset.

The computational complexity of A-DJPG compression [20], NA-DJPG compression [20], and BPPM-based method [31] are all 
                           O
                           (
                           N
                           )
                        , and the computational complexity of our method is 
                           O
                           (
                           
                              
                                 N
                              
                              
                                 2
                              
                           
                           )
                        , where N is the total pixels of the tested image. The computational cost of our method is mainly spent on the adaptive component detection method. Because the adaptive component detection method needs to use mean shift algorithm and spectral segmentation with the k-means algorithm, the computational cost is high. It is worth mentioning that the computational complexity can be effectively reduced by the following solutions [32]: (1) clever choice of kernel supports (such as in the image segmentation examples), (2) introduction of approximate iterations (such as the Fast Gauss Transform [33]), (3) use of suitable stopping criteria to eliminate unnecessary iterations, and (4) employing other heuristic rules that save computations (such as checking conditions similar to the information force tree approach [34]). Therefore, the proposed method is feasibility for image tampering detection.

A-DJPG compression [20], NA-DJPG compression [20], and BPPM-based method [31] are all the non-overlapping blocks-based tampering detection methods and they would obtain tampered regions with jagged shapes. Our method uses image components rather than non-overlapping blocks, thus our method can obtain more fine contours of tampered regions than ones obtained using these non-overlapping blocks-based tampering detection methods.

Furthermore, A-DJPG compression [20], NA-DJPG compression [20], and BPPM-based method [31] make the tampering detection fail whenever the target image is not saved with JPEG format and only composite image is saved with JPEG format, such as the cases of Figs. 9 and 10.

Compared to JPEG-compression-based tampering detection methods [17–20,31], experimental results show that the proposed method can work well for without the limitation of quality factors in JPEG compression for target and composite images.

An open source database-CASIA v1.0 dataset [30] is used to evaluate the performance of the proposed method. CASIA v1.0 dataset focus on splicing detection evaluation. Image splicing is defined as a simple cut-and-paste operation of image regions from one image onto the same or another image without performing post-processing. It is a fundamental operation of tampering. CASIA v1.0 dataset has 1721 images which contain 800 authentic and 921 spliced color images of size 
                           384
                           ×
                           256
                         pixels with JPEG format. Five state-of-the-art methods, JPEG-compression-based tampering detection method [20], BPPM-based method [31], SPN-based methods [23,35], and EXIF-noise-based tampering detection method [29], were used to compare with the proposed method to evaluate the performance in CASIA v1.0 dataset. Comparison of detection capability in CASIA v1.0 dataset is list in Table 5
                        .

In CASIA v1.0 dataset, 98.96% of 1721 images don't have aperture, shutter speed and ISO in the EXIF headers, which are needed in EXIF-noise-based tampering detection method [29]. Therefore, detection capability of EXIF-noise-based tampering detection method is ineffective in CASIA v1.0 dataset.

In SPN-based method for camera identification [23], the correlation is calculated between the image noise residual and the known camera reference pattern to decide whether a tested image was taken by a specific camera, where camera reference pattern is an approximation of the pixel nonuniformity (PNU) noise. In SPN-based method for image tampering detection [35], the sliding block is used and then the correlation is calculated between the block noise residual and the known camera reference pattern to detect the tampered regions. In CASIA v1.0 dataset, all images don't know that were taken by the types of cameras. It is necessary to know camera reference pattern in SPN-based methods [23,35]. Therefore, detection capability of SPN-based methods [23,35] is ineffective in CASIA v1.0 dataset. Besides, all images are also without camera reference pattern in own dataset and JPEG compression dataset, because these tested images were downloaded from Internet. Therefore, detection capability of SPN-based methods [23,35] is ineffective in own dataset and JPEG compression dataset.

Furthermore, 921 spliced images of CASIA v1.0 dataset have 461 images which belong to copy–move image forgery (simple cut-and-paste operation of image regions from one image onto the same image), thus there are only 460 composite images. Therefore, 1260 tested images (800 authentic and 460 composite images) are used to further evaluate the performance of JPEG-compression-based tampering detection [20] method, BPPM-based method [31], and our method. These 1260 tested images are named as the selected CASIA v1.0 dataset. Fig. 12
                         is the detected tampered regions of some examples in the selected CASIA v1.0 dataset, where Fig. 12(a) is the result using the A-DJPG compression [20], Fig. 12(b) is the result using the NA-DJPG compression [20], Fig. 12(c) is the result using the BPPM-based method [31], and Fig. 12(d) is the result using our method.


                        Table 6
                         is the performance evaluation results using A-DJPG compression [20], NA-DJPG compression [20], BPPM-based method [31], and our method in selected CASIA v1.0 dataset, where 
                           
                              
                                 TP
                              
                              ¯
                           
                         is the total number of true positive images, 
                           
                              
                                 FP
                              
                              ¯
                           
                         is the total number of false positive images, 
                           
                              
                                 TN
                              
                              ¯
                           
                         is the total number of true negative images, and 
                           
                              
                                 FN
                              
                              ¯
                           
                         is the total number of false negative images.

The detection accuracy of A-DJPG compression, NA-DJPG compression, BPPM-based method, and our method are 51.35%, 49.29%, 50.63, and 61.11%, respectively. The detection accuracy is defined in (10). Experimental results show that the proposed method outperforms state-of-the-art methods [20,31] for JPEG-compression tampering detection.
                           
                              (10)
                              
                                 
                                    
                                       D
                                    
                                    
                                       a
                                    
                                 
                                 =
                                 (
                                 
                                    
                                       TP
                                    
                                    ¯
                                 
                                 +
                                 
                                    
                                       TN
                                    
                                    ¯
                                 
                                 )
                                 /
                                 (
                                 
                                    
                                       TP
                                    
                                    ¯
                                 
                                 +
                                 
                                    
                                       TN
                                    
                                    ¯
                                 
                                 +
                                 
                                    
                                       FP
                                    
                                    ¯
                                 
                                 +
                                 
                                    
                                       FN
                                    
                                    ¯
                                 
                                 )
                              
                           
                        
                     

Furthermore, the detection accuracy of authentic images and composite images using different methods can be further broken down as Table 7
                        .

The reason of low detection accuracy using A-DJPG compression and NA-DJPG compression maybe is the given identification rule not being optimal. The low detection accuracy using BPPM-based method maybe is caused from the limitations of three working conditions of BPPM-based tampering detection method, which were reported in Subsection 3.2. The main reason of low detection accuracy using our method is that the obtained image components using the adaptive component detection method [10] are not the accurate result, because the adaptive component detection method is suitable for image segmentation of images having the foreground objects. It is worth mentioning that a more suitable detection method of image components can effectively raise the detection accuracy of our method.

@&#CONCLUSION@&#

This paper proposed an effective composite image detection method. The image components are first obtained using adaptive component detection. Next, the variance of the noise remaining after de-noising in each image component is calculated. Finally, the tampered regions are detected using the variance of the remaining noise of image components based on a tampering detection rule.

This paper makes three major contributions. (i) The proposed method uses image components rather than non-overlapping blocks to obtain fine contours of tampered regions. (ii) The variance of noise remaining after de-noising (sensor pattern noise) is used to determine feature inconsistency for tampering detection. (iii) The proposed method can work well for without the limitation of quality factors in image compression for target and composite images, for composite images whose target and source images are in either compressed or uncompressed format or a mixture, and for tampered regions subjected to geometric operations (such as scaling, rotation, and morphing). Experimental results show that the proposed method has good composite image detection performance and that it outperforms state-of-the-art methods for composite image detection. Therefore, the proposed method is a useful forgery detector for composite images.

@&#ACKNOWLEDGEMENTS@&#

This work was supported by the National Science Council of Taiwan under grant NSC102-2221-E-346-007 and MOST103-2221-E-346-007. The authors wish to express the appreciation to Mr. Chu-Lin Chuang, Mrs. Jiayuan Fan, Prof. Alessandro Piva, Prof. Zhouchen Lin, and Prof. Wei Wang for their help with the experiments. The authors also gratefully acknowledge the helpful comments and suggestions of reviewers, which have improved the quality and presentation.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A Multi-Tree Committee to assist port-of-entry inspection decisions

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We tackle the difficult port-of-entry inspection problem by adding coherency.


                        
                        
                           
                           A decision-based logical model is defined under realistic assumptions.


                        
                        
                           
                           We develop a simple yet widely applicable algorithm for real sequential inspections.


                        
                        
                           
                           Combination of binary decision trees and minimization of boolean functions.


                        
                        
                           
                           The efficiency and flexibility of the algorithm is measured against real data.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Risk analysis

Port-of-entry

Inspection policy

Binary decision tree

Multi-Tree Committee

@&#ABSTRACT@&#


               
               
                  A natural way to avoid the injection of potentially dangerousor illicit products in a certain country is by means of protection, following a strict port-of-entry inspection policy. A naive exhaustive manual inspection is the most secure policy. However, the number of within containers allows only to check a limited number of containers by day. As a consequence, a smart port-of-entry selection policy must trade cost of inspection with security, in order to fit into the dynamic operation of a port.
                  We explore the design of port-of-entry container inspection policies with imperfect information (unavailable or untrusted data). Starting from an a-priori classification provided by port-of-entry customs operator, a combinatorial optimization problem is introduced. The goal is to match an a-priori container classification with a logically coherent one, subject to a given level of container inspection. Inspired in the related literature, a novel Multi-Tree Committee is introduced in order to find a solution to the previous combinatorial problem. It combines the strength of binary decision trees and minimization of logical functions. The algorithm is easy-to-handle and useful for an on-line production. We highlight the effectiveness of our proposal, regarding real traces available from the port of Montevideo. The results show the capability to detect the most risky containers and its conservative nature, respecting any desired level of inspection.
               
            

@&#INTRODUCTION@&#

The decisions ruled by a port-of-entry customs operator must overcome several challenges, as the presence of illicit products or even foreign attacks. The source of inspiration is their experience to detect anomalies and sometimes, it is assisted with electrical detection by sensors and operational research-based algorithms for manual inspection.

The real problem is so complex that theoretical tools and automatic algorithms usually assist, but do not replace, the decision of an operator. The main difficulties arise when the available information is untrusted, incomplete or imperfect. Furthermore, there is no international agreement in the encoding of information. As a consequence, an automatic approach is highly desirable, but it is hard to design. Moreover, it is difficult to compare the sensibility of different models against the presence of suspicious containers. So far, the proposed approaches from the operational research community ranges from game-theoretic models (Wein, Wilkins, Baveja, & Flynn, 2006), design of logical functions (Young, 2010), binary decision trees (Madigan, Mittal, & Roberts, 2007; Stroud, 2003), multi-objective optimization  (Xue & Villalobos, 2012; Young et al., 2010), dynamic programming techniques (Young et al., 2010), and Bayesian approach (Candy, 2013), among many other ad-hoc models for screening under budget constraints (Dreiding & McLay, 2013) and prophylactic models for terrorist attacks (McLay & Dreiding, 2012).

In this paper, we propose a novel approach with the objective of “correcting” inconsistencies found within the a-priori classification provided by port-of-entry customs operators according to their work experience. The decisions are supported by a set of rules or risk-indicators, that suggest which containers are suspicious and which are not. The goal is to enforce coherence in the classification, i.e. a container with more risk-indicators should be classified as more suspicious, and therefore should be pointed out to be manually checked with higher probability. As far as we know, the detection and correction of inconsistencies in a real-life port-of-entry inspection policy has not been addressed in previous works in the related literature. The main contributions of this paper are summarized in the following items:

                        
                           •
                           To the best of our knowledge, this is the first paper in the area that enriches an operational research approach based on previous experience offered by customs operators in a real port.

Previous works assume perfect knowledge of detection/false alarm probabilities, or percentage of illicit containers (Anand, Madigan, Mammone, Pathak, & Roberts, 2006; Boros, Fedzhora, Kantor, Saeger, & Stroud., 2009; Candy, 2013; Madigan et al., 2007; Stroud, 2003; Young, 2010). However, a pointwise estimation of those probabilities are usually performed with small sample size in relation with the whole container population. We believe this assumptions lead to unaccurate models. In this sense, our model seems to be more realistic.

We provide an explicit formulation of a combinatorial optimization problem, called Coherence Problem. The goal is to enrich an a-priori classification given by real customs operators, adding coherence and respecting a desired level of inspection (i.e. the fraction of containers to be inspected).

A novel Multi-Tree Committee is introduced in order to provide a feasible solution. It combines the strength of Binary Decision Trees (BDTs) and minimization of logical functions.

We obtained real traces offered by our National Port Operator, called Administración Nacional de Puertos, located at Montevideo, Uruguay. We will appreciate the capability of our Committee-based approach to detect the most risky containers, and its conservative nature, respecting the level of inspection imposed by customs operators.

This document is organized as follows. Section 2 contains related work, mainly focused on binary decision trees and logical design of inspection policies. In Section 3, an ideal approach is developed. Here, we try to follow the classification provided by customs operators as close as possible. A Mirror solution presents the minimum gap. However, it is not coherent, in the sense that more risky containers are not opened. Inspired in the deficiencies of the previous approach, a Realistic Approach is presented in Section 4. It captures a notion of coherence in the decision which is usually not met in real-life, giving possibilities of enhancement and automation. Furthermore, a desired fraction of containers is selected to be inspected, hence it achieves a realistic level of inspection.

In Section 5, an algorithm called TreeCommittee is introduced for the general Coherence Problem. It tries to unify the strength of both worlds: binary decision trees and logical functions. As we will see, the role of the committee is to cope with imperfect information and to adjust to a desired level of inspection. Section 6 illustrates the results on the lights of real traces from our national port of Montevideo. There, we study the gap between TreeCommittee and Mirror. Finally, in Section 7 we point-out concluding remarks and discuss trends for future work.

@&#RELATED WORK@&#

The inspection process can be regarded as the collection and analysis of information available from multiple sensors and other sources, in order to decide whether a container should be allowed to enter the port or not (Young, 2010).

The means to detect anomalies are supported in digital signal processing of physical information of containers and consistency of the documentation related with the container. Candy provides an X-ray physics-based threat detection solution, using a probabilistic model (Candy, 2013). The Bayesian approach enables the development of a physics-based detection algorithm capable of detect threat under restricted assumptions, including known detection and false alarm probabilities.

Madigan et al. develop an abstraction of the port-of-entry inspection problem (Madigan et al., 2007), assuming the existence of n logical sensors which return binary variables 
                        
                           
                              
                                 {
                                 
                                    d
                                    i
                                 
                                 }
                              
                              
                                 i
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 n
                              
                           
                           ,
                        
                      such that 
                        
                           
                              d
                              i
                           
                           =
                           1
                        
                      means that the feature number i studied by that sensor is suspicious; and 
                        
                           
                              d
                              i
                           
                           =
                           0
                        
                      otherwise. As a consequence, each container has a corresponding binary word 
                        
                           d
                           =
                           
                              d
                              1
                           
                           …
                           
                              d
                              n
                           
                           ,
                        
                      and the authors study classification mechanism of binary words by means of binary decision trees (BDT). A BDT is a widely used classification technique, where there is a special root-node and all nodes have output-degree 2. The container information i is inserted in the root-node, which is identified with a question (precisely, one sensor labeled with the numbers 
                        
                           {
                           1
                           ,
                           …
                           ,
                           n
                           }
                        
                     ). If the answer is affirmative (negative), the information i travels to the right (left) branch of that node. Finally, there is a correspondence between the terminal nodes and the set {0, 1}, in order to assign a binary classification to every container. A challenging problem is to design the questions to be inserted in each node. As a consequence, the design of a BDT is reduced to a sequential decision problem, where the aim is to decide the order of the sensors to minimize a cost function.

A related perspective of the problem is to design a binary function f: {0, 1}
                        n
                      → {0, 1}, where the containers are manually classified whenever their corresponding binary word d complies 
                        
                           f
                           (
                           d
                           )
                           =
                           1
                        
                     . There are several realizations of a certain binary function f(d) with equivalent BDTs. Hyafil and Rivest proved in 1976 that the minimization of the expected number of questions in the set of equivalent BDTs is an NP-Complete problem, where the probabilities 
                        
                           P
                           (
                           
                              d
                              i
                           
                           =
                           1
                           )
                        
                      are known (Hyafil & Rivest, 1976). In the year 2003, Stroud (2003) provides an exhaustive enumeration of BDTs such that no sensor appears twice in any branch. Specifically, if Nn
                      is the number of such BDTs, then 
                        
                           
                              N
                              n
                           
                           =
                           2
                           +
                           n
                           
                              
                                 (
                                 
                                    N
                                    
                                       n
                                       −
                                       1
                                    
                                 
                                 )
                              
                              2
                           
                           ,
                        
                      where 
                        
                           
                              N
                              0
                           
                           =
                           2
                        
                      (with no sensor, the only BDTs are either output 0 or 1). The reader can easily check that there are only 74 BDTs with 
                        
                           n
                           =
                           2
                        
                      sensors, but N
                     5 ≈ 5 × 1018. The cardinality Nn
                      of BDTs in terms of the number of sensors n has an exponential growth, and an exhaustive evaluation of BDTs is not practical for a large number of sensors. Stroud defines the cost of a tree combining both the misclassification probability and inspection cost (i.e. the use of sensors). The first contribution depends on the failure probability of the sensors, as well as the statistical distribution of the containers, that must be previously estimated from historical information. It sounds mandatory to reduce the search space. Therefore, the author finds an optimal BDT among a reduce subset. They ranked all trees formed from 3 or 4 sensors according to increasing tree costs, and defined an enumeration algorithm. Their results can not be directly extended to higher number of sensors. However, Anand et. al point out that the optimal inspection policy provided by Stroud algorithm is remarkably insensitive to parametric changes (Anand et al., 2006), reinforcing their approach.

Similar in spirit and with a BDT-based classification, Madigan first tunes the thresholds for each sensor in order to minimize the cost function, by means of numerical methods for non-linear equations, combining gradient-descent and Newton–Raphson. A key element of his development is to study a distinguished sub-class of BDT, which are monotonous and complete (a BDT is monotonous when it realizes a monotonous binary function, and complete whenever the BDT includes all sensors). In this sub-world of BDT, an algorithm for exhaustive enumeration is feasible, and the author finds the optimal BDT when 
                        
                           n
                           =
                           4
                        
                     . The number of BDTs in this subset is now 263, 515, 920 when 
                        
                           n
                           =
                           5
                        
                     . The number of monotonous logical functions with n bits is called Dedekind’s number since his seminal work in 1897 (Dedekind, 1897), and the exact number is an open problem for large number of n (recent advances in this area confirm for instance the case 
                        
                           n
                           =
                           8
                        
                      (Wiedemann, 1991)).

The search in the space of complete-monotonous BDTs takes into consideration a neighborhood structure (i.e. a polytime and completely transitive neighborhood system) that swaps, deletes, merges and replaces nodes for cost minimization. Nevertheless, the multi-modal nature of the objective function leads the local search to get stuck in local minima. As a consequence Madigan introduces a heuristic approach with randomness, inspired in simulated annealing. The heuristic is tested with the set of complete monotonous BDT, reaching 42 times the global optimum, which was more economic than the BDT found by Anand, who search even in the whole universe of BDT. Since the complete study for 
                        
                           n
                           =
                           5
                        
                      also escapes to million of tree configurations, it was suggested as a trend for future work, and suggests the use of genetic algorithms. Indeed, the design of genetic algorithms to face a multi-modal objective has been suggested in other works (Fu & Mae, 2001; Li, Balazs, Parks, & Clarkson, 2003), and implemented in subsequent works (Concho & Ramirez, 2010; Ramirez, 2008).

More recently, Young tackles the port-of-entry inspection problem in order to avoid undesired cargo in the United States, in her PhD thesis (Young, 2010). The thesis includes a background of the problem and discussion of several formulations for the port-of-entry inspection problem by mathematical models, with a neat treatment of the assumptions and horizon of applicability. Based on Elsayed, Young, Xie, Zhang, and Zhu (2009), the goal of the models is to reduce the overall expected cost in the space of sequential inspection policies. Following works from Stroud (2003),  Anand et al. (2006) and Boros et al. (2009), it is assumed that the sensors return normally distributed numerical values. Young finds optimal thresholds by numerical estimation, that lead to a binary output. A sequential configuration of the sensors can be identified with parallel-series logical circuits or equivalently, conjunctive normal forms. Let π be the proportion of containers with risky elements, that should be manually inspected under optimal conditions, and let us denote with X the random variable that assumes the value 1 whenever the container has illegal cargo and 0 otherwise: 
                        
                           π
                           =
                           P
                           (
                           X
                           =
                           1
                           )
                        
                     . Consider 
                        
                           
                              p
                              i
                           
                           =
                           P
                           
                              (
                              
                                 d
                                 i
                              
                              =
                              1
                              )
                           
                        
                      and their complements 
                        
                           
                              q
                              i
                           
                           =
                           1
                           −
                           
                              p
                              i
                           
                        
                     . Additionally, the utilization of sensor i has a cost ci
                     .

The most strict policy Fs
                      will define a container as risky whenever there is at least one sensor set to 1. In normal form it is 
                        
                           
                              F
                              s
                           
                           =
                           
                              ∨
                              
                                 i
                                 =
                                 1
                              
                              n
                           
                           
                              {
                              
                                 d
                                 i
                              
                              =
                              1
                              }
                           
                        
                     . The following question has a simple answer, but illustrates a valuable concept for the problem under study. Which is the optimum sequence for the container inspection under strict policy? The answer is to order the sensors with low cost and higher sensibility to positive first: c
                     1/q
                     1 < c
                     2/q
                     2 < ⋅⋅⋅ < cn
                     /qn
                     , where we re-labeled the sensors to respect the previous inequalities.

The opposite policy is the most permissive, and defines a container as risky only when all sensors are positive: 
                        
                           
                              F
                              p
                           
                           =
                           
                              ∧
                              
                                 i
                                 =
                                 1
                              
                              n
                           
                           
                              {
                              
                                 d
                                 i
                              
                              =
                              1
                              }
                           
                        
                     . Which is the optimal sequence in this case? In this case, the sensors with highest sensibility to negative should be revised before, weighting their costs. More precisely, the order must respect c
                     1/p
                     1 < c
                     2/p
                     2 < ⋅⋅⋅ < cn
                     /pn
                     .

The previous results are intuitive, and were proved for the first time by Zhang, Schroepfer, and Elsayed 2006 and further generalized to all logical functions (Elsayed et al., 2009; Young, 2010). It is worth noting that the correct use of this optimization tool requires knowledge about the probabilities 
                        
                           
                              p
                              i
                           
                           =
                           P
                           
                              (
                              
                                 d
                                 i
                              
                              =
                              1
                              )
                           
                        
                      for each sensor, as well as the proportion π of risky containers and the cost of utilization ci
                      of all sensors. Young also weights the cost of inspection in the cost function by a convex combination between misclassification and inspection, or Pareto curves that trade both aspects as desired.

An alternative approach is to exploit historical classification provided by port operators and conduct a mimetic solution. In Graneri, Moscatelli, Romero, Tansini, and Viera (2015), we provide the closest deterministic classification to that offered by customs operators. The measure of similarity is there captured by the number of matchings in the classification of a part of the training set, and the result has a statistical meaning.

This work is widely inspired in prior works from David Madigan and Young (2010). However, the context is rather hostile, since the information available is not statistically significant to define correct estimations for the misclassification probabilities, nor the proportion of risky containers π. As pointed out before, the novelty of this approach is the introduction of consistency to a previously given incoherent classification. Additionally, we will combine the strength of BDTs and minimization of normal forms evaluation in order to define an inspection policy suitable for an arbitrary number of sensors and level of inspection. In Section 3, we conduct an ideal approach, and a summary of the main ingredients provided in Graneri et al. (2015). Then, a realistic analysis is carried out in Section 4. A corresponding realistic classification is presented in Section 5, and a later comparison between both approaches is highlighted in Section 6.

We will follow the terminology from Section 2, where we are given a training multiset 
                        
                           W
                           =
                           {
                           
                              w
                              1
                           
                           ,
                           …
                           ,
                           
                              w
                              N
                           
                           }
                        
                      of (possibly repeated) binary words, for N containers. The set 
                        
                           {
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           r
                           }
                        
                      will be denoted by [r] for short, and represent the levels of risk. Each container is labelled (by customs operators) a risk level 
                        
                           
                              l
                              1
                           
                           ,
                           …
                           ,
                           
                              l
                              N
                           
                           ,
                        
                      where li
                      ∈ [r]. In the real problem, we are also concerned with a level of inspection α, but we will not study this constraint until the following section. In a first ideal approach, the goal is to define a deterministic function f: {0, 1}
                        n
                      → [r] that automatically classifies containers, and is similar to the labels provided by customs operator. This approach reflects the expertise from customs operators, where the fuzzy classification is realized in an automatic manner.

Observe that we do not assume misclassification probabilities nor sensor calibration. Therefore, to the best of our knowledge, there is only one prior work in the area that is suitable to the conditions of our real problem, written by the same authors (Graneri et al., 2015). This article is our point of departure, and will be summarized in this section as an ideal approach.

Two notions of similarity are considered. The symmetric difference between f and the multiset W of binary words is:

                        
                           
                              
                                 
                                    Δ
                                    W
                                 
                                 
                                    (
                                    f
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    1
                                    
                                       {
                                       f
                                       
                                          (
                                          
                                             w
                                             i
                                          
                                          )
                                       
                                       ≠
                                       
                                          l
                                          i
                                       
                                       }
                                    
                                 
                              
                           
                        
                     
                  

An alternative measure of similarity is the mean square error:

                        
                           
                              
                                 
                                    d
                                    W
                                 
                                 
                                    (
                                    f
                                    )
                                 
                                 =
                                 
                                    1
                                    N
                                 
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    
                                       (
                                       
                                          {
                                          f
                                          
                                             (
                                             
                                                w
                                                i
                                             
                                             )
                                          
                                          −
                                          
                                             l
                                             i
                                          
                                          }
                                       
                                       )
                                    
                                    2
                                 
                              
                           
                        
                     
                  

The following combinatorial optimization problem formalizes the Ideal Approach:

                        
                           
                              
                                 
                                    
                                       
                                          min
                                          
                                             f
                                             :
                                             
                                                
                                                   {
                                                   0
                                                   ,
                                                   1
                                                   }
                                                
                                                n
                                             
                                             →
                                             
                                                [
                                                r
                                                ]
                                             
                                          
                                       
                                    
                                    
                                       
                                          d
                                          (
                                          f
                                          ,
                                          W
                                          )
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     being either 
                        
                           d
                           
                              (
                              f
                              ,
                              W
                              )
                           
                           =
                           
                              Δ
                              W
                           
                           
                              (
                              f
                              )
                           
                        
                      the symmetric difference or 
                        
                           d
                           
                              (
                              f
                              ,
                              W
                              )
                           
                           =
                           
                              d
                              W
                           
                           
                              (
                              f
                              )
                           
                        
                      the mean square error.

It is well known from elementary calculus that the mean square error is minimized when f(w) is an averaging and rounding among all the labels wi
                      ∈ W such that 
                        
                           
                              w
                              i
                           
                           =
                           w
                        
                     . Let us denote f
                     1 to that average-and-rounding classification rule (for convention, we choose 
                        
                           
                              f
                              1
                           
                           
                              (
                              w
                              )
                           
                           =
                           1
                        
                      whenever w∉W). Now, let us consider 
                        
                           d
                           
                              (
                              f
                              ,
                              W
                              )
                           
                           =
                           
                              Δ
                              W
                           
                           
                              (
                              f
                              )
                           
                           ,
                        
                      what is called the Decision Problem. The following definition has been introduced by the same authors in Graneri et al. (2015):

                        Definition 1
                        Given the multiset 
                              
                                 W
                                 =
                                 {
                                 
                                    w
                                    1
                                 
                                 ,
                                 …
                                 ,
                                 
                                    w
                                    N
                                 
                                 }
                              
                            and respective labels 
                              
                                 
                                    l
                                    1
                                 
                                 ,
                                 …
                                 ,
                                 
                                    l
                                    N
                                 
                                 ∈
                                 
                                    [
                                    r
                                    ]
                                 
                                 ,
                              
                            the Mirror Solution is the function f
                           2: {0, 1}
                              m
                            → [r] where f
                           2(w) is the empirical mode (i.e., the most frequent label for w in the multiset W). As a convention, we choose 
                              
                                 
                                    f
                                    2
                                 
                                 
                                    (
                                    w
                                    )
                                 
                                 =
                                 1
                              
                            whenever w∉W.

The following result is intuitive.

                        Proposition 1
                        
                           The Mirror Solution is a global optimum for the Decision Problem.
                        

Let us consider an arbitrary solution 
                              
                                 g
                                 :
                                 
                                    
                                       {
                                       0
                                       ,
                                       1
                                       }
                                    
                                    m
                                 
                                 →
                                 
                                    {
                                    1
                                    ,
                                    …
                                    ,
                                    k
                                    }
                                 
                              
                            and the Mirror Solution f
                           2. We will establish the inequality ΔW
                           (f
                           2) ≤ ΔW
                           (g).

Let us consider the frequency of the binary word w in the multiset W with label i, this is 
                              
                                 
                                    t
                                    i
                                 
                                 
                                    (
                                    w
                                    )
                                 
                                 =
                                 
                                    {
                                    j
                                    ∈
                                    
                                       [
                                       1
                                       ,
                                       N
                                       ]
                                    
                                    :
                                    
                                       w
                                       j
                                    
                                    =
                                    w
                                    ,
                                    
                                    l
                                    
                                       (
                                       
                                          w
                                          j
                                       
                                       )
                                    
                                    =
                                    i
                                    }
                                 
                              
                           .

The number of incorrect assignments to word w using f
                           2 is precisely


                           
                              
                                 
                                    ɛ
                                 
                                 
                                    (
                                    
                                       f
                                       2
                                    
                                    ,
                                    w
                                    )
                                 
                                 
                                    =
                                    (
                                 
                                 
                                    ∑
                                    
                                       1
                                       ≤
                                       i
                                       ≤
                                       k
                                    
                                 
                                 
                                    |
                                 
                                 
                                    t
                                    i
                                 
                                 
                                    (
                                    w
                                    )
                                 
                                 
                                    |
                                    )
                                 
                                 −
                                 
                                    max
                                    {
                                    |
                                 
                                 
                                    t
                                    i
                                 
                                 
                                    (
                                    w
                                    )
                                 
                                 
                                    |
                                    :
                                    1
                                    ≤
                                    i
                                    ≤
                                    k
                                    }
                                 
                              
                           . If g(w) ≠ f
                           2(w) then the number of incorrect assignments to word w using g is


                           
                              
                                 
                                    
                                       ɛ
                                    
                                    
                                       (
                                       g
                                       ,
                                       w
                                       )
                                    
                                    =
                                    (
                                 
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    k
                                 
                                 
                                    |
                                 
                                 
                                    t
                                    i
                                 
                                 
                                    
                                       (
                                       w
                                       )
                                    
                                    |
                                    )
                                 
                                 −
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    k
                                 
                                 
                                    1
                                    
                                       {
                                       g
                                       (
                                       w
                                       )
                                       =
                                       i
                                       }
                                    
                                 
                                 
                                    |
                                    
                                       t
                                       i
                                    
                                    
                                       (
                                       w
                                       )
                                    
                                    |
                                 
                              
                           .

Since only one of those indicators is true, we immediately conclude that ɛ(f
                           2, w) ≤ ɛ(g, w), and

                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Δ
                                                   W
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      2
                                                   
                                                   )
                                                
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   1
                                                   
                                                      {
                                                      
                                                         f
                                                         2
                                                      
                                                      
                                                         (
                                                         
                                                            w
                                                            i
                                                         
                                                         )
                                                      
                                                      ≠
                                                      
                                                         l
                                                         i
                                                      
                                                      }
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      w
                                                      ∈
                                                      
                                                         
                                                            {
                                                            0
                                                            ,
                                                            1
                                                            }
                                                         
                                                         m
                                                      
                                                   
                                                
                                                
                                                   1
                                                   
                                                      {
                                                      w
                                                      ∈
                                                      
                                                      W
                                                      }
                                                   
                                                
                                                
                                                   (
                                                   
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      k
                                                   
                                                   
                                                      |
                                                      
                                                         t
                                                         i
                                                      
                                                      
                                                         (
                                                         w
                                                         )
                                                      
                                                      |
                                                   
                                                   
                                                   )
                                                
                                                
                                                   −
                                                   max
                                                   {
                                                   |
                                                
                                                
                                                   t
                                                   i
                                                
                                                
                                                   (
                                                   w
                                                   )
                                                
                                                
                                                   |
                                                   ,
                                                   i
                                                   =
                                                   1
                                                   ,
                                                   …
                                                   ,
                                                   k
                                                   }
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                
                                                
                                                   ∑
                                                   
                                                      w
                                                      ∈
                                                      
                                                         
                                                            {
                                                            0
                                                            ,
                                                            1
                                                            }
                                                         
                                                         m
                                                      
                                                   
                                                
                                                
                                                   1
                                                   
                                                      {
                                                      w
                                                      ∈
                                                      
                                                      W
                                                      }
                                                   
                                                
                                                
                                                   ɛ
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      2
                                                   
                                                   ,
                                                   w
                                                   )
                                                
                                                
                                                ≤
                                                
                                                
                                                
                                                   ∑
                                                   
                                                      w
                                                      ∈
                                                      
                                                         
                                                            {
                                                            0
                                                            ,
                                                            1
                                                            }
                                                         
                                                         m
                                                      
                                                   
                                                
                                                
                                                   1
                                                   
                                                      {
                                                      w
                                                      ∈
                                                      
                                                      W
                                                      }
                                                   
                                                
                                                
                                                   ɛ
                                                
                                                
                                                   (
                                                   g
                                                   ,
                                                   w
                                                   )
                                                
                                                =
                                                Δ
                                                
                                                
                                                   (
                                                   g
                                                   ,
                                                   L
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                           □

For the sake of simplicity, we will consider the deterministic rule f
                     1 (average-and-rounding) as the classification provided by customs operators. It is the optimal rule in the sense that it minimizes the mean square error.

We we follow the terminology from Section 3. We are given a triad (W, f, α), where 
                        
                           W
                           =
                           {
                           
                              w
                              1
                           
                           ,
                           …
                           ,
                           
                              w
                              N
                           
                           }
                        
                      represents a multiset of (possibly repeated) binary words, 
                        
                           f
                           =
                           
                              f
                              1
                           
                        
                      is the averaging-rounding rule, that assigns a risk-value in the set [r] to each container, and a level of inspection α ∈ [0, 1] that determines the fraction of containers to be inspected.

The project signed by our university and the port pursues the goal of designing an algorithm that should adapt to a variable number of sensors n and risk-levels r, meeting at the same time a desired level of inspection.

Observe that the set of binary words accepts a partial order: if 
                        
                           w
                           =
                           
                              d
                              1
                           
                           …
                           
                              d
                              n
                           
                        
                      and 
                        
                           
                              w
                              ′
                           
                           =
                           
                              d
                              1
                              ′
                           
                           …
                           
                              d
                              n
                              ′
                           
                           ,
                        
                      then w ≤ w′ if and only if 
                        
                           
                              d
                              i
                           
                           ≤
                           
                              d
                              i
                              ′
                           
                        
                      for all 
                        
                           i
                           =
                           1
                           ,
                           …
                           ,
                           n
                        
                     . A function g: {0, 1}
                        n
                      → [r] is monotonous, or coherent, if g(w) ≤ g(w′) whenever w ≤ w′. In practice, the classification f offered by the customs operator is not coherent. Indeed, there are certain containers that were assigned a low classification, while they should have been classified as risky, in terms of sensors.

Therefore, we are motivated to introduce the Coherence Problem. Let us denote Δ(f, g) the symmetric difference between two given functions f and g. More precisely, if f: {0, 1}
                        n
                      → [r] and g: {0, 1}
                        n
                      → [r] then

                        
                           
                              
                                 Δ
                                 
                                    (
                                    f
                                    ,
                                    g
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       w
                                       ∈
                                       
                                          
                                             {
                                             0
                                             ,
                                             1
                                             }
                                          
                                          n
                                       
                                    
                                 
                                 
                                    1
                                    
                                       {
                                       f
                                       (
                                       w
                                       )
                                       ≠
                                       g
                                       (
                                       w
                                       )
                                       }
                                    
                                 
                                 ,
                              
                           
                        
                     where 1{x} equals 1 if x is true, and 0 otherwise. Alternatively, the symmetric difference with respect to the multiset W of binary words is:

                        
                           
                              
                                 
                                    Δ
                                    W
                                 
                                 
                                    (
                                    f
                                    ,
                                    g
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    1
                                    
                                       {
                                       f
                                       
                                          (
                                          
                                             w
                                             i
                                          
                                          )
                                       
                                       ≠
                                       g
                                       
                                          (
                                          
                                             w
                                             i
                                          
                                          )
                                       
                                       }
                                    
                                 
                              
                           
                        
                     Our goal is to find the coherent classification g that is closest to the given one f, with respect to the multiset W, respecting a given level of inspection α ∈ (0, 1), that determines the fraction of containers to be inspected. The Coherence Problem is formulated as follows:

                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          min
                                          
                                             g
                                             ,
                                             I
                                          
                                       
                                    
                                    
                                       
                                          
                                             Δ
                                             W
                                          
                                          
                                             (
                                             f
                                             ,
                                             g
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                       
                                    
                                    
                                       
                                    
                                 
                                 
                                    
                                       
                                          f
                                          (
                                          w
                                          )
                                       
                                    
                                    
                                       
                                          ≤
                                          f
                                          
                                             (
                                             
                                                w
                                                ′
                                             
                                             )
                                          
                                          ,
                                          ∀
                                          
                                          w
                                          ≤
                                          
                                             w
                                             ′
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             ∑
                                             
                                                w
                                                ∈
                                                W
                                             
                                          
                                          
                                             1
                                             
                                                {
                                                g
                                                (
                                                w
                                                )
                                                >
                                                I
                                                }
                                             
                                          
                                       
                                    
                                    
                                       
                                          ≤
                                          α
                                          |
                                          W
                                          |
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (3)
                           
                              
                                 
                                    
                                       I
                                    
                                    
                                       
                                          ∈
                                          [
                                          r
                                          ]
                                       
                                    
                                 
                              
                           
                        
                     In words, coherence is introduced to the classification f provided by the operator (Constraint 1), meeting at the same time a certain level of inspection α (Constraint 2). Decision variable I plays the role of a threshold, where the containers to be inspected w must respect the inequality g(w) > I. Constraint 3 states that the threshold is an arbitrary integer in the set [r].

The reader can appreciate that the Coherence Problem does not involve misclassification probabilities, in contrast to most previous works in the area (Anand et al., 2006; Boros et al., 2009; Candy, 2013; Madigan et al., 2007; Stroud, 2003; Young, 2010).

In this section we will propose an algorithm to address the Coherence Problem in its most general formulation. Even though it is more sophisticated than averaging or statistical mode, as a result we will have a coherent solution that meets the levels of inspections that must be met in real-life applications.

As stated before, any arbitrary container is identified with a binary word 
                        
                           w
                           =
                           
                              d
                              1
                           
                           …
                           
                              d
                              n
                           
                           ,
                        
                      
                     di
                      ∈ {0, 1}. A classification is a function g: {0, 1}
                        n
                      → [r]. The main reason to return a function g with range in the same set [r] is that the symmetric difference ΔW
                     (f, g) can be dynamically compared by new functions f and multisets W offered by customs operators. Furthermore, containers classified on-line can be added to the training data in the future (adding the concept of closed-loop or feedback in our control system). TreeCommittee receives the multiset W, classification f: {0, 1}
                        n
                      → [r], a level of inspection α and returns a coherent classification g and threshold I.
                  

A key element is to translate the problem into 
                        
                           r
                           −
                           1
                        
                      binary sub-problems. This is where it is possible to exploit the knowledge provided from prior works in the field, covering structures of binary decision trees, logics in normal form, heuristics and minimization. Precisely, Convert(W, f, i) receives a set of binary words in its first argument, a function f: {0, 1}
                        n
                      → [r], a positive integer 
                        
                           i
                           ∈
                           {
                           1
                           ,
                           …
                           ,
                           r
                           −
                           1
                           }
                        
                      and returns the binary function gi
                     : W → {0, 1} such that 
                        
                           
                              g
                              i
                           
                           
                              (
                              w
                              )
                           
                           =
                           
                              1
                              
                                 {
                                 f
                                 (
                                 w
                                 )
                                 >
                                 i
                                 }
                              
                           
                        
                      (Line 2). The heart of TreeCommittee is Function OptimizeBDT, that is applied sequentially to each function gi
                      during for loop (Line 3). It returns a binary decision tree that is equivalent to a coherent function (related with the input function). The output g is precisely a Multi-Tree Committee. It combines the opinion of the tree-committee 
                        
                           
                              {
                              
                                 T
                                 i
                              
                              }
                           
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              r
                              −
                              1
                           
                        
                      in a simple fashion: the risk is the number of risky opinions from the trees, or sum risk, plus one (Line 5). During the block of Lines 6–14 the threshold I is found. An auxiliary variable Iaux
                      is iteratively increased, until the level of inspection is not met. Then, the correction 
                        
                           I
                           =
                           
                              I
                              
                                 a
                                 u
                                 x
                              
                           
                           −
                           1
                        
                      takes place in Line 14. Both decision variables (g, I) are returned correspondingly in Line 15.

                        Remarks
                        
                           
                              
                                 1.
                                 The range of g is precisely [r] as desired, since Ti
                                    (w) ∈ {0, 1}, for all 
                                       
                                          i
                                          ∈
                                          {
                                          1
                                          ,
                                          …
                                          ,
                                          r
                                          −
                                          1
                                          }
                                       
                                    .

The functions gi
                                     are defined in the multiset W, but in the whole set {0, 1}
                                       n
                                    .

Moreover, functions gi
                                     may be non-coherent.

A sum of coherent functions is coherent. Therefore, the output committee function g inherits the monotonicity of its terms Ti
                                    .

As a consequence, OptimizeBDT should introduce coherence to the input function of its third argument (i.e. gi
                     ), extend its domain and translate it to an equivalent binary decision tree. That tree will be further optimized by means of a local search and rewritten to minimize the number of questions, inspired in parallel-series minimization of logical functions (Young, 2010).
                  


                     Coherence receives a (possibly incomplete) binary function g and returns a coherent function g
                     1 with the same domain. Consider the partially ordered set 
                        
                           R
                           =
                           (
                           
                              
                                 {
                                 0
                                 ,
                                 1
                                 }
                              
                              n
                           
                           ,
                           ≤
                           )
                        
                     . Coherence uses the relation in the subset W inherited by R, and explores each maximal chain. If during that process there are two words w ≤ w′ with 
                        
                           g
                           
                              (
                              w
                              )
                           
                           =
                           1
                           >
                           g
                           
                              (
                              
                                 w
                                 ′
                              
                              )
                           
                           =
                           0
                           ,
                        
                      then g(w) is set to 0. The process is finite, and the result is a coherent function g
                     1. Analogously, Complete extends g
                     1 preserving coherence (iteratively in each chain by means of Zorn’s Lemma), and returns g
                     2. If a certain word w not in W has some lower bound set to 1, then 
                        
                           
                              g
                              2
                           
                           
                              (
                              w
                              )
                           
                           =
                           1
                        
                     . If it has an upper bound set to 0, then 
                        
                           
                              g
                              2
                           
                           
                              (
                              w
                              )
                           
                           =
                           0
                        
                     . Otherwise, if w is not comparable with any element in W, we set 
                        
                           
                              g
                              2
                           
                           
                              (
                              w
                              )
                           
                           =
                           0
                        
                     .

Once the complete coherent function g
                     2 is obtained, a translation to a binary decision tree takes place (Line 3). In order to carry-out the translation, a canonical reduced representation of logical functions is used, by means of an ordered binary decision diagram (OBDD), following recommendations from Bryant (1992). Function Translate works in three stages. These stages are illustrated one-by-one with an example (the reader can find properties of OBDDs and a thorough overview in Bryant (1992)). Consider the input function g from Table 1
                     .


                     Fig. 1
                      shows an equivalent complete binary-tree representation of g, where the output values 0 or 1 are written in blocks. Observe that solid external links are used when the sensor returns an affirmative answer, while negative answers are represented by external dashed links. In the second stage, internal nodes are identified whenever they have the same answer (i.e. the same external nodes), as illustrated in Fig. 2
                     . Finally, in the third stage redundant questions are deleted (see Fig. 3
                      for the application in the example). These stages are iteratively applied, until no modification is feasible (in the example the process is complete).

A naive local search is included in Line 4, where two questions (nodes) are swapped whenever the solution is both feasible and has lower symmetric difference with the given function.

Finally, a SpeedUp process takes effect, inspired in prior work of Young (2010). SpeedUp does not change the logical value of the input tree T
                     2, but just rewrites the sequential order of the questions. Precisely, we write the equivalent logical value for T
                     2 with a normal form 
                        
                           
                              T
                              2
                           
                           =
                           
                              ∨
                              
                                 i
                                 =
                                 1
                              
                              m
                           
                           
                              (
                              
                                 ∧
                                 
                                    j
                                    =
                                    1
                                 
                                 r
                              
                              
                                 φ
                                 
                                    i
                                    j
                                 
                              
                              )
                           
                           ,
                        
                      where each φ
                        ij
                      assumes a possible value dk
                      or its negation 
                        
                           
                              d
                              k
                           
                           ¯
                        
                      for some 
                        
                           k
                           =
                           1
                           ,
                           …
                           ,
                           n
                        
                     . Both operations of disjunction (∧) and conjunction (∨) are commutative. Therefore, we can commute the order and the logical result is unaffected, but the computational effort (for instance, the number of questions) can be reduced. For each sensor, the probabilities 
                        
                           
                              p
                              i
                           
                           =
                           P
                           
                              (
                              
                                 d
                                 i
                              
                              =
                              1
                              )
                           
                        
                      can be estimated with the statistical average, and 
                        
                           
                              q
                              i
                           
                           =
                           1
                           −
                           
                              p
                              i
                           
                        
                     . Since in this problem the costs ci
                      of the sensors are similar, we fix 
                        
                           
                              c
                              i
                           
                           =
                           1
                        
                     . The least frequent clauses of T
                     2 in the set W (concretely, the less frequent events of the set 
                        
                           
                              {
                              
                                 ∧
                                 
                                    j
                                    =
                                    1
                                 
                                 r
                              
                              
                                 φ
                                 
                                    i
                                    j
                                 
                              
                              }
                           
                           
                              j
                              =
                              1
                              ,
                              …
                              ,
                              r
                           
                        
                     ) appear first, whereas the most frequent literals φ
                        ij
                      of each clause appear first. To summarize, Function SpeedUp rewrite the input tree exploiting the fact that the operations ∨ and ∧ are commutative, in order to minimize the computational effort in the evaluation.

The customs operators from Administración Nacional de Puertos (ANP) provided us a classified training data of 
                        
                           |
                           W
                           |
                           =
                           1433
                        
                      labelled containers in order to design a port-of-entry inspection algorithm with a level of inspection 
                        
                           α
                           =
                           0
                           ,
                           02
                        
                     . The labels accept 
                        
                           r
                           =
                           3
                        
                      possibilities according to their expertise, where 1 means low risk, 2 medium risk and 3 represents the highest risk.

We summarize from our analysis from Sections 3 and 5
the following three solutions, and the corresponding terminology:

                        
                           •
                           Average-and-rounding rule, f
                              1, is the best inspection policy for the Ideal Approach, when the mean square error is being minimized.

Mirror solution, f
                              2, is the best inspection policy for the Decision Problem, when the symmetric difference is being minimized.


                              TreeCommittee, denoted by g, is a feasible solution for the Coherence Problem, where the solution meets both coherence and a desired level of inspection.

The operators suggested us to use 
                        
                           n
                           =
                           6
                        
                      risk-indicators, that we will label as sensors, using the classical terminology, with output 
                        
                           w
                           =
                           
                              d
                              1
                           
                           
                              d
                              2
                           
                           …
                           
                              d
                              6
                           
                           ,
                        
                      being di
                      ∈ {0, 1}. These sensors take the training data and find the output di
                      by means of a statistical analysis, reflecting anomalies with high risk. For the sake of data privacy, the adjustment of the sensors and their thresholds is excluded (in fact, they return numerical values instead of binary ones). However, we followed a traditional optimization technique by means of a discretization of the n-dimensional cube, in order to find thresholds and translate real values into binary ones (Graneri et al., 2015).

As a pre-processing stage, we studied the correlation between each indicator di
                      and the given classification. We excluded one indicator from our study, since its output was consistently null for all containers in the training data (as a consequence, a positive answer from this sensor would mean an immediate manual inspection). Additionally, by rank-correlation and independent tests we could identify another indicator that has weak correlation with the given classification. From previous observations, we work with four risk-indicators.

Incidentally, Madigan suggests optimal solutions when 
                        
                           n
                           =
                           4
                        
                      (Madigan et al., 2007). However, Madigan’s methodology is not applicable for this scenario, since we do not have historical information of false positives and negatives in order to estimate the misclassification probability.


                     Table 2
                      shows the discrepancy between Mirror solution and the labels provided by customs operators 
                        
                           L
                           =
                           {
                           
                              l
                              1
                           
                           ,
                           …
                           ,
                           
                              l
                              1433
                           
                           }
                        
                     . Observe that the main diagonal represents the number of matchings between Mirror and the labels, while the sum of the remaining entries is the symmetric difference.

Observe that Mirror classifies 
                        
                           390
                           +
                           581
                           +
                           23
                           =
                           994
                        
                      containers correctly out of 1433, so 
                        
                           
                              Δ
                              W
                           
                           
                              (
                              
                                 f
                                 1
                              
                              )
                           
                           =
                           439
                        
                     . From Proposition 1, we know that Mirror presents the lowest symmetric difference. However, as an ideal approach, it does not meet coherence nor level of inspection of 2 percent.

We know that our TreeCommitee solution will present lower matchings than Mirror, since the Coherence Problem is multi-constrained (see Table 3
                      for details). However, in order to have a major understanding of its performance it is worth to have a closer look of its classification in terms of the labels of specific words, coherence and level of inspection.

We implemented TreeCommittee in Matlab and injected the given classification W with labels, with a running time close to one minute in a home-PC. We obtained the binary trees T
                     1 and T
                     2 illustrated in Figs. 4
                      and 5
                      respectively, together with the output classifier g from Table 4
                     .

The first tree penalizes more cases than the second-one. This is reasonable, since the corresponding input functions g
                     1 and g
                     2 of OptimizeBDT respect the inequality g
                     1 ≥ g
                     2. This is a strong indication of consistency from the tree-building block, since the level of inspection of T
                     2 is lower than one of T
                     1. Constraint 2 states that the number of words w ∈ W such that g(w) > 1 must not exceed 
                        
                           ⌊
                           α
                           |
                           W
                           |
                           ⌋
                           =
                           ⌊
                           0
                           ,
                           02
                           ×
                           1433
                           ⌋
                           =
                           28
                        
                      elements. The number of containers w ∈ W such that g(w) > 1 are precisely the ones with a positive answer of some binary tree (equivalently, the rows from Table 4 such that g(w) > 1), and represents 
                        
                           27
                           /
                           1433
                           ×
                           100
                           =
                           1
                           ,
                           88
                        
                      percent, respecting the level of tractability accepted by the dynamism of our national port (fixed in 2 percent).

There were only seven real containers in the training data that have been classified with maximum risk 3, since those containers were common to both trees, representing a level of inspection of 
                        
                           7
                           /
                           1433
                           ×
                           100
                           =
                           0
                           ,
                           488
                        
                      percent. According to the coherence-guided process, the most risky word 
                        
                           w
                           =
                           1111
                        
                      is assigned the maximum risk (
                        
                           g
                           (
                           1111
                           )
                           =
                           3
                        
                     ), while 
                        
                           w
                           =
                           0000
                        
                      has minimum risk (
                        
                           g
                           (
                           0000
                           )
                           =
                           1
                        
                     ). There was exactly one container with maximum risk in the training set, and 
                        
                           f
                           (
                           1111
                           )
                           =
                           3
                        
                      accordingly. There were exactly six containers that present the word 
                        
                           w
                           =
                           0111
                           ,
                        
                      and respect 
                        
                           g
                           (
                           0111
                           )
                           =
                           f
                           (
                           0111
                           )
                           =
                           3
                        
                     .

The words with intermediate classification represent a mass of 20 containers. Both words 
                        
                           w
                           =
                           1010
                        
                      and 
                        
                           w
                           =
                           1011
                        
                      occur exactly in two containers each, and they have been classified with intermediate risk by both inspection policies: 
                        
                           g
                           (
                           1010
                           )
                           =
                           f
                           (
                           1010
                           )
                           =
                           2
                        
                      and 
                        
                           g
                           (
                           1011
                           )
                           =
                           f
                           (
                           1011
                           )
                           =
                           2
                        
                     . We appreciate a reasonable matching, regarding our original assumption that the target objective is a logical function. The case with highest gap between the labels and Multi-Tree Committee occurs in the binary word 
                        
                           w
                           =
                           1101
                        
                     . This word appears 16 times in the set W and 
                        
                           g
                           (
                           1011
                           )
                           =
                           2
                           ,
                        
                      but it was assigned 8 times the maximum risk, 7 times intermediate risk and 1 time the lowest risk, by customs operators. This gap suggests the need to have a higher number of rules. Additionally, the operators wish to include randomness to the current algorithm, in order to try an optimistic manual inspection of “non-risky” containers from time to time.

@&#CONCLUSIONS@&#

In a real-world port-of-entry inspection problem, misclassification probabilities are hard to estimate, and customs operators use their experience but sometimes lack of a theoretical foundation. However, to the best of our knowledge, prior works assume perfect knowledge of these probabilities, which is not our case. Additionally, our context is hostile, since the training data is inaccurate.

In this article, a Coherence Problem has been introduced, and a Multi-Tree Committee algorithm has been developed in order to define a port-of-entry inspection policy. Both the model and its resolution are deterministic and easy-to-handle, which is a relevant aspect in practice.

We show that an arbitrary classification can be optimized in two aspects. The first is to introduce coherence in the decision, while the second is to develop a fully-automatic solution, saving time and human-resources. In a first ideal approach, an automatic solution is presented. Then, we introduce coherence to the previous solution.

The main benefits of Multi-Tree Committee are its adaptability to an arbitrary number of sensors n, classification range [r], and level of inspection, without a need of misclassification probabilities (whose estimation is non-trivial) and historical feedback, since the new classification can extend the training set.

Regarding these elements and the recommendations from the port operators, as a future work we want to contrast stochastic-based mechanisms with respect to the current development, and tune our algorithm here described adding randomness, in order to cope with purely deterministic attacks.

@&#ACKNOWLEDGMENTS@&#

This work has been partially supported by Administración Nacional de Puertos (ANP) and Dirección Nacional de Aduanas (DNA), from Montevideo, Uruguay. We express our most sincere gratitude to Franco Robledo for his support and effort in order to set-up the contract between Facultad de Ingeniería andAdministración Nacional de Puertos.

@&#REFERENCES@&#


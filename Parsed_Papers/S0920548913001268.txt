@&#MAIN-TITLE@&#A standard for developing secure mobile applications

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Most apps are developed without applying information security and best practices.


                        
                        
                           
                           The DoD recently published a standard for secure app development.


                        
                        
                           
                           The standard consists of 70 security controls for developing and vetting apps.


                        
                        
                           
                           This research explores app vulnerabilities and DoD's standard approach to them.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Mobile device security

Mobile application security

Application security

Cyber security

@&#ABSTRACT@&#


               
               
                  The abundance of mobile software applications (apps) has created a security challenge. These apps are widely available across all platforms for little to no cost and are often created by small companies and less-experienced programmers. The lack of development standards and best practices exposes the mobile device to potential attacks. This article explores not only the practices that should be adopted by developers of all apps, but also those practices the enterprise user should demand of any app that resides on a mobile device that is employed for both business and private uses.
               
            

@&#INTRODUCTION@&#

The United States Department of Defense (DoD) published the first publicly available standard that mobile applications (apps) can be developed by and tested against. The long-awaited standard enables DoD personnel to more safely use a variety of apps that will improve their mission performance, as well as to take advantage of apps to perform many tasks that cannot easily be accomplished on laptops. Unfortunately, in bringing mobile devices to the DoD workplace, the threat of data disclosure or an accidental or intentional bridge between a DoD network and the public Internet is significant. Because of the DoD's high security needs and the large volume of threats against its networks, the DoD cannot allow apps to be used without thoroughly vetting their functionality and analyzing their potential vulnerabilities.

Regardless of the stringent security measures practiced for mobility by the DoD, there are numerous attack surfaces on a smartphone or tablet. These attack surfaces appear in the form of the high volume of widely used apps. Each app represents a plethora of vulnerabilities not only for the device and all data on it but also for the networks to which the device is attached. Bringing a smartphone or tablet hosting a rogue app into a DoD building has the potential to compromise a DoD network in multiple ways, allowing an attacker to gain access through the many avenues a badly written or maliciously developed app offers.

To combat this, the DoD's Defense Information Service Agency (DISA) developed a standard that may be used not only for developing new apps but also for testing, vetting, and assessing existing apps. This will provide a considerable degree of protection through applying controls and best practices in use throughout the industry to reduce vulnerabilities. The standard, known as the Mobile Applications Security Requirements Guide [1] or the SRG, is available for public download from the Information Assurance Support Environment.

This paper discusses key technical highlights from the standard. Section 2 explores app vulnerabilities while Section 3 focuses on operating system (OS) vulnerabilities. Section 4 discusses cryptography concerns. Section 5 covers the security concerns not addressed in Sections 2, 3, and 4. Section 6 examines mobile device software testing and Section 7 briefly discusses related work in mobile security. Finally, Section 8 provides a conclusion for the paper.

One of the most common sources of vulnerabilities for mobile devices is the actual vulnerabilities in the apps themselves. This section discusses these vulnerabilities in the following categories: the app code, input handling, initialization, termination, and external code.

The app code itself is the primary source of most app vulnerabilities. The DoD requires that all parameters be initialized upon app startup to prevent any values that would potentially cause a frozen or unstable condition for the app, making the device more vulnerable and easier to exploit. Controlling code is also of great importance, so any source code that is never executed during runtime must not be included in an app unless the source code was provided by an approved third party.

App code must never include hardcoded references to external resources (e.g., an external IP address). Apps must not call functions that are vulnerable to buffer overflows. Race conditions in which the app becomes unstable must also be avoided. Finally, the app must not contain known malware; this may seem obvious, but the rate of app developers using freeware routines and libraries that contain known malware remains high.

A key distinguishing feature of apps relative to traditional desktop applications is that apps often have a much broader set of inputs. In traditional applications, the input usually consists of standard keyboard characters. In mobile apps, user input may also consist of swiping or tapping fingers on the display. Apps may also accept inputs from sensors on the device (e.g., a GPS radio, accelerometer, gyroscope, and ambient light sensor.) Ideally, all forms of input are considered in an information assurance (IA) assessment. However, the SRG currently considers only character inputs.

Traditionally, the inputs to a program are where weaknesses can be exploited, and an app is equally susceptible. When an app requires user input, the input character set must be defined and constrained. This means if the user is required to enter only numbers, then the app must define the input set to be in the range 0–9, rejecting all letters and symbols. An app that accepts undefined characters may experience unanticipated behaviors. Equally important, the input field must be designed to not be vulnerable to XML and SQL injection attacks. Injection attacks may result in an immediate loss of integrity of the data. If an app does not permit injection, then the risk of exploits from this form of attack is greatly reduced.

Format string vulnerabilities usually occur when invalidated input is entered and is directly written into the format string used to format data in the print style family of C/C++ functions. Format string vulnerabilities may lead to information disclosure vulnerabilities and may also be used to execute arbitrary code, so the SRG requires that apps must not be vulnerable to such conditions. If an attacker can manipulate a format string, this may result in a buffer overflow. If the app code does not contain format string vulnerabilities, then the risk of buffer overflows and other software exploits is significantly mitigated.

The behavior of an app must be controlled within limits to prevent exploitation by a third party when the app fails to initialize. If an app relies on external security functions such as software modules that encrypt data, then the app must shut down, reset, or perform some safeguard action if a security module or function is unavailable. This requirement applies at app startup and during runtime. While mobile apps primarily rely on mobile OS security controls, a mobile app may contain security functions that enable the device and user to operate in a secure manner.

For example, the mobile app may operate its own cryptographic modules for data at rest and data in transit. If these modules are not present, then all data, the device, and the network would be at risk to exposure and intrusion from an unauthorized user if the app does not prevent its own execution. This measure mitigates risk and exposure from being compromised due to failed or disabled security modules. When the app shuts down it must cease running and not just deny services to a user. Other response actions might include writing an entry to the audit log, notifying the user, or limiting access to particular app features, such as the ability to export data.

For many mobile apps, the only state that is known to be compliant is the initial state, because there is no documented security policy regarding state transitions. An app could be compromised, providing an attack vector to the app and OS if shutdown and aborts are not designed to keep the app in a secure state. DoD therefore requires that an app fails to an initial state if it unexpectedly terminates, thus returning the app and device to the secure state they were previously in. An app maintains a secure state when there is strong assurance that each of its state transitions is consistent with the app's security policy. If the app fails without closing or shutting down processes or open sessions, authentication and validation mechanisms do not provide sufficient protection against unauthorized access to the app and all stored data. Securing the app to its initial level of security in the event the app crashes or terminates will mitigate the threat of an unauthorized user taking control of the device and accessing the app and stored data, compromising integrity and confidentiality.

The SRG requires that upon termination, each app remove all temporary files and tracking cookies it created during the session. Temporary files left on the system after an app has terminated may contain sensitive information, including authentication credentials or session identifiers that would enable an adversary to re-launch the app, gain unauthorized access to resources, or otherwise breach the confidentiality or integrity of the data stored on the device. Removing such files when an app terminates greatly mitigates the risk of this type of attack. Finally, any memory blocks that were used to store and process sensitive data must be cleared or overwritten to completely eradicate any trace of that data. Unless an app does this, the possibility exists for an attacker to crash the app, then analyze a memory dump of the app for sensitive information. Clearing memory will ensure that the app can operate more securely, with greater protection applied to sensitive data that will be properly removed when no longer required.

Finally, in the area of app termination, the SRG also covers transaction-based issues. Transaction-based systems must have transaction rollback, journaling, or technical equivalents implemented to ensure that the system can recover from an attack or faulty transaction data, preventing denial of service attacks.

Mobile code is code downloaded from a remote source and executed on the device without user direction. Typically, mobile code is executed within web browsers. However, some apps may have the capability to execute such code in a similar fashion to a web browser. This poses a significant IA risk because such code would not have been reviewed and could perform unauthorized functions. The SRG requires that all apps must comply with the DoD Mobile Code Policy which essentially means the app must validate the signature on all ActiveX and script languages interpreted at the OS command level. This is also true for code that has full functionality to the services and resources of a device such as Java mobile code and the various scripting languages running within the confines of a browser. DoD is assuming that a level of security exists through acknowledging a valid digital signature, which implies that a trusted source created the code, and that it contains no malware. If no signature is present or the signature could not be verified, then the app must not execute it. Further to this, DoD requires that any mobile code in the app not only be signed, but also be mobile code that has already been categorized. Any uncategorized code, even though potentially safe, must not be used.

Embedding interpreters in an app to invoke prohibited code will expose the device and stored data to many forms of malicious attack. Prohibited code is intentionally not used in order to maintain the security and integrity of the device and all stored data. The SRG therefore requires that the app code must not include interpreters for any prohibited code as well.

Before external code that the app downloads during runtime may be executed, the DoD requires the user to (i) be notified that the code is being downloaded and (ii) be given the option to authorize execution of this code. Finally, the DoD requests that any APIs or external resources called or invoked must only be done so if the app determines these particular resources are required.

Operating system (OS) vulnerabilities can often cause significant security problems for app usage. This section discusses OS vulnerabilities grouped into the following categories: file permissions, geolocation, shared resources, time source, and OS privileges.

The SRG requires that an app does not change the file permissions for any files other than those dedicated to the app's own operation. Similarly, the app must not enable other apps or non-privileged processes to modify software libraries. The need to prevent the app from assuming OS-level privileges when managing files is important, because locking a file or preventing it from being backed up can cause a denial of service that prevents access to the file or its loss. Therefore, the DoD requires that an app must not have the ability to lock or set permissions on app files such that the OS or an approved backup app cannot copy the files.

The SRG considers the individual user or operative when using location-based apps. The SRG requires that any app using GPS and location-based services must not forward the user's location to an external resource unless the user explicitly acknowledges that this is taking place and knows where the data is going. When sensor data is either recorded locally or sent to a remote server, the potential exists for an adversary to obtain sensitive information that could be used to harm the user or compromise information systems. In particular, when location data is forwarded, the user may be physically targeted. User safety and mission assurance risks are mitigated when sensor data is only collected or forwarded when expressly authorized by the user.

To protect data from a number of vulnerabilities that could lead to loss of integrity and confidentiality, the app must not share persistent memory with other apps, nor must it read from OS resources unless necessary to perform app functions.

Control over app behavior also means that the app must use the mobile device's system time for its authoritative time source. Synchronizing with authorized timing sources enables an app to perform a number of important back-office functions that require synchronization between the app, the device, the network, and the back office infrastructure. Without this synchronization, a number of issues could arise concerning control functions that must be accomplished in short time frames, as well as the incorrect time-stamping of events.

To gain an OS privilege is to gain root access in the traditional computing scenario. The same applies to apps, so each app must be controlled in the rights and privileges it has, in the event it is maliciously accessed and used as a proxy to cause further damage to the device through reading sensitive data, executing unauthorized code, etc. Then additional attacks on the system and DoD networks may be possible. Therefore, the DoD requires apps to implement automated mechanisms to enforce access control restrictions which are not provided by the OS.

An app that operates with the privileges of its host OS is vulnerable to integrity issues and escalated privileges that would affect the entire platform and device. To that end, DoD also requires that the app must not request or assign OS privileges or modify OS parameters unless necessary to perform app functions, and the app must not execute as a privileged OS process to perform any app functions. If the app is able to obtain OS privileges greater than necessary for proper operation, then an adversary that can breach the app has access to these additional privileges and can perform unauthorized functions. Prohibiting an app from assigning itself unnecessary privileges greatly mitigates the risk of unauthorized use of those privileges.

Cryptography is imperative as a security control, but improper use of cryptography can create exploitable vulnerabilities in mobile devices and apps. This section looks at cryptography-related vulnerabilities involving both general practices and certificates/digital signatures.

Typically, any cryptography carried out is a function of the OS; most apps can transparently leverage the OS's cryptographic services without having to replicate any code or functionality. For example, the SRG does not necessarily require apps to encrypt data at rest or call a cryptographic API because the OS may be able to perform this function for all data at rest or in transit. However, in some cases, the app may use its own cryptographic module or explicitly call external cryptographic modules.

The SRG requires the use of Class 3 certificates, which undergo an independent verification and check of identity and authority, performed by the issuing certificate authority. Apps involved with asymmetric keys must use approved Class 3 certificates or prepositioned keying material and hardware tokens that protect the user's private key. Networks and apps not using Class 3 certificates are vulnerable to a variety of malicious attacks that would essentially allow unauthorized access to and intrusion in a network. The use of approved Class 3 certificates assures authentication, message, data and content integrity, and confidentiality encryption.

Symmetric and asymmetric cryptographic keys must be managed according to approved processes using approved technology to ensure that malicious intruders do not take advantage of any network resource exposure that may occur as a result of non-standard practices and tools being applied. Therefore, apps involved in the production, control, and distribution of both symmetric and asymmetric cryptographic keys must use NIST approved or NSA-approved key management technology and processes. If non-standard practices are applied to key management, then the DoD is potentially vulnerable to attack from adversaries who are able to exploit weak encryption keys.

App and app users themselves generate information throughout the course of a session and this, along with app-specific configuration data needs to be protected. Configurations and/or rule sets for firewalls, gateways, intrusion detection/prevention systems, and filtering routers and authenticator content are examples of system information likely requiring protection. Thus, for data at rest, the DoD requires the app employs NSA-approved cryptography to protect classified information. Again, this could be achieved through the OS, but the app may provide that functionality if the OS cannot meet the requirements.

Applying public key infrastructure (PKI) adds several layers of security to a device and network. In order to use PKI effectively, the correct chain of trust must be in place. With a chain of trust, the top entity, a Certification Authority (CA) starts the path that then proceeds through a number of intermediate certificates up to a trusted root certificate, typically issued by a trusted CA. The DoD requires any app that authenticates remote resources using PKI certificates to verify that the certificate has been signed by an authorized CA, has not expired, and has not been revoked. Path validation is necessary for a relying party to make an informed trust decision when presented with any certificate not already explicitly trusted.

Similarly, if the app processes digitally signed data or code, it must validate the digital signature, and this will also be accomplished using PKI. Whereas this may be common practice in a desktop environment, the speed and rate at which apps are developed means that crucial items in such areas as PKI can be missed either on purpose or through careless programming and design. The app that is using code whose digital signature cannot be validated opens the app and OS to many vulnerabilities; the data or code the app uses may contain malicious code that could gain root access and other escalated privileges, compromising the security posture of the device and the data on it.

Digital signatures are of prime importance in discerning between malicious code and that which originated from a trusted source. Simply put, using software that cannot be traced to a trusted source means the code may have been written by an untrusted source. The SRG requires that signatures are used and that the signatures themselves be created in accordance with defined standards, in this case the Federal Information Processing Standard (FIPS) 186-3 [2]. This includes digitally signing the app installation package, which can be used to authenticate that software comes from a trusted source before it is installed. The digital signature on the app installation code must identify the entity responsible for the app. This demonstrates that the signature was generated by a trusted source, otherwise it is possible that an adversary created a malicious app that has the appearance and utility of an app in current use.

This section addresses the security concerns not already addressed in Sections 2, 3, or 4. Specifically, this section covers security concerns involving network communications; audit, logging, and alerts; dual-persona devices; and classified data handling.

A device is most vulnerable when communicating; the very communication channel that is used during an app's operation is what will also be used by a malicious user who is attempting a man-in-the-middle attack or perhaps a replay attack. This is particularly true for wireless communications, which can be intercepted without having physical access to networks or their attached systems. The DoD has taken steps to mitigate the risks associated with accessing a network through a number of controls as follows.

The app must close any opened network ports at the end of the app session or after a period of inactivity as defined by the organization using the app. Ports that are not closed upon termination of an app or following a pre-defined period of inactivity leave the device vulnerable to exposure from attacks that exploit ports that remain open. As an example, wireless ports, such as Wi-Fi and Bluetooth, are vulnerable to an adversary in a war driving or blue snarfing/blue jacking scenario. In this event, the unauthorized user has the potential to access the device and compromise the stored data.

When data is exchanged between information systems, security attributes must be associated with this data. Security attributes are an abstraction representing the basic properties or characteristics of an entity with respect to safeguarding information, typically associated with internal data structures (e.g., records, buffers, files) within the information system, and used to enable the implementation of access control and flow control policies. Therefore, the SRG requires that all data leaving a device must possess a security attribute bound to the data it is transmitting. Applying this control assures that security attributes may be explicitly or implicitly associated with the information contained within the information system to support correct handling of the data according to its classification.

Unencrypted sensitive app data can be intercepted in transit and extricated or modified. Thus, the SRG asserts that all data transmission must employ cryptographic mechanisms preventing the unauthorized disclosure of information. It is recognized that the OS would generally provide the encryption function; however, the SRG allows the app to provide this functionality in the event the OS cannot provide a VPN that complies with DoD requirements.

If a wireless device authenticates on a network without using encryption to protect the authentication data, then the device is vulnerable to intruders who will perform either replay or man-in-the-middle and spoofing attacks, as well as many other attacks that take advantage of the lack of strong encryption. If the app controls other wireless device connections, it must employ bidirectional cryptographic authentication when communicating to and authenticating these wireless devices. Intruders who exploit these weaknesses can launch further attacks on other network components and attempt to gain control of the network. Bidirectional authentication greatly mitigates the risk that the app will allow connections from unauthorized devices and helps prevent remote devices from improperly connecting to a rogue network.

The SRG requires apps to provide a number of audit, logging, and alerting functions. The SRG requires the app to alert the OS or Mobile Device Manager (MDM) upon each instance of an app component failure. Such a failure leaves the app, mobile device, and stored data exposed to potential malicious activity. One component that may fail, yet leave the app operational, is a security module that provides encryption of all data at rest or in transit. Similarly, a module that labels data with the appropriate classification attribute could also fail, yet allow the app to continue to function. In these instances, the app is no longer able to protect itself to the same level of security when fully operational. These alerts can be used to initiate a fix or invoke incident response procedures.

The need to verify security functionality applies to all security functions and can be achieved through automated security tests of the app. When an app fails one of its tests, this indicates that the app is no longer able to protect itself to the same level of security. Therefore, the app is required to perform automated security testing and provide notification of any failed tests. Automated security tests may include checking the cryptographic hash of key app files, and verifying the presence of critical OS services, the presence of a VPN connection, correct file permissions, etc. The app is able to activate an alarm, log an event, and/or automatically notify the user a security test has failed, providing the user a greater level of security knowing that the app should stop being used.

Finally, though logging and alerting have great utility, IA controls can be defeated if the alerts themselves are not managed properly or contain too much data. Thus, the SRG requires that the app must not include sensitive information in system logs, nor must it transmit error messages to any entity other than the MDM, authorized audit logs, or the actual device's display.

In the context of mobile computing a “persona” is a domain on the mobile device that is subject to its own security policy. A mobile device with two personas can separate domains for personal and business activities, which could potentially include separating classified from unclassified data in a DoD context. Furthermore, dual persona relates to the concept of “Bring Your Own Device” (BYOD) in which personally owned equipment could be adapted to provide similar isolation.

Multiple-persona apps are those that can operate across multiple personas, allowing access to persona data as determined by organizational rules. For example, contact databases or calendar apps that handle multiple personas may be able to integrate data from the personal and business personas in a single view. If an app supports multiple personas, it must include the capability to isolate data from each persona even when they may be viewed together (e.g., by not permitting a user to cut and paste from one persona to another, or to save documents from one persona in a folder associated with another persona).

The IA concepts underlying multiple personas are very closely related to those applied to systems processing data at multiple levels of classification. However, the two should not be confused. If an app complies with requirements for multiple-persona apps, this does not render the app fit to handle classified data. DoD recommends organizations should approach multiple personas with caution and approve such capabilities on a case-by-case basis because there is significant risk that a compromised dual-persona app would disclose sensitive information. The SRG applies the following requirements to multiple-persona apps:
                           
                              •
                              The app must record a log entry when there is a failed attempt to improperly transfer data from one persona to another. Transferring data between domains exposes the data to both accidental compromise and physical attack. An unauthorized user could gain access to the OS or app through one of the domains. Similarly, sensitive data conveyed to a less-secure domain holds the potential to cause data exposure. Adding controls that prevent the transfer of data between security domains mitigates a number of IA risks. Furthermore, logging all failed attempts to transfer data between security domains enables the user and administrator to identify when there has likely been a security breach and take appropriate incident response measures.

Preventing access to domains outside of that which the user is operating in greatly mitigates the risk of unauthorized disclosure of sensitive data. The DoD requires each app to enforce a non-discretionary access control policy that prohibits a user from accessing sensitive data when operating in a persona not authorized for access to data classified at that level. This forces the correct domain to be used for the given security classification of the data being worked on.

An organization's policy can be applied and enabled through rules set up in software that satisfy the organization's operating requirements. The DoD requires that such capabilities are present in an app and therefore requires that it implements or incorporates policy filters that constrain data objects and structure attributes according to that organization's security policy statements. This control greatly mitigates the risk of unauthorized disclosure of sensitive data by incorporating policy that will prevent the user from transferring the data between domains inadvertently, unless he/she chooses to do so, fully aware of the action that is being taken.

A dual-persona device answers many issues that the concept of BYOD raises. However, one of the pitfalls with a dual-persona device is the danger of data crossing the security domains inadvertently. An additional risk with dual-persona devices is malware present in one persona migrating to another persona. In order to mitigate these risks, the SRG requires that an app using dual-persona devices identifies and authenticates both the persona from which data is being transferred and the persona to which data is being transferred before permitting the transfer.

Whether data is classified or sensitive, the SRG places stringent demands on its storage, processing, and transmission. In some instances, classified data may become mixed with less sensitive data. In this instance, the app must reclassify the aggregate data at the higher level, achieved through a data attribute. This also applies to any newly-created files and data streams. A classification attribute assures the data is correctly handled and processed according to its sensitivity. If the classification attribute is missing, then there is increased risk of data misclassification, which could result in a data spill.

The SRG also requires that apps that transmit data maintain the binding of classification attributes to information with sufficient assurance that the information/attribute association can be used as the basis for automated policy actions. Losing a data classification attribute bind or using a weak bind offers a high potential for this data to be misclassified once it has been received and further distributed, blending different classifications of data together. If the bind is weak, an adversary could modify it.

The SRG requires an app to allow the user of the mobile device to assign a classification level to any data the user creates. A classification attribute assures the data is correctly stored, transmitted, handled, and processed according to its sensitivity, greatly reducing the risk of misclassification and data spills.

Whenever the app displays any data to the mobile device's user, the data's classification must be displayed in human-readable form. The DoD is concerned about unlabeled and sensitive data that could easily be mixed with unclassified data, and also about misclassified data that could be transmitted on an unsecured network. Unless the app informs the user of the sensitivity of any data being worked with, the potential exists for a data spillage.

Data attributes for data in transit must themselves be protected against any malicious action, so the SRG requires that the app provides integrity protection for classification attributes. If integrity checks are not used to detect errors or manipulative action by intruders, there is no way to ensure the integrity of the app data as it traverses a network. The data classification attribute would be subject to manipulative action, which could lead to incorrect handling and distribution of the data upon receipt.

Within a system, data of varying sensitivity will exist and modification of the data classification must not be allowed. Therefore, the SRG requires that the app must not permit any classification attribute to be modified to a lower level of classification. This greatly reduces the risk of the data being inadvertently combined with non-sensitive data, creating a data spill.

Now that we've looked at all the major categories of vulnerabilities that affect apps, let's explore some of the major highlights regarding mobile device software testing. First, Section 6.1 compares mobile device software testing to traditional software testing. Next, Section 6.2 discusses testing involving app updates, and Section 6.3 briefly examines the testing performed by mobile app stores. Finally, Section 6.4 discusses alternative measures that can be taken against mobile app threats, besides app testing.

Significant differences exist between the testing of mobile device software and the traditional software typically found on desktops and laptops, including the following distinctions:
                           
                              •
                              Whereas laptops and desktops enjoy the luxury of 110V power sources and high-capacity batteries, the relatively limited battery lives in mobile devices means that apps must be written properly so that all unwanted functions are not used and only the minimum amount of memory space is addressed. Apps outside these limits have the potential to exhaust a mobile devices battery quicker than expected, potentially causing a denial of service. This is an important consideration for some users in mission-critical roles.

The obvious memory capacity differences between mobile devices and their desktop/laptop counterparts mean that code-efficient programming is imperative. Apps should be tested for this since an app with a large footprint can prevent other apps from storing any data they create and thus limit the utility of the device.

Mobile devices afford the user the ability to be permanently connected to any number of services, to include the Internet, a wireless carrier, and the GPS network. These services are reachable through the mobile device's Wi-Fi, Cellular, and GPS module. Each of these services provides a means by which the device can be compromised and indicates that mobile devices are susceptible to a very different class of threat when compared to their desktop and laptop counterparts. Therefore, apps must be tested for the different forms of exposure a mobile device faces.

Most apps are free or inexpensive, built by developers adhering to no particular software development standard. It is therefore of great importance that such apps are tested for the ability to carry out rogue actions such as uploading the address book contents or GPS location to a third party server. An app may contain no malware, but may well be programmed to transmit a user's address book, location, and any personally identifying information to a pre-determined location. This is something that a laptop software package would almost certainly not do, and is what typically sets the two apart. The salient point being raised here is that the risk of malware may not necessarily be the issue at stake with a mobile device; the app itself might well be the Trojan or the virus, willingly downloaded by the user because it was free and performs functions the user desires.

Mobile devices feature different screen sizes and resolutions, which means the same app either has to be written for each screen type or has to be able to work across the many different options available.

An additional area of concern for testing is the app update. When desktop or laptop software is modified to correct an issue or improve functionality, a new release is made available to licensed owners with a full description of what changes took place. With apps, it is similar; users are told what to expect with the new version and offered the option to download it from the mobile app store. The difference is that the app in all probability was hurriedly written and then updated using a non-standard approach to software development. This means that it cannot be determined what effects the new code will place on the remainder of the program and if it has the potential to cause instability issues. Each and every app update should be tested unless it can be proven and documented that the update does not impact the user and the use cases. Since this level of information is largely incompatible with the approach taken by most app developers, the end user's organization would be wise to consider testing the app against a standard.

Although some form of testing takes place before an app is made available on a mobile app store, the volume of apps storefront operators process is very high, so the depth of app testing or assessment cannot possibly reach the depth of the standard described in this article. The DoD standard described requires strict control over many areas, to include digital signatures from trusted developers, mobile or external code that carries advertising, and the display of warning banners for the user to be notified of such events as the GPS location being transmitted. These items alone serve to illustrate the differences and depth of assessment that would take place between the various mobile app stores and the requirements featured in this paper.

Although applying a standard for developing and testing an app is recommended, some threats can be mitigated through alternative means. Sandboxing an app by wrapping its code in a protective layer of code is one approach available through a number of vendors. The sandbox approach essentially limits inbound and outbound communications from the app with certain mobile device interfaces. Sandboxes are capable of encrypting data at rest, performing firewall functions, limiting copy and paste functions, and even geo-fencing a device by shutting off access to the GPS if a certain location boundary is breached. The sandbox also serves as a filter for controlling the type and content of messaging to and from an app. This means that a user or administrator can control an app's access to the address book or stored emails. Thus, an app that was developed by third parties could conceivably be loaded on a device, placed in the sandbox, and used with full knowledge of what level of protection is in place.

Prudence and best practices, however, would dictate that adherence to the NIST Special Publication 800-53 [3] control-based SRG described in this paper would assure users of a safer operating environment. There will always be residual risk from using any app loaded on a mobile device. Though there are many means available to protect the mobile device, it is important to understand that a risk-managed approach towards app security is the minimum that should be done. Applying the DoD standard at the minimum will indicate the areas of risk, giving the user the opportunity to decide if the risk is manageable or if it is simply too high.

A considerable amount of work has been carried out in the industry in the arena of mobile security, both defensive and offensive in nature. Of interest is the dire need to develop and maintain standards that can be used for developing apps securely. One prime example of this draws attention to the iPhone Stealth Airborne Malware project [4] that created malware using the very tools that are used to develop apps. There are multiple tools available that enable an app developer to create apps, even test them during the development stage. It should leave no question as to whether an external standard should also be applied that will provide the coverage needed to ensure the app is being developed to the highest possible standard of security. Many tools and services exist that perform some level of testing to pre-determined scripts. These work in conjunction with subject matter experts who observe the app's source or binary code as a measure to counter the false positives and negatives that users of these tools often experience.

Ultimately, user privacy is the end goal in applying the standards to mobile device app development. User privacy assurance stems from the standard tenets of information assurance — confidentiality, integrity, and availability. It is questionable as to whether user privacy is an item that is approached with the same vigor applied to the functionality of an app along with its user experience, an aspect that is used to judge all apps by. The manner in which an app is delivered and experienced is, after all, the most important aspect of mobility [5]. Thus the push and pull of functionality, usability, and security tend to favor the former two over the latter in favor of popularity and user experience which leads to the many privacy issues highlighted in this article.

Apps that prove to be popular with users are certainly potential test cases that could explore the real vulnerabilities such apps expose the user to. Whether it is a third party app that was rushed to market without secure standards applied to its development or an app driven by rapid revenue for a developer, it remains to be seen just how many users have been compromised without knowing it and how many service providers were caught flatfooted with security issues as they sprinted towards revenue.

@&#CONCLUSIONS@&#

The SRG is very stringent in certain areas and covers many aspects of mobile app vulnerabilities, though not all possible threat scenarios. Subsequent versions of the SRG will have greater depth and scope in reaction to more devices and apps becoming available on the marketplace, and thus in concert with the wider adoption of mobile devices by the DoD and US Government. It is questionable as to whether any app currently available to the public is compliant with the standard. However, it could be guaranteed that future apps be compliant if the developers adopted the SRG which would certainly permit the app to be available for download from a DoD app store.

Creating a standard for software security also means that testing take place in order to assess compliance, which is not an exact science. Mobile software assurance is a complex discipline. The app environment differs substantially across mobile OSes, which themselves are experiencing rapid changes. Automated code scanning or simulation tools are available, but they provide only a partial assessment. Reviewers will almost always need to interpret the output of these tools, compare results against the intended capabilities of the app, and perform manual follow-up investigations to verify compliance with the specific standard's requirements. Consequently, a high degree of skill is required in performing reviews of apps, entailing a strong understanding of:
                        
                           •
                           Mobile OSes on which the apps run

Programming languages used to develop the apps

Mobility-related IA vulnerabilities

Available features and limitations of static and dynamic program analysis software

Reverse engineering compiled binaries

Emulation of mobile app software.

In most cases, this understanding should be based on several years of experience in software assurance, mobile systems, and related areas, which also rely on resources to include the following:
                        
                           •
                           Test devices

Mobile OS emulators

Malware scanning tools

Test cases and test case generators

Static and dynamic program analysis software

Software to derive source code from app binaries

Network protocol analyzers

Network and computing infrastructure to support the above, including Internet connections to reach cloud-based services for some forms of testing.

In some cases, reviewers must have access to cloud-based services to perform analysis. When Internet access is required, the assessment laboratory cannot be certified as an isolated local area network. Organizations seeking to perform IA evaluations of mobile apps should either possess or obtain such capabilities in preparation for the evaluations.

@&#REFERENCES@&#


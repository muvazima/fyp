@&#MAIN-TITLE@&#Effect of alternative video displays on postures, perceived effort, and performance during microsurgery skill tasks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Compared with microscopes, neck posture was more neutral and neck movements were more frequent on the video displays.


                        
                        
                           
                           Task completion times didn’t differ between 2D and 3D, but times were slower on the video displays than the microscope.


                        
                        
                           
                           Video displays reduce posture constraints and may reduce musculoskeletal symptoms and fatigue in microsurgery.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Microsurgery displays

Posture patterns

Biomechanics

@&#ABSTRACT@&#


               
               
                  Physical work demands and posture constraint from operating microscopes may adversely affect microsurgeon health and performance. Alternative video displays were developed to reduce posture constraints. Their effects on postures, perceived efforts, and performance were compared with the microscope. Sixteen participants performed microsurgery skill tasks using both stereo and non-stereoscopic microscopes and video displays. Results showed that neck angles were 9–13° more neutral and shoulder flexion were 9–10° more elevated on the video display than the microscope. Time observed in neck extension was higher (30% vs. 17%) and neck movements were 3x more frequent on the video display than microscopes. Ratings of perceived efforts did not differ among displays, but usability ratings were better on the microscope than the video display. Performance times on the video displays were 66–110% slower than microscopes. Although postures improved, further research is needed to improve task performance on video displays.
               
            

@&#INTRODUCTION@&#

Work-related musculoskeletal pain, fatigue, and discomfort can affect both the comfort of surgeons and their ability to complete surgical tasks; yet, the reported prevalence of musculoskeletal symptoms in the neck, back, and shoulders is as high as 87% among surveyed laparoscopic, ophthalmic, and general surgeons (Davis et al., 2014; Capone et al., 2010; Park et al., 2010; Sivak-Callcott et al., 2011; Szeto et al., 2009; Wauben et al., 2006). Furthermore, a survey of 130 ophthalmic surgeons who frequently used magnification, e.g., loupes and microscopes, showed that 9.2% of surgeons stopped operating due to neck pain (Sivak-Callcott et al., 2011). Due to the high cost of training and impending shortage in the surgical workforce (Williams et al., 2009), time away from work and reduced career longevity due to musculoskeletal pain can be a costly form of waste in the healthcare system.

Surgeons who perform microvascular surgeries, frequently done in the plastic, otolaryngology, and reconstructive surgery specialties (Jarrett, 2004), may be at additional risk for musculoskeletal symptoms. Although microsurgery can be performed with loupes or microscopes, surgeons who perform microsurgery frequently (i.e., maxillofacial, plastics, ophthalmologists, otolaryngologists, and neurosurgeons) predominantly use operating microscopes (Jarrett, 2004). Additionally, operating microscopes are used exclusively for procedures requiring high magnification, e.g., 0.5 mm vessels during finger replantation and neurosurgery. Previous studies observed that operating microscopes required surgeons to fixate over optical eyepieces (Fig. 1
                     ), constrained the surgeon's eye locations, reduced comfort, and forced surgeons to be in awkward positions (Franken et al., 1995; Ross et al., 2003; Yu et al., 2013). For example (Fig. 1), while adjustable operating microscopes can allow a surgeon to have upright neck posture (right surgeon, Fig. 1), the small patient work site, assisting surgeon's position, operating room table, and microscope working distance can constrain surgeon posture and can lead to neck flexed positions (left surgeon, Fig. 1). Finally, a vast majority of microsurgery is done from a standing position, since the operating room (OR) table components prevent sitting with the surgeon's legs underneath the table. Despite these ergonomic risk factors in microsurgery, current literature quantifying the impact of these workplace and microsurgical task constraints on surgeon postural demands is limited.

A preliminary study by Yu et al. (2013) found that microsurgeons remain primarily static (0.3 ± 0.4 movements per minute) while using the microscope compared to 5.5 ± 6.1 movements observed at rest. Another study rated postures of laryngologists performing microsurgery on an operating microscope and measured rapid upper limb assessment (RULA) scores of 4–5, indicating poor posture and potential risk for injuries (McAtamney and Nigel Corlett, 1993; Statham et al., 2010). Posture constraints were postulated to be responsible for the significant association observed between microscope use greater than three hours per week and the prevalence of cervical and thoracic pain reported among 339 surveyed plastic surgeons (Capone et al., 2010).

Alternative video displays to traditional loupes and operating microscopes have been proposed to 1) reduce the physical demands of microsurgery, 2) allow surgeons to select comfortable postures, and 3) improve team communication (Chen et al., 2012; Franken et al., 1995; Gorman et al., 2001; Nissen et al., 2011; Yu et al., 2015). Although performance times were longer using video displays (Cheng et al., 2012; Nissen et al., 2013), these pilot studies showed 1) video displays can be successfully used during live microsurgery and 2) 50–75% of surveyed surgeons viewed the comfort and education potential of video displays favorably (Franken et al., 1995; Gorman et al., 2001). However, the posture benefits from alternative displays were merely speculated by these previous studies, and quantitative measurements are needed to compare the impact of microscope and video displays on postures.

To address microsurgery performance limitations observed by previous studies using 2D video displays (Gorman et al., 2001; Nissen et al., 2011), a recent study suggested that stereoscopic displays may reduce the observed performance gap between video and conventional microsurgery (Jianfeng et al., 2014). However, the performance benefit of stereoscopic video systems over non-stereoscopic systems in surgery is still currently under debate and warrants further investigation (Bilgen et al., 2013; Gurusamy et al., 2011; Hofmeister et al., 2001; Kong et al., 2010; Munz et al., 2004). Quantitative and controlled studies on the effect of stereo and non-stereoscope alternative displays on posture stresses and perceived effort are needed to assess the potential musculoskeletal health and performance benefits of implementing alternative video displays over traditional microscopes.

The purpose of this study is to measure the effect of stereoscopic video displays in reducing physical risk factors that may contribute to musculoskeletal fatigue and injuries during simulated microsurgery skills tasks. In contrast to conventional microscopes, it is hypothesized that video displays will allow users to:
                        
                           1)
                           Assume more neutral and less static postures,

Reduce perceived efforts, and

Improve task performance, i.e., completion time and errors.

Findings from this study will quantify the impact of video displays and microscopes on postures, perceived efforts, and task performance for microsurgery skills tasks and provide guidance on the application of video displays for improving postures in the operating theatre and in other jobs that require optical magnification.

@&#METHODS@&#

A laboratory study was conducted to determine how posture, perceived efforts, and performance were influenced by different magnification displays.

This study was approved by the university's institutional review board and informed consent was obtained from 16 university students with no prior surgical experience. Participants were recruited through university email lists and included students from both engineering and medicine. Mean age of the participants was 22 ± 2 years old. Mean BMI was 22 ± 3.6, and mean height was 170 ± 10 cm. All subjects were right-handed, 50% were males, 63% wore corrective lenses, 81% had experience with microscopes, and 44% had experience with 3D displays.

Four displays were tested in this experiment (Fig. 2
                        ): 1) non-stereo microscope (Micro2D), 2) stereoscopic microscope (Micro3D), 3) non-stereoscopic video display (Video2D), and 4) stereoscopic video display (Video3D). Although non-stereo microscopes were not used in surgery, it was tested to compare the effect of stereoscopy and investigate whether the additional cost of 3D translates to improved performance. To simulate Micro2D, participants wore a concave eye patch that occluded vision of one eye while using a binocular microscope (Scienscope™ Model XTL-V). The 3D video system streamed real-time interlaced video, at <100 ms lag, to a 101.3 cm 3D high-definition television (Samsung UN40C7000WF) from two synchronized microscope eyepiece cameras (Premiere Microscope MA87N) mounted on the binocular microscope. Both participants and study team members were able to view the video in 3D, using Samsung wireless shutter glasses. The 2D video system was created using the tele-macro video stream from a video camera (Sony DCR-SX83) positioned 64 cm above work site that was viewed on the flat-panel display without 3D glasses.

Field-of-view for all displays was calibrated to 38 mm × 38 mm. This range was larger than the 1–4 mm diameter vessels during microsurgery (Yu et al., 2014) and was within the field of views range (16.5 mm–180 mm in diameter) of commercial surgical microscopes (Leica Microsystems©). The optical microscope and the 3D video system were positioned as shown in Fig. 2a and b. Standing postures were more typical in microvascular surgeries and thus focused on in this study. The starting table height was adjusted so that the microscope eyepieces were between the tip of the nose and eyes of each participant. Although microscope positioning in an operating room varies based on patient anatomy and leads to head postures ranging from upright to flexed, this starting position was designed to control for differences in participant heights and to simulate task conditions and postures within the range observed in the field, e.g., Fig. 1. The distance to the flat panel display was 100 cm in front for all subjects. Subjects were instructed to position the flat-panel display (height, distance, and lateral location) and microscope (height) according to their preferences. It is important to note that the microscope equipment used in our current study differs from the realistic OR equipment, e.g., eyepiece angle and mounted on an adjustable workbench (Figs. 1 and 2), and video displays are currently not used in microsurgery; however, findings in this laboratory study will provide quantitative posture comparisons between displays and help inform future studies in the operating theatre.

During this study, participants performed two microsurgery skill tasks adapted from standardized laparoscopic skills tasks (Rosser et al., 1997) or designed with microsurgeons' guidance to reflect the skills needed to manipulate blood vessels 1–4 mm in diameter during microsurgery (Yu et al., 2014):
                           
                              1.
                              Pegboard Transfer (Fig. 2c): Adapted from laparoscopic skill task (Rosser et al., 1997), participants transferred eight silicone tubes that were 1.5 mm length and 1.2 mm outer diameter (Silastic® Laboratory Tubing) from the one side of the pegboard to the opposite side, then back to their original position using microsurgery forceps (Product# 12-412-11, KLS Martin Group). The pegboard was adapted to have 16 pegs either short (0.5 mm) or tall (1 mm) in length with five orientations (Fig. 2c). These adaptations increased task length and complexity. Participants held the pegboard with their non-dominant hand and used their dominant hand to transfer each tube to the corresponding peg on the opposite side of the board from top to bottom and outermost to innermost.

Tube Transfer (Fig. 2d): This task was created to simulate how microsurgeons grasp and manipulate blood vessels and sutures during microsurgery (Yu et al., 2014). Subjects held forceps with both hands to thread a monofilament thread (0.16 mm diameter) through eight silicone tubes.

Subjects were instructed to complete the tasks as quickly as possible while maintaining accuracy. Completion time and number of handling errors (i.e., grasp and release errors) were quantified using recorded videos. Grasp errors were defined as the number of failed grasp attempts, where subjects attempted to grasp the tube, but did not succeed (e.g., forceps misses tube or tube slips out of forceps). Release errors were defined as the number of failed attempts to place the tube at the target destination, e.g., peg for task 1 or thread for task 2.

@&#EXPERIMENTAL DESIGN@&#

Each of the four displays was repeated three times for each participant. For the first two repetitions, subjects had 12 min to complete each task twice on each display. For the third repetition, subjects performed each task continuously for six minutes. Five minute breaks were taken between displays for changeover and 10 min breaks were taken between the three repetitions. Total time each subject spent performing the skill tasks was approximately 126 min. The experimental design and display order among subjects followed a 4 × 4 Latin square design (Appendix A).

After completing each display in the final repetition, subjects completed surveys on 1) perceived efforts, e.g., head and neck, back, right arm, left arm, and lower extremity (adapted from Huang, 1999), and 2) display usability characteristics, i.e. field of view (FOV), brightness, contrast, color, resolution, and depth. All questions were surveyed with 10 cm visual-analogue scales.

Joint locations (Fig. 3
                        ) were recorded with 31 smart markers from Northern Digital Inc's (NDI) Optotrak Certus motion capture system by two position sensors. Markers were affixed to each participant using 3M athletic tape at each joint location (Fig. 3). Optotrak's Smart Marker Rigid Body™ contained three markers each and was used to calculate vectors normal to the Rigid Body or the mid-point of the Rigid Body plane. At the beginning of the experiment, subjects assumed a neutral standing posture with shoulder-elbow-wrist link at 90° flexion and posture data was calibrated with each individual's neutral standing posture.

Matlab® (The MathWorks, Inc.) scripts were used to calculate posture angles from marker locations. The following metrics were calculated:
                           
                              1)
                              Posture angles in the neck, upper-extremity, and back (angles defined in Table 1
                                 ),

Percent-time in static postures, defined as change in angle <1° per second (adapted from Szeto et al., 2012), and

Number of movements, defined as “the number of times that the joint moved away from the mean angle by…more than 10°” (adapted from Szeto et al., 2012, see Appendix B).

Statistical analyses were conducted on SPSS Statistics (IBM Corp. v21) using a multivariate general linear model with display and task as fixed factors and subject as covariate. Differences in postures among displays were calculated using Bonferroni's method for pairwise comparison. Univariate models with Tukey's multiple comparison tests were used to analyze performance.

@&#RESULTS@&#

Results from the motion tracking, survey, and performance among the displays are summarized in the following sections. Sixteen subjects participated in this study, but posture and performance data for one subject was excluded due to trial lengths differences during the final repetition.

The definitions and descriptive statistics for each posture angle are shown in Table 1. Example plot of how neck flexion varied between microscope (2D/3D) and video (2D/3D) displays for a representative subject is shown in Fig. 4
                           . For this subject, neck angle on the microscopes was positive which indicated that the neck was flexed forward throughout the task. This subject was observed to look up or assume a more neutral neck posture, at t = 238 s for Micro3D and t = 197 s for Micro2D (Fig. 4). In contrast, the neck angle for this subject was more upright when using the video displays, and the participant looked down at the task location at t = 166 s for Video2D and t = 236 s for Video3D (Fig. 4).

In comparison to microscopes, included neck angles, i.e., the angle between the torso and head segment (Fig. 3), were reduced 9–13° for the video displays, and angles were significantly different (p < 0.01) between the microscopes and Video2D. Neck rotation was 11–16° larger (p < 0.01) for the video displays than microscopes. Significant differences were also observed among displays for shoulder flexion. Specifically, right shoulder flexion on Video3D (38 ± 14°) was 9–10° further elevated from the torso than the microscopes (p < 0.05). No significant differences in postures were observed between non-stereo/stereoscopic condition, i.e., between the 2D and 3D video display or between the 2D and 3D microscopes.

Neck and shoulder postures are shown in Fig. 5
                           a and b to illustrate the distribution of angles. The percent time observed in neck postures with minimal injury risk, defined as 0–10° neck flexion (McAtamney and Nigel Corlett, 1993), for 2D and 3D video displays was 22% and 20% respectively, and these percentages were greater than the percent time observed for 2D and 3D microscopes, 12% and 11% respectively (Fig. 5a). The percent times observed in −20 to 20° right shoulder flexion (recommended postures from McAtamney and Nigel Corlett, 1993) for the 2D and 3D flat-panel displays were 15% and 17% respectively, and these percentages were less than the percent time observed for 2D and 3D microscopes, 21% and 22% respectively (Fig. 5b).

Postures were defined as static when the change in angle was <1° per second (adapted from Szeto et al., 2012). The right shoulder and elbow were static 81–86% of the time during the tasks, and the left shoulder and elbow were static 90–91% of the time. Neck postures were static 73–86% of the time. No statistical differences in time spent in static postures were observed between displays.

Additional analysis was conducted on the neck, back, and shoulder postures, areas with high prevalence of musculoskeletal pain and disorders among surgeons who used optical magnification (Capone et al., 2010; Sivak-Callcott et al., 2011; Statham et al., 2010). Postural shifts in the included neck angle (Table 1) were 3.22 times more frequent (p < 0.05) on the Video3D than Micro3D (Table 2
                           ). Back flexion movements were 1.9 times more frequent (p < 0.10) on the Video3D than Micro3D. No significant differences were found between displays for shoulder movements (Table 2).

Perceived efforts ranged from 3.7 to 5.4, where 0 = no perceived effort and 10 = worst perceived effort (Table 3
                        ). Perceived effort in the head and neck region was reported the highest. Perceived efforts did not differ among displays.

Mean usability ratings for each display ranged from 4.4 to 8.6, where 0 = worst imaginable and 10 = best imaginable (Table 3). All ratings were better than neutral (i.e. score of 5.0) except for depth of field on the video displays. The Video3D was rated 0.6–3.4 points lower (p < 0.05) than microscopes (2D and 3D) for every usability characteristic, except for the FOV. Ratings of depth-of-field between 2D and 3D displays were not statistically different.

Performance measures for each display on each task are shown in Table 4
                        . Completion time was reported as time needed to transfer or thread each tube. Errors were reported as number of handling errors observed per tube during the task (defined in Section 2.3).

For the pegboard task (Task 1), mean completion times ranged from 5.6 to 10.2 s per tube, and mean number of errors ranged from 0.9 to 1.1 per tube (Table 4). Video displays required 3.9–4.6 s or 66–82% more time than microscopes (p < 0.05) to complete each tube in the pegboard task. Number of errors did not differ among displays on the pegboard task. In addition, performance did not differ between non-stereo/stereoscopic conditions, i.e., completion times and number of errors were not different between Micro2D and Micro3D, and between Video2D and Video3D.

Performance times were longer on the threading task (Task 2) than the pegboard task (Table 4). Completion times ranged from 33.9 to 71.3 s per tube, and the number of errors ranged from 3.7 to 5.8 per tube. Video3D required 36.8–37.4 s or 107–110% more time than microscopes (p < 0.05) to complete each tube. On average, 2.0 more errors were observed when subjects used Micro2D than Micro3D (p < 0.05). On average, 2.1 less errors were observed on Video2D than Video3D (p < 0.05).

@&#DISCUSSION@&#

The observed neck postures were within the 10–20°+ range measured by Statham et al. (2010) during microlaryngoscopy. Included neck angles were 9–13° closer to neutral when subjects used video displays than when using microscopes (Table 1). Observed differences may have implications for reducing biomechanical loads and muscle exertions during microsurgical tasks.

Using the biomechanical models developed by Snijders et al. (1991) to interpret the neck angles observed in this study (i.e., 14° on Micro3D and 8° Video3D in Table 1), joint moment at the cervical 7-thoracic 1 joint was estimated to be 23N or 17% higher for Micro3D than Video3D. Previous studies found that neck moments had a positive association with neck muscle activity during video display use (Villanueva et al., 1997). Specifically, percent maximum voluntary contraction (%MVC) of the neck extensor was 10.4%MVC at 12° neck flexion, 7.8%MVC at 1.1° flexion, and 5.4%MVC at 11.3° extension. Based on these trends (Villanueva et al., 1997), the smaller neck flexion observed on video display suggest that mean neck extensor muscle activity requirements can be lower when using a video display than microscope. However, the predicted neck muscle activity, given the mean angles on either microscope or video displays, is still higher than recommended 2–5% MVC for static work (Villanueva et al., 1997).


                           McAtamney and Nigel Corlett (1993) suggested that neck flexion beyond 0–10° can increase joint loads and injury risks; however, neck flexion in the present study was observed to exceed these guidelines 88% of the time on the Micro3D and 80% of the time on Video3D (Fig. 5a). In addition, subjects were observed in neck extension 22% of the time while using video displays (Figs. 4 and 5a). Although neck extension was hypothesized to increase the risk for musculoskeletal disorders (McAtamney and Nigel Corlett, 1993), biomechanics studies have suggested that neck extension can reduce neck moments from gravity and lower neck extensor muscle activity levels (Straker et al., 2009; Villanueva et al., 1997). The observations of neck extension and neck movements during video displays (Table 1, Figs. 4 and 5a) may illustrate a mechanism that allowed participants to reduce or shift muscle loads.

Observed shoulder flexion for all displays were within the 20–45° shoulder flexion range recommended for laryngeal microsurgery (Chen et al., 2012; Statham et al., 2010); however right shoulder flexion (defined in Table 1) was 9° higher on the Video3D than microscope (Table 1). The increase in shoulder flexion on the video displays was unexpected because 1) shoulder loads were predicted to increase with increasing shoulder angle, and 2) video displays were hypothesized to reduce posture constraints and allow subjects to choose comfortable postures that reduce musculoskeletal stresses. Specifically, postures while using video displays were only constrained by task area, and shoulder flexion could be reduced by moving the torso closer to the task area (Figs. 2 and 3). Possible explanations for the observed shoulder angles may be that 1) larger shoulder and elbow angles allowed subjects to assume a more comfortable distance from the task area (i.e., table) and/or the display, or 2) shoulder joint loads were reduced by resting their hands and arms on the task area. However, display distances and table locations were not controlled in the present study. Further studies are needed to investigate the effect of display distances and to limit the ability to rest hands and arms on the table since this may not be feasible during live surgical procedures.

Previous studies have suggested that sustained postures without sufficient recovery time are risk factors for fatigue and musculoskeletal injuries during surgery (Berguer et al., 1997; Szeto et al., 2012). However, because movement time for adjusting posture was short compared to the duration of the task, “percent time in static postures” may not the best metric to assess the sustained exertions during microscope tasks. Postural shifts may be more important for reducing the sustained loads and static muscle contractions during microsurgery tasks. Park et al. (2010) emphasized that 84% of surveyed laparoscopic surgeons indicated that postural shifts were used to prevent fatigue, and the present study observed that postural shifts were more frequent during Video3D use than during microscope use (Table 2). This observation may support our hypothesis that video displays reduce posture constraints and allow participants to adjust their posture more frequently. However, these findings are limited to standing postures only, and additional research is needed to relate postural shifts to musculoskeletal fatigue and discomfort.

Previous studies advocating for video displays for microsurgery reported that surgeons have commented favorably on the system's comfort and educational potential, but technological limitations of the video systems prevented surgeons from achieving comparable performance with conventional microscopes (Franken et al., 1995; Gorman et al., 2001). Similar performance trends were observed in the present study (Table 4), and these differences may be due to technical limitations, i.e., brightness, contrast, color, resolution, and depth, in video systems (Table 3).

Handling errors may be relevant to patient outcomes in microsurgery, as failed attempts to grasp the delicate blood vessels may damage the vessel walls and lead to thrombosis of the transplanted tissue (Yu et al., 2014). For the pegboard task, errors were not significantly different among the displays (Table 4). For the threading task, fewer errors were observed using the 3D microscope than the 2D microscope. The impact of 2D and 3D on errors may be explained by task difficulty. The pegboard task consisted of placing tubes on a pegboard fixed to the work surface; however, the threading task required subjects to manipulate both the thread and tube in 3D-space. This suggests that Micro3D may be beneficial for tasks in 3D-space. In contrast, performance on Video3D resulted in more errors compared to the performance on Video2D. These differences may be due limitations on Video3D in camera resolution, reduced brightness from shutter glasses, or camera alignment.

Although video displays improved posture angles and reduced posture constraints in this laboratory study, further studies are needed to understand if findings translate to improving surgeon postures in the OR by addressing limitations in 1) task length, 2) task complexity, and 3) equipment layout and display performance.

One limitation of this study was the short time duration that subjects continuously worked with each display. Microsurgery typically lasts 1–2 h in length (Yu et al., 2015), but participants of the current study only worked with each display for 12 min before changing over to a different display. Although postures were statistically different between displays, the short task duration may explain why perceived efforts did not differ among displays. Additionally, physical demands of microsurgery may be underestimated since the study focused on simulated skill tasks and the participants lacked prior surgical experience and continuous biomechanical exposures accumulated by surgeons that perform the procedure daily. Further investigations of more representative simulation or surgical tasks in the operating theatre with surgeons are warranted to observe how increased task demands affect postures on the different displays. Finally, additional studies are needed to address performance limitations of the video displays. For example, performance may be impacted by differences in visual clarity (surgeons can adjust eyepieces to personal preferences vs. video displays which may be limited by screen size and distance). There is a need to examine whether postures improvements observed in this study is consistent at different display locations and sizes and when better displays are used.

@&#CONCLUSIONS@&#

Video displays have been previously suggested to improve ergonomics and comfort during microsurgery, and this study examines three hypotheses to quantitatively compared postures between displays. First, results showed that neck postures were more upright and postural shifts were more frequent on video displays than microscopes. These observations suggest that video displays can reduce biomechanical loads and muscle exertions. The second hypothesis focused on the relationship between displays and perceived efforts, and no differences in perceived efforts were observed among display. Finally, video displays were hypothesized to improve task performance, but task completion times were 66–110% faster on the microscopes than video displays. In addition, 2D and 3D displays did not differ in performance times, and errors were significantly different only on the more advanced threading task.

@&#ACKNOWLEDGMENTS@&#

This study was funded in part by the National Science Foundation Graduate Research Fellowship under Grant No. DGE 1256260. This publication was supported by the Grant or Cooperative Agreement Number, T42 OH008455, funded by the Centers for Disease Control and Prevention. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the Centers for Disease Control and Prevention or the Department of Health and Human Services. The authors would also like to acknowledge the recommendations from the university surgeons and the assistance from the Center for Ergonomics faculty and staff.

@&#EXPERIMENTAL DESIGN@&#


                        
                           
                              
                                 
                                 
                                 
                                    
                                       Subject
                                       Display order, where A is Micro2D, B is Micro3D, C is Video2D, D is Video3D
                                    
                                 
                                 
                                    
                                       Subject 1
                                       1st repetition: ABCD, 2nd repetition: BDAC, 3rd repetition: CADB
                                    
                                    
                                       Subject 2
                                       1st repetition: BDAC, 2nd repetition: CADB, 3rd repetition: DCBA
                                    
                                    
                                       Subject 3
                                       1st repetition: CADB, 2nd repetition: DCBA, 3rd repetition: ABCD
                                    
                                    
                                       Subject 4
                                       1st repetition: DCBA, 2nd repetition: ABCD, 3rd repetition: BDAC
                                    
                                    
                                       Subject 5
                                       1st repetition: ABCD, 2nd repetition: BDAC, 3rd repetition: CADB
                                    
                                    
                                       …
                                       
                                    
                                    
                                       Subject 16
                                       1st repetition: DCBA, 2nd repetition: ABCD, 3rd repetition: BDAC
                                    
                                 
                              
                           
                        
                        
                           
                              
                           
                        
                     

Lines in the figure are defined as follows:
                           
                              •
                              Solid blue line: angle change over time

Dashed black line: mean angle

Dotted red line: 10° above and below mean angle (black line)

The green thick-lined box contains intersections where the subject's neck angle deviates greater than 10° from the mean angle. Only one “crossing” is contained within the box because “movements” must cross both the mean (black line) and 10° from the mean (red line). Total number of crossing in this example is three.

@&#REFERENCES@&#


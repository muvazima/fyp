@&#MAIN-TITLE@&#A new classifier fusion method based on historical and on-line classification reliability for recognizing common CT imaging signs of lung diseases

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           CISLs play important roles in the diagnosis of lung diseases.


                        
                        
                           
                           We fuse the classifiers in a weighted-sum form for recognizing CISLs.


                        
                        
                           
                           The weights are based on the confusion matrix and classification confidence values.


                        
                        
                           
                           The weights reflect the historical and on-line reliability of decision-making of classifiers.


                        
                        
                           
                           Our method is robust to classifiers and features.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Medical image classification

Classifier fusion

Lung CT images

Common CT imaging signs of lung diseases (CISL)

Confusion matrix

@&#ABSTRACT@&#


               
               
                  Common CT imaging signs of lung diseases (CISL) play important roles in the diagnosis of lung diseases. This paper proposes a new method of multiple classifier fusion to recognize the CISLs, which is based on the confusion matrices of the classifiers and the classification confidence values outputted by the classifiers. The confusion matrix reflects the historical reliability of decision-making of a classifier, while the difference between the classification confidence values reflects the on-line reliability of its decision-making. The two factors are merged to determine the weights of the classifiers’ classification confidence values. Then the classifiers are fused in a weighted-sum form to make the final decision. We apply the proposed classifier fusion method to combine five types of classifiers for CISL recognition, including support vector machine (SVM), back-propagation neural network (BPNN), Naïve Bayes (NB), k-nearest neighbor (k-NN) and decision tree (DT). In the experiments on lung CT images, our method not only brought stable improvements of recognition performance, compared with single classifiers, but also outperformed two well-known methods of classifier fusion, AdaBoost and Bagging. These results show that the proposed method is effective and promising.
               
            

@&#INTRODUCTION@&#

CT technology developed quickly from the conventional single-slice acquisitions to volume acquisition with multi-slice, hence, it contains more and more image information and can highlight the density difference between the normal and diseased lungs [1]. However, it is time-consuming for radiologists to identify a large number of abnormal lesions from the CT images. Therefore, the problem of recognizing lesions in lung CT images automatically for aiding radiologists in the diagnosis of lung diseases has received extensive attention in recent years.

Various types of single classifiers have been used in the past years for lung CT image recognition, including k-nearest neighbors (k-NN) [2–6], neural networks (NN) [5–10], Bayes [6,11,12], rule-based schemes [13], decision trees (DT) [6,11], linear discriminant analysis (LDA) [14] and support vector machine (SVM) [2,5,6,14]. Although much progress has been made, a single classifier is still difficult to achieve satisfactory performance in the practical applications. Plentiful studies have shown that the fusion of multiple classifiers is a feasible solution to bring the better classification results since diversity of classifiers usually compensates for errors of any single classifier.

In this paper, we propose a novel weighted-sum method of classifier fusion for recognizing common CT imaging signs of lung diseases (CISLs). Different from other weighted-sum counterparts, we consider both HIStorical reliability and ON-line reliability of each single classifier. The resultant method is accordingly called HISON for short. The historical reliability is reflected by the confusion matrix established in the training procedure and the on-line reliability is reflected by the difference between the classification confidence values computed in the test procedure. The two information above are employed to determine the weight of each single classifier. Then the classifiers are combined in the weighted linear sum form to make the final classification decisions. We apply the proposed HISON classifier fusion method to combine the five widely used classifiers, including support vector machine (SVM), back-propagation neural network (BPNN), Naïve Bayes (NB), k-nearest neighbors (k-NN) and decision tree (DT), for recognizing CISLs contained in the regions of interests (ROIs) in lung CT images. The resultant method was tested in the instances collected from the Cancer Institute and Hospital at Chinese Academy of Medical Sciences. The CISLs mean the well-known categories of CT imaging signs of lung diseases that frequently appear in patients’ lung CT images and play important roles in the diagnosis of lung diseases. Nine categories of CISLs are considered in this paper, including grand grass opacity (GGO), lobulation, cavity & vacuolous (CV), spiculation, pleural indentation (PI), obstructive pneumonia (OP), calcification, air bronchogram (AB), and bronchial mucus plugs (BMP). We illustrate them in Fig. 1
                     . Notice that this paper is expanded and updated from a preliminary study of ours [15]. More comprehensive investigation of related work and more in-depth theoretical analysis are provided. Furthermore, much more experiments have been designed and conducted to prove the effectiveness, the efficiency and the robustness of the proposed method.

The rest of this paper is organized as follows. Section 2 reviews the common related work on classifier fusion in the medical imaging community. Section 3 presents our classifier fusion method. Section 4 describes our CISL recognition algorithm. The experimental results are reported in Section 5. We conclude in Section 6.

@&#RELATED WORK@&#

The classifier fusion methods based on the linear sum have attracted a lot of attention for their simplicity and good performance. It can be divided into two types: hard classification based and soft classification based.

In hard classification based fusion methods, the output of each classifier is the class label, usually 1 for the recognized class and 0 for other classes. Based on this kind of outputs, the voting strategy is often used to realize the fusion. It counts the numbers of all categories classified by the classifiers and makes the class which receives the largest number votes among the voters, that are the classifiers, as the final classification decision, such as majority vote (MV), weight vote (WV), Learn++ and Bagging, and so on. Wang et al. [16] used the minimum within-class scatter support vector machine as the individual classifiers and made the decision for the classification of pulmonary cancer in CT scanned images by using the MV. Salama et al. [17] introduced a MV fusion method for combining the different classifiers including DT, multi-layer perception (MLP), NB, SVM, k-NN and tested the classification accuracy of the combined classifier on three different databases, Wisconsin Breast Cancer, Wisconsin Diagnosis Breast Cancer and Wisconsin Prognosis Breast Cancer. Lee et al. [18] combined LDA classifiers through using the MV method to make the diagnosis of pulmonary nodules. Prasad et al. [19] used the MV method to fuse LDA classifiers for classifying mammogram into malignant or benign. WV means that not all classifiers are equal and each classifier's vote carries the different weight. Soda et al. [20] applied the WV method to achieve the better results for the recognition of antinuclear autoantibodies (ANA). Patel et al. [21] combined several SVM classifiers using the WV method for early diagnosis of Alzheimer's disease, where the weights of SVMs were determined based on the average performance of classifiers on the validation data. Learn++ is an incremental learning algorithm and creates an ensemble of weak classifiers, each trained on a subset of the current training dataset. The final decision is obtained by combining these weak classifiers through MV. Polikar et al. [22] used Learn++ for early diagnosis of Alzheimer's disease. Bagging is also an ensemble of weak classifiers which trains a weak classifier on a new training set gotten by sampling uniformly and with replacement from the database and combines all the classifiers by voting for the final classification. Tartar et al. [23] utilized Bagging algorithm to classify the candidate nodules extracted from CT images into the nodules or non-nodule for reduction of false positives in the detection of pulmonary nodules. Tu et al. [24] used Bagging algorithm to identify the heart disease of a patient.

In soft classification based fusion methods, the output of each classifier is the probability of making decisions. Usually each classifier is assigned a weight. The weighted output of each classifier is summed up for making the final decision. Zhao et al. [25] proposed a weighted-sum classifier fusion method for classification of breast masses. It contained two terms, the weights of the classifiers and the probability tracing matrix, where the weights were decided by their classification accuracy on the training data and were constant in the test phase. Leeb et al. [26] proposed two classifier fusion techniques for the practical brain–computer interfaces (BCIs). In the first approach, the fusion weights were equally balanced between two classifiers, and in the second one, they used the Bayes rule to estimate the final classification probability. Through the experiments, they demonstrated the Bayesian fusion approach could lead to a very constant and better behavior. Gupta et al. [27] introduced parametric weighted fusion model to improve the classification accuracy of averaged multichannel evoked potentials. The weights were determined according to the classification accuracy rate of each classifier, which was measured on the training data. Wu et al. [28] introduced a novel trained linear combination method called perceptron average (PA) to identify breast masses in mammograms as malignant or benign, which could effectively improved the classification performance of component neural networks (CNNs). Besides, the most frequently used fusion methods, like simple average (SA) and AdaBoost, are also the classical line-sum fusion methods based on the probability. For the SA, the decisions of classifiers are linearly and equally combined to form an overall decision. Peng et al. [29] utilized the SA fusion method for the breast masses classification. Das et al. [30] used the SA fusion method to combine four nonlinear multivariate models including NN, DT, SVM, and self-organizing map for the prediction of radiation-induced pneumonitis. The AdaBoost is an ensemble fusion approach that iteratively constructs optimal weak classifiers from reweighing training samples in each round. It can produce accurate prediction by combining those weak learners in a weighted linear combination. Kuwahara et al. [31] applied the AdaBoost method to improve the classification rate of diffuse lung disease patterns. Ochs et al. [32] used the AdaBoost learning method to train a set of ensemble classifiers for classifying lung bronchovascular anatomy.

The linear sum fusion methods based on the votes give each class the hard 0 or 1, while the linear sum fusion methods based on probability can give each class a classification confidence between 0 and 1, which is more reasonable and more accurate for the classification. For the latter, the determination of the fusion weight of each classifier is a crucial issue. In previous work, the weights are usually determined by the performance of classifiers on the training data. It will assign larger weights to the classifiers having the better historical reliability of decision-making. In this way the diversity and specificity of the test samples is ignored. However, it is possible that a classifier with better performance on historical data may make a false prediction for the current test sample. Thus only considering historical reliability of classifiers for fusion could cause the classification accuracy degradation. It is more reasonable to determine the weight of each classifier according to not only the historical performance of the classifier but also the characteristics of the test samples. This is the core idea behind our method.

Suppose we have N single classifiers. Given an input pattern, each classifier will output its predicted class with confidence. Then the final decision can be made through combining the N classifiers in a weighted-sum form. Here the determination of weights of base classifiers is a crucial problem. In order to tackle the problem, we consider not only the quality of each classifier but also the characteristics of the test samples. Hence, we utilize the confusion matrix and the difference between classification confidence values for competing classes to reflect the distribution of historical errors and the recognition performance on the test sample, respectively. By considering the two aspects above, the reliability of decision-making of each classifier is measured and used to weigh the classification confidence values outputted from the classifiers. The weighted sum of classification confidence values from all the classifiers is the final criterion for classification.

Our classifier fusion method based on the idea above is called HISON for short and illustrated in Fig. 2
                     . As shown in Fig. 2, our method includes two stages: the training and the recognition. In the training stage, we train each classifier on the training set and obtain the confusion matrix of each classifier on the validation set. In the recognition stage, we calculate the weights of base classifiers by utilizing the on-line classification confidences for the test samples and the confusion matrices established in the training stage. Then the weights are used to combine the on-line classification confidences of base classifiers in a weighted-sum form for making the final classification decision. The details of two stages are given in the following sections.

In the training stage, we firstly train each classifier on the training dataset. Then we establish the confusion matrix of each classifier on the validation dataset. The confusion matrix [33] describes the relationship between the true class and the output of the classifier, which can measure the prior behavior of a classifier and is a common method of evaluating the ability of classifier.

Given n classes, a n
                        ×
                        n confusion matrix will be established for each classifier, where each row or column corresponds to a class, respectively. Let 
                           
                              
                                 m
                                 
                                    i
                                    j
                                 
                                 k
                              
                           
                         be the element at the i-th row and the j-th column of the confusion matrix of the k-th classifier, which is the frequency that the pattern belonging to the i-th class is recognized as the j-th class by the k-th classifier. Then the whole confusion matrix of the k-th classifier is
                           
                              (1)
                              
                                 
                                    
                                       M
                                       k
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            11
                                                         
                                                         k
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            12
                                                         
                                                         k
                                                      
                                                   
                                                
                                                
                                                   …
                                                
                                             
                                             
                                                
                                                   ⋮
                                                
                                                
                                                   ⋮
                                                
                                                
                                                   ⋱
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            n
                                                            1
                                                         
                                                         k
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            n
                                                            2
                                                         
                                                         k
                                                      
                                                   
                                                
                                                
                                                   …
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            1
                                                            n
                                                         
                                                         k
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   ⋮
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         m
                                                         
                                                            n
                                                            n
                                                         
                                                         k
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The diagonal element in the confusion matrix show the probabilities that the examples from each category are predicted correctly and the non-diagonal elements show the probabilities that the examples from any two categories are confused with each other. Therefore, the confusion matrix reflects the distribution of historical errors of a classifier.

In the recognition phase, given an input pattern, each classifier will output a classification confidence value. Based on this value and the confusion matrix established in Section 3.1, we compute the weight for each classifier. Then we sum up the weighted classification confidence values of the classifiers to make the final decision.

Formally, let X be an input pattern, K be the number of individual classifiers, 
                           
                              
                                 P
                                 k
                              
                              
                                 
                                    
                                       C
                                       i
                                    
                                    |
                                    X
                                 
                              
                           
                         be the classification confidence value outputted by the k-th classifier for the pattern X and the i-th class C
                        
                           i
                        . Firstly we determine the inverse on-line reliability of the k-th classifier, 
                           
                              
                                 D
                                 
                                    i
                                    j
                                 
                                 k
                              
                           
                        , as
                           
                              (2)
                              
                                 
                                    
                                       D
                                       
                                          i
                                          j
                                       
                                       k
                                    
                                    =
                                    exp
                                    
                                       
                                          −
                                          
                                             
                                                
                                                   P
                                                   k
                                                
                                                
                                                   
                                                      
                                                         C
                                                         i
                                                      
                                                      |
                                                      X
                                                   
                                                
                                                −
                                                
                                                   P
                                                   k
                                                
                                                
                                                   
                                                      
                                                         C
                                                         j
                                                      
                                                      |
                                                      X
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Then, the weight assigned to the k-th classifier, 
                           
                              
                                 w
                                 
                                    i
                                    k
                                 
                              
                           
                        , is determined by
                           
                              (3)
                              
                                 
                                    
                                       w
                                       
                                          i
                                          k
                                       
                                    
                                    =
                                    
                                       
                                          
                                             m
                                             
                                                i
                                                i
                                             
                                             k
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                                ,
                                                j
                                                ≠
                                                i
                                             
                                             n
                                          
                                          
                                             
                                                m
                                                
                                                   i
                                                   j
                                                
                                                k
                                             
                                             
                                                D
                                                
                                                   i
                                                   j
                                                
                                                k
                                             
                                          
                                          +
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                                ,
                                                j
                                                ≠
                                                i
                                             
                                             n
                                          
                                          
                                             
                                                m
                                                
                                                   j
                                                   i
                                                
                                                k
                                             
                                             
                                                D
                                                
                                                   i
                                                   j
                                                
                                                k
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The rationality of Eq. (3) is explained as follows. The numerator of Eq. (3), i.e., 
                           
                              
                                 m
                                 
                                    i
                                    i
                                 
                                 k
                              
                           
                        , is the possibility that the k-th classifier can identify the patterns belonging to the i-th class correctly. Obviously, the bigger this possibility is, the more reliable 
                           
                              
                                 P
                                 k
                              
                              
                                 
                                    
                                       C
                                       i
                                    
                                    |
                                    X
                                 
                              
                           
                         is. In the denominator of Eq. (3), we consider the possibility that the k-th classifier incurs classification errors related to the i-th class, including two types of errors. The first type of errors are those that the patterns belonging to the i-th class are classified into any other classes, the possibilities of which are 
                           
                              
                                 m
                                 
                                    i
                                    j
                                 
                                 k
                              
                              
                                 |
                                 
                                    j
                                    =
                                    1
                                    ,
                                    j
                                    ≠
                                    i
                                 
                                 n
                              
                           
                        , i.e., the elements in the i-th row of the confusion matrix, except 
                           
                              
                                 m
                                 
                                    i
                                    i
                                 
                                 k
                              
                           
                        . The second type of errors are those that the patterns belonging to any other classes are classified into the i-th class, the possibilities of which are 
                           
                              
                                 m
                                 
                                    j
                                    i
                                 
                                 k
                              
                              
                                 |
                                 
                                    j
                                    =
                                    1
                                    ,
                                    j
                                    ≠
                                    i
                                 
                                 n
                              
                           
                        , i.e., the elements in the i-th column of the confusion matrix, except 
                           
                              
                                 m
                                 
                                    i
                                    i
                                 
                                 k
                              
                           
                        . The possibilities of the two types of errors above are determined by the performance of the classifier on historical validation set, in which the particularity of the currently inputted pattern is not involved. So it is not very satisfactory to only consider them for measuring the possibility of current misclassification. That is why 
                           
                              
                                 D
                                 
                                    i
                                    j
                                 
                                 k
                              
                           
                         is involved. It is an inverse online-reliability, which means that the smaller 
                           
                              
                                 D
                                 
                                    i
                                    j
                                 
                                 k
                              
                           
                         is, the more reliable the current classification is, so the higher the weight should be. To sum up, the resultant 
                           
                              
                                 w
                                 
                                    i
                                    k
                                 
                              
                           
                         reflects both historical and on-line reliability of confidence value from the k-th classifier.

Based on the weights computed from Eq. (3), the combined classification confidence is computed as
                           
                              (4)
                              
                                 
                                    P
                                    
                                       
                                          
                                             C
                                             i
                                          
                                          |
                                          X
                                       
                                    
                                    =
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       K
                                    
                                    
                                       
                                          w
                                          
                                             i
                                             k
                                          
                                       
                                       
                                          P
                                          k
                                       
                                       
                                          
                                             
                                                C
                                                i
                                             
                                             |
                                             X
                                          
                                       
                                    
                                 
                              
                           
                        
                     

We concern the problem of recognizing CISLs in the regions of interests (ROIs) in lung CT images. Our algorithm for solving this problem consists of two components: feature extraction and ROI classification.

We employ four different types of image features, including the bag-of-visual-words based on the histograms of oriented gradients (HOG), the wavelet transform based features, the local binary pattern (LBP) and the CT value histogram (CVH).

The HOG feature is a texture descriptor describing the distribution of image gradients in different orientations. It can be obtained by combining all the histograms of the image patches. Following the HOG feature extraction scheme of Dalal et al. [34], we divide a ROI into smaller rectangular blocks of 8×8 pixels and further divide each block into 4 cells of 4×4pixel. An orientation histogram which contains 9 bins covering a gradient orientation range of 0°−180° is computed for each cell. Then a block is represented by the linking of the orientation histograms of cells in it. That means a 36-D HOG feature vector is extracted for each block.

The commonly used image representation based on HOG features is to join the feature vectors of all the blocks in the image in sequence. This kind of HOG based image representation strategy requires that all the images have the same size, or else the dimensions of resultant feature vectors will be diverse for different images. But the size of ROIs in lung CT images varies with different patients and different pathological lesions. So this widely used strategy is not applicable in this work. To solve this problem, we adopt the bag-of-visual-words [35] on HOG features as the ROI representation. Different from the original bag-of-visual-words, we use the GMM based clustering algorithm instead of the k-means algorithm to generate more accurate visual words. In the GMM based clustering, we employ the expectation–maximization (EM) algorithm [36] to estimate the parameters in the GMM with specific structure and the minimum description length (MDL) criterion [37] to determine the GMM structure. After the GMM is fitted to the data, each Gaussian component is taken as a cluster center as well as a visual word. All the visual words constitute a visual dictionary. We map the 36-D HOG feature vector of each block to the visual word corresponding to the highest likelihood for it. Then the number of the HOG feature vectors assigned to each visual word is accumulated and normalized by the number of all the HOG feature vectors to form a histogram representation of the ROI.

Wavelets are important and commonly used feature descriptors for texture analysis, due to their effectiveness in capturing localized spatial and frequency information and multi-resolution characteristics [38]. In this paper, the ROIs are decomposed to 4 levels, LL, LH, HL, and HH, by using 2D symlets wavelet because the symlets wavelet has better symmetry than Daubechies wavelet and thus more suitable for image processing [39]. We extract horizontal, vertical and diagonal directional detail coefficients from the wavelet decomposition structure. Finally, we get the wavelet features by calculating the mean and the variance of these wavelet coefficients.

LBP [40] is a compact texture descriptor, which is defined as a grayscale invariant texture measure in a local neighborhood. We divide the ROI into a grid of n
                           ×
                           n cells. For each cell, we get the binary numbers by the comparative result between a center pixel and one of its surrounding neighbors and compute the histogram of the frequency of each number. We obtain the LBP feature by concatenating the normalized histograms of all cells. The neighborhood in LBP operator can be defined very flexibly by using circular neighborhoods and bilateral interpolation of pixel values. These kinds of neighborhoods can be denoted by (P, R), which means we evenly sample P neighbors on the circle of radius R around the center pixel. In order to characterize the texture of our lesions better, we set the ranges of P and R to {4, 5} and {1, 2}, respectively. As a result, we extract 4 types of LBP features and join them to form a multi-scale LBP feature.

CVH means the histogram of CT values, which is the statistic probabilistic distribution of each density value in a CT imaging and is invariant in scale, rotation and translation. In this paper, the number of bins of the histogram is determined by experiments. Actually, we tested the numbers from 20 to 60 at the step of 10. For each tested number, we extracted the corresponding CVH features and used k-NN as the classifier to perform the CISL recognition. The results showed that the number of 40 leaded to the highest classification accuracy rates.

Since the different types of features may contain complementary information, it could bring better classification performance through selecting discriminative features from various feature spaces. Thus we select the optimal feature subset from the features above. The task is completed by a feature selection method based on Fisher criterion and genetic optimization [41]. The Fisher criterion is applied to evaluate feature subsets, based on which a genetic optimization algorithm is developed to find out an optimal feature subset from the candidate features.

In this section, we recognize the CISLs using our proposed classifier fusion method described in Section 3. We combine the commonly used classifiers, including the support vector machine (SVM), Naïve Bayes (NB), back-propagation neural network (BPNN), k-nearest neighbor (k-NN) and decision tree (DT), to classify the ROIs in lung CT images into the corresponding class of CISLs. Notice that we implement the five classifiers by using the corresponding functions in WEKA [42], a machine learning library in java. The names of these functions are: (1) “SMO” (SVM), (2) “MultilayerPerceptron” (BPNN), (3) “NaiveByes” (NB), (4) “IBk” (k-NN), (5) “J48” (DT). All these different types of classifiers output the confidence values in [0,1]. Thus they are diverse and comparable. According to Duin [43], it is reasonable to take them as base classifiers.

The proposed classifier fusion method is experimentally compared with well-known Bagging algorithm and Adaboost algorithm.

Bagging algorithm [44], a sobriquet for bootstrap aggregating, relies on random and independent changes in the training data implemented by boostrap sampling. Given a training data set, Bagging generates new training sets by sampling uniformly and with replacement. For each new training set, it utilizes a weak learner for training classifier model. Then, all the learned models are combined by voting for the final classification.

Adaboost algorithm [45], the most frequently used or referred boosting method, gives the weight to each sample, then trains the classifiers on these weighted samples in an iterative way. At each iteration a new classifier is trained and the distribution of weights is updated. It increases the weights of the incorrectly classified samples and decreases the weights of the correctly classified samples. That is, it focuses on those training examples that are “difficult” to be classified. Unlike Bagging algorithm which is a parallel ensemble method, Adaboost is a sequential ensemble algorithm where the weights of samples depend on the previous distribution. Adaboost has been empirically demonstrated to achieve high classification accuracy.

@&#EXPERIMENTS@&#

We collected the instances of nine categories of CISLs from the Cancer Institute and Hospital at Chinese Academy of Medical Sciences. All the lung CT images in the DICOM form were taken by slice thickness of 5mm with 512×512 in plane pixel matrices. The total slice number for each CT scan ranges from 43 to 131 with an average of 66/scan. The diameters of the CISLs range from 1mm to 20mm.

The rectangular ROIs wrapping CISLs are manually labeled and annotated by an experienced radiologist to produce a gold standard. The resultant number of ROIs is 511. The set of all these available instances is nearly evenly divided into five disjoint subsets. Furthermore, we guarantee that any two of the five subsets do not contain the instances from same patients, so that the bias in measuring classification performance is avoided. Table 1
                            lists the numbers of ROI examples in five data subsets, the total numbers of ROI examples and the numbers of patients for each CISL category, where NoP means “the number of patients”. In the lung images from a patient, perhaps there are several ROIs with a same CISL. It means that a patient could be corresponding with several instances with a same CISL, so the number of instances could be larger than that of patient. Based on these five data subsets, we conducted the 5-fold cross validation experiments of CISL recognition. Actually, each of five data subsets is taken as the test set in turn. Then the two subsets in the remaining data are selected randomly as the training set and the other two data subsets as the validation set.

The performance of the algorithm is evaluated by the commonly used three measurements: sensitivity and specificity, classification accuracy rate and the confusion matrix.

The sensitivity measures the proportion of actual positives which are correctly identified, while the specificity measures the proportion of negatives which are correctly identified. If a positive example can be recognized correctly by the algorithm, we call it ‘true positive’; otherwise we call it ‘false negative’. The means of ‘true negative’ and ‘false positive’ are defined similarly. Let TP, TN, FP, FN be the number of true positives, true negatives, false positives and false negatives, respectively. Then the sensitivity and the specificity are measured as TP/(TP+FN) and TN/(TN+FP), respectively.

The classification accuracy rate is the ratio of the number of correctly classified examples to the number of all examples.

As described in Section 3.1, the confusion matrix is another popular tool for evaluating the performance of multi-class pattern recognition. It reflects the tendency of the classifier to classify a pattern into a correct class or into any of other wrong classes.

We calculated these algorithm performance measurements in each round of 5-fold tests and obtained the average sensitivity, specificity, classification accuracy rate and confusion matrix to evaluate the algorithm.

@&#EXPERIMENTAL RESULTS@&#

As mentioned before, we use our classifier fusion method to combine the five classifiers, including ‘BPNN’, ‘NB’, ‘SVM’, ‘k-NN’ and ‘DT’. We conducted the 5-fold cross-validation experiments of CISL recognition by using each individual classifier and our fused classifier, respectively. The corresponding results from each single classifier and our fused one are shown in Table 2
                           . Notice that we choose the best k for the k-NN in each round of 5-fold cross-validation experiments by testing each number from 1 to 50. The resultant best values of k in five rounds of tests are 1, 2, 3, 5 and 8, respectively.

As shown in Table 2, the proposed classifier fusion method brought obviously better recognition performance than five single classifiers. Compared with the BPNN, NB, SVM, k-NN and DT, our method brought the increase rate of 6.05%, 6.14%, 6.62%, 8.25% and 12.30% in classification accuracy rate, respectively. As for the sensitivity and specificity, our method brought an obvious increase in sensitivity as well as a little increase in specificity. The increase rates in average sensitivity are 11.18%, 3.20%, 18.68%, 5.90% and 12.73%, respectively, and the increase rates in average specificity are 0.56%, 0.44%, 0.86%, 0.79% and 0.79%, respectively. Since the specificity of each single classifier is already high, it is reasonable that the growth rate in specificity is not very obvious.

In addition, we compare our method with the single classifiers from the view of computation efficiency. We record the average running time of 5-fold cross-validation experiments for each single classifier and our fused one in seconds, respectively. The resultant learning time and recognition time are shown in Table 3
                           . Notice that all the algorithms run in a PC computer with 2.33GHz CPU and 4GB Memory. The learning time of our classifier fusion method is the sum of the training time of all the single classifiers and the computation time of the confusion matrix for each classifier. As shown in Table 3, our learning time is 29.46s which is bigger than the sum of the learning time (29.23s). The additional time is consumed for the construction of confusion matrices. The case is similar for the recognition time. Our time is the sum of the recognition time of all the single classifiers and the time of weight computation. According to the data shown in Table 3, the weight computation consumed 0.00223s, which is real-time. So the recognition by our fused classifier will be real-time, if each involved single classifier is real-time. Furthermore, it is possible to perform each single classifier in parallel to further improve the efficiency.

We further evaluate our method by comparing it with two well-known ensemble classifiers, Bagging and AdaBoost, through the same 5-fold cross-validation experiments. In our experiments, we used the same SVM, NB, BPNN, k-NN and DT implemented by WEKA as weak classifiers for both Bagging and AdaBoost. The performance measurements recorded for each CISL are shown in Table 4
                           , where ‘Se’, ‘Sp’ and ‘ACC’ means ‘sensitivity’, ‘specificity’ and ‘classification accuracy rate’, respectively. From Table 4, we can see that our method behaved better than both Bagging and AdaBoost. The classification accuracy rate from our method is 76.79%, which is better than 75.61% from the Bagging and 75.62% from the AdaBoost. Furthermore, compared with Bagging, our method brought the increase rates of 10.90% and 0.09% in average sensitivity and specificity, respectively, and compared with Adaboost, it brought the increase rates of 6.07% and 0.24% in average sensitivity and specificity, respectively. Through observing the performance of three fusion methods on each CISL category, we find out that our method can obviously improve the recognition rate on some CISL categories, compared with other two methods. For example, the sensitivity obtained by Bagging for AB category is 0%, but that by our method is 39.29%. The same phenomenon occurred on spiculation category for AdaBoost and our method. Although our method is not always the best one on all the categories, the improvement brought by Bagging and AdaBoost is less distinct than that shown in the two examples above. It shows that our method is more stable for the CISL classification problem.

We further make use of the confusion matrix to compare the performance of our method with those of Bagging and AdaBoost on each category. Actually, we calculate the confusion matrix of our method, Bagging and AdaBoost, respectively. Then we subtract the confusion matrix of Bagging and AdaBoost from our confusion matrix, respectively. As a result, we obtain two differential confusion matrices and show them in Fig. 3
                           . The diagonal elements in a differential confusion matrix reflect the difference of two methods in accuracy rates, and non-diagonal elements in error rates. Therefore, we hope that the values of diagonal elements are positive and the larger the value is, the better our method is. As for non-diagonal elements, the situation is the opposite. According to Fig. 3, the sums of diagonal elements in two differential confusion matrices are 0.5595 and 1.6857, respectively. As for non-diagonal elements, the sums are −0.5595 and −1.6857, respectively. These values demonstrate that our method leads to better discriminative ability.

In the end, we compare our method with other ensemble classifiers, Adaboost and Bagging, on the computation efficiency, through the same 5-fold cross-validation experiments. We record the average running time of Bagging and AdaBoost and show them in Table 5
                           . By comparing Tables 3 and 5, we can see that our learning time is the least one among three ensemble methods. The reasons behind this phenomenon are the Bagging needs to sample from the training set and AdaBoost needs to reweight the training samples during the each iteration. Our recognition time is little more than those of Bagging and AdaBoost due to the fact that Bagging makes the final decision by voting while the weights of classifiers of Adaboost are fixed for any test samples. But our method still perform recognition in real-time. Under this situation, it is reasonable to trades recognition time for accuracy. As shown in Table 4 and Fig. 3, our method brought better effects.

In order to demonstrate the reasonability of our method more directly, we explored whether the weights computed by our method are reasonable. We observed 36 test examples, in which four examples for each CISL category. For each of them, we recorded its true category, the category predicted by classifiers and the weights of classifiers which are computed by our method. The results are listed in Table 6
                           , where each row is corresponding with one example, ‘Num’, ‘C’ and ‘W(classifier) ‘means the number of the example, its true class label, and the weights calculated for the base classifier shown in the bracket, respectively. There the class label ‘0′, ‘1′, …, ‘8′ represent the CISL category of ‘GGO’, ‘lobulation’, ‘calcification’, ‘CV’, ‘spiculation’, ‘PI’, ‘AB’, ‘BMP’ and ‘OP’, respectively. Furthermore, if a classifier gives an error prediction, we highlight its misclassified result and its corresponding weight values in bold type.

As shown in Table 6, the weight of a classifier making a false classification is usually smaller than those of the classifiers with right decision. Taking the example 5 as an example, it belongs to class 1 but the SVM misclassified it into class 5. The corresponding weight of SVM, computed by our method, is 0.0892. It is far less than the weights (0.2466, 0.1830, 0.2345 and 0.2466) of the other classifiers making correct predictions. So compared with the SVM, other classifiers making correct predictions will exert much more influence on the final decision. Thus the probability of correct classification will be increased. Although this expected characteristic is true for most of experimental cases, we observed that it does not always happen. Taking the example 20 as an example, the classifiers k-NN and DT recognized it correctly, but unfortunately, their weights are lower than those of BPNN, NB and SVM, which make false classification decisions. We carefully analyzed the reasons behind this kind of wrong computation and found out that the error was caused by the different ranges of classification confidences of different classifiers. For example, the classification confidences of k-NN vary from 0.005 to 0.963, while those for SVM are 0 to 0.222. To normalize the ranges of classification confidences of different classifiers is a possible solution for this problem, which will be investigated in our future work.

We further tested the robustness of our method by performing it on various combinations of the five single classifiers, respectively. The combined results are shown in Table 7
                           , where the sets in the first column indicate which classifiers are included in the combination and ‘N’, ‘B’ ‘S’, ‘K’ and ‘T’ means ‘BPNN’, ‘NB’, ‘SVM’, ‘k-NN’ and ‘DT’, respectively. For example, ‘(N,K)’ means the combination of BPNN and k-NN. By comparing the results in Table 7 with those from single classifier as shown in Table 2, we conclude that the accuracy rate of any combined classifier is always better than that of each component classifier in it. Furthermore, if the number of classifiers in the combination is larger than 3, the accuracy rates are improved steadily along with the increase of the number of classifiers. In other words, the combination of any four classifiers must leads to the better performance than that of any three classifiers, and the combination of all the five classifiers outperforms the combination of any four classifiers. These results confirm that our method is robust to classifiers.

In the end, we tested the robustness of our method by observing whether the fusion result could be affected by the features. We conducted the 5-fold cross-validation experiments of CISL recognition by using each type of original features, respectively. We recorded the corresponding average accuracy rates for each single classifier and the fused classifier. The results are compared in Table 8
                           , where LBP (P, R) means the LBP feature vector configured with P neighbors and radius R, as described in Section 4.1. From Table 8, we can see that compared with each single classifier, our fused one achieved the highest accuracy rate no matter what feature is used. It confirms that our fusion method is robust to not only classifiers but also features.

The above experimental results show that our fusion method is effective and robust. According to Dietteric [46], there are three main reasons behind the effectiveness of classifier fusion: statistical, computational, and representational. Our classifier fusion method belongs to the category of weighted sum fusion, thus it can make a direct assault on the representative problem. The weight computation is our main contribution. First, the historical reliability for computing weights is measured by the confuse matrices on the validation set, so it will help alleviate the risk of overfitting on the training set. Second, the on-line reliability for computing weights reflects the characteristic of the recognized sample. So our weighted sum of base classifiers is a local and self-adaptive representation. Compared with the traditional global and constant weighted representation, ours can find a better approximation to the true hypothesis. These are the reasons why our method is effective and robust in the experiments.

@&#CONCLUSIONS@&#

In this paper, a new weighted-sum method of multiple classifier fusion, called HISON, has been proposed for recognizing common CT imaging signs of lung diseases (CISLs). Our method is based on the confusion matrices of the classifiers and the classification confidence values outputted by the classifiers. Our work demonstrates that it is reasonable to fuse classifiers by considering not only the historical reliability but also the on-line reliability of the classifiers. Through considering these two types of reliability together, the weights computed for the classifiers making correct classification tend to be bigger than those for the classifiers making error prediction.

We apply the proposed HISON method to fuse five different classifiers, including support vector machine (SVM), Naïve Bayes (NB), back-propagation neural network (BPNN), k-nearest neighbor (k-NN) and decision tree (DT), for recognizing nine categories of common CT imaging signs of lung diseases (CISLs). In order to evaluate the resultant method, we conducted the 5-fold cross validation experiments on 511 Region of Interests in lung CT images and achieved the average sensitivity of 70.40%, the average specificity of 96.84% and the classification accuracy rate of 76.79%. These results are better than not only the single classifiers but also the two well-known methods of classifier fusion, Bagging and AdaBoost. From the perspective of sensitivity and specificity, compared with the best results from single classifiers, our method brought increase rates of 3.20% and 0.44%, respectively; compared with the Bagging and the Adaboost, the increase rates are 10.90% and 0.09%, 6.07% and 0.24%, respectively. From the perspective of classification accuracy rate, the increase rates brought by our method are 6.05%, 1.56% and 1.55% compared with the best result from single classifiers, the Bagging, and the AdaBoost, respectively. Our method brought not only better classification performance, but also the satisfactory computation efficiency. Our learning time is 29.46s and the recognition time for one sample is 0.00455. It proves that our method is a real-time classification method. We further show that the method is robust to not only classifiers but also features.

As mentioned in the experiments, a reason behind some unsatisfactory results from our method is that the ranges of classification confidences of classifiers are not uniform. In the next work, we want to investigate the normalization of classification confidences of classifiers for further improving the fusion effectiveness.

@&#ACKNOWLEDGMENTS@&#

This research was partially supported by National Natural Science Foundation of China (grant no. 60973059, 81171407) and Program for New Century Excellent Talents in University of China (grant no. NCET-10-0044).

@&#REFERENCES@&#


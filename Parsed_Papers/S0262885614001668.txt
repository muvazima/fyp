@&#MAIN-TITLE@&#Visual re-identification across large, distributed camera networks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Formalization of object re-identification problem in a distributed environment


                        
                        
                           
                           Re-identification treated as an open-world problem


                        
                        
                           
                           Novelty detection and forgetting included in the scheme


                        
                        
                           
                           A set of performance measures, geared towards open-world, distributed surveillance


                        
                        
                           
                           Experiments on a many-camera (36) surveillance dataset and publicly available source code


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Re-identification

Distributed sensors

Smart cameras

Visual-sensor networks

Surveillance

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

The increasing demand for security leads to a growing need for surveillance in many environments [1]. This includes installations of vast closed circuit TV (CCTV) systems; at the time of writing, London Underground has more than 12,000, and a typical casino in Las Vegas has more than 2000 surveillance cameras. Since visual sensors generate large amount of data, scalability becomes important, which gives rise to solutions based on distributed architectures — distributed camera networks. Computer-vision-based methods in camera networks are useful for different tasks, such as object detection and tracking, recognition of problematic or unlawful behavior, and re-identification of objects of interest. In this paper, we focus on the problem of re-identification [2–6], which is the process of finding correspondences between images of an object, acquired at different moments in possibly different camera views.

Visual sensor networks (VSNs) may provide relatively large amount of computing and storage resources, but these are typically, both spatially and topologically distant, and the computational capability of an individual node may be low to reduce per-node cost or preserve energy [7]. Consequently, random access to a distant resource may be prohibitively expensive in terms of required network bandwidth, especially in wireless multi-hop networks. While this may be trivially alleviated by replicating all data and processing across all nodes, this defeats the purpose of a distributed architecture and does not solve the polynomially-increasing communication burden. In a truly distributed system, both re-identification and learning are expensive operations; the input data appears randomly at multiple nodes, thus requiring constant exchange with all other nodes, which may or may not have relevant information about object's identity.

We present a holistic approach towards object re-identification in distributed camera networks, which specifically addresses the issues of distributed environments. Specifically, we claim the following contributions:
                           
                              •
                              Formalization of object re-identification problem in a distributed environment.

Treatment of re-identification as an open-world problem, with novelty detection and forgetting.

A set of performance measures that specifically address issues in open-world distributed surveillance.

Reproducible experiments on a many-camera surveillance dataset (“Dana36”, [8]), 8-camera SAIVT-SoftBio dataset [9] and publicly available experimental source code.
                                    1
                                 
                                 
                                    1
                                    The full source code can be downloaded from: http://vision.fe.uni-lj.si/research/reid/.
                                  The code reproduces all results and graphs from this paper. Researchers are encouraged to use it for rapid evaluation of their descriptors or datasets, evaluation of parameter influence and learning and forgetting strategies.

The remainder of this paper is organized as follows. After the overview of related work in Section 2, we explain the concept of re-identification in large, distributed camera networks in Section 3. The core of the proposed re-identification mechanism and the experimental methods we used are presented in Section 4, followed by experiments and results in Section 5. Section 6 concludes the paper.

@&#RELATED WORK@&#

The task of identifying an object based on its previous appearance in some other parts of the camera network is called re-identification. In this respect, we can think about re-identification as form of large-scale tracking [10], which is comprised of several distinct challenges. Therefore, we address these separately.

The most frequently studied problem in re-identification is representation of object's appearance. We do not aim to improve the state-of-the-art in this respect, however, since object description is a necessary part of any re-identification system, we present the work done so far for the sake of completeness.

Several approaches model whole body appearance, and have recently been compared by Doretto et al. [10]. Overall appearance is commonly modeled by color or brightness histograms, as for example in [11–13]. Spatial information can be added by representing appearances in joint color spatial spaces [14]. One of the popular approaches is a mixture of color features and texture features [2,15,16]. Other representations include spatio-temporal appearance modeling, such as [17] or spatial and appearance context modeling, such as [18]. Authors in [14] train a multi-class classifier for recognizing people using low-level feature, i.e., color and height histogram. In some approaches, as for example in [19], primitive features such as color, height and body aspect ratio are used in combination with simple threshold-based classification. There is a group of approaches that strives to normalize object appearance across multiple cameras, to improve the performance of appearance descriptors [20,21].

Several approaches use training data to learn a holistic representation based on different low-level features, for example in [22] based on the bag-of-features representations, or in [23] based on Haar-like features and dominant color descriptors. Parts-based approaches are used as well. Part identification and correspondence can be carried out in several ways. One is to use interest point operators such as SURF [24] as in [25] or in [26] and SIFT [27], for example in [28].

Several authors identify body parts by other means. Bak et al. [29] propose an approach for person re-identification using spatial covariance regions [30] of human body parts, which are detected by using Histogram of Oriented Gradients (HOG, [31]). An approach proposed by Farenzena et al. [32] is based on a pondered extraction of local features that encoded different information: chromatic information, structural information through uniformly colored regions, and the nature of recurrent informative (in an entropy sense) patches. Recently, authors in [4] proposed a novel multiple-shot approach, which builds a specific human signature model based on Mean Riemannian Covariance (MRC) patches extracted from tracks of a particular individual. Authors in [33] evaluate different features, trying to find the most suitable ones for person re-identification. They conclude that despite recent advances, person re-identification using local features remains challenging, which might be due to existing descriptors describing mainly shape and texture.

There seems to be a consensus in scientific community that a person re-identification is a difficult problem and despite the best efforts from computer vision researchers, some claim that it remains largely unsolved [34]. Recently, topic models started to appear as a representation of choice in surveillance and re-identification tasks. Such models are usually based on the Latent Dirichlet Allocation (LDA, [35]), see for example [22]. When used for human appearance representation, LDA does not provide topics with obvious, humanly-understandable meaning. Therefore, Liu et al. [16] devised a semi-supervised method for topic generation that yields topics which can be easily interpreted.

Further challenges arise from the need for distributed representation, which is especially important to guarantee efficient computation in large-scale networks.

As shown by recent work [26,22,23,28,36,37], the community is increasingly aware of constraints in distributed systems. The multi-stage approach proposed by Jungling et al. [28] provides local extraction of features on camera nodes, thus allowing the lower stages of re-identification to be performed by transmitting extracted features rather than images. Nevertheless, the approach builds its efficiency mainly on compact feature representation that is suitable for transmission and storage in distributed system, and does not provide a specific solution for efficient feature distribution in a large distributed camera system. In the system envisioned by Presti et al. [22], each node individually and autonomously processes the data acquired by its own camera. Communication among nodes enables knowledge sharing and is performed whenever an object leaves a camera's field of view. During the initialization phase, each node detects people and trains a LDA [35] model. These appearance models are propagated across the network and used both to describe incoming objects and to establish correspondences, but it is unclear how the underlying topic model is propagated. Authors claim that the knowledge of the camera network topology is not needed, but they only demonstrate results on data obtained from two cameras — a test case in which efficient feature distribution is obviously not an issue.

The issue of efficient feature propagation in large camera networks has been specifically addressed in our previous work [38]. We have shown that by using hierarchical encoding of features, it is possible to substantially decrease the amount of data transmitted across the network. However, such reduction is limited to matching, which is known in surveillance terminology as matching to the gallery set 
                        [15].

An important concept in surveillance and person re-identification is the novelty detection 
                        [39]. Despite being a classic task in computer vision that had been previously addressed, e.g., [40,41], novelty detection in surveillance received only limited attention, and was to the best of our knowledge used mainly in tasks such as detection of anomalies [42–44], detection of new classes of objects [45] or detection of unusual pedestrian behavior [46].

A large amount of work on pedestrian detection, tracking and activity analysis has been done in the framework of the successive PETS workshops. However, to the best of our knowledge, there are only few datasets that are specifically designed for identification and re-identification of pedestrians: the VIPeR dataset [2], the GRID dataset [47], the Person Reidentification dataset [3], 3DPeS [48] dataset, SAIVT-SoftBio [9] dataset, CUHKO02 [49] dataset, and our recent Dana36 dataset [8]. The first three provide only small number of images from one or two cameras, while 3DPeS contains video sequences for 200 people in a 8-camera multi-view setting, but provides bounding boxes for only about 1200 frames (a subset named 3DPeS ReId Snap). SAIVT-SoftBio consists of image sequences of 150 people, with average 400 frames per person observed with 8 cameras, but the observed persons pass a particular camera view only once. CUHK02 contains images of 1816 persons, but their identity is observed pairwise regarding the camera views, not on a global scale. The last one, Dana36 dataset, provides 23,683 images from 36 different camera views.

CAVIAR dataset
                           2
                        
                        
                           2
                           
                              http://homepages.inf.ed.ac.uk/rbf/CAVIAR/.
                         and iLids dataset
                           3
                        
                        
                           3
                           
                              http://www.homeoffice.gov.uk/science-research/hosdb/i-lids/.
                         are not primarily intended for evaluation of re-identification but may be used for this purpose as well. Due to lack of well-annotated, many-camera datasets, it is not surprising that most of the previously-mentioned work [22,3,10,28,16] has been done on datasets that include up to five cameras. This is a relatively small number, which does not exhibit problems that are specific to large-scale camera systems.

Our aim is to address those problems, which in our opinion have so far received insufficient attention. They include re-identification across topologically distant nodes, novelty detection, and objective evaluation in truly distributed surveillance scenarios. Our work is in several aspects most closely related to [36,28,22], and in some aspects, extends the work of [38]. Contrary to most of the related work, a) we focus on systems with many cameras (e.g., 36 in our dataset), b) we assume communication constraints, c) we assume that the people re-identification in realistic setting has an open world nature, with unknown number of true identities, and d) we assume that pre-training of a such system is either infeasible or impractical.

Object re-identification in camera network essentially requires obtaining object correspondences between any pair of possibly distant camera nodes. In this respect, it would be advantageous to have a single central processing server node that aggregates information from all cameras. The main characteristic of such fully-centralized architecture is the ability of the processing node to locally access any piece of stored information. This is the setting that is implicitly assumed, but usually not explicitly stated in most of the research on surveillance re-identification. Therefore, fully-centralized architecture is spatially constrained, and state-of-the-art classification and recognition algorithms do not scale well with the growing network size due to non-zero communication cost. Additionally, methods that assume closed-world nature of the re-identification, cause the system to be severely temporally constrained. This is true for essentially any discriminative method that requires training–testing approach and is evaluated by cross-validation.

A realistic, distributed camera network cannot rely on these constraints. A distributed system in a realistic setting is forced to perform re-identification from just a few visual samples, perhaps even from a single previously-obtained image or tracklet, and has to decide on-the-fly whether a sample represents novel identity or not. Even if the best known learning and classification algorithms are run locally or on a group of locally-clustered nodes, they cannot readily use negative samples from distant nodes without intensive and prohibitively expensive communication across the network.

Under such circumstances, obtaining even a basic feature correspondence between two distant nodes becomes a non-trivial task, whose complexity and the associated communication cost increase polynomially with the network size. To keep even this basic problem manageable, one can use optimized algorithms for routing of queries across the network, such as hierarchical scheme for feature distribution (HFD) and basic object matching [38] or algorithm for grouping cameras into neighborhoods [36]. If the capacity of the network allows, simple flooding can be used as well. In the rest of the paper we assume that the functionality of obtaining simple correspondence between the two distant nodes is available in the analyzed network.

@&#METHODS@&#

In the proposed distributed method for object re-identification, we assume that image features have already been extracted from an image into a feature vector. Without any loss of a generality, features could be extracted from a set of images, or a video sequence, but in the rest of the paper, we use the term “image”, which should be interpreted in a broad sense. We use a color histogram descriptor with some minor modifications, as described in Section 4.4. The descriptor is basic enough to allow quick and efficient demonstration of our framework and the effects that appear in camera network in a realistic setting. However, for practical applications, more sophisticated descriptors could be used, such as [20,36].

We formulate the re-identification problem as follows: given a new image of a previously-seen person, the re-identification system has to be able to determine that person's identity. This is achieved by comparing the new image to an image set that contains examples for each known person. Such examples are called gallery images 
                        [2,15] and the process is called gallery matching.

From a perspective of an external observer, the whole camera network behaves like a multi-class classifier. However, internally, this multi-class classifier consists of a number of binary classifiers that are distributed across a network, as illustrated by Fig. 1 and Fig. 2
                        
                        .

Assuming that feature vectors x
                           
                              i
                            have been already extracted from the corresponding images, we define a set of gallery feature vectors, which represent unique identities of objects that are known to our system as
                              
                                 (1)
                                 
                                    
                                       X
                                       gallery
                                    
                                    =
                                    
                                       
                                          
                                             x
                                             i
                                          
                                          |
                                          i
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          L
                                       
                                    
                                    ,
                                 
                              
                           where L is the number of known identities. The situation is shown in Fig. 1. When the system observes a new feature vector x, it performs classification by comparing x to each sample from X
                           
                              gallery
                           . In terms of object classification, we are dealing with the set Ω of L binary classifiers, Ω
                           ={ω
                           
                              i
                           |i
                           =1,…,
                           L}, each providing a binary decision y
                           
                              i
                           
                           ∈{−1,1} whether x belongs to the class i or not. The binary decision of classifier ω
                           
                              i
                            is based on the value of its gallery vector x
                           
                              i
                           :
                              
                                 (2)
                                 
                                    
                                       ω
                                       i
                                    
                                    :
                                    
                                       x
                                       
                                          x
                                          i
                                       
                                    
                                    ↦
                                    
                                       y
                                       i
                                    
                                    .
                                 
                              
                           
                        

In the simplest case, the classifier ω
                           
                              i
                            calculates the distance d
                           
                              i
                           
                           =
                           d(x
                           
                              i
                           ,
                           x) and applies the threshold T:
                              
                                 (3)
                                 
                                    
                                       y
                                       i
                                    
                                    =
                                    
                                       
                                          
                                             
                                                +
                                                1
                                             
                                             
                                                d
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   x
                                                
                                                ≤
                                                
                                                T
                                             
                                          
                                          
                                             
                                                −
                                                1
                                             
                                             
                                                otherwise
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

In a distributed system, objects are seen by different nodes on different occasions. Therefore, gallery images are scattered across the network and the cost of transmitting them to the single location is high. Effectively, this means that the classifiers ω
                           
                              i
                            are distributed across the network, as shown in Fig. 2. Since we formulate the classification task as gallery matching using L classifiers and a global threshold T, such structure can exist in a distributed form, as for example in [38]. In a distributed setting, the communication between the nodes is costly, and therefore the distributed classifiers ω
                           
                              i
                            cannot efficiently compete for a best match. Consequently, the system may produce multiple positive answers, without the individual classifiers ω
                           
                              i
                            being aware of that. However, from the system perspective, the recipient of this information can aggregate the positive results from individual classifiers — transmission of distances that are below the threshold T across the network incurs only marginally higher communication costs than simply reporting the occurrence of the match. The recipient may then select the best match by comparing the multiple received distances, as follows:
                              
                                 (4)
                                 
                                    y
                                    =
                                    
                                       argmin
                                       i
                                    
                                    
                                       
                                          d
                                          
                                             
                                                x
                                                i
                                             
                                             x
                                          
                                       
                                    
                                    |
                                    d
                                    
                                       
                                          x
                                          i
                                       
                                       x
                                    
                                    ∈
                                    
                                       Δ
                                       T
                                    
                                 
                              
                           where y is the final object label and Δ
                              T
                            is the set of distances below the threshold T, as received from all the individual classifiers ω
                           
                              i
                            that reported the match. This formulation is similar to the operation of the one-versus-all multi-class classifier, but the distributed nature precludes centralized learning due to the communication cost.

A typical surveillance environment is highly dynamic, and any pre-training is thus of a limited value. This aspect does not appear if cross-validation on a closed dataset is used — such approach implicitly assumes that a system can be successfully pre-trained and that the obtained knowledge never expires. Conversely, we assume that a re-identification system does not have any prior knowledge about objects — initially its gallery is empty. Therefore, online learning is a critical component of such a system. If the learning is unsupervised – a desirable property for fully automated operation – then the novelty detection is needed as well. We implement novelty detection as a complement of classification rule (3):
                              
                                 (5)
                                 
                                    
                                       y
                                       novelty
                                    
                                    =
                                    
                                       
                                          
                                             
                                                +
                                                1
                                             
                                             
                                                d
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   x
                                                
                                                >
                                                T
                                                |
                                                ∀
                                                i
                                                =
                                                1
                                                ,
                                                …
                                                ,
                                                L
                                             
                                          
                                          
                                             
                                                −
                                                1
                                             
                                             
                                                otherwise
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where y
                           
                              novelty
                           
                           =+1 signals that x is sufficiently distant from all of the gallery vectors in X
                           
                              gallery
                            that it can be regarded as describing a novel object. Effectively, at this point, a new classifier ω
                           
                              L
                              +1 is created from the novel feature vector x at the camera node that observed the object.

Such implementation of novelty detection has its own drawbacks — if the amount of false positives according to rule (5) is greater than zero (a realistic assumption), such scheme may result in a continuously increasing gallery and a continuously increasing number of the corresponding classifiers ω
                           
                              i
                            across the network. Depending on the circumstances, this number may be far larger than the true number of unique object identities (L
                           ≫
                           NID
                           ). This leads to identity fragmentation — since we are forced to assume that each classifier ω
                           
                              i
                            represents a unique object, a single object observed by the system may end up being recognized as several different entities.

The number of unique objects encountered in realistic surveillance environments is essentially unbounded. Consequently, the amount of knowledge accumulated during the operation of the system may be overwhelming. On the other hand, knowledge may become obsolete after a certain period of time after the last observation. People may change their clothing or appearance, or they may simply leave the observed area. Therefore, some kind of systematic forgetting needs to be implemented.

Conceptually, forgetting addresses the general problem of limited resource management. In our case, the resources are limited by the maximum number of classifiers ω
                           
                              i
                            and the storage capacity required to store the associated gallery feature vectors x
                           
                              i
                           . Situations of similar nature have been already dealt with in computer science, e.g., cache management and page replacement algorithms.

When managing the number of classifiers ω
                           
                              i
                           , one should be aware of the following two basic factors:
                              
                                 •
                                 
                                    Aging. Probability that the data will be needed decreases with the time that has passed from the last observation of an object.


                                    Limited resources. In unfavorable conditions, some data must be discarded due to the lack of resources.

Accordingly, we define two parameters for our forgetting scheme. During the run, each classifier ω
                           
                              i
                            is associated with its time-to-live counter τ
                           
                              i
                           . The parameter τ
                           
                              max
                            determines the maximum value of τ
                           
                              i
                           , at which classifier ω
                           
                              i
                            and its gallery feature vector x
                           
                              i
                            expire. Whenever the classifier ω
                           
                              i
                            provides a positive answer, the counter τ
                           
                              i
                            is reset to its initial value. This way, we prevent accumulation of outdated information, but retain the information that was recently used. On the other hand, each node can contain only the limited number of classifiers. Therefore, node j is associated with the counter of stored classifiers, λ
                           
                              j
                           . Hence, the second parameter is the maximum number λ
                           
                              max
                            of classifiers ω
                           
                              i
                            per node, which constrains the memory and processing resources used by our method, and reduces identity fragmentation.

Depending on those parameters and input data, the system operates between the two operating points: limited lifespan, where classifiers ω
                           
                              i
                            are discarded mainly due to their age and limited capacity, where classifiers ω
                           
                              i
                            are discarded mainly due to the appearance of freshly-learned ones.

The hierarchical feature-distribution scheme (HFD, [38,50]) solves very narrow, yet fundamental problem in distributed camera networks: how to efficiently obtain correspondence between the acquired feature vector with unknown identity on one side, and the number of distant and topologically distributed feature vectors with known identities on the other. Using HFD, each node in the network has the ability to query the whole network for the objects that are similar to the observed object.

The classification rule (3) can be implemented either in a centralized or in a distributed system. It directly corresponds to classification approach as defined by HFD and therefore needs no additional modifications.

The classification rule for novelty detection (Eq. (5)) uses simply an inverted logic of the classification rule (3). Therefore, it maps onto HFD without modifications.

Given the classification rule (3), HFD can be viewed as an efficiently managed structure of many simple binary classifiers, distributed among the nodes. Those classifiers forward the query packets based on their own classification results, until the query reaches the node with authoritative classification answer (the actual classifier ω
                        
                           i
                        ). A series of “routing classifiers” correspond to a single ω
                        
                           i
                        . Therefore, routing classifiers can share attributes (such as τ
                        
                           i
                        ) with ω
                        
                           i
                         and follow its fate — dying when ω
                        
                           i
                         is removed from the classifier set due to forgetting.

Recently, we published a dataset “Dana36”
                           4
                        
                        
                           4
                           
                              http://vision.fe.uni-lj.si/research/dana36/.
                         
                        [8]. It is intended for evaluation of object matching and recognition methods in surveillance scenarios. The dataset consists of 23,683 images depicting 15 persons and 9 vehicles. The dataset was acquired from 36 stationary camera views using a variety of surveillance cameras. 27 cameras observed the persons and vehicles in an outdoor environment, while the remaining 9 observed the same persons indoors. Due to the large number of camera views, the dataset is especially suitable for research on large-scale distributed camera networks in surveillance scenarios. Instances of different objects are shown in Fig. 3
                        . In this work, we use color-histogram-based descriptor. The re-identification problem on the whole dataset is a difficult one due to large variations between cameras (resolution, location, vantage point, indoor, outdoor and mixed lighting) and similarity between many of the objects and persons. In this situation, it makes sense to either merge visually similar classes, or to retain only the classes that exhibit obvious visual difference. We chose the latter option, selecting 13 most visually-distinctive ones: persons labeled 1, 3, 5, 8, 9, 11, 12, and 15 and cars labeled 16, 17, 18, 22 and 24 (referred to as 13-object subset Dana3613 and consisting of N
                        
                           Dana36,13
                        =13,483 images).

Dana3613 dataset was complemented with the use of SAIVT-SoftBio [9] dataset, which provides image sequences of 152 persons, but only 8 camera views. However, for each observation, it provides the image sequence and corresponding bounding boxes. Since it provides the information about the temporal sequence of observations, it allowed us to simulate the exact, realistic sequence of events.

In our experiments, we use a segmented color histogram: a cropped image of an object is divided into 25 overlapping rectangular segments, and a set of 25 color histograms H
                        
                           k
                        (k
                        =1,...,25) is computed. We use a three-dimensional RGB histograms with 4×4×4 bins, resulting in 1600-dimensional feature vector (64×25). To compare two sets of image features x
                        
                           i
                         and x
                        
                           j
                        , we compute the distance d(x
                        
                           i
                        ,
                        x
                        
                           j
                        ) as the average distance across all image segments:
                           
                              (6)
                              
                                 d
                                 
                                    
                                       x
                                       i
                                    
                                    
                                       x
                                       j
                                    
                                 
                                 =
                                 
                                    1
                                    25
                                 
                                 
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       25
                                    
                                    
                                       
                                          d
                                          k
                                       
                                       
                                          
                                             x
                                             i
                                          
                                          
                                             x
                                             j
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

The distance d
                        
                           k
                        (x
                        
                           i
                        ,
                        x
                        
                           j
                        ) between two segment histograms H
                        
                           i,k
                         and H
                        
                           j,k
                         is the Hellinger distance. The range of the distance measure d(x
                        
                           i
                        ,
                        x
                        
                           j
                        ) is between zero (complete similarity) and one (complete dissimilarity). The exact implementation of the descriptor is available as part of our source code download.
                           5
                        
                        
                           5
                           
                              http://vision.fe.uni-lj.si/research/reid/.
                         The descriptor has been adapted to work on image sequences as well; in that case, histograms are obtained by counting the pixel values inside bounding boxes across multiple images from the sequence.

Using the Dana36 and SAIVT-SoftBio, the descriptor performs sufficiently well to illustrate our approach, and in combination with the threshold T it allows simple adjustment of the operating point of the classifier (the ratio of false and true positives of the binary classifiers ω
                        
                           i
                        ). Therefore, we can easily observe our proposed approach at different operating points of the classifier set Ω.

To evaluate the proposed method for re-identification in distributed camera networks, we define a set of measures that are relevant to distributed re-identification.

Since we deal with multi-class classification, we first evaluate multiclass recognition performance as seen from the recipient of the multiple distances scores (Eq. (4)). For this purpose, we obtain the confusion matrix, and calculate the multi-class accuracy (Acc
                           
                              multiclass
                           ) as the ratio of results on the main diagonal of the confusion matrix vs. the number of all results.

However, Acc
                           
                              multiclass
                            does not present the whole picture. In evaluation of each new sample, all classifiers from the current classifier set Ω are consulted; this could be done in an optimized way, as shown for example in [38], or with simple flooding of the unknown sample across the network. In either case, a querying node receives none, one or more responses from the other network nodes, and the number of replies affects the network traffic. This aspect is mostly irrelevant in centralized implementation, however, in distributed setting, it is not. Therefore, we keep track of overall statistics from the binary classifiers, by observing the numbers of false positives (FP) and true positives (TP), false negatives (FN), true negatives (TN) and total number of tested samples (M) across all classes (micro-averaging [51]). We declare a result of a classification of the vector x using the classifier ω
                           
                              i
                            as a true positive if the true identity of x corresponds to the identity represented by ω
                           
                              i
                           . Similarly, we count the number of FP, TN and FN. In our case, M denotes a number of individual tests done on all classifiers Ω, {ω
                           
                              i
                           ;
                           i
                           =1,…,
                           L}. Finally, we calculate standard classification measures [52] — due to the effect they have on the network traffic, we primarily observe false positive rate (FPR) and true positive rate (recall or TPR).

The classification rates alone do not show the whole picture regarding the performance of the network. Therefore we keep track of the few additional values. U is the number of unknowns, or the objects that yield no positive answer from any classifier ω
                           
                              i
                           . We also observe the number of learned classifiers (corresponding to the number of gallery images — L) and the number of the unique object identities observed by the system (N
                           
                              ID
                           ). Finally, we keep tally of the unique object identities that are represented by the existing gallery or classifier set (N
                           
                              ID
                           (Ω)).

From these counts we define three additional measures: identity fragmentation (F
                           
                              ID
                           ), unknown rate (UR) and classifier coverage (C):
                              
                                 (7)
                                 
                                    
                                       F
                                       ID
                                    
                                    =
                                    
                                       
                                          L
                                          −
                                          
                                             N
                                             ID
                                          
                                          
                                             Ω
                                          
                                       
                                       
                                          N
                                          ID
                                       
                                    
                                 
                              
                           
                           
                              
                                 (8)
                                 
                                    U
                                    R
                                    =
                                    
                                       U
                                       M
                                    
                                 
                              
                           
                           
                              
                                 (9)
                                 
                                    C
                                    =
                                    
                                       
                                          
                                             N
                                             ID
                                          
                                          
                                             Ω
                                          
                                       
                                       
                                          N
                                          ID
                                       
                                    
                                    .
                                 
                              
                           
                        

Identity fragmentation occurs due to the presence of false negatives: if all classifiers ω
                           
                              i
                            give negative result on a previously-seen object, this triggers unnecessary learning of this object's identity. If the same objects are learned more than once, the correct response of such system may result in several distinct labels. Naturally, an ideal system would have F
                           
                              ID
                           
                           =0, along with high recognition rates.

The second measure that is related to the same phenomenon is the unknown rate, UR. When all of the classifiers ω
                           
                              i
                            give negative result for an input sample, the system has to conclude that the object is unknown (and proceeds with learning). Therefore, in the absence of forgetting, the unknown rate is related to increase in the total number of learned classifiers, L — a greater unknown rate UR causes faster learning. At the beginning, an ideal system would have unknown rate UR
                           =1. If such ideal system was faced with the problem of closed nature (a finite number of object identities in input data) UR would then approach zero. In theory, unknown rate UR increases if we force the system to start forgetting accumulated knowledge.

The third measure is associated with the opposite phenomenon, which occurs due to non-zero FPR — occasionally, a system will observe a new object, but fail to recognize it as such, falsely assigning it to one of already known identities. If such behavior is consistent for a particular object, its identity will never be learned and the system will always produce erroneous response when encountering that object. In that case, such system will have classifier coverage C
                           <1. On the other hand, an ideal system would consistently have C
                           =1.

The re-identification problem, as addressed in this paper, has a dynamic and open-world nature. To further illustrate the need for the proposed measures, we provide a step-by-step example, which address three hypothetic, yet realistic scenarios. Note that in these scenarios we assume a specific made up sequence of classifier decisions, to illustrate as many aspects of the proposed measures as possible.

The first scenario is a general one, depicted in detail in Fig. 4
                           , with its final outcome shown in Fig. 5(a). The surveillance system starts its observation with an empty set of classifiers Ω
                           =∅ (not shown in Fig. 4). The values of M and L increase with the number of test samples and the number of classifiers, respectively, so we do not explicitly track their progress. The sequence is started by a sample with identity (true class value) of 1. Since the classifier set Ω is empty, this sample is considered to be unknown, therefore the number of unknown samples U increases. The classifier ω
                           1 is created, and the number of identities represented by the classifier set, N
                           
                              ID
                           (Ω) is incremented to 1. In terms of classification, this sample does not influence TP, FP, TN or FN. The outcome of this step is shown in Fig. 4(a).

Suppose that the next sample has the true class value of 5, but is incorrectly classified as 1. Therefore, FP is incremented (Fig. 4(b)). The next sample has the true class value of 2, and after a negative classification result by the only classifier ω
                           1, it is declared as unknown. Therefore, a new classifier ω
                           2 is created, and N
                           
                              ID
                           (Ω) is incremented to 2. U and TN are incremented as well, since the sample was unknown, and the ω
                           1 yielded the correct result (Fig. 4(c)).

The next sample has true class value of 5 and is (incorrectly) positively recognized by ω
                           2 (FP is incremented) and (correctly) recognized as negative by ω
                           1 (TN is incremented). The situation is depicted in Fig. 4(d). The next sample has true class value of 3 (depicted in Fig. 4(e)) and is correctly declared as unknown and yields the new classifier ω
                           3 (U, N
                           
                              ID
                           (Ω) and TN are incremented accordingly). The next sample has the true class value of 3 and is correctly rejected by ω
                           1 and ω
                           2 (TN is incremented accordingly), but incorrectly rejected by ω
                           3, therefore a new classifier ω
                           4 is created. In this case, FN and U are incremented, but N
                           
                              ID
                           (Ω) is not — even with the classifier ω
                           4, the system represents only three unique classes, effectively, ω
                           4 is redundant and contributes to identity fragmentation. This case is shown in Fig. 4(f). A new sample, with true class value of 3 is correctly rejected by ω
                           1 and ω
                           2 (TN is incremented), incorrectly rejected by ω
                           3 (FP is incremented) and correctly recognized (positively classified) by ω
                           4 and therefore, TP is incremented (Fig. 4(g)). The next three samples have true identity of 4, the first one creates a new classifier ω
                           5 and the two that follow are correctly classified by ω
                           5 and rejected by other classifiers. TN, U, N
                           
                              ID
                           (Ω), and TP are incremented accordingly. The situation is shown in Fig. 4(h).

The next two samples have true class value of 2. The first one is incorrectly rejected by ω
                           2 and correctly rejected by other classifiers, creating ω
                           6, incrementing U, TN and FN, but not N
                           
                              ID
                           (Ω) and resulting in situation shown in Fig. 4(i). The next one is (correctly) recognized by ω
                           6 and rejected by classifiers ω
                           1, ω
                           3, ω
                           4, and ω
                           5, but (incorrectly) rejected by ω
                           2 — the outcome is shown in Fig. 5(a). In this case, TP, TN and FN are incremented. Note that the final value of L
                           =6 (we have 6 classifiers), N
                           
                              ID
                           (Ω)=4 (these classifiers model four unique classes), and N
                           
                              ID
                           
                           =5 (we have shown the system samples from five unique classes). The outcome along with the final values of the evaluation measures is shown in Fig. 5(a).


                           Fig. 5(b) and (c) shows results of degenerate scenarios. In scenario (b) all samples are below the threshold, and therefore, after the first sample creates ω
                           1, all the others are accepted as being in the same class, either correctly or incorrectly. Note that in this case, the poor performance is shown through a low value of classifier coverage, C — the system does not model the majority of the classes, resulting in low recognition performance (high FPR). In scenario (c), four samples with a common identity are shown to the system, and are recognized by none of the classifiers created along the way. This results in a high number of false negatives (FN), but more importantly, it also results in a very high identity fragmentation F
                           
                              ID
                           .

We performed experiments in the following manner. First, a matrix of pairwise feature distances d(x
                        
                           i
                        ,
                        x
                        
                           j
                        ),
                        i,
                        j
                        ∈1,…,
                        N for each of the datasets was computed using a segmented color histogram descriptor from Section 4.4. In the case of Dana36, features were pre-calculated from single images, cropped by the bounding box, and in the case of SAIVT-SoftBio, features were pre-calculated from image sequences, which were cropped according to the provided bounding boxes.

Binary classification threshold T, common to all future classifiers ω
                        
                           i
                        , is chosen. The system is initialized with an empty set of classifiers Ω
                        =∅. Then a sample-by-sample test run is performed, as shown in Algorithm 1.

Note that all statistics are gathered in each step, therefore measures, such as FPR, TPR and others, become functions of step t, FPR
                        =
                        FPR(t), TPR
                        =
                        TPR(t), etc. In the case of Dana36, our test run contains a random component (sampling of feature vectors x). Therefore we repeat the test multiple times, and calculate mean and standard deviation for all of the observed measures. Standard deviation is in this context a measure of system stability — large standard deviation would indicate that system performance heavily depends on the actual sequence of input samples. In the case of SAIVT-SoftBio, the sequence of observations, as provided by the dataset itself, was used, and the test was performed without repetition.

So far, we always assumed that there is exactly one gallery feature vector x
                        
                           i
                         per classifier ω
                        
                           i
                        . However, this concept can be extended with the possibility that each classifier contains multiple gallery vectors x
                        
                           ik
                         that model variations in the class it represents (k
                        =1,…,
                        K
                        
                           i
                        , K
                        
                           i
                         is the number of vectors in the classifier ω
                        
                           i
                        ). There are many possibilities of implementing such functionality, however, to stay within the constraints of the distributed camera network, the behavior of the classifier ω
                        
                           i
                         towards the network must remain exactly the same.

Internally, classifier ω
                           
                              i
                            calculates multiple (that is, K
                           
                              i
                           ) distances d
                           
                              ik
                           
                           =
                           d(x
                           
                              ik
                           ,
                           x) to the observed vector x, one for each of the stored vectors x
                           
                              ik
                           , and d
                           
                              i
                            is assigned the smallest of the distances d
                           
                              ik
                           . Then, classification rule (3) is applied to the obtained d
                           
                              i
                            and the decision whether x is positive or negative is made.

If a result of classification is positive, the distance d
                           
                              i
                            is checked against two learning thresholds, T
                           
                              inner
                            and T
                           
                              outer
                           . If it lies between them, T
                           
                              inner
                           
                           <
                           d
                           
                              i
                           
                           <
                           T
                           
                              outer
                           , then the newly recognized sample x is added to the classifier ω
                           
                              i
                           's gallery and K
                           
                              i
                            is incremented by one. T
                           
                              inner
                            prevents the learning of the samples that are very close to existing samples in the ω
                           
                              i
                           's gallery and would waste resources; on the other hand, T
                           
                              outer
                            determines the maximum allowed degree of adaptation of the classifier in a single step.

Instead per-classifier, the forgetting is re-formulated to operate on per-vector basis — when all of the classifier's gallery feature vectors are forgotten, the classifier itself is removed from the classifier set.

Since the behavior of each single classifier towards the network remains the same, all evaluation measures remain valid even for a case with multiple gallery samples.
                              Algorithm 1
                              Evaluation (full run)
                                    
                                       
                                       
                                    
                                 
                              

@&#EXPERIMENTS AND RESULTS@&#

Experiments have been designed to examine the following:
                        
                           •
                           The behavior of the proposed approach during the test run. In particular, we are interested in the dynamics of the evaluation measures.

The stability of the proposed method, expressed as standard deviation of evaluation measures among the multiple test runs.

The effects of parameter variation — we varied T, τ
                              
                                 max
                               and T
                              
                                 outer
                              , one at a time, with all other parameters fixed.

Unless specified otherwise, the experiments were performed with the following settings: based on our preliminary research, we set the threshold T to T
                     13
                     =0.5. At this threshold, false positive rate on Dana36 was estimated to be below 20%. Online updating of samples was disabled (T
                     
                        inner
                     
                     =
                     T
                     
                        outer
                     
                     =1), except in the last experiment, when the influence of T
                     
                        outer
                      was examined.

Each run consisted of 2000 steps on Dana36 and 788
                        6
                     
                     
                        6
                        This is the actual number of samples in the SAIVT Soft-Bio dataset.
                      steps on SAIVT-SoftBio. Our implicit assumption is that new images or image sequences arrive in constant time intervals, therefore, in the rest of the paper, we equate the step number with time. To estimate standard deviation of observed measures, each test on Dana36 consisted of 10 runs — in this case, each sample is drawn uniformly without replacement. When comparing multiple tests (e.g., to determine the influence of parameters), a sequence of pseudo-random numbers is restarted between the tests, to provide consistent results.

In this case, τ
                        
                           max
                         and λ
                        
                           max
                         are set to infinity, which means that no classifiers expired during the test run. This simulates the system that retains all the acquired information.

The results for both subsets are shown in Fig. 6
                         and summarized in Table 1
                        .

As seen in Fig. 6, at the beginning of the run, there is intensive learning, indicated by high values of unknown rate UR, and steeper slope for number of classifiers L. Later, the increase in L is more gradual. The number of unique identities represented by classifier set Ω, N
                        
                           ID
                        (Ω) rises, but with the parameters selected, it does not reach the true number of identities in the observed data, N
                        
                           ID
                        . This also results in the final classifier coverage C being below one. For both datasets, after the initial instability, TPR slowly falls until the end of experiment. The multi-class accuracy measure Acc
                        
                           multiclass
                         for SAIVT-SoftBio may seem low at first glance, but one should remember that recognizing identities of 152 persons is a very difficult problem — a random classifier would yield Acc
                        
                           multiclass
                         of only 1/152=0.0066.

In the next two experiments, we examined the performance of a system with forgetting. Two extreme operating points were selected. In the first one, we enforced the limited lifespan, with τ
                        
                           max
                        
                        =100 steps for Dana36 and τ
                        
                           max
                        
                        =10 for SAIVT-SoftBio. In the second part of the experiment, we enforced limited capacity, with λ
                        
                           max
                        
                        =2 classifiers per node for both datasets.

Results for this case are shown in Fig. 7
                            and in Table 1. In comparison to the approach without forgetting, the graphs show that the limited-lifespan-based forgetting scheme introduces some instability into the number of classifiers L on Dana36 dataset. At the beginning, the system learns quickly and levels off as the classifiers start to expire. Due to quick learning at the beginning, several classifiers expire approximately at the same time. This effect is visible as lower rise and then drop-off in L. The other effect of such forgetting scheme is well visible in results for SAIVT-SoftBio — much smaller number of classifiers L, and correspondingly smaller classifier coverage (C), but also significant drop in identity fragmentation (F
                           
                              ID
                           ). This shows an important tradeoff of such forgetting scheme — identity fragmentation can be decreased, but at the cost of lower coverage and possibly less stable L. Finally, multi-class accuracy Acc
                           
                              multiclass
                            for SAIVT-SoftBio actually rises and displays slightly upwards trend due to benefits of forgetting on such realistic scenario. The system quickly forgets people which are not seen at any later moment, thus improving its odds at classifying people that actually appear.

Results for limited capacity are shown in Fig. 8
                           . Compared to limited lifespan, it can be seen that in this operating point there is no instability in L for Dana36, but increase in multi-class accuracy Acc
                           
                              multiclass
                            for SAIVT-SoftBio is still visible. The final results are shown in Table 1.

Previous experiments were performed with fixed parameter values, chosen to illustrate the dynamics of the proposed system during its operation. Nevertheless, parameters have significant influence on the performance and stability. We explored the influence of classification threshold T, which controls the operating point of classifier set Ω, the influence of maximum time-to-live parameter τ
                        
                           max
                         when limited lifespan is enforced, and the influence of learning threshold T
                        
                           outer
                        , which controls the degree of updating. We varied only single parameter and fixed the rest to values from the beginning of Section 5. When examining the influence of T and T
                        
                           outer
                        , forgetting was disabled (τ
                        
                           max
                        
                        =∞,
                        λ
                        
                           max
                        
                        =∞). Results for T and τ
                        
                           max
                         are shown in Figs. 9 and Fig. 10
                        
                        , respectively.

It can be seen that T and τ
                        
                           max
                         influence the behavior of the system in similar ways, despite the significant differences in nature of the data (Dana36 is image-based and samples were drawn randomly, SAIVT-SoftBio is image-sequence-based with predetermined sequence of events). Increasing the threshold T increases the number of true and false positives, while the classifier coverage C drops, along with identity fragmentation F
                        
                           ID
                        . This further confirms that there is tradeoff between higher C and lower F
                        
                           ID
                        . Similarly, lower τ
                        
                           max
                         reduces identity fragmentation, but also lowers the classifier coverage C. It is also obvious that both T and τ
                        
                           max
                         influence the multi-class accuracy Acc
                        
                           multiclass
                         — in the case of SAIVT-SoftBio dataset, intensive forgetting (low τ
                        
                           max
                        ) actually increases Acc
                        
                           multiclass
                        .

In the last batch of experiments, shown in Fig. 11
                        , we examined the influence of online updating threshold T
                        
                           outer
                        . Based on our preliminary experiments, the value of T
                        
                           inner
                         was set to a value of 0.05, and the value of T
                        
                           outer
                         was varied between 0.05 and 0.5 (the latter is the chosen value of the classification threshold T), resulting in more (high T
                        
                           outer
                        ) or less (low T
                        
                           outer
                        ) aggressive updating.

It can be seen that in this case, the accuracy Acc
                        
                           multiclass
                         does not improve with online updating — it even decreases with Dana3613. However, sufficiently aggressive updating does reduce identity fragmentation F
                        
                           ID
                        , which is a tangible benefit. With online updating, individual classifiers are able to model variations in data, therefore fewer new classifiers are created.

All presented results clearly demonstrate that in a distributed re-identification system that works on the realistic, open-world problem, there are many inter-dependencies among various aspects of the system performance — the recognition performance alone does not tell the whole story.

@&#CONCLUSION@&#

In this paper, we addressed re-identification problem in large, distributed camera networks — a topic that has been under-represented in the research so far. We formalized object re-identification problem in a distributed environment, and analyzed it as an open-world problem. We documented the obstacles that are inherent to truly distributed surveillance systems. These preclude the direct use of state-of-the-art algorithms, and demand that functionality of the system is built using only the limited resources available in a distributed environment. Assuming only this basic functionality, we built a scheme for distributed re-identification, which provides on-line learning, forgetting and novelty detection — critical components for addressing open world problems. Performance analysis in such distributed system requires more than just observing classification performance. Therefore, we proposed a set of measures geared towards distributed surveillance. We demonstrated that in such a system, we deal with multiple tradeoffs — even in the case of the simplest classification algorithm with a single parameter, the operating point of the classifier set influences several aspects of the system, not just classification rates. This interdependence may radically alter the overall performance of the re-identification system.

It should be noted that the presented method for constructing distributed re-identification system is generic. Even though we limited ourselves to color histograms, the method could be applied to more sophisticated cases where complex features are extracted from images or image sequences, or even from locally-connected multi-view camera systems, which can still represent single node in a large, distributed camera network.

@&#ACKNOWLEDGMENTS@&#

This work was supported by research programs P2-0095 and P2-0098, research project J2-4284 and the research grant 1000-10-310118, all by the Slovenian Research Agency. We would like to thank the SAIVT Research Labs at Queensland University of Technology (QUT) for freely supplying us with the SAIVT-SoftBio database for our research.

@&#REFERENCES@&#


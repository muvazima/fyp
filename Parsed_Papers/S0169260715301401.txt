@&#MAIN-TITLE@&#Complex wavelet based quality assessment for AS-OCT images with application to Angle Closure Glaucoma diagnosis

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new quality assessment method for AS-OCT images using wavelet based LBP features.


                        
                        
                           
                           It is a first work; so far there is no objective assessment of AS-OCT image quality.


                        
                        
                           
                           The proposed algorithm does not require any additional information from the AS-OCT device.


                        
                        
                           
                           This work aimed at collecting high quality AS-OCT images for Glaucoma diagnosis.


                        
                        
                           
                           Our proposed quality index score is similar to the quality assessment of Glaucoma experts.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optical coherence tomography

Angle closure glaucoma

Complex wavelets

Local binary pattern

Image quality assessment

Machine learning

@&#ABSTRACT@&#


               
               
                  Background and objectives
                  Angle closure disease in the eye can be detected using time-domain Anterior Segment Optical Coherence Tomography (AS-OCT). The Anterior Chamber (AC) characteristics can be quantified from AS-OCT image, which is dependent on the image quality at the image acquisition stage. To date, to the best of our knowledge there are no objective or automated subjective measurements to assess the quality of AS-OCT images.
               
               
                  Methods
                  To address AS-OCT image quality assessment issue, we define a method for objective assessment of AS-OCT images using complex wavelet based local binary pattern features. These features are pooled using the Naïve Bayes classifier to obtain the final quality parameter. To evaluate the proposed method, a subjective assessment has been performed by clinical AS-OCT experts, who graded the quality of AS-OCT images on a scale of good, fair, and poor. This was done based on the ability to identify the AC structures including the position of the scleral spur.
               
               
                  Results
                  We compared the results of the proposed objective assessment with the subjective assessments. From this comparison, it is validated that the proposed objective assessment has the ability of differentiating the good and fair quality AS-OCT images for glaucoma diagnosis from the poor quality AS-OCT images.
               
               
                  Conclusions
                  This proposed algorithm is an automated approach to evaluate the AS-OCT images with the intention for collecting of high quality data for further medical diagnosis. Our proposed quality index has the ability of automatic objective and quantitative assessment of AS-OCT image quality and this quality index is similar to glaucoma specialist.
               
            

@&#INTRODUCTION@&#

Glaucoma causes irreversible optic nerve damage and is associated with raised Intra-Ocular Pressure (IOP) [1]. Glaucoma can be broadly classified into two types: angle-closure and open-angle depending on the anterior chamber angle status. Angle-closure disease is characterized by a narrow Anterior Chamber (AC) angle with subsequent blockage of the trabecular meshwork. This reduces the aqueous outflow resulting in raised IOP. The AC angle can be imaged and measured by an anterior segment optical coherence tomography (AS-OCT) imaging technique [2]. AS-OCT is a non-contact, fast, and highly reproducible imaging device which provides cross sectional views of the AC and angle structures of the eye [3]. AS-OCT has helped to demonstrate the multifactorial mechanisms of Angle Closure Glaucoma (ACG) disease which includes pupil block, plateau iris configuration, thick peripheral iris roll, and increased anterior lens vault mechanisms [4].

Noise and blur are two fundamental degradation processes that occur in AS-OCT images. Image Quality Assessment (IQA) techniques can predict the quality of a natural image which matches with the human vision [5]. IQA of the AS-OCT images is a significant issue because multiple images usually have to be made until one is sufficient for ACG mechanism detection and analysis by glaucoma experts. Many IQA algorithms are explored for natural images [6–8] and these algorithms can be broadly classified into three categories, viz. full-reference (FR) IQA algorithms which require both original and distorted images [6]; reduced reference (RR) IQA algorithms that require distorted image and some information about the original image [7] and no-reference or blind IQA algorithms which do not require any additional information except distorted images [8].

In general, FR-IQA and RR-IQA algorithms perform better than the blind IQA algorithms since no information about the original (or reference) signal is available in the blind IQA algorithms. Some learning techniques have been used in [8,9] for blind IQA algorithms for natural images. Fang et al. [10] proposed a new blind IQA algorithm using the characteristics of natural images. These algorithms are proposed for natural images and cannot be directly applied to medical images, particularly AS-OCT images, as characteristics of natural and AS-OCT images are quite different. Moreover, the criteria to assess the quality of natural and AS-OCT image are different. For example, a natural image with consistent edges is assumed to be a good image [11]. While in the AS-OCT images, the criteria used for a good image as follows: visible anterior segment characteristics (such as identification of the anterior chamber structures, position of the scleral spur, angle opening distance, trabecular-iris space area and angle recess area), the smallest amount of artefacts resulting from movement of eyelids and corneal scars in the image. From these requirements, we can realize the need for designing a new IQA method for the AS-OCT images. Very few IQA algorithms are proposed in the literature for posterior segment OCT images [12–14]; but not for the anterior segment (AS) OCT images. All these studies for posterior segment OCT image quality assessments require additional information for the objective assessments parameters such as signal to noise ratio (SNR), signal strength (SS), and signal deviation (SD) with application to glaucoma diagnosis.

The researchers have also used SNR to assess the quality of the posterior segment OCT images [12], although study about the IQA [15] matrices and use of IQA matrices [16] suggested that SNR is a poor indicator of the image quality since it does not count the distribution of the scan image. Another image quality parameter such as signal strength (SS) is used in the posterior segment OCT imaging device which combines SNR and the uniformity of the signal within a scan. The value of SS parameter ranges from 1 to 10, where the increment of the SS parameter suggests the better image quality [12]. Signal deviation is also used to characterize OCT images [14] which are based on signal pixels in the total number of A-scans within one B scan. These three existing objective parameters SNR, SS and SD require the signal pixels and noisy pixels values which are given by the customized OCT software. All these above mentioned algorithms [12–14] can be classified into reduced reference IQA techniques. However, there is no blind IQA algorithm exists in the literature, which can assess the quality of OCT images. Therefore, this work proposes a blind IQA algorithm for AS-OCT images. The algorithm is designed to match the suggestions of the OCT experts which does not require any additional information.

This study aims to develop a new technique to evaluate the quality of AS-OCT images in a quantitative and objective way which matches with the subjective evaluation done by the OCT experts. This can enable the OCT users to obtain good quality images for efficient diagnosis of ACG. To the best of our knowledge there is no existing technique for AS-OCT image quality assessment. The proposed method is compared with subjective assessments from the experts of OCT images to verify its reliability.

Overview of the proposed method for image quality assessment of AS-OCT images is shown in Fig. 1
                     . This includes the acquisition of raw AS-OCT images followed by the extraction of a large number of morphological features based on complex wavelet based LBP representation. A small set of discriminative and inter-dependent features are then selected and fed into a Naïve Bayes Classifier. Performance is then evaluated using the selected features. Then the selected features are used for the quality index parameter calculation and for grading the images.

The data used in this work consists of AS-OCT eye images of 194 patients affected with the angle-closure disease. These images were provided by the Department of Ophthalmology in the National University Hospital, Singapore (NUHS). Ethics approval was obtained from the review board of NUHS and written consent was also obtained from all subjects prior to AS-OCT imaging. A skilled technician obtained the clinical images through a horizontal scan, including sections of the nasal and temporal quadrants, of all subjects using AS-OCT (Visante, software version 2.01.88; Carl Zeiss Meditec, Dublin, CA) in a dark room (0lx), with the images centred at the pupil. 1300nm infrared light was used to acquire cross-sectional view of the anterior segment image with high resolution.

The standard AS single-scan protocol, producing 256 scans in 0.125s, was used to obtain the scans. Several AS-OCT images were acquired for each patient. The image saturation and noise were adjusted, and the polarization for each scan was optimized by the examiner to obtain the images. Each eye image was captured several times with undilated state of the pupil and only images with clearly visible scleral spurs were analyzed qualitatively by the glaucoma specialists. The images were categorized into four groups of images based on ACG mechanisms i.e., Exaggerated Lens Vault (LV), Pupil Block (PB), Thick Peripheral Iris Roll (PIR) and Plateau Iris Configuration (PL) mechanism.

Since this work is mainly intended for IQA of AS-OCT, the glaucoma specialists (Dr. K. Victor and Dr. M.C. Aquino) graded the image quality into to a three-level scale (good, fair, and poor) shown in Fig. 2
                        . AS-OCT images with the smallest amount of artefacts were categorized as good. The images with artefacts resulting from movement of eyelids and corneal scars were labelled as poor. Other images were categorized as fair, after they were ascertained as acceptable for measuring anterior segment characteristics. The number of patients with different grade categories is listed in Table 1
                        . The relatively small data set size is due to the number of ACG patients supported by Ministry of Education (MoE) AcRF Tire 1 Funding, Singapore.

The Local Binary Pattern (LBP) based texture analysis is very efficient and used for several pattern classification tasks [17–19]. Since, controlling the spatial sample orientation is difficult in standard LBP; we used uniform rotation-invariant LBP features for analyzing the AS-OCT images. In this work, instead of directly using intensity to compute spatial histogram, a multilevel and multidirectional wavelet transformation [20] with LBP is proposed to analyze the AS-OCT images. As few problems are associated with LBP features, such as, (1) LBP features perform efficiently only for textures; (2) AS-OCT images are generally contaminated with noise and these features are quite sensitive to the image noise [21]. In this work complex wavelet based LBP features are extracted to evaluate the image quality of AS-OCT images, since standard DWT's are shift variant [22–24].

First, Double Density Dual Tree-Complex Wavelet Transform (DDDT-CWT) is used for the decomposition of AS-OCT images. Then, several decomposition levels of the image are obtained. In this, there are sixteen sub-bands in each decomposition level for real and imaginary parts, respectively. So, the combined 32 complex wavelet decomposition levels are obtained and these are localized in several directions when both real and imaginary parts are combined. The value of histogram bin corresponding to each complex coefficient in these sub-bands is computed by a LBP operator (more details are given in the following subsections). After labelling the magnitudes of complex coefficients in each sub-band, the labelled bins in sub-band are called as DDDT-CWT based LBP features.

DDDT-CWT is a combination of both double density discrete wavelet transform and the dual tree discrete wavelet transform, so the resultant transform have taken the advantages of both transform [22]. Dual tree discrete wavelet transform has less number of degrees of freedom whereas the double density discrete wavelet transform has more number of degrees of freedom, which can exploit information in 32 directions. These two combined transforms form a new family of dyadic wavelet frames based on two scaling functions and four distinct wavelets Ψ
                              h,i
                           (t) and Ψ
                              g,i
                           (t), i
                           =1, 2.where,
                              
                                 (1)
                                 
                                    
                                       
                                          Ψ
                                          
                                             h
                                             ,
                                             1
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       
                                          Ψ
                                          
                                             h
                                             ,
                                             2
                                          
                                       
                                       (
                                       t
                                       −
                                       0.5
                                       )
                                       ;
                                        
                                       
                                          Ψ
                                          
                                             g
                                             ,
                                             1
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       
                                          Ψ
                                          
                                             g
                                             ,
                                             2
                                          
                                       
                                       (
                                       t
                                       −
                                       0.5
                                       )
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       
                                          Ψ
                                          
                                             g
                                             ,
                                             1
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       H
                                       {
                                       
                                          Ψ
                                          
                                             h
                                             ,
                                             1
                                          
                                       
                                       (
                                       t
                                       )
                                       }
                                       ;
                                        
                                       
                                          Ψ
                                          
                                             g
                                             ,
                                             2
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       H
                                       {
                                       
                                          Ψ
                                          
                                             h
                                             ,
                                             2
                                          
                                       
                                       (
                                       t
                                       )
                                       }
                                    
                                 
                              
                           
                        

Eq. (1) indicates that Ψ
                              h,1(t) and Ψ
                              h,2(t) are offset from one another by one half and similarly for Ψ
                              g,i
                           (t). Eq. (2) shows that the two wavelets Ψ
                              h,1(t) and Ψ
                              g,1(t) forms an approximate Hilbert transform pair and Ψ
                              g,2(t), Ψ
                              h,2(t) likewise. Therefore they are suitable for directional and complex wavelet transforms. The detailed design procedure for the DDDT-CWT using the double density discrete wavelet transform and the dual tree discrete wavelet transform can be found in [23,24]. The filter bank structure for the double density dual tree-complex wavelet transform DDDT-CWT is illustrated in Fig. 3
                           . There are two separate filter banks denoted by h
                           
                              i
                           (n) and g
                           
                              i
                           (n) where, i
                           =0, 1, 2. The filter banks h
                           
                              i
                           (n) and g
                           
                              i
                           (n) are unique and designed in a specific way. So, the upper part and lower part of the DDDT-CWT sub-band signals have represented as the real part and imaginary part of a complex wavelet transform, respectively.

The wavelet coefficients w are stored as w{i}{j}{k}{d} for i
                           =1, 2; j
                           =1 to J; k
                           =1, 2; d
                           =1 to 8, where, j represents the scale; i
                           =1 for real part (Tree 1), i
                           =2 for imaginary part (Tree 2); (k, d) represents the orientation and J represents number of stages of wavelet decomposition, respectively. These sub-bands possess certain properties, which enables proposed algorithm to efficiently extract the features of AS-OCT images. These properties are: (1) DDDT-CWT consists of 32 wavelets, which is higher than the traditional wavelet which has only 3 wavelets and each wavelet represents non-overlapping particular directions [22]; (2) DDDT-CWT is able to overwhelm the situation of extracting more low frequency information by decomposing an AS-OCT image into more number of sub-bands which represents high-frequency characteristics.

LBP operator quantifies the pattern of a texture for grayscale images, particularly which is useful in medical image analysis. Such as, the LBP operator [19] is one of the most useful texture extracting operator for diverse applications as spacing from biometrics applications [25,26] to cell analysis [27]. The LBP has high descriptive capability and it is also invariant to local grayscale changes which make it more useful for pattern recognition applications. LBP assumes that an image is constituted by micro-patterns. The LBP operator for every pixel in the AS-OCT image can be estimated on the basis of a circular neighbourhood of radius R which has Q number of pixels whose intensity level is p
                           
                              q
                            and centre pixel has intensity value p
                           
                              c
                            as follows:
                              
                                 (3)
                                 
                                    
                                       LBP
                                       (
                                       Q
                                       ,
                                       R
                                       )
                                       =
                                       
                                          ∑
                                          
                                             q
                                             =
                                             0
                                          
                                          
                                             Q
                                             −
                                             1
                                          
                                       
                                       
                                          s
                                          (
                                          
                                             p
                                             q
                                          
                                          −
                                          
                                             p
                                             c
                                          
                                          )
                                          
                                             2
                                             q
                                          
                                       
                                    
                                 
                              
                           where,
                              
                                 (4)
                                 
                                    
                                       s
                                       (
                                       a
                                       )
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         1
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         a
                                                         ≥
                                                         0
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         0
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         a
                                                         <
                                                         0
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

For example, the output of the 16 neighbours can be used to produce an eight digit binary number, p
                           1, p
                           2,…, p
                           8, where, p
                           
                              i
                           
                           =0 if the intensity of the ith neighbouring pixel in circular window R is less than, or equal to as compared to centre pixel p
                           
                              c
                           , otherwise p
                           
                              i
                           
                           =1. The histogram of the binary numbers has the ability of representing the texture of an image. Thus, the extracted binary codes are represented in the histogram form and it is useful to describe texture patterns in the image.

The extended LBP operator uses bilinear interpolation and circular neighbourhood, which enables it to have adaptive number pixels in surrounding, so it can have distinct sizes and shapes to label each pixel. In this work, we used circular neighbourhood to extract the features of the AS-OCT images, as it has more degree of freedom for rotational invariance as compared to LBP's with rectangular neighbourhood. As, output of the LBP is a binary number and if any LBP has at most one bitwise transition (such as 0 to 1 or 1 to 0), it is called as the uniform LBP. The extended operator has some additional properties such as, it allows for detecting the uniform-pattern at circular neighbourhood with rotation invariant property at any spatial resolution.

The uniform LBP pattern can be represented as 
                              
                                 LB
                                 
                                    P
                                    
                                       Q
                                       ,
                                       R
                                    
                                    
                                       riu
                                       2
                                    
                                 
                              
                           ,
                              
                                 (5)
                                 
                                    
                                       LB
                                       
                                          P
                                          
                                             Q
                                             ,
                                             R
                                          
                                          
                                             riu
                                             2
                                          
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               q
                                                               =
                                                               0
                                                            
                                                            
                                                               Q
                                                               −
                                                               1
                                                            
                                                         
                                                         
                                                            s
                                                            (
                                                            
                                                               p
                                                               q
                                                            
                                                            −
                                                            
                                                               p
                                                               c
                                                            
                                                            )
                                                            
                                                               2
                                                               q
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         if
                                                          
                                                         U
                                                         (
                                                         
                                                            LBP
                                                            
                                                               Q
                                                               ,
                                                               R
                                                            
                                                         
                                                         )
                                                         ≤
                                                         2
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         Q
                                                         +
                                                         1
                                                      
                                                   
                                                   
                                                      
                                                         otherwise
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (6)
                                 
                                    
                                       U
                                       (
                                       
                                          LBP
                                          
                                             Q
                                             ,
                                             R
                                          
                                       
                                       )
                                       =
                                       
                                          
                                             s
                                             (
                                             
                                                p
                                                
                                                   q
                                                   −
                                                   1
                                                
                                             
                                             −
                                             
                                                p
                                                c
                                             
                                             )
                                             −
                                             s
                                             (
                                             
                                                p
                                                0
                                             
                                             −
                                             
                                                p
                                                c
                                             
                                             )
                                          
                                       
                                       +
                                       
                                          ∑
                                          
                                             q
                                             =
                                             1
                                          
                                          
                                             Q
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             
                                                s
                                                (
                                                
                                                   p
                                                   q
                                                
                                                −
                                                
                                                   p
                                                   c
                                                
                                                )
                                                −
                                                s
                                                (
                                                
                                                   p
                                                   
                                                      q
                                                      −
                                                      1
                                                   
                                                
                                                −
                                                
                                                   p
                                                   c
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           where, ‘riu2’ represents uniform patterns which has rotation invariance property, s() is a sign function, p
                           
                              c
                            is the central pixel's intensity value and p
                           
                              q
                           (q
                           =0, …, (Q
                           −1)) is the intensity value of the pixels in the circular neighbourhood. By Eq. (6), the value of U(LBP
                              Q,R
                           ) in every pixel in an AS-OCT image is computed to label the pixels in the corresponding bins. After labelling all the pixels of the AS-OCT image, a histogram of the labelled pixels can be defined as;
                              
                                 (7)
                                 
                                    
                                       
                                          H
                                          i
                                       
                                       =
                                       
                                          ∑
                                          
                                             x
                                             ,
                                             y
                                          
                                       
                                       
                                          I
                                          {
                                          f
                                          (
                                          x
                                          ,
                                          y
                                          )
                                          =
                                          i
                                          }
                                           
                                          i
                                          =
                                          0
                                          ,
                                          …
                                          (
                                          n
                                          −
                                          1
                                          )
                                       
                                    
                                 
                              
                           where, n is the number of distinct labels generated by the 
                              
                                 LB
                                 
                                    P
                                    
                                       Q
                                       ,
                                       R
                                    
                                    
                                       riu
                                       2
                                    
                                 
                              
                            operator and I{A}=1 if A is true, else it is 0. This histogram includes the information of the distribution of the local micro-patterns over the whole image [20].

Minimum Redundancy Maximum Relevance (mRMR) is a feature selection algorithm which intends to find best features that are most relevant to the target classes, while reducing the redundancy between the selected features simultaneously [28]. In previous studies [29–31], mRMR algorithm being shown to be superior in classifying various ACG mechanisms, hence it is used in this work for feature selection method. To find relevant features, the mutual information between a feature and the target class should be maximized.

In order to obtain the parameter for evaluating the overall quality of the AS-OCT images, firstly, thirty-five features were selected based on mRMR features selection algorithm explained in the previous subsections. After selecting the thirty-five features, these features are pooled using the Naïve Bayes classifier (NBC) [32], to obtain the final quality index (QI). We have chosen NBC for pooling as it demonstrates its effectiveness in binary and multiclass classification when the features are independent of each other [33,34]. It generates a single probabilistic model for each class and we are assuming that features in the each class are conditionally independent. Since the mutual information among the features selected by using mRMR is minimized, these features are predominantly independent of each other and suitable for NBC.

The NBC considers the contribution of all the features independently to arrive at the probability of the target class and hence, it provides more useful information for decision support other than a class label or class probability [33]. NBC returns the probability of the given AS-OCT image belonging to the certain class. In the proposed algorithm, this probability is used as the quality index (QI). This QI parameter has the ability to help the medical practitioner to review the AS-OCT images, whether to use it for the medical diagnosis or not. The quality of the image is estimated as follows:
                           
                              (8)
                              
                                 
                                    Image
                                     
                                    quality
                                     
                                    index
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      Excellent
                                                   
                                                
                                                
                                                   
                                                      if
                                                       
                                                      Q
                                                      I
                                                      >
                                                      0.9
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      Acceptable
                                                   
                                                
                                                
                                                   
                                                      if
                                                       
                                                      0.9
                                                      >
                                                      Q
                                                      I
                                                      >
                                                      0.8
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      Bad
                                                   
                                                
                                                
                                                   
                                                      else
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

From Eq. (8), it is noticeable that the image quality index is corresponding to the image class (i.e. good, fair, or poor). For example if the tag returned by the NBC is bad and QI is greater than 0.9, it suggests that the in proposed algorithm is 90% confident that this image is a bad image and should not be used for the diagnosis.

The confusion matrix is used to evaluate the performance of classification of AS-OCT images in good, fair and poor classes. The performance of the classifier can be computed in terms of accuracy, F-measure, sensitivity and specificity and which in turn can be derived from the rates of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN) using standard formulas [29].

The proposed method is implemented and tested on MATLAB 8.0 R2012b (The Mathworks Inc., Natick, MA, USA) with the experimental data consisting of AS-OCT images. All the features are normalized to have zero mean and a standard deviation of unity and discretized in order to compute the mutual information for feature selection. We have tried different feature selection algorithms as reported in [35] with various machine learning classifiers (such as, SVM, ANN, RF, decision tree and Adaboost classifier). Through, our extensive experiments; we found that mRMR feature selection algorithm with Naïve Bayes classifier gives best performance. Since feature selection algorithm predominantly affects the accuracy of the classifier and ranked features are selected amongst extracted features using mRMR algorithm. In this way, top 35 ranked features are selected amongst 1728 extracted features (32 layers×3 scales×8 LBP features) using mRMR algorithm, prior to classification using NBC. The set of features such as DDDT-CWT based LBP features are used to train NBC classifier. The classifier performance has been evaluated using leave-one-out cross-validation (LOOCV) due to the small sample size.


                     Table 2
                      shows the confusion matrix of 3-way classifier using NBC through LOOCV method. The accuracy, F-measure, specificity and sensitivity of each class using Naïve Bayes classifier based on the selected 35 features are calculated and shown in Table 3
                     . Our method achieves 82.9% of accuracy, 82.5% of F-measure with a precision of 83.1% and a recall of 83%. From the experimental results shown in Tables 2 and 3, we can see that the classification accuracy of Good is relatively higher than that of fair and poor. It is due to the imbalanced sample size of the experimental dataset, with more samples in good and less samples in the fair and poor graded images.

In the proposed algorithm, we classified all the AS-OCT images in three classes such as good, fair and poor. In order to evaluate the performance of the proposed image quality assessment for AS-OCT images, we also asked the expert ophthalmologists to grade AS-OCT images in three classes. Finally, we compared these two assessments and observed that classification based upon the proposed quality index matches the classification done by the ophthalmologists and proposed algorithm achieves 82.9% accuracy.

Each of the 194 images was manually/visually classified and graded as good, fair and poor by the first expert in the round one and this classification result was used as ground truth for evaluation of the proposed automated method. To analyze inter and intra observer variability, a manual classification was performed by a different expert (Dr. M. C. Aquino), and a second time by the first expert (Dr. K. Victor). These inter and intra observer variability is calculated to ensure the consistency of the expert during the classification of AS-OCT images (Table 4
                     ). The inter-observer accuracy was 87.6% and the intra-observer accuracy 91.7% as shown in Fig. 4
                     . In order to validate the need of using wavelet with the LBP features, we also extracted the LBP features alone for AS-OCT images and all eighteen features are used to feed the Naïve Bayes classifier. The maximum classification accuracy attained by using alone LBP features is only 62%. Considering the above factors, an effective representation and recognition method that is multiresolution and multidirectional DDDT-CWT based LBP features is developed. By combining DDDT-CWT and LBP features methods, the representation power of the spatial histogram is enhanced greatly due to its multi-layered AS-OCT images in its multidirectional view.

The performance of the NBC classifier of the proposed method have been compared (see Table 5
                     ) with the other most used contemporary classifiers for medical diagnosis such as ANN viz. multilayer perceptron model using a back-propagation algorithm, k-nearest neighbourhood (k-NN) and random forest (RF) classifier. For each classifier, we used leave-one-out cross-validation method. From Fig. 5
                     , it is illustrated that the proposed method using NBC provided better result for labelling the AS-OCT images than the other multivariate classifiers. We have split dataset using different ratio for separating the training and testing and we have evaluated the performance of the NBC classifier. The AS-OCT images was classified based on 10-fold cross validation, 50–50%, 70–30%, and 80–20%, respectively, due to training and test of all the AS-OCT dataset. The obtained test classification accuracies were 81.4%, 81.5%, 81.03% and 82.05% respectively. It is observed that the proposed method has given nearly similar performance for different ratios of training and testing dataset.

As aforementioned, we have concerned only about reliable Good AS-OCT images which can be further utilized for the medical diagnosis. With this point of view, we combined both the ‘Fair’ and ‘Poor’ classes of AS-OCT images and called this new class as ‘Fair+Poor’ class to perform our algorithm. We randomly divided all 194 AS-OCT images into training and test-set (in 50:50 ratios). mRMR feature selection algorithm is used to select features only from training data-set and NBC classifier is used to learn parameters. These parameters are applied to rest of the AS-OCT images (50% test data-set) to classify these AS-OCT images into ‘Good’ and ‘Fair+Poor’ class and the proposed algorithm achieved 84.4% of accuracy for this 50% test data-set (Table 6
                     ). Accuracy of the proposed algorithm with two classes is higher than the three classes result and lesser number of the ‘Fair+Poor’ class AS-OCT images are classified into the ‘Good’ class due to the relatively balanced dataset. Using the proposed algorithm accepts only six ‘Fair+Poor’ class AS-OCT images into ‘Good’ class. In order to further reduce the number of ‘Fair+Poor’ AS-OCT images into ‘Good’ class, we proposed that AS-OCT images which are classified into ‘Good’ class and have quality score more than 0.9 should be used for further ACG diagnosis and other AS-OCT images good should be discarded, since these images are not reliable and not useful for further diagnosis and we call such images as reliable Good AS-OCT images. We found that using the proposed algorithm and quality score (Eq. (8)) only 3 ‘Fair+Poor’ images are classified into Good images. Hence, the proposed image quality index has the ability of choosing the images, which should be used for the medical diagnosis.

@&#CONCLUSION@&#

In this paper, we proposed an efficient quality assessment method for AS-OCT images using the complex wavelet transform based local binary patterns. The experimental results shown that the proposed method can provide the efficient quality assessment, which matches the subjective assessment done by trained ophthalmologists. The double density dual tree complex wavelet based LBP features are the effective approaches for automated image quality assessment of AS-OCT images for angle-closure diagnosis. The advantages of the proposed automated analysis can build an accessible tool which can help the ophthalmologists to select the best image for ACG diagnosis, which enables diagnosis to be fast and with more accuracy. An important contribution of this work is to propose an AS-OCT quality measurement function, which does not require any additional information (such as signal pixels and noise pixels) provided by the AS-OCT software with the AS-OCT scans. In summary, in this work, we proposed an automated approach to evaluate the AS-OCT images with the intention for collecting of high quality data. Our proposed quality index has the ability of automatic objective and quantitative assessment of AS-OCT image quality and this quality index is similar to glaucoma specialist.

None declared.

@&#ACKNOWLEDGEMENTS@&#

This work was supported by Ministry of Education (MoE) AcRF Tire 1 Funding, Singapore, under Grant M4010981.020 RG36/11.

@&#REFERENCES@&#


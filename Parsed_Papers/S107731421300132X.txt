@&#MAIN-TITLE@&#Multi-spectral dataset and its application in saliency detection

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A multi-spectral dataset is constructed containing RGB and near-infrared images.


                        
                        
                           
                           The incorporation of near-infrared is proved to be valuable for saliency detection.


                        
                        
                           
                           The best model for integrating RGB and near-infrared clues is analyzed.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multi-spectral

Near-infrared

Saliency

Regression model

@&#ABSTRACT@&#


               
               
                  Saliency detection has been researched a lot in recent years. Traditional methods are mostly conducted and evaluated on conventional RGB images. Few work has considered the incorporation of multi-spectral clues. Considering the success of including near-infrared spectrum in applications such as face recognition and scene categorization, this paper presents a multi-spectral dataset and applies it in saliency detection. Experiments demonstrate that the incorporation of near-infrared band is effective in the saliency detection procedure. We also test the combinational models for integrating visible and near-infrared bands. Results show that there is no single model to effect on every saliency detection method. Models should be selected according to the specific employed method.
               
            

@&#INTRODUCTION@&#

Saliency detection has been a promising topic recently [1–4]. The goal of saliency detection is to extract salient areas from an input image and present the result as a gray scale image. The whiter the pixel seems, the more possible it might be salient. Since the detected saliency map can be utilized in various applications, such as recognition [5], segmentation [6], and tracking [7], research towards this subject has attracted much attention [8–10].

Generally, methods for saliency detection can be categorized into local based and global based schemes [11]. Local based methods calculate a region’s saliency according to the contrast to a small neighborhood [12–14]. Global based methods evaluate saliency with respect to the whole image’s statistical characteristic [15,16]. Whatever the case is, saliency detection is mostly conducted on natural images taken by ordinary cameras. These cameras can respond to wavelengths from about 390 to 700nm, which is called the visible spectrum [17]. The obtained images are regular RGB images. As for the electromagnetic spectrums beyond this scope, their information is lost during the imaging process. However, the lost spectrums might be also valuable for vision tasks because the more supporting information we have, the more rationale decisions will be made. This judgment is not only the common sense for humans, but also proved by other applications in computer vision field. For example, after the proposition of SIFT descriptor [18] on gray scale images, CSIFT [19,20] was developed to incorporate the color bands into the descriptor. Then not long ago, MSIFT [21] was presented to include the near-infrared band for a richer descriptor. As for the face recognition research, early work primarily focus on the gray or RGB images. Later, other light bands besides the visible spectrum [22] are involved to eliminate the lighting problem. The same is true for boundary detection [23] and tracking [24] that incorporating more clues will improve the performance. In remote sensing, the spectrum is not limited to one or several bands, but up to a level of tens and hundreds [25–27].

Considering the success of including other light bands besides the visible light in many applications, we construct a multi-spectral dataset containing both near-infrared (NIR) and regular RGB images in this work. Several dataset containing NIR images have been presented before. For example, the PolyU-NIRFD dataset [22] for face recognition, the NIR–RGB dataset [21] for scene categorization. But these datasets are designed for specific purpose. They cannot be readily utilized for saliency detection. To this aim, the presented dataset is constructed in the hope of providing a new platform for saliency research.

The rest of this paper is organized as follows. Section 2 presents the proposed multi-spectral dataset. Section 3 introduces the distinguishable properties of near-infrared band. Section 4 applies the presented dataset in saliency detection. Finally, conclusion is made in Section 5.

Since more clues are prone to provide richer information, we hope that a camera can capture the NIR and RGB spectrums simultaneously. However, most existing datasets contain images captured from only RGB bands. We cannot get the information of the four bands at the same time. Though the NIR–RGB dataset [21] has images of both bands, each pair of them are taken consecutively with two cameras. This makes the contents of image pairs not the same. When these images are employed, they have to be accurately registered. But the obtained results are still not satisfying because some objects exist in one image but not in the other. Considering this problem, we employ a multi-spectral camera to simultaneously capture the images of the four bands.

The camera we employed is a prism based 2-CCD progressive area scan one, the configuration of which is shown in Fig. 1
                     (a). We can see clearly that the prisms in the camera spit the input light into two channels. One is 400–700nm visible spectrums of red, green and blue, and the other is 700–1000nm NIR spectrums. This separation is accurately ensured by the dichroic coatings of the prisms. The splitted spectrums are then responded by two distinct CCDs, each of which is sensitive to a range of wavelengths. Their response curves are shown in Fig. 1(b) and (c). The advantage of this camera is that it can capture two images at the same time and the obtained image pair are with the same scope and content.

With this camera, we took 40 pairs of 512×384 images of indoor and outdoor scenes and each image contains one or several salient objects within it. Then the salient objects in each pair were labeled by 5 graduate students major in computer vision. In this procedure, few instructions were given to the participants except segmenting the salient ones they thought as. This ensures the minimum amount of influence on the participants’ labelings due to the unnecessary instructions. Since every individual’s perception is different, their labelings differ with each other. To get an unbiased ground truth, we select the common areas of each participant’s labeling as the final results. Typical examples are shown in Fig. 2
                     .

The NIR spectrum is between the visible light band and the thermal infrared band. It has the properties of both visible light and thermal infrared light, but is different from any of them. Firstly, unlike thermal infrared, objects can reflect the NIR light the same way as they do to visible light. Secondly, it is invisible to human eyes like the thermal infrared and reflects an “unseen” characteristic different from visible light.

In order to know the relationship and difference between the RGB and NIR spectrums, we plot their pairwise cooccurrence distributions on the 40 image pairs in the 2D plane. All the RGB and NIR values are normalized to [0,1] and different occurrence frequencies are denoted by different colors. From Fig. 3
                     , it is obvious that the distributions of RG, RB and GB are different from those of RN, GN and BN. The latter ones spread more widely in the 2D plane. This implies that the original visible light of red, green and blue are much higher correlated in a pairwise manner than the NIR with them. The NIR spectrum can provide more different information than the visible spectrum.

To justify this point, we calculate the joint entropy [21] of each two bands as
                        
                           (1)
                           
                              H
                              (
                              X
                              ,
                              Y
                              )
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       ,
                                       j
                                    
                                 
                              
                              -
                              p
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                              )
                              
                                 
                                    log
                                 
                                 
                                    2
                                 
                              
                              p
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                              )
                              ,
                           
                        
                     where X and Y are the examined spectrums, x
                     
                        i
                      and y
                     
                        j
                      are the pixel values of the corresponding spectrum image, and p(x
                     
                        i
                     ,
                     y
                     
                        j
                     ) is the probability density. According to the information theory, the entropy is a measure of unpredictability and reflects the information content. The higher H(X,
                     Y) is, the more information is contained in a message. The calculated joint entropy is shown in Table 1
                     . From the table, we can see that the joint entropies with the NIR band are generally higher than those without it. This result demonstrates that the NIR band can provide much abundant information. Trying to utilize it in applications is reasonable.

To demonstrate the effectiveness of the presented dataset, we conduct experiments in the application of saliency detection. Saliency maps are firstly extracted from RGB images and NIR images. Then the obtained maps are combined together to get the final results. The purpose of these experiments is to answer the two following questions: 1) whether or not the incorporation of NIR band can improve the saliency detection performance; 2) which kind of models is the best to combine the saliency maps from the two channels.

To answer the first question, we compare the results generated with only RGB band and the results with both RGB and NIR bands. Algorithms employed in this process are all canonical ones in saliency detection fields. They are AC [29], CA [13], FT [16], HC [11], IT [12], LC [30], MSS [31], RC [11], SR [32] and SUN [33]. To answer the second question, it is more difficult because a traversal test of comparative models is impossible. Considering the initial success of [34], we concentrate on the regression models in this work.

To compare experimental results, an evaluation measure should be firstly specified. In saliency detection field, three metrics are usually employed: precision, recall, and F-measure. They are defined as follows
                           
                              (2)
                              
                                 
                                    
                                       
                                       
                                          
                                             precision
                                             =
                                             
                                                
                                                   TP
                                                
                                                
                                                   TP
                                                   +
                                                   FP
                                                
                                             
                                             ,
                                             
                                             recall
                                             =
                                             
                                                
                                                   TP
                                                
                                                
                                                   TP
                                                   +
                                                   FN
                                                
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             F
                                             -
                                             measure
                                             =
                                             
                                                
                                                   precision
                                                   ×
                                                   recall
                                                
                                                
                                                   (
                                                   1
                                                   -
                                                   α
                                                   )
                                                   ×
                                                   precision
                                                   +
                                                   α
                                                   ×
                                                   recall
                                                
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where TP is true positive, FP is false positive, and FN is false negative. These three metrics are usually utilized in information retrieval community and each of them reflects a different aspect. Precision represents the accuracy, recall represents the detectability, and F-measure is a balance between them. When precision and recall contradict with each other, F-measure is usually employed to represent a compromised measurement [35].

In our processing, the aim is to infer each pixel’s saliency value according to its obtained saliency maps from the RGB and NIR bands. Suppose the RGB and NIR saliency are denoted as X
                        
                           rgb
                         and X
                        
                           nir
                        , respectively. The question is how to determine the mapping function f: (X
                        
                           rgb
                        ,
                        X
                        
                           nir
                        )→
                        Y, where Y is the desired saliency value. Three commonly used regression models are employed here. They are linear regression, polynomial regression and logistic regression.

In linear regression [36], the output variable is a linear combination of input variables. To be specific, the model can be expressed as
                              
                                 (3)
                                 
                                    Y
                                    =
                                    
                                       
                                          α
                                       
                                       
                                          0
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          1
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          rgb
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          nir
                                       
                                    
                                    .
                                 
                              
                           The task is to estimate {α
                           
                              i
                           }
                              i=0,1,2 from the observed N training points 
                              
                                 
                                    
                                       {
                                       
                                          
                                             X
                                          
                                          
                                             rgb
                                          
                                          
                                             n
                                          
                                       
                                       ,
                                       
                                          
                                             X
                                          
                                          
                                             nir
                                          
                                          
                                             n
                                          
                                       
                                       ,
                                       
                                          
                                             Y
                                          
                                          
                                             n
                                          
                                       
                                       }
                                    
                                    
                                       n
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                 
                              
                           . A special case of linear regression is that the constant coefficient α
                           0 equals 0. In this case, the output is only the proportional combination of X
                           
                              rgb
                            and X
                           
                              nir
                           , with no translation. The two models are abbreviated as LinearR-I and LinearR-II in later discussion.

In polynomial regression, the independent variables include not only linear terms, but also quadratic and interactive terms. The model is expressed as
                              
                                 (4)
                                 
                                    Y
                                    =
                                    
                                       
                                          α
                                       
                                       
                                          0
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          1
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          rgb
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          nir
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          3
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          rgb
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          nir
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          4
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          rgb
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          5
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          nir
                                       
                                       
                                          2
                                       
                                    
                                    .
                                 
                              
                           The processing is the same as linear regression. According to the known input and output pairs, get an estimation of {α
                           
                              i
                           }
                              i=0,…,5 that best fit the training data. This model is denoted as PolyR to facilitate the representation.

For logistic regression [37], the model is defined as
                              
                                 (5)
                                 
                                    f
                                    (
                                    X
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                e
                                             
                                             
                                                X
                                             
                                          
                                       
                                       
                                          
                                             
                                                e
                                             
                                             
                                                X
                                             
                                          
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          1
                                          +
                                          
                                             
                                                e
                                             
                                             
                                                -
                                                X
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where X represents some set of independent variables, which in this work is defined as
                              
                                 (6)
                                 
                                    X
                                    =
                                    
                                       
                                          α
                                       
                                       
                                          0
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          1
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          rgb
                                       
                                    
                                    +
                                    
                                       
                                          α
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          nir
                                       
                                    
                                    .
                                 
                              
                           
                        

The model reflects the nonlinear relationship between the input and output variables, especially emphasizing an approximately linear mapping in the mid-range of input variables and stretching out the extremes exponentially. It is denoted as LogisticR.

@&#EXPERIMENTS@&#

In this section, intensive comparative experiments are conducted to answer the previously posed two questions. 10 images are selected for training the parameters of the regression models and the other 30 for testing. Since each image contains 512×318pixels, involving them all from the 10 training images will lead to a great number of training samples. Besides, there are many repeated triplets 
                           
                              {
                              
                                 
                                    X
                                 
                                 
                                    rgb
                                 
                                 
                                    n
                                 
                              
                              ,
                              
                                 
                                    X
                                 
                                 
                                    nir
                                 
                                 
                                    n
                                 
                              
                              ,
                              
                                 
                                    Y
                                 
                                 
                                    n
                                 
                              
                              }
                           
                         with the same values if all the pixels are employed, which will lead to a biased model. Therefore, we first resize the training images to 1/4 times of the original size. Then all the pixels (128×80×10=102,400) are utilized as training samples. After all the parameters are learned from the training stage, the remaining 30 images are processed by the acquired models. Typical examples of the regression results are shown in Fig. 4
                        . To quantitatively evaluate the performance of each regression model, we plot the averaged precision, recall and F-measure bars of the original methods and their improvements (in percentage) of the regression models in Fig. 5
                        . Detailed analysis is presented below.

From Fig. 5, we can see that the incorporation of NIR band makes the three metrics change greatly. Sometimes, they change towards the desired direction. Other times, the inclusion of NIR band makes the indexes drop unsatisfyingly. There are still cases that the precision and recall change oppositely or their improved degrees are different. This leads to a difficult comparison of the regression models. According to [35], F-measure should be referred to in this case because it is a compromise of precision and recall. From Fig. 5 it is evident that for each saliency detection method, there is at least one regression model that can improve the F-measure of the detected results. This means the added NIR band is effective when employing the appropriate model. The maximum improvement is approximately 40% and the minimum is about 5% in our experiments.

For each saliency detection method, its corresponding regression model performs differently. Some models improve the results, while others may make the results worse. But every method has at least one regression model that can make the original results better. The best regression model for each method is labeled by an purple rectangle. We can see clearly that not every method has an identical best regression model. For CA, FT, HC, LC, RC and SUN, their best performance are achieved on LinearR-II model. For AC and SR, LinearR-I fits them more properly. And for IT and MSS, PolyR is the most appropriate one.

Since each saliency detection method generates a different result, which represents a distinguishable data distribution and paradigm, their best combinational manner might differ with each other. Six methods achieve their excellence on LinearR-II model. This means the LinearR-II is a more generalized and suitable model for saliency detection. No methods perform best on LogisticR model. This means that the model is not fit for these saliency detection techniques (e.g. several results are all black in the last column of Fig. 4).

@&#DISCUSSION@&#

In the above Section, experimental results are presented and analyzed. There are still several issues remaining to be discussed in this part.

The first one is about model selection. In this work, we only focus on the conventional regression models to describe the combinational relationship of RGB and NIR bands. However, since there are still other models for the combination of the two bands and we have not tested them all, we do not claim the regression models are the most perfect ones. On the contrary, we think models should be selected according to the specific saliency detection method. This is reasonable to understand because models are built on the actual data. Different methods generate dissimilar saliency maps, which represent distinct data paradigms. Consequently, there is no reason to assume an universal model to all methods.

The second one is about the performance of the employed saliency detection methods. From Fig. 4 and Fig. 5, we can see that the employed canonical methods do not perform well enough as reported in [11]. This is because the presented dataset is a little more complex than the dataset utilized in [11]. The backgrounds usually contain several disturbing objects of different colors. The salient objects are not with the distinguishable fresh color, either. This phenomenon also reveals that the current state-of-the-art methods heavily rely on the color contrast and its robustness deserves to be improved.

The third one is the size of the presented dataset. 40 images are not a large number. This is because the platform for capturing images is not convenient to move around. We only set the environment within and not far from the laboratory. Now we are working on transplanting the desktop capturing system to a laptop and taking more images to form a larger dataset. On the other hand, the average F-measure can be improved with a maximum of 40%, which is not a small improvement. We think it is not a coincidence and presents a promising result.

@&#CONCLUSION@&#

In this work, a multi-spectral dataset is presented to serve as a new platform for saliency research. Different from existing ones, our dataset contains pairs of RGB and NIR images. This can provide more valuable information for detecting the salient areas in an image. Experiments demonstrate the effectiveness of the incorporation of NIR band in saliency detection. We also test several regression models for combining the RGB and NIR bands. Results show that it is not appropriate to employ one single model as prototype. The best model should be selected according to the specific method. Future work plans to transplant the image capturing system to a laptop and take more images into the dataset.

@&#ACKNOWLEDGMENT@&#

This work is supported by the State Key Program of National Natural Science of China (Grant No. 61232010), the National Natural Science Foundation of China (Grant No. 61172143 and 61105012), and the Natural Science Foundation Research Project of Shaanxi Province (Grant No. 2012JM8024).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Using image segmentation for evaluating 3D statistical shape models built with groupwise correspondence optimization

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose an application-driven approach for evaluating 3D correspondence.


                        
                        
                           
                           Image segmentation is simulated using SSMs built from different correspondences.


                        
                        
                           
                           We compare correspondences of different optimization strategies and cost functions.


                        
                        
                           
                           Comparison with correspondence evaluation reveals limitations of that approach.


                        
                        
                           
                           Using various distance measures and data set we derive practical recommendations.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Statistical shape models

Correspondence

Optimization

Image segmentation

Evaluation

@&#ABSTRACT@&#


               
               
                  Statistical shape models (SSMs) are a well-established tool in medical image analysis. The most challenging part of SSM construction, which cannot be solved trivially in 3D, is the establishment of corresponding points, so-called landmarks. A popular approach for solving the correspondence problem is to minimize a groupwise objective function using the optimization by re-parameterization approach. To this end, several objective functions, optimization strategies and re-parameterization functions have been proposed. While previous evaluation studies focused mainly on the objective function, we provide a detailed evaluation of different correspondence methods, objective functions, re-parameterization, and optimization strategies. Moreover and contrary to previous works, we use distance measures that compare landmark shape vectors to the original input shapes, thus adequately accounting for correspondences which undersample certain regions of the input shapes. Additionally, we segment binary expert segmentations to benchmark SSMs constructed from different correspondences. This new evaluation technique overcomes limitations of the correspondence based evaluation and allows for directly quantifying the influence of the correspondence on the expected segmentation accuracy. From our evaluation results we identify pitfalls of the current approach and derive practical recommendations for implementing a groupwise optimization pipeline.
               
            

@&#INTRODUCTION@&#

Statistical shape models (SSMs) [1] capture the shape variability of a particular object class on the basis of a representative training population. The strength of SSMs is their ability to adapt elastically to previously unseen, patient specific shape instances under the constraint of statistical plausibility. This predestines them for a wide variety of medical image computing applications, such as image segmentation [2–5], shape analysis [6,7] and shape extrapolation [8,9].

A linear SSM is learned by applying principal component analysis (PCA) to a set of training shapes represented by vectors of corresponding landmarks. Training shapes are typically generated from binary segmentations using standard algorithms such as Marching Cubes [10], which yields surface meshes with varying number of points and no inherent index correspondence. Therefore, the elementary prerequisite for SSM construction is to identify corresponding points (so-called landmarks) across all training samples.

Solving the correspondence problem is actually the most challenging part of SSM construction and demands for application of automatic methods in a 3D setting (Section 3). To this end, a wide range of different methods have been developed since the invention of SSMs by Cootes et al. [1]. One can divide these methods into two categories: pairwise and groupwise approaches. Subsequently, we briefly introduce these two basic concepts. Since our work focuses on 3D anatomical structures, we restrict ourselves to methods that have been explicitly designed to handle 3D shapes or for which the extension from 2D to 3D is straightforward. For a more profound analysis of the subject, the reader is referred to the review of Heimann and Meinzer [3]. Moreover, we refer to [11] for a review on correspondence in computer graphics in general.

Pairwise approaches for establishing correspondence resort to some kind of registration algorithm, which establishes correspondence between two shapes. The registration algorithm either registers surface meshes [12], adapts meshes to binary images [13] or establishes correspondence completely in the image domain, for example using image registration [14,15]. In order to obtain landmarks, one can define them on a single training example, the template, and propagate these landmarks to all other examples through the registration process [16]. Because quality of correspondence may vary significantly with different choices of the template, the template can be iteratively re-estimated to improve the results [17]. Yet a different approach to reduce the bias introduced by the template is to construct a binary shape tree [18,19] or a minimum spanning shape tree [20] from a similarity matrix that compares all pairs of training shapes. The landmarks are then propagated along this tree, thus ensuring that a pairwise registration is only done for shapes that are similar.

The correspondence measure in pairwise approaches is often implicitly defined through the selected registration algorithm. These range from purely distance based measures like in the frequently employed Iterative Closest Point (ICP) algorithm [12] and its variants [18,17,21] to features such as curvature [22], physical properties such as the thin-plate-spline bending energy [16,23], or image information in case of elastic or affine image registration such as normalized mutual information [14,15] or label consistency [24].

Alternatively, shapes can be represented using particular basis functions. Inherent correspondence is then defined by identifying points featuring the same basis function coefficients for all shapes. A prominent approach is to use spherical harmonics for description of closed surfaces [25]. This so-called SPHARM model [4] has already proven its feasibility for the construction of SSMs of objects with varying complexity [6,7,26–28] that are homeomorphic to the unit 2-sphere. The variational approach of Lamecker et al. [29,5] is not limited to objects that are topologically equivalent to the sphere but requires the manual identification of cutting lines.

In groupwise approaches, the correspondence between two shapes depends on all other examples in the training set. Intuitively, each training example provides additional information about the true anatomical variation, and thus helps to determine the correspondence between the other shapes. Groupwise approaches explicitly measure correspondence with an objective function, which usually depends on the computed SSM. The key idea is that the optimal set of corresponding points inherently provides the “best” model. Arguably the most renowned objective function is the minimum description length (MDL) function introduced by Davies et al. [30], which is founded on information theory. For optimizing this objective function, Davies formulates the correspondence problem as one of reparameterization 
                     [31]: All training shapes are mapped to a suitable parameter space, which reflects the topology of the shapes. The objective function is then minimized by manipulating these parameterizations.

The MDL objective function is complex and its evaluation costly. Similar cost functions [32] and simplifications of the full MDL objective function exist [33], which typically have the disadvantage that they are controlled by (at least) one free parameter, for which there is no obvious choice. Up to now, the influence of this parameter on the resulting models has not been thoroughly studied. Beside this, the optimization may be influenced by the choice of the re-parameterization function, by the choice of the employed optimization strategies such as coarse-to-fine approaches [31,34], and by including additional parameters such as the shapes’ pose. The different approaches will be reviewed in more detail in Section 2.2.

Evidently, a large number of possible combinations of the aforementioned building blocks can be imagined. However, up to now there exists no study that aims at benchmarking which combination provides the correspondence that performs best. Moreover, with the current evaluation methodology, it is not possible to directly quantify the influence of correspondence on the performance of SSMs in an application such as medical image segmentation. In particular, while it allows to rank different models, it does not estimate the gain in segmentation accuracy that can be obtained by building better models. Thus, the elementary aspect of this article is to provide a thorough qualitative and quantitative evaluation of different SSMs that have been constructed using groupwise optimization by varying all of the aforementioned components, and, by this means, close the gap between correspondence evaluation and SSM-based image segmentation.

@&#RELATED WORK@&#

Davies [35] introduced the well-known and by now frequently employed (e.g. [23,6,31,34,28,36,37]) correspondence quality measures compactness, specificity and generalization ability for measuring the quality of the SSM in case ground-truth data is not available (cf. Section 4.1). Since compactness is known to inherently favor MDL correspondence, it is not used in this work. A theoretical foundation of specificity and the related generalization ability is given in the work of Twining and Taylor [38].

While these measures have established themselves as a standard, some researchers criticized their use, and pointed out counter-intuitive behavior and shortcomings of the evaluation measures [39,40]. To overcome these issues, Ericsson and Karlsson [39] introduced a correspondence measure which requires (manually defined) ground-truth correspondence. Similarly, Munsell et al. [40] propose to benchmark correspondence algorithms by testing their capability for recovering the “ground-truth” shape space of a given SSM on the basis of a large number (800) of synthetic shapes randomly sampled from the “ground-truth” shape space. In both studies, experiments are only performed on 2D shapes.

Although the extension of these evaluation methods to 3D is theoretically possible, annotating large 3D data sets manually is extremely time-consuming. Moreover, it is difficult to identify landmarks reliably on medical and biological shapes in 3D, thus the inevitable inter- and intra-observer variability may impinge on the validity of the resulting “ground-truth”. In the method of Munsell et al. [40], the requirement to optimize correspondence for several hundred or even thousand 3D shapes constitutes an additional burden because of long optimization times.

Besides Ericsson and Munsell, several other authors reported problems with the standard evaluation measures [41,16,42]. In fact, these problems can often be explained by the use of landmark based distance measures for shape comparison that most authors use [23,31,34,36,26], which disregard the error introduced when a densely sampled input geometry is approximated by a landmark representation. There are two strategies to account for this approximation error. One strategy is to use two different tests: In the first test, the distance between landmark representation and corresponding input geometry is computed. If this approximation error is considered as sufficiently low for all landmark vectors, the evaluation can be done using landmark based metrics. A similar approach has been used for Active Appearance Models in [38]. The other strategy is to use distance functions, which are capable of comparing shapes sampled from the model with the original input geometry, as for example the volumetric measures used by Heimann et al. [34] or the surface based metrics used by Gollmer and Buzug [42]. The advantage of this approach over the first strategy is that there is no need to set a threshold on the approximation error, and that it allows for directly comparing SSMs that were built from landmark representations with different approximation errors.

There are several studies that evaluate correspondence in 3D thereby employing the aforementioned correspondence quality measures, although all these studies ignore the problems caused by deficient shape approximations we discussed just before. For instance, Styner et al. [36] evaluated groupwise optimized correspondence algorithms against alternative correspondence algorithms including semi-automatic landmark labeling. However, the impact that different cost function parameters or optimization strategies might have on the attainable correspondence quality was not investigated. Later on, Styner et al. [26] used the simplified MDL objective [33] for measuring the correspondence quality in case surface curvature is taken into account.

Recently, Davies et al. [31] published an evaluation study that provides a thorough evaluation of the convergence behavior of their optimization scheme under different parameter settings and optimization strategies. However, they did not compare their method with alternative optimization strategies such as the open-source implementation of Heimann et al. [43].

Heimann et al. [41] and subsequently [44] stressed the importance of an adequate shape parameterization in order to obtain SSMs that do not suffer from severe artifacts. Indeed, we could show recently that thoroughly constructed and consistently aligned parameterizations can be used to construct SSMs that perform as well as SSMs with optimized correspondence on some objects [28].

All the aforementioned evaluation studies evaluate correspondence mainly from a theoretical point of view, but not in context of an actual application: Firstly, specificity tests are restricted w.r.t. the assumptions that are already made during the establishment of correspondence, namely that the shape variability can be modeled using a particular (e.g. multivariate Gaussian) distribution. Secondly, the fact that the leave-one-out generalization ability may be biased due to the groupwise character of the correspondence optimization is not addressed at all (see discussion in Section 4.1). Thirdly, it is not possible to directly quantify the influence of the correspondence on the performance of the SSM in an actual application such as image segmentation.

To our knowledge, the only study with a more application driven evaluation is the work of Styner et al. [37]. They looked into the correspondence quality in an application for morphometric analysis. However, in contrast to image segmentation, no ground truth is available for morphometric analysis and therefore it is not straightforward to draw quantitative conclusions concerning the influence of different correspondence methods on the performance of the respective SSM.

Faced with the lack of ground-truth correspondence, we propose a new application driven approach for measuring the quality of different SSMs that goes beyond that of benchmarking correspondence of 3D shapes (e.g. [16,23,6,31,41,34,28,26,36]): In order to detect whether a set of correspondence performs better or worse compared to another one in an application for image segmentation, we segment binary expert segmentations with the SSMs constructed from different correspondences (cf. Section 4.3). By this means we (i) are able to measure model specificity w.r.t. randomly generated shapes that are not drawn from a particular (e.g. multivariate Gaussian) distribution (cf. Section 4.3), (ii) are able to measure model generalization ability by segmenting completely unseen shapes, which is not quite the same as measuring Davies’ leave-one-out generalization ability (cf. Section 4.3), and thus (iii) are able to quantify the expectable influence of correspondence on the segmentation performance in practice.

Moreover, we address shortcomings and limitations of the aforementioned evaluation studies by
                           
                              1.
                              comparing different state-of-the-art optimization approaches [31,41],

comparing different state-of-the-art objective functions for correspondence optimization [31–33], and evaluate the influence of the respective free parameter,

discussing and applying different distance functions for quantifying the quality of SSMs constructed under permutation of the options itemized before,

directly comparing the findings made by employing Davies’ correspondence measures and the proposed segmentation evaluation, respectively, and

investigating the influence of different optimization strategies and cost functions on the shape parameterizations in order to identify current weak spots and directions for further improvement.

In order to adequately address all the aspects mentioned we employ different publicly available data set of varying shape complexity and shape variability.

In order to be able to systematically evaluate the influence of different aspects of 3D SSM construction, this work is divided into five main parts.

In Section 2 we provide the reader with the necessary background information about the core aspects of SSMs. Having introduced the common approach for modeling shape variability (Section 2.1), we review how the correspondence problem can be solved (Section 2.2). Finally, we formally introduce measures for quantitatively evaluating correspondence (Section 4.1).

Section 3 focuses on the pipeline used for the establishment of groupwise optimal correspondence.

The SSMs obtained using that pipeline are evaluated in various ways as will be described in Section 4. Starting with a short review of state-of-the-art distance functions (Section 4.2), we then introduce the proposed segmentation evaluation (Section 4.3), detail how the shape parameterizations are benchmarked (Section 4.4) and finally detail our data sets and how we designed the experiments (Section 4.5).

Section 5 reports on the experimental results, which are discussed in Section 6 and final conclusions are drawn.

@&#BACKGROUND@&#

In this section, we give the background on groupwise correspondence optimization which may be skipped by the reader already familiar with that material. We first give a short introduction to statistical shape models (Section 2.1), and then introduce the groupwise correspondence optimization pipeline and discuss its current state-of-the art (Section 2.2).

Statistical shape models (SSM) [1] describe the shape variability of a particular object class on the basis of corresponding points (landmarks) that have to be identified across all samples of the training population.

Let a set of 
                           
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                           
                         shapes 
                           
                              {
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ∈
                              X
                              ⊂
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                              ;
                              
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                              }
                           
                         of a certain object class be given, represented as piecewise-linear surfaces consisting of triangles and vertices. Here, 
                           
                              X
                           
                         is the set of all shape instances. The shapes are aligned in a common coordinate frame and sampled at corresponding positions using 
                           
                              
                                 
                                    n
                                 
                                 
                                    p
                                 
                              
                           
                         landmarks 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    j
                                    )
                                 
                              
                              ∈
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                              j
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    p
                                 
                              
                           
                        . Any point is represented by a tuple 
                           
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    j
                                    )
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    j
                                    )
                                 
                              
                              ,
                              
                                 
                                    z
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    j
                                    )
                                 
                              
                              )
                           
                         of Cartesian coordinates in 
                           
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                           
                        . By concatenating the landmark coordinates into a single vector we can represent each shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                         by means of its shape vector 
                        
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              =
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    z
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                    )
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                    )
                                 
                              
                              ,
                              
                                 
                                    z
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                    )
                                 
                              
                              )
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    3
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                 
                              
                           
                        .

Assuming a multivariate Gaussian distribution of the training samples in 
                           
                              
                                 
                                    R
                                 
                                 
                                    3
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                 
                              
                           
                        , the object’s shape variability can be described by the linear model
                           
                              (1)
                              
                                 x
                                 =
                                 
                                    
                                       x
                                    
                                    
                                       ‾
                                    
                                 
                                 +
                                 Pb
                                 +
                                 r
                                 .
                              
                           
                        Here, 
                           
                              
                                 
                                    x
                                 
                                 
                                    ‾
                                 
                              
                              =
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                                 
                                    -
                                    1
                                 
                              
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          s
                                       
                                    
                                 
                              
                              
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         is the mean shape, and the columns of the matrix 
                           
                              P
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    3
                                    
                                       
                                          n
                                       
                                       
                                          p
                                       
                                    
                                    ×
                                    
                                       
                                          n
                                       
                                       
                                          m
                                       
                                    
                                 
                              
                           
                         are the first 
                           
                              
                                 
                                    n
                                 
                                 
                                    m
                                 
                              
                           
                         eigenvectors of the sample covariance matrix 
                           
                              C
                              =
                              
                                 
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          s
                                       
                                    
                                    -
                                    1
                                    )
                                 
                                 
                                    -
                                    1
                                 
                              
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          s
                                       
                                    
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              -
                              
                                 
                                    x
                                 
                                 
                                    ¯
                                 
                              
                              )
                              
                                 
                                    (
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    -
                                    
                                       
                                          x
                                       
                                       
                                          ¯
                                       
                                    
                                    )
                                 
                                 
                                    T
                                 
                              
                           
                        . The parameter 
                           
                              
                                 
                                    n
                                 
                                 
                                    m
                                 
                              
                           
                         determines the number of eigenmodes used in the model and the vector 
                           
                              b
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          m
                                       
                                    
                                 
                              
                           
                         contains the shape parameters. In the Gaussian model, the shape parameters 
                           
                              
                                 
                                    b
                                 
                                 
                                    m
                                 
                              
                              ∈
                              R
                              ,
                              
                              m
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    m
                                 
                              
                           
                         are independent, Gaussian distributed random variables with zero mean and variance 
                           
                              
                                 
                                    λ
                                 
                                 
                                    m
                                 
                              
                           
                        , where 
                           
                              
                                 
                                    λ
                                 
                                 
                                    m
                                 
                              
                           
                         is the m-th largest eigenvalue of 
                           
                              C
                           
                        . 
                           
                              r
                           
                         is a residual vector with noise.

For constructing SSMs, it is necessary to establish point correspondence on a set of input shapes. One approach for solving the correspondence problem is groupwise optimization which has gained a lot of attention due to its rigorous justification by information theoretical principles. The general approach of groupwise optimization is described in the next paragraphs, and the most important related work in this context are reviewed.

The general idea of groupwise optimization methods is to explicitly measure correspondence by an objective function which depends on all input shapes. In most cases model-based objective functions are used, which assess the correspondence by measuring desirable properties of the induced SSM. These properties can be explicitly improved by manipulating the correspondences of the shapes with an optimization algorithm.

Most groupwise optimization algorithms follow the optimization by re-parameterization paradigm which was introduced by [32]. Fig. 1
                        
                         gives a schematic overview over this approach for a subset of the liver training population. All input shapes are initially mapped to a common parameter domain. This mapping defines an initial correspondence between the shapes, i.e. points on different shapes with identical parameter space coordinates correspond. By re-parameterization, which means purposely modifying the parameterization of the shapes, the objective function is optimized.

We follow the optimization by re-parameterization paradigm in this work because it was adopted by most other authors [31,34,26,36]. The building blocks of this approach and their various implementations are discussed in the next paragraphs. An alternative optimization strategy was proposed by Cates et al. [45] who minimize their model-based objective function by optimizing the positions of a discrete set of particles which are constrained to lie on the shapes’ surfaces.

The first groupwise objective function was introduced by Kotcheff and Taylor [32] who proposed to minimize the determinant of the covariance matrix, which is
                              
                                 (2)
                                 
                                    
                                       
                                          L
                                       
                                       
                                          dc
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             log
                                             (
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             +
                                             ∊
                                             )
                                             -
                                             log
                                             ∊
                                          
                                       
                                    
                                    .
                                 
                              
                           This function, often referred to as DetCov, is a measure of the model compactness. The regularization parameter 
                              
                                 ∊
                              
                            is a measure of the noise in the training set, and is required because the covariance matrix of the data set can be singular. However, the biggest disadvantage of the DetCov function is that it has no rigorous justification. Davies et al. [30] addressed this problem and derived an objective function which is founded on the minimum description length (MDL) principle. This function uses information theoretical concepts to measure the complexity of an SSM and has the essential characteristic to, at least to some extent, optimally trade off for the model complexity and its quality [46]. Davies et al. [31] also introduced a continuous approximation of the full MDL function, which we used in this work. It takes the form
                              
                                 (3)
                                 
                                    
                                       
                                          L
                                       
                                       
                                          mdl
                                       
                                    
                                    (
                                    Δ
                                    )
                                    =
                                    f
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          s
                                       
                                    
                                    ,
                                    Δ
                                    ,
                                    R
                                    )
                                    +
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             :
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             ⩾
                                             
                                                
                                                   λ
                                                
                                                
                                                   min
                                                
                                             
                                          
                                       
                                    
                                    (
                                    
                                       
                                          n
                                       
                                       
                                          s
                                       
                                    
                                    -
                                    2
                                    )
                                    log
                                    
                                       
                                          
                                             
                                                λ
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    +
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             :
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             <
                                             
                                                
                                                   λ
                                                
                                                
                                                   min
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             (
                                             
                                                
                                                   n
                                                
                                                
                                                   s
                                                
                                             
                                             -
                                             2
                                             )
                                             log
                                             
                                                
                                                   
                                                      
                                                         λ
                                                      
                                                      
                                                         min
                                                      
                                                   
                                                
                                             
                                             +
                                             
                                                
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         s
                                                      
                                                   
                                                   
                                                      
                                                         λ
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                                
                                                   2
                                                   
                                                      
                                                         λ
                                                      
                                                      
                                                         min
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           Here, 
                              
                                 Δ
                              
                            is the coding accuracy of the data, R is an upper bound of the spatial range of the data, and 
                              
                                 f
                                 (
                                 
                                    
                                       n
                                    
                                    
                                       s
                                    
                                 
                                 ,
                                 Δ
                                 ,
                                 R
                                 )
                              
                            is a constant function for a given data set and coding accuracy. The value for 
                              
                                 
                                    
                                       λ
                                    
                                    
                                       min
                                    
                                 
                              
                            is chosen in dependence of the coding accuracy, that is 
                              
                                 
                                    
                                       λ
                                    
                                    
                                       min
                                    
                                 
                                 =
                                 4
                                 
                                    
                                       Δ
                                    
                                    
                                       2
                                    
                                 
                              
                           . In practice, the objective function is integrated over a range 
                              
                                 [
                                 
                                    
                                       Δ
                                    
                                    
                                       min
                                    
                                 
                                 ,
                                 
                                    
                                       Δ
                                    
                                    
                                       max
                                    
                                 
                                 ]
                              
                            of values. Refer to [31] for a detailed discussion of Eq. (3) and its parameters. For performance reasons, Davies et al. [31] first optimize this continuous approximation, and then fine tune the correspondences using the full MDL function [47].

Thodberg [33] introduced a simplified version of the MDL function,
                              
                                 (4)
                                 
                                    
                                       
                                          L
                                       
                                       
                                          smpl
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             :
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             ⩾
                                             
                                                
                                                   λ
                                                
                                                
                                                   cut
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             1
                                             +
                                             log
                                             (
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             /
                                             
                                                
                                                   λ
                                                
                                                
                                                   cut
                                                
                                             
                                             )
                                          
                                       
                                    
                                    +
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             :
                                             
                                                
                                                   λ
                                                
                                                
                                                   i
                                                
                                             
                                             <
                                             
                                                
                                                   λ
                                                
                                                
                                                   cut
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    /
                                    
                                       
                                          λ
                                       
                                       
                                          cut
                                       
                                    
                                    .
                                 
                              
                           Similar to 
                              
                                 
                                    
                                       L
                                    
                                    
                                       dc
                                    
                                 
                              
                            
                           (2), 
                              
                                 
                                    
                                       L
                                    
                                    
                                       smpl
                                    
                                 
                              
                            
                           (4) has a free cut-off parameter denoted as 
                              
                                 
                                    
                                       λ
                                    
                                    
                                       cut
                                    
                                 
                              
                            for measuring the noise in the training data set. Although Thodberg’s function is an ad hoc approximation of Davies’ original formulation [30], Ericsson [48] showed later on that (4) only differs in a constant if 
                              
                                 
                                    
                                       n
                                    
                                    
                                       s
                                    
                                 
                              
                            is large. However, the actual reason why (4) found its way into several MDL-based implementations [43,49] is its analytical differentiability, which makes the optimization computationally much more appealing [50]. Thodberg and Olafsdottir [51] as well as Styner et al. [26] proposed to add curvature terms to the 
                              
                                 
                                    
                                       L
                                    
                                    
                                       smpl
                                    
                                 
                              
                            function, which has been reported to be beneficial on some, but not all data sets [26].

In order to evaluate the objective function, two important aspects must be taken into account: Firstly, both Kotcheff and Taylor [32] and Davies et al. [31] model the shapes as continuous surfaces, such that the shape covariance matrix is infinite dimensional in theory. However, its nonzero eigenvalues can still be computed as long as the number of input shapes is finite. In practice, the integral must be numerically approximated with finitely many sample points. Secondly, it is assumed that the shapes are in the same coordinate system. This means that pose parameters must be determined for the input shapes to compute this alignment. Heimann et al. [41] recompute the pose parameters using Procrustes analysis before each objective function evaluation. Davies et al. [31] studied the effect on explicitly optimizing pose during optimization. However, they did only investigate the effect on the objective function, not the effect on the metrics used for evaluating the model quality.

Model-based objective functions are usually optimized by mapping the shapes to a common parameter space and manipulating the parameterizations. In most 3D implementations the unit sphere is used as parameter domain [31,41], as many organs such as, for example, liver and kidney have spherical topology. Alternative parameter domains for nonspherical shapes are for example the rectangle for surfaces with boundary [52], or a “continuous” rectangular parameter space for shapes with genus 1 topology [53]. The mapping of a mesh to a parameter domain such as the sphere leads in general to distortions of angles and areas, and it is therefore reasonable to find a distortion-minimizing mapping. Davies et al. [31] propose to use the spherical mapping approach of [25] which is constrained to be area preserving and additionally tries to minimize angular distortion. Other authors propose to use conformal (angle-preserving) spherical mapping [54,41]. While it can be shown that a conformal mapping of a shape with spherical topology to the unit sphere always exists [55], it usually comes at the cost of large area distortions, such that it becomes crucial to use adaptive techniques for sampling shapes from the parameterizations [41]. As the initial parameterization defines the starting point of the optimization, it is important to parameterize the shape consistently to avoid poor local optima and ensure faster convergence [56]. Consistent parameterization of a group of shapes is often achieved by integrating registration algorithms such as the ICP algorithm into the parameterization process [56,54,28,57].

The initial parameterization is manipulated during optimization with a re-parameterization function. Davies et al. propose so called Theta transformations [31,47] and clamped plate splines (CPS) [56]. Both functions are controlled by hyperparameters, for example the center of the spline, and parameters that control the magnitude of the re-parameterization. Clamped plate splines have the advantage over the Theta transformation that their effect is localized. Heimann et al. [34] propose an alternative localized re-parameterization with bounded Gaussian kernels on the sphere. Instead of using parametric functions like splines or Gaussian kernels, one can also use nonparametric regularization to express a larger class of re-parameterizations [58].

For evaluating the objective function, the parameter space must be sampled with finitely many sample points. Heimann et al. [34] apply the re-parameterization function directly to the parameterizations, whereas Davies et al. [31] manipulate the sample points instead. While both approaches have in principle the same effect, the latter is computationally less complex.

Kotcheff and Taylor [32] initially proposed a genetic algorithm for optimization of correspondences of 2D shapes. Because the genetic algorithm was impractically slow in the 3D setting, Davies et al. [31] later changed the optimization algorithm to an iterative stochastic approach: In each iteration, the hyperparameters of the re-parameterization function are chosen at random, and then its parameters are optimized with the Nelder–Mead method. The optimization can be further improved by using gradient descent optimization with semi-analytically computed gradients [50,34]. In each iteration, one can either reparameterize all parameterizations simultaneously, or only modify a single, randomly chosen parameterization [31].

@&#SUMMARY@&#

In summary, most groupwise optimization algorithms follow the same principle, but different alternatives are available for the different building blocks of the algorithm. Table 1
                            gives a comparative overview of the choices made by Davies et al. [59] and Heimann et al. [41].

Based on the methods presented in the preceding chapter, we implemented a state-of-the-art correspondence optimization pipeline that incorporates the most important objective function and the most promising optimization techniques. We discuss the pipeline in the following section, and justify the choices we made.

The initial correspondence is defined on the basis of a shape-preserving embedding of the shapes 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                         into the parameter domain of the unit-2-sphere 
                           
                              
                                 
                                    S
                                 
                                 
                                    2
                                 
                              
                           
                        . At this, the spherical parameterization 
                           
                              {
                              
                                 
                                    ω
                                 
                                 
                                    i
                                 
                              
                              :
                              
                                 
                                    S
                                 
                                 
                                    2
                                 
                              
                              →
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ,
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                              }
                           
                         defines a one-to-one correspondence between the spherical surface 
                           
                              
                                 
                                    P
                                 
                                 
                                    
                                       
                                          S
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              ∈
                              
                                 
                                    S
                                 
                                 
                                    2
                                 
                              
                           
                         and 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                        . Recently, it has been shown [28] that a suitable parameterization algorithm has to take into account two possibly conflicting aspects: The minimization of angle and area distortion and consistency. The former allows for sampling high quality shape vectors from the parameterizations whereas the latter ensures that similar features are mapped to approximately the same spherical regions. These two aspects are the basic ingredients of a couple of pairwise correspondence algorithms, among others the well-established SPHARM approach [4]. However, in this work, initial (pairwise) correspondence is established based on the Distmin parameterization method, which has outperformed several alternative algorithms for consistent spherical parameterization like SPHARM [4] and propagation [57] in context of correspondence optimization in a detailed evaluation [28]. Moreover, it has been shown that pairwise correspondence established based on the Distmin method performs just as well as groupwise optimized correspondence in terms of specificity (Eq. (5)) and generalization ability (Eq. (6)) on some objects [28]. The superior performance of Distmin over SPHARM, which reaches almost that of MDL, can be clearly observed in Figs. 3 and 4
                        
                        .

The Distmin algorithm works as follows: The mapping 
                           
                              {
                              
                                 
                                    ω
                                 
                                 
                                    i
                                 
                              
                              :
                              
                                 
                                    S
                                 
                                 
                                    2
                                 
                              
                              →
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ;
                              
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                              }
                           
                         is established independently for all training shapes by mapping those to the unit sphere using the area- and approximately angle-preserving mapping of Brechbühler et al. [25]. One of the training shapes, 
                           
                              
                                 
                                    S
                                 
                                 
                                    ref
                                 
                              
                           
                        , is selected as reference shape and all other shapes are aligned with 
                           
                              
                                 
                                    S
                                 
                                 
                                    ref
                                 
                              
                           
                        . The alignment is achieved by first rescaling each shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ,
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                              ,
                              i
                              
                              ≠
                              
                              ref
                           
                         with an anisotropic scaling, such that the scale of the shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                         as measured on its three principal axes matches that of 
                           
                              
                                 
                                    S
                                 
                                 
                                    ref
                                 
                              
                           
                        . The scaling is computed by means of a PCA of the mesh points. The rescaled shape is then ICP aligned [12] with 
                           
                              
                                 
                                    S
                                 
                                 
                                    ref
                                 
                              
                           
                        . The closest point relation after alignment defines an approximate correspondence relation between the points on the shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                         to the mesh vertices of 
                           
                              
                                 
                                    S
                                 
                                 
                                    ref
                                 
                              
                           
                        . This relation is transferred to the unit sphere by means of the initially calculated 
                           
                              
                                 
                                    ω
                                 
                                 
                                    i
                                 
                              
                           
                         and then used to compute a rotation matrix that optimally superimposes the spherical surface 
                           
                              
                                 
                                    P
                                 
                                 
                                    
                                       
                                          S
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         with 
                           
                              
                                 
                                    P
                                 
                                 
                                    
                                       
                                          S
                                       
                                       
                                          ref
                                       
                                    
                                 
                              
                           
                         in a least squares sense using the method of Horn [60]. The aligned spherical surface is denoted by 
                           
                              
                                 
                                    P
                                 
                                 
                                    
                                       
                                          S
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    ′
                                 
                              
                           
                        .

The effect of the algorithm is depicted schematically in Fig. 2 for a subset of the liver training population. Equidistant remeshing of the spherical surfaces 
                           
                              {
                              
                                 
                                    P
                                 
                                 
                                    
                                       
                                          S
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              }
                           
                         using 
                           
                              
                                 
                                    n
                                 
                                 
                                    p
                                 
                              
                           
                         points and transferring the interpolated points to the shapes 
                           
                              {
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              }
                           
                         yields the shape vectors 
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                         that are needed for SSM construction (Section 2.1).

The initial correspondence is now iteratively optimized such as to establish groupwise optimal correspondence. In each iteration, one of the shapes is selected uniformly at random, and its parameterization is optimized using a gradient-descent optimization. We incorporated several different objective functions in our implementation, two different re-parameterization algorithms, as well as some optional optimization strategies such as multi-resolution and pose optimization.

We implemented the most widely used objective functions: The DetCov function [32] (Eq. (2)), the continuous version of the MDL function [31] (Eq. (3)), as well as the simplified MDL function (Eq. (4)) proposed by Thodberg [33]. The MDL function was chosen because it has the most rigorous justification. The DetCov functions has been previously reported to behave similar to the MDL [36] and is advantageous as regards computational complexity. Thodberg’s function is comparably simple, and has gained popularity because it is part of the open-source MDL implementation of Heimann et al. [43].

Both Thodberg’s function (Eq. (4)) and the DetCov objective (Eq. (2)) have a free regularization parameter that estimates the noise in the data. Similar to the reasoning of Thodberg [33], we choose these parameters in dependence of the average voxel spacing 
                              
                                 δ
                              
                            of the expert segmentations. We assume that the standard deviation of the noise per landmark is 
                              
                                 θ
                                 δ
                              
                           , where 
                              
                                 θ
                              
                            is a scaling factor. Because we believe that the magnitude of noise in the expert segmentations is roughly in the order of one voxel, 
                              
                                 θ
                              
                            should be in the order of 1. Then, with the original average RMS radius of the training shapes, R, one can estimate the variance of an eigenmode that only contains noise. In case that the shape vectors are scaled to unit length, this is estimated as 
                              
                                 
                                    
                                       g
                                    
                                    
                                       ′
                                    
                                 
                                 (
                                 θ
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   θ
                                                   δ
                                                
                                                
                                                   R
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                              
                           . In our implementation, the shapes are scaled to RMS radius one, hence we use 
                              
                                 g
                                 (
                                 θ
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   θ
                                                   δ
                                                
                                                
                                                   R
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 *
                                 
                                    
                                       n
                                    
                                    
                                       p
                                    
                                 
                              
                            as a threshold for noise dominated modes. For the DetCov function (Eq. (2)), we choose two different regularization parameters in order to study its influence: We define 
                              
                                 
                                    
                                       ∊
                                    
                                    
                                       ∗
                                    
                                 
                                 =
                                 g
                                 (
                                 0.3
                                 )
                              
                           , a choice which has been previously used by Thodberg [33] and Heimann et al. [34], and denote the corresponding objective function by DetCov∗. With DetCov, we denote the objective function with the standard regularization parameter 
                              
                                 ∊
                                 =
                                 0.001
                              
                            proposed by Kotcheff and Taylor [32]. For Thodberg’s function (Eq. (4)), we follow [34], set 
                              
                                 
                                    
                                       λ
                                    
                                    
                                       cut
                                    
                                 
                                 =
                                 g
                                 (
                                 0.3
                                 )
                              
                            and denote this by Thodberg∗.

Several non-rigid mappings could be imagined to generate an appropriate warp of the parameterizations. In our implementation, we can choose between clamped plate splines (CPS) [56] or clamped Gaussian kernels (Gausswarp, GW) [34]. We do purposely not consider re-parameterization schemes that require the optimization of various coefficients such as Cauchy kernels [31,47] or polynomials [49] since it would make the influence of the re-parameterization subpart onto the overall optimization approach less clear.

Both chosen reparameterization methods are localized, which means that they only affect a local spherical region. The spherical region can be defined by the position and the size of the reparameterization kernel. In order to achieve a global reparameterization, we distribute a set of kernels uniformly on the sphere. Like Heimann et al. [34], we keep the positions of the kernels fixed, but rotate in each iteration the spherical parameterizations with a randomly drawn rotation matrix such that all spherical regions are affected by the re-parameterization in the same way.

Following [34], our algorithm starts with establishing optimal correspondence over a relatively large region but allows for successively switching to smaller areas. This is achieved by choosing few but large re-parameterization kernels on the coarsest resolution level. In finer levels, the number of kernels is increased while their width decreases. While such a coarse-to-fine technique is rather common in problems like image registration, one might also think that the optimization of correspondences on rather fine details introduces spurious artifacts. Therefore, we compare the correspondence found by using the prescribed multi-resolution (MR) approach with the one obtained by optimizing solely at the coarsest resolution (single resolution, SR).

We evaluate whether any quality gain can be achieved by pose optimization that justifies the additional computational costs. Although Davies et al. [31] reported slightly better values of the objective function in case pose is optimized explicitly, it has not been proven that a smaller objective value really coincides with superior correspondence quality. In fact, we have previously shown that this is not the case for the continuous approximation of the MDL [28], albeit we did not conduct experiments using the full MDL function.


                        Specificity and generalization ability 
                        [35] are widely used measures [59,6,34,61,28,26,36] for quantifying the quality of the correspondence and hence the resulting model. Both criteria estimate the similarity of different shapes by means of a particular metric and depend on the number 
                           
                              
                                 
                                    n
                                 
                                 
                                    m
                                 
                              
                           
                         of parameters 
                           
                              {
                              
                                 
                                    b
                                 
                                 
                                    m
                                 
                                 
                                    ∗
                                 
                              
                              ∈
                              R
                              ;
                              
                              m
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    m
                                 
                              
                              }
                           
                        . Correspondingly, we define specificity 
                           
                              S
                           
                         and generalization ability 
                           
                              G
                           
                         in terms of some distance function 
                           
                              D
                              :
                              X
                              ×
                              X
                              →
                              R
                           
                        .

Specificity measures the validity of any shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    ∗
                                 
                              
                           
                         with shape vector 
                           
                              
                                 
                                    x
                                 
                                 
                                    ∗
                                 
                              
                           
                         generated by the model (1). Hence, an SSM with high specificity (low values of 
                           
                              S
                           
                        ) always provides valid shape instances of the particular object class. It is measured by computing a large number of N (here: 
                           
                              N
                              =
                              1000
                           
                        ) shape reconstructions by randomly varying 
                           
                              {
                              
                                 
                                    b
                                 
                                 
                                    m
                                 
                                 
                                    ∗
                                 
                              
                              }
                           
                         (here: 
                           
                              
                                 
                                    b
                                 
                                 
                                    m
                                 
                                 
                                    ∗
                                 
                              
                              ≤
                              ±
                              3
                              
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          m
                                       
                                    
                                 
                              
                           
                        ) w.r.t. the underlying probability density function (pdf) and estimating the similarity of the reconstructions 
                           
                              {
                              
                                 
                                    S
                                 
                                 
                                    k
                                 
                                 
                                    ∗
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             m
                                          
                                       
                                    
                                 
                              
                              ∈
                              X
                              }
                           
                         with the shape samples 
                           
                              {
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ∈
                              X
                              }
                           
                        :
                           
                              (5)
                              
                                 S
                                 
                                    
                                       
                                          
                                             
                                                n
                                             
                                             
                                                m
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 
                                    
                                       
                                          min
                                       
                                       
                                          
                                             
                                                
                                                   i
                                                   =
                                                   1
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         s
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 D
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                k
                                             
                                             
                                                ∗
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         m
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

On the other hand, the model should also be able to generalize from the shapes of the training set. Accordingly, small values of 
                           
                              G
                           
                         indicate that the model is well suited for representing previously unknown shape instances. Generalization ability can be measured by a series of leave-one-out tests [6]: By omitting the i-th training shape 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                        , an SSM is built and subsequently used to generate the reconstruction 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                                 
                                    ∗
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             m
                                          
                                       
                                    
                                 
                              
                              ∈
                              X
                           
                         of 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                        . Averaging over the series of tests yields
                           
                              (6)
                              
                                 
                                    
                                       G
                                    
                                    
                                       ∼
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                n
                                             
                                             
                                                m
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             s
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                n
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 D
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                             
                                                ∗
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         m
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        There is a subtle problem when using leave-one-out tests to evaluate groupwise optimization. If one optimizes using all shapes, the leave-one-out test is inherently biased, because the left-out shape was used during optimization and thus has influenced the correspondences. If the optimization is done 
                           
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                           
                         times by excluding each time another shape, it is nontrivial to compare the left-out shape with the other shapes, because the correspondences are unknown. At least, some kind of registration is necessary, and the chosen registration approach may influence the results. Beside this, the computational burden of optimizing 
                           
                              
                                 
                                    n
                                 
                                 
                                    s
                                 
                              
                           
                         times is extremely high.

In order to measure generalization ability over the entire model pdf, a measure that is analogous to specificity (5) can be defined according to [62],
                           
                              (7)
                              
                                 G
                                 
                                    
                                       
                                          
                                             
                                                n
                                             
                                             
                                                m
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             s
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                n
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          min
                                       
                                       
                                          
                                             
                                                
                                                   k
                                                   =
                                                   1
                                                   ,
                                                   …
                                                   ,
                                                   N
                                                
                                             
                                          
                                       
                                    
                                 
                                 D
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                k
                                             
                                             
                                                ∗
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         m
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        While specificity (5) measures the similarity between reconstructed shape instances and any, but not necessarily all, shapes of the training set, generalization ability (7) measures how well all shapes of the training population fit to the generated model.

The selection of a suitable distance function 
                           
                              D
                           
                         is crucial when computing specificity (5) and generalization ability Eqs. (6) and (7). Most studies [23,6,31,34,26,36] use the Euclidean distance between shape vectors as metric. A severe problem of this approach is that the metric can only be applied to the output of the correspondence algorithm, and not on the original input shapes. Thus, it is not possible to account for differences between the original input shapes and their corresponding shape vectors. The evaluation may therefore favor models learned from shape vectors, which represent the original surface poorly. This problem was first addressed by Heimann et al. [41], who proposed to use the Jaccard Coefficient as a similarity measure, which was later also employed in [40]. For this, the sampled shapes are converted to label images, and then compared to label images of the training examples. Let 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                         be the volume encompassed by the shapes 
                           
                              
                                 
                                    S
                                 
                                 
                                    ∗
                                 
                              
                           
                         and 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                        , respectively. The similarity of the sets of volume elements (voxels) 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                              
                           
                         is computed as the ratio of the number of common voxels and the size of their union, which is known as the Jaccard Coefficient,
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       JC
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                V
                                                
                                                   
                                                      
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               ∗
                                                            
                                                         
                                                      
                                                   
                                                
                                                ∩
                                                V
                                                
                                                   
                                                      
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                V
                                                
                                                   
                                                      
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               ∗
                                                            
                                                         
                                                      
                                                   
                                                
                                                ∪
                                                V
                                                
                                                   
                                                      
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        The negation of 
                           
                              
                                 
                                    C
                                 
                                 
                                    JC
                                 
                              
                           
                        , which equals 1 in case that 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                         are identical and 0 if they do not overlap at all, and multiplication with 100 yields
                           
                              (8)
                              
                                 
                                    
                                       D
                                    
                                    
                                       VOE
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 =
                                 100
                                 
                                    
                                       
                                          1
                                          -
                                          
                                             
                                                C
                                             
                                             
                                                JC
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         ∗
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        which measures the percental volumetric overlap error of two volumes 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              V
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        .

However, the voxelization may lead to small discretization errors, a problem that can be circumvented using surface based metrics [42]. Accordingly, we compute specificity (5) and generalization ability (Eqs. (6) and (7)) using several surface based distance functions, namely the average symmetric surface distance (
                           
                              
                                 
                                    D
                                 
                                 
                                    ASD
                                 
                              
                           
                        ), the root mean square symmetric surface distance (
                           
                              
                                 
                                    D
                                 
                                 
                                    RMSD
                                 
                              
                           
                        ) and the symmetric Hausdorff surface distance (
                           
                              
                                 
                                    D
                                 
                                 
                                    HD
                                 
                              
                           
                        ). Given an arbitrary point 
                           
                              
                                 
                                    ρ
                                 
                                 
                                    ′
                                 
                              
                              ∈
                              
                                 
                                    S
                                 
                                 
                                    ′
                                 
                              
                           
                         and let 
                           
                              d
                              
                                 
                                    
                                       
                                          
                                             ρ
                                          
                                          
                                             ′
                                          
                                       
                                       ,
                                       S
                                    
                                 
                              
                              :
                              =
                              
                                 
                                    min
                                 
                                 
                                    ρ
                                    ∈
                                    S
                                 
                              
                              |
                              |
                              
                                 
                                    ρ
                                 
                                 
                                    ′
                                 
                              
                              -
                              ρ
                              |
                              
                                 
                                    |
                                 
                                 
                                    2
                                 
                              
                           
                         be the distance of 
                           
                              
                                 
                                    ρ
                                 
                                 
                                    ′
                                 
                              
                              ∈
                              
                                 
                                    S
                                 
                                 
                                    ′
                                 
                              
                           
                         to the shape S with surface area 
                           
                              |
                              S
                              |
                           
                         we obtain
                           
                              (9)
                              
                                 
                                    
                                       D
                                    
                                    
                                       ASD
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      ∗
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    ∫
                                    
                                       
                                          
                                             ρ
                                          
                                          
                                             ∗
                                          
                                       
                                       ∈
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                                 d
                                 
                                    
                                       
                                          
                                             
                                                ρ
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 d
                                 
                                    
                                       S
                                    
                                    
                                       ∗
                                    
                                 
                                 +
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    ∫
                                    
                                       ρ
                                       ∈
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 d
                                 
                                    
                                       
                                          ρ
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                       
                                    
                                 
                                 d
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (10)
                              
                                 
                                    
                                       D
                                    
                                    
                                       RMSD
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            ∗
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          ∫
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ∗
                                                
                                             
                                             ∈
                                             
                                                
                                                   S
                                                
                                                
                                                   ∗
                                                
                                             
                                          
                                       
                                       d
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ρ
                                                      
                                                      
                                                         ∗
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             2
                                          
                                       
                                       d
                                       
                                          
                                             S
                                          
                                          
                                             ∗
                                          
                                       
                                       +
                                       
                                          
                                             1
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          ∫
                                          
                                             ρ
                                             ∈
                                             
                                                
                                                   S
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       d
                                       
                                          
                                             
                                                
                                                   ρ
                                                   ,
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         ∗
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             2
                                          
                                       
                                       d
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (11)
                              
                                 
                                    
                                       D
                                    
                                    
                                       HD
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                S
                                             
                                             
                                                ∗
                                             
                                          
                                          ,
                                          
                                             
                                                S
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    max
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   max
                                                
                                                
                                                   
                                                      
                                                         ρ
                                                      
                                                      
                                                         ∗
                                                      
                                                   
                                                   ∈
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         ∗
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   d
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  ρ
                                                               
                                                               
                                                                  ∗
                                                               
                                                            
                                                            ,
                                                            
                                                               
                                                                  S
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                
                                                   max
                                                
                                                
                                                   ρ
                                                   ∈
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   d
                                                   
                                                      
                                                         
                                                            ρ
                                                            ,
                                                            
                                                               
                                                                  S
                                                               
                                                               
                                                                  ∗
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        The sensitivity for local shape differences increases from Eqs. (9)–(11): The Hausdorff distance (Eq. (11)) quantifies the maximum local distance while 
                           
                              
                                 
                                    D
                                 
                                 
                                    ASD
                                 
                              
                           
                         is appropriate for measuring global differences. The latter is also true for the root mean square distance (Eq. (10)), which is however more sensitive to local differences since outliers are weighted stronger and therefore especially suited for quantifying shape differences [63]. In practice, these continuous metrics are evaluated using Monte Carlo integration, whereas we sample each shape with a sufficiently large number of sampling points which are drawn uniformly at random from the shape surface following [64].

In order to evaluate Eqs. (5)–(7) by means of Eqs. (8)–(11) we use 
                           
                              
                                 
                                    S
                                 
                                 
                                    ∗
                                 
                              
                              ≔
                              
                                 
                                    S
                                 
                                 
                                    k
                                 
                                 
                                    ∗
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             m
                                          
                                       
                                    
                                 
                              
                           
                         in case (8)–(11) are inserted into Eqs. (5) and (7) and 
                           
                              
                                 
                                    S
                                 
                                 
                                    ∗
                                 
                              
                              ≔
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                                 
                                    ∗
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             m
                                          
                                       
                                    
                                 
                              
                           
                         if inserted into Eq. (6), respectively.

The standard evaluation methodology (Section 4.1) used with appropriate metrics (Section 4.2) allows us to compare and rank different shape models. While the quantitative numbers can give a hint which of the model should be preferred, it does not directly answer which benefit can be expected in a real application. We are particularly interested in the influence of correspondence on segmentation quality, which is a frequent application of SSMs [3]. While one could estimate the influence by segmenting the training scans, the results of such an evaluation would be affected by several additional factors introduced by the image information. For example, abnormal image appearance caused by tumors or image artifacts is likely to have a large effect on the segmentation quality, thus correspondence should be evaluated without the presence of these factors.

Instead of segmenting the original scans, we therefore propose to segment the corresponding expert segmentations, that is binary images, using the Active Shape Model (ASM) [1]. For each expert segmentation, we manually place the mean shape of the Distmin model (Section 3.1), i.e. the SSM whose correspondence constitute the starting point of any correspondence optimization in this work, onto the structure. Subsequently, we apply the found initial transform to our SSMs with optimized correspondence (Section 3.2) and adapt the shape model using the standard ASM. We use a fixed number of 50 iterations, because we observed that if we use more iterations, the segmentation results only fluctuate slightly, but do not improve significantly anymore. As image features, we sample linear profiles of five millimeter length for each landmark. The profiles are oriented in normal direction, and point from inside to outside. Assuming that we sample values between 0 (background) and 1 (object), we assess the costs of a profile 
                           
                              
                                 
                                    g
                                 
                                 
                                    →
                                 
                              
                           
                         using the function
                           
                              (12)
                              
                                 f
                                 (
                                 
                                    
                                       g
                                    
                                    
                                       →
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   g
                                                
                                                
                                                   →
                                                
                                             
                                             -
                                             
                                                
                                                   
                                                      
                                                         g
                                                      
                                                      
                                                         →
                                                      
                                                   
                                                
                                                
                                                   ref
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          →
                                       
                                    
                                 
                                 
                                    ref
                                 
                              
                              =
                              
                                 
                                    
                                       1
                                       ,
                                       1
                                       ,
                                       
                                          
                                             1
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       0
                                       ,
                                       0
                                    
                                 
                              
                           
                         is the appearance vector of an image feature we expect at the boundary. Since the intensity values are sampled from the images using linear interpolation, values between 0 and 1 are likely to occur at the object boundary, which is accounted for by the reference profile. We reduce the influence of the manual initialization by repeating the segmentation for each image with slightly varied initializations, and averaging the results. At this, the initialization is modified by translating the model in x-, y- and z-direction and varying its scale. We use three different values for each of the four parameters that modify the initialization, such that, for each model, in total 81 different tests were performed per image.

The prescribed experiments test the generalization ability of the shape model in its application to image segmentation: It shows, which segmentation accuracy can be obtained with a shape model in case an optimal appearance model would be available. This can either be done in a leave-one-out manner similar to the generalization ability proposed by Davies (Eq. (6)), but also to segment completely unseen shapes that have not been considered during correspondence optimization. While this distinction is meaningless for pairwise correspondence methods, it is not for groupwise optimized correspondence, where non-biased leave-one-out tests are not directly possible, as discussed in Section 4.1. Fig. 3 gives an example where the relative performance of models is in fact different in leave-one-out tests compared to tests on unseen data.

While it is undeniably reasonable to test the model specificity by randomly drawing shape samples from the assumed probability density function (pdf) (cf. Eq. (5)), a specific model should also withstand misleading features that are independent from this very pdf. Hence, a specific model should additionally be able to provide robust segmentation results even in the presence of noise, low contrast between neighboring organs, or pathologies. We test the specificity of an SSM by repeating the test to ground truth images with additional noise. These noisy images are obtained by flipping individual voxels of each expert segmentation with a certain probability 
                           
                              
                                 
                                    p
                                 
                                 
                                    flip
                                 
                              
                           
                        . By this means, we can also study the behavior of models with different levels of noise, whereas the segmentation accuracy decreases with increasing flip probability (Fig. 4). Note that 
                           
                              
                                 
                                    p
                                 
                                 
                                    flip
                                 
                              
                              =
                              0.5
                           
                         corresponds to a binary image where each voxel value was drawn uniformly at random. An essential difference to the specificity measure of Davies (Eq. (5)) is that randomly generated shapes are not drawn from the same (Gaussian) distribution that was assumed during the previous modeling stage (Section 2.1) but instead is completely independent thereof.

As discussed before (Section 3.2), correspondence optimization involves purposeful manipulation of the initial parameterizations. However, the question arises to what extent these manipulations are reasonable and when must they be classified as “artifacts”. In this context it should be noted that the objectives in Eqs. (2)–(4) are evidently not regularized in any explicit way but only implicitly through the employed re-parameterization scheme (cf. Section 3.2).

Since our optimization starts from a set of shape parameterizations that are quasi distortion-free [25] (cf. Section 3.1), an obvious way for quantifying distortions that may be introduced during the correspondence optimization is to measure the area distortion of the spherical parameterization before and after optimization. We denote by 
                           
                              T
                              =
                              
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             
                                                
                                                   1
                                                
                                             
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             T
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         the set of triangular faces connecting the vertices 
                           
                              V
                              =
                              {
                              
                                 
                                    v
                                 
                                 
                                    
                                       
                                          ι
                                       
                                    
                                 
                              
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                              ;
                              
                              ι
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    v
                                 
                              
                              }
                           
                         of the mesh 
                           
                              
                                 
                                    M
                                 
                                 
                                    S
                                 
                              
                           
                        , which represents the shape S. Moreover, 
                           
                              
                                 
                                    P
                                 
                                 
                                    S
                                 
                              
                           
                         denotes the mesh of the spherical parameterization of S with vertices 
                           
                              
                                 
                                    V
                                 
                                 
                                    ∼
                                 
                              
                              =
                              {
                              
                                 
                                    ω
                                 
                                 
                                    -
                                    1
                                 
                              
                              (
                              
                                 
                                    v
                                 
                                 
                                    
                                       
                                          ι
                                       
                                    
                                 
                              
                              )
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                              ;
                              
                              |
                              |
                              
                                 
                                    ω
                                 
                                 
                                    -
                                    1
                                 
                              
                              (
                              
                                 
                                    v
                                 
                                 
                                    
                                       
                                          ι
                                       
                                    
                                 
                              
                              )
                              |
                              
                                 
                                    |
                                 
                                 
                                    2
                                 
                              
                              =
                              1
                              ,
                              ι
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    n
                                 
                                 
                                    v
                                 
                              
                              }
                           
                         and same connectivity 
                           
                              T
                           
                        . Then, the area distortion of 
                           
                              
                                 
                                    P
                                 
                                 
                                    S
                                 
                              
                           
                         w.r.t. 
                           
                              
                                 
                                    M
                                 
                                 
                                    S
                                 
                              
                           
                         can be calculated as
                           
                              (13)
                              
                                 A
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                n
                                             
                                             
                                                T
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  T
                                                               
                                                               
                                                                  
                                                                     
                                                                        M
                                                                     
                                                                     
                                                                        S
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        k
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  M
                                                               
                                                               
                                                                  S
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             -
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  T
                                                               
                                                               
                                                                  
                                                                     
                                                                        P
                                                                     
                                                                     
                                                                        S
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        k
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  P
                                                               
                                                               
                                                                  S
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             
                                                
                                                   M
                                                
                                                
                                                   S
                                                
                                             
                                          
                                          
                                             
                                                
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             
                                                
                                                   P
                                                
                                                
                                                   S
                                                
                                             
                                          
                                          
                                             
                                                
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         are the area of the k-th triangle of 
                           
                              
                                 
                                    M
                                 
                                 
                                    S
                                 
                              
                           
                         and 
                           
                              
                                 
                                    P
                                 
                                 
                                    S
                                 
                              
                           
                        , respectively. 
                           
                              
                                 
                                    
                                       
                                          
                                             M
                                          
                                          
                                             S
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 
                                    
                                       
                                          
                                             P
                                          
                                          
                                             S
                                          
                                       
                                    
                                 
                              
                           
                         are the surface area of the shape mesh and of its spherical parameterization, respectively.

In order to get a more intuitive impression in how far a possibly large area distortion influences the actual shape vectors that are obtained by remeshing the shape parameterizations with a fixed number of landmarks 
                           
                              
                                 
                                    n
                                 
                                 
                                    p
                                 
                              
                           
                         (cf. Section 2.2), we also measure the deviation of the shape vectors 
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       ∈
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                         from the original shapes 
                           
                              
                                 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                       ∈
                                       X
                                       ⊂
                                       
                                          
                                             R
                                          
                                          
                                             3
                                          
                                       
                                       :
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          
                                             n
                                          
                                          
                                             s
                                          
                                       
                                    
                                 
                              
                           
                         using Eqs. (9)–(11).

We built SSMs for four different structures/organs that are of medical relevance (cf. Table 2
                        ). All of them originate from clinical imaging modalities and have been either segmented manually by expert observers, or, in case of the left heart ventricle, semi-automatically [65]. In the first place, the segmented volume data were resampled to isotropic voxel size and smoothed using a Gaussian kernel to remove aliasing artifacts. From these preprocessed binary images, surface meshes were extracted and moderately smoothed [66] to obtain staircase artifact free shape representations with well-shaped triangles and regularly distributed mesh vertices. We used the following publicly available data for SSM construction: Hippocampus dataset of the SPHARM-PDM UNC Toolbox (http://www.nitrc.org/projects/spharm-pdm/), liver dataset from the MICCAI liver-segmentation challenge [63] (http://sliver07.org), and the data of the Internet Brain Segmentation Repository (IBSR) (http://www.nitrc.org/projects/ibsr) to generate the striatum region. Additionally, we used the liver expert segmentations of the publicly available 3D-IRCADb-01 data base (http://www.ircad.fr/softwares/3Dircadb/3Dircadb1/) for testing the liver SSMs on completely unseen data. In order to evaluate the hippocampus SSMs on completely unseen data we extracted this very region from the brain segmentations of the IBSR database that were also used for generating the striatum SSMs.

The SSM construction involved correspondence optimization for all four objects under variation of cost function, re-parameterization, multi-resolution, and pose (Section 3.2). Each item was evaluated independently in order to avoid that the result are biased by their mutual influence. Nevertheless, the number of figures and plots that we obtained by evaluating each SSM w.r.t. to a couple of different quality measures (Sections 4.1 and 4.3) and metrics (Section 4.2) is far too large to be presented in its entirety, which is the reason why we restricted the plots included in this paper as follows:
                           
                              •
                              SSMs were evaluated w.r.t. all four different optimization strategies (Section 3.2) for the two arguably most challenging objects striatum and liver except for cost function which was evaluated considering all four objects.

Correspondence evaluation includes specificity (Eq. (5)) and leave-one-out generalization ability (Eq. (6)), the two most renowned and most frequently employed measures in this context.

Segmentation specificity tests using 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             flip
                                          
                                       
                                       =
                                       0.1
                                    
                                  and 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             flip
                                          
                                       
                                       =
                                       0.2
                                    
                                  were omitted since these arguably do not add additional information compared to the generalization tests (cf. Fig. 4). Moreover, using 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             flip
                                          
                                       
                                       =
                                       0.4
                                    
                                  results in such noisy images that the model mostly has to simply guess, which is arguably not the effect we want to evaluate. Therefore, we restricted ourselves to 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             flip
                                          
                                       
                                       =
                                       0.3
                                    
                                  for the segmentation specificity tests shown in this work.

The metric 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             RMSD
                                          
                                       
                                    
                                  (Eq. (10)) turned out to provide the information needed in order to adequately account for both, global and local shape differences. Where appropriate, we point out differences that were observed for the other metrics.

Note, however, that this restriction was solely made for clarity reasons whereas our actual experiments were conducted w.r.t. all quality measures and metrics in Sections 4.1, 4.3, and 4.2, respectively.

@&#RESULTS@&#

Results of the previously described experiments are shown in Figs. 5–14
                     
                     
                     
                     
                     
                     
                     
                     
                     
                      and Table 3
                     . The most important observations that can be made are enumerated in the following Sections 5.1–5.4 and will be discussed in Section 6.


                        
                           
                              C.1.
                              In the correspondence evaluation we observe that Thodberg∗/Detcov show the best/worst generalization ability for the liver and the striatum (Fig. 5(e) and (g)). On the other hand, Thodberg∗ performs worst on the hippocampus (Fig. 5(c)). We do not observe meaningful differences between the different cost functions for the left ventricle (Fig. 5(a)). We also note that in terms of the Hausdorff distance Thodberg∗ performs worst for all data set.

In the segmentation evaluation the generalization ability of Thodberg∗ is worst in three of four cases (Fig. 5(b), (d), and (h)). The three other cost functions perform very similar except for the liver, where Detcov drops behind all others (Fig. 5(f)).

Similarly, Thodberg∗ performs significantly worse than MDL, DetCov, and DetCov∗ – which again show very similar results – in case completely unseen data are segmented (Fig. 7).

The specificity of Thodberg∗/DetCov is best/worst in three out of four cases in the correspondence evaluation (Fig. 6(a), (c), and (g)).

In the segmentation evaluation the specificity of Thodberg∗ is worse than DetCov∗, DetCov, and MDL on all data set. However, the ranking of the three latter is not very consistent (Fig. 6(b), (d), (f), and (h)).

Moreover, DetCov∗ shows in almost all tests very similar results as MDL (w.r.t. both, the absolute error measures as well as their ranking w.r.t. DetCov and Thodberg∗), at which MDL performs slightly better in a majority of cases.

The comparison of DetCov and DetCov∗ indicates that the latter seems to have advantages in the correspondence evaluation (Fig. 5/6(a), (c), (e), and (g)) but DetCov outperforms DetCov∗ in many segmentation evaluation tests (Fig. 5/6(b), (d), (f), and (h)).


                        
                           
                              P.1
                              Optimizing the pose parameters explicitly w.r.t. a model based cost function does not make meaningful differences (Fig. 8), independent from the evaluation method (i.e. correspondence or segmentation) as well as from the quality measure (i.e. generalization ability or specificity).


                        
                           
                              M.1.
                              For the liver, MR optimization shows slightly better generalization ability and specificity over SR optimization with respect to 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             RMS
                                          
                                       
                                    
                                  (Figs. 9(a), (b) and 10)(a), (b)) and 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             VOE
                                          
                                       
                                    
                                 . The advantage of MR optimization becomes more pronounced the more modes are used.

In contrast to M.1, the MR model and the SR model perform equally well on unseen liver data (Fig. 9(c)).

For the striatum, SR optimization produces models with marginally better generalization ability than MR optimization with respect to the 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             RMS
                                          
                                       
                                    
                                  metric (Figs. 9(d) and (e)). Moreover, it is noticeable that SR optimization has significantly smaller maximum errors (
                                    
                                       
                                          
                                             D
                                          
                                          
                                             HD
                                          
                                       
                                    
                                 ) in the generalization tests.

The results for specificity are contradictory: The segmentation evaluation results show slight advantages of the SR models (Fig. 10(d)), while the standard evaluation procedure shows slight advantages of the MR models (Fig. 10(c)). In contrast to the generalization tests, no large difference with respect to the 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             HD
                                          
                                       
                                    
                                  are observable.

Multiresolution optimization tends to increase the distortions on the parameterizations (Fig. 14(a)) and leads to larger differences between remeshes and input shapes (Fig. 14(b)).


                        
                           
                              R.1.
                              For both generalization ability and specificity, models computed with CPS re-parameterization have a smaller 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             RMS
                                          
                                       
                                    
                                  (Figs. 11(a), (b), (d), (e) and 12(a)–(d)) and 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             VOE
                                          
                                       
                                    
                                  than those computed with Gaussian warps re-parameterization. The difference is relatively small for the leading eigenmodes, but tends to become larger with increasing number of modes. At the same time, CPS-based models have a larger 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             HD
                                          
                                       
                                    
                                 . Here, the distance to the models computed with Gausswarp re-parameterization decreases with increasing number of modes.

On unseen liver data, models generated with Gausswarp re-parameterization have a significantly smaller 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             RMS
                                          
                                       
                                    
                                  (Fig. 11(c)) and smaller 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             HD
                                          
                                       
                                    
                                  than those generated with CPS re-parameterization. However, they perform equally well w.r.t. 
                                    
                                       
                                          
                                             D
                                          
                                          
                                             VOE
                                          
                                       
                                    
                                 .

CPS re-parameterization leads to larger distortions on the parameterizations than Gaussian warps (Fig. 14(a)). Similarly, it increases the difference of the shape vectors to the input shapes (Fig. 14(b)).

@&#DISCUSSION@&#

A very important general observation of our experimental results is that groupwise optimization actually improves the model quality compared to pairwise methods like SPHARM or Distmin, even if we start with parameterizations with good initial correspondence – as Distmin arguably does (Figs. 3 and 4(b) vs. (c)). It should be noted that previous studies that reported the same observation used evaluation metrics which do not account for a possible loss of detail introduced during optimization. The results of the segmentation evaluation indicates that one can indeed expect better segmentation accuracy in practical applications with SSMs constructed from groupwise optimized correspondence.

The segmentation evaluation proposed in this work does allow for quantifying the expectable influence of correspondence on the segmentation performance in practice. Moreover, and in contrast to the correspondence evaluation, it also allows for (i) benchmarking specificity without making assumptions about the distribution of the data and (ii) easily evaluating the model on unseen data which have not been used for model construction.

One may argue that because our method works directly on expert segmentations, the evaluation results may be hampered by inter- or intraobserver variability of the experts. While we cannot exclude this influence, we stress that this problem is not a particular problem of our methodology. In fact, the data used in most studies originates from expert segmentations, and thus the results of these studies may be influenced by inter- and intraobserver variability as well. We recommend to remedy this problem by using binary images that are combined from several segmentations of the same subject. For example, the liver data from the MICCAI challenge we use has been constructed that way [63]. However, because the availability of such data limited, we use in most experiments of this paper segmentations of a single observer.

Another possible point of criticism is that the results of our evaluation technique are influenced by several external factors, such as for example the search strategy of the ASM. However, alternative approaches such as k-fold cross validation is virtually impractical because it requires time consuming correspondence optimization for k different subsets of the shapes. Moreover, evaluating correspondence by using a shape to which the actual correspondence is unknown will always require some sort of registration and thus will be influenced by the used registration algorithm, which is in our case the ASM. Because the ASM is by far the most frequently used algorithm for SSM-based image segmentation (e.g. [3]), the algorithm is also the natural choice for evaluating the correspondences. At this we observe indeed differences between leave-one-out tests and tests on the basis of unseen data. Specifically, the difference between the quality of two models tends to be smaller (Fig. 3(b) vs. (c) and Fig. 9(b) vs. (c)) or may even be reversed (Fig. 11(b) vs. (c)) on unseen data that did not influence the correspondence. An explanation for this could be that the optimization can overfit the correspondence to the available data, such that the leave-one-out experiments on the training data are slightly biased. While this effect is not present in the Distmin or SPHARM correspondence (Fig. 3), it may increase with larger re-parameterizations as these occur in case multi-resolution (Fig. 9) and/or clamped plate splines (Fig. 11) are used, something which is also indicated by observations M.2 and R.2.

As regards the comparison of the absolute values of correspondence and segmentation evaluation, investigation of the respective generalization ability reveals that these are quite similar (Figs. 3(a) vs. (b), 5(a), (c), (e), (g) vs. (b), (d), (f), (h), 8(a) vs. (b), 9(a), (d) vs. (b), (e) and Figs. 11(a), (d) vs. (b), (e)). The reason why the values of the segmentation evaluation are in general slightly worse may be attributed to the limited search space along the one dimensional intensity profiles, whereas such a limitation does not exist for the correspondence evaluation. Using a more flexible search algorithm than the ASM (see e.g. [3] for a discussion of several approaches) more accurate segmentation results than those presented in this work might be achieved. However, this would amount to benchmarking different segmentation algorithms while the focus of the present work is the evaluation of methods for establishing correspondence.

In this regard, our experiments indicate that the building blocks of the correspondence optimization pipeline should be chosen with care, because they greatly influence the performance of the SSM. Concerning the use of different cost functions, we observe that DetCov, DetCov* and MDL perform quite similar (observations, C.2, C.4–C.7) whereas the results of Thodberg* are in many tests different. The reason why Thodberg* shows different behavior may be attributed to the fact that Thodberg* combines both, the trace and the determinant of the covariance matrix of the shape vectors, whereas the other functions are mainly dependent on the covariance matrix determinant [59]. At first glance it seems that Thodberg* performs better in the correspondence evaluation (observations C.1, C.4), but contrary (i.e. Thodberg* performs worse) in the segmentation evaluation (observations C.2, C.3, C.5). However, we also note in our experiments that Thodberg* shows for all data set the worst generalization ability in the correspondence evaluation in terms of the Hausdorff distance (observation C.1). Such large local errors indicate undersampling of some regions as can for instance observed in Fig. 13. Naturally, such an undersampling has a more severe effect on the segmentation evaluation due to the limited search space along the one dimensional intensity profiles. Here, the chance to miss important features increases considerably in case the distance between neighbor landmarks and hence between the one dimensional intensity profiles increases. The correspondence evaluation on the other hand does not consider this particular aspect of the ASM, which indicates that the proposed segmentation evaluation can indeed help to get a better understanding of the influence of the correspondence on the expectable segmentation performance.

The ranking of DetCov and DetCov* seem to depend heavily on the data set and the criterion, that is specificity and generalization ability. Each of these functions dominates the other in one experiment, but is also dominated by the other in another experiment. Interestingly, this cannot be said for the MDL cost function, which indicates the superior robustness of this function (see also observation C.6) and indicates that it finds indeed the best compromise between specificity and generalization ability. In fact, MDL is the only function, which does not depend on a free parameter. The different behavior of DetCov and DetCov* shows that such a free parameter has indeed a significant influence on the model quality and must be tailored to the application.

Concerning the explicit optimization of pose parameters our tests show that this does not improve the model correspondence or segmentation quality significantly (observation P.1). This is in accordance to previous studies which showed that shape alignment by minimizing the model’s description length has merits compared to Procrustes alignment in terms of a slightly smaller cost function value [31] or for synthetic test data [67], but does hardly make any difference in practice [67].

In our tests, multi-resolution (MR) optimization does not significantly improve the model quality in all cases. This is surprising on the first glance, as one intuitively expects a larger search space when using MR optimization, which is for instance reflected by observation M.1. Indeed, MR optimization achieves in our experiments smaller objective function values than single-resolution (SR) optimization (Table 3). However, a smaller cost function value does not imply per se better generalization ability and specificity (observations M.3 and M.4 and e.g. Fig. 10(d)). Additionally, MR optimization increases the distortions in the parameterizations (observation M.5, cf. Fig. 13(g) vs. (i)), which lead to poorer shape reconstructions of the input shapes caused by undersampling of some regions (Fig. 13(c) vs. (e)). In our tests MR optimization turned out to be useful for the liver but does not pay off for the striatum. A possible explanation is that the MR approach can help to improve the positioning of the landmarks on the highly variable and pronounced local bulges of the liver. The striatum on the other hand, though showing a rather complex shape in terms of the construction of a spherical parameterization (Section 3.1), does not show as many local bulges as the liver. Therefore, a single resolution suffices to adequately position the landmarks on the striatum.

As regards different reparameterization schemes, our tests indicate that CPS tends to allow for larger re-parameterizations compared to Gausswarp (observation R.1, see also Fig. 13(g) vs. (h) and Fig. 13(i) vs. (j)), which is also indicated by a considerably smaller cost function value (Table 3). On the one hand, this can improve the model quality, which explains a smaller volumetric overlap error. On the other hand, it also introduces more artifacts, as the distortions in the parameterizations increases (observation R.3). This in turn, leads to sampling artifacts in the shape vectors and thus to an increase of the Hausdorff distance. For instance, the latter is especially large for the generalization ability of the correspondence evaluation in case CPS reparameterization is used for the striatum. Similar to the observations we made before in the context of the Thodberg∗ objective, undersampling of certain regions typically accompanies these large local errors. This makes it more likely that important features are not hit by the ASM search along one dimensional intensity profiles. Thus the performance of the CPS reparameterization decreases (Fig. 11(e)). On the other hand it performs superior in the correspondence evaluation (Fig. 11(d)) where this limitation of the search space does not exist.

The observation we made for MR optimization and CPS re-parameterization reveal a practical problem of the correspondence optimization that has not been adequately addressed by now, namely that the objective function does not regularize distortions in the parameter space domain. In the theoretical derivation of the MDL the problem of distortions is not present, as one integrates over the shape surfaces thereby assuming that each point on the surface influences the objective value. However, every practical implementation must approximate this integral numerically and thus, in essence, requires sampling with a finite number of points. Because MDL and related objective function try to simplify the model complexity, they tend to move sampling points away from difficult details of the shape. Thus, one can often observe a clustering of sampling points in geometrically simple regions of the shapes [31]. In our implementation, we approximated the integral of the MDL function using the integration scheme of Davies et al. [31] which allegedly avoids this clustering. However, our observations show that this is not true for all data set and optimization strategies. An alternative and probably more robust solution is the approach of Heimann et al. [41]: During optimization, they adapt the sampling grid from time to the distortions in the parameterization and thus avoid undersampling. However, the latter strategy may lead to discontinuities in the optimization. In our opinion the most rigorous approach is therefore to use a fixed sampling pattern, but to add a regularization term in the objective function that explicitly penalizes distortions.

In this study, we evaluated various aspects of the correspondence optimization pipeline by experimenting with different cost functions, re-parameterization functions and optimization strategies. For evaluating the quality of the SSM, we used the standard measures specificity and generalization ability with shape based distance functions. Additionally, we proposed a new technique for evaluating the quality of SSMs by simulating image segmentation with the active shape model. This evaluation technique relates correspondence with image segmentation by directly quantifying the influence of correspondence on the delineation accuracy of active shape models, something which is not possible with the standard correspondence evaluation.

Our evaluation shows that groupwise correspondence optimization improves specificity and generalization ability of SSMs. This observation could also be made with our new evaluation metric, which indicates that, compared to pairwise approaches, groupwise correspondence optimization enhances in fact the segmentation accuracy of SSM-based segmentation algorithms. Based on our evaluation results, we recommend to use the MDL function as objective function due to its superior robustness and independence of free parameters. We also recommend to use multi-resolution optimization and CPS re-parameterization, because our observations indicate that these strategies allow for larger re-parameterizations, such that poor local optima can be avoided more easily. We also observed that optimization may lead to large distortions on the parameterizations or the sampling grid. These distortions may cause that important details of training shapes are cut away, such that they can no longer be captured by the SSM. Moreover, the proposed segmentation evaluation revealed that the undersampling typically accompanying such distortions is even more severe for the actual segmentation application since the risk that the ASM misses important features of the object to be segmented increases. Therefore, an important task for future work is to explicitly incorporate sampling accuracy as a regularization term into the optimization, such that high quality reconstruction of the input shapes can be guaranteed.

This work focused on a particular method (groupwise optimization) for a particular problem (the correspondence problem) of a particular shape representation (landmark-based shape models). An interesting direction for future work might be an evaluation study that considers alternative shape representations, modeling approaches or search algorithms. By means of the proposed segmentation evaluation technique it shall then be possible to deduce the relative performance of the different approaches in an actual image segmentation application.

@&#ACKNOWLEDGMENTS@&#

Hippocampus data was provided by M. Styner and co-workers, UNC Neuro Image Analysis Laboratory, as part of the public UNC Shape Tool distribution. Original data acquisition was funded by the Stanley Foundation. Manual segmentations of MR brain data set provided by the Center for Morphometric Analysis at Massachusetts General Hospital were used to generate striatum and hippocampus data.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Measuring the impact of translation on the accuracy and fluency of vocabulary acquisition of English

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We study how translation affects ESL vocabulary learning.


                        
                        
                           
                           A reading tutor using language technologies measures each student's learning.


                        
                        
                           
                           Use of translation increases the retrieval time of L2 lexical items.


                        
                        
                           
                           Excessive use of translation decreases long-term retention of L2 lexical items.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Reading tutor

Vocabulary acquisition

Translation

ESOL

@&#ABSTRACT@&#


               
               
                  This article assesses the impact of translation on the acquisition of vocabulary for higher-intermediate level students of English for Speakers of Other Languages (ESOL). The use of translation is a relevant issue in the research of Second Language (L2) acquisition and different authors provide arguments on both sides of the issue. Language technologies serve this issue in both the usability of automatic translation and the automatic detection of lexical phenomena. This paper will explore translation as it affects the acquisition of new words in context when students are given real texts retrieved from the Internet in a web-based interface. The students can instantly obtain the dictionary definition of a word and its translation to their native language. This platform can accurately measure how much each student relies on translation and compare this to their accuracy and fluency on a lexical retrieval task using words seen in the texts. Results show that abundant use of translation may increase accuracy in the short term, but in the longer term, it negatively affects accuracy and possibly fluency. However, students who use translation in moderation seem to benefit the most in this lexical task. This paper provides a focused and precise way to measure the relevant variables for each individual student, and new findings that contribute to our understanding of the impact of the use of translation in language learning.
               
            

@&#INTRODUCTION@&#

Many language technologies are useful for language learning. Synthesizing written words, generating pertinent assessment questions and disambiguating meanings are only some of the contributions that language technologies can bring to this domain. Another contribution could be the automatic translation of parts of texts. Yet, the use of translation is a subject of controversy in the language acquisition realm and in the general language learning area. Translation is usually seen as scaffolding that builds the new language around the native language of the student. It aids in the initial acquisition of the new language and Sweet (1964), Sheen (1996) and Cook (2010) have shown that it is also helpful when there is a need to explain subtle details. However, translation, seen as a scaffold, has to be removed or avoided in order for the student to become fluent in the new language according to Krashen (1981), Stieglitz (1955) and Stern (1983). A major limitation to our understanding of how translation actually affects the students production and perception is the difficulty of accurately measuring how much an individual student relies on translation and how much their fluency in the new language is affected by it. Language technologies and intelligent tutoring can provide new ways to obtain these measurements. Intelligent tutors can be used to store all the actions of a student during a learning event and furnish precise measurements of accuracy and response time in a variety of evaluation tasks.

The use of the student's First Language (L1) in the Second Language (L2) learning classroom, and specifically in the English for Speakers of Other Languages (ESOL) classroom, has been historically avoided since the Direct Method became mainstream at the end of the 19th century (Cook, 2001). The main reason for this avoidance of the student's L1 is the comparison of L2 acquisition with L1 acquisition. Since the L1 is successfully acquired without the scaffolding of a previous language, it was assumed that the L2 should follow the same process. Thus authors like Asher (1986) proposed to avoid all use of the L1 in the classroom. Other reasons to avoid using the L1 include the fact that sometimes teachers might not speak the L1 of their students, and that there might usually be several students in the class with different L1s.

This view has been challenged. Studies by Levine (2003), Grace (1998) and Prince (1996) have argued that using the L1 actually reinforces learning of the L2, since it aids in the construction of the new language. Another reason to use the L1 in class is the student's lack of self-confidence when using the L2 alone due to the limitations that it imposes on them (Levine, 2003). Moreover, the introduction of intelligent tutors provides resources in the L1 of each student without teacher intervention. Off-line and on-line bilingual dictionaries, for example, are now totally accessible and easy to integrate into language learning tutors.

More specifically, the use of the L1 in L2 vocabulary acquisition has also elicited divergent opinions. Models of L2 lexical acquisition by Jiang (2000) and Kroll and Sunderman (2003) consider that the new L2 words are assimilated through an L1 lemma that is generalized and applied to concepts in the L2. Excessive use of the L1 is then believed to reduce the L2 fluency of the students and to fossilize errors. Context, dictionary definitions and examples of other sentences in which a word could be used are considered to be the most effective tools for teaching new words since students can assimilate the concept of the new word without any reliance in their L1. This implies that the use of such techniques can lead to better learning and improved fluency than the direct use of L1 translation would. Some research has challenged this claim, with results in Grace (1998) that show higher scores on vocabulary tests when translation is provided, both in the short-term and long-term use of the new words. Prince (1996) also claimed that the more proficient students benefit more from translation on short-term lexical recall tasks, since they can get rid of the L1 scaffolding more easily. More recently, Laufer and Girsai (2008) also showed that higher results were attained in incidental vocabulary acquisition using translation exercises and contrastive analysis.

The study of the use of translation in vocabulary acquisition has been hampered by the difficulty of determining how much each student uses translation. It is not feasible for teachers to keep track of the patterns of use of bilingual dictionaries and other resources that provide translation in a class with many students. Thus when students are allowed to consult these resources, there has been no controlled measure of how much they actually use them. Furthermore, while teachers can measure the accuracy of their students in assessment tasks they cannot precisely measure how much time it takes for each one of them to respond to a given question. This measure could be used to determine the student's speed of response, thus implying how quickly that student can access the lexical information and consequently how fluently they can use a given word. Although teachers have a rough estimate of the aggregate time spent on a test, they cannot measure the time taken for a specific question.

The use of Computer-Assisted Language Learning (CALL) tutors in vocabulary acquisition can provide useful interfaces where dictionaries, translation tools and other resources can be integrated into a reading activity. CALL tools can also be a very useful platform for language learning research. Horst et al. (2005) developed a corpus-based on-line collaboration tool to help in vocabulary acquisition. In this platform, the students could all work together and provide input to the tool database, showing solid results in facilitating deep processing of new vocabulary. Laufer and Hill (2000) performed a reading comprehension and vocabulary learning experiment with students in Israel and Hong Kong. In the students’ immediate post-test results they were shown to perform well when multiple options for understanding the vocabulary were provided (dictionary definition, translation or word lexeme). With the use of the logs of their reading comprehension tool the authors could reliably know which and how many help options a student requested.

A much wider review of existing tutors was performed by Abraham (2008) who did a meta-analysis of eleven studies of reading comprehension and vocabulary acquisition in CALL. All the eleven studies had experimental groups that were provided with glosses during reading sessions. Overall, there were clear effects in accuracy in immediate and delayed post-tests for providing the glosses during the readings.

Based on this previous knowledge, this article attempts to answer several research questions related to the use of translation in ESOL vocabulary acquisition. First is how intelligent tutors can provide a precise measure of the use of translation by ESOL students and of their accuracy and fluency in lexical tasks. The second is how accuracy and fluency in lexical tasks are affected by the use of translation. And the final question is how the amount of reliance on translation has an influence on each individual student's accuracy and fluency.

The structure of the paper is as follows: Section 2 will introduce the Reader-Specific Lexical Practice (REAP) reading tutor as a platform for vocabulary acquisition in English. Section 3 will present the experimental setup and methodology followed in our classroom studies. Section 4 will report the results of the studies. Finally, Section 5 will give a discussion of the results presented; and Section 6 will summarize the conclusions of this work.

The REAP project aims at providing appropriate curriculum for vocabulary acquisition in ESOL classes while serving as a platform for research studies (Brown and Eskenazi, 2005). REAP provides ESOL students with texts retrieved from the Internet according to their reading level and their preferences (Heilman et al., 2008) and helps them acquire new words from context (Juffs et al., 2006). REAP incorporates several features that help in the process of vocabulary acquisition like reading the definition of words from a dictionary, text-to-speech synthesis of words and translation of words to the student's native language.

REAP presents the reading prepared for the student in any web browser with the interface shown in Fig. 1
                     . The student can get a definition of a word: a pop-up window opens showing the definition and examples of use of that word and a button for hearing the pronunciation of the word. When a translation is requested, another pop-up window appears showing the translation. To provide the translation, students must provide their native language when registering into the system. Focus words, the words that the teacher has chosen for the students to learn, are highlighted in the text.

Since its initial deployment, REAP has shown that it can improve the acquisition of new vocabulary in ESOL students (Heilman et al., 2006). Features embedded in REAP have been validated in several experimental studies which showed the learning outcomes achieved by the students due to, for example, the use of definition ordering (Dela Rosa and Eskenazi, 2011) and text-to-speech synthesis (Dela Rosa et al., 2010). Motivational issues in the use of REAP have also been studied and a significant correlation of motivation and positive learning gains has been found (Heilman et al., 2007; Dela Rosa and Eskenazi, 2011).

The Cambridge Advanced Learners’ Dictionary (CALD) (Walter, 2005) is embedded in REAP and is used by the students to look up definitions of both focus words and other difficult words as they are encountered. At the same time, the students can listen to the pronunciation of the word with the Cepstral
                        1
                     
                     
                        1
                        
                           http://www.cepstral.com.
                      test-to-speech synthesizer. The translation (bilingual dictionary) of the words is provided by WordReference
                        2
                     
                     
                        2
                        
                           http://www.wordreference.com.
                      and the Bing Translator,
                        3
                     
                     
                        3
                        
                           http://www.microsofttranslator.com.
                      verified and embedded in REAP. REAP takes the request from the student, queries the translation engine and presents the results within the REAP interface. The definitions and translations of the words in all of the different L1s of the students can be manually verified off-line to make sure that the definition or a translated word corresponded with the specific context in which it appeared. If necessary, a change in the definition and/or the translation can be made to make it context-appropriate.

Two in-vivo classroom studies were carried out at the English Language Institute (ELI) of the University of Pittsburgh, the first one during the Fall semester of 2011 and the second one during the Spring semester of 2012. We will refer to them as Fall 2011 and Spring 2012 respectively. An interval of 3 months elapsed between the ending of Fall 2011 and the beginning of Spring 2012. The ELI students are adult learners of English, typically college students. They have intensive courses in Grammar, Listening, Reading, Speaking and Writing at different levels. The two studies described herein were carried out in the Level 5 Reading courses, which is the topmost ELI level. The students in Level 5 are described as “higher-intermediate or advanced learners of English”. All the students who enter in the ELI take a test for Level placement to ensure the students are properly matched to their Level and the groups are homogeneous. These placement tests were comprehensive and covered reading, writing, speaking and listening through cloze questions and writing assignments. In both studies, the students used the REAP tutor with the goal of improving vocabulary acquisition.

The first study initially involved 43 students taking the ELI Level 5 Reading course. Eventually 27 of them completed the study. The other 16 students withdrew from the course for various reasons such as medical leaves or withdrawal from the ELI due to relocation to another university or city. The results in this paper refer to the 27 students who completed the study. 25 of the students were native speakers of Arabic, 1 spoke Spanish and 1 spoke Turkish.

The second study initially involved 40 students in the Level 5 Reading course. 26 students finished this study: 22 of them were native Arabic speakers, 2 were Mandarin Chinese speakers and 2 were Korean speakers. There were five students that took the Level 5 Reading class during both semesters and participated in both the Fall 2011 and Spring 2012 studies.

@&#PROCEDURE@&#

In both studies, the setups were similar. In the first session, the students had a pre-test which measured their knowledge of a set of focus words in a lexical retrieval task. The lexical retrieval task consisted of multiple-choice cloze questions, where the target word was removed from a full, meaningful sentence. The student had to select it from 4 possible options (the target word and 3 distractors). There were 2 of these questions for each focus word in the pre-test. The students were not allowed to see their pre-test results. Fig. 2
                         shows an example of a test question where the correct answer is the focus word ‘vital’. Post-reading and post-test questions had the same form as the pre-test and involved completely different sentences. The ELI teachers were present during all the tests to avoid the use by the students of dictionaries, books or the Internet to look up the correct answers.

In the following sessions, students completed a given number of readings using the REAP interface. The readings were manually selected according to the level of reading proficiency of the students as described in Heilman et al. (2008) and were related to the topics that the ELI teachers were discussing during the course. Each reading had approximately 400–500 words and contained some of the focus words that the teacher had selected for the study. After each reading, the students completed a post-reading test where they answered 2 previously unseen cloze questions for each focus word they had encountered in the reading. The students were shown their results along with the correct answers to the cloze questions at the end of each post-reading test. In the last session of the study, the students completed a post-test containing 2 new unseen questions for each focus word.

The design of the study is shown in Fig. 3
                        . The pre-test was designed to measure the ability of the students to properly use the focus word in the lexical retrieval task before the readings. Post-reading questions were designed to measure their ability to use those words immediately after being exposed to them in the reading. Finally, the post-test questions measured their ability to retain the use of the words over the long term after the readings were finished.

The first study took place for 8 weeks in the Fall of 2011. Sessions were 1h per week. The students had the pre-test, 6 weekly reading sessions and the post-test that took place the week after the final reading activity. Each reading session had one reading prepared for the students with 4 focus words, for a total of 24 focus words. The second study took place for 6 weeks in the Spring of 2012. The shorter duration of this study was due to ELI internal scheduling. This study consisted of the pre-test, 4 reading sessions and the post-test that also took place the week after the final reading activity. In this study, there were 2 readings per session for a total of 8 readings. With 3 focus words per reading, the total number of focus words was 24, the same as in Fall 2011.

The main difference in the setup of both studies was how the students accessed a translation. The REAP interface provides the students with the definition of a word, and/or its translation to the student's L1, within the reading. For the Fall 2011 study students had to type or copy and paste the word into a box at the bottom of the screen to get its translation. In the Spring 2012 study they could use a left mouseclick to get the translation. In both studies, the students could click (left mouseclick in Fall 2011 and right mouseclick in Spring 2012) to obtain the definition from CALD and to listen to text-to-speech synthesis of the word. For the studies presented in this paper, the automatic translation provided by REAP of the focus words was manually verified by native speakers prior to the reading tasks. This was done to verify that the translations were correct and that they fitted the context in which each word appeared in the text.

These studies were designed as in-vivo experiments, with a direct intervention into a classroom, instead of laboratory experiments, where two conditions can be evaluated by applying them separately on two different groups of participants. The constraints of in-vivo design required that all the participating students were presented the same condition. Since students could not avoid direct contact in the classroom they would have noticed the differences between conditions and this could have potentially modified their behavior, limiting the conclusions that could have been obtained from this setup.

Although REAP is able to automatically select suitable texts from the Internet, the texts that were used in this work were manually selected. There were two reasons for this: The first one was to match the topics covered in these texts to the topics covered by the ELI in the curriculum for the Level 5 Reading course that the students were attending. The second one was to ensure that the focus words appeared in the correct context and that no focus word appeared repeatedly in one or several texts.

48 focus words were used for the two studies, 24 in Fall 2011 and 24 in Spring 2012. These words were selected either from the Academic Word List in Coxhead (2000) or the Barron's GRE Word List in Geer (2011). These two lists are often used by the ELI teachers in the Reading classes. The lists of focus words are presented in Tables 1 and 2
                        
                        . Once the focus words were selected, they were provided to the teachers of the ELI, who were instructed not to use these words in any of the reading exercises they carried on with their classes. This way, the study made sure that the students were only learning these words through REAP.

The independent variables in the studies were the use that the students made of the REAP features (dictionary and translation). The use of dictionary definitions was measured as the total number of dictionary look-up requests made by each student divided by the total number of sessions. The use of translation was measured as the number of translation requests made by each student divided by the total number of sessions.

The dependent variables in our study were the accuracy of the students in the pre-test, post-reading and post-test assessment tasks; and the fluency of the students in the pre-test and post-test assessment tasks. The accuracy of each student at the pre-test, post-reading and post-test was calculated as the percentage of correct answers over the total number of questions in the test. The fluency was calculated as the latency in response time between the moment a question appeared on the screen and the moment the student clicked on the multiple choice answer. We used the median and not the mean of the response times since the mean was distorted by outliers produced by very long response durations for some few questions (possibly due to students being distracted and other uncontrolled situations). Again, this is the measure that we developed to reflect the rapidity of response, a possible indication of fluency as also considered in Gardner (1991).

We also defined comparative measures, such as gain and normalized gain in accuracy between two different assessment tasks. The gain is defined in Eq. (1) as the difference between the accuracy in the post-test (or post-reading practice) to the pre-test accuracy. The normalized accuracy in Eq. (2) is calculated differently depending on whether the gain was positive (increase in accuracy) or negative (decrease in accuracy).


                        
                           
                              (1)
                              
                                 Gain
                                 =
                                 
                                    Accuracy
                                    
                                       post
                                       -
                                       test
                                    
                                 
                                 −
                                 
                                    Accuracy
                                    
                                       pre
                                       -
                                       test
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    Gain
                                    ˆ
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      Gain
                                                      
                                                         100
                                                         −
                                                         
                                                            Accuracy
                                                            
                                                               pre
                                                               -
                                                               test
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      Accuracy
                                                      
                                                         post
                                                         -
                                                         test
                                                      
                                                   
                                                   >
                                                   
                                                      Accuracy
                                                      
                                                         pre
                                                         -
                                                         test
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      Gain
                                                      
                                                         
                                                            Accuracy
                                                            
                                                               pre
                                                               -
                                                               test
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      Accuracy
                                                      
                                                         pre
                                                         -
                                                         test
                                                      
                                                   
                                                   >
                                                   
                                                      Accuracy
                                                      
                                                         post
                                                         -
                                                         test
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

There were also measures for the change and normalized change of the median response time between two assessment tasks (for instance, from pre-test to post-test). The change in response time in Eq. (3) is the difference between the median response time in the post-test and the median response time in the pre-test. The normalized value in Eq. (4) is normalized differently depending whether the unnormalized change is positive or negative. A positive value in the change in median response time indicates that the student answered more rapidly in the post-test; while a negative value indicates that the student answered more slowly in the post-test.


                        
                           
                              (3)
                              
                                 Δ
                                 Time
                                 =
                                 
                                    Time
                                    
                                       pre
                                       -
                                       test
                                    
                                 
                                 −
                                 
                                    Time
                                    
                                       post
                                       -
                                       test
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    
                                       Δ
                                       Time
                                    
                                    ˆ
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         Δ
                                                         Time
                                                      
                                                      
                                                         
                                                            Time
                                                            
                                                               pre
                                                               -
                                                               test
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      Time
                                                      
                                                         pre
                                                         -
                                                         test
                                                      
                                                   
                                                   >
                                                   
                                                      Time
                                                      
                                                         post
                                                         -
                                                         test
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         Δ
                                                         Time
                                                      
                                                      
                                                         
                                                            Time
                                                            
                                                               post
                                                               -
                                                               test
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      Time
                                                      
                                                         post
                                                         -
                                                         test
                                                      
                                                   
                                                   >
                                                   
                                                      Time
                                                      
                                                         pre
                                                         -
                                                         test
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The results presented in this paper will typically refer to the normalized values of these variables (normalized gain and normalized change in response time). Some normalization is necessary because, although students enrolled in the same class were tested to have a similar level of knowledge, they may present individual differences in the specific words they know. Since the results of each student are normalized to the original scores in the pre-test, this ensures that we are measuring their progress with the use of REAP independently of their initial knowledge at the time of the pre-test.

@&#RESULTS@&#

First the independent variables were studied. Table 3
                      shows the number of requests for dictionary definitions and for translations normalized by the number of students and the number of readings for both studies. In Fall 2011 access to translation involved more effort since students had to type or copy and paste the word they wanted to translate. As a result, only 2.31 translations on average per student for each reading were requested, compared to 5.29 dictionary definitions. Definitions were accessed by a simple left mouseclick. However, in Spring 2012, when the access to translation became as easy as the dictionary (left click for translation versus right click for definition), the number of translation requests increased to 8.15 per student and per reading, while the dictionary lookups decreased to 1.78.

The results show that when students had easy access to translation, they used it more often, in detriment to using dictionary definitions, which had previously been their main resource. It also shows that students request these features not only for focus words, but for many other words in the text. Students did not request definitions or translations for all of the focus words. This may indicate that they are not indiscriminately clicking on words, as has sometimes been seen in the past. Rather they are making an effort to click on words they felt they did not know well.

The dependent variables (accuracy and fluency) are shown in Table 4
                     , and their normalized changes in Table 5
                     . The results in terms of scores in the assessment tasks show a normalized gain from pre-test to post-test of 29% for the students in the Fall 2011 study and 22% for the students in the Spring 2012 study. In both studies, the results from pre-test to post-test are significantly different according to a paired t-test with p
                     <0.001. This shows that students significantly improved their knowledge of the focus words with REAP. There are not significant differences in the scores between the Fall 2011 and Spring 2012 studies, indicating that the previous knowledge of the students and the difficulty of the focus words was similar in both studies. Response times can also be seen in Table 4, and the values of normalized change in response time in Table 5. These times were similar between both studies for the pre-test questions, but while students in Fall 2011 just increased their response time by 6% in the post-test, students in Spring 2012 were much slower in the post-test, up to 5s (29% of increase).

This section examines the external variables that could influence the use of translation as an independent variable. We identified 3 variables that could affect this: previous knowledge, relative word difficulty, and difficulty of the texts in which the words were embedded.

Previous knowledge could influence the study results. For example, the students with the lowest initial vocabulary knowledge could be using translation the most. Spearmam's rank correlation coefficient r
                        
                           s
                         between the students’ pre-test and their number of translation requests is shown in Table 6
                        , for both Fall 2011 and Spring 2012. This does not show a correlation between the use of translation and previous knowledge. Individual differences in the pre-test were taken into account in the measure of normalized gain and, hence, do not affect the results.

Similarly, differences in the use of translation could be due to differences in the relative frequency of the words. The exposure of the students to specific English words depends on how frequently each word appears in everyday sources like written press, television or academic texts. Infrequent words could be more likely to require help when present in a reading, due to the lack of exposure of the students to that word and its morphological variants. To account for this possible difficulty, we counted the frequency of occurrence of each focus word in the English Gigaword corpus, which contains a large amount of news wire data over many years (Graff and Cieri, 2003). We examined the relationship of the number of translations to the total number of occurrences of each word in the Gigaword corpus. The results are shown in Table 7
                        . This table shows that, as expected, there is a significant negative correlation between the frequency of occurrence of the focus words and the number of translations requested. However, the correlation coefficients r
                        
                           s
                         are not close to −1, meaning that the correlation is not strongly linear and the correlation is held mainly by 14.6% of the focus words (7 out of 48) which are both infrequent and translated more often than the rest. These words were ‘barrage’, ‘ubiquity’ and ‘rustle’ in Fall 2011 and ‘vulnerable’, ‘vantage’, ‘resile’ and ‘seismic’ in Spring 2012. Further analysis, following the Cambridge English Vocabulary Profile,
                           4
                        
                        
                           4
                           
                              http://vocabulary.englishprofile.org.
                         showed that all the words belonged to levels B2, C1 and C2 of the Common European Framework of Reference (CEFR) [6]. The distribution of the three levels was similar for both studies, with 36% B2, 20% C1 and 44% C2 for the words in Fall 2011 and 40% B2, 27% C1 and 33% C2 for the words in Spring 2012. This showed that there was no bias in terms of word difficulty between both studies.

Finally, another influencing variable could have been the difficulty of the texts. Students could have requested more translations for words appearing in the more difficult texts since it could be more difficult to extract the meaning from the context in this case. This had been dealt with during the study setup. The texts in both studies were chosen to be of 8th grade reading level according to REAP's automatic readability measure from Heilman et al. (2008). There were a few exceptions. In Fall 2011 there was one 7th grade level text and two 9th grade texts. In Spring 2012 one text was 9th grade level and one was 10th grade level. Fig. 4
                         shows the relationship between text difficulty (readability level) and the number of translations requested. In Fall 2011 (Fig. 4a), words in more difficult texts have a larger span of number of translations requested, while in Spring 2012 (Fig. 4b), the words in simpler texts were the ones that had more variation in the number of translations. In general, no dependency can be seen and, as with the previous two variables, text difficulty does not seem to have influenced the results.

Results showed a shift in student behavior between the two studies. This shift was manifested in the increase in the number of translations requested. Due to this, another analysis of the dependent variables (accuracy and fluency) was run for two groups. The group of translated words includes the results for the questions answered when a student had requested a translation for the word during the readings. The second group is the group of not translated words, which includes the rest of the words, i.e. the ones for which a student did not request a translation.


                        Fig. 5
                         shows an example of this distinction. A given student, Student A, requested the translation of the word ‘deny’, but not of the word ‘confine’. The answers of Student A to the questions related to ‘deny’ will be included in the set of translated words, while the answers to the questions related to ‘confine’ will be included in the set of not translated words. If another student, Student B, did not request the translation of any of those words, the answers to questions relating to both words will be included in the set of not translated words. Finally, another student, Student C, translated the word ‘confine’, but not ‘deny’; hence, the results of Student C for ‘confine’ will be in the set of translated word results.

The results in terms of accuracy and fluency for the group of not translated words are presented in Table 8
                        , including normalised values of post-reading and post-test accuracy against the pre-test accuracy, and normalised value of change in response time from pre-test to post-test. In both studies, there is an increase in accuracy in post-reading assessment tasks and post-tests with respect to the pre-test and a slight increase in response time from pre-test to post-test. For this group of words, students obtained scores on the post-reading questions that were similar to those in the post-test. This indicates that students were transferring the knowledge they had acquired during the readings and post-reading practice to the post-test.

The equivalent results for the group of translated words are presented in Table 9
                        , also including normalised values of accuracy and response time. Accuracy increases in post-reading tests and post-tests with respect to the pre-test for both studies. But there is a drop in the post-test scores with respect to the post-reading tests in Spring 2012. Furthermore, there is an increase in response time in the post-test, which is more pronounced for Spring 2012. These are the first indications of possible differences in student performance related to their patterns of use of translations.

There are limitations to the analysis of the group results. Individual students can behave very differently from one another in their use of REAP (number of translations they request for instance) and also achieve very different results in accuracy and fluency on the assessment tasks. For that reason, an individualized analysis of the results was carried out. In this analysis, the results of each student are viewed separately, according to the total amount of translation they used and their results in accuracy and fluency.

The correlations between an individual student's number of translations and their normalized gain for translated words were analyzed. As in the previous example, if a student requested the translation of the word ‘deny’, the results for this word and all other focus words that were translated are included in the calculation of normalized gain for translated words. As a result, we have r
                        
                           s
                        
                        =−0.32, p
                        =0.18 for Fall 2011 and r
                        
                           s
                        
                        =−0.30 and p
                        =0.15 for Spring 2012. This means that students that use translation more tend to have lower gains from pre-test to post-test, as marked by the negative value of Spearman's correlation (r
                        
                           s
                        ), but these otherwise weak correlations are not significant according to the p-values obtained.

We also analyzed the normalized change in response time for each individual student according to the amount of translation of the focus words. Fig. 6
                        a shows this relationship for Fall 2011 and Fig. 6b for Spring 2012. In this case, differences can be seen. Fig. 6a shows that students who used translation more often all have slower response times on the post-test (normalized change lower than 0), while the rest of the students present a normal distribution, with some being slower and others being faster. In Fig. 6b students who used more translation again perform more slowly on the post-test. This trend is less prominent due to the fact that Spring 2012 students used a larger amount of translation than their Fall 2011 peers. In general, most of the Spring 2012 students appear slower in the post-test than in the pre-test, and this could be affected by their significant use of translation.

It could also be possible that there were differences in student accuracy between the results in the short-term (post-reading tests) and in the long-term (post-test). Table 9 shows that, in Spring 2012, there was a drop in accuracy from post-reading test to post-test for the translated words. This drop did not appear at in Fall 2011 or in Spring 2012 for not translated words.

To find whether the amount of translation actually affected this result, Spring 2012 students were separated into 2 groups: the 13 students who used the least number of translations and the 13 students who used the most translations. Fig. 7
                         shows the normalized gains in post-reading and post-tests over the pre-test for these 2 groups. Both groups present a similar gain in post-reading (approximately 0.35) and, while this gain was lower for both groups on the post-test, the students who used translation the most had a larger loss. Although not significant (p = 0.48), this difference, which is approximately 7% in normalized gain, indicates that these students are having more difficulty transferring the knowledge they had acquired during the readings in the longer term.

@&#DISCUSSION@&#

These set of studies have shown that intelligent tutors can provide measures of a variety of dependent and independent variables that can help understand some issues in ESOL learning. This is consistent with the results shown in previous studies like Laufer and Hill (2000) or Abraham (2008). With the REAP system, we have been able to store all the actions of each student for later analysis. This includes knowledge of when the student begins and ends a lesson (precise start and end times), precise timing of the use of features (i.e., dictionary definitions and translations) and accurate measures (including response times) for assessment activities. This kind of information can be used to discover the relation between student choices during practice and their results on assessment tests. Student models have been used for a long time in the design of cognitive tutors for science or math with successful results (Ritter et al., 2006), but little evidence of the usefulness of these tutors in the realm of language learning has appeared. Our work shows that cognitive modeling could help understand the relationship between students’ work habits and their performance.

Regarding how translation affects accuracy and fluency, the results show that translation affects vocabulary acquisition of ESOL students. Extensive use of translation increases accuracy in the short term, immediately after learning, but this does not transfer to the long term. Fluency, as manifested in longer response times, is also affected by extensive translation. We note, however, that the significance of the results is at times limited by the relatively small number of participants in the two studies.

The studies reported here point in the direction that translation does have an impact in accuracy and fluency. There seems to be no binary answer as to whether translation is good or not in ESOL vocabulary acquisition, rather an awareness that the use of translation has to be controlled. This paper shows that moderate use of translation is the most beneficial and that excessive use seems to impair long term vocabulary retention. However, the definition of what is moderate or excessive may depend on the task. In our case, students performed weekly readings of approximately 400–500 words in length selected for their reading level with a small target vocabulary.

We also note that some of the infrequent focus words in the studies had more translations than the rest of the focus words. Word frequency has been shown to have a mild correlation with the number of translations requested. Thus students may be looking up the less frequent words more often since they have not encountered them in the past. However, all words used in the two studies analysed in this work had a difficulty (B2 to C2 according to the CEFR) appropriate for the students involved and similar between studies.

The students in these studies are advanced learners. Advanced L2 learners tend to have a larger stockpile of vocabulary, especially passive vocabulary (Laufer, 1998), easier incidental vocabulary learning and bettser retention results in learning vocabulary by translation. Also, the majority of the students were native speakers of Arabic. The characteristics of this language may have had an influence on the student's desire to obtain translations. Students with different linguistic backgrounds might present different patterns in their use of translation.

In order to locate the work presented in this paper with regard to previous works, Table 10
                      summarizes the characteristics of some relevant works from the literature against this work. Hulstijn et al. (1996) found that access to translation improved short-term retention of new words in advanced students, although it did not study fluency or longer-term accuracy. Prince (1996), when working with a groups of beginner and advanced learners, found that beginners could not transfer the words they had learnt through translation to context-based activities like cloze-questions. Grace (1998) made a strong point for the use of translation, showing that beginner learners of French increased retention of new words when having the option to use translation in a CALL scenario. However, this study did not measure the precise amount of translation the students were using. Laufer and Hill (2000) obtained mixed results when studying two groups of students, with Israeli students benefiting more from translation than students from Hong Kong. Finally, Laufer and Girsai (2008) showed that the use of bilingual dictionaries improved the retention of words in intermediate learners.

The present study fills some questions not answered yet by the previous works reported in Table 10. It aimed to study not only short or long term accuracy, but also fluency, through response time. It also aimed to obtain a more accurate measure of the use of translation and dictionaries than self-reporting. Finally, it wanted to evaluate advanced students in an in-vivo classroom scenario, as a fully realistic approach to study acquisition of vocabulary. Compared to advanced students, beginner and intermediate learners will exhibit lower reading comprehension and more difficulty to infer the meaning of words from context, which makes them more likely to require translation. A longitudinal study that tracks ESOL students from an intermediate to an advanced level would be required to understand how proficiency affects the influence that translation has in vocabulary learning.

@&#CONCLUSION@&#

The results shown throughout this article contribute to the assessment of the use of translation in language learning and specifically for vocabulary acquisition. Our use of an intelligent tutor, REAP, is one effective way to carry out well-controlled vocabulary learning studies. It will be interesting to carry out further studies, with larger student populations to confirm and extend our findings.

Our studies imply that teachers should allow some translation, but tightly control the amount of translation, making their students aware of the consequences of heavily relying on this scaffold. The limit for the use of translation in class has to be set up according to a large number of variables that teachers have to take into account. Students’ previous level, text difficulty, students’ background, among others must be considered when deciding to control the amount of translation used by the students.

@&#ACKNOWLEDGMENTS@&#

This work is supported through the Refinement and Fluency Thrust of the Pittsburgh Science of Learning Center which is funded by the US National Science Foundation under grant number SBE-0836012. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF. Oscar Saz was supported with Fulbright/MEC fellowship.

The authors would like to thank Prof. Alan Juffs, Dr. Greg Mizera and the teachers and students of the University of Pittsburgh's English Language Institute for their participation in the classroom studies. Special thanks to Prof. Charles Perfetti of the Learning Research and Development Center of the University of Pittsburgh for discussions on the content of this paper.

@&#REFERENCES@&#


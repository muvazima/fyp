@&#MAIN-TITLE@&#A two-stage character segmentation method for Chinese license plate

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Characters on license plate with interferences are cut using a two-stage method.


                        
                        
                           
                           Plate frame is removed and vertical tilt is corrected before segmentation.


                        
                        
                           
                           A harrow-shaped filter with values of 0 and 1 is designed for matching.


                        
                        
                           
                           Boundaries of the remarkable space are located accurately in initial segmentation.


                        
                        
                           
                           A∗ algorithm is used for the precise segmentation of connected characters.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

License plate character segmentation

Horizontal boundaries location

Template matching

A∗ path-finding

@&#ABSTRACT@&#


               
               
                  As a part of character recognition, character segmentation (CS) plays an important role in automatic license plate recognition (ALPR) system. In recent years, lots of methods on CS have been proposed and they work well on their own datasets. However, it is still challenging to segment characters from images with frame, declination and quality degradation because of noises and overlapped, connected or fragmented characters. In this paper, we propose a two-stage segmentation method for Chinese license plate. At the first stage, a novel template matching method is presented using a harrow-shaped filter (HSF) bank and minimum response. It finds the locations of the segmenting points between characters roughly. Then, the accurate segmentations between connected or overlapped characters are adjusted by a variant of A∗ path-finding algorithm at the second stage. Experiments on a challenging dataset including 2334 images demonstrate the effectiveness and efficiency of the proposed method.
               
            

@&#INTRODUCTION@&#

With the rapid growth in the number of vehicles, it is of great importance to develop intelligent transportation system (ITS) to improve the management of high ways, toll stations and parking lots [1,2]. As one of the most important parts of ITS, automatic license plate recognition (ALPR) system generally consists of license plate localization (LPL), character segmentation (CS) and character recognition (CR). Among them, CS aims to locate the boundaries of each character accurately so as to segment the corresponding image patch for recognition. Hence, its performance has great influence on the whole system. During the past few years, a lot of researches have been done on CS. The existing methods can be divided into three categories: vertical projection (VP) based methods [3–6], connected component analysis (CCA) based methods [7–11] and template matching (TM) based methods [12–14].

Among them, the VP-based methods are the simplest and fastest. Characters are segmented directly by detecting valleys in the projection histogram. Thus, this kind of method is sensitive to noise and likely to fail in segmenting connected or fragmented characters correctly. In the methods based on CCA, character-like components are often detected and their positional relationships are utilized to segment the real characters. But in the case of connection or fragmentation, the segmentation will become difficult. Therefore, the performances of CCA based methods depend largely on the result of binarization.

By contrast, methods using TM are more robust to connection and fragmentation. Usually, a square wave having the same structure with standard license plate and a score function are used for matching. When there are noises at the left and right sides of the plate or severe adhesions between characters, the results given by these methods are far from satisfaction. Therefore, a more effective approach needs to be developed to solve those problems out.

In this paper, we propose a two-stage character segmentation method that takes full advantage of the arrangement structure of Chinese license plate. It consists of three main steps: image preprocessing, initial segmentation and precise segmentation. In the preprocessing step, the horizontal borders of frame are removed and vertical tilt is corrected on the binary image. Then, a bank of harrow-shaped filter (HSF) is deigned and convolved with the vertical projection in the initial segmentation stage, aiming to find the locations of segmenting points between characters roughly. Finally, the accurate segmentations between connected or overlapped characters are adjusted by a variant of traditional A∗ path-finding algorithm. The main contributions of our work are given as follows:
                        
                           (1)
                           CCA and horizontal scanning are combined to remove the horizontal borders of plate frame.

HSF bank and minimum response are used for rough segmentation.

The connected and overlapped characters are segmented on the basis of the variant of A∗.

The rest of this paper is organized as follows. First, related work is presented in Section 2. Then, Section 3 gives a detailed description of the proposed method, including image preprocessing, initial segmentation and precise segmentation. In Section 4, we discuss and evaluate the experiment results, as well as a comparison of our results with several state-of-the-art methods. Finally, the work is concluded in Section 5.

@&#RELATED WORK@&#

In literature, many license plate character segmentation algorithms have been proposed [15]. Although it has been studied for many years, it is still a challenging task to segment characters on license plates with frame, declination and quality degradation. According to different methods mentioned in introduction, we will review the related work of each category.

For VP based methods, the peak-valley distribution in vertical projection histogram is explored. In [3], after removing the plate frame by horizontal projection, the binary image is projected vertically to find the largest space for locating the boundaries of each character by adding or subtracting the estimated character width. The work in [4] differs from [3] in locating the upper and lower boundaries of character region. The image is divided into many blocks in horizontal and each block is projected horizontally to get two sets of subsection lines. For each set, Hough transform is implemented on the midpoint of each subsection line to get the boundary line. So this method can deal with inclined plates. Studies in [5,6] mainly focus on the segmentation of connected and overlapped character. In [5], a morphological thickening algorithm and a morphological thinning algorithm are adopted, respectively. The method proposed in [6] uses an optimal pathfinding algorithm called A∗ 
                     [16], which is not only effective in accuracy but also efficient in time.

CCA is another popular technique used for character segmentation. Usually, connected components with the same aspect ratio as character or those recognized as characters are first extracted from the binary image, as presented in [7,8]. By analyzing the spacial relationships between them, characters undetected are segmented. Compared with blob detection by thresholding, maximally stable extremal region (MSER) detector proposed in [17] is more powerful and often adopted for text detection [18]. It is first applied for segmentation of license plate character in [9]. MSERs that meet some geometry features are considered as plate characters. The study in [10,11] make full use of MSERs in their license plate recognition system. Therefore, methods using CCA is robust to plate frame and invariant to tilt.

Utilizing the characters’ arrangement on license plates, many methods base on TM are proposed as well. A recent work in [12] presents a variable-length template matching method, according to the characteristics of horizontal and vertical projections. Two sets of templates, one with single square wave and another with seven square waves, are designed and matched with the horizontal projection of horizontal gradient and vertical projection of vertical gradient image, respectively. The best matches are achieved at positions with maximal correlation coefficients. Miao [13] has proposed a novel usage of TM, in which midpoints of intervals on the vertical projection histogram are compared with those on the template, to distinguish character blocks from noises. In [14], the difference between the number of white pixels in character blocks and in intervals is taken as a measure of matching.

Different from the methods mentioned above, we fulfill the segmentation task via two steps. The initial segmentation stage aims to separate the plate characters into two parts accurately and get an estimation of the character width and space width. Based on this, the positions of midpoints between overlapped or connected characters are adjusted by A∗ path-finding algorithm in precise segmentation. With our proposed method, characters on a Chinese license plate image can be segmented effectively and efficiently.

@&#PROPOSED METHOD@&#


                     Fig. 1
                      depicts the flowchart of our framework. Three parts shown in the flowchart will be described in detail. It is worth noting that the inputs for segmentation are isolated license plate images, which are generated by our license plate location module. In this module, horizontal tilt correction and a rough segmentation are carried out to get a more accurate extracted plate image, which not only facilitate the plate verification process but also the character segmentation module. Thus, in this paper only vertical tilt correction is considered. Several samples shown in Fig. 2
                      illustrate the process of obtaining the input license plates from original image patches.

In this paper, the task of image preprocessing includes binarization, vertical boundaries location and vertical tilt correction, which aims to get a binary image with upright characters without frame.

Usually, it is necessary to convert a color image into a grayscale one first before binarization. And in RGB color space, the G-component image of plate often has higher contrast, the gray-level difference between characters and their background in the plate, than the other two components. But for license plate captured at night, the R-component image is preferred. To make a balance, we choose the one with higher contrast. Let c be the color component variable and 
                              
                                 c
                                 ∈
                                 {
                                 R
                                 ,
                                 G
                                 }
                              
                           , and 
                              
                                 
                                    
                                       g
                                    
                                    
                                       c
                                    
                                 
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            be the corresponding horizontal gradient value at pixel 
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                           . The contrast of c-component image is computed by the following formula.
                              
                                 (1)
                                 
                                    
                                       
                                          S
                                       
                                       
                                          c
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             x
                                          
                                       
                                    
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             y
                                          
                                       
                                    
                                    
                                    
                                       
                                          g
                                       
                                       
                                          c
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                 
                              
                           
                        

To highlight the characters and restrain the background effectively, an adaptive binarization method proposed in [19] is used. By combining global with local method, it is insensitive to noise and uneven illumination. Let 
                              
                                 f
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            denote the gray value at 
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                                 ,
                                 T
                              
                            denote the global threshold given by Otsu [20], and 
                              
                                 
                                    
                                       T
                                    
                                    
                                       1
                                    
                                 
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            denote the local threshold at 
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                           , which is given by Bernsen [21]. According to the procedure described in [19], the binarization is formulated as follows,
                              
                                 (2)
                                 
                                    b
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      f
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      <
                                                      (
                                                      1
                                                      -
                                                      α
                                                      )
                                                      T
                                                   
                                                
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      f
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      <
                                                      (
                                                      1
                                                      +
                                                      α
                                                      )
                                                      T
                                                   
                                                
                                                
                                                   
                                                   
                                                      h
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      
                                                      else
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (3)
                                 
                                    h
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      f
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ⩽
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      f
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      >
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 b
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            is the binary value at 
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            and 
                              
                                 h
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                            is an intermediate value computed by local threshold, 
                              
                                 α
                                 ∈
                                 [
                                 0
                                 ,
                                 1
                                 ]
                              
                            is a parameter adjusting the range of gray level to be binarized by local threshold. It is shown in [19] that a good result can be achieved when 
                              
                                 α
                              
                            is between 0.2 and 0.4. In our work, it is set to 0.3 empirically. The binarization results of the first two images in Fig. 2 are shown in Fig. 3
                           .

Since extra non-plate areas, plate frame and rivets, may exist in the license plate image, the upper and lower boundary of character region are supposed to be located before segmentation. Horizontal scanning method (HCM), which counts the times that pixel changes from one color to the opposite row by row, is a popular way to achieve this aim. However, adhesions around characters often lead to over-segmentation or under-segmentation. In some cases of under-segmentation, CCA can also be adopted for location by extracting connected components with similar height.

Therefore, we combine HCM and CCA together to achieve better performance. If the number of components extracted is greater than 2, CCA is employed. Otherwise, HCM is chosen. The location results are shown in Fig. 4
                           .

In Fig. 5
                           , two vertical tilt modes are given. To get a plate image with upright characters, the method proposed in [22] is used. It estimates the skew angle by finding the projection minimum and correcting the image by moving pixels in each row horizontally. Denote the slant angle by 
                              
                                 θ
                              
                            and the height of the binary image by H. The moving distance of each pixel could be computed by:
                              
                                 (4)
                                 
                                    
                                       
                                          d
                                       
                                       
                                          x
                                       
                                    
                                    =
                                    (
                                    H
                                    /
                                    2
                                    -
                                    y
                                    )
                                    tan
                                    θ
                                 
                              
                           where x and y are the current pixel coordinates. If 
                              
                                 
                                    
                                       d
                                    
                                    
                                       x
                                    
                                 
                              
                            is greater than 0, the pixel is moved to the right, else it is moved to the left. In our experiments, the rotation angle ranges from −20° to 20° and increases 1° each time. Fig. 6
                            shows the corrected images and corresponding skew angles.

Generally, the boundaries of each character can be obtained easily by defining and locating a baseline on the license plate and performing a series of mathematical operations between it and character width. For the segmentation task of Chinese license plate, the wider space that separates the plate into left and right is chosen as the baseline. And in this subsection, our purpose is to locate the wider space accurately and giving an estimation for the character width. To this end, a novel template matching method based on a bank of harrow-shaped filters with minimum response is developed.

To build the filter bank, we start with setting a range of character width based on the vertical projection. Assume the variable of character width is denoted by 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                        , then according to the Ministry of Public Security standards for license plate, the normal space width 
                           
                              
                                 
                                    d
                                 
                                 
                                    1
                                 
                              
                           
                        , the wider space width 
                           
                              
                                 
                                    d
                                 
                                 
                                    2
                                 
                              
                           
                         and the filter width w corresponding to 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                         can be deduced by equations listed below:
                           
                              (5)
                              
                                 
                                    
                                       d
                                    
                                    
                                       1
                                    
                                 
                                 =
                                 round
                                 (
                                 12
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 /
                                 45
                                 )
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       d
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 round
                                 (
                                 34
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 /
                                 45
                                 )
                              
                           
                        
                        
                           
                              (7)
                              
                                 w
                                 =
                                 7
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 +
                                 5
                                 
                                    
                                       d
                                    
                                    
                                       1
                                    
                                 
                                 +
                                 
                                    
                                       d
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                     

Next, the shape of the filter should be modeled, which has a direct effect on the segmentation result. In traditional methods [12,14], the distributions of character blocks and spaces are exactly the same as that of standard license plate and the values on them are set to 1 and 0, respectively, as shown in Fig. 7
                        (a). In addition, maximal correlation coefficient and maximum variance are selected as matching criteria. To improve their robustness to degraded plate images, a harrow-shaped filter with minimum response is designed. It differs from the traditional ones in two aspects. Firstly, the size of each normal space is shrunk to 1-pixel width, while the size of each character block is expanded. The values assigned to them are 0 and 1, which is contrary to the traditional ones. In this way, the harrow-shaped filter is obtained, as shown in Fig. 7(b). The second difference is the way we compute the response. The filter is convolved with the projection vector to count the projection sum over spaces. In this way, the influences of adhesions and noises can be reduced greatly.

Let W be the width of a corrected image and 
                           
                              v
                              (
                              x
                              )
                              (
                              x
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              W
                              )
                           
                         be the vertical projection vector. The convolution response at 
                           
                              j
                              (
                              1
                              ⩽
                              j
                              ⩽
                              W
                              -
                              w
                              )
                           
                         can be formulated as:
                           
                              (8)
                              
                                 R
                                 (
                                 j
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          =
                                          1
                                       
                                       
                                          w
                                       
                                    
                                 
                                 v
                                 (
                                 x
                                 +
                                 j
                                 )
                                 
                                 s
                                 .
                                 t
                                 .
                                 
                                 x
                                 ∈
                                 {
                                 
                                    
                                       p
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       4
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       5
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       6
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       7
                                    
                                 
                                 }
                                 ∪
                                 [
                                 
                                    
                                       p
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       3
                                    
                                 
                                 ]
                              
                           
                        where 
                           
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                              (
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              7
                              )
                           
                         denotes the 
                           
                              i
                              th
                           
                         segmentation position, which is determined by:
                           
                              (9)
                              
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         c
                                                      
                                                   
                                                   +
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   /
                                                   2
                                                
                                                
                                                   i
                                                   =
                                                   1
                                                
                                             
                                             
                                                
                                                   2
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         c
                                                      
                                                   
                                                   +
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                
                                                
                                                   i
                                                   =
                                                   2
                                                
                                             
                                             
                                                
                                                   2
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         c
                                                      
                                                   
                                                   +
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   +
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                                
                                                   i
                                                   =
                                                   3
                                                
                                             
                                             
                                                
                                                   (
                                                   i
                                                   -
                                                   1
                                                   )
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         c
                                                      
                                                   
                                                   +
                                                   (
                                                   i
                                                   -
                                                   2.5
                                                   )
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   +
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                                
                                                   4
                                                   ⩽
                                                   i
                                                   ⩽
                                                   7
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

To obtain the best matched character width 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                                 
                                    ∗
                                 
                              
                           
                         and starting position of character region 
                           
                              
                                 
                                    j
                                 
                                 
                                    ∗
                                 
                              
                           
                        , the response is repeated over all values of 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                         and j, and the values with minimum response are chosen. Taking the corrected image in Fig. 6(a) for example, the lower limit and upper limit of character width are set to 7 and 18, respectively. After matching, the minimum response curve of 
                           
                              R
                              (
                              j
                              )
                           
                         over 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                         is obtained, as given in Fig. 8
                        (a). Clearly, the optimal character width is 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                                 
                                    ∗
                                 
                              
                              =
                              13
                           
                        . Meanwhile, the response curve of 
                           
                              R
                              (
                              j
                              )
                           
                         over j under 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                                 
                                    ∗
                                 
                              
                           
                         is presented in Fig. 8(b), which shows that the optimal match is achieved at 
                           
                              
                                 
                                    j
                                 
                                 
                                    ∗
                                 
                              
                              =
                              21
                           
                        . To give a better comprehension of how the matching process is implemented, a list of variable description and the corresponding algorithm pseudocode are summarized in Tables 1 and 2
                        
                        , respectively.

Finally, it is worth to point out that mismatch is likely to happen when several “1”s exist in the image. To handle this problem, some constraints should be made. For convenience, we denote by 
                           
                              
                                 
                                    Cs
                                 
                                 
                                    i
                                 
                              
                              (
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              7
                              )
                           
                         the projection sum of the ith character block, by 
                           
                              
                                 
                                    l
                                 
                                 
                                    i
                                 
                              
                              (
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              6
                              )
                           
                         the space width in the histogram and by 
                           
                              
                                 
                                    Th
                                 
                                 
                                    i
                                 
                              
                           
                         the adaptive threshold for 
                           
                              
                                 
                                    Cs
                                 
                                 
                                    i
                                 
                              
                           
                        . Then, the following constraints should be met while searching for the best match: 
                           
                              
                                 
                                    Cs
                                 
                                 
                                    i
                                 
                              
                              <
                              
                                 
                                    Th
                                 
                                 
                                    i
                                 
                              
                              (
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              7
                              )
                              ,
                              
                                 
                                    l
                                 
                                 
                                    1
                                 
                              
                              <
                              
                                 
                                    l
                                 
                                 
                                    2
                                 
                              
                           
                         and 
                           
                              max
                              
                                 
                                    (
                                    
                                       
                                          l
                                       
                                       
                                          i
                                       
                                    
                                    )
                                 
                                 
                                    i
                                    =
                                    3
                                    ,
                                    4
                                    ,
                                    5
                                    ,
                                    6
                                 
                              
                              <
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                        . In our experiment, 
                           
                              
                                 
                                    Th
                                 
                                 
                                    i
                                 
                              
                           
                         relates to 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                              
                           
                        . The segmentation results in Fig. 9
                         shows that the wider space is located accurately and references on the midpoints of other spaces are provided as well.

In this stage, the accurate boundaries of each character will be obtained by making use of the initial segmentation result. For adjacent characters that are not connected or overlapped in horizontal direction, it is easy to get the left or right boundary by searching around the reference points. Thus, we concentrate on the cases of connection and overlapping. And a variant of A∗ is employed for this task. For characters on the right part, the segmentation baseline is 
                           
                              
                                 
                                    p
                                 
                                 
                                    3
                                 
                              
                           
                         and 
                           
                              
                                 
                                    p
                                 
                                 
                                    2
                                 
                              
                           
                         for characters on the left part. Taking the right part for example, the implementation detail of is described below.

First of all, for a clear presentation of the variant of A∗ algorithm, a formal statement is given in Table 3
                        . Then, to apply the A∗ variant to the binary image, a weight map is constructed by the rule illustrated in Fig. 10
                        . Here, the center red point represents a white foreground pixel and the others are background pixels around it. Based on the idea that a path between adjacent characters should pass through object pixels as less as possible, the weights set to A, B, C and D are 20, 5, 3 and 1, experimentally. A considerable cost is assigned to object pixel. In this way, a winding path going by background pixels is more preferred. The weight at background pixels is 1, which is the smallest cost to pay for moving through.

When the weight map is constructed, the actual cost of an optimal path from the starting point to point p can be known from the iterative formula presented blow:
                           
                              (10)
                              
                                 Ac
                                 (
                                 p
                                 )
                                 =
                                 Ac
                                 (
                                 Fa
                                 (
                                 p
                                 )
                                 )
                                 +
                                 Wei
                                 (
                                 p
                                 )
                              
                           
                        For the starting point 
                           
                              s
                              ,
                              
                              Ac
                              (
                              s
                              )
                           
                         is initialized to 0. Based on the fact that the cheapest path is located from current point to the bottom row, the remainder possible cost can be obtained as follows:
                           
                              (11)
                              
                                 Fc
                                 (
                                 p
                                 )
                                 =
                                 H
                                 -
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        By adding the two costs together, the total cost of an optimal path through p can be achieved. The implementation process of the variant of A∗ is presented in Table 4
                         and the optimal paths between connected characters are found in Fig. 11
                        .

Finally, straight segmentation lines are derived from the zigzag paths by sliding window technique. For each region bounded by the left boundary of the character on left and the zigzag path, a 
                           
                              
                                 
                                    w
                                 
                                 
                                    c
                                 
                                 
                                    ∗
                                 
                              
                              
                              *
                              
                              H
                           
                         window is moved horizontally. When the number of foreground pixels within the window reaches the maximum, the right boundary of the window is taken as the segmentation line. The final results after precise segmentation are shown in Fig. 12
                        .

@&#EXPERIMENTS@&#


                     Testing dataset: To evaluate the performance of our method, we build a dataset including 2334 plate images in total. They are generated by our license plate localization module working on vehicle images collected from different ways. For example, some of them are captured at a toll station, crossroad or highways. And some are downloaded from the internet, which are public provided in [23]. The rest are captured by us in campus or parking lot. Since horizontal tilt correction has been carried out in the location process, plates in the test images are almost horizontal. But, there are still many factors that cause the segmentation task difficult, such as plate frame, vertical tilt, image quality degradation and low resolution. Based on the characteristic of each image, the dataset is divided into five groups. Several typical samples of each group are shown in Fig. 13
                     . Note that images in the degraded group include cases of uneven illumination, noise, dirt or blurring.

@&#EVALUATION@&#

In the experiments, we compare our approach with other four methods on character segmentation, such as AMM [5], AOLPR [9], MVTM [14] and VLTM [12]. Among them, the first two are based on vertical projection (VP) and connected component analysis, respectively. In AMM, after dividing the plate codes into two parts by VP, merging of fragments and separation of overlapped or connected characters using morphological operations are carried out. In AOLPR, a number of blobs are extracted from the grayscale image by MSER detector and verified by their aspect ratios and orientations. MVTM and VLTM fall into the template matching class. They are similar in ideology, but different in methodology. MVTM removes plate frame by horizontal scanning, and searches for the left and right boundaries of each character by maximizing the variance between character cluster and space cluster. In VLTM, two filters, one with single square wave and another with seven square waves, are used for vertical and horizontal segmentation, respectively. By traversing all possible values of character height and width, the best matches are achieved at the positions with maximal correlation coefficient.

These four methods and the proposed one are all realized using Visual C++ 6.0 and OpenCV. And the experiments are implemented on a Microsoft Windows XP operating system, Intel Core 3.07GHz CPU and 1.92G RAM.

In this paper, the experimental results are evaluated by two aspects, segmentation accuracy and character recognition rate. Firstly, a character is considered to be segmented correctly if 
                              
                                 A
                                 ⊆
                                 B
                              
                            and 
                              
                                 B
                                 /
                                 A
                                 ⩾
                                 0.8
                              
                           , where A is the segmented region and B is the ground truth region. Otherwise, it is missed or segmented incorrectly. Based on this, the segmentation accuracy is given by the number of characters segmented correctly divided by the number of characters presented. Then, a binary image composed of the segmented characters, as shown in Figs. 14–18
                           
                           
                           
                           
                           , is sent to the professional OCR software called ABBYY FineReader [24] for recognition. Since AOLPR and VLTM work on the grayscale image and gradient image, respectively, we convert the character images to binary format by Otsu to construct the binary image. The recognition rate is given by the number of characters recognized correctly divided by the number of characters segmented correctly.

The segmentation results of the four compared methods and our method are shown in Table 5
                           . It can be seen that the proposed method achieves higher accuracy than the others on all five groups.

On the first group, it gives a 97.86% true positive segmentation rate, which is higher than AMM by 8.29%, AOLPR by 1.59%, MVTM by 7.88%, and VLTM by 3.13%. The main error comes up with Chinese characters that have a left–right or left-middle-right structure. On plates with frame, an accuracy of 91.45% is achieved, which is much higher than the others. On the one hand, this owes to the effectiveness of our horizontal frame removal approach, on the other hand, it profits from the robustness of the novel template matching strategy to noises at the left and right sides of the license plate. The correction of vertical tilt makes the proposed method be able to work on plates captured from different viewpoints. The accuracy obtained is about 93.34%. Due to the incapability in dealing with inclined plates, the results of MVTM and VLTM are not counted. Accuracies on the last two groups are a little lower, 89.01% and 89.92%, because of the influence of uneven illumination, imaging noise at night, abrasion of plate, dirt, blurring and low resolution. The comparison shows that the proposed method is robust in segmenting characters from plates with different conditions.

From the perspective of character recognition, the rates of characters in the first group segmented by the five methods are presented in Table 6
                           . We just count the result of the last six characters since the OCR software almost fails to recognize the first Chinese character. Due to the misrecognition between similar characters, like ‘8’ and ‘B’, ‘6’ and ‘G’, ‘0’ and ‘D’, the recognition rate of characters extracted by our method is only 88.88%, which is lower than that reported in other literatures. But it is still higher than the results of compared methods. This further proves that the characters segmented by our method are more accurate.

In this paper, time efficiency is investigated from two aspects. One is the preprocessing time and another is the time used to segment characters from the corrected image. The average time cost per image of each method is shown in Table 7
                           . The proposed method takes 10.05ms in average for segmentation, which is faster than AMM by about 6.7ms but slower than MVTM and VLTM by 7.44ms and 2.65ms. The reason behind this is that all possible values of character width as well as space width are traversed in experiments to reduce the rounding error in parameter estimation. By contrast, it is a long time to spend 25.71ms on preprocessing. This is because the adaptive thresholding method is very time-consuming compared to Otsu. According to the time cost reported in [25], which is 37ms for CS, the time consumption of our method is acceptable for real time application.

When license plates generated from the location module are free from frame, tilt and contamination, all the five methods can segment the characters accurately, as shown in Fig. 14. Nevertheless, their performance varies on plates with different conditions. In the following, the influence of several factors on CS is discussed and the segmentation results of corresponding samples are given.

Adhesion often occurs in plate image with frame, and this has a great impact on the segmentation accuracy. In AMM, MVTM and VLTM, the horizontal borders of frame are removed to eliminate the interference. And no measure is taken in AOLPR in view of its robustness to plate frame. Fig. 15 gives the segmentation results of samples shown in Fig. 13(b). It is easy to tell that the proposed method outperforms the others in removing the horizontal borders and distinguishing characters from noise blocks at the left and right sides of plate.

Since plates captured in open environment often suffer from vertical tilt, it is of great importance to concern tilt correction before segmentation. But this is not mentioned in the compared methods except for AOLPR, which is realized by MSER detection and free to vertical tilt. Segmentation results of samples in Fig. 13(c) are given in Fig. 16, from which we can see that characters segmented from the corrected image are more accurate and preferred for recognition.

Generally, a plate image with consistent intensity in characters and high contrast between characters and background is desired. However, factors like uneven illumination, noise, dirt or blurring often decrease the image quality and increase the difficulty of segmentation. As a result, efforts on exploring robust binarization and segmentation approaches need to be made. From the segmentation results given in Fig. 17, of samples in Fig. 13(d), we can notice that the adaptive binarization method used in this paper is effective in dealing with degraded plates, and the two-stage segmentation method can work very well on binary image with severe interference.

Generally speaking, the scale change of plates has little effect on the accuracy. But for plates with low resolution, in which the height of characters is smaller than 15 pixels, the segmentation accuracy will decrease sharply as well as the recognition rate. Fortunately, the results achieved by the proposed method are much more satisfied. Fig. 18 shows the segmentation results of samples presented in Fig. 13(e).

@&#CONCLUSIONS@&#

In this paper, we proposed a novel method for segmenting characters on Chinese license plates. Above all, a template matching method based on a bank of harrow-shaped filter (HSF) is proposed to locate rough segmenting points and then a variant of A∗ path-finding algorithm is applied for connected characters segmentation on binary image for the first time. Our approach is effective in dealing with various license plates exhibitions, such as plates with frame, vertical tilt, image degradation and low resolution. Though the time cost of our method is not the lowest among the compared methods, it is acceptable and can be reduced greatly through more efficient binarization algorithm. Besides, by altering the position of the wider space in the filter, it is feasible to apply our method to license plates in other countries as long as they have a left–right structure.

Since the frame removal method presented in this paper aims at facilitating the segmentation process, we could not guarantee that the segmented characters are perfect for recognition. Thus, advanced segmentation in vertical direction is necessary. All of these will be studied in our future work.

@&#REFERENCES@&#


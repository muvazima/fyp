@&#MAIN-TITLE@&#Exploiting multi-expression dependences for implicit multi-emotion video tagging

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a novel multiple emotional tagging method based on multi-expressions.


                        
                        
                           
                           We propose a novel multi-expression recognition by exploring dependencies among expressions.


                        
                        
                           
                           We model the relationships between expressions and emotions using a Bayesian Network.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Implicit video tagging

Multi-emotion

Multi-expression

@&#ABSTRACT@&#


               
               
                  In this paper, a novel approach of implicit multiple emotional video tagging is proposed, which considers the relations between the users' facial expressions and emotions as well as the relations among multiple expressions. First, the audiences' expressions are inferred through a multi-expression recognition model, which consists of an image-driven expression measurement recognition and a Bayesian network representing the co-existence and mutual exclusion relations among multi-expressions. Second, the videos' multi-emotion tags are obtained from the recognized expressions by another Bayesian Network, capturing the relations between expressions and emotions. Results of the experiments conducted on the JAFFE and NVIE databases demonstrate that the performance of expression recognition is improved by considering the relations among multiple expressions. Furthermore, the relations between expressions and emotions help improve emotional tagging, as our approach outperforms the traditional expression-based or image-driven implicit tagging methods.
               
            

@&#INTRODUCTION@&#

Recent years have seen a rapid increase in the size of digital video collections. Because emotion is an important component in the personalized classification and retrieval of digital videos, assigning emotional tags to videos has been an active research area in recent decades [1]. This tagging work is usually divided into two categories: explicit and implicit tagging [2]. Explicit tagging involves a user manually labeling a video's emotional content based on his/her visual examination of the video. Implicit tagging, on the other hand, refers to assigning tags to videos based on an automatic analysis of a user's spontaneous response while consuming the videos [2]. Although explicit tagging is a major method at present, it is time-consuming and brings users extra work. Implicit emotion tagging can overcome the above limitations of the explicit tagging.

The manifestations of human emotion are various, including physiological signals and visual behaviors, which are adopted as users' spontaneous nonverbal responses in implicit emotion tagging research. Physiological signals reflect subtle unconscious variations during emotion experience in bodily functions, which are controlled by the Sympathetic Nervous System (SNS). Most of these functions cannot be easily captured by other sensory channels or observation methods. However, to capture physiological responses, users are required to wear complex apparatuses, which may make some users feel uncomfortable. In contrast, when obtaining an implicit tag by visual behavior, no complex apparatus other than one standard visible camera is needed. Thus video-based approach is more easily applied outside the laboratory.

Facial expression analysis is one of the most feasible visual behaviors for implicit video tagging. Six basic expression categories proposed by Paul Ekman are the widely adopted descriptors, including anger, disgust, fear, happiness, sadness, and surprise [3]. Present expression-based video tagging research however assumes human's expression as a singular category. It means that only one particular category of expression appears at a time. This assumption may be challenged by psychology studies, which demonstrate that some expression manifestations are the combination of some specific basic expression categories [4] because of the underlying facial anatomy. In addition, some expressions may rarely appear together, such as happiness and sadness. These co-existent and mutual exclusive phenomenon of basic expressions should be considered in expression recognition. In this paper, multi-expression recognition is conducted. The relationships among expressions are taken into consideration by a Bayesian Network (BN).

Even though facial expression is the major visual manifestation of emotions, they are still different [5–8]. Thus, we cannot treat them totally similarly [9]. However, the relationships between them are rarely analyzed or considered [10]. In the video emotion tagging, the facial expressions are typically regarded as the emotions. Similar to expressions, multiple emotions may appear while subjects watch stimuli videos [11] or during our daily communications. Therefore, it is reasonable to tag a video's emotion with multi-emotion categories and to consider their relationships. In this paper, we use a BN to capture the relations between multiple emotions and multiple expressions.

In this paper, a multi-emotion tagging method is proposed. First, the multi-expressions of the user are recognized through a novel expression recognition model, which contains an image-driven expression recognition and a BN model exploiting the relations among multi-expressions. Then, the video's multi-emotion tags are obtained from recognized multi-expressions through another BN model considering the relations between the expressions and emotions. Expression recognition results on both JAFFE [12] and NVIE [13] databases demonstrate the importance of modeling multi-expression relations. Emotional tagging results on NVIE database validate the effectiveness of our approach.

@&#RELATED WORK@&#

To the best of our knowledge, study on emotional tagging of videos was first conducted at the beginning of the last decade by Moncrieff et al. [14]. Earlier studies mainly infer emotional tags directly from video content, and so they belong to the explicit approach.

Two kinds of tag descriptors are often used. One is the categorical approach. It uses subset of six basic emotions (happiness, sadness, surprise, fear, disgust, and anger) [15–18], and other emotion descriptor (such as boring, exciting and so on) [19–29]. The other is the dimensional approach [18,19,27–35], such as valence and arousal [18,28–34].

Various kinds of visual and audio features (e.g., color, motion, and sound energy) are extracted from videos [14,19,36,37]. The mapping from video features to emotional tags is accomplished by different machine learning methods, such as support vector machine [36], support vector regression [38], neural networks [23], hidden Markov model [17,18,25], dynamic Bayesian networks [27], conditional random fields [39], etc.

Only recently have researchers begun to realize that users' spontaneous physiological and behavior responses are useful features to the video's emotional tags. By recognizing users' emotion from their induced physiological/behavioral signals while watching the videos, the tags can be obtained automatically. This is called the implicit approach. Pantic and Vinciarelli [2] is the first to introduce the concept of implicit human-centered tagging, and identify the main problems with this research. Currently, implicit emotion tagging of videos mainly uses physiological signals or subjects' spontaneous visual behavior. In this section, we give a brief review of video emotion tagging and related work, such as indexing, retrieval, segmentation, and summarization of the emotional content from videos [40].

Several researchers have focused on implicit tagging using physiological signals, which could reflect subtle variations in the human body. Money and Agius [41,42] investigated whether users' physiological responses, such as Galvanic Skin Response (GSR), respiration, Blood Volume Pulse (BVP), Heart Rate (HR) and Skin Temperature (ST), can serve as summaries of affective video content. They collected 10 subjects' physiological responses during watching three films and two award-winning TV shows. Experimental results showed the potential of the physiological signals as external user-based information for affective video content summaries. They [43] further proposed Entertainment-Led Video Summaries (ELVIS) to identify the most entertaining sub-segments of videos based on their previous study.

Soleymani et al. [44,45] analyzed the relationships between subjects' physiological responses, the subject's emotional valence as well as arousal, and the emotional content of the videos. Moreover, Kierkels et al. [46] implemented an affect-based multimedia retrieval system by using both implicit and explicit tagging methods. Two multimodal databases are further constructed for implicit tagging. One is DEAP (Database for Emotion Analysis using Physiological signals) [47], in which electroencephalogram (EEG) and peripheral physiological signals, including GSR, respiration amplitude, ST, electrocardiograph (ECG), BVP, electromyography (EMG) and electrooculogram (EOG), were collected from 32 participants during their watching of 40 one-minute long excerpts of music videos. Frontal face videos were also recorded from 22 among 32 participants. The other database is MAHNOB-HCI [48], in which face videos, speech, eye gaze, and both peripheral and central nervous system physiological signals of 27 subjects were recorded during two experiments. In the first experiment, subjects self-reported their felt emotions to 20 emotion-induced videos using arousal, valence, dominance and predictability as well as emotional keywords. In the second experiment, subjects assessed agreement or disagreement of the displayed tags with the short videos or images.

While these two pioneer groups investigated many kinds of physiological signals as the implicit feedback, other researchers focused only on one or two kinds of physiological signals. For example, Canini et al. [49] investigated the relationship between GSR and affective video features for the arousal dimension. Smeaton and Rothwell [50] proposed to detect film highlights from viewers' HR and GSR. Toyosawa and Kawai [51] proposed to extract attentive shots with the help of subjects' heart rate and heart rate variability.

Two researcher groups considered event-related potential (ERP) as subjects' implicit feedback. One of them [52] attempted to validate video tags using an N400 ERP. Another group [15] attempted to perform implicit emotion tagging of multimedia content through a brain-computer interface system based on a P300 ERP.

Recently, Abadi et al. [53] proposed to differentiate between low versus high arousal and low versus high valence using the Magnetoencephalogram (MEG) brain signal.

Instead of using contact and intrusive physiological signals, Krzywicki et al. [54] adopted facial thermal signatures, a nonconstant and nonintrusive physiological signal, to analyze affective content of films.

These studies described above have indicated the potential of using physiological signals for the implicit emotion tagging of videos. However, to acquire physiological signals, subjects are usually required to wear several contact apparatuses, which may make them feel uncomfortable and hinder the real application of these methods.

Several researchers have turned to implicit tagging according to human spontaneous visual behavior, since it can be measured using non-contact and non-intrusive techniques, and easily applied in real life. Joho et al. [55] proposed to detect personal highlights in videos by analyzing viewers' facial activities. The experimental results on a dataset of 10 participants watching eight video clips suggested that compared with the activity in the lower part, the activity in the upper part of face tended to be more indicative of personal highlights. Arapakis et al. [56] proposed a multimodal recommender system that uses facial expression to convey users' emotional feedback. The experimental results on 24 participants verified the effectiveness of facial expression for the recommender system.

Other than focusing on subjects' whole facial activity, Ong and Kameyama [30] analyzed affective video content by using viewers' pupil sizes and gazing points. Experimental results on 6 subjects watching 3 videos showed the effectiveness of their approach.

Peng et al. [57] proposed to fuse users' eye movements (like blink or saccade) and facial expressions (positive or negative) for home video summarization. Their experimental results on 8 subjects watching 5 video clips, demonstrated the feasibility of both eye movements and facial expressions for video summarization application. They [58] also proposed and integrated an interest meter module into a video summarization system, and achieved good performance.

McDuff et al. [59] proposed to classify “liking” and “desire to watch again” automatically from spontaneous smile responses. Their study based on over 1500 facial responses to media collected from the Internet demonstrated the feasibility of using facial responses for content effectiveness evaluation.

The studies described above illustrate the development of methods for using spontaneous visual behavior in the implicit tagging of videos. However, the assumptions made by the above studies is that the expressions displayed by the subjects were the same as their internal feelings when they watched the videos. For this reason, most researchers have used the recognized expression directly as the emotional tag of the videos. However, research has indicated that internal feelings and displayed facial behaviors are related, but not always the same [5–7]. Facial expressions reflect not only emotions, but also social context etc. [8]. Thus, a certain emotion does not necessarily produce a certain spontaneous expression. Furthermore, present research of expression-based emotional video tagging assumes that subjects only display one expression while watching videos, thus there is only one emotional tag for a video. However, it is very hard to find one subject who can only express a high level of a single expression without the presence of any other categories either in day-to-day living or inside the laboratory emotion stimuli experiments [9,11]. From the existing expression databases [12,13] with multi-expression labels, we can observe that multiple expressions can be assigned for a singular expression image. For example, a sample with fear expression may co-exist with a certain degree of anger and surprise. On the other hand, the sample with happiness expression will not exist with the negative expressions, such as anger, sadness, and so on. The same is with the emotional tags of videos. For example, Gross and Levenson [11] developed a set of films to elicit eight emotion states. Based on their study, the videos that elicit amusement always elicit happiness and surprise. The videos that induce anger may also induce some degree of disgust, sadness, fear and surprise. The videos that induce disgust may also induce fear and surprise to some extent. However, the videos that induce anger and disgust may not induce high level of happiness. Those phenomena of co-existence and mutual exclusion for emotional categories are also revealed in [60]. Till now, there is little research considering multi-expression recognition and multi-emotion tagging of videos [61]. Although Kierkels et al. [46] and Kierkels and Pun [62] have considered multiple labels for emotional tagging, it does not exploit the dependencies among the labels. Each label is predicted individually.

Thus, in this paper, we treat expression–recognition and video emotional tagging as multi-label classification. We propose two BNs: one is to systemically capture the dependencies among expressions, and the other is to model the relations between multiple emotions and multiple expressions.

Compared to the related work, our contributions are as follows: First, we are among the first to exploit the coexistent and mutually exclusive relationships among multiple expressions, which is further exploited for multi-expression recognition. Second, we are the first to consider the relations between the expressions and the emotions in implicit video tagging.

@&#METHOD@&#

The framework of our implicit emotion tagging approach is shown in Fig. 1
                     , which consists of two modules: multi-expression recognition and multi-emotion tagging. The former module includes feature extraction, expression measurements extraction using an image-driven method, and multi-expression recognition using BN, which captures the relations among multi-expressions. The latter module infers multi-emotions of the stimuli video from the recognized multi-expressions. The details are described in the following sections.

In this paper, Active Appearance Model (AAM) [63] features are extracted from the apex expressional images, which capture both texture and shape [63] information. First, the subject's eyes are located automatically by using an eye location method based on AdaBoost and Haar features [64]. Then, all the expressional images are normalized to 400×400 grayscale images. After that, the face is labeled with 61 points as shown in Fig. 2
                           . Here, AAMs are trained in a person-independent manner, and the AAM tool from [65] is used. Finally, a 30-dimension appearance feature vector is obtained for each facial image, including shape and texture feature.

In order to select discriminative features for classification, the F-test statistic [66] is used for feature selection. The significance of all features can be ranked by sorting their corresponding F-ratios in descending order, and then 10-fold cross validation is adopted during training to empirically determine the number l and to select top l features. The F-ratio of feature x is calculated by using Eq. (1):
                              
                                 (1)
                                 
                                    
                                       F
                                       −
                                       ratio
                                       
                                          x
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      c
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                             
                                             
                                             
                                                n
                                                c
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            x
                                                            ¯
                                                         
                                                         c
                                                      
                                                      −
                                                      
                                                         x
                                                         ¯
                                                      
                                                   
                                                
                                                2
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      c
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                             
                                             
                                             
                                                
                                                   
                                                      n
                                                      c
                                                   
                                                   −
                                                   1
                                                
                                             
                                             
                                                σ
                                                c
                                                2
                                             
                                          
                                       
                                       ×
                                       
                                          
                                             
                                                n
                                                −
                                                N
                                             
                                             
                                                N
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           where xc
                            is the average of a single feature x within class c, σ
                           
                              c
                           
                           2 is the variance and 
                              
                                 x
                                 ¯
                              
                            is the global mean, and nc
                            is the number of samples of class c.

After feature selection, SVMs are adopted as the classifiers. The input of the SVM is the feature vector consisting of the selected features. The output of the SVM is a binary value, indicating whether this sample has a certain expression tag or not. There are a total of six classifiers, corresponding to six basic expression categories proposed by Ekman, including happiness, disgust, fear, surprise, anger and sadness, since the adopted databases in our experiments, i.e. the NVIE database and the JAFFE database, are annotated with only six basic expression categories. Finally, each sample can be attached with a binary string of 6 bits. The binary string is used as the input to the BN model in the following step.

As traditional facial expression recognition methods treat each expression category individually and do not consider the dependencies among categories in the training set, some valuable information may be lost. In order to model the semantic relationships among expression categories, we utilize a BN model for further expression recognition. As a probabilistic graphical model, BN can effectively capture the dependencies among variables in data. In our work, each node of the BN is an expression label, and the links and their conditional probabilities capture the probabilistic dependencies among expressions.

The BN learning consists of structure learning and parameter learning respectively. The structure consists of the directed links among the nodes, while the parameters are the conditional probabilities of each node given its parents.

Given the dataset of multiple target labels DL
                              ={T
                              
                                 i
                              }
                                 i
                                 =1
                              
                                 m
                              , where T
                              
                                 i
                              
                              ={λ
                              
                                 ij
                              }
                                 j
                                 =1
                              
                                 n
                              , m is the number of samples, and n is the number of labels, the structure learning is to find a structure G that maximizes a score function. In this work, we employ the Bayesian Information Criterion (BIC) [67] score function which is defined as follows:
                                 
                                    (2)
                                    
                                       
                                          Score
                                          
                                             G
                                          
                                          =
                                          
                                             
                                                max
                                                θ
                                             
                                          
                                          
                                          log
                                          
                                             
                                                p
                                                
                                                   
                                                      DL
                                                      |
                                                      G
                                                      ,
                                                      θ
                                                   
                                                
                                             
                                          
                                          −
                                          
                                             
                                                Di
                                                
                                                   m
                                                   G
                                                
                                             
                                             2
                                          
                                          logm
                                       
                                    
                                 
                              where the first term is the log-likelihood function of parameters θ with respect to data DL and structure G, representing the fitness of the network to the data; the second term is a penalty relating to the complexity of the network, and DimG
                               is the number of independent parameters.

To learn the structure, we propose to employ our BN structure learning algorithm [68]. By exploiting the decomposition property of the BIC score function, this method allows learning an optimal BN structure efficiently and it guarantees to find the global optimum structure, independent of the initial structure. Furthermore, the algorithm provides an anytime valid solution, i.e., the algorithm can be stopped at any-time with a best current solution found so far and an upper bound to the global optimum. Representing state of the art method in BN structure learning, this method allows automatically capturing the relationships among expressions. Details of this algorithm can be found in [68]. Examples of the trained BN structure are shown in Figs. 4 and 5.

After the BN structure is constructed, parameters can be learned from the training data. Learning the parameters in a BN means finding the most probable values 
                                 
                                    θ
                                    ^
                                 
                               for θ that can best explain the training data. Here, let λj
                               denote a variable of BN, and θjlk
                               denote a probability parameter for BN, then,
                                 
                                    (3)
                                    
                                       
                                          
                                             θ
                                             jlk
                                          
                                          =
                                          P
                                          
                                             
                                                
                                                   λ
                                                   j
                                                   k
                                                
                                                |
                                                p
                                                
                                                   a
                                                   l
                                                
                                                
                                                   
                                                      λ
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              where j
                              ∈{1,…,n}, l
                              ∈{1,…,rj
                              } and k
                              ∈{1,…,sj
                              }. Here n denotes the number of variables (nodes in the BN); pa(λj
                              ) represents the parent of variable λj
                              ; rj
                               represents the number of the possible instantiations for pa(λj
                              ); sj
                               indicates the number of the state instantiations for λj
                              . Hence, λ
                              
                                 j
                              
                              
                                 k
                               denotes the kth
                               state of variable λj
                              .

Based on the Markov condition, any node in a Bayesian network is conditionally independent of its non-descendants, given its parents. The joint probability distribution represented by BN can be denoted as: P(λ)=
                              P(λ
                              1, …, λ
                              
                                 n
                              )=∏
                                 j
                              
                              P(λ
                              
                                 j
                              |pa(λ
                              
                                 j
                              )). In this work, the “fitness” of parameters θ and training data D is quantified by the log likelihood function log(P(D|θ)), denoted as LD
                              (θ). Assuming the training data are independent, based on the conditional independence assumptions in BN, the log likelihood function is shown in Eq. (4).
                                 
                                    (4)
                                    
                                       
                                          
                                             L
                                             D
                                          
                                          
                                             θ
                                          
                                          =
                                          log
                                          
                                             
                                                
                                                   
                                                      ∏
                                                      
                                                         j
                                                         =
                                                         1
                                                      
                                                      n
                                                   
                                                   
                                                
                                                
                                                
                                                   
                                                      ∏
                                                      
                                                         l
                                                         =
                                                         1
                                                      
                                                      
                                                         r
                                                         j
                                                      
                                                   
                                                   
                                                
                                                
                                                
                                                   
                                                      ∏
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      
                                                         s
                                                         j
                                                      
                                                   
                                                   
                                                
                                                
                                                
                                                   θ
                                                   jlk
                                                   
                                                      n
                                                      jlk
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              where njlk
                               indicates the number of elements in D containing both λ
                              
                                 j
                              
                              
                                 k
                               and pal
                              (λj
                              ).

Since there is no hidden node in the BN, and the fully labeled training data are used in this work, maximum likelihood estimation (MLE) method can be described as a constrained optimization problem, which is shown in Eq. (5).
                                 
                                    (5)
                                    
                                       
                                          
                                             
                                             
                                                MAX
                                                
                                                
                                                   L
                                                   D
                                                
                                                
                                                   θ
                                                
                                             
                                          
                                          
                                             
                                                S
                                                .
                                                T
                                             
                                             
                                                
                                                   g
                                                   jl
                                                
                                                
                                                   θ
                                                
                                                =
                                                
                                                   
                                                      ∑
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      
                                                         s
                                                         j
                                                      
                                                   
                                                   
                                                
                                                
                                                
                                                   θ
                                                   jlk
                                                
                                                −
                                                1
                                                =
                                                0
                                             
                                          
                                       
                                    
                                 
                              where gjl
                               imposes the constraint that the parameters of each node sum to 1 over all the states of that node. Solving the above equations, we can get 
                                 
                                    
                                       θ
                                       jlk
                                    
                                    =
                                    
                                       
                                          
                                             n
                                             jlk
                                          
                                          
                                             
                                                
                                                   ∑
                                                   k
                                                
                                                
                                             
                                             
                                             
                                                n
                                                jlk
                                             
                                          
                                       
                                    
                                 
                              .

A complete BN model is obtained after parameter and structure learning. Given the expression measurements obtained in the first procedure, the true expression category of the input sample is estimated through BN inference. During the BN inference, the posterior probability of categories can be estimated by combining the likelihood from measurement with the learned prior model. Let λj
                         and M
                        λj
                        , j
                        ∈{1,…n}, denote the variable and the corresponding measurements obtained by image-driven methods respectively. Then, the probability of each expression combination pattern given the measurements is calculated as follows:
                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             
                                                Y
                                                ⋆
                                             
                                             =
                                             
                                                
                                                   
                                                      arg
                                                      
                                                      max
                                                   
                                                   
                                                      
                                                         λ
                                                         1
                                                      
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         λ
                                                         n
                                                      
                                                   
                                                
                                             
                                             
                                             P
                                             
                                                
                                                   
                                                      λ
                                                      1
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      λ
                                                      n
                                                   
                                                   |
                                                   M
                                                   
                                                      λ
                                                      1
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   M
                                                   
                                                      λ
                                                      n
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             ∝
                                             
                                                
                                                   
                                                      arg
                                                      
                                                      max
                                                   
                                                   
                                                      
                                                         λ
                                                         1
                                                      
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         λ
                                                         n
                                                      
                                                   
                                                
                                             
                                             
                                             
                                                
                                                   ∏
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   n
                                                
                                                
                                             
                                             
                                             P
                                             
                                                
                                                   M
                                                   
                                                      λ
                                                      j
                                                   
                                                   |
                                                   
                                                      λ
                                                      j
                                                   
                                                
                                             
                                             
                                                
                                                   ∏
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   n
                                                
                                                
                                             
                                             
                                             P
                                             
                                                
                                                   
                                                      λ
                                                      j
                                                   
                                                   |
                                                   pa
                                                   
                                                      
                                                         λ
                                                         j
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

The first part of the equation is the likelihood of λj
                         given the measurements and the second part is the product of the conditional probabilities of each category node λj
                         given its parents pa(λj
                        ), which are BN model parameters that have been learned. In practice, the belief propagation algorithm [69] is used to estimate the posterior probability of each category node efficiently.

Expression is the facial appearance of the subject's emotion, and the emotion tag is the latent feeling. In order to establish the relationship between the recognized expressions and the individual emotion states, another BN is constructed for video emotion tagging, whose structure is manually defined as shown in Fig. 3
                        . It includes 12 discrete nodes, representing six emotion tags Y
                        =
                        Y
                        1,…,Y
                        6 and six recognized expressions X
                        =
                        X
                        1,…,X
                        6. Each node has 2 states (1,0), representing whether this expression or emotion tag exists or not. The connections of these nodes capture the transition relationship from expression to emotion. We choose to use the six emotional prototypes mainly because of the database we used for our experiments. The NVIE database is annotated with only the six emotions. Our method however is not limited to the six emotions and it can be trained to classify other emotion categories.

Given the BN's structure as shown in Fig. 3, the BN parameters, i.e., the prior probability P(Yj
                        ) of Yj
                         (j
                        =1,…6), and the conditional probability P(Xl
                        |Yj
                        )(l,j
                        =1,…,6) are learned from the training data through the maximum likelihood estimation. After training, the posterior probability P(Yj
                        |X
                        =
                        X
                        1,…,X
                        6) of a testing sample is calculated according to the following equation:
                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             P
                                             
                                                
                                                   
                                                      Y
                                                      j
                                                   
                                                   |
                                                   X
                                                   =
                                                   
                                                      
                                                         X
                                                         1
                                                      
                                                      …
                                                      
                                                         X
                                                         6
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             =
                                             
                                                
                                                   P
                                                   
                                                      
                                                         Y
                                                         j
                                                      
                                                   
                                                   P
                                                   
                                                      
                                                         X
                                                         =
                                                         
                                                            
                                                               X
                                                               1
                                                            
                                                            …
                                                            
                                                               X
                                                               6
                                                            
                                                         
                                                         |
                                                         
                                                            Y
                                                            j
                                                         
                                                      
                                                   
                                                
                                                
                                                   P
                                                   
                                                      
                                                         X
                                                         =
                                                         
                                                            
                                                               
                                                                  X
                                                                  1
                                                               
                                                               ,
                                                               …
                                                               ,
                                                               X
                                                               6
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             =
                                             
                                                
                                                   P
                                                   
                                                      
                                                         Y
                                                         j
                                                      
                                                   
                                                   
                                                      
                                                         ∏
                                                         
                                                            l
                                                            =
                                                            1
                                                         
                                                         6
                                                      
                                                      
                                                   
                                                   
                                                   P
                                                   
                                                      
                                                         
                                                            X
                                                            l
                                                         
                                                         |
                                                         
                                                            Y
                                                            j
                                                         
                                                      
                                                   
                                                
                                                
                                                   P
                                                   
                                                      
                                                         X
                                                         =
                                                         
                                                            
                                                               
                                                                  X
                                                                  1
                                                               
                                                               ,
                                                               …
                                                               ,
                                                               X
                                                               6
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

Based on the calculated posterior probability P(Yj
                        |X
                        =
                        X
                        1,…,X
                        6) of each emotion node, the final emotion tag of the corresponding stimuli video is obtained as follows: Z
                        =(z
                        1,…,zj
                        ,…,z
                        6), where 
                           
                              
                                 z
                                 j
                              
                              =
                              
                                 
                                    
                                       arg
                                       
                                       max
                                    
                                    t
                                 
                              
                              
                              
                                 
                                    P
                                    
                                       
                                          
                                             Y
                                             j
                                          
                                          =
                                          t
                                       
                                    
                                    |
                                    X
                                 
                              
                              ,
                              t
                              ∈
                              
                                 0
                                 1
                              
                              ,
                              j
                              =
                              1
                              ,
                              …
                              ,
                              6
                           
                        .

@&#EXPERIMENTS@&#

Presently, three public databases can be used for implicit video emotion tagging. They are DEAP [47], MAHNOB-HCI [48] and NVIE [13]. The first two databases provide neither multiple emotion tags for a video, nor expression annotations. Thus, this paper adopted the NVIE database, which contains both posed expressions and video-elicited spontaneous expressions of more than 100 subjects. During the spontaneous expression collection experiments, the participants offered the self-report intensity of the six basic emotion categories, ranging from 0 to 4, to the stimuli video according to their emotion experiences. These can be regarded as the emotion tags of the videos. In addition, the NVIE database provides the facial expression intensity annotations of both apex facial images and image sequences in six categories, ranging from 0 to 2. The construction details of the NVIE database can be found in [13]. Therefore, spontaneous samples with six expression and emotion categories in the NVIE database are considered in this paper to recognize multiple expressions of users' and to assign multiple emotions to videos. Before the experiments, the expression and emotion annotations of each sample is converted to a binary vector according to the following strategy: if the annotation value of an expression or emotion category is larger than 0, the state of this expression or emotion is set to be 1, otherwise, it is set to be 0. Ultimately, 1154 samples are selected.

With respect to facial expression database, exhaustive surveys can be found in [70] and [71]. Most present expression databases only assign one expression category to one image or image sequence, except for the JAFFE and NVIE databases. Thus, the JAFFE database is adopted for multiple expression recognition experiment besides the NVIE database. The JAFFE database is a posed database consisting of only apex facial expression images, which are evaluated using a five-scale (1–5) intensity for six basic expression categories by 60 raters. An expression is present if the average intensity for this expression is higher than 3. There are some images whose intensities for 6 expressions are all less than 3. So in the experiment, those images are removed. After image preprocessing, we get 1154 images from NVIE and 188 images from JAFFE. Since both the NVIE database and JAFFE database provide the apex facial images, we hence need not identify the apex facial images. We just use the existing apex facial images in the databases. We do not employ the temporal information in our algorithm. Table 1
                         presents the distribution of samples.

The evaluation metric of multi-label classification is different from that of single label classification, since for each instance there are multiple labels which may be classified partly correctly or partly incorrectly. Thus, there are two kinds of commonly used metrics, example-based and label-based measures [72], evaluating the multi-label emotional tagging performance from the view of instances and labels respectively. We adopt both measures in this work. Let Ti
                         denote the true labels for instance i, and Zi
                         denote the predicted labels for instances i. Both are binary strings. m represents the number of the instances and n is the number of labels. The example-based measures: hamming loss, precision, and subset accuracy are defined in Eqs. (8)–(10). and the label-based measures: precision and accuracy, are defined in Eqs. (11)–(12).

Example-based measures:
                           
                              (8)
                              
                                 
                                    
                                       
                                          Hamming
                                          
                                          loss
                                          =
                                       
                                    
                                    
                                       
                                          
                                             1
                                             nm
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             
                                          
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                          
                                          
                                          
                                             
                                                I
                                                
                                                   
                                                      j
                                                      ∈
                                                      
                                                         T
                                                         i
                                                      
                                                      ∧
                                                      j
                                                      ∉
                                                      
                                                         Z
                                                         i
                                                      
                                                   
                                                
                                                +
                                                I
                                                
                                                   
                                                      j
                                                      ∉
                                                      
                                                         T
                                                         i
                                                      
                                                      ∧
                                                      j
                                                      ∈
                                                      
                                                         Z
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where I is the indicator function. Hamming loss measures the degree of distance between predicted labels and actual labels.
                           
                              (9)
                              
                                 
                                    Precision
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          m
                                       
                                       
                                    
                                    
                                    
                                       
                                          
                                             
                                                T
                                                i
                                             
                                             ∩
                                             
                                                Z
                                                i
                                             
                                          
                                       
                                       
                                          
                                             Z
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Precision is the proportion of correctly predicted labels to the total number of actual labels, averaged over all instances.
                           
                              (10)
                              
                                 
                                    Subset
                                    
                                    accuracy
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          m
                                       
                                       
                                    
                                    
                                    I
                                    
                                       
                                          
                                             T
                                             i
                                          
                                          =
                                          
                                             Z
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Subset accuracy indicates the ratio of completely correctly predicted samples to the total number of samples.

Label-based measures:
                           
                              (11)
                              
                                 
                                    Precision
                                    ,
                                    
                                       P
                                       micro
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                          
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             
                                          
                                          
                                          
                                             T
                                             i
                                             j
                                          
                                          
                                             Z
                                             i
                                             j
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                          
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             
                                          
                                          
                                          
                                             Z
                                             i
                                             j
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                        Pmicro
                         is the proportion of correctly predicted labels to the total number of actual labels, averaged over all labels.
                           
                              (12)
                              
                                 
                                    Accuracy
                                    ,
                                    Ac
                                    
                                       c
                                       micro
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                          
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             
                                          
                                          
                                          I
                                          
                                             
                                                
                                                   T
                                                   i
                                                   j
                                                
                                                =
                                                
                                                   Z
                                                   i
                                                   j
                                                
                                             
                                          
                                       
                                       nm
                                    
                                 
                              
                           
                        
                     


                        Accmicro
                         is the proportion of the correctly classified sample number in the total samples. It is the average accuracy over all labels.

For the hamming loss, the smaller the value the better the performance. For the other metrics, the larger the value the better the performance. In order to satisfy subject-independent, the subjects are divided into ten groups as equally as possible. Then 10-fold cross-validation is adopted, and for each validation, one group is taken as the testing set and the other nine groups are taken as the training set. Therefore, there is no intersection between the subjects of training set and those of testing set. T-test is used to examine the improvement significance.

To further evaluate the effectiveness of our approach, we conduct cross-database experiments in addition to the within database experiments. The NVIE database can be used for both expression recognition and emotional tagging, while the JAFFE database can only be used for expression recognition, since it is a posed facial expression database. Therefore we conduct two kinds of cross-database multi-expression recognition experiments. In the first experiment, we train the SVM classifiers using one database and test its performance on the other database. In the second experiment, we train the BN model using the labels from one database, and evaluate its performance on the other database. The results are summarized in Section 4.2.3.

We quantify the co-occurrence among different expressions using a conditional probability of P (λj
                           |λi
                           ), which measures the probability that expression λj
                            happens, given that expression λi
                            happens. Tables 2 and 3
                           
                            show the condition probabilities between different expressions for the NVIE and JAFFE databases respectively.

From Table 2, we can find that subjects can display multiple expressions. For instance, anger is often accompanied by sadness with high probability. There exist two kinds of relationships among emotions: co-occurrence and mutual exclusion. For example, P(anger|happiness) and P(sadness|happiness) are 0.00 and 0.016, suggesting that happiness rarely coexists with anger or sadness. Disgust and anger are co-occurrent together with a relatively high P(disgust|anger) of 0.495. Similar to NVIE database, JAFFE database also shows two relations: co-existence and mutual exclusion. For example, P(disgust|anger) is 0.965, showing that anger and disgust are present together frequently, while P(happiness|sad) is 0, indicating mutual exclusive relationship.

Compared the two tables, we find that the value of P (λj
                           |λi
                           ) of the NVIE database ranges from 0.0 to 0.535, while that of the JAFEE database ranges from 0.0 to 0.965. The top ranked and the bottom ranked P (λj
                           |λi
                           ) of the two databases are not exactly the same either, although most of them are similar. The inconsistency between the databases in terms of expression overlaps may be caused by the inherent database biases. After all, the NVIE database is a spontaneous database, while the JAFFE database is a posed facial expression database.

To systematically capture relationships among labels, we train a BN on each database. Figs. 4 and 5
                           
                            show the learned BNs from the NVIE database and JAFFE database respectively. The links in the structure represent the dependencies among labels. In Fig. 4, the links from happiness to fear and anger demonstrate that there are strong dependencies between the two pairs. From Table 2, we can see that the probabilities of P(fear|happiness) and P(anger|happiness) are 0.03 and 0, indicating mutual exclusive relations. In Fig. 5, the link from anger to disgust shows the co-occurrent relationship because the probability of P(disgust|anger) is 0.965 in Table 3.

Comparing two trained BNs with the two dependency tables, we find that the label pairs whose conditional probabilities are top ranked or bottom ranked are linked in the BNs for NVIE and JAFFE databases in most cases. It demonstrates the effectiveness of the BN structure learning method which can effectively capture the mutual exclusive and co-existent relationships among multiple expression labels. Some common co-existent and mutual exclusive relationships are well established in both structures. For example, the mutual exclusive expression pairs, sadness and happiness, disgust and happiness are modeled in both BN structures. The co-existent expression pair, sadness and disgust are shown in both BN. Besides, there exist some differences in two structures. For example, there is a link from anger to disgust in the JAFFE structure which is not shown in the NVIE structure. There exists a link from fear to sad in the NVIE structure which is not captured in the JAFFE structure. The reason for the differences is that the conditional probability distributions for expression pairs in the two database are different, indicating the database bias.


                           Tables 4 and 5
                           
                            show the experimental results of the NVIE database and JAFFE database respectively. From Table 4, we can find that our approach improves the performance of expression recognition by considering the relations among expressions, since most of the example based and label based measures of our approach are better than those of SVM classifier without considering the relations among expressions. Most of the improvements are significant. The improvement of subset accuracy demonstrates that our approach can obtain more completely correctly classified samples. Thus, our method makes the predictions more accurate than traditional methods. For NVIE database, the average accuracy rate of six expressions is increased from 77.3% to 80.3% by employing the relationships among expressions. For JAFFE database, our approach increases the average accuracy rate to 84.3% from 84.0%. The above experimental results demonstrate the effectiveness of our approach, since it can more effectively capture the dependencies among expressional labels.

The cross-database multi-expression recognition experimental results are summarized in Table 6
                           . From Table 6, we can observe the following: 1) For both cross-database experiments, their performances decrease compared to the corresponding within-database experiments. This performance decrease is expected because of the incongruity of the two databases and their inherent biases. In particular, the NVIE database is a spontaneous expression database, while the JAFFE is a posed expression database. Hence, the image features or the BN model learned from one database cannot completely characterize the emotions in another database. 2) The cross-database performance decrease, however, is asymmetric. Specifically, the cross-database performance for the JAFFE database is better than that of the NVIE database. This suggests that NVIE database is more general and more applicable to the JAFFE database. The reverse is, however, not true. 3) Comparing the two cross-database experiments (the “SVM+BN (cross)” row and the “SVM (cross)” row of Table 6), SVM+BN improves the performance over SVM. This suggests that the BN model, though learnt from a different database, can still generalize to another database despite the significant differences between the two databases.

The relationships between expression and emotion are shown in Table 7
                        . From Table 7, it can be seen clearly that there are multiple expressions for one emotion, and multiple emotions for one expression. For example, out of 432 self-reported happiness emotions, 346 samples present happiness expression, and 210 samples present surprise expression. It indicates the necessity to model the relations between expressions and emotions.

Based on the predefined BN in Section 3.2, the testing results obtained in Section 4.2.2 are used as the inputs of this model. The final video emotion tagging results are obtained based on the decision method defined in Section 3.2, and given in the “Exp-BN-Emo” row of Table 8
                        .

In order to verify the effectiveness of our multi-emotion tagging method, two comparative experiments are conducted. In the first comparative experiment, emotion tags are recognized by an image-driven method, which uses AAM features and SVMs, similar to the first step of expression recognition. The tagging results are shown in the “SVM-Emo” row of Table 8. In the second experiment, the recognized expressions are directly regarded as the subjects' emotions. This is the commonly adopted expression based video tagging method. The results are shown in the “RecExp-Emo” row of Table 8.

Comparing with these two experimental results, we can see that our approach (results showed in “Exp-BN-Emo” row) can get better results, since most of the example based and label based measurements of our approach are better than those of image-driven method and traditional expression-based emotion tagging. Most of the improvements are significant. The improvements of hamming loss indicate that the predicted results of our method are closer to the actual labels than the image-driven method and traditional expression based emotion tagging. Our approach gets an average accuracy of 75.4% for six emotions, while the image-driven method obtains an average accuracy of 72.1% and the expression-based emotion tagging gets an average accuracy of 74.2%. Compared with these two experimental results, the effectiveness of our video emotion tagging method considering the relationships among multi-expressions as well as the relationships among the expressions and emotions is well validated.

@&#CONCLUSION@&#

In this paper, a video emotion tagging model, considering the relationship among the facial multi-expressions, and the relationships among the expressions and emotions, is proposed and validated on JAFFE and NVIE databases. Experimental results demonstrate that: (1) the relations among the expressions can be well captured through the Bayesian Network's structures and parameters. Their relations help improve the performance of expression recognition. (2) Emotion tagging results, considering the relationships among the expressions and emotions, are better than those of image-driven methods and those obtained by directly regarding the expressions as the emotions. All these results verify the effectiveness of our proposed method in this paper. Since the BN is learned from the ground truth labels, it can only capture the genuine relationships between expression and emotion, and cannot model the masking expressions and emotions.

There are a few issues we would like to investigate in the future. First, besides facial expression, emotions can also be characterized by the facial action units (AUs). Facial expressions describe facial behavior globally, while facial action units represent facial muscle actions locally. Instead of using expression categories, AUs can also be used for emotional video tagging. Since current video tagging databases do not provide the AU labels of the viewers', we only use expressions as expression descriptors for emotional video tagging in this paper. In the future, we may investigate emotional tagging approach using AUs.

Second, in this paper the self-report is used to obtain the emotions of the subjects since it is the most commonly used method in previous research. However, the emotion of the subjects is very difficult to obtain, and even self-reports are not always reliable due to many problems, such as cognitive bias [73]. Recently, Healey's work [74] indicated that triangulating multiple sources of ground truth information, such as “In situ” rating, “End-of-Day” rating and “Third Party” rating, leads to a set of more reliable emotion labels. We may refer this work to obtain ground truth emotion labels in the future work.

Finally, as we discussed in Section 4.2.1, the incongruity between the databases and their inherent biases may cause challenges for cross-database expression recognition and video emotion tagging. The expression overlap of different databases may not be exactly the same due to the inherent database biases. We will further investigate this issue in the future.

@&#ACKNOWLEDGMENTS@&#

This work has been supported by the National Program 863 (2008AA01Z122), the National Natural Science Foundation of China (Grant No. 61175037, 61228304), the US NSF (A40338), Special Innovation Project on Speech of Anhui Province (11010202192), project from Anhui Science and Technology Agency (1106c0805008) and the Fundamental Research Funds for the Central Universities.

@&#REFERENCES@&#


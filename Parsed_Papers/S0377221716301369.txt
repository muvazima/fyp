@&#MAIN-TITLE@&#A two-stage classification technique for bankruptcy prediction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We design single and ensemble-based models to forecast bankruptcy.


                        
                        
                           
                           We estimate a set of financial profiles that represent several archetypal situations.


                        
                        
                           
                           We build bankruptcy prediction models that fit each financial profile.


                        
                        
                           
                           We compare model performance using these two ways of designing models.


                        
                        
                           
                           Profile-based models perform better than single and ensemble-based models.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Decision support systems

Finance

Bankruptcy

Forecasting

Financial profile

@&#ABSTRACT@&#


               
               
                  Ensemble techniques such as bagging or boosting, which are based on combinations of classifiers, make it possible to design models that are often more accurate than those that are made up of a unique prediction rule. However, the performance of an ensemble solely relies on the diversity of its different components and, ultimately, on the algorithm that is used to create this diversity. It means that such models, when they are designed to forecast corporate bankruptcy, do not incorporate or use any explicit knowledge about this phenomenon that might supplement or enrich the information they are likely to capture. This is the reason why we propose a method that is precisely based on some knowledge that governs bankruptcy, using the concept of “financial profiles”, and we show how the complementarity between this technique and ensemble techniques can improve forecasts.
               
            

@&#INTRODUCTION@&#

Most models that are designed by financial institutions or by scholars to forecast corporate bankruptcy, are usually built using a limited number of financial ratios that are measured once (Balcaen & Ooghe, 2006). Such models assume that all ratios that are likely to account for failure deteriorate in a systematic manner for all firms that may fail (Laitinen, 1991), and within a same time frame. This suggests that early warning signs of bankruptcy are embodied in the same variables and occur more or less at the same time and with the same magnitude. However, this is partly wrong. It is not uncommon that some firms that appear to be healthy fail unexpectedly, and that others that are likely to go bankrupt survive, and sometimes for a long time (D’Aveni, 1989).

These assumptions represent the main weaknesses of traditional models: they make it possible to estimate an average distance between the financial situation of a given company and a predefined situation of bankruptcy, while a state of bankruptcy is not reducible to a single reference state. One knows that failure is the result of a protracted process that occurs over time (Dimitras, Zanakis, & Zopounidis, 1996), that firms do not follow the same process (Laitinen, 1991), and that quite a few patterns of decline exist (D’Aveni, 1989). Therefore one understands that patterns of failure, that is to say prototype situations that firms may experience before going bankrupt, have the same character of multiplicity, and that a single model, whatever its accuracy, is not likely to properly capture such a variety of situations.

To overcome the limitations of traditional models, a first response was brought that was intended to take into account the diversity of situations that firms may face shortly before dying, but disregarding any a priori knowledge about bankruptcy. This response is embodied in techniques based on ensembles of models (bagging, boosting...): each component of an ensemble is specialized in discriminating a subset of firms, and the design of the ensemble relies on an algorithm, the aim of which is to ensure the complementarity of its different components. However, these techniques do not take into account any explicit characteristics about bankruptcy, and as a consequence the resulting models do not benefit from any knowledge one may have on this phenomenon. This is why we have designed a method that makes it possible to estimate the decision boundary between failed and non-failed firms using a priori knowledge about the different financial situations that firms may face at a given moment of their life, and for some of them, before going bankrupt. This method relies on the fact that different firm profiles exist, some of them typifying specific patterns of decline (D’Aveni, 1989) that lead to bankruptcy, and that one may take advantage of these profiles to design models. Thus, instead of building a single model, or an ensemble based on an algorithm that ignores everything that may lead firms to failure, we suggest designing a set of profiles that closely mirror the various situations firms may experience at a given moment of their existence, then to build as many models as there are profiles. These profiles are estimated using a vector quantization method (Kohonen map). So as to study the performance of this technique, we use several modeling methods to design, by profile, both single models (decision tree, discriminant analysis, logistic regression, neural network) and ensembles of models (bagging, boosting, random subspace). Then, we compare the results achieved with these models to those estimated using models that do not take into account profiles, and these comparisons are made with several samples so as to test the robustness of our method. The remainder of this paper is divided into five sections. Section 2 presents a literature review that explains our research question. Section 3 describes the data and modeling methods used in our study. Section 4 presents the way models are estimated and how model performance is calculated. Section 5presents and discusses the results and Section 6 concludes the paper.

@&#LITERATURE REVIEW@&#

Failure models are usually designed using financial ratios calculated with data from balance sheets and income statements. The use of ratios is as much due to their predictive power as to their availability and standardization. They generally allow for good discrimination between failed and non-failed firms (Altman, 1968), are easily available and are homogeneous because they are calculated in the same way within a given regulatory framework. Of course, there are other types of variables that can enhance model accuracy (Psillaki, Tsolas, & Margaritis, 2010) and that characterize dimensions other than the financial one, but they are scarcely used. Accounting models thus dominate the world of bankruptcy prediction. However, the way they are designed is one of their main weaknesses: they are estimated using a small number of variables that are often measured once and on average one year before the horizon of a prediction and, as a consequence, they rely on a uniform and instantaneous vision of firm health. This implies that two firms whose situations can be considered similar by a model may share the same estimated probability of failure whereas their real respective probabilities may severely diverge from each other. Indeed, some firms are able to acquire over time a sort of ability to face threats that allow them to survive more easily than others (D’Aveni, 1989), while apparently nothing suggests that these two kinds of firms are financially different. Some others weaken to such a point that they strongly look like bankrupt firms, but still manage to survive. Still others eventually die just because the carrying capacity of their economic environment has deteriorated (Moulton & Thomas, 1996), whereas if it has remained stable, they would have been able to pursue their activity.

So as to take into account such phenomena, some solutions have been suggested that are all rooted in the same principle: one tries to approximate the local peculiarities of the decision boundary between failed and non-failed firms by attempting to adapt the modeling process to variations that may occur within this boundary. For this purpose, instead of estimating a single model, one estimates an ensemble of models by ensuring that each one has its own particular expertise in a certain region of the decision space (Kuncheva, Skurichina, & Duin, 2002). In doing so, one gets a meta-model whose constituent elements, if they are sufficiently well chosen, make it possible to capture more information about the decision boundary than a single model does (Tumer & Ghosh, 1996). These techniques are rather efficient as shown in Table 1
                     
                     . This table presents the results achieved by the main studies that used ensemble techniques to forecast corporate bankruptcy. Panel A is devoted to traditional ensemble techniques such as bagging, boosting, random subspace...(called “traditional ensemble-based models”), and Panel B to ensembles that combine models designed using different modeling methods, such as, for example, a neural network combined with a discriminant analysis and a logistic regression (called “hybrid ensemble-based models”). Table 1 makes it possible to compare the performance of single models to that of ensemble of models.

In almost all cases, ensemble models have better predictive ability than single models. The difference between correct classification rates achieved with both types of models, and estimated using the size of the different test samples, is on average 2.87%. More precisely, this difference is 2.61% for “traditional” ensemble-based models, and 3.31% for “hybrid” models. These figures clearly demonstrate the real contribution of ensemble techniques, but also show that none of them can be considered more accurate than others. Nevertheless, in all studies mentioned in Table 1, the information provided through the use of many models is not explicitly dependent on any factors that may explain why some firms fail. In a certain sense, ensembles of models have the ability to capture, randomly and with an unstructured manner, some facets of the firm’s financial situation that single models cannot, and that might be related to some “profiles” or “states” that are more or less likely to lead to bankruptcy. That said, these facets are captured without providing the models with any explicit information about their real characteristics. However, these facets or profiles are not completely unknown and their specificities might be useful to enrich the information that ensembles are able to capture at random. One can imagine that this information may facilitate the way the decision space can be partitioned: for example, one might use several ensembles in conjunction with a technique that would specialize each of them on a given portion of the space, not randomly, but according to a subdivision of the boundary between failed and non-failed firms that would be done based on some knowledge about failure.

This notion of dividing the data space relies on an idea that has long been elaborated in the field of credit scoring. Indeed, since 1976, Chandler and Ewert (1976) had wondered whether specializing a credit scoring model by sex might lead to better results than those obtained using a single model. The method that consists in splitting a population into different groups and then developing a scoring model for each group was subsequently used by Banasik, Crook, and Thomas (1996), Lim and Sohn (2007), Finlay (2011) or Bijak and Thomas (2012). If the conclusions drawn by Chandler and Ewert (1976) underline the fact that such a specialization seems to improve the predictions, the results obtained by the other studies do not all reflect the same improvement, showing that a gain in accuracy is not systematic. This way of designing models has also been used in the field of bankruptcy prediction (Tsai, 2014), by first dividing the data space into different zones, using a data mining system, and then modeling each zone with a particular ensemble. The approach we present in this paper is similar to the approach proposed by Tsai (2014), but differs on a key-point: with Tsai’s approach, the creation of a model is solely data-driven, while with ours, the creation of a model is subject to a domain expertise.

The literature shows that firms that are about to fail do not share the same profile (D’Aveni, 1989) and that different archetypes exist, which typify both failed and non-failed companies (Miller & Friesen, 1977). We know there are a few failure processes and that models that are able to account for these processes achieve forecasts that are more accurate than those of models that do not (du Jardin, 2015). One may then think that if these profiles or archetypes do exist, and if they can be quantized accurately, the information they are likely to capture might very well complement the information that might be brought by an ensemble, and thus enhance model accuracy. Such profiles have been used to describe categories of firms that shared common characteristics (Serrano-Cinca, 1996), but they have never been used, to our knowledge, to serve as a basis for designing models as we propose to do.

The aim of our method is to design models that fit different firm profiles. To do so, we first estimate a typology of firms using Kohonen maps applied to a sample of companies, half of which went bankrupt. This typology is used to highlight a set of profiles that characterize all financial situations of these companies, ranging from the situation of the most efficient firms to that of the least efficient. Then, using a traditional modeling method, we build as many models as there are profiles. To estimate model prediction ability, we select another sample, and we look for the profile that best corresponds to the situation of each firm within this new sample. Once the profile is determined, we make a forecast using the corresponding model. Forecasts are then summed up so as to estimate the performance of this set of models. The procedure is then repeated, using a different modeling method each time.

Modeling methods have been selected from among the most commonly used classification techniques in the financial literature (Ravi-Kumar & Ravi, 2007): a decision tree called CART, discriminant analysis, logistic regression and a neural network, called multilayer perceptron or MLP. We have added several ensemble techniques (Sun, Li, Huang, & He, 2014), namely bagging, boosting and random subspace. Moreover, we have designed models without taking into account firm financial profiles. They serve as a benchmark to estimate the interest of the proposed method. To reinforce the robustness of all results, and to control for the effect of changes in firm economic environment on model estimation (Mensah, 1984), we use several samples that were collected over different periods that alternate phases of growth and downturn.

Data come from the Diane database (bureau Van Dijk), which stores balance sheets and income statements for over than 1.4 million French firms that file their annual reports through the French commercial courts. We have collected 11 learning samples and 11 test samples. With the learning samples, we have selected firms that filed their financial reports between 2002 and 2011, and with the test samples, we have chosen firms that filed their reports between 2003 and 2012. Each model has been designed with data from a given year n and tested with data from year 
                           
                              n
                              +
                              1
                           
                        . Table 2 shows the characteristics of each sample. So as to characterize the economic cycle of each period in France, we have added the change in bankruptcy growth rate to this table, that in GDP growth rate and, on the last line, an arrow that typifies the economic cycle.

We used samples that rely on data that were measured over a single year since it facilitates running multiple learning and test sequences. This method of collecting samples is rather different from the method that is recommended in practice, and presented by Stein (2007), where the size of a sample of historical data is increased year upon year so as to benefit from all available information. This principle lies at the root of many financial models used by banks. For instance, Bardos (1998) and Bardos (2007) showed that samples used by Banque de France are based on moving time windows: hence, for a given period studied, data that characterize non-failed firms are collected and added to data that characterize failed companies, but companies that will go bankrupt not only one year ahead, but also two and three years ahead.
                     

Moreover, each learning and test sample is made up of as many failed firms as there are non-failed firms, and each group of firm, within each sample, was selected at random. Our samples are made up of the same number of sound and unsound firms and as a consequence, from a statistical point of view, may lead to biased results. For instance, Zmijewski (1984) argued that using a non-random sample may lead to a “choice-based sample bias” and therefore to biased probabilities in standard probit or logit models. Indeed, Zmijewski (1984) demonstrated that, when one estimates a bankruptcy prediction model, the overall error rate of a logit or probit model remains rather stable as the proportion of failed and non-failed companies ranges from 50/50 to a 1/20 (1/20 corresponds, on average, to the true proportion of unsound firms among sound ones), but this result holds solely when the costs of misclassifications are equal, as noticed by Tian, Yu, and Zhou (2015). However, he empirically showed that the proportion of failed firms that are correctly classified by a model is significantly overestimated when compared to the same rate calculated using a random sample. Moreover, he clearly showed that the lower the number of failed firms within a learning sample, the less likely it is that a model is able to correctly forecast their fate. These results are confirmed by Platt and Platt (2002). Nevertheless, with some other modeling methods such as neural networks, this choice-based sample bias is less pronounced (Neves & Vieira, 2000). Tian et al. (2015) in particular show that with a neural network, as well as a support vector machine, a choice-based sample “demonstrates desirable accuracy” and achieves better results than those calculated with a random sample. However, when the cost of misclassification of failed firms is far higher than that of non-failed ones, the cut-off value should be fitted to the difference between these two costs. All these results show that, when the objective of a model is to accurately forecast firm fate, non-random samples can be considered reliable and can provide robust results, even though adjustments may be required in some situations.

Variables have been calculated using data from balance sheets and income statements: we solely used ratios. The initial set of variables with which models have been designed, was not determined arbitrarily, contrary to common practice. Indeed, this choice is often made according to the prevailing financial analysis orthodoxy that indicates what the “best” predictors of failure are. While this approach is legitimate since there is no bankruptcy theory (Lensberg, Eilifsen, & McKee, 2006) that could serve as a guide to select explanatory variables, we preferred selecting the initial set differently so as to design profiles that are not completely dependent upon our own arbitrary judgment. We first looked for the financial dimensions that appear in the literature as embodying the main factors of bankruptcy, or that are used by the few authors who have attempted to ground their models into theoretical foundations, such as Aziz, Emanuel, and Lawson (1988). We selected the dimensions that were most cited and then we chose the ratios that belong to each of them (Table 3). The dimensions are as follows: activity (efficiency with which a firm uses its resources), financial structure (allocation of a firm’s resources between debt and equity), profitability (a firm’s ability to generate profits), turnover (a firm’s ability to convert assets into cash), liquidity (a firm’s ability to meet its short-term debts) and solvency (a firm’s ability to meet its mid- and long-term debts).

The ratios, within each dimension, were chosen because they generally present a good mid-term discrimination ability, up to a 3-year horizon, so as to make models as insensitive as possible to short-term variations that may occur in the economic environment. We have also selected some ratios because, when carrying out our last research study, and especially when we computed the results presented in du Jardin (2015), we found that some ratios, that were not frequently selected by variable selection techniques based on linear hypotheses between model inputs and outputs, were selected more often with methods that fit neural networks characteristics, due to the non-linear relationships that exist between them and some other ratios.

Discriminant analysis is the first modeling method that was used to design failure models (Altman, 1968). This technique is able to partition the variable space using functions that attempt to discriminate observations belonging to different groups using a variance criterion. When the problem deals with a two-group classification, as it is the case with failure models, the function is unique and is estimated so as to maximize the between-group variance while minimizing the within-group variance. The function calculates a z score for each observation as follows:

                                 
                                    
                                       
                                          
                                             
                                                
                                                   z
                                                   =
                                                   
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         n
                                                      
                                                      
                                                         
                                                            w
                                                            i
                                                         
                                                         
                                                            x
                                                            i
                                                         
                                                      
                                                      +
                                                      
                                                         w
                                                         0
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              with xi
                               the explanatory variables and wi
                               the coefficients of the function.

To make a forecast, the z score of a given firm is compared to a threshold that embodies the boundary between failed and non-failed firms, and the firm is then classified into one of the groups depending on the position of its score with respect to the threshold. This method achieves optimal results when the variance/covariance matrices of each group are equal and when explanatory variables follow a multivariate normal distribution within each group.

Logistic regression was used to design failure models shortly after discriminant analysis (Ohlson, 1980) and presents two main advantages over the latter: it does not impose any condition for optimality on explanatory variables and allows the use of qualitative variables. To design a failure model, the method aims to estimate a function that calculates a z score for each firm. This score represents a probability of failure and can be expressed as follows:

                                 
                                    
                                       
                                          
                                             
                                                
                                                   z
                                                   =
                                                   
                                                      1
                                                      
                                                         1
                                                         +
                                                         
                                                            e
                                                            
                                                               −
                                                               
                                                                  (
                                                                  
                                                                     ∑
                                                                     
                                                                        i
                                                                        =
                                                                        1
                                                                     
                                                                     n
                                                                  
                                                                  
                                                                     
                                                                        w
                                                                        i
                                                                     
                                                                     
                                                                        x
                                                                        i
                                                                     
                                                                  
                                                                  +
                                                                  
                                                                     w
                                                                     0
                                                                  
                                                                  )
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              with xi
                               the explanatory variables and wi
                               the coefficients of the function. The coefficients are estimated using a maximum likelihood technique. With this method, a forecast is also achieved by comparing the z score of a given company to a threshold.

Decision trees were used to design bankruptcy models a few years after the use of logistic regression (Frydman, Altman, & Kao, 1985). A tree partitions the variable space using a series of splits, each of them being performed with a single variable. When the dependent variable is binary, each split is also binary: all splits then take the form of a tree made up of nodes, where each node splits the space into two branches. To design a tree, the CART algorithm (Breiman, Friedman, Olshen, & Stone, 1984) uses two processes. The first one governs the growing of the tree. During this phase, CART uses the Gini index of heterogeneity to perform a split. The tree grows until a stopping criterion is reached. Then, during a second phase, the tree is pruned so as to remove useless branches. Pruning is generally performed using a test sample and stopped when the predictive performance of a given tree is considered satisfactory. Terminal nodes, that is to say nodes that cannot be split, are assigned to a given class and these nodes are used to make forecasts.

Neural networks, and especially MLPs, began to be used to estimate failure models from the early 1990s. A network is usually made up of three layers when a classification task is to be performed: an input layer made up of as many neurons as there are explanatory variables, a hidden layer made up of a certain number of neurons and an output layer often made up of a single neuron, when the classification task at hand is binary. All neurons of a given layer are connected to those of the following layer. Each connection is represented by a (numeric) weight that embodies the strength of the relationship between two neurons and each neuron computes, using an activation function (most often a logistic function or the hyperbolic tangent), a weighted sum of its inputs. A failure model designed using a neural network calculates, for a given firm, a z score that represents its probability of bankruptcy, and that can be expressed as follows, with a network made up of one hidden layer, one output neuron and one bias per layer:

                                 
                                    
                                       
                                          
                                             
                                                
                                                   z
                                                   =
                                                   f
                                                   
                                                      (
                                                      f
                                                      
                                                         (
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            n
                                                         
                                                         
                                                            w
                                                            
                                                               i
                                                               j
                                                            
                                                         
                                                         
                                                            x
                                                            i
                                                         
                                                         +
                                                         
                                                            b
                                                            j
                                                         
                                                         )
                                                      
                                                      ·
                                                      
                                                         (
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            p
                                                         
                                                         
                                                            w
                                                            j
                                                         
                                                         )
                                                      
                                                      +
                                                      b
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              with f the activation function, n the number of variables, p the number of hidden neurons, xi
                               the neurons of the input layer, wij
                               the weights that represent the relationships between the input layer and the hidden layer, wj
                               the weights between the hidden layer and the output layer, bj
                               the bias weights of the hidden neurons, and b the bias weight of the output neuron.

Weights are estimated with observations whose class membership is known a priori and by using a learning process. During this process, weights are gradually adjusted, so as to reduce the discrepancy between network responses and those that are expected, using a cost function (most often an error function or the cross-entropy) that one seeks to minimize. The process is repeated until a stopping criterion is reached. A classification is then performed by comparing a given score to a threshold.

Ensemble techniques rely on a simple principle: using several models, instead of a single one, to benefit from additional information (Tumer & Ghosh, 1996). This gain in information is due to model diversity, and ensemble techniques are designed to produce such diversity. However, the relationship between diversity and the accuracy of an ensemble as well as the concept of diversity itself are still debatable as a sound theoretical framework is lacking (Kuncheva, 2003). This is why ensemble methods rely on heuristics where diversity is sought, especially by combining either algorithms or subsets of instances.


                           Finlay (2011) considers that ensemble modeling techniques can be divided into three groups. The first one, called “static parallel system”, corresponds to techniques where the classification rules are designed in parallel, and independently from each other, and where the final forecast is achieved using the forecast of each individual model, using different techniques to combine them. In some cases, the modeling technique is the same for all models, but not the data. For instance, random subspace uses the same modeling method but variables used to design a given model are picked up at random. Bagging also used the same modeling method but each model is designed using a subsample drawn at random with replacement from an initial sample. In other cases, the modeling method is not the same for all models, as with Stacking (Wolpert, 1992) or Cascade Generalization (Gamma & Brazdil, 2000).

The second one, called “multi-stage system”, represents techniques that build classification rules iteratively, where the rule designed at time t depends on the characteristics of the rule designed at 
                              
                                 t
                                 −
                                 1
                              
                           . The final prediction is then achieved using the same rule as that used with static parallel models, as it is the case with boosting. Other methods also build models iteratively, but each model is designed using a subsample drawn from the original sample.

The third one, called “dynamic classifier selection”, corresponds to methods where classification rules are built or applied to different regions of the decision space. In some cases classifiers are designed together and are then each applied to a specific region, whereas in some others they are built and fitted to a particular region. The regions are estimated using either an automated technique, such as a clustering method, or an expertise of the field under consideration.

From among all these methods, we have selected three of them based on their popularity in the financial literature, and whose main results are presented in Table 1 (Panel A): bagging, boosting and random subspace. We have also chosen these techniques because they are standard methods, the results of which can be easily compared with those in the literature. The algorithms used in our study are those presented below.

Bagging (Breiman, 1996) is performed by drawing bootstrap samples from an initial sample (observations are selected randomly and with replacement) and then by designing as many models as there are bootstrap samples, using any classification or regression technique. The final forecast is then obtained by combining the individual prediction of each model through a majority voting scheme. According to Breiman (1996), bagging can reduce the variance of the error achieved with the base model in some circumstances. However, Grandvallet (2001) showed that the stability of a forecast is not directly related to the variance, but to the presence of observations that have a greater influence than others on model estimation: then bagging can stabilize forecasts by equalizing the respective influence of observations. Conversely, bagging may be useless when all observations have the same impact on the phenomenon being studied or even harmful when the estimation process may take advantage of possible differences between observations. The bagging algorithm can be described as follows:

                                 
                                    •
                                    Step 1: Repeat k times, with 
                                          
                                             k
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             K
                                          
                                       :

Step 1.1: Draw a bootstrap sample 
                                          
                                             
                                                S
                                                k
                                             
                                             =
                                             
                                                (
                                                
                                                   S
                                                   
                                                      1
                                                   
                                                   k
                                                
                                                ,
                                                
                                                   S
                                                   
                                                      2
                                                   
                                                   k
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   S
                                                   
                                                      n
                                                   
                                                   k
                                                
                                                )
                                             
                                          
                                        from a learning sample 
                                          
                                             S
                                             =
                                             (
                                             
                                                S
                                                1
                                             
                                             ,
                                             
                                                S
                                                2
                                             
                                             ,
                                             …
                                             ,
                                             
                                                S
                                                n
                                             
                                             )
                                          
                                       ;

Step 1.2: Design a model Mk
                                       (s) using sample Sk
                                       ;

Step 2: Combine the forecasts of the Mk
                                       (s) models using a majority voting rule to achieve a final forecast:

                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            P
                                                            r
                                                            e
                                                            v
                                                            
                                                               (
                                                               s
                                                               )
                                                            
                                                            =
                                                            
                                                               arg max
                                                               
                                                                  g
                                                                  ∈
                                                                  
                                                                     {
                                                                     −
                                                                     1
                                                                     ;
                                                                     1
                                                                  
                                                                  }
                                                               
                                                            
                                                            
                                                               ∑
                                                               
                                                                  k
                                                                  =
                                                                  1
                                                               
                                                               K
                                                            
                                                            
                                                               δ
                                                               
                                                                  s
                                                                  i
                                                                  g
                                                                  n
                                                                  (
                                                                  
                                                                     M
                                                                     k
                                                                  
                                                                  
                                                                     (
                                                                     s
                                                                     )
                                                                  
                                                                  )
                                                                  ,
                                                                  g
                                                               
                                                            
                                                            
                                                            with
                                                            
                                                            
                                                               δ
                                                               
                                                                  i
                                                                  ,
                                                                  j
                                                               
                                                            
                                                            =
                                                            
                                                               {
                                                               
                                                                  
                                                                     
                                                                        
                                                                           1
                                                                           
                                                                           if
                                                                           
                                                                           i
                                                                           
                                                                           
                                                                           =
                                                                           
                                                                           
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        
                                                                           0
                                                                           
                                                                           if
                                                                           
                                                                           i
                                                                           
                                                                           ≠
                                                                           
                                                                           j
                                                                        
                                                                     
                                                                  
                                                               
                                                               }
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    

where 
                                 
                                    g
                                    ∈
                                    
                                       {
                                       −
                                       1
                                       ;
                                       1
                                    
                                    }
                                 
                               is the result of the forecast of a single model and corresponds to the label of the predicted group (failed or non-failed).

Bagging depends on the number k of models that are designed and this parameter cannot be determined a priori, as pointed out by Grandvallet (2001). It is therefore desirable to set up k using a cross validation technique or a test sample.

A certain number of extensions or versions of bagging have been proposed over time to improve its performance. They belong to two families: the first one, called “global bagging”, solely relies on data from a learning sample, and the second one, called “local bagging”, relies both on learning and test samples.

Below, we provide a few well-known examples of methods belonging to the first group. The version called “nice bagging” (Skurichina & Duin, 1998) makes it possible to combine, not all classifiers, but solely the best ones; bagging classifiers whose error is lower than that of the classifier estimated using the whole learning sample are finally chosen. This procedure makes the different models more stable that those calculated using standard bagging. The version called “trimmed bagging” (Croux, Joossens, & Lemmens, 2007) proposes removing the worst classifiers, hence those that achieve the largest error estimated on a learning sample. This version leads to results that are similar to those estimated with standard bagging when the modeling method tends to design unstable models, such as a classification tree. In contrast, it allows for the improvement of classification forecasts when models are considered to be stable, as it is the case when they are designed with an SVM (support vector machine). The version called “subbagging” (Bühlmann & Yu, 2002) relies on a technique where observations are drawn without replacement from an initial sample. This method achieves results that are very similar to those achieved with standard bagging, but appears to be computationally cheaper than the latter.

The second family tries to deal with a problem that previous techniques are not able to handle: when data are noisy, all these techniques perform poorly. To address this issue, this family relies on a technique that tries to minimize the error estimated on a test sample. The main learning technique is based on a method that uses a group of neighbors of each observation belonging to a test sample to customize all classifiers so as to reduce their overall error. Thus, Zhu (2007) has proposed a version called “lazy bagging” which adds several neighbors of each observation x, belonging to a test sample, to each bag so as to reduce the bias and the variance achieved using x. Other authors have suggested mixing the principles that govern “global” and “local” techniques within a single method, such as “glocal bagging” (Zhang, Zhang, Li, & Shi, 2008).

Unlike bagging, where models are estimated randomly and independently from each other, boosting (Freund, 1990; Schapire, 1990) creates models sequentially so as to progressively give more weight to observations that tend to be wrongly classified. During the sequence, the weight of observations that are not correctly classified at a given step is increased so as to reinforce their influence on the estimation done at the next step. The process is repeated until a stopping criterion is reached. The final prediction is performed by all models using a weighted majority voting scheme. Since there are several algorithms for boosting, the algorithm that corresponds to a modified version of AdaBoost (Skurichina & Duin, 2002):

                                 
                                    •
                                    Step 1: Assign a similar weight to each observation of the learning sample 
                                          
                                             S
                                             =
                                             (
                                             
                                                S
                                                1
                                             
                                             ,
                                             
                                                S
                                                2
                                             
                                             ,
                                             …
                                             ,
                                             
                                                S
                                                n
                                             
                                             )
                                             ,
                                          
                                        with 
                                          
                                             i
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             n
                                          
                                       : 
                                          
                                             
                                                w
                                                
                                                   i
                                                
                                                1
                                             
                                             =
                                             
                                                1
                                                n
                                             
                                          
                                       
                                    

Step 2: Repeat k times, with 
                                          
                                             k
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             K
                                          
                                       :

Step 2.1: Build a model Mk
                                       (s) with a weighted version 
                                          
                                             
                                                S
                                                k
                                             
                                             =
                                             
                                                (
                                                
                                                   w
                                                   
                                                      1
                                                   
                                                   k
                                                
                                                
                                                   S
                                                   1
                                                
                                                ,
                                                
                                                   w
                                                   
                                                      2
                                                   
                                                   k
                                                
                                                
                                                   S
                                                   2
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   w
                                                   
                                                      n
                                                   
                                                   k
                                                
                                                
                                                   S
                                                   n
                                                
                                                )
                                             
                                          
                                        of S;

Step 2.2: Classify observations from S using Mk
                                       (s);

Step 2.3: Calculate the weighted error of Mk
                                       (s):


                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               E
                                                               k
                                                            
                                                            =
                                                            
                                                               ∑
                                                               
                                                                  i
                                                                  =
                                                                  1
                                                               
                                                               n
                                                            
                                                            
                                                               w
                                                               
                                                                  i
                                                               
                                                               k
                                                            
                                                            e
                                                            
                                                               r
                                                               
                                                                  i
                                                               
                                                               k
                                                            
                                                            
                                                            with
                                                            
                                                            e
                                                            
                                                               r
                                                               
                                                                  i
                                                               
                                                               k
                                                            
                                                            =
                                                            
                                                               {
                                                               
                                                                  
                                                                     
                                                                        
                                                                           0
                                                                           
                                                                           if
                                                                           
                                                                           
                                                                              S
                                                                              i
                                                                           
                                                                           
                                                                           is
                                                                           
                                                                           correctly
                                                                           
                                                                           classified
                                                                        
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        
                                                                           1
                                                                           
                                                                           if
                                                                           
                                                                           
                                                                              S
                                                                              i
                                                                           
                                                                           
                                                                           is
                                                                           
                                                                           not
                                                                           
                                                                           correctly
                                                                           
                                                                           classified
                                                                        
                                                                     
                                                                  
                                                               
                                                               }
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    

Step 2.4: Estimate the confidence index c of model Mk
                                       (s): 
                                          
                                             
                                                c
                                                k
                                             
                                             =
                                             
                                                1
                                                2
                                             
                                             l
                                             n
                                             
                                                (
                                                
                                                   
                                                      1
                                                      −
                                                      
                                                         E
                                                         k
                                                      
                                                   
                                                   
                                                      E
                                                      k
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    

Step 2.5: If 0 < Ek
                                        < 0.5 then update weights: 
                                          
                                             
                                                w
                                                
                                                   i
                                                
                                                
                                                   k
                                                   +
                                                   1
                                                
                                             
                                             =
                                             
                                                w
                                                
                                                   i
                                                
                                                k
                                             
                                             
                                                e
                                                
                                                   
                                                      c
                                                      k
                                                   
                                                   e
                                                   
                                                      r
                                                      
                                                         i
                                                      
                                                      k
                                                   
                                                
                                             
                                          
                                       
                                    

And then normalize weights so that: 
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                w
                                                
                                                   i
                                                
                                                
                                                   k
                                                   +
                                                   1
                                                
                                             
                                             =
                                             1
                                          
                                       
                                    

Step 2.6: If Ek
                                        ≥ 0.5 then reset weights so that 
                                          
                                             
                                                w
                                                
                                                   i
                                                
                                                k
                                             
                                             =
                                             
                                                1
                                                n
                                             
                                          
                                        and restart at Step 2 with 
                                          
                                             k
                                             =
                                             k
                                             −
                                             1
                                          
                                       ;

Step 3: Combine forecasts of models Mk
                                       (s) using a weighted majority voting to achieve a final forecast:

                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            P
                                                            r
                                                            e
                                                            v
                                                            
                                                               (
                                                               s
                                                               )
                                                            
                                                            =
                                                            
                                                               arg max
                                                               
                                                                  g
                                                                  ∈
                                                                  
                                                                     {
                                                                     −
                                                                     1
                                                                     ;
                                                                     1
                                                                  
                                                                  }
                                                               
                                                            
                                                            
                                                               ∑
                                                               
                                                                  k
                                                                  =
                                                                  1
                                                               
                                                               K
                                                            
                                                            
                                                               c
                                                               k
                                                            
                                                            
                                                               δ
                                                               
                                                                  s
                                                                  i
                                                                  g
                                                                  n
                                                                  (
                                                                  
                                                                     M
                                                                     k
                                                                  
                                                                  
                                                                     (
                                                                     s
                                                                     )
                                                                  
                                                                  )
                                                                  ,
                                                                  g
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    

Boosting is proned to overfitting depending on the number of k iterations of the algorithm. Thus this parameter must be estimated using a cross validation technique or a test sample.

The very first boosting algorithms rely on the works by Schapire (1990) and Freund (1990). A little later on, Freund and Schapire (1996) designed a new algorithm that makes it possible to solve some practical problems due to the former, and which has become one of the most used versions of boosting: AdaBoost (adaptive boosting). Many other algorithms were then developed and differ from each other in the way they handle the weight attributed to data from learning and test samples. We present some notable examples here.

GentleBoost (Friedman, Hastie, & Tibshirani, 2000) uses a new function which assigns weight to observations, relying on a Newtonian method, and makes it possible to improve classifier accuracy by drastically decreasing the computation load. MadaBoost (Domingo & Watanabe, 2000), which is a modified version of AdaBoost, makes it possible to reduce the AdaBoost sensitivity to noisy data using a technique which increases the weight of those observations that are misclassified until they are finally correctly classified. BrownBoost, proposed by Friedman, Hastie, and Tibshirani (2001), shares the same goal as MadaBoost, but using a technique that gives less weight to observations that are more often misclassified. LPboost (Demiriz, Bennett, & Taylor, 2002) relies on a linear programming technique that is used to maximize the discrepancy between observations belonging to each class of the learning sample. This method converges to a solution faster than AdaBoost does but requires more computational time. TotalBoost (Warmuth, Liao, & Ratsch, 2006) also relies on an optimization technique and presents the same characteristic of convergence as that of LPBoost.

Random subspace was proposed by Ho (1998). Unlike previous methods, each model is built using a random selection of variables drawn for an initial set that characterizes a given sample of observations. The final forecast is performed, here as well, with a majority voting. The algorithm is as follows:

Let each observation Si
                              
                              
                                 
                                    (
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    n
                                    )
                                 
                               of a learning sample 
                                 
                                    S
                                    =
                                    (
                                    
                                       S
                                       1
                                    
                                    ,
                                    
                                       S
                                       2
                                    
                                    ,
                                    …
                                    ,
                                    
                                       S
                                       n
                                    
                                    )
                                 
                               be an r-dimensional vector 
                                 
                                    
                                       S
                                       i
                                    
                                    =
                                    
                                       (
                                       
                                          s
                                          
                                             i
                                             1
                                          
                                       
                                       ,
                                       
                                          s
                                          
                                             i
                                             2
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          s
                                          
                                             i
                                             r
                                          
                                       
                                       )
                                    
                                    ,
                                 
                               where r corresponds to the number of variables. Within the random subspace, each r-dimensional vector is replaced by a randomly selected q-dimensional vector, where q < r. A new learning sample 
                                 
                                    
                                       S
                                       k
                                    
                                    =
                                    
                                       (
                                       
                                          S
                                          
                                             1
                                          
                                          k
                                       
                                       ,
                                       
                                          S
                                          
                                             2
                                          
                                          k
                                       
                                       ,
                                       …
                                       ,
                                       
                                          S
                                          
                                             n
                                          
                                          k
                                       
                                       )
                                    
                                 
                               is then designed and is made up of n observations 
                                 
                                    
                                       S
                                       
                                          i
                                       
                                       k
                                    
                                    =
                                    
                                       (
                                       
                                          s
                                          
                                             i
                                             1
                                          
                                          k
                                       
                                       ,
                                       
                                          s
                                          
                                             i
                                             2
                                          
                                          k
                                       
                                       ,
                                       …
                                       ,
                                       
                                          s
                                          
                                             i
                                             q
                                          
                                          k
                                       
                                       )
                                    
                                 
                               that are characterized by q variables.

                                 
                                    •
                                    Step 1: Repeat k times, with 
                                          
                                             k
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             K
                                          
                                       :

Step 1.1: Randomly select q variables among the r initial variables;

Step 1.2: Design a model Mk
                                       (s) using sample Sk
                                       ;

Step 2: Combine the forecasts of the Mk
                                       (s) models using a majority voting rule to achieve a final forecast:


                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            P
                                                            r
                                                            e
                                                            v
                                                            
                                                               (
                                                               s
                                                               )
                                                            
                                                            =
                                                            
                                                               arg max
                                                               
                                                                  g
                                                                  ∈
                                                                  
                                                                     {
                                                                     −
                                                                     1
                                                                     ;
                                                                     1
                                                                  
                                                                  }
                                                               
                                                            
                                                            
                                                               ∑
                                                               
                                                                  k
                                                                  =
                                                                  1
                                                               
                                                               K
                                                            
                                                            
                                                               δ
                                                               
                                                                  s
                                                                  i
                                                                  g
                                                                  n
                                                                  (
                                                                  
                                                                     M
                                                                     k
                                                                  
                                                                  
                                                                     (
                                                                     s
                                                                     )
                                                                  
                                                                  )
                                                                  ,
                                                                  g
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    

Here as well, the parameter k is to be set up depending on the problem at hand.

Unlike bagging and boosting, random subspace did not give rise to particular variants, but rather to a series of works that analyzed different ways of using this method to deal with variable selection issues (Lai, Reinders, & Wessels, 2006), or to build prediction models that combine random subspace with resampling techniques such as bagging or boosting (Garcia-Pedrajas & Ortiz-Boyer, 2008; Panov & Dzeroski, 2007).
                           

A Kohonen map (Kohonen, 2001) is a clustering method that relies on a non-linear projection of a set of observations that are represented by n variables onto a two-dimensional space. This projection is performed so as to preserve, as well as possible, the structure and the topology of the input space. A map is generally made up of a set of neurons that are organized on a square or rectangular grid. A neuron is represented by a weight vector whose size corresponds to the number of variables of each observation. These weights are estimated using a learning process whose algorithm is as follows:

                              
                                 •
                                 Step 1: Repeat t times, with 
                                       
                                          t
                                          =
                                          1
                                          ,
                                          2
                                          ,
                                          …
                                          ,
                                          T
                                       
                                    :

Step 1.1: Set up the number of neurons k and randomly initialize the r weights 
                                       
                                          
                                             W
                                             j
                                          
                                          =
                                          
                                             (
                                             
                                                w
                                                
                                                   j
                                                   1
                                                
                                             
                                             ,
                                             
                                                w
                                                
                                                   j
                                                   2
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                w
                                                
                                                   j
                                                   r
                                                
                                             
                                             )
                                          
                                       
                                     of each neuron, 
                                       
                                          j
                                          =
                                          1
                                          ,
                                          2
                                          ,
                                          …
                                          ,
                                          k
                                       
                                    ;

Step 1.2: Select an observation 
                                       
                                          
                                             S
                                             i
                                          
                                          =
                                          
                                             (
                                             
                                                s
                                                
                                                   i
                                                   1
                                                
                                             
                                             ,
                                             
                                                s
                                                
                                                   i
                                                   2
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                s
                                                
                                                   i
                                                   r
                                                
                                             
                                             )
                                          
                                          ,
                                       
                                     characterized with r variables, from a learning sample 
                                       
                                          S
                                          =
                                          (
                                          
                                             S
                                             1
                                          
                                          ,
                                          
                                             S
                                             2
                                          
                                          ,
                                          …
                                          ,
                                          
                                             S
                                             n
                                          
                                          )
                                       
                                    ;

Step 1.3: Compute the distance between each neuron Wj
                                     and observation Si
                                     and find neuron Wc
                                     that is closer to Si
                                    : 
                                       
                                          
                                             ∥
                                          
                                          
                                             S
                                             i
                                          
                                          −
                                          
                                             W
                                             c
                                          
                                          
                                             ∥
                                             =
                                             m
                                             i
                                             n
                                          
                                          
                                             
                                                ∥
                                             
                                             
                                                S
                                                i
                                             
                                             −
                                             
                                                W
                                                j
                                             
                                             
                                                ∥
                                             
                                          
                                       
                                    
                                 

Step 1.4: Update the weights of all neurons located in the neighborhood of Wc
                                    :


                                    
                                       
                                          
                                             W
                                             
                                                j
                                             
                                             
                                                t
                                                +
                                                1
                                             
                                          
                                          =
                                          
                                             W
                                             
                                                j
                                             
                                             t
                                          
                                          +
                                          
                                             α
                                             t
                                          
                                          
                                             h
                                             
                                                c
                                                k
                                             
                                             t
                                          
                                          
                                             (
                                             
                                                S
                                                
                                                   i
                                                
                                                t
                                             
                                             −
                                             
                                                W
                                                
                                                   j
                                                
                                                t
                                             
                                             )
                                          
                                       
                                    
                                 

with α the learning step and hck
                                     the neighborhood function. Once the learning process is over, each neuron or set of neurons, can be used to find groups that are not known a priori.

We have chosen a Kohonen map as a clustering technique because it has some advantages over traditional methods. To analyze these advantages, we will compare a Kohonen map to the main types of clustering techniques that can be grouped into four categories. The first one corresponds to non-hierarchical partitioning methods, such as k-means. A Kohonen map share a common principle with this type of technique: the data space is grouped into clusters depending on the position of observations with respect to the center of each cluster (called centroid with k-means and neuron with a Kohonen map) using an index that measures the distance or the similarity between observations. However, the space designed with a Kohonen map, unlike that designed with k-means, is ordered thanks to the neighborhood function of its algorithm. A Kohonen map is then able to quantize data as k-means does but imposes a constraint on the order of the centroids. This is an essential characteristic and it is very useful to easily visualize the organization of a map. Indeed, the neurons being ordered, any cluster will be made up of contiguous neurons on a map. This is the reason why each different class of risk that is presented on each map shown on Fig. 1, is distributed along a single, continuous territory. However, a method such as k-means might also be used to design our profiles instead of a Kohonen map, but would be less practical if one would like to get a topological representation of data.

The second one represents hierarchical methods, whether they are ascending or descending. These methods rely on principles that are somehow different from those on which the former techniques rely, and especially those that govern the way clusters can be visualized, even if they are also based on measures of distance or similarity between observations. Indeed, they represent the way data are clustered through a sequence of nested partitions that can be visualized using a binary tree: at the top of the tree, all observations belong to a single cluster, and at the bottom, each observation belongs to a single cluster. As a consequence, once the clustering is performed, one has to determine a position in the tree that will lead to the partition one may choose. With this type of technique, one gets a hierarchy of partitions, whereas with k-means or a Kohonen map, one gets a set of centroids of a given partition. This representation around centroids is an essential means that makes it possible to represent territories at risk, as we did, and that is not directly possible with hierarchical clustering methods. Such techniques might also be used to design profiles, but would require selecting and choosing a partition and then calculating the centroid of each cluster.
                        

The third one corresponds to density-based methods. Unlike hierarchical methods, where observations are compared pairwise so as to calculate a distance or a similarity, density-based methods seek for regions in the data space where observations are more concentrated than elsewhere. If the criterion used to cluster data is quite different from that used with the latter methods, the result of the clustering process is similar: one solely gets a partition, but not a set of centroids.

The fourth one corresponds to mixture models. These methods con be considered an extension of those that belong to the k-means category. Indeed, instead of representing each group by an archetypal point, such as a centroid, they represent each group using a distribution while considering that the members of a group are the points that belong to the distribution that characterizes this group. Once again, this method solely calculates a partition.

Before designing a model, we analyzed the discrimination ability of each variable belonging to the initial set of variables using the quartiles of its distribution within each group of firms (failed and not failed). We analyzed the discrimination ability of each variable at a 1, 2 and 3-year horizon so as to avoid choosing predictors with solely very short-term discrimination ability, and therefore variables that are more sensitive than others to any change in economic conditions. We assessed, using bootstrap estimations, the confidence interval of each quartile (1st, 2nd and 3rd quartiles) and when the intervals of a majority of quartiles overlapped, the variable was removed. We were able to conduct such an analysis since we collected for each firm of a given sample, balance sheets and income statements over a period up to five years, when it was possible. Moreover, we analyzed the distribution of each variable within each group using a Mann–Whitney test to confirm their discrimination ability.

We also checked the correlations and chose the variables whose correlation with others was not greater than 0.6; Leshno and Spector (1996) and Atiya (2001) chose 0.7 while they were conducting studies whose context was similar to that of our study. To do so, we first compared the correlations of each pair of variables belonging to the same dimension and removed the variable that showed the highest correlations with all other variables. Then, we checked whether there was no remaining correlation larger than 0.6, and when that was the case, we removed the variables most correlated with all others.

Once the final set of variables was determined, we used it to design the financial profiles and the different models. Table 4 presents the correlations between variables of the final set selected with data from 2005, after removal of those with correlations higher than 0.6. Table 5
                         shows some statistics about the latter variables that demonstrate their individual discrimination power assessed over three time horizons: 1, 2 and 3 years prior to the determination of firm status (failed vs. non-failed). The individual discrimination ability was estimated using a Mann-
                           −
                        Whitney test since none of the variables were normally distributed.

This procedure was used with each learning sample. Due to a lack of space, we do not present the different sets of variables but we can, however, notice that models we designed show a very similar structure over consecutive years, when the economic conditions that govern firm environments are rather stable, and are made up of rather similar variables. Models are then not purely conjunctural. This is certainly due to the fact the initial variables present rather good mid-term discrimination ability.

We estimated one model per year and per modeling method. Variables were selected, with each model, among the final set of variables and using learning samples. With CART, the selection was performed during the pruning process. Trees were grown using 80% of each sample, and using a Gini coefficient to measure node heterogeneity, and were pruned using the remaining 20%. During pruning, the error achieved with each sub tree, after each node removal, was estimated and pruning was performed until all nodes were removed. We then looked for all sub trees whose error was statistically close to the lowest error, using a test for differences between proportions, and we chose the tree that was made up of the smallest number of variables. With discriminant analysis, variables were chosen using a backward search procedure and an evaluation criterion based on the estimation of an out of sample error: 80% of each sample was used to estimate model parameters and the remaining 20% to choose the best subset. The process was performed until no selected variable remained. When all variables were removed, we chose the subset with error statistically close to the lowest error and made up of the smallest number of variables. With logistic regression and the neural network, variables were selected using the same procedure. Moreover, with the neural network, the selection was performed using predefined network architecture, as it is commonly done (Leray & Gallinari, 1998). We used the Levenberg–Marquardt algorithm as an optimization technique, and designed networks with a single-hidden layer, one output neuron, one bias per layer, and the hyperbolic tangent as an activation function. To assess the size of the hidden layer of each network we conducted a set of experiments. We drew, from each learning sample, 100 sub samples made up of a random number of variables. 80% of each sub sample was used to estimate model parameters and the remaining 20% to assess model performance. Then we tested several sizes of the hidden layer (between 2 and 25 neurons) using different learning rates (between 0.05 and 0.5, with a 0.05 step). Results were averaged, the architectures that led to an error statistically close to the lowest error were then selected, and the network that was made up of the smallest number of neurons was finally chosen.

With each sample, we designed as many models as there are classification methods and ensemble techniques. With bagging, we estimated an ensemble made up of models designed with CART, another designed with discriminant analysis, another with logistic regression and the last one with the neural network. We used the same scheme with boosting and random subspace. So as to estimate the size of each ensemble (parameter k presented Section 3.3.2), we ran a set of experiments: k was set up between 10 and 200 and we used 80% of the data of a given sample to estimate models, and 20% to assess their accuracy. On average, the best results were achieved when the number of models ranged from 35 to 60, and we chose the latter value with all techniques.

The variables used to design each component of an ensemble, using a given modeling method, were the same as those that were selected to design single models. Hence, over a given period, variables that were used to build a single discriminant model were also used to estimate the parameters of each component of an ensemble model based on discriminant analysis. With the modeling methods that require some tuning, thus with CART and the neural networks, models parameters were re-estimated. With CART, and with each learning sample, we used a procedure similar to that used to design single models: trees were grown using 80% of a learning sample and pruned using the remaining 20%, pruning was performed until all variables were removed, and we selected the tree whose error was statistically close to the lowest error and that was made up of the smallest number of variables. With the neural networks, we tested different sizes of the hidden layer and different learning rates, as those presented in Section 4.2.1. Model parameters were assessed using 80% of a learning sample and the remaining 20% were used to estimate model performance. We selected the architectures that led to an error statistically close to the lowest error and we finally chose the network that was made up of the smallest number of neurons.

Finally, we used a majority voting to estimate the final forecast with bagging and boosting, and a weighted majority voting with random subspace, as Finlay (2011) did.
                        

We have represented all firms from our samples using variables that characterize the main explanatory factors of bankruptcy, also called “financial dimensions”. This level of representation is important because it ensures that the variables we used really embody all facets of the phenomenon. It is also important because financial dimensions are used to group firms according to common financial characteristics for which we assume they characterize archetypes of bankruptcy: since all companies do not go bankrupt for the same reasons, we assume that these differences should be embodied in particular forms which we called “profiles”, and that these forms exist in a finite number of states.

A profile, as we defined it, then reflects a particular financial structure shared by a subset of firms and which can be expressed as a set of positions on different scales that characterize their activity, financial structure, profitability, turnover, liquidity and solvency. Therefore, a given profile may represent firms with very high activity indicators and excellent turnover, solvency and liquidity indicators, that is to say firms that are able to use their resources with efficiency but also earn cash and pay their debts, but at the same time these firms may have a fragile financial structure and an average profitability because they maybe under-capitalized with a weak cost structure. Another profile may correspond to high performing firms on each financial dimension. Therefore, a profile represents a subset of firms that are similar along all dimensions.

Profile-based models were designed using a two-step procedure. During the first step, we quantized the financial situations of a sample of companies using Kohonen maps, one map per dimension, so as to precisely assess their characteristics. Indeed, one may think that, for example, the liquidity structure maybe different from the solvency structure, and as a consequence, the way liquidity should be quantized must be different from that used to quantize solvency. This is the reason why each dimension was quantized separately and independently from others. Once the quantization was done, we estimated the profile of each company: a profile is represented by the position of a firm on each map. A sequence of positions then corresponds to a profile. Then we clustered all these individual profiles into a set of archetypal profiles, and we finally assign each company the archetypal profile that was closest to its own profile so as to create subsets of firms that share a common financial situation. During the second step, with each subset of firms, hence for each profile, we designed several models using the previously described modeling techniques. The whole procedure is presented below in detail.

To design firm profiles, we used the same set of variables as that used to select the final predictors of the different models, that is to say the set of variables that were chosen after examining the quartiles of their distribution within each group of firms and their correlations with others (see 4.1). We designed a Kohonen map for each dimension using the a priori categorization of the latter variables, and as mentioned in Table 3. To do so, we ran a set of experiments. For each dimension, we first designed a set of maps with sizes ranging from 40 to 150 neurons. Then we compared all these maps using a measure that is presented in Kaski and Lagus (1996), which makes it possible to assess their ability to preserve both the topology of data and the information they convey, and which is independent from the number of neurons. This measure combines an index of continuity of the mapping between the data space and that of the map, and an index of the accuracy with which a map represents the data. We selected the maps that minimized this measure. Once the maps were chosen, we grouped all neurons of each map into a small number of classes, because the literature shows that there are few archetypes of failed and non-failed firms and thus that it is not relevant to consider a wide range of levels of liquidity, solvency, etc. The clustering was performed with a hierarchical ascendant classification method and a Ward criterion. We estimated, for each map, different partitions (2 to 10 groups) and we chose the most homogeneous one using the three best indices of homogeneity described by Milligan (1981).

The maps designed with data from 2005 are shown on Fig. 1. Each zone that corresponds to a cluster is labeled using a numerical scale ranging from 1 to a max value ≤8. Category 1 represents firms that are the most liquid, solvent and profitable, which have the soundest business activity and financial structure and that exhibit the highest receivables or inventory turnover ratios, etc., while the last category represents those that are on the opposite side. This ranking was assessed using the mean of all variables that characterize each group of firms belonging to the same profile.

The maps were then used to estimate firm profiles. For this purpose, for each firm of a given sample, we calculated its position on each of the six maps: a position was determined by seeking the neuron that was the closest to its financial situation, using a distance calculation. Then, we assigned each firm the number of the class to which the six neurons belong: a sequence of positions then makes it possible to define a firm’s individual profile. Given that the classes within each map were numbered with numerical values that correspond to a scale reflecting the position of different subsets of firms on each dimension, we quantized all individual profiles using another Kohonen map so as to define a limited number of general profiles. To estimate this latter map, we designed a set of small maps, made up of a number of neurons that ranged from 2 to 10, and we looked for the most homogeneous partition with the same indices as those used previously; each neuron of this map then represents a general profile. For example, Fig. 2 is a graphic portrayal of the eight general profiles (one per graph), calculated with data from 2005 and the maps presented on Fig. 1, which correspond to the best partition.

The X-axis on each graph represents the different dimensions or maps (activity, financial structure, profitability, turnover, liquidity and solvency), with one map per dimension, and the Y-axis, the number of classes used to cluster the neurons belonging to each of the six dimensions or maps; class 1 represents firms that occupy the best situation on a given scale and the last value represents firms that occupy the weakest situation. Vertical lines represent the number of classes within each dimension (4 for the dimension activity, 6 for financial structure, 8 for profitability, 8 for turnover, 8 for liquidity and 5 for solvency). The small circles symbolize the position of firms belonging to a given profile on each map. For instance, the first graph, on the left hand side of Fig. 2, represents the profile of firms that exhibit average activity indicators (the circle is situated between position 2 and position 3 on a scale that ranges from 1 to 4), that share an excellent financial structure (position near 2 on a scale that ranges from 1 to 6), have good profitability (position near 3 on a scale that ranges from 1 to 8), good turnover indicators (position near 3 on a scale from 1 to 8), good liquidity (position near 3 on a scale from 1 to 8) and excellent solvency (2 on a scale from 1 to 5).

The first graph on Fig. 2, which corresponds to the first group of firms, represents companies whose financial situations are among the best ones. The 7th and 8th graphs, on the opposite side, correspond to groups of firms experiencing a very challenging financial situation (too much debt, not enough shareholder funds), an extremely poor ability to use their resources and a level of liquidity that is considerably lower than that of the other groups of firms. The remaining five graphs are typified by one or two dimensions that are rather or very low. Thus, the third graph represents firms with average profitability and average activity indicators, while the fourth graph corresponds to firms with a highly fragile financial structure and low liquidity, the fifth, to firms with a bad financial structure and a very low liquidity, and the sixth, to firms with average profitability and an average financial structure, as well as low liquidity and solvency.
                        

Profile-based models (PBMs) were designed with the same methods as those that are presented above, but we estimated as many models as there are profiles in a given sample. For example, with data from 2005, as eight profiles were defined, we built, with each modeling technique, eight different models. Since the proportion of failed and non-failed firms within each profile is never the same, PBMs were estimated with the same number of both types of firms so as to avoid the over-representation of one group.

To study the predictive ability of PBMs, we first had to define the individual profiles of firms belonging to test samples. We therefore estimated the position of each company on the six maps presented previously. Then we sought the general profile that was the closest to the individual profile of each firm and we used the PBM that corresponded to this general profile to make forecasts. Finally, results achieved with the different PBMs were summed up to assess the performance of each method.

Model accuracy was performed by comparing the status of each company (failed or non-failed) with the predicted status, then by calculating the percentage of firms that were correctly classified. The cut-off value used to delimit the boundary between the two groups was first calculated using the value that maximizes the overall correct classification rate, as it is traditionally done. However, this method is suitable when the classes are well balanced in the population under consideration, which is not the case in the population from which our samples were drawn, because non-failed firms represent the majority group (on average, 98% of firms). Moreover, this estimation is independent from the cost of misclassification and, in the field of bankruptcy prediction, the cost of a type-I error may be largely greater than that of type-II errors (Balcaen & Ooghe, 2006). This is why we used a second way to estimate model accuracy, one that takes into account such cost. Moreover, taking into account the asymmetry between the costs of both types of error makes it possible to overcome the problem due to the asymmetry between bankruptcy and non-bankruptcy rates (He & Garcia, 2009). We then changed the rule used to compute the cut-off value of each individual model using what Frydman et al. (1985) called the observed expected cost of misclassification. The following function was used to estimate the cut-off value:

                           
                              
                                 
                                    
                                       
                                          
                                             Expected
                                             
                                             cost
                                             
                                             of
                                             
                                             misclassification
                                             =
                                             
                                                
                                                   
                                                      c
                                                      1
                                                   
                                                   
                                                      p
                                                      1
                                                   
                                                   
                                                      e
                                                      1
                                                   
                                                
                                                
                                                   n
                                                   1
                                                
                                             
                                             +
                                             
                                                
                                                   
                                                      c
                                                      2
                                                   
                                                   
                                                      p
                                                      2
                                                   
                                                   
                                                      e
                                                      2
                                                   
                                                
                                                
                                                   n
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        with c
                        1 and c
                        2 the respective costs of type-I and type-II errors, p
                        1 and p
                        2 the respective prior probabilities of failure and non- failure, e
                        1 and e
                        2 the respective type-I and type-II errors, and n
                        1 and n
                        2 the respective numbers of failed and non-failed firms. We estimated several cost scenarios since the choice of a given ratio c
                        1/c
                        2 depends on the purpose of a model and on the risk aversion of its user: we then set up c
                        2 constant and equal to 1 while c
                        1 was set up using values that range from 1 to 100.

When one uses an ensemble of models, on may choose a calculation method to estimate these costs. One way to do this is to use the base classifiers in their usual form, and change the ensemble algorithm (Sun, Kamel, Wong, & Wang, 2007). There are techniques that can be used to modify the boosting or the random subspace algorithm in this direction. Another and most common way is to change the cut-off value used with individual classifiers, as previously presented, and use these classifiers and the modified cut-off values with each ensemble technique (Kim, Kang, & Kim, 2013). This latter way was used.

Finally we used the area under the receiver operating characteristic curve (AUC) to estimate model performance. This curve makes it possible to represent, on one axis of a graph, the proportion of true positive (also called sensitivity), and on the other, the proportion of false positive (
                           
                              1
                              −
                              s
                              p
                              e
                              c
                              i
                              f
                              i
                              c
                              i
                              t
                              y
                           
                        ), where 
                           
                              s
                              e
                              n
                              s
                              i
                              t
                              i
                              v
                              i
                              t
                              y
                              =
                              t
                              r
                              u
                              e
                           
                         
                        positive/(true
                        
                           
                              p
                              o
                              s
                              i
                              t
                              i
                              v
                              e
                              +
                              f
                              a
                              l
                              s
                              e
                           
                         
                        negative) and 
                           
                              s
                              p
                              e
                              c
                              i
                              f
                              i
                              c
                              i
                              t
                              y
                              =
                              t
                              r
                              u
                              e
                           
                         
                        negative/(true
                        
                           
                              n
                              e
                              g
                              a
                              t
                              i
                              v
                              e
                              +
                              f
                              a
                              l
                              s
                              e
                           
                         
                        positive) while changing the cutoff value. The AUC is an interesting measure as it makes it possible to assess a model discrimination ability that does not depend on any matrix of misclassification costs. However, it has a major drawback, as analyzed by Hand (2009): this method uses different misclassification cost distributions for different classifiers, hence different metrics to evaluate different classification rules. This is why we complemented this measure with the H-statistics proposed by Hand (2009), which is intended to overcome the main drawback of the AUC
                           1
                        
                        
                           1
                           Some results were calculated using Spss (descriptive statistics presented in 3 and 4, and the clustering of neurons belonging to Kohonen maps), but most calculations were performed using our own implementations of all algorithm used in this study.
                        .

@&#RESULTS AND DISCUSSION@&#

We first analyzed the results achieved using each sample in order to study the error by period and see if there are trends that might show how the different models behave.


                        Tables 6
                        
                        –9 present the results estimated with a cut-off value that maximizes the overall correct classification rate. Table 6 compares the correct classification rates achieved using single models (Panel A) to those achieved using PBMs designed with a set of single models (Panel B). Table 7 compares the same rates calculated using bagging alone with those calculated using PBMs designed with bagging. Tables 8 and 9
                         do the same but with boosting and random subspace respectively. Within these tables, Panel C exhibits the p-values of a statistical test for differences between rates presented in Panel A and those in Panel B; p-values that correspond to situations where there is no significant difference (p-value ≥0.05) appear with underlined characters, and we added a 
                           
                              (
                              −
                              )
                           
                         symbol next to each p-value to indicate a significant difference in favor of models that are not based on profiles. These tables show that whatever the technique used to design them, in most cases PBMs lead to results that are significantly better than those achieved with models that are not profile-based, and in a few cases to results that are worse. Nevertheless, it seems that these results cannot be interpreted in the same manner depending and the samples and techniques used.
                        
                     

When we analyze the results by combining those obtained when the testing period is, from an economic point of view, rather different from that of the learning period (that is to say when we aggregate the results of years 2003, 2008, 2009, 2010 and 2012) and compare them to those obtained when the testing and learning period are rather similar (2004, 2005, 2006, 2007 and 2011), we can notice a trend where PBMs seem to be less sensitive than other models to changes in economic conditions. Thus, the difference between the results calculated during these two periods is 1.56% with single models and 0.62% with PBMs designed with a set of single models; it is 2.38% with SMs combined with bagging and 1.84% with PBMs also designed with bagging; and it is 2.07% with SMs designed using random subspace and 1.08% with PBMs designed with random subspace. In these situations, the difference is statistically significant, even if its magnitude is rather low. However, there is no difference between the results achieved with SMs (1.57%) and those achieved with PBMs (1.62%) when they are combined with boosting.

These results are rather interesting and, above all, unexpected since they show that, in some circumstances, PBMs are able to deal with some variations that may affect model accuracy. Indeed, several studies since that by Mensah (1984) have shown that any change that occurs within the economic environment of firms, between the period during which a model is designed and the period when it is used, leads to unstable forecasts. Presumably, in some situations, PBMs are also able to stabilize results because they can capture what allows some firms to better resist environmental shocks than others, as well as resist what SMs cannot.

PBMs thus lead to predictions that are, on the whole, more accurate than those of traditional models. In addition, they have in some situations the ability to better forecast the fate of some companies, which must still be confirmed, when the macroeconomic situation is rather fluctuant.

Then we analyzed the global error of the different models so as to characterize the added value of PBMs. We assume that PBMs are likely to achieve better forecasts than those achieved using traditional models, and that they might have performed well when combined with ensemble techniques, and hence improve their performance. So as to analyze the results achieved with the different techniques, we have aggregated the results calculated with the 10 test samples by class of models, and we have studied the contribution of PBMs compared to that of ensemble techniques. We then computed, on one hand, the difference between correct classification rates achieved with ensemble techniques and rates achieved with an SM, and on the other hand, the difference between those achieved with a PBM and those achieved with an SM (Table 10).

First of all, Table 10 shows that ensemble-based models are more accurate than SMs, in all cases. This result is consistent with the results presented in Table 1, where most of the time ensembles achieve the best results when compared to SMs.The overall gain we get, regardless of the methods, is 2.57%, which is nearly the gain provided by these methods in the literature (2.61%), as mentioned in Section 2. Table 10 also shows the additional gain provided by PBMs designed with ensemble techniques. The overall gain of PBMs is 4.74% when their performance is compared to that of SMs. All differences shown in Table 10 are statistically very significant (p-value ≤0.0001). We have not mentioned the p-values for the sake of economy of space. Thus the gain brought by PBMs is nearly 85% of that provided by ensemble techniques, and this gain is also significant.
                        
                     

Nevertheless the average gain in accuracy achieved using PBMs hides differences between methods. This is why we have mentioned the average gain by technique in Table 10. We notice that models designed with random subspace lead to better results than those achieved with SMs, but also better than those achieved with bagging and boosting and, at the same time, that PBMs designed with random subspace lead to even better results than those achieved solely with random subspace. With bagging and boosting, the gain provided by PBMs is not negligible but is well below that provided with random subspace. The results of a test for differences between rates presented in Panel A and Panel B from Table 10 are all statistically very significant (p-value ≤0.0001). We have not mentioned the corresponding p-values for the sake of economy of space.

These results show that a hierarchy exists between all models, with single models at the bottom, ensemble models in the middle, PBMs designed with ensemble techniques at the top, and PBMs designed with random subspace at the very top. The position of random subspace can probably be explained by the fact that the way it creates diversity, by combining variables, may better fit PBMs than the way used by other methods where diversity is produced using re-sampling techniques. Moreover, with samples from 2008 and 2009, PBMs designed with random subspace lead to much better predictions than any other PBM.

The results we presented previously were calculated using a cutoff value that maximized the overall correct classification rate. To overcome the limitations of such estimations, we have assessed model performance using different costs of misclassification, but also using measures that are independent from these costs.


                        Table 11 shows the misclassification costs by model and by cost of type-I error with, on Panel A, the costs estimated with non-profile-based models, called “traditional models”, and on Panel B, the costs estimated with PBMs. For the sake of clarity, we have just mentioned those calculated with a cost of type-I error equal to 1, 20, 40, 60, 80 and 100, and results were multiplied by 100. So as to better discern the differences between all models, Table 11 is complemented with Table 12. Table 12 presents the differences between misclassifications costs achieved with and without PBMs (Panel A) and shows which one of the two classes of models leads to the lowest costs (Panel B). These two tables first show that PBMs achieve costs that are similar to those of traditional models when the cost of type-I error (c
                        1) is low: on average, between 1 and 30. Beyond this, PBMs lead to costs that are, on the whole, lower than those of other models. Actually, PBMs manage to better classify both failed and non-failed companies (when c
                        1 is greater or equal to 40), than others, with a slight advantage for non-failed firms. These tables also show that random subspace achieves better results than the three other techniques, regardless of the base classifiers. They finally indicate that PBMs designed with random subspace achieve better results than those obtained when PBMs are estimated using bagging, boosting and single models, whatever the value of c
                        1. This latter result reinforces what we mentioned earlier about the complementarity that seems to characterize the relationship between PBMs and random subspace. Thus, when the c
                        1/c
                        2 ratio is high, which corresponds to a situation usually faced by financial institutions when assessing the risk of one of their counterparties, and to the loss associated with a bad decision, PBMs provide better forecasts than traditional models regardless of whether they are individual models or ensemble models.


                        Table 13 presents the results estimated using the AUC (Panel A) and the H-statistics by Hand (2009) (Panel B). We can first notice that the results achieved using the H-statistics are consistent with those achieved with the AUC. Indeed, models that present the best and worst results by the H-statistics are much the same as those that present such results, but using the AUC. We can also notice that these results reinforce the dominant position of random subspace among ensemble techniques, especially when PBMs are based on random subspace.

With traditional models, when one compares single models to ensemble-based models, bagging leads to better results than those obtained with single models, boosting leads to results that are slightly better than those achieved with bagging and, finally, those achieved with random subspace are fairly better than those achieved with the two other ensemble techniques. Moreover, with PBMs, boosting leads to better results that bagging, while random subspace does better than the latter methods. All these figures show that PBMs are indeed able to improve model accuracy, especially when they are designed with random subspace.

@&#CONCLUSION@&#

All results presented in this study are consistent with the assumptions we make in the introduction. Ensemble models seem to capture some variations within the decision space that individual models do not, thanks to the diversity they generate randomly, while profile-based models designed with these same techniques are also able to capture such variations, but more accurately, and this time not by chance but through to the knowledge they convey about bankruptcy. The profiles we have designed can thus be considered meta-variables that are likely to account for different situations that firms may experience at a given moment of their lives, which explain why firms are not equal in the face of bankruptcy, in contrast to traditional models which assume all firms are equal. In a certain sense, the way profile-based models partition the decision space can be usefully complemented by the way ensemble models create diversity among decision rules. However, these models present a major drawback. Their decision rule is not explicit and as a consequence, a financial analyst who needs to understand the forecasts of such models will not be able to do so – these models are black boxes. Moreover, in some countries, such as France, the allocation of a loan cannot legally be dependent on a single automated process. Therefore, even if a financial institution would provide its financial advisors, in charge of granting loans, with such models to help them assess the risk of their customers, these models would not be of any help if the advisors had to explain their final decision, particularly if the motives behind these decisions were solely based on ensemble models. However, this type of technique would be useful as an internal risk assessment tool.

@&#ACKNOWLEDGMENT@&#

We are very grateful to the three anonymous reviewers for their substantial contribution to the improvement of this article.

@&#REFERENCES@&#


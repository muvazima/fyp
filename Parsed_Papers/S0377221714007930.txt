@&#MAIN-TITLE@&#Using SVM to combine global heuristics for the Standard Quadratic Problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The Standard Quadratic Problem (StQP) is NP-hard with many local minimizers.


                        
                        
                           
                           Global unconstrained heuristics proposed for StQP do not dominate each other.


                        
                        
                           
                           We use Support Vector Machines to combine three global heuristics into one.


                        
                        
                           
                           We prove that our method allows to obtain a good heuristic.


                        
                        
                           
                           We use as benchmark test set the StQP deriving from the max clique problem.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Quadratic programming

Nonlinear programming

Data mining

Maximum Clique Problem

Global optimization

@&#ABSTRACT@&#


               
               
                  The Standard Quadratic Problem (StQP) is an NP-hard problem with many local minimizers (stationary points). In the literature, heuristics based on unconstrained continuous non-convex formulations have been proposed (Bomze & Palagi, 2005; Bomze, Grippo, & Palagi, 2012) but none dominates the other in terms of best value found. Following (Cassioli, DiLorenzo, Locatelli, Schoen, & Sciandrone, 2012) we propose to use Support Vector Machines (SVMs) to define a multistart global strategy which selects the “best” heuristic. We test our method on StQP arising from the Maximum Clique Problem on a graph which is a challenging combinatorial problem. We use as benchmark the clique problems in the DIMACS challenge.
               
            

@&#INTRODUCTION@&#

We concentrate on the Standard Quadratic optimization Problem (StQP) of the form

                        
                           (1)
                           
                              
                                 
                                    min
                                    {
                                    
                                       f
                                       0
                                    
                                    
                                       (
                                       y
                                       )
                                    
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       y
                                       ⊤
                                    
                                    A
                                    y
                                    :
                                    y
                                    ∈
                                    Δ
                                    }
                                 
                              
                           
                        
                     where Δ denotes the standard simplex in n-dimensional Euclidean space 
                        
                           
                              R
                              n
                           
                           ,
                        
                      namely

                        
                           (2)
                           
                              
                                 Δ
                                 =
                                 {
                                 y
                                 ∈
                                 
                                    R
                                    n
                                 
                                 :
                                 
                                    e
                                    ⊤
                                 
                                 y
                                 =
                                 1
                                 ,
                                 y
                                 ≥
                                 0
                                 }
                                 
                                 ,
                              
                           
                        
                     where 
                        
                           A
                           =
                           
                              [
                              
                                 a
                                 
                                    i
                                    j
                                 
                              
                              ]
                           
                           ∈
                           
                              R
                              
                                 n
                                 ×
                                 n
                              
                           
                        
                      is a symmetric matrix not positive semidefinite, e is the n-vector of all ones and the apex ⊤ denotes the transposition. We note by side that the more general case of 
                        
                           
                              Δ
                              K
                           
                           =
                           
                              {
                              y
                              ∈
                              
                                 R
                                 n
                              
                              :
                              
                                 c
                                 ⊤
                              
                              y
                              =
                              K
                              ,
                              y
                              ≥
                              0
                              }
                           
                        
                      where ci
                      > 0, i = 1, …, n and K > 0 can be converted into problem (1) by the simple transformation 
                        
                           
                              
                                 c
                                 i
                              
                              K
                           
                           
                              y
                              i
                           
                           →
                           
                              y
                              i
                           
                        
                     .

The problem is non-convex and we look for a global solution y*, i.e. a point y* such that f
                     0(y*) ≤ f
                     0(y) for all y ∈ Δ. It is well known that StQP is an NP-hard problem and that many local minimizers or stationary points that are not global exist. For a review of StQPs we refer e.g. to Bomze (2009) and references therein. Indeed, the StQP has been used as a tool to solve Maximum Clique Problems on the basis of a well-known reduction described by Motzkin and Strauss (Motzkin and Straus, 1965) for the unweighted case, and by Gibbons et al. (1997) for the weighted case. In some cases, the converse reduction, from a StQP to a nonlinear constrained weight clique problem, is used to develop exact and heuristic algorithms for solving a StQP (Scozzari and Tardella, 2008).

Problem (1) is a constrained non-convex optimization problem and possible solution techniques can be based on the use of different heuristics. Since the optimal solution is not known a priori and optimality cannot be certified, an heuristic stops returning the best solution found. In general, heuristics can perform differently in terms of best value found and in this sense it is not possible to state that one dominates the others. Hence it may be worthwhile to define a paradigm to combine different heuristics limiting the overall computational effort. Indeed, an obvious way of combining different heuristics consists in using each of them sequentially and store the best value obtained. However, in this way the computational effort grows up. In this framework, although the procedure described below can be applied to a finite number of unconstrained formulations, we focus on combining the different heuristics proposed in Bomze, Grippo, and Palagi (2012) and Bomze and Palagi (2005). Therein, equivalent unconstrained formulations of the original constrained problem (1) have been proposed that allow the use of standard unconstrained methods, in connection with a multistart global strategy. Actually, the results in Bomze et al. (2012) and Bomze and Palagi (2005) showed that none of the three formulations dominates the others in terms of best value found. This motivates the idea of combining the different heuristics in a clever way, so that the overall number of optimization runs is controlled. Indeed, combining sequentially the heuristics without any filter may lead to a great number of local optimizations, useless in locating the best solution.

Following this idea, in Cassioli, Di Lorenzo, Locatelli, Schoen, and Sciandrone (2012) an algorithm called LeGO (Learning for Global Optimization) has been proposed as a variation of a multistart unconstrained method. It tries to learn the unknown relationship between the starting condition (initial point or parameters) and the final value obtained by the method. To this aim, using as learning dataset the first runs of the algorithm (epochs) with a given initial setting, Cassioli et al. proposed to use a machine learning tool, in particular Support Vector Machines (SVMs), to estimate the outcome of future runs. In our context this can be directly applied to each single unconstrained formulation, reducing the number of unconstrained minimizations required. However, it may happen that a given starting point is “promising” for every unconstrained formulation so that the local procedure should be applied on each of them. We propose to use SVMs to tackle also this issue. The paper is structured as follows: in Section 2 we recall properties of the StQP and the continuous Maximum Clique formulation proposed in Bomze (1997). In Section 3 we report the three unconstrained formulations introduced in Bomze et al. (2012) and Bomze and Palagi (2005). In Section 4 we present the trivial multistart global strategy THEM that combines sequentially the three unconstrained formulations. In Section 5 we briefly introduce Support Vector Machines and in Section 6 we introduce the Global heuristic Optimization Strategy by SVM (GHOSt
                     SVM). Finally in Section 7 we test GHOSt
                     SVM on a set of problems arising from a continuous formulation of the Maximum Clique from the DIMACS challenge (Johnson and Trick, 1996). We show that SVMs are a powerful tool to combine different formulations.

We concentrate on the NP-hard Standard Quadratic optimization Problem (StQP) of the form (1)
                     
                        
                           
                              
                                 min
                                 
                                    {
                                    
                                       f
                                       0
                                    
                                    
                                       (
                                       y
                                       )
                                    
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       y
                                       ⊤
                                    
                                    A
                                    y
                                    :
                                    
                                       e
                                       ⊤
                                    
                                    y
                                    =
                                    1
                                    ,
                                    y
                                    ≥
                                    0
                                    }
                                 
                                 .
                              
                           
                        
                     Problem (1) arises in many applications; among them we are particularly interested in a continuous formulation of the Maximum Clique Problem. Given an undirected graph G = (V, E) with vertex V and edge set E⊂V × V, a clique is a subset of V with the property that all the nodes are pairwise adjacent (a complete subgraph of G). The Maximum Clique Problem consists on finding a clique of G of maximum cardinality ω*. This problem has many different continuous formulations as a non-convex optimization problem. For a survey we refer to Bomze et al. (1999). The first continuous formulation of the Maximum Clique Problem as an StQP goes to the so called Motzkin–Strauss formulation (Motzkin and Straus, 1965); the value of the maximum clique ω* is obtained as (1 − f*)−1 where f* denotes the optimal value of the indefinite quadratic program

                        
                           
                              
                                 max
                                 {
                                 
                                    y
                                    ⊤
                                 
                                 
                                    A
                                    G
                                 
                                 y
                                 :
                                 
                                 y
                                 ∈
                                 Δ
                                 }
                              
                           
                        
                     with 
                        
                           A
                           G
                        
                      being the adjacency matrix of the graph, namely aij
                      = 1 if (i, j) ∈ E and aij
                      = 0 otherwise, and Δ the unit simplex defined in (2). This formulation has the drawback of having spurious solutions, namely local solutions that are not in a one-to-one correspondence with cliques of the original combinatorial problems.

Later Bomze (1997) proposed a stronger formulation obtained by perturbing the Motzkin–Strauss objective function adding the term 
                        
                           
                              
                                 1
                                 2
                              
                              
                                 
                                    ∥
                                    y
                                    ∥
                                 
                                 2
                              
                              ,
                           
                        
                      so that the Maximum Clique Problem is written as:

                        
                           (3)
                           
                              
                                 max
                                 
                                    {
                                    
                                       y
                                       ⊤
                                    
                                    
                                       (
                                       
                                          A
                                          G
                                       
                                       +
                                       
                                          1
                                          2
                                       
                                       I
                                       )
                                    
                                    y
                                    :
                                    
                                    y
                                    ∈
                                    Δ
                                    }
                                 
                                 
                                 ,
                              
                           
                        
                     which is an StQP of the type (1) with matrix 
                        
                           
                              A
                              =
                              −
                              2
                              (
                              
                                 A
                                 G
                              
                              +
                              
                                 1
                                 2
                              
                              I
                              )
                           
                        
                     .

The regularized version (3) avoids the drawback of the original Motzkin–Strauss formulation. The main result proved in Bomze (1997) is reported here:

                        Theorem 1
                        Let G be an undirected graph and consider problem (3). Then the following assertions are equivalent:

(a) 
                              
                                 y
                                 ¯
                              
                            is a strict local maximum for problem (3);

(b) 
                              
                                 y
                                 ¯
                              
                            is a local maximum for problem (3);

(c) 
                              
                                 
                                    y
                                    ¯
                                 
                                 =
                                 
                                    1
                                    
                                       ω
                                       ¯
                                    
                                 
                                 
                                    ∑
                                    
                                       i
                                       ∈
                                       σ
                                    
                                 
                                 
                                    e
                                    i
                                 
                              
                            where σ is a maximal clique of cardinality 
                              
                                 ω
                                 ¯
                              
                           .

If one of the above conditions (and therefore all) is met, the objective 
                              
                                 
                                    
                                       
                                          y
                                          ¯
                                       
                                       ⊤
                                    
                                    
                                       (
                                       
                                          A
                                          G
                                       
                                       +
                                       
                                          1
                                          2
                                       
                                       I
                                       )
                                    
                                    
                                       y
                                       ¯
                                    
                                 
                              
                            equals the value 
                              
                                 1
                                 −
                                 
                                    1
                                    
                                       2
                                       
                                          ω
                                          ¯
                                       
                                    
                                 
                              
                           .

Assertions (a) and (b) imply that every local solution of (3) is strict, so that there is no problem in identifying a clique σ from 
                        
                           y
                           ¯
                        
                     . Indeed a vertex i ∈ σ if and only if 
                        
                           
                              
                                 y
                                 ¯
                              
                              i
                           
                           >
                           0
                        
                      and 
                        
                           
                              ω
                              ¯
                           
                           =
                           
                              1
                              2
                           
                           
                              
                                 (
                                 1
                                 −
                                 
                                    f
                                    ¯
                                 
                                 )
                              
                              
                                 −
                                 1
                              
                           
                        
                     . Obviously σ* is a maximum clique of G if and only if y* is the global solution of (3).

General constrained algorithms are able to locate points satisfying first order necessary conditions. Since the constraints are linear, the constraint qualifications are met and the Karush–Kuhn–Tucker (KKT) conditions are necessary for optimality. The first-order KKT necessary optimality conditions state that a feasible point 
                        
                           y
                           ¯
                        
                      is a local solution of problem (1) if a scalar 
                        
                           λ
                           ¯
                        
                      exists such that

                        
                           (4)
                           
                              
                                 {
                                 
                                    
                                       
                                          
                                             
                                                
                                                   (
                                                   A
                                                   
                                                      y
                                                      ¯
                                                   
                                                   )
                                                
                                                i
                                             
                                             +
                                             
                                                λ
                                                ¯
                                             
                                             =
                                             0
                                          
                                       
                                       
                                          
                                             for
                                             
                                             
                                                i
                                                :
                                                
                                                   
                                                      y
                                                      ¯
                                                   
                                                   i
                                                
                                                >
                                                0
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   (
                                                   A
                                                   
                                                      y
                                                      ¯
                                                   
                                                   )
                                                
                                                i
                                             
                                             +
                                             
                                                λ
                                                ¯
                                             
                                             ≥
                                             0
                                          
                                       
                                       
                                          
                                             for
                                             
                                             
                                                i
                                                :
                                                
                                                
                                                   
                                                      y
                                                      ¯
                                                   
                                                   i
                                                
                                                =
                                                0
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        
                     From (4) we get also that the Lagrange multiplier is uniquely determined from 
                        
                           y
                           ¯
                        
                      as 
                        
                           
                              λ
                              ¯
                           
                           =
                           −
                           
                              
                                 y
                                 ¯
                              
                              ⊤
                           
                           A
                           
                              y
                              ¯
                           
                           =
                           −
                           2
                           
                              f
                              0
                           
                           
                              (
                              
                                 y
                                 ¯
                              
                              )
                           
                        
                     .

Of course second-order necessary optimality conditions can also be introduced to refine among KKT points but we are not going to use them in this paper.

Problem (1) is a constrained optimization problem and possible solution techniques are based on the solution of equivalent unconstrained non-convex problems, so that well established, robust and efficient unconstrained methods can be used.

In Bomze et al. (2012) and Bomze and Palagi (2005) different formulations have been proposed that lead to three unconstrained problems of the type

                        
                           (5)
                           
                              
                                 
                                    min
                                    
                                       x
                                       ∈
                                       
                                          D
                                          i
                                       
                                    
                                 
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 
                                 
                                 for
                                 
                                 i
                                 ∈
                                 
                                    {
                                    1
                                    ,
                                    2
                                    ,
                                    3
                                    }
                                 
                              
                           
                        
                     where 
                        
                           
                              f
                              i
                           
                           :
                           
                              R
                              n
                           
                           →
                           R
                        
                      are continuously differentiable functions over the open set 
                        
                           
                              D
                              i
                           
                           ⊆
                           
                              R
                              n
                           
                        
                      and may depend on a set of parameters Ωi
                      to be chosen appropriately, in order to get equivalence between problem (1) and the ith problem (5). The three different formulations have been used in Bomze et al. (2012) and Bomze and Palagi (2005) to define three different simple multistart heuristics hi
                      for solving the StQP.

We report in this section the main steps that lead to the three unconstrained problems (5) together with their main properties.

The definition of the first two unconstrained problems i = 1, 2 are based on the construction of an intermediate constrained problem, obtained by the substitution 
                        
                           
                              y
                              i
                           
                           =
                           
                              x
                              i
                              2
                           
                        
                      into (1) to get rid of the sign constraints yi
                      ≥ 0. Then the condition e
                     ⊤
                     y = 1 reads ‖x‖2 = 1, and Bomze and Palagi (2005) obtained the following homogeneous problem of minimizing a fourth-order polynomial over the unit sphere

                        
                           (6)
                           
                              
                                 min
                                 
                                    {
                                    
                                       1
                                       2
                                    
                                    
                                       x
                                       ⊤
                                    
                                    X
                                    A
                                    X
                                    x
                                    :
                                    
                                       
                                          ∥
                                          x
                                          ∥
                                       
                                       2
                                    
                                    =
                                    1
                                    :
                                    x
                                    ∈
                                    
                                       R
                                       n
                                    
                                    }
                                 
                              
                           
                        
                     where X denotes n × n the diagonal matrix with elements xi
                     . It has been proved that any local/global solution of problem (6) provides a local/global solution of problem (1) and vice versa. Problem (6) has the advantage to have a simple constraint that can be tackled easily. The counterpart is that the transformation 
                        
                           
                              y
                              i
                           
                           =
                           
                              x
                              i
                              2
                           
                        
                      may produce spurious KKT points which do not satisfy the KKT conditions (4) of the original problem (1), so that problem (6) is not “fully equivalent” to problem (1) in the sense of Di Pillo and Grippo (1989). Bomze and Palagi (2005) proposed the following continuous differentiable globally exact penalty function for problem (6):

                        
                           (7)
                           
                              
                                 
                                    f
                                    1
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 
                                    1
                                    2
                                 
                                 
                                    x
                                    ⊤
                                 
                                 
                                    
                                       X
                                       A
                                       X
                                       x
                                       (
                                       3
                                       −
                                       2
                                       ∥
                                       x
                                       ∥
                                    
                                    2
                                 
                                 
                                    )
                                    +
                                 
                                 
                                    1
                                    
                                       ɛ
                                    
                                 
                                 
                                    
                                       (
                                       ∥
                                       x
                                       ∥
                                    
                                    2
                                 
                                 
                                    
                                       −
                                       1
                                       )
                                    
                                    2
                                 
                              
                           
                        
                     which depends on the set of parameters Ω
                     1 = {ɛ} with ɛ freely chosen within 
                        
                           (
                           0
                           ,
                           
                              
                                 ɛ
                              
                              ¯
                           
                           ]
                        
                      where the upper bound 
                        
                           
                              ɛ
                           
                           ¯
                        
                      can be easily calculated. The choice of the value of the parameter ɛ may cause numerical instability. Function f
                     1(x) is twice continuously differentiable on the whole space 
                        
                           
                              
                                 R
                              
                              n
                           
                           ,
                        
                      and its unconstrained minimization lead to the 1st problem (5) with 
                        
                           
                              D
                              1
                           
                           ≡
                           
                              
                                 R
                              
                              n
                           
                        
                     . Any stationary point of problem (5) with i = 1 corresponds to a KKT point of problem (6) and we can obtain back a feasible solution for StQP by the transformation y = T
                     1(x) with 
                        
                           
                              y
                              i
                           
                           =
                           
                              T
                              1
                           
                           
                              (
                              
                                 x
                                 i
                              
                              )
                           
                           =
                           
                              x
                              i
                              2
                           
                        
                      and its (partial) inverse transformation 
                        
                           x
                           =
                           
                              T
                              1
                              
                                 −
                                 1
                              
                           
                           
                              (
                              y
                              )
                           
                           ,
                        
                      namely 
                        
                           
                              x
                              i
                           
                           =
                           +
                           
                              
                                 y
                                 i
                              
                           
                        
                     .

A second way of exploiting the constraint of problem (6) relies on the idea in Grippo et al. (2012). Bomze et al. (2012) proposed the following function

                        
                           (8)
                           
                              
                                 
                                    
                                       f
                                       2
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       
                                          
                                             x
                                             ⊤
                                          
                                          X
                                          A
                                          X
                                          x
                                       
                                       
                                          
                                             ∥
                                             x
                                             ∥
                                          
                                          4
                                       
                                    
                                 
                              
                           
                        
                     to be minimize over an open domain 
                        
                           
                              D
                              2
                           
                           ⊂
                           
                              
                                 R
                              
                              n
                           
                        
                      containing the unit sphere but excluding the origin, where the function is not continuously differentiable. In this case the set of parameter Ω
                     2 = ∅ and the transformation that gives back a feasible point of StQP is y = T
                     2(x) with 
                        
                           
                              y
                              i
                           
                           =
                           
                              
                                 x
                                 i
                                 2
                              
                              
                                 
                                    ∥
                                    x
                                    ∥
                                 
                                 2
                              
                           
                        
                      and its (partial) inverse transformation 
                        
                           x
                           =
                           
                              T
                              2
                              
                                 −
                                 1
                              
                           
                           
                              (
                              y
                              )
                           
                           ,
                        
                      namely 
                        
                           
                              x
                              i
                           
                           =
                           +
                           
                              
                                 y
                                 i
                              
                           
                        
                     .

The third unconstrained problem was proposed in Bomze et al. (2012) and it is obtained starting from a different constrained formulation due to Bomze (1998), where the following quadratic problem, over the positive orthant, has been introduced:

                        
                           (9)
                           
                              
                                 min
                                 
                                    {
                                    
                                       1
                                       2
                                    
                                    
                                       p
                                       ⊤
                                    
                                    Q
                                    p
                                    −
                                    
                                       e
                                       ⊤
                                    
                                    p
                                    :
                                    p
                                    ≥
                                    0
                                    ,
                                    p
                                    ∈
                                    
                                       R
                                       n
                                    
                                    }
                                 
                                 ,
                              
                           
                        
                     being

                        
                           (10)
                           
                              
                                 Q
                                 =
                                 
                                    1
                                    2
                                 
                                 A
                                 +
                                 ϱ
                                 e
                                 
                                    e
                                    ⊤
                                 
                              
                           
                        
                     and ϱ chosen such that Q is strictly 
                        
                           R
                           +
                           n
                        
                     -copositive. We observe that such value can be calculated by the user from 
                        
                           
                              
                                 q
                                 
                                    i
                                    j
                                 
                              
                              =
                              
                                 1
                                 2
                              
                              
                                 a
                                 
                                    i
                                    j
                                 
                              
                              +
                              ϱ
                           
                        
                      if a range of variability for aij
                      is known.

In Bomze (1998) and Bomze et al. (2012) it has been shown that a global solution of problem (9) provides a global solution of problem (1). The same one-to-one correspondence holds among KKT points.


                     Bomze et al. (2012) used again the substitution 
                        
                           
                              p
                              i
                           
                           =
                           
                              x
                              i
                              2
                           
                        
                      to eliminate the constraints p ≥ 0, and obtained the following continuously differentiable quartic function

                        
                           (11)
                           
                              
                                 
                                    f
                                    3
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 
                                    1
                                    2
                                 
                                 
                                    x
                                    ⊤
                                 
                                 X
                                 Q
                                 X
                                 x
                                 −
                                 
                                    
                                       ∥
                                       x
                                       ∥
                                    
                                    2
                                 
                              
                           
                        
                     with Q as in (10) and the set of parameters Ω
                     3 = {ϱ}. This leads to the 3rd problem (5) with 
                        
                           
                              D
                              3
                           
                           ≡
                           
                              R
                              n
                           
                        
                     . As mentioned before, also in this case the transformation 
                        
                           
                              p
                              i
                           
                           =
                           
                              x
                              i
                              2
                           
                        
                      may produce spurious stationary points of f
                     3 which do not correspond to KKT points of problem (9). However we can still get feasible point for StQP by the transformation y = T
                     3(x) with 
                        
                           
                              y
                              i
                           
                           =
                           
                              
                                 x
                                 i
                                 2
                              
                              
                                 
                                    ∥
                                    x
                                    ∥
                                 
                                 2
                              
                           
                        
                      and the (partial) inverse 
                        
                           x
                           =
                           
                              T
                              3
                              
                                 −
                                 1
                              
                           
                           
                              (
                              y
                              )
                           
                        
                      with 
                        
                           
                              x
                              i
                           
                           =
                           
                              
                                 
                                    
                                       |
                                    
                                    
                                       y
                                       i
                                    
                                    
                                       |
                                    
                                 
                                 
                                    ϱ
                                    +
                                    
                                       f
                                       0
                                    
                                    
                                       (
                                       y
                                       )
                                    
                                 
                              
                           
                        
                     .

Summarizing, all the derived problems (5) are unconstrained non-convex problems for any i = 1, 2, 3. The counterpart of these unconstrained formulations lies in the fact that they are not “fully equivalent” to problem (1) in the sense of Di Pillo and Grippo (1989). Indeed, for all of them it is possible to prove that any global solution of problem (5) for any i ∈ {1, 2, 3} provides a global solution of problem (1) and vice versa. However for any i ∈ {1, 2, 3} spurious stationary points of (5) may exist which do not correspond to KKT points of the original problem (1), while the vice versa is always true. Anyway it is well known that local unconstrained optimization methods can produce only stationary points 
                        
                           
                              x
                              ^
                           
                           i
                        
                      of 
                        
                           
                              
                                 min
                                 
                                    x
                                    ∈
                                    
                                       D
                                       i
                                    
                                 
                              
                              
                              
                                 f
                                 i
                              
                              
                                 (
                                 x
                                 )
                              
                           
                        
                       for any given i = 1, 2, 3, so that formulations (5) must be carefully used to find solutions of the original StQPs as pointed out in Bomze et al. (2012) and Bomze and Palagi (2005).

For the sake of clarity we summarize the correspondence among first order stationary points of the three unconstrained problems and StQP as follows:

                        
                           
                              
                                 
                                    y
                                    ¯
                                 
                                 
                                 
                                    KKT
                                    
                                    point
                                    
                                    of
                                    
                                    StQP
                                 
                                 
                                 
                                    ←
                                    
                                       
                                          x
                                          ¯
                                       
                                       =
                                       
                                          T
                                          i
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          (
                                          
                                             y
                                             ¯
                                          
                                          )
                                       
                                    
                                 
                                 
                                 
                                    x
                                    ¯
                                 
                                 ∈
                                 
                                    D
                                    i
                                 
                                 
                                 
                                    stationary
                                    
                                    point
                                    
                                    of
                                 
                                 
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 ∀
                                 
                                 i
                                 .
                              
                           
                        
                     whereas correspondence among global minimizers holds also in the reverse direction

                        
                           
                              
                                 
                                    y
                                    ¯
                                 
                                 
                                 
                                    global
                                    
                                    minimizer
                                    
                                    of
                                    
                                    StQP
                                 
                                 
                                 
                                    
                                       
                                          
                                             ←
                                             
                                                
                                                   x
                                                   ¯
                                                
                                                =
                                                
                                                   T
                                                   i
                                                   
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   (
                                                   
                                                      y
                                                      ¯
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             →
                                             
                                                
                                                   y
                                                   ¯
                                                
                                                =
                                                
                                                   T
                                                   i
                                                
                                                
                                                   (
                                                   
                                                      x
                                                      ¯
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                 
                                    x
                                    ¯
                                 
                                 ∈
                                 
                                    D
                                    i
                                 
                                 
                                 
                                    global
                                    
                                    minimizer
                                    
                                    of
                                 
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 ∀
                                 
                                 i
                                 .
                              
                           
                        
                     Analyzing into details the results in Bomze et al. (2012) and Bomze and Palagi (2005), it is possible to state that starting from a feasible point y
                     0 ∈ Δ with the corresponding 
                        
                           
                              x
                              0
                           
                           =
                           
                              T
                              i
                              
                                 −
                                 1
                              
                           
                           
                              (
                              
                                 y
                                 0
                              
                              )
                           
                           ∈
                           
                              D
                              i
                           
                           ,
                        
                      any unconstrained algorithm applied to the solution of problem (5) for i ∈ {1, 2, 3} converges to a stationary point 
                        
                           
                              
                                 x
                                 ^
                              
                              i
                           
                           ∈
                           
                              D
                              i
                           
                        
                      which gives a feasible point for the corresponding intermediate constrained formulation (6) or (9). This in turn implies that the corresponding point 
                        
                           
                              
                                 y
                                 ^
                              
                              i
                           
                           =
                           
                              T
                              i
                              
                                 −
                                 1
                              
                           
                           
                              (
                              
                                 
                                    x
                                    ^
                                 
                                 i
                              
                              )
                           
                        
                      is feasible for problem (1), i.e. 
                        
                           
                              
                                 y
                                 ^
                              
                              i
                           
                           ∈
                           Δ
                           ,
                        
                      although it may not correspond to a KKT point of problem (1). Further we also have that at any point 
                        
                           x
                           =
                           
                              T
                              i
                              
                                 −
                                 1
                              
                           
                           
                              (
                              y
                              )
                           
                        
                      corresponding to a feasible y, the values of the objective functions fi
                      are equals for any i and also 
                        
                           
                              f
                              0
                           
                           
                              (
                              
                                 
                                    y
                                    ^
                                 
                                 i
                              
                              )
                           
                           =
                           
                              f
                              i
                           
                           
                              (
                              
                                 
                                    x
                                    ^
                                 
                                 i
                              
                              )
                           
                        
                     . Hence,we have the following relationship

                        
                           (12)
                           
                              
                                 
                                    f
                                    0
                                 
                                 
                                    (
                                    
                                       
                                          y
                                          ^
                                       
                                       i
                                    
                                    )
                                 
                                 =
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          x
                                          ^
                                       
                                       i
                                    
                                    )
                                 
                                 ≤
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    
                                       T
                                       i
                                       
                                          −
                                          1
                                       
                                    
                                    
                                       (
                                       
                                          y
                                          0
                                       
                                       )
                                    
                                    )
                                 
                                 =
                                 
                                    f
                                    0
                                 
                                 
                                    (
                                    
                                       y
                                       0
                                    
                                    )
                                 
                                 
                                 ∀
                                 
                                 
                                    y
                                    0
                                 
                                 ∈
                                 Δ
                                 
                                 ∀
                                 
                                 i
                                 ∈
                                 
                                    {
                                    1
                                    ,
                                    2
                                    ,
                                    3
                                    }
                                 
                                 .
                              
                           
                        
                     This property can be useful in the definition of the global heuristic.

The results reported in the preceding section allow to look for global minimizers of constrained problem (1) by applying an unconstrained procedure to one of the unconstrained problems (5) with fi
                      given in (7), (8) and (11).

For the solution of the unconstrained problems we can use any local algorithm for unconstrained optimization. Of course there is no guarantee that any of these algorithms would converge to global minimizers of the selected unconstrained function fi
                      and hence of problem (1). We can only have convergence to a stationary point 
                        
                           
                              x
                              ^
                           
                           i
                        
                      of the function fi
                      with i = 1, 2, 3 and by the inverse transformation we obtain a 
                        
                           
                              
                                 y
                                 ^
                              
                              i
                           
                           =
                           
                              T
                              i
                              
                                 −
                                 1
                              
                           
                           
                              (
                              
                                 
                                    x
                                    ^
                                 
                                 i
                              
                              )
                           
                           ∈
                           Δ
                        
                     . Although we never observe such an occurrence in practice, it may happen that a spurious stationary point is located so that 
                        
                           
                              y
                              ^
                           
                           i
                        
                      is not a KKT point of the constrained problem (1). Nevertheless, since 
                        
                           
                              y
                              ^
                           
                           i
                        
                      is feasible for (1) and it satisfies (12) we can define a global heuristic for problem (1).

We note that the procedure reported in the following can be used in connection with any finite number of unconstrained formulations for the StQP; in the following we restrict to the three unconstrained formulations proposed in Section 3.

In order to define a global heuristic we adopt a standard multistart global optimization technique. It consists in repeating M > 1 runs of the same local minimization process starting from different randomly chosen points x
                     0k
                      and selecting the point 
                        
                           x
                           ^
                        
                      which provides the best objective value over all the runs. A multistart approach applied to the ith unconstrained formulation leads to an heuristic hi
                      for solving problem (1). In Bomze et al. (2012) and Bomze and Palagi (2005), three heuristics hi, i = 1, 2, 3 have been proposed to solve the StQPs arising from the Maximum Clique Problems; none of them dominates the others in term of best optimal values obtained so that an integrated approach can be useful.

A trivial way for combining these three heuristics consists in using all the three unconstrained formulations fi
                      at each random point x
                     0k
                      for all k = 1, …, M (THE
                        M
                     ). The overall number of unconstrained minimizations is 3M.

Of course this approach, reported in Algorithm 1
                     , requires a great computational effort which is often useless because many of the 3M runs produce the same solution without improving the best current one. In order to avoid useless optimizations, we propose to extend the approach described in Cassioli et al. (2012), where machine learning tools are used to improve a global multistart strategy. Cassioli et al. (2012) proposed the algorithm L
                     e
                     GO: L
                     e
                     arning for Global Optimization, which uses Support Vector Machines to learn the relationship between the starting point of an algorithm and the final outcome, which is usually related to the function value at the point returned by the procedure. We extend this approach to tackle also the choice of the best unconstrained formulation.

In this section we briefly present the classification method using Support Vector Machines (SVMs) employed in the following experiments. For a general and more detailed introduction to this topic, the reader can look in Vapnik (1998) and Burges (1998). We refer to a standard two class classification problem aimed to construct a function able to classify correctly new instances. Indeed in our context, the classifier should be able to decide whether a pair (x
                     0k
                     , fi
                     ) can be discarded in the sense that a minimization procedure applied to fi
                      starting from x
                     0k
                      will not probably produce a better solution.

In a classification problem, we must refer to a Training Set 
                        T
                      described as:

                        
                           (13)
                           
                              
                                 T
                                 =
                                 {
                                 
                                    (
                                    
                                       x
                                       ℓ
                                    
                                    ,
                                    
                                       d
                                       ℓ
                                    
                                    )
                                 
                                 ,
                                 
                                    x
                                    ℓ
                                 
                                 ∈
                                 
                                    R
                                    n
                                 
                                 ,
                                 
                                    d
                                    ℓ
                                 
                                 ∈
                                 
                                    {
                                    −
                                    1
                                    ,
                                    1
                                    }
                                 
                                 ,
                                 ℓ
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                                 }
                              
                           
                        
                     where 
                        
                           
                              x
                              ℓ
                           
                           ∈
                           
                              R
                              n
                           
                        
                      represents the input (in our case it will be the starting point) and d
                     ℓ ∈ { − 1, 1} the output, namely the belonging class (in our case promising or not promising).

SVMs are a special class of Kernel methods which uses as notion of similarity among data the inner product in a possible larger feature space. Thus, SVMs implement binary classifiers that learn the possibly nonlinear border between datasets belonging to different classes. The nonlinear classifier function 
                        
                           Φ
                           :
                           
                              R
                              n
                           
                           →
                           
                              {
                              −
                              1
                              ,
                              1
                              }
                           
                        
                      has the general form

                        
                           
                              
                                 
                                    
                                       
                                          Φ
                                          
                                             (
                                             x
                                             )
                                          
                                          =
                                          sign
                                          
                                             (
                                             
                                                ∑
                                                
                                                   ℓ
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                λ
                                                ℓ
                                             
                                             
                                                d
                                                ℓ
                                             
                                             k
                                             
                                                (
                                                x
                                                ,
                                                
                                                   x
                                                   ℓ
                                                
                                                )
                                             
                                             +
                                             b
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           λ
                           ∈
                           
                              R
                              N
                           
                        
                      and 
                        
                           b
                           ∈
                           R
                        
                      are obtained during the training phase by means of an optimization procedure. Among the most common kernels functions k(x, z) are:

                        
                           •
                           Polynomial k(x, z) = (x
                              ⊤
                              z + γ)
                                 p
                              , where p ≥ 0 and γ ≥ 0 which includes the linear kernel (γ = 0, p = 1);

Gaussian k(x, z) = exp( − γ‖x − z‖2), with γ ≥ 0

Points x
                     ℓ corresponding to an optimal value λ
                     ℓ > 0 are the so called Support Vector, namely points that are on the boundary of the nonlinear surface separating the two classes.

The optimization problem that needs to be solved to find λ and b is a special convex StQP in the dimension 
                        
                           
                              |
                           
                           
                              T
                              i
                           
                           
                              |
                              =
                              N
                           
                        
                      which involves user-defined parameters which appear either in the kernel function used (such as γ or p) and in a “penalization” term of misclassified points. The choice of these parameters may affect the classification performance of the function Φ and their values are often selected by means of a cross-validation procedure using the training data (see e.g. Bishop 2006). A drawback of cross-validation is that the number of training runs that must be performed increases, and this in our context can be more expensive than the computational effort of the several running. Hence we do not use a cross-validation procedure but we rather use a user-defined setting.

As we mentioned in the introduction, we intend to define a paradigm to combine different heuristics into a single one by extending the approach proposed in Cassioli et al. (2012). Although the procedure described below can be applied to a finite number of unconstrained formulations for StQP, we focus on the three ones described in Section 3.

The purpose of the Global Heuristic Optimization Strategy by SVM (GHOSt
                     SVM) is to decide which unconstrained formulation, if any, can produce a good solution for the StQP starting from a given point x
                     0k
                     . To this aim, we use a learning procedure to predict whether a point x
                     0k
                      could be considered promising for one of the formulations fi
                     , in the sense that the stationary point 
                        
                           
                              x
                              ^
                           
                           
                              i
                              k
                           
                        
                      obtained by means of an unconstrained procedure starting from x
                     0k
                      gives a “good value” for the StQP (1). The meaning of “good value” will be specified later in this section. If no formulation is selected, than the point x
                     0k
                      is skipped. Whenever the point x
                     0k
                      is promising for more than one unconstrained formulation, the algorithm must also decide the most suitable among them in order to apply at most a single unconstrained optimization procedure for each x
                     0k
                     .

Now we enter details of GHOSt
                     SVM which can be divided in two phases. The aim of Phase I is the construction and training of three classifiers SVM
                        i
                     , i = 1, 2, 3 that return if it is worthwhile to start the optimization procedure from x
                     0k
                      using formulation fi
                     . In order to train the three classifiers, we first need to construct three training sets 
                        
                           
                              T
                              i
                           
                           ,
                        
                      made up of pairs (x
                     0k
                     , dik
                     ) with 
                        
                           
                              x
                              
                                 0
                                 k
                              
                           
                           ∈
                           
                              R
                              n
                           
                        
                      and dik
                      ∈ { − 1, 1}, where dik
                      = 1 is assigned to a “good” point. To this purpose we need to define a criterion to establish whether a a point x
                     0k
                      is “good” with respect to formulation i, or not. Actually this issue is quite important. Of course many different criteria can be proposed and any of these may present weak and strength points with respect to the definition of a good training set. In Section 7 we report the results using different criteria. After several trials, we select as default criterion the one that gave the best performance as a tradeoff of the best value found and the computational savings. In particular a point x
                     0k
                      is classified as good with respect to formulation i, if both the returned value of objective function 
                        
                           
                              f
                              i
                           
                           
                              (
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    i
                                    k
                                 
                              
                              )
                           
                        
                      is sufficiently reduced with respect to a reference value f
                     ref, and if it is sufficiently far from a region of attraction of a “reference” point. In the numerical experience we tried to use different “reference” point. The precise rules which define the adopted criterion are reported in the sketch Algorithm 2
                     and corresponds to the most robust one.

Of course a check whether the training sets 
                        
                           
                              T
                              i
                           
                           ,
                        
                      
                     i = 1, 2, 3 are balanced must be performed. In particular, the case when for a given fi
                      most or all the labels have the same value must be tackled, in order to overcome possible misclassifications, and we use a standard approach proposed in SVM literature.

At the end of Phase I, three classifiers (SVM
                        i
                     )
                        i = 1, 2, 3, which can be used in a multistart procedure to select promising (dik
                      = 1) pairs (x
                     0k
                     , fi
                     ), i = 1, 2, 3, are available. At any given point x
                     0k
                      it may happen that dik
                      = 1 for more than one index i while we are interested in selecting just one of them. This selection is based upon the performances achieved in Phase I, namely selecting the unconstrained formulation which had given the best value on average. The sketch of GHOSt
                     SVM is reported in Algorithm 3
                     where the stopping criterion in the main loop must still be specified.

We observe that the value f* returned by GHOSt
                     SVM cannot be worst than the one returned by Phase I and that GHOSt
                     SVM performs at least 3N local searches.

The computational burden of GHOSt
                     SVM is due either to the training of the SVM
                        i
                      using 
                        
                           T
                           i
                        
                      and to the local searches. The training of the three SVM
                        i
                      requires the solution of three small dimension (N ≪ n) single constrained quadratic convex problems that can be performed in a very efficient way (see e.g. Joachims 1998; Lin et al. 2009). We can affirm that the computational burden of training each SVM
                        i
                      is equivalent to a single local search. These three problems in 
                        
                           R
                           N
                        
                      are solved once for all at the end of the first N epochs, whereas strictly more than 3N local searches in 
                        
                           R
                           n
                        
                      must be performed. Hence the computational cost related to the training of each SVM
                        i
                      is negligible with respect to the local searches.

We focus now on the definition of the stopping criterion missed in the general sketch of GHOSt
                     SVM. A first use of GHOSt
                     SVM consists in fixing the overall number of starting points generated in Phase I and Phase II to M, so that the stopping criterion requires ♯
                        pt
                      ≤ M − N and the number of local searches performed ♯
                        opt
                      can be at most 3N + (M − N) = 2N + M < 3M. We refer to this version as GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                     .

On the other hand, we can define the stopping criterion considering the overall number of local searches. In particular we stop when the number of local searches reaches ♯
                        opt
                      = 3M, with a safeguard rule on the maximum number of random starting points generated 
                        
                           
                              ♯
                              
                                 p
                                 t
                              
                           
                           ≤
                           
                              ♯
                              
                                 p
                                 t
                              
                              max
                           
                           ,
                        
                      and we refer to this version as GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                     . In this case the computational effort of GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      is equal to the one of THE
                        M
                      and we evaluate the ability of GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      of individuating better values f* than THE
                        M
                     .

We consider the StQP test problems arising from the Maximum Clique Problem on a set of graphs from the DIMACS challenge (Johnson and Trick, 1996) that were also considered in Bomze et al. (2012) and Bomze and Palagi (2005). From now on we refer to a maximization problem as in (3) and we report the results in terms of the equivalent value of the best clique ω* obtained as 
                        
                           
                              ω
                              *
                           
                           =
                           
                              1
                              2
                           
                           
                              
                                 (
                                 1
                                 −
                                 
                                    f
                                    *
                                 
                                 )
                              
                              
                                 −
                                 1
                              
                           
                        
                     . We recall that a feasible solution 
                        
                           y
                           ¯
                        
                      of the StQP (1) gives a clique if and only if 
                        
                           y
                           ¯
                        
                      is a local maximizer. Hence, recalling that spurious stationary points of fi
                      may occur, we check at 
                        
                           y
                           ¯
                        
                      the satisfaction of the KKT conditions of (1) and the fact that a clique has been found. Actually, experimental testing showed that such spurious stationary points never occur.

GHOSt
                     SVM has been implemented in Fortran 90 in the two versions GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      and GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                     . We use a pseudorandom number generator for the starting point, as implemented in the Fortran library. As for the unconstrained method to solve problem (5), we use the non-monotone Barzilai–Borwein gradient method proposed in Grippo and Sciandrone (2002). The SVMs were trained by LibSVM (the reader can refer to Chang and Lin 2011 for more details) launched by a shell using a System call from the Fortran code. We run several experiments with different kernels and we select the Gaussian kernel. We do not implement a cross-validation procedure for finding the user-defined parameters γ and C, but we set the kernel parameter to γ = 1 and the penalty on misclassified training data to C = 100. For sake of completeness, we report the effect of changing these parameters on a subset of problems where misclassification occurs.

In GHOSt
                     SVM: Phase I, we set the dimension N of the training sets 
                        
                           T
                           i
                        
                      according to the dimension n of the problem as follows

                        
                           
                              
                                 N
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             50
                                          
                                          
                                             
                                                if
                                                
                                                
                                                   n
                                                   ≤
                                                   1000
                                                
                                             
                                          
                                       
                                       
                                          
                                             70
                                          
                                          
                                             
                                                otherwise
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

It may happen that a training set 
                        
                           T
                           i
                        
                      turns out to be unbalanced, that is the percentage of positive instances, dik
                      = 1, with respect to negative ones, dik
                      = −1, is quite different. When this happens the learning procedure may be biased by the most common label. A trivial way to tackle this issue consists in increasing the cardinality N of the training sets to get more information. However this will lead to a larger number of local searches to be performed in the training phase and may not produce a more balanced training set. We prefer to tackle this issue using a particular tool in LIBSVM, which allows to choose different penalty parameters for the two classes in the SVM training problem, by setting different weights w
                     +, w
                     − for the classes. In particular we use as w
                     +, w
                     − respectively the percentage of the negative and positive instances in 
                        
                           T
                           i
                        
                     .


As a term of comparison, we run the three heuristics over the overall set of 73 problems setting M = 220. The results are in Table A.1
                     of the Appendix A. We report for each problem the best known value (bkv), the best (max), the average (avg) and the worst (min) clique values found by each heuristic i = 1, 2, 3. From the table, we observe that on 19 problems over the 73 used, all the three heuristics find the benchmark value (these problems are: C125.9, the c-fat family, hamming6-2, hamming6-4, hamming8-4, the Johnson family, mann_a9, p_hat300-1, p_hat300-2, p_hat500-1). We classify this problem as trivial ones and we eliminate them from the test set.

We note however that this classification is possible only because a certified optimal solution is known. For a generic StQP problem this information may be not available so that even if the heuristics performs the same, none of them may have found the global solution. This actually happens on other 25 problems over the 54 remaining, where each heuristic found the same clique value which is not the optimal one. However, combining the heuristics as in GHOSt
                     SVM does not require to have run them separately (otherwise it is of course useless), hence we decide to include them in the benchmark to test the capability of GHOSt
                     SVM to perform its different tasks. Over the remaining 29 problems, the three heuristics perform differently and we report for these cases in Table 1
                     the number of wins, ties and losses of each heuristic with respect to the others in terms of the best value obtained. In these problems, none of the three heuristics dominates the others in terms of best clique value found and hence they represent the most challenging ones.

We end up with 54 problems in which we tested the two versions of GHOSt
                     SVM. First we observe that, as mentioned in Section 6, a crucial aspect for a good performance is the choice of the criterion used in Phase I to define the training set (i.e. assign label ± 1 to points in 
                        
                           T
                           i
                        
                     ) and the tuning of the parameters %ref and %d. To understand the relevance of these choices, we run GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      with M = 220 using in Phase I different criteria, namely (i) the default criterion reported in Algorithm 2; (ii) a criterion based only on the function value 
                        
                           
                              
                                 
                                    f
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          x
                                          ^
                                       
                                       
                                          i
                                          k
                                       
                                    
                                    )
                                 
                              
                              
                                 f
                                 ref
                              
                           
                           ≤
                           
                              %
                              ref
                           
                        
                      (GHOSt
                     
                        
                           
                           
                              R1
                           
                           SVM
                        
                     ); (iii) a criterion using only the distance 
                        
                           
                              
                                 
                                    ∥
                                 
                                 
                                    x
                                    
                                       0
                                       k
                                    
                                 
                                 −
                                 
                                    x
                                    
                                       best
                                    
                                    
                                       0
                                       i
                                    
                                 
                                 
                                    
                                       ∥
                                    
                                    2
                                 
                              
                              
                                 
                                    ∥
                                 
                                 
                                    
                                       x
                                       ^
                                    
                                    
                                       i
                                       k
                                    
                                 
                                 −
                                 
                                    x
                                    
                                       best
                                    
                                    i
                                 
                                 
                                    
                                       ∥
                                    
                                    2
                                 
                              
                           
                           ≥
                           
                              %
                              d
                           
                        
                      (GHOSt
                     
                        
                           
                           
                              R2
                           
                           SVM
                        
                     ), where also different reference points than 
                        
                           
                              x
                              
                                 best
                              
                              
                                 0
                                 i
                              
                           
                           ,
                           
                              x
                              
                                 best
                              
                              i
                           
                        
                      have been tried. After different trials, we set %ref = 1 and %d = 0.95 and to highlight the role of different criteria we summarize the results in a picture. In particular for each criterion, we report the number of problems solved as a function of the number of local optimization calls. We eliminate those problems where none of the three versions reaches the value found by THE
                        M
                      i.e. the best value among the three heuristics (these are nine problems). In Fig. 1
                     we report the three curves: on the x-axis we report the number of optimization calls actually applied during the overall procedure; a point on a curve represents the number of problems solved within the corresponding number of optimization calls. In other words, the smaller the value on the x-axis, the higher the number of starting points discarded. Hence, the best performance corresponds to the highest curve. It turns out that the performance of GHOSt
                     
                        
                           
                           
                              R1
                           
                           SVM
                        
                      is comparable to that of GHOSt
                     
                        
                           
                              
                              
                                 v1
                              
                              SVM
                           
                           ,
                        
                      thus the the criterion based on the function values dominates the one based only on the ratio of distances (this is true whatever the reference point is). However the joined use of the two criteria as in GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      produces a benefit in terms of computational savings and we select this as the default criterion.

Finally, we run GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      and GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      over the 54 problems and we report the complete results in Table A.2. As a term of comparison, we report in the same table for each problem the best value (bv) found by each of the heuristics, the best value (bv) and the number of local searches ♯
                        opt
                      returned by THE220, GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      and GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      respectively. In the following, we analyze the results achieved by GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      and GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      separately.

Concerning GHOSt
                     
                        
                           
                              
                              v1
                              SVM
                           
                           ,
                        
                      first of all it is important to observe that, since the random points used are the same ones used by the three heuristics, the best value achieved by it cannot be better than the one returned by THE
                        M
                     . Hence in this setting of the experiments, we check whether GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      is able to save optimizations without losing a best pair in the set (x
                     0k
                     , fi
                     )
                        k = N + 1, …, M; i = 1, 2, 3. We can distinguish the analysis among the two subset of problems composing the test set. Indeed, in the 25 problems where the three heuristics perform the same, one can argue that it could have obtained the best value by selecting randomly one of them. However, this is true only if we knew in advance the performance but, when applying GHOSt
                     
                        
                           
                              
                              
                                 v1
                              
                              SVM
                           
                           ,
                        
                      we must assume that we did not have run the heuristics before. GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      always finds the same value of the three heuristics, hence it achieves one of its tasks, i.e. the “right” pair (x
                     0k
                     , fi
                     ) is not lost. In order to classify this problems as wins, ties or losses we consider the percentage of computational saving. In particular, we say that the computational saving is p percent if GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      performs in Phase II at most the (100 − p) percent of the optimization calls, namely if the overall number of optimization calls satisfies ♯
                        opt
                      ≤ 3N + (1 − p/100)(220 − N) (Table 2
                     ).

We classify these problems as a win of GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      whenever the best value is found with at least a 40 percent of savings; these are 11 problems and on 5 of them the saving was over 80 percent. We say that there is a tie whenever GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      finds the best value by saving 10 percent ≤ p < 40 percent; these are 8 problems. On the other hand when the overall saving in less than 10 percent we classify the problem as a loss.

Now we analyze the results on the 29 problems where the three heuristics do not perform the same and hence to get the best value we should run THE220 which requires 660 optimization runs. On 18 problems GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      found the same best value performing a lower number of optimization calls. These problems are classified as wins. On the remaining 11 problems, the value reported by GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      is worse with respect to that of THE220. These cases correspond to misclassification, since GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      discard the correct pair (x
                     0k
                     , fi
                     ). In order to clarify this aspect, we run on these 11 problems GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      changing the γ parameter in the Gaussian Kernel used in the SVM model.

These results are reported in Table 3
                     where the best value found is in boldface. It is shown that these failures are related to the choice of γ rather than the idea behind the algorithm and that tuning the value of γ is not easy. Indeed a more accurate choice, possible with a suitable cross validation procedure could be applied to find the best setting for the SVM parameters, but this was out the scope of the paper. Hence these problems cannot be easily classified as wins, ties, losses. We summarize the overall performance of GHOSt
                     
                        
                           
                           
                              v1
                           
                           SVM
                        
                      over the 54 problems in Fig. 2
                     reporting the percentage of wins, ties, losses and misclassification cases.

As regards GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      we fix the number of local searches to 3 · M = 660 and the competitor is THE220. In this case we focus on the capability of finding a better value than THE220 applying the same number of local searches. When this happens we say that GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      wins over THE220. We define instead a tie when GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      and THE220 return the same value. Otherwise GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      loses. We note that on some problems GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      performs less than 3M = 660 local searches because it does not accept enough points within the maximum safeguard number.

We summarize the numbers of wins, ties and losses of GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      versus THE220 in Fig. 3
                     . The detailed results are in Table A.2 of Appendix A where problems when GHOSt
                     
                        
                           
                           
                              v2
                           
                           SVM
                        
                      wins are highlighted in gray and the ones when it loses are in boldface.

@&#ACKNOWLEDGMENT@&#

The authors want to thank the anonymous referees for valuable remarks which helped significantly in improving an earlier version of this paper.


                     
                     
                     
                  

@&#REFERENCES@&#


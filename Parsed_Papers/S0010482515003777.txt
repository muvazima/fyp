@&#MAIN-TITLE@&#SME2EM: Smart mobile end-to-end monitoring architecture for life-long diseases

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We developed a novel mobile-based architecture for monitoring life-long diseases.


                        
                        
                           
                           It provides smart features to tackle several challenges (e.g., data explosion).


                        
                        
                           
                           Our mobile monitoring architecture is formally modeled and verified at design time.


                        
                        
                           
                           Its components are implemented as Web services and supported by Cloud services.


                        
                        
                           
                           Its applicability is experimentally evaluated by monitoring epileptic diseases.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Model checking

Smart mobile monitoring

Data as a service

Visualization as a service

SOA

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           fx1
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

The last decade has witnessed a substantial increase of patients with life-long diseases all around the world. For example, neurodegenerative (i.e., brain) disorders, a famous class of life-long diseases, has become an immense burden for health-care authorities. Alzheimer [1], Parkinson׳s disease [2], and epilepsy [3–5] are the most famous types of brain diseases. In Europe alone, the expense costs of brain diseases are more than the ones of heart diseases, cancer, and diabetes all put together [6,7]. In fact, the total 2010 European bill of brain disorders was around 800 billions [8]. The National Institute of Mental Health
                        1
                     
                     
                        1
                        
                           http://www.nimh.nih.gov/about/strategic-planning-reports/introduction.shtml.
                      (NIMH) estimates the USA total costs associated with brain disorders to exceed 300 billion dollars every year [9].

In underdeveloped countries and countries with limited budgets, patients find several difficulties to receive available treatments and supervision as the treatment is usually quite expensive. In this context, authors in [10] show that the burden of epileptic seizure in “low-income countries is more than twice of that found in high-income countries” as the relative frequency of risk factors is very high. The center for disease control and prevention
                        2
                     
                     
                        2
                        
                           http://www.cdc.gov/mmwr/preview/mmwrhtml/mm6145a2.htm.
                      reports that 1.0%, approximately 2.3 million of the United States adults and 1.9% of those with family income levels less than $34,999 per year had active epilepsy. Moreover, epileptic seizures happen randomly (e.g., when epileptic patient might sleep, watch TV, or play), follow a non-uniform distribution with unknown causes [4,5] over a long period of time, and are hard to predict at the medium and long run [4]. The suitable approach to detect epileptic seizures is to have the patient continuously monitored over a long period of time, ranging from several hours to several days and even several weeks. In traditional monitoring set ups, the patient has to stay in an appropriately equipped hospital, which is connected to a large and bulky set of equipment. While such monitoring set ups are suitable for a short period of the monitoring process, they are unpractical for long monitoring periods, which are necessary for life-long diseases.

To cope with the exponential increase in population suffering from life-long diseases and their associated costs, many health-care governments decided to shift into mobile health monitoring systems. In these systems, mobile phones, pocket personal computers or personal digital assistants are employed as the main coordination and processing module. This will definitely allow long-term monitoring of brain disorders and will reduce health-care government costs, since patients stay in their usual environments and at the same time receive professional health-care services. The new trend of remote and mobile monitoring services has been made possible, due to a fabulous development in mobile sensing devices and smartphones alongside wireless and cellular communication networks.

For most health vital signs, there are a quite number of accurate and industry-approved light, wireless, and mobile sensors. These sensors, when connected to a mobile smartphone, can constitute an essential pillar towards the development and adoption of an effective mobile monitoring system. A wireless sensor specifically reads vital signs directly from the patient׳s body, and relays the sensed information to the mobile smartphone. The intermediate smartphone in turn relays the received information to the hospital information systems. Physicians and/or neurologists will continuously have an on-the-fly view of the patient׳s status. They can also get in touch with the patient through either the reversed channel or traditional communication mediums such as the telephone or the SMS system.

In order to get this set of heterogeneous hardware and software components to collaborate together for a single objective within an integrated framework, a lot of challenging issues have to be studied and solved. On one side, body sensors coming from medical equipment manufacturers are more focused on the quality of sensors than the communication and data handling (e.g., storage and exchange) aspects. On the other side, smartphone industries are more centered on the communication aspect than the sensing and data handling aspects. On their side, storage providers are focusing only on their primary business processes than the sensing and communication process.

The ultimate aim of the present work is to develop a novel smart mobile end-to-end monitoring architecture (shortly, SME2EM) to monitor and visualize life-long diseases. The endeavor of SME2EM is to bridge the gap between sensor manufacturers, smart-phone industries, public internet service providers, data storage providers, patients, physicians, and health-care stakeholders in general. The word smart precisely refers to the capacity of our architecture׳s components to be pro-active, reactive, adaptive or dynamic, which accordingly make our architecture cost-effective, efficient, and usable. As the term “general” suggests, our architecture is not based on a specific kind of sensors, manufacturer, smartphones, communication protocols or platforms. It is also worth mentioning that the objectives and aspects of SME2EM are still desiderata, as clearly shown in some of the latest works (see [11] for example). From bio-informatics perspective, our satisfied aspects strongly and positively contribute in improving patients׳ diseases monitoring and quality of life. Specifically and as well be thoroughly analysed in Section 2, our SME2EM tries to address and solve many of the limitations of related works.

In terms of the feasibility aspect, several application areas can benefit from our system architecture, since its main streamlined idea is to allow anywhere and anytime monitoring of long-life diseases. The user interaction with the system is extremely important for the timeliness and accuracy of the monitoring process and for gaining the benefits of using the proposed remote monitoring system. It is worth mentioning that: (1) the usability of our mobile monitoring system depends on the user being able to setup and interact with the system; and (2) the information illustrated from analyzing and processing sensed data might be a challenging issue to anyone who is not physician and does not have a deep understanding of the medical vital signs. The user׳s expertize should not be a barrier towards the use of our solution by users with little (or no) medical background knowledge, as we will show, in Section 3, how the usability aspect has been addressed in our system from a user perspective. The following scenario illustrates how our architecture can be applied to monitor epileptic seizures.

Wang, an epileptic villager from Galephu city of Kingdom of Bhutan, must undertake frequent and long trips to the capital city Thimphu for diagnoses and checkup, since there is no neurosurgeon in Wang׳s original village. If Wang has the necessary equipment, his doctor, in the capital Thimphu or even elsewhere, can have a real time view of Wang׳s brain activity while Wang is working in his farm. Whenever necessary, the physician could get in touch with Wang, or a family member, asking them to take appropriate actions, such as taking medicines or getting away from a source of excitation. In an ideal environment, Wang will wear a brain ElectroEncephaloGraphy (EEG) sensor, which is connected to a smartphone, located in Wang׳s pocket. The EEG sensor gets brain activities to the smartphone and the later relays them to the physician.

Moreover, the developed smart monitoring architecture is not only supporting discrete EEG recoding, but also allowing Wang to record continuously and non-invasively the EEG signals using his smart-phone. Another feature of the developed architecture is that Wang can interact with a physician through the system requesting advices and/or adjusting medications without the need to physically travel and meet the physician. Moreover, Wang can be coached in case of emergency and requested to visit the physician or any appropriate health-care center once intervention is required.

The paper is organized as follow: in Section 2, we review and evaluate in the light of the above scenario the current electronic and mobile health monitoring architectures and systems. We briefly summarize current limitations of these systems, identify challenging issues and present our fundamental contributions to address these challenges and limitations. In Section 3, we introduce the design and description of our SME2EM Smart end-to-end mobile architecture for monitoring and visualizing life-long diseases. In Section 4, we show how to formalize the developed system SME2EM in order to automatically and formally verify its correctness against desirable properties using a model checking approach at design time and then makes the design of our system error free, as much as possible. In Section 5, we describe how we fully implemented SME2EM system as a collection of Web services to be easy to deploy and integrate with other components that make SME2EM. To show the feasibility and applicability of the implemented system, we use it to monitor and visualize epileptic seizures׳ states, recorded by an EEG sensor. We also discuss how we addressed the raised challenges through the design and implementation processes. In Section 6, we analytically and experimentally compute the overhead cost of SME2EM. We also evaluate the effectiveness and scalability of the implemented SME2EM system through a set of concrete and reasonable experimental scenarios. An overall discussion of the obtained results is also presented at the end of this section. Section 7 concludes the article and identifies the direction for future work.

@&#RELATED WORK@&#

Until recently, continuous recording and monitoring has always been seen as in-hospital activity. Patients have to attend to a designated room in a hospital, wear bulky equipment, relax on a flat bed, and wait for the recording to finish. This standard procedure is starting to move toward another trend, which is bringing the monitoring equipment to the patient rather than getting the patient into the monitoring equipment room. The new trend is mainly made possible, thanks to a tremendous development of mobile sensors and on-the-go Internet connectivity. Sophisticated sensors, when wirelessly connected to smartphones, can record brain electrical activity, and vital signs anywhere and anytime. With the wide availability of wireless and mobile networks (e.g., Wi-Fi, 3G/4G) with good capacity, the sensed data can be shared on-the-fly with neurologists and hospital personnel, who can be located anywhere. In this section, we only discuss the e-health, and m-health approaches that have a direct relevance to the present article as well as the approaches that are targeting both vital signs and electrical activities recorded by electrocardiogram (ECG) and EEG. The focus on these vital signs is justified by the specific requirements that generate a considerable amount of data when monitoring these vital signs.

In the literature of e-health and m-health monitoring systems, there has been an interesting number of research initiatives, which led to the emergence of various solutions, architectures, and frameworks. In e-health and m-health systems, mobile devices and communication technologies basically provide solutions to deliver health-care services to remote and mobile patients. Among current e-health monitoring systems, the authors in [14] proposed a platform in which cardiac patients were provided with portable recording equipment and cellular phone that support data transmission as well as Wireless Application Protocol (WAP). However, the platform only considers patients in a stable condition and emergency situations were deliberately excluded.

The authors in [13] presented a mobile system, which is based on Body Area Networks (BAN) that record vital signs and then send them through 2.5G and 3G networks in order to evaluate the suitability of those communication networks.

E. Kyriacou et al. in [15] surveyed available technologies for building mobile health systems, such as HygeiaNet, which is used to transmit 12-lead ECG in order to support ambulance and rural health center emergencies, and OTELO-Project Tele-operated robotic system needed for a mobile Tele-Echography, which is a fully integrated end-to-end mobile Tele-Echography system. The mobile Tele-Echography system serves population groups that are not served by medical ultrasound experts and offers an alternative to medical centers that lack ultrasound specialists. The paper concludes that these technologies exploitation in daily practice still remains to be achieved.

The authors in [16] proposed an embedded mobile ECG reasoning and Radio Frequency IDentification (RFID) to identify and monitor elderly patients using mobile devices. The reasoning model is developed by using the Fuzzy Petri Net (FPN) [17] technique, which allows quick classification, and diagnosis of ECG data.

The authors in [18] presented a mobile health-care system for patients monitoring with the focus on the security of the system and the wireless communications supporting it. Another system based on wireless webcam is presented in [19]. Jeonggil et al. in [20] presented results on the use of wireless body networks in monitoring body vital signs within hospital environments. On a similar note, the authors in [21] reported their experience in using ZigBee technology for patients monitoring.

In our evaluation, the above-discussed approaches are mainly focused on wireless systems that can be deployed within a limited space, such as homes or hospitals, rather than completely mobile health systems wherein patients and physicians have a complete mobility-freedom.

As pointed out by Baig and Gholamhosseini in [12], m-health monitoring systems, which are a special subset of e-health monitoring systems, can be classified into: (1) general/multipurpose; (2) specific medical condition; (3) vital signs; and (4) smart technology. Among current m-health monitoring systems, the authors in [22–24] presented applications that can run on Personal Device Assistants (PDAs) and connect to ECG sensors. The recorded vital signs are then analyzed by the mobile applications in order to detect anomalous patterns.

Pawar et al. in [25] proposed a generic architecture after evaluating and comparing six mobile patient monitoring systems. This generic architecture determines feature sets of prospective real-time mobile patient monitoring system using the example of epilepsy monitoring.

Other current m-health and e-health monitoring systems [26–32] are indeed adaptations of some of the works presented above. To this end, the systems and solutions introduced in [16,18–24,26,28,29,31,32] have common objectives: remotely monitor patient׳s vital signs, support physician with relevant clinical information in order to accurately diagnose diseases, and assist patients in positively controlling their health situation. To cope with failures experienced in m-health monitoring systems, authors in [33,34] propose to evaluate the reliability and dependability of WSN. They used event calculus formal language and event-based formalism to detect event׳s failure, disconnection and data resiliency. This pre-evaluation have led to reliable and dependable m-health systems.

In terms of complexity aspect, monitoring of brain signals and neurological disorders is seen as the most challenging. This is because sensors used for monitoring brain signals with multiple contact points generate a considerable amount of data and the monitoring needs to run over extended period of time. Hairston et al. in [35] compared the current wireless EEG sensors in terms of the quality of contact points (also called electrodes), scalp coverage, and integration time. The approach in [36] compared wet electrodes and dry ones in the present of hair within a Steady State Visual Evoked Potential (SSVEP) trial performed by the Brain–Computer-Interface (BCI) program.

Wong et al. in [37] reported on the use of single dry frontal wireless EEG sensor in analyzing motor skill signals. The authors in [38] proposed a mobile EEG and respiratory-based system that can help in detecting cars׳ driving lousiness caused by fatigue in order to avoid potential road accidents. On a similar research topic, the authors in [39] proposed a system that can use a dry wireless EEG sensor with mobile advices to help drivers take safe decisions. While the authors in [40] valued the use of mobile EEG monitoring, they however deplore the lack of software that can support and assist in building the mobile monitoring system.

In the following, we review and evaluate two interesting approaches, which are close to our proposal. In the first work, Honda and Kudoh in [41] presented a portable EEG telemetry system, called “Air Brain System” using 3G networks and smartphones. The air brain system records EEG signals as long as a 3G network is available. In addition, various sensors on a smart-phone are used to sense human behavior. In the second work, Stopczynski et al. in [42] proposed a system, called “Smartphone Brain Scanner”. Specifically, in the smartphone brain scanner system, raw EEG data are extracted from the sensor and processed on an accompanying smartphone.

The features of both approaches are technically limited in terms of data integration, processing, and visualization of EEG signals compared to the proposal of this article. They also do not consider the challenging issue of the smartphone limited resources (e.g., battery) used in the monitoring process. Furthermore, the first work [41] relies heavily on 3G networks without offering any possibility to consider other options and all sensed signals are systematically sent to the back-end server. That is, the processing and analyzing of EEG signals is only done at the back-end server. The patient side thus does not support any intelligent feature. On the contrary, the smartphone brain scanner in [42] merely consists of the patient side that is responsible for acquiring, processing, and analyzing EEG signals.

To recap the discussion on existing works and comparison with SME2EM, the following table (
                     Table 1) provides a side-by-side comparison of related work and our approach using a set of objective comparison criteria. This evaluation demonstrates that our architecture has a significant amount of benefits that other m-health solutions do not address.

In this article, we propose a smart end-to-end architecture covering all processes involved in a mobile-based monitoring system, dedicated to life-long diseases. The monitoring cycle involves signal acquisition, pre-processing, features extraction and selection, classification, visualization, support for decision taking, and report generation. Each one of these activities reveals multitudes of research challenges. The crucial challenges are bounded to the following:
                           
                              1.
                              Data intensive/data explosion: synchronization problem, transmission, storage, and processing cost.

Integration: integrating heterogeneous systems and solutions, including both hardware and software.

Limited resource constraints: battery drainage of sensors and mobile devices, limited processing power, network availability, etc.

Real time data streams visualization: dynamic visualization, and interactive visualization of very dynamic data.

Resource-awareness: temporal resources, resource analysis, and taking necessary actions to adapt to the available resources (e.g., battery).

Availability: a continuous monitoring solution has to provide a high-level of availability despite the requirements expressed in previous points (from 1 to 5). Unavailability, beyond what is expected in the environment and context of use, should not affect the quality of data collection or the decision-taking.

The proposed system architecture is novel in a way that it provides a set of smartness features to tackle continuous monitoring challenges as well as the aforementioned challenging issues. Moreover, our architecture has impact on: (1) the performance of monitoring processes; (2) the scalability of monitoring processes; (3) the availability of sensory data; and (4) the accuracy of outcomes obtained from processing and analyzing sensed data. A summary of our architecture׳s contributions and novelties is depicted as follows:
                           
                              1.
                              Smart data and service integration: we make use of the Service-Oriented Architecture (SOA) to expose every entity as a service (e.g., Data as a Service (DaaS), Pre-Processing as a Service (PPaaS), Visualization as a Service (VaaS)) and to allow a seamless integration of different monitoring processes.

Smart data visualization: visualization involves the implementation of different visualization profiles (e.g., physicians and patients), 2D and 3D visualization (brain map), customized display, energy-aware visualization, device-display adaptation, and adjusted volume and depth of visualized data.

Model formulation and verification: the mobile monitoring system architecture is formally modeled and then formally verified at design time against desirable properties to be error-free, robust, and safe for the implementation phase.

Overhead evaluation: evaluate the overhead of monitoring processes in terms of size of data acquired and synchronized as well as system׳s resources. The size of data will have an impact on required resources (e.g., CPU, memory, and battery) as well as the cost of synchronization over a paid network.

Adaptability and scalability: our architecture guarantees key performance properties including adaptability, scalability, and availability. In terms of adaptability, we propose energy and resource-aware mobile-based monitoring which considers for example network availability, battery drainage, mobile׳s CPU, and memory availability. It also guarantees scalability property by supporting an increasing number of users, requests, data size, and number of services, thanks to the use of Cloud infrastructure and services.

Security: the security property is required and guaranteed given the privacy of health data. All monitoring processes including data sensing, transmission, storage, processing, and visualization guarantee privacy through a number of state-of-the-art security protocols such as data encryption and access rights enforcement.

High availability: to improve the availability of our solution, we propose and test the use of various wireless technologies (Bluetooth, WiFi, 3G/4G). We also use the Cloud resources (IaaS) to ensure high-availability. As soon as the patient gets connected, the whole monitoring solution is available on the fly. When the patient is not connected, offline monitoring resumes and data is sent as soon as a connection is available. In the situation where urgent readings are observed and there is no Internet connection, the system falls back to traditional communication mechanisms, such as telephone and SMS.

Cost reduction: monitoring life-long diseases generates a tremendous amount of data that need to be synchronized on time. The network and battery cost of data synchronization can be so huge that it might threaten the viability of the mobile monitoring approach. We envision to use appropriate and efficient compression algorithms to reduce the size of stored and transmitted EEG data, as argued in [43], without impacting the quality of data or computation resources.

We begin this section by identifying a set of fundamental requirements, which are of prime importance in building a novel, proficient, and smart mobile-based end-to-end monitoring architecture. In principle, the three reasons that helped us in tuning these requirements are: (1) the thorough analysis and synthesis we have done for related work; (2) the apparent demands from patients, physicians, and health-care providers; and (3) the huge size of acquired, processed, transferred, and continuous data, generated from recording life-long diseases.

The requirements supported by the proposed architectural solution are as follows:
                           
                              1.
                              Smart sensing: non-invasive, transparent measurement, and combined filters.

Mobility: continuous monitoring requires anywhere connectivity in order to transmit on the fly sensory data especially in situations when a critical situation is anticipated.

Data intensive: continuous monitoring generates massive data that need to be cleaned, processed, stored, and analyzed in a real time.

Full integration of heterogeneous systems: should integrate seamlessly different systems, applications and services independently of their implementations and or manufacturers.

Flexibility/adaptability: adjust to the environment constraints such as network availability, battery drainage, and resource availability and or scarcity (CPU, memory, etc.).

Scalability: should support a highly increasing number of users, requests, data size, and number of services such as DaaS, PPaaS, and VaaS.

Security: since patient׳s collected data is private, it needs to be protected during data sensing, transmission, storage, processing, and visualization stages. Also, only authorized roles will have access to private data using a role-based access control technique.

High availability: the end-to-end monitoring system should be available 24/7, except what is expected within the context of use.


                        
                        Fig. 1 gives an overview of the proposed architecture, which achieves smart and efficient monitoring and visualization of life-long diseases. From an architectural perspective, our proposition achieves separation of concerns through a combination of tiers and layered design. Specifically, the upper layer includes processes, which are represented as towers, and incorporated in the end-to-end monitoring cycle. The two lower layers include tools, platforms, and technologies used to support and provide services (e.g., storage, processing, and analysis) to the upper layer׳s processes.

To support heterogeneity of components and manufacturers, most processes employed in these layers are implemented as Web services with respect to the SOA architecture and then integrated seamlessly to constitute an end-to-end infrastructure. The communication between heterogeneous platforms and applications is supported through the use of standard Simple Object Access Protocol (SOAP)
                           3
                        
                        
                           3
                           Available at: http://www.w3c.org/TR/soap.
                         and lightweight data-interchange format, called JavaScript Object Notation (JSON).
                           4
                        
                        
                           4
                           Available at: http://www.json.org.
                         The proposed architecture additionally supports high-processing performance, massive data storage and analysis, thanks to the Cloud elasticity, which supports big data tools, processes, and technologies.

In terms of mobility, our architecture promotes high levels of mobility for both patients and physicians. This mobility has a straightforward impact on availability since patients and physicians would be able to use monitoring architecture anytime anywhere. Mobility is supported at different tiers of the architecture as follows:
                           
                              •
                              Wireless sensors: we make use of wireless body sensors with integrated batteries. Most vital signs sensors now are efficient in terms of battery use and can endure hours of continuous monitoring. This is mainly important during the day when the patient is away from power sources. However, the development in small and portable power banks can provide additional hours of operation without the need for a wired charging power supply.

Mobile devices: nowadays smartphones are equipped with batteries with capacities of more than 5000mAh of usable power. This is usually enough for a full working day out of home and office. Combined with mobile power banks, the time interval between two required wired charging sessions could be extended.

Wireless networks: as SME2EM makes use of wireless and cellular networks, chances that a patient is within reach of Wi-Fi and/or 3G/4G networks is very high in most areas. In case those are not available, satellite communication is also possible.

From a security perspective, the communication between the sensor and the mobile application is usually secured by the protocols shipped with the sensor and the libraries provided by the manufacturer. As the sensors are usually closed boxes, it is not possible to customize security features between the sensor and the mobile application. Except that part of the architecture, all other components implement various customizable and state-of-the-art secuirty techniques to make sure the data being transmitted is secure. In this version of the architecture, we make an extensive use of an international de facto security standard, namely TLS/SSL3 [44].

In the following, we describe the main components of our architecture׳s layers and their implementations. Since these components provide intelligent functions that existing systems do not, we then present in our description the required information that explain and specify how and why each one of these components (e.g., data acquisition, pre-processing, feature extraction and selection, classification and visualization) is characterized as smart. To support high-availability and ease of deployment and integration, all components are implemented as Web services/Cloud services.

The architecture׳s upper layer includes a set of smart monitoring processes described as follow:
                              
                                 1.
                                 Smart data acquisition: this process smartly handles data and signal retrieval and transmission in an effective way. The event-driven mechanism is developed within the mobile application to pro-actively and intelligently collect data only: (1) when needed; (2) when a specific pre-defined/pre-programmed situation occurs; or (3) when unexpected events happen. When the collected data are accurate, reliable, and effective, then only meaningful data, that can be used for identifying and diagnosing disease patterns from health patterns, are captured.

The mobile application has required preliminary logic to decide on the accuracy, reliability, and effectiveness of collected data. This logic is mainly based on continuous control of the sensors׳ contact with the body as well as the use of vital signs thresholds (e.g., normal min and max values) as provided by physicians. Finally, SME2EM data acquisition is considered smart, as it implements the event-driven mechanism and the data of interests to the diagnosis process is solely tagged for synchronization with the back-end server, while other acquired data remains on the mobile, in case they might be required later.

Smart data pre-processing: this process handles data pre-processing and implements a couple of smart features at the mobile devices to effectively retrieve and transmit sensory data. These features include data compression, grouped transmission, delayed transmission, and piggybacking. The main motivation behind implementing such features within mobile application is to optimize the transmission cost by reducing required resources (e.g., battery and network).

The pre-processing activity is characterized as smart, since each one of these actions (e.g., compression and piggybacking) is executed only if resources are available and the action will be of benefits. For example, if the compression action at some point is going to use more resources than the transmission of non-compressed data, the compression action is not performed.

Smart feature extraction and selection: this process applies only when data collected are complex signals recorded by ECG and EEG. It combines different feature extraction techniques to improve the accuracy of differentiating individual disease׳s states, which cannot be obtained by individual techniques. It also improves the processing time needed to select relevant features by combing filter and wrapper selection algorithms into an effective algorithm [4].

The feature extraction and selection are branded as smart, since the developed algorithms are of proactive nature, meaning that their outputs will be changed according to the embedded learning algorithms and training-sensing EEG (or ECG) signals. Thus, each patient may have different selected features.

Smart classification and diagnosis: this process combines different unsupervised learning techniques (e.g., hierarchical clustering techniques) to increase precision and robustness of the classification and diagnosis process [4]. From a transactional flow perspective, this process is invoked through Web services whose functionalities are exposed to other mobile applications. The classification algorithm is characterized as smart as it is readily a proactive one as well as its input selected features are smart as well.

Smart visualization: the process of visualizing data serves the following purposes: (1) validation of collected data; (2) support physician to make appropriate decisions; (3) report on continuous updates on seizures; and (4) preparation of any interventions in case of critical situations. The data can be presented using different views that include: (1) a summary of monitoring results, graphs, and patterns of readings, and (2) a report on discrepancies of measures and generation of automatic preventive actions that might be suggested. Since the volume, speed, and dynamist of collected data characterize signal-based monitoring, then a visualization activity consists of: (1) pre-processing and formatting of sensory data, (2) personalized views, (3) optimized display, (4) meaningful representation (e.g., 3D representation), and (5) on-demand visualization. The visualization features of SME2EM are considered as smart, as they achieve proactive, dynamic and adaptive behaviors, which are implemented in our graphical user interface (GUI).

It is worth mentioning at this point that the usability of our monitoring system has been addressed in the proposed system architecture with respect to the setup purposes and the interaction of prospective users. For setup purposes, SME2EM provides an easy set up wizard based on illustrative screens so as to show the user how to wear the sensor. Also, we expect that the user׳s physician will provide a live demonstration when the user is first introduced and provided with the system.

While the wizard and the demonstrations are important during the first uses of the system, they become of less interest as users get used to the setup. At that time, the user will only need to wear the wireless sensor and then click on the mobile application icon, all SME2EM activities will follow automatically. It is also to be noted that modern body sensors are quite light and easy to wear. As will be discussed in Section 5, a control panel is provided to show the quality of contact with the body. Whenever the contact is not appropriate, the user gets a warning message as well as illustrative visuals, which can easily guide them to fix the situation.

From a user interaction point of view, the GUI of the monitoring application is designed taking into account profiles of users. Such users are classified as experts, intermediate, low, or illiterate users. Expert users have a full view of the GUI while illiterate users are provided with color patterns and visual icons such that each color has a standardized specific meaning. The meanings of colors and icons are clearly explained by the treating physician during the initial introduction to the system. Other users are provided with well-understood information. The process can be further developed by adapting approaches from the literature (see for example [45,46]). As soon as the sensor is appropriately fixed and the application is launched, the end user does not have to do anything extra so as to keep the monitoring session running. In fact, the distant doctor has means by which they remotely interact with the user׳s application.

Continuous monitoring will generate a massive amount of data. Managing these data requires intelligence and processing capabilities that should integrate different technologies, data-oriented techniques, platforms, and infrastructures. The application of these techniques relies heavily on: (1) the availability of resources needed to store and process these data, (2) the accuracy and consistency of collected data itself, (3) the resource availability, and (4) the network availability. We describe here the lower layers׳ technologies and infrastructures used to support and implement the set of monitoring processes along with the smart features they implement. These particularly include the following:
                              
                                 1.
                                 Cloud infrastructure and services: Cloud infrastructure and services will heavily support monitoring processes with storage, processing, and networking capabilities while maintaining a high-scalability, availability, and elasticity capabilities. Cloud data centers offer the possibility to scale up with the number of monitored patients, the size of data stored and processed by various monitoring processes, and the number of provided monitoring services (e.g., pre-processing, feature extraction and classification).

Service oriented architecture: web services technologies will allow us to integrate different monitoring processes and provide each process as a service. This will support full integration of the complete solution regardless of their implementations, underlying platforms, manufacturers, and technologies used by each monitoring process.

Big data technologies: since continuous monitoring can be classified as big data, different technologies that support big data processing, classification, and analysis can be directly used. Technically, MapReduce
                                       5
                                    
                                    
                                       5
                                       Available at: http://research.google.com/archive/mapreduce.html.
                                     and Hadoop
                                       6
                                    
                                    
                                       6
                                       Available at: http://hadoop.apache.org.
                                     can be used for distributed data processing, Mahout
                                       7
                                    
                                    
                                       7
                                       Available at: http://mahout.apache.org.
                                     for advanced analysis, and MATLAB for signals processing (e.g., filtering, smoothing, segmenting, extracting features).

In this section, we formally model the SME2EM system architecture in order to automatically verify its correctness against desirable properties. This verification process is done at design time before the implementation process is undertaken to help designers detect and correct any potential design error.

The following health scenario describes the sequence of operations performed by the main entities of SME2EM. The scenario begins when a patient wearing a sensor logins to the SME2EM monitoring system after providing credential information. If the patient fails to enter the correct login information, the system evolves into the failure state and then moves to the final state, named logout state, after triggering an error message. By entering the correct information, the system initializes the cycle of the monitoring process: acquire signals, smart visualize data, store data, preprocess data, extract and select features, detect life-long disease states, visualize results, generate report, and take decision.


                        
                        Fig. 2 illustrates the finite state machine of the SME2EM monitoring system in which each state is identified by its name and connected with other states by appropriate transitions. The names of the transitions reflect the corresponding action. According to the received decision, the system either: (1) recommends the patient to stay at home with/without a new medication dose and evolves into the logout state; (2) informs the patient to visit a hospital, dispatches the ambulance if the situation necessitates an emergency intervention and then evolves into the final state, named Necessitate_Emergency; or (3) continues sensing in order to engage into another monitoring cycle.

Since we model each process in the processed architecture as a Web service or a set of Web services, we can implement each service as an autonomous agent. Thus, the SME2EM monitoring system described in Fig. 2 can be modeled as a multi-agent system (MAS). Specifically, as in the recent work introduced in [47], we implement a Web service as an intelligent agent in order to use the formalism of interpreted systems. This formalism provides a useful framework to model a MAS system in a natural and standard way. To use the formalism to model our system, we assume the MAS system is composed of a set 
                           
                              AG
                              =
                           
                           
                              {
                              
                                 1
                                 ,
                                 …
                                 ,
                                 n
                              
                              }
                           
                         of 
                           
                              n
                           
                         agents enacting and implementing services in which each service 
                           
                              i
                              ∈
                              AG
                           
                         is defined by:
                           
                              •
                              A set 
                                    
                                       
                                          
                                             L
                                          
                                          
                                             i
                                          
                                       
                                    
                                  of finite local states. In Fig. 2, Preprocess, Extract_Select_Features and Detect_Disease_states are some examples of the server service׳s local states.

A set 
                                    
                                       
                                          Act
                                       
                                       
                                          i
                                       
                                    
                                  of finite local actions. In Fig. 2, continue_Sensing and stay_at_Home are two examples of the system service׳s local actions.

A local protocol 
                                    
                                       
                                          
                                             P
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             : L
                                          
                                          
                                             i
                                          
                                       
                                       
                                          →
                                       
                                       
                                          
                                             2
                                          
                                          
                                             
                                                
                                                   Act
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                  is a function that delineates the set of allowable actions at a given local state. In Fig. 2, 
                                    
                                       
                                          P
                                       
                                       
                                          System
                                       
                                    
                                 (Login)= {incorrect_Info, correct_Info}.

The configuration of all services in the system at a given time is represented by the notion of global state 
                           
                              s
                           
                         of 
                           
                              n
                           
                         elements, i.e., 
                           
                              s
                              =
                           
                           
                              (
                              
                                 
                                    
                                       l
                                    
                                    
                                       1
                                    
                                 
                                 
                                    ,
                                    …
                                    ,
                                 
                                 
                                    
                                       l
                                    
                                    
                                       n
                                    
                                 
                              
                              )
                           
                        , where each element 
                           
                              
                                 
                                    l
                                 
                                 
                                    i
                                 
                              
                              
                                 ∈
                              
                              
                                 
                                    L
                                 
                                 
                                    i
                                 
                              
                           
                         represents a local state of service 
                           
                              i
                           
                        . Therefore, the set of all global states 
                           
                              S
                              =
                           
                           
                              
                                 L
                              
                              
                                 1
                              
                           
                           
                              X
                              …
                              X
                           
                           
                              
                                 L
                              
                              
                                 n
                              
                           
                         is the Cartesian product of all local states of 
                           
                              n
                           
                         services. The global transition function is defined as: 
                           
                              T:S X ACT
                              →
                              S
                           
                        , where 
                           
                              
                                 
                                    ACT
                                 
                                 =
                              
                              
                                 
                                    Act
                                 
                                 
                                    1
                                 
                              
                              
                                 
                                    
                                    X
                                 
                                 …
                                 
                                    
                                    X
                                 
                              
                              
                                 
                                    Act
                                 
                                 
                                    n
                                 
                              
                           
                         and each component 
                           
                              a
                              ∈
                              ACT
                           
                         is a tuple of actions, called joint action. The local transition function is defined as: 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                              
                                 :
                              
                              
                                 
                                    L
                                 
                                 
                                    i
                                 
                              
                              
                                 X
                              
                              
                                 
                                    Act
                                 
                                 
                                    i
                                 
                              
                              
                                 →
                              
                              
                                 
                                    L
                                 
                                 
                                    i
                                 
                              
                           
                        .


                        Definition (Models) our model of MASs is a tuple 
                           
                              M
                              =
                              (
                              G
                              ,
                           
                           
                              
                                 T
                              
                              
                                 R
                              
                           
                           
                              ,
                              I
                              ,
                              v
                              }
                           
                         where:
                           
                              •
                              
                                 
                                    
                                       G
                                    
                                    
                                       ⊆
                                    
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                    
                                       ×
                                       …
                                       ×
                                    
                                    
                                       
                                          L
                                       
                                       
                                          n
                                       
                                    
                                  
                                 is a set of global states for the system.


                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             R
                                          
                                       
                                       
                                          ⊆
                                       
                                       
                                          G
                                       
                                       
                                          ×
                                       
                                       
                                          G
                                       
                                    
                                 
                                 is a total transition relation defined by 
                                 
                                    
                                       (
                                       
                                          g
                                          ,
                                          g
                                       
                                       )
                                    
                                    
                                       ∈
                                    
                                    
                                       
                                          T
                                       
                                       
                                          R
                                       
                                    
                                  
                                 if there exists a joint action 
                                 
                                    
                                       (
                                       
                                          
                                             
                                                a
                                             
                                             
                                                1
                                             
                                          
                                          
                                             ,
                                          
                                          
                                             
                                                
                                                   …
                                                   ,
                                                
                                                
                                                   a
                                                
                                             
                                             
                                                n
                                             
                                          
                                       
                                       )
                                    
                                    
                                       ∈
                                    
                                    
                                       ACT
                                    
                                  
                                 such that 
                                 
                                    
                                       T
                                    
                                    
                                       (
                                       
                                          
                                             g
                                          
                                          
                                             ,
                                          
                                          
                                             
                                                a
                                             
                                             
                                                1
                                             
                                          
                                          
                                             ,
                                             …
                                             ,
                                          
                                          
                                             
                                                a
                                             
                                             
                                                n
                                             
                                          
                                       
                                       )
                                    
                                    
                                       =
                                    
                                    
                                       g
                                    
                                    
                                       ′
                                    
                                 .


                                 
                                    
                                       I
                                    
                                    
                                       ⊆
                                    
                                    
                                       G
                                    
                                  
                                 is a set of initial global states for the system.


                                 
                                    
                                       V
                                    
                                    
                                       :
                                    
                                    
                                       Ap
                                    
                                    
                                       →
                                    
                                    
                                       
                                          2
                                       
                                       
                                          G
                                       
                                    
                                 , where 
                                 
                                    
                                       Ap
                                    
                                  
                                 is a set of atomic propositions, is a valuation function.

Another advantage of the interpreted system formalism is that it is directly implemented in the symbolic model checker, called MCMAS [48]. The MCMAS tool is able to automatically verify the correctness of MASs against specifications expressed in Computation Tree Logic (CTL) [49].


                        Definition (Syntax) The syntax of CTL is given by the following grammar rules:
                           
                              
                                 
                                    ϕ
                                    ∷
                                    =
                                    p
                                    
                                    
                                       |
                                       
                                          
                                          ¬
                                          ϕ
                                          
                                       
                                       |
                                    
                                    
                                    ϕ
                                    ∨
                                    ϕ
                                    
                                    
                                       |
                                       
                                          
                                          E
                                          X
                                          ϕ
                                          
                                       
                                       |
                                    
                                    
                                    E
                                    G
                                    ϕ
                                    
                                    |
                                    
                                    E
                                    
                                       (
                                       
                                          ϕ
                                          
                                          U
                                          
                                          ϕ
                                       
                                       )
                                    
                                    
                                 
                              
                           
                        where 
                           
                              
                                 p
                              
                              
                                 ∈
                              
                              
                                 Ap
                              
                           
                         is an atomic proposition; E is the existential quantifier on paths; 
                           
                              X
                              ,
                              G
                           
                        , and U are path modal connectives standing for “next”, “globally”, and “until”, respectively; the Boolean connectives 
                           
                              ¬
                           
                         and 
                           
                              ∨
                           
                         are defined and read in the usual way.

To check the correctness of the MAS system, we use CTL to express some desirable properties.
                           
                              1.
                              
                                 Reachability property: given a certain state, is there a computation sequences to reach that state from the initial state? The used reachability properties are defined as:


                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             1
                                          
                                       
                                       
                                          =
                                       
                                       
                                          EF
                                       
                                       
                                          Fail
                                       
                                    
                                 
                              


                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             2
                                          
                                       
                                       
                                          =
                                       
                                       
                                          EF
                                       
                                       
                                          Logout
                                       
                                    
                                 
                              


                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             3
                                          
                                       
                                       
                                          =
                                       
                                       
                                          EF
                                       
                                       
                                          Extract
                                       
                                       
                                          _
                                       
                                       
                                          Select
                                       
                                       
                                          _
                                       
                                       
                                          Features
                                       
                                    
                                 
                              


                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             4
                                          
                                       
                                       
                                          =
                                       
                                       
                                          E
                                       
                                       
                                          (
                                          ¬
                                       
                                       
                                          store
                                       
                                       
                                          (
                                          
                                             
                                                Sig
                                             
                                             
                                                _
                                             
                                             
                                                Data
                                             
                                          
                                          )
                                       
                                       
                                          U
                                       
                                       
                                          store
                                       
                                       
                                          (
                                          
                                             
                                                Sig
                                             
                                             
                                                _
                                             
                                             
                                                Data
                                             
                                          
                                          )
                                       
                                    
                                  
                                 
                                    
                                       ∧
                                    
                                    
                                       EF
                                    
                                    
                                       preprocess
                                    
                                    
                                       (
                                    
                                    
                                       Sig
                                    
                                    
                                       _
                                    
                                    
                                       Data
                                    
                                    
                                       )
                                       )
                                    
                                 
                              

The formulas 
                           
                              
                                 ϕ
                              
                              
                                 1
                              
                           
                        , 
                           
                              
                                 ϕ
                              
                              
                                 2
                              
                           
                         and 
                           
                              
                                 ϕ
                              
                              
                                 3
                              
                           
                         check whether or not there exists a path to reach the Fail state, Logout state, and Extract_Select_Features state, respectively. The formula 
                           
                              
                                 ϕ
                              
                              
                                 4
                              
                           
                         means that there exists a path where the Server service will not start to preprocess signal data until the data is stored.
                           
                              2.
                              
                                 Liveness property: This property reflects that “something good will eventually happen”. For example, in all paths globally if the Server service detects disease states, then there is a path in its future through which the system will dispatch the ambulance for emergency intervention.
                                    
                                       
                                          
                                             
                                                
                                                   ϕ
                                                
                                                
                                                   5
                                                
                                             
                                             
                                                =
                                             
                                             
                                                AG
                                             
                                             
                                                (
                                             
                                             
                                                Detect
                                             
                                             
                                                (
                                             
                                             
                                                Diseases
                                             
                                             
                                                )
                                                →
                                             
                                             
                                                EF
                                             
                                             
                                                
                                                Neccessitate
                                             
                                             
                                                (
                                             
                                             
                                                Emergency
                                             
                                             
                                                )
                                                )
                                             
                                          
                                       
                                    
                                 
                              


                                 Safety property: This property insures that “something bad never happens”. For example, a bad situation is that the patient enters correctly the required information to login the system, but the latter never initializes the cycle of monitoring process.

The automatic evaluation of our tested formulas using the MCMAS model checker returns true within a very small execution time (specifically, 0.127s). In what follows, 
                        Table 2 reports the verification results of 10 experiments. The first experiment considers one patient connecting with the formal model representing the developed system architecture, while the last experiment considers 10 patients connecting with the formal model to acquire, transform, store, analyze and visualize their EEG brain signals synchronously. That is, we test in the last experiment the correctness of the developed system architecture during monitoring epileptic seizures of 10 patients all at the same time through, on the one side, their smartphones and, on the other side, their physicians׳ Tablets. Moreover, in the last experiment, the state space of our system model is 1.78614e+10 states, which executes in 399.609s and uses 80.7MB of RAM. Since the evaluation of our testing properties totally returns true, we guarantee that our system model is reachable, live, and safe.

We also ensure that the expenses cost of implementation and maintenance processes will be reduced; so we can proceed to implement our architecture. Before that, it is worth at this point mentioning that the model checking technique is in fact responsible for checking the correctness of the model at design time. So, if the implementation phase implements the exactly corrected model, then the model and its implemented system will have the same behavior. In order to computationally compare the performance of the model and the performance of the system, we used a testing technique at run time, which indeed complements the model checking technique. In our experimental results, we focused on a set of concrete experimental scenarios, which have a direct link with the tested properties. For example, in the data acquisition feature, the implementation has been able to correctly connect the mobile application with the sensor, read EEG data from the sensor, store that data locally, synchronize data with the back-end server, and provide appropriate views on the smart-phones. These implementation issues comply with the safety property.

To prove the applicability and effectiveness of our SME2EM architecture, we implemented its components and their inter-communications with respect to epileptic seizure disease. Based on the concise description of Section 3 and the positive empowerment by the verification process in Section 4, we have developed a working proof of concept that we introduced to address the appeared challenges. Before that, we start with configuring our employed test bed.


                        
                        Fig. 3 describes the test bed that we used to implement our monitoring architecture. The proposed configuration makes data and processes transparent to all monitoring entities. Indeed, our implementation promotes the separation of responsibilities by using three different servers. Particularly, all sensed data are stored in a MySQL database (Server #2 in fig. 3). All accesses to the data are done via Web services, which are hosted on the embedded Glassfish container and then deployed on the application server (Server #1 in fig. 3). Data analytics are performed on a separate server (Server #3 in fig. 3) in which different processing and analysis software tools (e.g., MATLAB and Weka) are deployed. For scalability purposes, those servers can be made redundant through physical and or virtual appliances.

The description of the main technologies, tools, devices, platforms, sensors and standard data-set that we have used to implement, and test our monitoring system is given as follows:


                           
                              
                                 •
                                 Servers: Intel CoreTM i7-3770K CPU @ 3.40GHz with Turbo Boast, 32GB of DDR3 RAM, 1TB hard drive, and 64-bit operating system.

Database: MySQL, version 5.5.28.

Web services: Restful Web Services, which are implemented in NetBeans 7.2.1 using JAX-RS Java API for RESTful services.
                                       8
                                    
                                    
                                       8
                                       Available at:https://jax-rs-spec.java.net.
                                    
                                 

Eclipse IDE 3.7 with plugin Android 5.0.

Smoothie chart: JavaScript charting library for stream data.
                                       9
                                    
                                    
                                       9
                                       Available at:http://smoothiecharts.org/.
                                    
                                 

JSON: JavaScript object notation.


                           
                              
                                 •
                                 Emotiv EPOC neuroheadset.
                                       10
                                    
                                    
                                       10
                                       Available at:https://emotiv.com/epoc.php.
                                    
                                 

MuseTM: the brain sensing headband.
                                       11
                                    
                                    
                                       11
                                       Available at:http://www.choosemuse.com.
                                    
                                 

MindWave Mobile: Myndplay bundle.
                                       12
                                    
                                    
                                       12
                                       Available at:http://store.neurosky.com/products/mindwave-mobile.
                                    
                                 


                           
                              
                                 •
                                 Samsung galaxy note 3.

Samsung galaxy Tab S 10.5-inch.

Dell Venue Pro Windows-based tablet, equipped with an Intel Atom Z3740D at 1.8GHz, 2GB of DDR3 RAM, and 32GB SSD.

We used the CHB-MIT database,
                              13
                           
                           
                              13
                              Available at:http://www.physionet.org/pn6/chbmit/.
                            which is collected at the Children׳s Hospital Boston. This data-set consists of EEG recordings from pediatric subjects with intractable seizures. Recordings, grouped into 23 cases, were collected from 22 subjects (5 males, ages 3–22; and 17 females, ages 1.5–19). Most files contain 23 EEG signals (24 or 26 in a few cases). Subjects were monitored for up to several days following withdrawal of anti-seizure medication in order to characterize their seizures and assess their candidacy for surgical intervention. EEG signals were sampled at 256 samples per second with 16-bit resolution. Number of recorded seizures included: 198 seizures.

@&#IMPLEMENTATION@&#

Hereafter, we describe the main SME2EM modules we have implemented. This includes the DaaS and VaaS modules along with the corresponding mobile applications and Web services.

Smart data integration (Data as a Service (DaaS)): we developed a set of Web services to support DaaS. These services are deployed on Server #1 to allow authorized applications to access and retrieve the current and the past EEG data in a seamless way using the set of interfaces depicted in 
                        Table 3. To support high-scalability and availability of data, and to benefit from the Cloud storage and processing resources, we have deployed our servers on a Cloud datacenter.

Smart visualization (Visualization as a Service (VaaS)): smartness of visual display is achieved by auto-optimization of the displayed data views with respect to the current battery measure. The mobile application smartly measures the battery power and automatically chooses the appropriate display by invoking the suitable Web services that nourish the menu with the needed data. For example, a 10% battery power would mean the device is running on critical battery (or Power Saver mode) and only the report view (or Reduced Data mode) is shown, while a 100% battery power (or Optimize Display mode) would show all menu׳s tabs, including application features, and graphics, as depicted in 
                        Fig. 4. Although the figure depicts only 3 battery levels, the battery power measured can range between 0% and 100% and the display will be optimized accordingly and with respect to user׳s profile. This will reduce data processing, and optimize battery consumption.

To experience different mobile devices, we have opted to use Windows-based mobile phone for the patient application and android mobile phone and Tablet for the physician application. The patient application basically focuses on data acquisition and presentation. The physician application is mainly responsible for presenting EEG readings in the tabular and graph forms, and incorporates a set of views, which illustrate seizure information, seizure map, and generated report information. The description of the physician application׳s capabilities is introduced below.

The data view illustrates the collected data from wireless sensors and reflects them into two views: tabular and chart views. The tabular view displays raw EEG readings, coming from every sensing point, while the graph view plots the readings on a 2-dimensional plan wherein the X-axis is the time and the Y-axis is the amplitude of the signal. For example, the tabular view in 
                           Fig. 5 shows the EEG readings obtained from 14 sensing points of the EPOC sensor. The graph view in 
                           Fig. 6 plots the EEG signals coming from 14 sensing points in a stackable user interface container wherein the frequency rate is 128Hz.

The seizure map in principle provides an overall idea about epileptic seizures to physicians. It specifically shows on a brain map the position of the seizure occurrence as well as the frequency of seizures at each of the monitored points as illustrated in 
                           Fig. 7. The seizure occurrences are listed by dates, which make the seizure easy to detect and then classify by physicians into a focal seizure or a generalized one.

Generated reports are the most useful feature of the physician Android application. This is because they provide a brief summary about detected seizures, seizure symptoms, seizure data as well as medication history of the selected patient as shown in 
                           Fig. 8. The physician can enter some inputs (e.g., diagnosis, advices, and comments) into the patient׳s file (see Fig. 8). The latter possibilities can be instantly updated and notified via Email or SMS.

During the analysis of both EEG data (or readings) flow and processes chaining in patient and physician applications, it was clear that the same data are going to be used by many processes (e.g., store, exchange, view, and plot) at the same time. This important aspect led us to the design of the users׳ applications by following the model–view–controller design pattern. However, each one of these processes raised a set of challenging issues. Particularly, the first challenge that we faced when handling sensory data from the EPOC sensor was the quantity of information and its relatively high-volume and velocity. Sensor reads data at a frequency of 128Hz from 14 sensing points; so the received raw data are huge and continuous.

The choice of data structure to hold readings had to be carefully selected. On one hand, a fixed-size data structure (e.g., array) might not be enough to store and handle acquired data while being processed by various processes (e.g., the plot process). In case of overflow, new EEG readings might prematurely overwrite precedent ones, which have not yet been processed. On the other hand, a dynamic and variable size of data structure might consume a good chunk of the system memory that is always limited in mobile devices. After a thorough analysis of the memory space requirements, we decided to use a queue data structure in which the sensor adds data at its tail while processes of the mobile application (e.g., store, view, and plot) removes data from the head.

The second challenge was related to: (1) the user interface and how to present all EEG readings in a suitable and clear view; and (2) different profiles of users. We solved this challenge by introducing the graph and tabular views. For the graph view, a dynamic and left-sliding plotting schema provides a live and up to date presentation of the EEG signal. To accommodate all channels in the same view, all signals׳ graphs are stacked vertically as shown in Fig. 6. For the tabular view (as in Fig. 5), presenting all EEG readings with their channels׳ identifiers and time stamps was another challenging issue. This challenge states that if new EEG readings are added at the top of the table, the cells with a high-frequency will be then pushed down; so the user (i.e., patient or physician) will not be able to clearly follow up. Otherwise, if new EEG readings are added at the bottom of the table, the view will then scroll up very fast; so the user will have a similar issue as in the previous case.

To offer a better usability and ease of use, we devoted a user experience pattern in developing the tabular view such that new EEG readings are added at the bottom of the table but, by a default, automatic vertical scrolling is disabled. This gives the user the ability to navigate through the readings up and down as well as right and left at their wills. However, the user can enable or disable the vertical scrolling through the settings of the tabular view. For both the tabular and the graph views, the user has the ability to select or unselect channels in order to view and plot. This is mainly useful when the patient or the physician is only interested in a subset of channels. For example, when a seizure happens in a subset of channels and other channels do not provide any supporting information.

The objective of this analytical evaluation is to study the growth of data with varying number of sensing points and their frequency of sensing. This study is very important to have a priori idea on the size of collected data so that the infrastructure can be set accordingly. If the size of the sensed data is above what the infrastructure can handle in a timely manner, it would affect the viability or at least the effectiveness of the mobile monitoring system.

The main overhead in the EEG mobile monitoring is the amount of data being collected, processed, and transmitted. In fact, continuous EEG monitoring generates a considerable amount of data. For an EEG signal to be representative, there is a minimum requirements on the frequency rate of sensing as well as the number of sensors to use, such as scalp coverage [50]. An EEG sensor has many contact points that have a direct contact with the scalp and read the EEG wavelengths, which constitutes the EEG signals. All the contact points are connected to the same sensor controller. In the literature, there is sometime a misuse of language referering to both the sensing points and the sensing controller as “sensor”. To avoid this ambiguity, in this article, we refer to the sensor controller as ‘sensor’ and to the sensing heads as “sensing points”. For the same purpose, we refer by “single reading” to a single reading from a sensing point of contact and by “sensor reading” to a tuple that consists of all single readings, taken at the same time from all sensing points.

As stated above, EEG sensors have a varying number of sensing points, n. In available sensors, this number can range from 3 to 64 sensing points. However, a sensor with 3 sensing points will not have a good coverage of the head scalp and the brain activity, hence the possibilities of “interpretive errors” increase, as shown in the guidelines developed by the American Clinical Neurophysiology Society for performing clinical electroencephalography.
                           14
                        
                        
                           14
                           
                              http://www.acns.org/pdf/guidelines/Guideline-1.pdf.
                           
                              http://www.acns.org/pdf/guidelines/Guideline-3.pdf.
                         Moreover, a sensor with 64 sensing points will generate a considerable amount of data that have apparent redundancy; hence, the probability of interpretive errors decreases but the size of sensed data increases. In general, this phenomenon is similar to wireless and cellular networks. That is, if two sensing points are too close, they will sense about the same data, but if sensing points are bit distant, then the brain activity arising in midway between sensing points is not captured by neither of them.

The frequency rate of readings has a direct impact on the accuracy of the signal and has a drawback similar to the one of the number of sensing points. This drawback is that a high-frequency will give more granularity of signal, but will generate a huge amount of related readings for each sensing point. Modern and sophisticated sensors can acquire EEG waves up to a frequency rate of 20KHz. However, a signal at quite lower frequencies is still very representative. We also suppose that all sensing points have the same frequency rate of readings, which is the case for all sensors that we have experimented.

The size of each single reading consists of the reading׳s value and its meta-data. The later includes a time-stamp and the identifier of the sensing point, which was the source of the reading. Let the size of a single reading be sr bytes, the size of the vital sign value be sv bytes, the size of time-stamp be st bytes, and the size of the identifier be sid. The total size of a single reading can be then computed by:
                           
                              (1)
                              
                                 
                                    s
                                    r
                                    =
                                    s
                                    v
                                    +
                                    s
                                    t
                                    +
                                    s
                                    i
                                    d
                                 
                              
                           
                        
                     

since a sensor usually gets readings from all sensing points at once using the same time stamp, the size of a sensor reading can be then computed by:
                           
                              (2)
                              
                                 
                                    s
                                    
                                       
                                          r
                                       
                                       
                                          n
                                       
                                    
                                    =
                                    n
                                    *
                                    (
                                    s
                                    v
                                    +
                                    s
                                    i
                                    d
                                    )
                                    +
                                    s
                                    t
                                 
                              
                           
                        
                     

when using a sensor with frequency rate f, the size of generated data after a sensing period of 1-second can be computed by:
                           
                              (3)
                              
                                 
                                    
                                       
                                          s
                                       
                                       
                                          1
                                          
                                             
                                             s
                                          
                                       
                                    
                                    =
                                    f
                                    *
                                    s
                                    
                                       
                                          r
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                           
                        
                     

it leads to the following equation for the size of generated data for a full day of continuous sensing:
                           
                              (4)
                              
                                 
                                    
                                       
                                          s
                                       
                                       
                                          1
                                          
                                             d
                                             a
                                             y
                                          
                                       
                                    
                                    =
                                    f
                                    *
                                    60
                                    *
                                    60
                                    *
                                    24
                                    *
                                    s
                                    
                                       
                                          r
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                           
                        
                     

by substituting the members of Eq. (2), we get:
                           
                              (5)
                              
                                 
                                    
                                       
                                          s
                                       
                                       
                                          1
                                          d
                                          a
                                          y
                                       
                                    
                                    =
                                    86400
                                    *
                                    f
                                    *
                                    
                                       (
                                       
                                          n
                                          *
                                          (
                                          s
                                          v
                                          +
                                          s
                                          i
                                          d
                                          )
                                          +
                                          s
                                          t
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

The last equation shows that the size of generated data for a sensing period is linear with regards to the sensor׳s frequency rate and the number of sensing points. In fact, the number of sensing points is always going to be low, as the number of required sensing points is limited. When the frequency rate gets very high, the product f ⁎ n will always stay linear and will never get into an exponential growth. The below figures show the size of data that will be generated during a sensing period for different sensors and frequencies when sv is 4 bytes, sid is 1 byte, and st is 9 bytes (including 2 bytes for year, 1 byte for month, 1 byte for day, 1 byte for hour, 1 byte for minute, 1 byte for second, and 2 bytes for milliseconds). Specifically, 
                        Fig. 9 shows the growth in the size of data when n is 14 sensing points and the frequency rate gets high, while 
                        Fig. 10 illustrates the growth in the size of data when f is 512MHz and the number of sensing points gets high.

We have executed a set of experimental scenarios to evaluate the smartness features of the SME2EM architecture. These scenarios evaluated mainly three features: data acquisition (DaaS), seizure information, and report generation (VaaS). For the data acquisition feature, the implementation has been able to correctly connect the mobile application with the sensor, read EEG data from the sensor, store that data locally, synchronize data with the back-end server, and provide the tabular and graph views on the mobile. All acquired EEG readings are verified against the sensor’s manufacturer test bench provided with the sensor platform running on Microsoft Windows desktop. This verification showed that readings on the mobile device are exactly the same, in terms of values and occurrences, to those observed in the test bench.

For the seizure information feature, since the live collected EEG data were sensed from healthy people who do not have seizure information; we opted to use the CHB-MIT data-set to test the seizure-related functionalities of our architecture. This data-set includes the required information of 198 seizures in order to experimentally test the developed architecture. SME2EM has detected all these seizures and then mapped them with their frequency of occurrences at each channel on the designed brain map. An example of experimental scenarios of seizure information is illustrated in Fig. 7. This example proves the effectiveness of the developed architecture in accurately reporting seizure information and visualizing seizures׳ episode on a brain map. The developed architecture also provides a summary of monitoring data for each patient (an example is shown in Fig. 8) and to the treating physician as support for diagnosis and clinical decision-making.

In terms of monitoring overhead cost, our experimental scenarios and their deep analysis have showed that the amount of data exchanged between the mobile application and the back-end servers (Server #2 and Server #3) is a linear increment and respects the growth rate analytically computed in the previous Section and also illustrated in Fig. 9. Although the growth rate is linear, the size of data to be synchronized between different processes is quite considerable. This size of data is technically acceptable and will have a financial impact only if it is synchronized over a non-flat rate 3G/4G connection. When the used connection is Wi-Fi or flat rate unlimited 3G/4G, the cost of synchronization is limited to the use of battery. As a measure to reduce the size of data, we proposed to use compression and selective synchronization techniques. The later techniques stipulate that only urgent EEG readings out of normal thresholds are synchronized over 3G/4G connections.

@&#DISCUSSIONS@&#

In this section, we provide a thorough discussion about advantages of the proposed SME2EM system assessed by comparing the performance of data processing, characteristics of extracted and selected features, and neatness of graphical user interfaces. We also specify which of the identified requirements are satisfied in the SME2EM system.

With regard to data acquisition, storage, and communication, our solution insures that data are acquired, stored, and exchanged in a cost-effective manner, thanks to key features provided by the SME2EM system. Data as a Service is developed to facilitate data access and integrate only data of interests to diagnosis, which in turn reduces the processing time and the needed resources. This also positively improves the performance of data transfer and storage space reduction.

In terms of feature extraction and selection, we developed an effective algorithm in terms of execution time, which combines filter and wrapper selection algorithms. This algorithm selects the best features. In our approach, the algorithm selects non-linear features computed by: (1) time domain techniques such as non-linear energy, Skewness, Kurtosis, and line length estimating Katz׳s Fractal dimension; and (2) discrete Wavelet domain techniques such as Skewness, Kurtosis, Shannon Entropy and Spectral Entropy. These findings cope with the literature. Moreover, we compared the automatic classification and diagnosis results obtained by the clustering technique, K-means, with the manual physician classification, and we found that they are very closely similar. For data visualization, the SME2EM architecture provides user-friendly interfaces, profile-aware, and a resource-aware visualization. The interface is optimized to display only relevant data while considering the available resources on the mobile device. In addition, users are classified per profile (e.g., experts, intermediate, and illiterate), which maximize application׳s usability and user satisfaction.

Results from the experiments we have conducted so far confirm our initial design guideline: adapting the visual components will affect the amount of used resources. In this suite of experiments, we tried various options of displaying data: list view (see Fig. 5), graph view with some channels plotted (see Fig. 6), and graph view with all channels plotted. Two sets of experimental results are reflected in 
                        
                        Figs. 11 and 12.


                        Fig. 11 shows how the amount of battery used goes down when we reduce visual components. In the same figure, the focus is on the number of sensing points from which values are being plotted. As specified above, the Emotiv sensor has 14 sensing points. The amount of saved battery is considerable if we plot values only from seven sensing points, the saving amount is even better if we disable the plotting aspect at all, while keeping data displayed in real-time in the list view. Fig. 12 shows the impacts of enabling or disabling the list view of the graph components on the used processor time. The later goes significantly down from 64.5 CPU percentage of usage when list view and graph view are displayed to 52 CPU percentage of usage when both visual components are disabled.

In this article, we proposed a smart and general end-to-end mobile-based monitoring architecture, called SME2EM, which is dedicated to automatically monitor and visualize different states of life-long diseases. The key features of our architecture solution include smart data integration, optimization of mobile resource management, monitoring overhead minimization, and smart data visualization. All processes of the architecture are developed and implemented using SOA, Web services, and Cloud services, which make them easy to deploy and integrate, and provide high-scalability and availability.

The proposed system architecture has been evaluated and assessed twofold: formally using a model checking technique and experimentally through a set of concrete experimental scenarios with respect to a testing technique. Its overhead cost has been analytically and experimentally evaluated as well. All these evaluations proved the applicability and effectiveness of our architecture solution to continuously and automatically monitor and visualize epileptic patients׳ states in an effective manner, while maintaining key system׳s properties such as adaptability, scalability, data correctness, availability, and reliability. Finally, the introduced architecture can be effectively employed as a smart system to assist physicians, clinicians and neurophysiologists in performing their work and decisions in an efficient and accurate manner. It would also help government health-care centers to rapidly intervene in the situation of emergency cases. Technically, our system can be readily implemented and deployed in many clinical research centers and laboratories to assist researchers and support cooperative studies.

As future work, we are planning to evaluate our architecture system in a large-scale environment wherein key health-care agencies might be involved. Given that, we are planning to investigate the applicability of the developed architecture in detecting and analyzing other life-long disorders, such as Alzheimer and Parkinson׳s disease [1,2]. Moreover, we are firmly looking at the evaluation of the quality of each component of the architecture during live monitoring. We also plan to use the reactive event calculus (REC) (for example the one implemented in REC
                        15
                     
                     
                        15
                        
                           https://www.inf.unibz.it/~montali/tools.html.
                     ) to monitor the states of each components incorporated in the developed architecture. Observing such states will in fact enable us to verify the good behaviors and/or bad behavior (if there exist) of the system architecture׳s components while the system is running. Doing so will provide another level of trust, after successful verification at design time and thorough testing during the implementation. This will give additional confidence to continuous monitoring stakeholders, including patients and physicians.

The authors whose names are listed immediately below certify that they have NO affiliations with or involvement in any organization or entity with any financial interest (such as honoraria; educational grants; participation in speakers׳ bureaus; membership, employment, consultancies, stock ownership, or other equity interest; and expert testimony or patent-licensing arrangements), or non-financial interest (such as personal or professional relationships, affiliations, knowledge or beliefs) in the subject matter or materials discussed in this manuscript.

@&#REFERENCES@&#


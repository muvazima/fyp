@&#MAIN-TITLE@&#Spatio-temporal texture modelling for real-time crowd anomaly detection


@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A real-time crowd anomaly detection algorithm for video surveillance is proposed.


                        
                        
                           
                           The research has developed a spatio-temporal texture model for feature extraction.


                        
                        
                           
                           A redundant texture feature space has been composed by using wavelet transform.


                        
                        
                           
                           Detection algorithm is based on 3-sigma rule which is fast and robust.


                        
                        
                           
                           The system shows improved accuracy and efficiency against many benchmark systems.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Crowd anomaly

Spatio-temporal volume

Spatio-temporal texture

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

The increasing demands of intelligent surveillance applications have triggered many innovative developments in automated video event detection areas. These techniques, such as crowd anomaly detection, can be used in monitoring and tracking emergency situations occurred in crowded scenes, including busy motorways, high streets, sporting events, and open air concerts.

Modelling crowd scenes from video recordings present tough challenges due to severe occlusion problems among crowd subjects. Traditional top-down approaches, which focused on accurately tracking and identifying the so-called “abnormal” behaviours of crowd entities, have been proven inefficient and inaccurate for crowd-based anomaly detection [1]. Crowd scenes often contain uncertainties such as changes of subject density, average subject size, shape, and boundaries of these entities that can bring ambiguities to the definition and interpretation of the meaning and natures of crowd anomalies. For tackling those problems, it has been widely acknowledged that the modelling of all (or most of) the crowd behaviours through analysing their constituent elementary characteristics in a chosen feature space is unavoidable (the so-called bottom-up process).

While the visual appearance of an individual subject's behaviour in a crowd scene may vary, their intra-/inter- group dynamics within certain quantifiable feature space are often statistically identical, for example, among a flock of birds, a school of fishes, and even vehicles travelling on a motorway. The swarm behaviours are constructed of similar “visual traces” for a studied scene. In the case of crowd anomaly analysis, such as to detect people's sudden gathering or dispersion, complex interactions of crowd subjects may change the visual appearance of the local/global image observations, which has motivated this research to model the crowd scene “changes” through analysing their overall grouping dynamics and facilitating real-time (or near real-time) anomaly warning applications.

It is worth noting that “normal” and “abnormal” events are intrinsically ambiguous on semantic level. Certain crowd behaviours are normal in one scenario but may become hazardous in others. For example, crowds running in a marathon are “normal”, but groups of people suddenly start running in a shopping mall may indicate an accident or incident. Based on the nature of main stream surveillance applications, the occurrence of anomaly events usually counts a very small percentage of the entire surveillance cycle and often demands immediate verification and response. In this research, it is considered reasonable to define normal crowd behaviours as the dominate pattern. Instead of composing complex event models for semantic interpretation, a normality crowd model in this research can be learnt and self-updated by abstracting the visual features along surveillance time-lines.

The core research problem highlighted in this research is to abstract effective visual features which can accurately describe normal crowd activities within the spatial and temporal domain, and to devise a robust decision making algorithm for real-world settings. Due to the application-oriented nature of this research, the implementation strategy should also be easily adopted by modern closed-circuit television (CCTV) systems with minimum lag.

In this paper, a crowd anomaly detection algorithm has been introduced based on image textures formulated by spatio-temporal information. The so-called spatio-temporal texture (STT) has been proven as an effective dynamic representation media and mechanism for single human action detection. This research explores its characteristics in maintaining the statistical consistency across crowd events domain and its sensitivity to group anomalies (or sudden changes). A “redundancy” feature space has been formulated based on the STT structure through wavelet transform, which enables a flexible multi-criteria binary decision making mechanism to be constructed.

This paper is structured as follows: a literature review of the related crowd modelling techniques have been introduced in Section 2. Section 3 focuses on the design of STT-based crowd modelling techniques. An innovative crowd anomaly detection algorithm is presented in Section 4. System evaluations over benchmarking approaches have been highlighted in Section 5. Section 6 concludes the research with a discussion on the pros-and-cons of the devised method and envisaged future improvements.

@&#LITERATURE REVIEW@&#

Computer vision-based crowd behaviour analysis has attracted immense attention from the research and application domains since the 1990s [2].Various algorithms and techniques for assisting the precision and speed of the processes have been studied in the last two decades. In general, there are three representative approaches: individual feature-based, flow field-oriented, and spatio-temporal feature-driven.

In the first category, crowd behaviour is often treated as an assembly of individual activities aggregated from each crowd entity. For example, a crowd movement along a busy street can be recognised as a group of people walking in the same direction. These methods are focused on describing crowd attributes by locating, isolating and analysing each crowd member. Benefited from recent development on machine learning theories and practices, those methods, such as tracking pedestrians through face detection [3] and estimating crowd size through head contour counting [4], have been proven as powerful individual-oriented tracking strategies [2,5].

Methods in the second category define the crowd scene as a dynamic flow field, which is the most popular approach to date, for analysing crowd features. Early studies, such as the “Minkowski fractal dimension” model [6], and the flow-based “crowd motion” model [7], had focused on the extraction of crowd attributes from the vector fields to describe crowd density, moving directions, and boundaries. In recent years, more attention has shifted towards the application-oriented techniques to improve crowd pattern interpretations [8–10]. In 2007, Ali [11] first introduced a crowd scene model based on “finite time Lyapunov exponent field” - an extension of the flow-filed model - for segmenting extremely dense crowd scenes recorded in a video. The segmentation outputs are then used in the so-called “floor field model” calculation for tracking specific individuals from dense human crowds [12]. This model has also been applied in group tracking that containing multiple or intersected crowd entities [13]. Rodriguez's off-line dominating crowd moving direction learning algorithm [14] has also been proven as an effective flow-based tracking approach. Related research works, such as Crowd Kanade-Lucas-Tomasi (KLT) corners [15], multi-label optimisation [16], and Lagrangian particle trajectories (“work-flow” model) [17], have defined crowd anomaly features from abstracted flow-field data. Those methods demonstrated their potentials in tracking the dynamic crowd under extremely crowded and partial occluded conditions but are bound to pre-defined crowd patterns and specific applications

Different from the first category, the flow field-based techniques are mainly based on the so-called “global” crowd motions. The impact of the “local” and individual crowd member is often ignored. However, it is widely accepted that acts from localised entity or entity group can bring significant changes to a crowd's consistency and its dominant motion pattern. Therefore, a more generic crowd model should be established for describing the interactions of both the local and group entity features.

The third significant approach defines the crowd scene videos as Spatio-temporal Volume (STV), which combines global crowd dynamics into a three-dimensional model. For example, in 2009, Benezeth [18] introduced a motion labelling method based on the co-occurrence of features defined in STV. The model has been implemented as a function of the Markov Random Field (MRF) for crowd anomaly detection. Kratz [19] introduced a STV-based motion pattern modelling method for highlighting the spatial-temporal statistical characteristics of extremely dense crowd scenes. In 2012, Bertini [20] developed a STV-based anomaly location detection technique through using localised cuboids in an unsupervised learning framework. The method has been proven as a valid approach for non-parametric modelling of spatio-temporal features.

Recently, another important “post-” processing model employing information fusion techniques has been introduced. Pilot researches, such as Mehran's “social force model” [21] and its optimised versions such as “interaction forces” [22,23] have been developed to serve as the preliminary assumptions for crowd behaviour patterns. The models require pre-defined conditions to be satisfied before operating, for example, the majority of a crowd should move towards the same target area, which restricts their flexibility in real-world applications.

It is also worth noting that the unsupervised (and some self-supervised) machine learning algorithms are becoming popular for detecting crowd anomalies. For example, Feng introduced an online self-organizing map (SOM) [24] to model crowd scenes, which keep updating its “normal” patterns by using new feeds. Jiang [25] used an unsupervised clustering algorithm to compare crowd members and their neighbours for identifying significant variations – sign of anomalies.

In this research, an innovative anomaly crowd detection strategy based on the statistical crowd features extracted from STTs has been devised. The texture model contain strong statistical characteristics for describing repetitiveness and randomness of recorded scenes, which inherently combines local and global crowd entity features. It is based on the assumption that a crowd scene and its related dynamic patterns can be encapsulated in the texture model conforming human perceptual intuition. Whilst other approaches have attempted to combine crowd scene texture features with spatio-temporal information [26,27], the proposed method justifies its core value through enabling real-time anomaly detection without the time-consuming machine learning process and rigid assumptions on crown behaviour patterns.

Spatio-temporal Texture (STT) model is a statistical model developed in this research, which is sensitive to the sudden changes of crowd motions.


                     Fig. 1
                     
                     
                      illustrates the main steps for defining STT from raw video data. In this pipeline, STT is composed by using spatio-temporal volume and its slices. The slices contain crowd scene information and can be abstracted using wavelet transforms. After transforming each slice from spatio-temporal domain into wavelet space, the crowd motion pattern can be analysed using statistical techniques such as correlation in related sub-bands.

As illustrated in Fig. 2, a Spatio-temporal Volume (STV) is defined in a 3D Cartesian space denoted by X, Y, and T (time) axes. In this structure, the concept of an individual frame is replaced by a continuous 3D volume section, in which its density, envelop and slices are all factors to the final interpretation of the model.

The STV data structure transforms the video event detection process from a conventional 2D frame-based mechanism into a 3D model analysis operation. Through this transformation, dynamic information of a crowd's moments can be represented by the variation of 3D shapes, flows, or point clouds. Various pattern recognition, shape analysis and matching algorithms can be applied to the volumetric crowd events.

As shown on the right in Fig. 2, a slice is generated by inserting a clipping plane at chosen position (the dash-line marked region) and going through the STV along the T axis. In this research, the position and direction of each STV slice are controlled by the local crowd region (shaded segments on the clipping plane), which will be explained in detail in Section 4.1.

Based on the viewpoint of human intuition, a static crowd texture contains spatially homogeneous image regions composed of the crowd members in random locations. As illustrated in Fig. 3(a), each frame marked by the dash lines has been cropped evenly into four sub-regions displayed alongside the original image. The “appearance” of each crowd member is different, but the sub-regions are quite similar and even visually indistinguishable. This similarity was caused by the pre-attentive decision of the human observer and stemmed from human vision biology and psychology. It is from this angle that this research set to investigate the spatial similarity of crowded scenes using extracted STV slices as pattern textures.

The spatial attributes shown in Fig. 3(a) are also applicable for modelling crowd dynamics. For example, captured by the STV slice shown in Fig. 3(b), sub-regions divided by dashed lines denote the different time sections along the video stream. Because the Marathon example used in Fig. 2 does not have sudden changes in terms of crowd behaviours, although the sub-regions contain different individual details, their compositing pattern textures are identical.

In case of an anomaly crowd event as shown in Fig. 4
                        , where a CCTV footage containing a sudden gathering and dispersing of a group of people during a shop-raid incident has been studied, the top row displays four snapshots from key event moments (t1, t2, t3 and t4). Between time t1 and t2, pedestrians were walking normally along the street. After t3, people start to rush into a shop. The changed patterns of pedestrians were encapsulated in the corresponding STV slices as shown in the bottom of the figure. The differences of the STV slices segments [t1, t2] and [t3, t4] are obvious to human observers, indicating the visual differences in STV slices can encapsulate changes from crowd.

Visual similarity is an intuitive concept based on the image appearance, which is consisted of varied and/or similar texture patterns. One of the classic mathematic models for describing this relationship using finite lattices is called Homogeneous Random Field (HRF) [28] , which has been widely adopted in nature image understanding [29]. In this research, HRF has been used for composing the initial STT feature space.

The fine-to-coarse-based image description schemes have been widely used in image recognition and analysis. Since a crowd scene contains rich information in both local and global feature levels over the entire STV space, an efficient translation- and rotation-invariant wavelet scheme based on the so-called “steerable pyramid” [30] has been used in this research.

The input image for each transformation is a sub-region of STV slice captured by a sliding window along the time (T) axis. Since the low pass band is subsampled by a factor of two along both axes, the size of the image need to be normalised to 2
                              n
                            × 2
                              n
                           .


                           Fig. 5 illustrates the core of a steerable pyramid where an image is treated as a linear combination of wavelet sub-bands from each layer of the pyramid. After splitting the input image into the high- and low-pass bands, the low-pass band is further decomposed into a group of oriented sub-bands and henceforth. The filers of this wavelet transform are polar-separable in the Fourier domain, which is a complex pair of even- and odd-symmetric filters corresponded by the real and imaginary parts of the filtering results.

The wavelet filter can be written as

                              
                                 (1)
                                 
                                    
                                       L
                                       
                                          (
                                          
                                             r
                                             ,
                                             θ
                                          
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             
                                                
                                                   
                                                      2
                                                      cos
                                                      
                                                         (
                                                         
                                                            
                                                               
                                                                  π
                                                                  2
                                                               
                                                            
                                                            
                                                               log
                                                               2
                                                            
                                                            
                                                               (
                                                               
                                                                  
                                                                     
                                                                        4
                                                                        r
                                                                     
                                                                     π
                                                                  
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            π
                                                            4
                                                         
                                                      
                                                      <
                                                      r
                                                      <
                                                      
                                                         
                                                            π
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      2
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      r
                                                      ≤
                                                      
                                                         
                                                            π
                                                            4
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      0
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      r
                                                      ≥
                                                      
                                                         
                                                            π
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       
                                          B
                                          n
                                       
                                       
                                          (
                                          
                                             r
                                             ,
                                             θ
                                          
                                          )
                                       
                                       =
                                       H
                                       
                                          (
                                          r
                                          )
                                       
                                       
                                          G
                                          n
                                       
                                       
                                          (
                                          θ
                                          )
                                       
                                       
                                       
                                       n
                                       ∈
                                       
                                          [
                                          
                                             0
                                             ,
                                             N
                                             −
                                             1
                                          
                                          ]
                                       
                                    
                                 
                              
                           where radial and angular parts are

                              
                                 (3)
                                 
                                    
                                       H
                                       
                                          (
                                          r
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             
                                                
                                                   
                                                      cos
                                                      
                                                         (
                                                         
                                                            
                                                               π
                                                               2
                                                            
                                                         
                                                         
                                                            log
                                                            2
                                                         
                                                         
                                                            (
                                                            
                                                               
                                                                  
                                                                     2
                                                                     r
                                                                  
                                                                  π
                                                               
                                                            
                                                            )
                                                         
                                                         )
                                                      
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            π
                                                            4
                                                         
                                                      
                                                      <
                                                      r
                                                      <
                                                      
                                                         
                                                            π
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      1
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      r
                                                      ≤
                                                      
                                                         
                                                            π
                                                            4
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      0
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      r
                                                      ≥
                                                      
                                                         
                                                            π
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (4)
                                 
                                    
                                       
                                          G
                                          n
                                       
                                       
                                          (
                                          θ
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             
                                                
                                                   
                                                      
                                                         2
                                                         
                                                            n
                                                            −
                                                            1
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               (
                                                               
                                                                  N
                                                                  −
                                                                  1
                                                               
                                                               )
                                                               !
                                                            
                                                            
                                                               
                                                                  N
                                                                  [
                                                                  
                                                                     2
                                                                     N
                                                                     −
                                                                     2
                                                                  
                                                                  ]
                                                                  !
                                                               
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               [
                                                               
                                                               
                                                                  cos
                                                                  
                                                                     (
                                                                     
                                                                     
                                                                        θ
                                                                        
                                                                        −
                                                                        
                                                                        
                                                                           
                                                                              
                                                                                 π
                                                                                 n
                                                                              
                                                                              N
                                                                           
                                                                        
                                                                     
                                                                     
                                                                     )
                                                                  
                                                               
                                                               
                                                               ]
                                                            
                                                         
                                                         
                                                            N
                                                            −
                                                            1
                                                         
                                                      
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      
                                                         |
                                                         
                                                            θ
                                                            
                                                            −
                                                            
                                                            
                                                               
                                                                  
                                                                     π
                                                                     n
                                                                  
                                                                  N
                                                               
                                                            
                                                         
                                                         |
                                                      
                                                      
                                                      <
                                                      
                                                      
                                                         
                                                            π
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      0
                                                      ,
                                                   
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           In the Equation, r, θ are polar frequency coordinates, L(r, θ) is low-pass band filter, and Bn
                           (r, θ) denotes the oriented filter with N directions. The initial value of the low- /high- pass filters can be defined by:

                              
                                 (5)
                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                   L
                                                   0
                                                
                                                =
                                                
                                                   
                                                      L
                                                      (
                                                      
                                                         r
                                                         2
                                                      
                                                      ,
                                                      θ
                                                      )
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                
                                                   H
                                                   0
                                                
                                                =
                                                H
                                                
                                                   (
                                                   
                                                      r
                                                      2
                                                   
                                                   ,
                                                   θ
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           For example, as shown in Fig. 6
                           
                           , the initial input of the process pipeline is the grayscale subarea of the STV slices from marathon video clip. In this 3-scale and 4-orientation wavelet sub-bands, the magnitudes hold important structural information of the pattern images.

Based on the wavelet transform, HRF highlights three groups of visual features. The crowd model can be constructed based on HRF for texture modelling, which has been summarised as:

• Fundamental low-level features
                        

The grayscale distributions extracted from each low-pass band and the down-sampled images of the steerable pyramid. The measurement is based on calculation of means, variance, skewness, kurtosis minimum and maximum values of every input STV slice's sub-region, as well as variances of the high-pass band, and skewness and kurtosis of every low pass images at each scale.

• Coefficient features
                        

The coefficient features are the local auto-correlations of the wavelet sub-bands. The features have been used for evaluating the periodical and long range correlations of the image distributions. Since the steerable pyramid can be an over-sampled linear representation introducing redundant feature dimensions, this research deployed an improved coefficient feature scheme based on auto-correlation at each low-pass band only for creating the scale-invariant model. Specifically, for measuring the characters of the texture frequencies and regularities, raw auto-coefficient correlations on each low pass band have been introduced into the process.

• Magnitude features
                        

As shown in Fig. 6, the large magnitudes appear similarly at the same locations of each scale, which represents the “edges”, “corners” and “bars” in the sub-bands. Using texture analysis techniques, such as the “second-order” texture features [31], the correlation of magnitudes from image sub-bands have been integrated into the design. This type of features is calculated by using cross-correlation of the pairs at adjacent positions, orientations and scales. Central samples of the auto-correlation of magnitude of each sub-band, cross-correlation of each sub-band magnitudes with those of other orientations at the same scale and coarser scales are recorded. Edge features based on cross-correlation of the real part of coefficients with both the real and imaginary part of the phase-doubled coefficients at all orientations of the parent's scales are also calculated.

During system testing, the total number of feature points is 710 on a 4-scales and 4-orientations wavelet transforms. In this paper, a redundant STT feature space has been designed. It is emphasised that the redundancy is caused by overlapped calculation of HRF components. For example, the variations of low pass images are also included in the autocorrelation. During the test, it is discovered that the “redundancy” calculation on overlaps actually serve as a “double check” that can significantly improve the robustness of the decision making process.

As illustrated in Fig. 7
                     , the system strategy deployed in this research starts from assembling a video buffer. In the experiment, the buffer was set to contain about 90 frames, approximately 3 s of video feeds.

The system contains two main modules: the learning pipeline and the detection pipeline. Both modules share the similar STT construction algorithm illustrated in Fig. 1. In this research, a normality crowd model is created by abstracting the normal instances’ of STT features on the fly. Any crowd events different from the normality will trigger the alarm.

A real life video stream contains not just rich dynamic data, but also signal noises and unwanted background information. It is essential to rapidly locate the crowded region and filtering out the noises. As shown in the Fig. 7, the learning module detects the moving crowd regions before composing the STV slices. This operation allows more dynamic information rather than static background and noises to be recorded on STV slices.

During the development, a so-called “average flow field” has been used in the prototype to evaluate the dynamic level of image scenes. The average flow field is composed by a group of binary calculations on optical flow field. Specifically, given a video clip containing Lv
                         frames, the average flow field 
                           
                              U
                              
                                 (
                                 
                                    x
                                    ,
                                    y
                                 
                                 )
                              
                              ∈
                              
                                 R
                                 2
                              
                              
                           
                        can be defined by

                           
                              (6)
                              
                                 
                                    U
                                    =
                                    
                                       ∑
                                       i
                                    
                                    
                                       u
                                       i
                                    
                                    ,
                                    
                                    and
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 
                                    
                                       u
                                       i
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   1
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      |
                                                   
                                                   
                                                      v
                                                      i
                                                   
                                                   
                                                      
                                                         |
                                                      
                                                      2
                                                   
                                                   ≥
                                                   
                                                      mean
                                                      (
                                                      |
                                                   
                                                   
                                                      v
                                                      i
                                                   
                                                   
                                                      
                                                         |
                                                         2
                                                      
                                                      )
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   0
                                                   ,
                                                
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              m
                              e
                              a
                              n
                              
                                 (
                                 ·
                                 )
                              
                              :
                              
                                 R
                                 2
                              
                              →
                              R
                           
                         calculate the average magnitude value of each flow filed. vi
                         denotes the Horn–Schunck optical flow field [32] calculated between the ith and the i + 1th frame. During the learning, the set of each flow field output can be denoted as 
                           
                              V
                              =
                              [
                              
                                 
                                    v
                                    1
                                 
                                 ,
                                 
                                    v
                                    2
                                 
                                 ,
                                 …
                                 
                                    v
                                    
                                       
                                          L
                                          v
                                       
                                       −
                                       1
                                    
                                 
                              
                              ]
                           
                        .


                        Fig. 8(
                        b) shows an example of U calculated by using video clips of Fig. 8(a). In the average flow field, higher values denote more dynamic changes across the timeline, which is mainly caused by the crowd movement; lower values, on the other hand, are usually caused by noise and insignificant changes. In the experiment, locations where U(x, y) ≤ 5 have been ignored based on empirical experience.


                        Fig. 8(c) highlights the boundary of U, which has been detected by using a group of morphological operations such as “open” and “convex hull”. Those boundaries limited the width of STV slices along the time line. Based on the definition of STV slices introduced in Section 3.1, a group of STV slices need to be sampled inside the region of U. For simplification, only XT (horizontal) slices and YT (vertical) slices are used. As illustrated in the Fig. 8(d), each sampled slice has been marked by lines across the XY (the frame) field. For keeping the detection accuracy and efficiency, it is not necessary to sample each slice at per pixel level. The distance between slices is set in between 10 and 50 pixels depending on the image size and resolution.

The average flow field provides the size, locations and directions of a crowd encapsulated on a sequence of STV slices. During the video buffering, those slices’ distribution information is set up as constants. These slices are renewed 
                           
                              L
                              =
                              
                                 L
                                 v
                              
                              −
                              
                                 L
                                 b
                              
                              +
                              1
                           
                         times for the entire learning process, where Lv
                         is the length of the video and Lb
                         denotes the length of the video buffer.

Given a group of STV slices for learning, the statistical texture features can be abstracted for establishing the model of crowd activities. Each STV slice instance has its own STT feature space 
                           
                              
                                 F
                                 
                                    i
                                    j
                                 
                              
                              =
                              
                                 [
                                 
                                    
                                       f
                                       
                                          i
                                          j
                                          1
                                       
                                    
                                    ,
                                    
                                       f
                                       
                                          i
                                          j
                                          2
                                       
                                    
                                    ,
                                    …
                                    
                                       f
                                       
                                          i
                                          j
                                          N
                                       
                                    
                                 
                                 ]
                              
                           
                        , (
                           
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              L
                              ;
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              S
                           
                        ), where 
                           
                              
                                 f
                                 
                                    i
                                    j
                                    k
                                 
                              
                              ,
                              
                              
                                 (
                                 
                                    k
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    N
                                 
                                 )
                              
                           
                         denotes the elements from STT feature space summarised in Section 3.3 and S denotes the total number of slices used in the video. Those operations generate S × L STT features in total for calculating the statistical distributions for the learning process.

During the experiment, it has been discovered that with fixed j, k values, 
                           
                              
                                 f
                                 
                                    1
                                    j
                                    k
                                 
                              
                              ,
                              
                                 f
                                 
                                    2
                                    j
                                    k
                                 
                              
                              ,
                              …
                              ,
                              
                                 f
                                 
                                    L
                                    j
                                    k
                                 
                              
                           
                         approximately follow the Gaussian distribution 
                           
                              N
                              (
                              
                                 μ
                                 ,
                                 
                                    σ
                                    2
                                 
                              
                              )
                           
                        . This empirical estimation works well on testing videos for anomaly detection (see Section 5), and has been used for modelling the normal crowd activities in this research. For each learning video in this design, μjk
                        , σjk
                         are defined as

                           
                              (8)
                              
                                 
                                    
                                       μ
                                       
                                          j
                                          k
                                       
                                    
                                    =
                                    
                                       1
                                       L
                                    
                                    
                                       ∑
                                       i
                                    
                                    
                                       f
                                       
                                          i
                                          j
                                          k
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (9)
                              
                                 
                                    
                                       σ
                                       
                                          j
                                          k
                                       
                                    
                                    =
                                    
                                       
                                          
                                             1
                                             L
                                          
                                          
                                             
                                                
                                                   ∑
                                                   i
                                                
                                                
                                                   (
                                                   
                                                      
                                                         f
                                                         
                                                            i
                                                            j
                                                            k
                                                         
                                                      
                                                      −
                                                      
                                                         μ
                                                         
                                                            j
                                                            k
                                                         
                                                      
                                                   
                                                   )
                                                
                                             
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Crowd anomaly detection in this research is a binary decision making process that labels “abnormal” from “normal” in a life feeds of CCTV frames to the video samples through comparing the detected STT features with the normality crowd model.

Same as the learning process, the STT features in the detection stage are also extracted from STV slices located at S positions using average flow field. For example, denoting the STT feature as 
                           
                              
                                 
                                    F
                                    ˜
                                 
                                 j
                              
                              =
                              
                                 [
                                 
                                    
                                       f
                                       ˜
                                    
                                    
                                       j
                                       k
                                    
                                 
                                 ]
                              
                           
                        , (
                           
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              S
                              ;
                              k
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              N
                           
                        ), the binary decision for each STT element is simply an accumulation of corresponding STT elements’ relations to the 3-sigma rule of Gaussian distribution, which is

                           
                              (10)
                              
                                 
                                    
                                       d
                                       
                                          j
                                          k
                                       
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   1
                                                   (
                                                   positive
                                                   )
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         f
                                                         ˜
                                                      
                                                      
                                                         j
                                                         k
                                                      
                                                   
                                                   ∈
                                                   
                                                      [
                                                      
                                                         
                                                            μ
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                         −
                                                         3
                                                         
                                                            σ
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                         ,
                                                         
                                                         
                                                            μ
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                         +
                                                         3
                                                         
                                                            σ
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                      
                                                      ]
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   0
                                                   (
                                                   negative
                                                   )
                                                
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        This operation has composed N sub-decisions for every STV slice. For making the “final” decision over the entire volume buffer, Dj
                        , a “voting ” mechanism has been introduced:

                           
                              (11)
                              
                                 
                                    
                                       D
                                       j
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            N
                                                         
                                                      
                                                      
                                                         ∑
                                                         k
                                                      
                                                      
                                                         d
                                                         
                                                            j
                                                            k
                                                         
                                                      
                                                      >
                                                      T
                                                   
                                                
                                             
                                          
                                          
                                             
                                                0
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        Eq. 11 starts from calculating a positive rate for all sub-decisions. A threshold, T, is then compared with the positive rate for making a final decision for the STV. In the voting mechanism, the threshold can be recognised as a pass-rate for the decision. Higher pass-rate means that the final positive decision for a slice requires more votes from its positive voters (
                           
                              
                                 d
                                 
                                    j
                                    k
                                 
                              
                              =
                              1
                           
                        ).

Since STV slices are independently distributed inside the average flow field, Dj
                         can be recognised as the local decision for a crowd image scene. Each Dj
                         can mark the normality or abnormality crowd event within its local area.

The developed prototype is an effective decision making system. The time consumption of the algorithm is much lower than the time used for video buffering (see details in Section 5.1). By using parallel programming strategy, the anomaly crowd behaviour can be detected before current video segments being cleared from buffer, which guarantees the real-time performance during the run.

In this research, a prototype system has been implemented to test the devised anomaly crowd detection model. The prototype has been run on a host PC with a 64bit Core i7 CPU (2 × 3.07 GHz) and 4GB RAM.

During the evaluation, this work has been compared with other benchmarking approaches such as Spatio-temporal Compositions (STC) [1] and Inference by Composition (IBC) [33]. The STC highlights its real-time performance and the IBC has been considered as one of the most accurate method for anomaly detection. All the methods have been tested under same hardware configurations and software setting.

Two popular online video databases, UMN [34] and UCSD [20], have been used for the system test. The UMN Dataset has been adopted for testing the system prototype design. It contains 11 scenarios subjecting to three different indoor and outdoor backgrounds (UMN1, UMN2, and UMN3). Each video records a group of people wondering in the scene and then escaping. The UCSD dataset contains two video scenes (Ped1 and Ped2) of pedestrians walking along the road. The anomaly events have been defined as cars or bicycles quickly passing through the crowd which could build up hazard road situations.

During the experiments, the video buffer has been set up for holding 3 s of video clips for all tests. All the video frames have been resized to 320 × 240 pixels, and only the grayscale channel has been used. For extracting STT features, the 3-scale and 4-orientation steerable pyramid wavelet transforms have been performed. The sizes of the input STV slices have also been normalised to 256 × 256 pixels through Bicubic interpolation.

The designed feature extraction and decision making algorithm is an effective solution for anomaly crowd detection. This test is designed for evaluating the time consumption of each step of the detection algorithm.

As illustrated
                        
                        
                        
                         in Fig. 9, the time consumption is calculated by measuring and averaging elapsed time of each step 50 turns. For a buffered video clip, the algorithm takes averagely 18.4 ms/frame based on 30fps video clip for normal/abnormal event detection. The break-down time consumption of anomaly detection has also been illustrated in the figure by using different colour labels.

It has been observed that detection steps such as STV construction, wavelet transforms and STT construction only take 3.3 ms to 5.6 ms per frame. The time consumed by overall detection operations is still far less than the video buffering process. During the experiment, an optimised prototype has been developed by running video buffering and anomaly crowd detection as two parallel processes, hence reducing the “playback” time, which is ideal for real-time surveillance applications.

The time consumption of this algorithm has been compared with popular approaches as illustrated in Table 1.
                        
                     

In the table, the STT feature-based approach introduced in this research performs faster than other benchmarking approaches. It also uses fewer memories for the data processing and storage, which is an important advantage for real-world system implementations.

To test the accuracy and robustness of the developed system, the receiver operating characteristic (ROC) curve is deployed during the test. The points on ROC curve are defined by true- and false-positive rate of the detection system. First, each video frame has been hand-marked by labels (i.e. “normality” and “abnormality”) as ground truths. The true-positive is then counted when a normality ground truth is marked correctly by the detection system. Otherwise, a false-positive entry will be recorded. For making a ROC curve, the threshold T was used as voting pass-rate (see Section 4.3) and increases from 0% to 100% in a 10% step size, which generates 11 points for a ROC curve.

• UMN database
                     


                        Fig. 10 shows some video snapshots from the UMN dataset. 5 s of video sampled from beginning of each clip has been used for learning, which only contains scene of a group of people wondering randomly in the scene. During the detection, the system sends alarms when the crowd started dispersing.


                        Fig. 11 shows the ROC curves for detecting anomaly crowd events from UMN dataset in the scene 1, 2 and 3. In the figure, STT feature-based approach developed in this research shows much better performance in all three scenes compared with STC and IBC. Because the anomaly crowd event in UMN datasets are occurred in the entire image scene, the better accuracy and robustness performances are contributed by the nature of STT model that both local randomness and global similarity can be described together along the spatio-temporal domain.

• UCSD database
                     

As illustrated in Fig. 12, anomaly events defined in UCSD database are more “local” than UMN. In the UCSD, only localised visual features are subjecting to change. For example, during the test, the crowd video containing only the pedestrians has been used for training. Alarms will be set off when road hazards occurred, such as cars, bicycles, and skateboarders passing through slowly moving pedestrians.

The horizontal and vertical lines in Fig. 12 mark the locations on XT and YT slices in the video volume indicating “abnormal” events. Since each STV slice is calculated independently, the marks can readily pin-point the position of the crowd anomaly regions in live video feeds.

Same evaluation strategy has been used for evaluating the system performance on the UCSD dataset. The test results have been represented by the ROC curves shown in Fig. 13. The proposed STT method shows comparable results with STC and IBC, but uses less time and system memory attributing to its simple and effective decision making algorithm introduced in Section 4.

The STT features are extracted from STV slices based on HRF texture analyses. Actually, for study visually undistinguished images, many texture models have been developed in recent years. During the feasibility test on the devised STT technique, texture models such as textons [35], and multivariate image analysis (MIA) [36] were chosen for benchmarking using the N-dimensional feature vectors and following same testing strategies introduced in Sections 4.2 and 4.3.

As shown in Fig. 14, comparing with other texture models, the devised approach and algorithms have shown promising characteristics for detecting crowd anomalies and proved the wavelet-based texture model as a superior tool for representing local randomness and global similarity.

Texture models, such as MIA and textons, are based on image moments and texture boundaries. Compared with wavelet-only approaches, they provide extra attention for the periodical nature and boundaries from different textures. It is believed that the combination of wavelet-, moment- and boundaries from the texture feature space can improve the sensitivity when detecting and locating crowd anomalies.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this research, an innovative STT based crowd anomaly detection method and its corresponding implementation techniques have been introduced. The prototype system starts from transforming video footages into a STV structure. After applying average flow field templates extracted from live video feeds, the highly dynamic areas from the crowd scenes can be quickly identified, which then guides the auto-selection of sizes, locations and directions of the sampling STV slices for further study. For distinguishing crowd “normalities” from abnormal behaviours, the sampled STT texture patterns are then analysed based on a Gaussian approximation model. A weighted multi-binary evaluation algorithm has been devised for online decision making based on the STT comparison outputs. The prototype system has shown satisfactory real-time performance during the tests and some promising characteristics for future intelligent CCTV surveillance applications.

The statistical STT features encapsulate both the local variations as well as global similarities of the established video volumes. Comparing with the state-of-the-art techniques, the devised method has shown increased efficiency, accuracy and flexibility. Based on the rotation- and translation- invariant wavelet transforms, STT models can be composed for more detailed analysis based on the similarity statistics between two crowd scenes along the timeline. The low-level texture feature-based thresholding algorithm in this project ensures the real-time performance of the system.

Although the current approach and system strategy are well-suited for high- and medium-dense crowd scenes of highly homogeneous STT feature patterns, for lower density crowd scenes where individual crowd element's behaviour may have significantly larger impact on the STT slice, the devised algorithm will gradually lose its performance superiority and robustness over other conventional image/frame-based approaches. Future work will see a crowd density estimation algorithm being investigated and embedded to the system for adaptive model selection and pattern recognition, which can open up new revenues for exploring more intelligent and adaptive crowd monitoring and early warning systems for real-life applications.

@&#REFERENCES@&#


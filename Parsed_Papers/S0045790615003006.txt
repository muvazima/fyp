@&#MAIN-TITLE@&#Automated detection and segmentation of drusen in retinal fundus images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Designed a new drusen detection and segmentation method finding meaningful drusen boundaries.


                        
                        
                           
                           To find true edges of drusen, a gradient based segmentation procedure is described.


                        
                        
                           
                           Connected component labeling is applied to remove suspicious pixels from drusen region.


                        
                        
                           
                           Edge linking is used to connect all labeled pixels into a meaningful boundary to detect drusen.


                        
                        
                           
                           The performance of proposed method is evaluated by (i) statistical measures and (ii) quantification of drusen to grade severity of age-related macular degradation.


                        
                        
                           
                           The proposed work characterizes the detected drusen in small, intermediate, and large/soft to show its ability to grade age-related macular degradation severity level, helpful in early age-related macular degradation diagnosis.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Drusen

Age-related macular degeneration

Segmentation

Boundary extraction

Retinal fundus images

Grading

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Age-related macular degeneration is a chronic irreversible medical condition characterized by drusen. Worldwide, AMD is the third most leading cause of irreversible vision loss in persons over the age of 50 [1]. If it is not detected and treated in time, it may cause total blindness. There are mainly two types of AMD: dry and wet. Most of the people, around 90%, with macular degeneration are affected by dry AMD, which causes lack of functioning of visual cells due to the presence of drusen on retina [2, 3]. An increase in number of drusen is a prominent symptom of dry AMD and used as a marker to detect the risk of AMD [4]. Therefore, a new methodology for more accurate detection of drusen has been proposed in the presented work.

Drusen are fatty deposits that appear as yellowish, cloudy bright blobs in retinal fundus images. They exhibit no specific size or shape [2, 5]. The modification in the size of individual drusen and their confluence indicates the development of macular degeneration disease. The severity level of macular degeneration is judged on the basis of the size of drusen and visibility of its boundaries in Wisconsin AMD grading system. The literature survey reveals that drusen can be classified as hard or soft [6] as shown in Fig. 1
                     (a) and (b), respectively. Soft drusen are further classified as distinguishable and indistinguishable [4–6]. Hard drusen appear smaller in size with sharper definition as compared to soft drusen that have fuzzy boundaries. Therefore, the accurate identification of boundary of drusen is a challenging task.

Drusen and their boundaries can be detected in retinal fundus images by trained clinicians with manual evaluation procedures [4] whereas biomedical researchers use automatic/semiautomatic methods to detect them. The automatic/semiautomatic methods proposed by several researchers to detect drusen are briefly summarized in Table 1. Mora et al. proposed drusen modeling and a gradient based segmentation approach to detect drusen [10]. They validated their method with twenty-two images and achieved a sensitivity of 68%. Bhuiyan et al. developed a drusen detection method using local intensity distribution, adaptive intensity thresholding and edge information [15]. They validated their method with twelve images and achieved a sensitivity of 74.94%. Grinsven et al. proposed a machine learning based method for AMD diagnosis. They achieved a sensitivity of 85% [16]. Prasath and Ramya proposed a method for drusen detection and validated with the dataset of forty images showing achieved results with only one performance measure. [19]. Kumari and Mittal validated their drusen detection method with thirty six images showing 95% sensitivity [20]. In a nutshell, the major limitations of existing works on drusen detection are the validation of methods on limited dataset with moderate performances in terms of sensitivity/accuracy, inaccurate drusen detection and insufficient information regarding quantification of drusen. Therefore, in the present work, a new method for drusen detection is proposed by (i) finding true edges of drusen using gradient based segmentation, (ii) removing suspicious pixels from drusen regions using connected component labeling and (iii) connecting detected edge pixels into a meaningful boundary using edge linking. The major highlights of the method are its validation on larger datasets resulting in comparatively higher sensitivity/accuracy than other methods, accurate detection of drusen boundaries with 99% specificity and categorization of detected drusen on the basis of size, area and number of drusen present in an image, contributing in early diagnosis of AMD especially through telemedicine for the people in rural areas.

The method comprises of three phases: in the first phase bright regions are enhanced followed by the noise removal in the retinal fundus images; in the second phase, regions of drusen are detected by suppressing the spurious regions; in the third phase boundary of drusen is detected by the edge linking procedure. In the last, the performance of proposed method is evaluated by (i) statistical measures and (ii) quantification of drusen to grade severity of AMD.

The rest of the paper is organized as follows: experiment materials for this paper are introduced, the proposed method are described in details and statistical measures to evaluate the proposed method are presented in Section 2, experimental results are showed, described and compared with other algorithms in Section 3, while conclusion is drawn in Section 4.


                     Materials:
                  

The retinal fundus images for the present study have been taken from open-source benchmark databases that are available online. The databases used in the study are (i) Structured Analysis of Retina (STARE) [21] and (ii) Automated Retinal Image Analysis (ARIA) [22]. The STARE database comprises of 400 images and they have been acquired using Topcon fundus camera at 35 degree field of view with resolution of 700×605 pixels. The ARIA database comprises of 450 images and they have been acquired using Carl Zeiss Meditec fundus camera at 50 degree field of view with resolution of 768×576 pixels. The images containing drusen were sorted out from these databases. Thus a total of 48 images comprising of 37 images from STARE database and 11 images from ARIA database have been used in the present work.


                     Method:
                  

The proposed method as shown in Fig. 2
                      consists of three phases, namely (i) retinal image preprocessing, (ii) drusen candidate edge detection and (iii) boundary extraction of drusen. The steps followed in these three phases of method are explained in this section. The performance evaluation parameters and grading criterion of AMD are also explained in the later stage of this section.

The retinal fundus images contain artifacts that occur during retinal image acquisition process. Retinal image preprocessing is necessary to remove these artifacts in order to improve quality of an image for easy detection of drusen. There are several factors responsible for the presence of artifacts in the image. One of them is non-uniform illumination which is responsible for the presence of intensity homogeneities and the shading artifacts in an image. Also, camera dependent factors like pixel noise and compression artifacts further degrade the image. The noise in the image may get amplified during contrast enhancement and impart a visible graininess to the image. This is highly undesirable especially in cases where the lesion characteristics are comparable to those of the artifacts produced due to noise amplification. Hence, retinal image preprocessing is essential to improve the quality of an image for easy detection of lesions. The steps involved in preprocessing are: (i) homomorphic filtering for removing artifact due to non-uniform illumination, (ii) green channel selection to have better contrast, (iii) Gaussian smoothing for noise removal.

Retinal images are acquired by a digital fundus camera that captures the intensity of light reflected from the retinal surface. Several patient dependent and camera dependent factors such as the retina convex surface, the lower reflectance from macula as compared from other parts of the retina, insufficient pupil dilation, poor patient collaboration and ocular media opacities, i.e., cataract etc. add non-uniform illumination led artifacts in the image [10]. These factors responsible for non-uniform illumination across an image contribute to variation in color and result in different contrast among different regions of the same image. Therefore, homomorphic filtering is used to normalize the image background to have uniform illumination. Homomorphic filtering also enhances the image by compressing brightness range and enhancing contrast simultaneously [23]. In this approach, the image is considered as a function of the product of the illumination and reflectance which is represented as:
                              
                                 (1)
                                 
                                    
                                       g
                                       (
                                       
                                          x
                                          ,
                                          y
                                       
                                       )
                                       ≈
                                       i
                                       (
                                       
                                          x
                                          ,
                                          y
                                       
                                       )
                                       .
                                       r
                                       (
                                       
                                          x
                                          ,
                                          y
                                       
                                       )
                                    
                                 
                              
                           where g(x, y), i(x, y) and r(x, y) represent the image intensity sensed by camera, illumination multiplicative factor and reflectance multiplicative factor, respectively in terms of Cartesian coordinates (x, y) of the image. Both of these factors are separated by taking the logarithm on both the sides of Eq. (1) as given below in Eq. (2).
                              
                                 (2)
                                 
                                    
                                       
                                          
                                          ln
                                       
                                       {
                                       
                                          g
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       }
                                       =
                                       ln
                                       {
                                       
                                          i
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       }
                                       +
                                       ln
                                       {
                                       
                                          r
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       }
                                    
                                 
                              
                           
                        

Since illumination varies smoothly throughout the image, therefore it is reflected in low frequency component of the Fourier transform of an image. On the other hand reflectance is associated with high frequency component of the image. Therefore in order to resolve the image into low and high frequency component, the Fourier transformation is applied on Eq. (2) as given in Eq. (3).
                              
                                 (3)
                                 
                                    
                                       
                                          ℑ
                                          [
                                          
                                             ln
                                             {
                                             
                                                g
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                             
                                             }
                                          
                                          =
                                          ℑ
                                          [
                                       
                                       
                                          ln
                                          
                                             {
                                             
                                                i
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                             
                                             }
                                          
                                          +
                                          ℑ
                                          [
                                          
                                             ln
                                             {
                                             
                                                r
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                             
                                             }
                                          
                                          =
                                          
                                             F
                                             i
                                          
                                          
                                             (
                                             
                                                u
                                                ,
                                                v
                                             
                                             )
                                          
                                          +
                                          
                                             F
                                             r
                                          
                                          
                                             (
                                             
                                                u
                                                ,
                                                v
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           where Fi
                           (u, v) and Fr
                           (u, v) are the Fourier transforms of ln {i(x, y)} and ln {r(x, y)}, respectively. The transformed image is then passed through a modified Butterworth high pass filter H(u, v) for homomorphic filtering as represented by Eq. (4).
                              
                                 (4)
                                 
                                    
                                       H
                                       
                                          (
                                          
                                             u
                                             ,
                                             v
                                          
                                          )
                                       
                                       =
                                       1
                                       −
                                       
                                          1
                                          
                                             1
                                             +
                                             
                                                
                                                   (
                                                   
                                                      u
                                                      2
                                                   
                                                   +
                                                   
                                                      v
                                                      2
                                                   
                                                   /
                                                   a
                                                   )
                                                
                                                n
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    
                                       u
                                       2
                                    
                                    +
                                    
                                       v
                                       2
                                    
                                 
                                 a
                              
                            determines the steepness of transition slope. Hence a filtered image G(u, v)is obtained as given by Eq. (5),
                              
                                 (5)
                                 
                                    
                                       G
                                       
                                          (
                                          
                                             u
                                             ,
                                             v
                                          
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             H
                                             
                                                (
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                                )
                                             
                                             
                                                F
                                                i
                                             
                                             
                                                (
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                                )
                                             
                                          
                                          }
                                       
                                       +
                                       
                                          {
                                          
                                             H
                                             
                                                (
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                                )
                                             
                                             
                                                F
                                                r
                                             
                                             
                                                (
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                                )
                                             
                                          
                                          }
                                       
                                    
                                 
                              
                           
                        

The spatial domain representation of filtered image is obtained by taking inverse Fourier transform of G(u, v) as shown in Eq. (6).
                              
                                 (6)
                                 
                                    
                                       
                                       
                                          g
                                          
                                             H
                                             F
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          ℑ
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          {
                                          
                                             g
                                             (
                                             
                                                u
                                                ,
                                                v
                                             
                                             )
                                          
                                          }
                                       
                                    
                                 
                              
                           
                           gHF
                           (x, y)is further enhanced by boosting the higher frequency values relative to low frequency values resulting in an enhanced image  gE
                           (x, y).

The processed color retinal fundus image  gE
                           (x, y) consists of three channels; green, red, and blue. Amongst them, green channel is selected which is more informative and has a better contrast than the other two channels.

As discussed earlier, noise at the pixel level is a major problem as it gets amplified during contrast enhancement operation. Since this noise has Gaussian distribution therefore it can be removed by using a smoothing filter such as Gaussian filter which is expressed as follows:
                              
                                 (7)
                                 
                                    
                                       
                                          g
                                          F
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          1
                                          
                                             2
                                             π
                                             
                                                σ
                                                3
                                             
                                          
                                       
                                       
                                          e
                                          
                                             −
                                             (
                                             
                                                
                                                   x
                                                   2
                                                
                                                +
                                                
                                                   y
                                                   2
                                                
                                                /
                                                2
                                                
                                                   σ
                                                   2
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           Where gF
                           (x, y) is Gaussian operator and σ is the standard deviation of Gaussian function that controls the degree of smoothening. Smoothed image gGF
                           (x, y), as represented by Eq. (8), is obtained by the application of Gaussian filter.
                              
                                 (8)
                                 
                                    
                                       
                                          g
                                          
                                             G
                                             F
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          g
                                          
                                             H
                                             F
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       ⊗
                                       
                                          g
                                          F
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

Detection of the candidate edges of drusen plays an important role in tracing the boundary of drusen. The following steps are followed for edge detection of drusen.

The smoothed image  gGF
                           (x, y), as obtained by Eq. (8), is filtered with a sobel kernel in both horizontal and vertical directions to get the first derivative of image intensity in horizontal direction (Gx
                           ) and vertical direction (Gy
                           ). From these two images, an edge gradient in terms of its magnitude, gf
                           (x, y), and direction θ(x, y) at each pixel are found as follows:
                              
                                 (9)
                                 
                                    
                                       ∇
                                       
                                          g
                                          
                                             G
                                             F
                                          
                                       
                                       =
                                       
                                       
                                          [
                                          
                                             
                                                
                                                   
                                                      G
                                                      x
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      G
                                                      y
                                                   
                                                
                                             
                                          
                                          ]
                                       
                                       =
                                       
                                          [
                                          
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         
                                                            g
                                                            
                                                               G
                                                               F
                                                            
                                                         
                                                      
                                                      
                                                         ∂
                                                         x
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         
                                                            g
                                                            
                                                               G
                                                               F
                                                            
                                                         
                                                      
                                                      
                                                         ∂
                                                         y
                                                      
                                                   
                                                
                                             
                                          
                                          ]
                                       
                                    
                                 
                              
                           
                           
                              
                                 (10)
                                 
                                    
                                       
                                          g
                                          f
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          
                                             
                                                G
                                                x
                                                2
                                             
                                             
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                             
                                             +
                                             
                                                G
                                                y
                                                2
                                             
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                    
                                 
                              
                           
                           
                              
                                 (11)
                                 
                                    
                                       θ
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          tan
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          (
                                          
                                             
                                                G
                                                y
                                             
                                             
                                                G
                                                x
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

After obtaining gradient magnitude and direction, a full scan of image is performed to remove unwanted pixels which may not constitute the edge. For this purpose, every pixel is checked to ascertain whether it is a local maxima in its neighborhood in the direction of gradient or not. This is done in two steps as given below:

Step 1 – The edge strength of the current pixel is compared with the edge strength of the pixels in both the positive and negative gradient directions.

Step 2 – If the edge strength of current pixel is the largest, preserve the value of the edge strength else suppress the value.

The application of non-maxima suppression gives the edge pixels in which many of them would probably be actual edges in the image, but some may be not due to noise and color variation across the image. In order to filter out the wrong pixels, the Canny edge detection algorithm is used. In this method, two threshold values are set to distinguish the right and wrong edge pixels. One of them is called high threshold value and the other is called low threshold value. If the gradient magnitude of edge pixels is higher than the high threshold value, they are marked as strong edge pixels. If the gradient magnitude of edge pixels is lower than high threshold value and higher than low threshold value, they are marked as weak edge pixels. If the pixel value is smaller than the low threshold value they will be suppressed. Gradient magnitude thresholding is mathematically expressed as given below:
                              
                                 (12)
                                 
                                    
                                       T
                                       =
                                       
                                          {
                                          
                                             
                                                
                                                   
                                                      
                                                         ∥
                                                      
                                                      
                                                         ∇
                                                         
                                                            g
                                                            
                                                               G
                                                               F
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                               ,
                                                               y
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         ∥
                                                         ≥
                                                      
                                                      
                                                         t
                                                         
                                                            1
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      d
                                                      e
                                                      f
                                                      i
                                                      n
                                                      i
                                                      t
                                                      e
                                                      l
                                                      y
                                                      
                                                      a
                                                      n
                                                      
                                                      e
                                                      d
                                                      g
                                                      e
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         t
                                                         0
                                                      
                                                      ≤
                                                      
                                                         ∥
                                                         
                                                            ∇
                                                            
                                                               g
                                                               
                                                                  G
                                                                  F
                                                               
                                                            
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         ∥
                                                      
                                                      <
                                                      
                                                         t
                                                         1
                                                      
                                                   
                                                
                                                
                                                   
                                                      m
                                                      a
                                                      y
                                                      
                                                      b
                                                      e
                                                      
                                                      a
                                                      n
                                                      
                                                      e
                                                      d
                                                      g
                                                      e
                                                      ,
                                                      
                                                      d
                                                      e
                                                      p
                                                      e
                                                      n
                                                      d
                                                      
                                                      o
                                                      n
                                                      
                                                      c
                                                      o
                                                      n
                                                      t
                                                      e
                                                      x
                                                      t
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         ∥
                                                      
                                                      
                                                         ∇
                                                         
                                                            g
                                                            
                                                               G
                                                               F
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                               ,
                                                               y
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         ∥
                                                         <
                                                      
                                                      
                                                         t
                                                         0
                                                      
                                                   
                                                
                                                
                                                   
                                                      d
                                                      e
                                                      f
                                                      i
                                                      n
                                                      i
                                                      t
                                                      e
                                                      l
                                                      y
                                                      
                                                      n
                                                      o
                                                      t
                                                      
                                                      a
                                                      n
                                                      
                                                      e
                                                      d
                                                      g
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where t
                           1 is a high threshold value and t
                           0 is low threshold value. Finally, the edge obtained after thresholding is represented as:
                              
                                 (13)
                                 
                                    
                                       E
                                       
                                          (
                                          
                                             x
                                             ,
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             
                                                
                                                   
                                                      1
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      
                                                         i
                                                         f
                                                         
                                                         ∥
                                                      
                                                      
                                                         ∇
                                                         
                                                            g
                                                            
                                                               G
                                                               F
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                               ,
                                                               y
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         ∥
                                                         >
                                                         T
                                                         
                                                         f
                                                         o
                                                         r
                                                         
                                                         s
                                                         o
                                                         m
                                                         e
                                                         
                                                         t
                                                         h
                                                         r
                                                         e
                                                         s
                                                         h
                                                         o
                                                         l
                                                         d
                                                         
                                                         T
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      0
                                                      ,
                                                   
                                                
                                                
                                                   
                                                      o
                                                      t
                                                      h
                                                      e
                                                      r
                                                      w
                                                      i
                                                      s
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Any edge will always have varying gradient strength, i.e., edge consists of both the strong and weak edge pixels. Strong edge pixels would certainly be a part of final edge image. However weak edge pixels can be a part of true edge or they may be due to noise and color variations. To achieve an accurate result, the weak edge pixels caused from noise and color variations are required to be removed. These unwanted weak edge pixels are removed on the basis of 8-connected neighborhood pixel check. If they are connected to strong edge pixels they are considered to be a part of the edge otherwise they are discarded.

The previous phase, i.e., edge detection phase is used to extract all candidate edges of drusen. Out of these candidate edges, few may be because of noise in the image. Therefore, after removal of such noisy component, remaining edges are required to be linked suitably to extract boundary of drusen. The procedure of boundary extraction of drusen is explained in this section.

The detected candidate edges may be of several pixels wide due to multiple edge responses. These multiple edge responses may create incorrect edge linking. In addition, a small candidate edge component may be a true edge component or an isolated component because of noise. Therefore in this work, the unnecessary edge responses and the isolated components are removed. It has been accomplished in the following two steps:
                              
                                 Step 1 – Image containing candidate edges is converted into binary image using global thresholding [22].

Step 2 – Morphological thinning algorithm is applied on the binary image to (i) get single-pixel-wide edges and (ii) remove the isolated pixels.
                                       
                                          (14)
                                          
                                             
                                                E
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                                ⊖
                                                S
                                                =
                                                E
                                                (
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                                )
                                                −
                                                (
                                                
                                                   E
                                                   (
                                                   
                                                      x
                                                      ,
                                                      y
                                                   
                                                   )
                                                   ⊗
                                                   S
                                                
                                                )
                                                .
                                             
                                          
                                       
                                    
                                 

The end points of edges in the edge map, obtained after edge thinning, seldom form closed connected boundaries of drusen. The required boundaries can be obtained only by proper linking of end points of edges. Therefore, the assessment of end points is required for linking the edges. This recovery of end points is performed with a set of 3×3 masks, as given below. These masks are applied to the edge map to find out possible edge links in all eight directions. The pixel, a candidate for end point, is center pixel in these masks. The mask entries indicated by ‘x’ can take any value (0 or 1) but at least one of them has a value 1 for end point recovery.
                              
                                 
                                    
                                       
                                          [
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   x
                                                
                                                
                                                   x
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   1
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                          
                                          ]
                                       
                                       
                                          [
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   x
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   1
                                                
                                                
                                                   x
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   x
                                                
                                             
                                          
                                          ]
                                       
                                       
                                          [
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   1
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   x
                                                
                                                
                                                   x
                                                
                                                
                                                   x
                                                
                                             
                                          
                                          ]
                                       
                                       
                                          [
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   x
                                                
                                                
                                                   1
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   x
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                          
                                          ]
                                       
                                    
                                 
                              
                           
                        

The endpoints of edges after recovery are labeled to minimize the incorrect linking decisions. A common label is assigned to the group of pixels that have similar features and in this way a local edge structure is assessed. The gaps in unconnected edge structures are bridged in agreement with the directionality of the endpoints.

Finally, the boundary of drusen is extracted by linking the edge components using a local processing [24]. Algorithm used in local processing is as follows:
                              
                                 Step 1 - Analyze the characteristics of pixel in small neighborhood for every point that has undergone edge detection.

Step 2 – All points that are similar are linked, forming a boundary of pixels that share some common property.

Step 3 – Two principle properties for establishing similarity are as follows:

Edge pixels with coordinates (x
                                    0, 
                                    y
                                    0) in the neighborhood of (x, y) are similar in magnitude to pixel at (x, y) if
                                       
                                          (15)
                                          
                                             
                                                
                                                   |
                                                
                                                
                                                   ∇
                                                   f
                                                   
                                                      (
                                                      
                                                         x
                                                         ,
                                                         y
                                                      
                                                      )
                                                   
                                                   −
                                                   ∇
                                                   f
                                                   
                                                      (
                                                      
                                                         
                                                            x
                                                            
                                                               0
                                                               ,
                                                            
                                                         
                                                         
                                                            y
                                                            0
                                                         
                                                      
                                                      )
                                                   
                                                
                                                
                                                   |
                                                   ≤
                                                   E
                                                
                                             
                                          
                                       
                                    
                                 

Edge pixel with coordinates (x
                                    0, 
                                    y
                                    0) in neighborhood of (x, y) has an angle similar to pixel at (x, y) if
                                       
                                          (16)
                                          
                                             
                                                
                                                   |
                                                
                                                
                                                   α
                                                   
                                                      (
                                                      
                                                         x
                                                         ,
                                                         y
                                                      
                                                      )
                                                   
                                                   −
                                                   α
                                                   
                                                      (
                                                      
                                                         
                                                            x
                                                            0
                                                         
                                                         ,
                                                         
                                                            y
                                                            0
                                                         
                                                      
                                                      )
                                                   
                                                
                                                
                                                   |
                                                   <
                                                   A
                                                
                                             
                                          
                                       
                                    
                                 

Edge pixel (x
                                    0, 
                                    y
                                    0) is linked with (x, y) if both criteria are satisfied.

Once the links are established, linked pixels are used as boundary of detected drusen.

Performance of the proposed method is evaluated by the medically important statistical measures. These measures are briefly described below:

Sensitivity is the measure of probability by which a method can detect to a dursen pixel correctly among dursen pixels. Mathematically it can be expressed as:
                              
                                 (17)
                                 
                                    
                                       Sensitivity
                                       =
                                       
                                          
                                             T
                                             P
                                          
                                          
                                             (
                                             
                                                
                                                   T
                                                   P
                                                
                                                +
                                                
                                                
                                                   F
                                                   N
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           where TP
                            represents the number of drusen pixels correctly classified by the method as drusen pixels and FN
                            represents the number of drusen pixels which are falsely classified by the method as non-drusen pixels.

Specificity is the measure of probability by which a method can detect to a non-dursen pixel correctly among non-dursen pixels and it can be expressed as:
                              
                                 (18)
                                 
                                    
                                       Specificity
                                       =
                                       
                                          
                                             T
                                             N
                                          
                                          
                                             (
                                             
                                                
                                                   T
                                                   N
                                                
                                                +
                                                
                                                   F
                                                   P
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           where TN
                            represents the number of non-drusen pixels correctly classified by the method as non-drusen pixels and FP
                            represents the number of non-drusen pixels which are falsely classified by the method as drusen pixels.

Accuracy of a method is the proportion of correctly detected drusen and non-drusen pixels among total examined pixels. Mathematically, it can be expressed as:
                              
                                 (19)
                                 
                                    
                                       Accuracy
                                       =
                                       
                                          
                                             (
                                             
                                                T
                                                N
                                             
                                             +
                                             
                                                T
                                                P
                                             
                                             )
                                          
                                          
                                             (
                                             
                                                
                                                   T
                                                   N
                                                
                                                +
                                                
                                                   T
                                                   P
                                                
                                                +
                                                
                                                   F
                                                   N
                                                
                                                +
                                                
                                                   F
                                                   P
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        

It is the probability to detect correct drusen pixels out of all detected drusen pixels by the method and it can be expressed as:
                              
                                 (20)
                                 
                                    
                                       PPV
                                       =
                                       
                                          
                                             T
                                             P
                                          
                                          
                                             (
                                             
                                                
                                                   T
                                                   P
                                                
                                                +
                                                
                                                   F
                                                   P
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        

It is the measure to evaluate a method by assessing the correlation in between the ground truth and the correct detected pixels by the method.
                              
                                 (21)
                                 
                                    
                                       MCC
                                       =
                                       
                                          
                                             
                                                T
                                                N
                                             
                                             *
                                             
                                                T
                                                P
                                             
                                             −
                                             
                                                F
                                                N
                                             
                                             *
                                             
                                                F
                                                P
                                             
                                          
                                          
                                             
                                                
                                                   (
                                                   
                                                      
                                                         T
                                                         P
                                                      
                                                      +
                                                      
                                                         F
                                                         P
                                                      
                                                   
                                                   )
                                                
                                                
                                                   (
                                                   
                                                      
                                                         T
                                                         P
                                                      
                                                      +
                                                      
                                                         F
                                                         N
                                                      
                                                   
                                                   )
                                                
                                                
                                                   (
                                                   
                                                      
                                                         T
                                                         N
                                                      
                                                      +
                                                      
                                                         F
                                                         P
                                                      
                                                   
                                                   )
                                                
                                                
                                                   (
                                                   
                                                      
                                                         T
                                                         N
                                                      
                                                      +
                                                      
                                                         F
                                                         N
                                                      
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

A number of grading systems have been established to provide standards for ophthalmologists and researchers in reliable diagnosis and management of AMD using color fundus images [25]. These systems grade the severity of AMD by objective quantification of principle abnormalities. Among these grading systems, age-related eye disease study (AREDS) grading system is used in this work to grade the severity of AMD by quantification of drusen detected by the proposed method.

Ophthalmologists usually identify and grade AMD using color fundus images by manually determining the size, number and extension of drusen, which is a tedious and time consuming task and usually prone to human error. In this work, severity level of AMD is graded by providing a reliable and accurate quantification of drusen by automated measuring the size, area and number of drusen.

@&#RESULTS AND DISCUSSIONS@&#

The proposed method is implemented in MATLAB version 7.10 on a PC with Intel core i3 (2.40 GHZ) processor. Two standard retinal image databases, as mentioned earlier, are used for detailed evaluation and validity of the proposed method. A total of 48 retinal images with different resolutions and a lot of variations are used. Images in Fig. 3
                     (a), (b) and (c) are randomly chosen retinal fundus images to demonstrate the results of proposed method, where Fig. 3(a) and (b) are the original images from STARE database and Fig. 3(c) is an original image from ARIA database.

The non-uniform illumination of original images is corrected by applying homomorphic filtering and the best results are obtained when boost value is set at 2 with cut-off frequency of 0.5 and order of 2 during the experiment. The filtered images as shown in Fig. 3(d), (e) and (f) are obtained after homomorphic filtering of retinal fundus images shown in Fig. 3(a), (b) and (c), respectively. It can be clearly observed that the filter, designed with the above parameter settings, compresses the dynamic range of the images and enhances their contrast along with the removal of non-uniform illumination effect. Further, the green channel is selected from a filtered image to obtain more information with better contrast. Fig. 3(g), (h) and (i) represent the selected green channel images from the filtered images in Fig. 3(d), (e) and (f), respectively. These green channel images may have Gaussian distributed pixel level noise. Therefore, Gaussian filter is used to remove the effect of such noise. A suitable value of σ for Gaussian filter is obtained on varying the value of σ in the range of 1 and 2 during the experiment and the best results are achieved with the value of σ as 1.5. The effect of smoothing is clearly visible in the images 3 (j), (k) and (l) which are obtained after applying Gaussian filtering on images 6 (g), (h) and (i), respectively.

Gradient vector images are created by taking the gradient at each pixel of the preprocessed image as an initial step to detect the candidate edges of drusen. The drusen appear as bright blobs in a retinal fundus image, therefore high magnitude of the gradient vector arises at their edges. The zoomed portions of gradient vector images, corresponding to the preprocessed images in Fig. 3(j), (k) and (l), are shown in Fig. 4
                        
                        (a), (b) and (c), respectively. These zoomed portion images clearly depict that the high magnitudes of the gradient vectors arise at the edges of drusen in comparison to their nearby regions. Next step is to preserve all local maxima in a gradient image by comparing edge strength of pixels with its neighborhood in positive and negative gradient directions in order to preserve the edges of drusen, Fig. 4(d), (e) and (f) show the quiver plot of images corresponding to the gradient images in Fig. 4(a), (b) and (c), respectively. Drusen are highlighted in these images by suppressing non-maxima gradient. The output of non-maxima suppression still contains the local maxima created by noise. To get rid of them effectively, hysteresis thresholding or double thresholding is used. After number of experimental trails on the database images, 0.28 and 0.020 have been selected as threshold values for maximum and minimum hysteresis, respectively. These values will further highlight only the strong pixels in the form of candidate edges of drusen as shown in Fig. 4(g), (h) and (i), respectively.

Candidate edges, obtained after apply hysteresis thresholding, are processed further to remove unnecessary edge responses and isolated components. This is done by first converting an image with candidate edges into a binary image using global thresholding and then applying morphological thinning on this binary image to remove unnecessary edge responses/ isolated components. Afterwards, the extraction of boundary of drusen is done by assessing true links in between the unconnected edges. True edge links are assessed by performing the scanning in all possible directions and then labeled to mark the unconnected edges. Labeling is used to track all unconnected edges that are forming a boundary of druse. Fig. 5(a), (b) and (c) show the labeled images corresponding to the images in Fig. 4(g), (h) and (i), respectively. After that, all unconnected edges are linked to form a boundary of drusen as shown in Fig. 5(d), (e) and (f). Extracted boundaries of drusen are highlighted by pseudo color in Fig. 5(g), (h) and (i). Pseudo color helps in counting the total number of drusen present in an image.

@&#PERFORMANCE EVALUATION@&#

The performance of proposed method in terms of five medically important statistical measures on the dataset of 48 test images is presented in Table 2. These measures are calculated by comparing the drusen detected by the proposed method to that of ground truth. Table 2 clearly illustrates that the average drusen detection accuracy, sensitivity and specificity are 96.17, 89.81 and 99.00%, respectively on the test images. These values indicate clearly the high performance of the proposed method. The box and whisker plots in Fig. 6(
                        a) highlight the summary of each evaluation parameter by showing deviation in its value around an average value. These plots clearly illustrate the overall high values of performance parameters on the dataset of 48 images with least deviation of 0.98% for specificity and highest deviation of 14.26% for sensitivity. Further Fig. 6 presents a detailed comparison of the performance of the proposed method with that of Kumari and Mittal [20] in terms of box plots of all five statistical measures. On comparing Fig. 6(a) and (b), it can be observed that the proposed method has a significant contribution in achieving an accuracy of (96.17 ± 5.41)% which is higher than that of Kumari and Mittal by (2.97 ± 2)%. Further, Fig. 6(c) and (d) depict that the proposed method achieved an average accuracy of (96.68 ± 4.69)% on STARE dataset, which exceeds by (8.755 ± 3.2)% from the method of Kumari and Mittal [20]. Also, an examination of Fig. 6(e) and (f) shows that the proposed method results in an increment of (11.97 ± 1.8)% in average accuracy on ARIA dataset in comparison to that of Kumari and Mittal's method. Fig. 7
                         pictorially depicts the comparison of segmented drusen area of proposed method (Fig. 7(a)) with that of the method of Kumari and Mittal (Fig. 7(b)) and thus, justifying all the results. Fig. 7(c) represents the ground truth for overall assessment of segmented results by the proposed method.

The comparative performance analysis of the proposed method with the existing methods is shown in Table 3
                        
                        . It is important to note that not all the drusen detection methods, mentioned in Table 3, have used same datasets. Nonetheless, it gives an overall idea about the performance of various mentioned methods. The proposed method has clearly outperformed the existing methods that have used same datasets for evaluation. It can also be observed that the proposed method is validated with a larger dataset as compared to the size of datasets of most of the existing methods. The drusen detection accuracy of the proposed method is quite high in comparison to the existing methods except that of Ramya and Prasath [19]. The limitation of Ramya and Prasath method is that it has been evaluated with only one statistical measure on the dataset of 40 images. Furthermore, the proposed method shows sensitivity/specificity of 95.36/99.56 on STARE dataset and 84.16/98.75 on ARIA dataset. Correlation of the detected drusen with the ground truth is 96.14% for STARE dataset and 93.5% for ARIA dataset. The prediction of true drusen by the proposed method is also quite high showing PPV value as 97.7% for STARE and 94.05% for ARIA dataset. In literature, only few methods calculated the execution time of the method. Bhuiyan et al. discussed in their work that the execution time to quantify the drusen area in a retinal fundus image by their method is less than 0.5 s [15]. The proposed method takes approximately 0.218 s to quantify the drusen area in a retinal fundus image, although this time may vary from image to image depending on the size and color effects. In addition to that, the execution time is (approximately) 0.0738 s for boundary detection, 0.251 s for edge tracking in 271 iterations, 0.385 s for edge linking of available pixels in 3246 iterations and 103.353 s for the total execution of the method as mentioned in Table 3. There is a 70% (from 175.093 to 103.353) time reduction by the proposed method in comparison to the method of Kumari and Mittal [20]. Conclusively, Table 3 shows that the proposed method has achieved higher values of sensitivity, specificity, PPV, MCC and lower values of computational cost in comparison to that of other methods. The improvement especially in terms of sensitivity and PPV is supported by drusen detection stage where the removal of spurious regions resulted in lower number of false positives. Drusen, after detection and segmentation, are quantified according to size, area and number. In the present work, drusen are categorized into three stages according to AREDS grading system that follows international drusen grading protocols [25]. Retinal fundus images, containing small, intermediate and soft drusen, are quantified by measuring the number, area and size of drusen in each individual image manually (for ground truth) and automatically (using drusen detection by proposed method) as shown in Table 4. It can be clearly observed that the proposed method achieves an average accuracy of 88.46% for small drusen, 98.55% for intermediate drusen and 88.37% for soft or large drusen and outwits the results of the drusen detection method by Bhuiyan et al. 
                        [15].

@&#CONCLUSION@&#

A new automated drusen detection and segmentation method for AMD diagnosis has been proposed and analyzed in this work. The proposed method reliably detects and segments drusen in retinal fundus images as it is designed by (i) finding true edges of drusen, (ii) removing suspicious pixels from the drusen region and (iii) afterward finding meaningful drusen boundaries. The performance of the proposed method has been measured on two retinal image datasets. The experimental results indicate the high performance of the proposed method in detection of drusen with accuracy of 96.17% on the dataset images. The results demonstrate a high precision on correct recognition of drusen showing positive predictive value of 96.40%. The results also reveal that the proposed method performs significantly well in distinguishing drusen pixel from other retinal pixels showing sensitivity of 89.81%. The specificity of 99.00% indicates a successful discriminating power while separating normal regions from drusen regions. The detected drusen by the proposed method also show high correlation with ground truth with the accuracy of 95.95%. In addition, the proposed method outperformed the other state of art methods in terms of computational cost and all above mentioned medically important performance measures. Furthermore, the method prove its early drusen detection capability by grading AMD after categorizing detected drusen into small, intermediate and large with accuracy of 88.46, 98.55 and 88.37%, respectively. Finally it can be emphasized that proposed drusen detection method may be used potentially to aid ophthalmologists in early treatment and effective planning of AMD diagnosis and to control the progression of disease.

@&#REFERENCES@&#


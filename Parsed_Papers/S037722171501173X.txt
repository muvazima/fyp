@&#MAIN-TITLE@&#Agent-based computational modelling of social risk responses

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Managing major societal risks involves the need to understand public risk responses.


                        
                        
                           
                           The social amplification of risk framework has been our main theoretical approach.


                        
                        
                           
                           We explore how to model endogenised risk observation, behaviour and communication.


                        
                        
                           
                           Agent simulation shows characteristic outcomes like peaks and drift in risk beliefs.


                        
                        
                           
                           The model indicates the key areas where further empirical research is needed.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

OR in societal problem analysis

Multiagent systems

Risk management

@&#ABSTRACT@&#


               
               
                  A characteristic aspect of risks in a complex, modern society is the nature and degree of the public response – sometimes significantly at variance with objective assessments of risk. A large part of the risk management task involves anticipating, explaining and reacting to this response. One of the main approaches we have for analysing the emergent public response, the social amplification of risk framework, has been the subject of little modelling. The purpose of this paper is to explore how social risk amplification can be represented and simulated. The importance of heterogeneity among risk perceivers, and the role of their social networks in shaping risk perceptions, makes it natural to take an agent-based approach. We look in particular at how to model some central aspects of many risk events: the way actors come to observe other actors more than external events in forming their risk perceptions; the way in which behaviour both follows risk perception and shapes it; and the way risk communications are fashioned in the light of responses to previous communications. We show how such aspects can be represented by availability cascades, but also how this creates further problems of how to represent the contrasting effects of informational and reputational elements, and the differentiation of private and public risk beliefs. Simulation of the resulting model shows how certain qualitative aspects of risk response time series found empirically – such as endogenously-produced peaks in risk concern – can be explained by this model.
               
            

@&#INTRODUCTION@&#

Managing the major risks experienced by a complex society – the risks of epidemic disease, climate change, food and drug contamination, the catastrophic failure of hazardous installations and so on – almost invariably involves managing public anxiety or public complacency as well as containing physical threat (Leiss, 2001). Not only are public perceptions pivotal in shaping public behaviour, and therefore exposure to the threat, but characteristically produce further risks. A recent analysis of the Fukushima nuclear power accident argued that:

                        ‘There was a rushed evacuation response to the accident … this evacuation actually led to more premature deaths, by a factor of at least ten, than it gave protection from radiation … The reaction was driven to a large extent by the public's sense of the scale of the hazard, which was not close to the reality of the risk … The studies of many previous accidents have come to a similar conclusion. Even for an accident as significant as Chernobyl it can be shown that the vast majority of the public health impacts are caused by mental stress relating to the fear of the event, rather than the effects caused by the amount of ionising radiation released...’ (Cahart, 2013).
                     
                  

Thus public risk perceptions have often mattered more than objective assessments of risk, as seen in such celebrated cases as Love Canal, Alar and TWA 800 in the US (Kuran & Sunstein, 1999) and the Sudan 1 and Hatfield scandals in the UK (Busby & Alcock, 2008). It has become essential for organisational decision making to be founded on an understanding of societal risk responses, and for decision makers to theorise, however loosely, about how such responses arise.

The formation of these responses has a number of defining features. Most if not all of the public, and many managers, have no first-hand technical knowledge of the risk and rely on other social actors – including the media – of whom they are often sceptical if not cynical (Petts & Niemeyer, 2004). These actors in turn generally have a clear appreciation of this cynicism and anticipate it in the way they act and communicate (Busby & Duckett, 2012). The responses of a wide range of actors, including risk managers and the general public, typically influence the character of the threat and the risk bearers’ exposure to it (Busby & Onggo, 2012). Responses are shaped by the way in which such groups inter-communicate within their social networks (Scherer & Cho, 2003). And the responses become events in their own right, to which social actors further respond (Kasperson et al., 1988).

Credible models of social risk responses need to incorporate such features. They need to endogenise observation, representing the way in which actors, despite their heterogeneity, often base their own responses in part on how they see peers or neighbours responding, not on direct experience or knowledge of the risk. They need to endogenise behaviour, representing the way actors adapt their behaviour to changing observations of a risk, thus changing their exposure and the risk itself, and thereby also changing subsequent perceptions of this risk. And they need to endogenise risk communication, representing the way actors base their risk perceptions on the communications of others whose apparent biases they correct for, but who in turn can anticipate such corrections in formulating their communications. Yet, as Rahmandad and Sterman (2008) point out, we typically model disease outbreaks as though contact rates were fixed, ignoring the way people change their behaviour as prevalence grows. And, as Busby and Onggo (2013) argue, we have typically ignored the way in which actors communicating about risk anticipate each other's biases, and even anticipate the anticipation of each other's biases. The aims of this paper are to explore how an agent based model can incorporate these characteristics, to explore what we can say about model validity, and to explore what quantities need to be known in order to parameterise such a model.

Our main theoretical foundation for doing this is the ‘social amplification of risk framework’ (Kasperson et al., 1988). The development of this framework followed earlier lines of work on individual risk perception (broadly starting with Fischhoff, Slovic, Lichtenstein, Read, & Combs, 1978), and on cultural risk selection (broadly starting with Douglas & Wildavsky, 1982). It has probably been the only mainstream attempt to try to synthesise this prior work, to deal with social emergence and to capture the importance of social communication in explaining risk behaviour (Renn, 1991). Much empirical work on risk responses in various domains, ranging from nuclear waste to terrorism, has been done under the heading of social risk amplification. But, as we attempt to show in the next section, the social amplification of risk remains largely un-modelled and under-specified. This means that various empirical findings that have emerged over the last 25 years remain ambiguous, and the implications for decision makers unclear.

There are several observations in the literature that motivate the use of agent models in particular. First, in the social risk amplification framework, risk has been seen as first and foremost a matter of social communication (Luhmann, 1993; Renn, 1991). The essence of the social amplification framework is that some risk event is experienced by a very small number of social actors, and communication about the risk then spreads through a system of heterogeneous actors seen as ‘amplification stations’ (Kasperson et al., 1988). Second, empirical work – notably Scherer and Cho's (2003) article and more recently Muter, Gore, and Riley (2013) in the risk literature, but also work such as that of Kohler, Behrman, and Watkins (2007) in the demography literature – has shown how important social interactions are in the development of risk perceptions. An individual's risk beliefs tend to be strongly correlated to those of others with close social connections, and individuals’ reports tend to acknowledge how those others have influenced them. Third, non-linearities are central to how risk amplification arises. Some of the few prior attempts at modelling risk amplification (Burns & Slovic, 2007; Busby & Onggo, 2012) have shown how complex are the feedback loops between the perceptions, behaviours and communications among the different actors in a risk issue, making analytical modelling infeasible. Fourth, the actors respond heterogeneously. Much of the later work on individual risk perception (for example Langford et al., 1999; Marris, Langford, Saunderson, & O'Riordan, 1997) has stressed individual differences. And individual risk sensitivity (Sjöberg, 2000) has been an important explanatory variable for differences in individual risk perception. All of these strongly point to agent-based modelling as the appropriate medium for modelling social risk amplification.

In this article we first review the literature on social risk amplification in an attempt to draw out the main theoretical and empirical contributions that have arisen since it was first proposed. We then describe the construction of a model, justifying its content by reference to the literature. We base this model on Kuran and Sunstein's (1999) account of availability cascades, and show how we can model central aspects of such cascades – particularly the ideas that individuals have both espoused and expressed risk beliefs, that they have both informational and reputational reasons for responding to beliefs common in a social discourse, and that there are availability ‘entrepreneurs’ who knowingly exploit the possibility of such cascades. We present typical results of simulating the model, and we discuss issues of model validity by reference to empirical work on time series of risk perceptions and concerns in the literature. We conclude with a discussion of the study's implications and limitations.

@&#LITERATURE REVIEW@&#

The social amplification of risk framework (SARF) was first proposed by Kasperson et al. (1988) as a way of explaining the often apparently mistaken responses of populations to risks in modern society. The original framework was intended to show ‘that risk events interact with psychological, social, and cultural processes in ways that can heighten or attenuate public perceptions of risk and related risk behaviours’. And it stressed the ‘ripple’ effects through which risk perceptions led people to behave in ways that created secondary impacts beyond the harmful effects of the original risk. Generally, it has been applied to study excessively high rather than excessively low risk perceptions, although the need for symmetry has long been recognised (Rip, 1988).

It has been used in a wide variety of contexts, including wildfire risk (Brenkert-Smith, Dickinson, Champ, & Flores, 2013), the siting of potentially hazardous installations (Binder, Scheufele, Brossard, & Gunther, 2011), environmental risk from tunneling (Chung, 2011), disease outbreaks (Busby & Duckett, 2012; Lewis & Tyshenko, 2009; Raude, Fischler, Lukasiewicz, Setbon, & Flahault, 2004), genetically modified foods (Frewer, Miles, & Marsh, 2002), the dismantling of hazardous installations (Bakir, 2005), chemical accidents (de Souza Porto & de Freitas, 1996), climate change (Renn, 2011), nuclear weapons facility accidents (Metz, 1996), inoculation risks (Petts & Niemeyer, 2004) and general levels of violence in society (Hill, 2001). In such situations, the framework has provided a way of describing how discrepancies between the risk beliefs of different groups, and between experts and lay communities especially, can arise.

The methods used in such studies have been wide-ranging. Some are qualitative, analyzing rich verbal accounts among the public from interviews (for example Masuda & Garvin, 2006) and discussion groups (Busby & Duckett, 2012; Petts & Niemeyer, 2004), or analysing media content (Bakir, 2005). These have revealed how the worldview of individuals affects their tendency to amplify risk, and how particular actors use the media to convey their view of the risk and influence opinion. Quantitative studies have occasionally used economic measures of risk responses, such as property values and business activity (Metz, 1996), and there has been some content analysis of the news media (Lewis & Tyshenko, 2009). But most quantitative work has been based on public surveys (for example Binder et al., 2011, Frewer et al., 2002; Brenkert-Smith et al., 2013). These are generally directed at the public, but some involve surveying the specific groups involved in a particular risk issue, such as physicians dealing with a potential disease outbreak (Raude et al., 2004). Surveys have generally been analysed by regressing risk perceptions, and sometimes amplified risk perceptions, against expected correlates. These include types of information source and social interaction (Brenkert-Smith et al., 2013), attitudes of support or hostility towards a technology (Binder et al., 2011), engagement in public meetings (McComas, 2003) and the volume of reporting (Frewer et al., 2002). Occasional studies have also looked at the covariation of behavioural changes, such as consumption of foods thought to carry disease, with risk perception (Raude et al., 2004).

Mostly these studies use data suggesting the presence of risk amplification, but Lewis and Tyshenko (2009) and Metz (1996) both found expected amplification not to be present, and so were primarily concerned with correlating the absence of risk amplification with specific circumstances. Some of the more ambitious studies of social risk amplification, attempting to develop a comprehensive view of the factors causing amplification, have had to use mixed methods. Burns et al. (1993) in particular needed a combination of public survey, expert ratings, a Delphi panel and analysis of media attention to develop structural equations linking risk amplification to physical risk and social processes. Both they, and subsequently Freudenberg (2003), emphasised the importance of perceived managerial incompetence or misconduct in amplifying public risk perceptions.

However, a basic limitation of this empirical work is its concentration on the statistical correlates of amplification, rather than the mechanism that produces it. The core of social risk amplification in Kasperson et al. (1988) original formulation is a mechanism rather than a law linking structural variables. The kind of modelling that explicitly represents this mechanism has been very limited to date. There has been some systems dynamics work, based on the observation that social risk amplification involves complex feedback loops connecting risk responses with decisions and behaviours that in turn modify risk and the perceptions of risk. Burns and Slovic (2007) modelled public perception and amplification of terrorism risk, while Busby and Onggo (2013) recently modelled socially amplified public responses to zoonotic disease outbreaks. But these studies assumed essentially homogenous populations. As suggested earlier, social risk amplification was from the start conceived as a communications phenomenon taking place in a network of 'amplification stations' of different kinds. And more recent work on risk perception (Muter et al., 2013; Scherer & Cho, 2003) has shown empirically that individuals' risk perceptions are strongly determined by their social connections. It therefore seems essential that modelling should involve heterogeneous agents interacting within a social network.

There have also been some basic criticisms of the social risk amplification framework itself. In particular, Rayner (1988) argued that the concept naively assumed risks to exist objectively. The criterion for testing whether risk was amplified at any time was whether social beliefs were greater than the objective level. Rayner argued that risks do not exist outside the social system, and those with the expertise to have the most complete and accurate understanding of a risk were still social actors, subject to social processes. A recent study (Busby & Duckett, 2012) made an attempt to deal with this. It involved an empirical analysis of how people form beliefs about distortions in the risk beliefs of others. Most people have to get their information about societal risks from other social actors, rather than direct experience. But, while relying on other actors, they also anticipate how their views might be biased. Some earlier studies pointed in the same direction. For example, Petts and Niemeyer (2004) referred to how people expect the news media to exaggerate risks knowingly. Frewer (2004) argued that people correct and even over-correct for the biases they expect in sources of information that promote their own vested interests (see also Frewer, Scholderer, & Bredahl, 2003). And Renn and Levine (1991) claim that information receivers by default tend to assume that risk communicators are trying to deceive their audience. Modelling risk amplification should therefore represent not just actors communicating risk beliefs to each other, but actors mutually theorising about and compensating for each other's apparent biases.

We therefore argue that there are several important reasons for modelling social risk amplification generally, and for using agent based modelling specifically. The general justification for using agent based modelling is that it is, as Axelrod (1997, p. 3) has suggested, ‘a third way of doing science' – not proving theorems but making inductions from what are effectively thought experiments. Gilbert and Troitzsch (1999, p. 5) suggest that building simple simulation models is valuable both as a process of formalising social theory and discovering its consequences in an artificial society. Computational agent-based models have a specific relevance because ‘the consequences of adaptive processes are often very hard to deduce when there are many interacting agents following rules that have non-linear effects...’ (Axelrod, 1997, p. 4). They are especially appropriate for studying processes that lack central coordination (Macy & Willer, 2002) and where the effects of diversity in individuals' attributes and behaviours are relevant to the behaviour of a system as whole (Macal & North, 2010). Social risk amplification is a phenomenon in which heterogeneous agents are engaged in parallel processes without a well-defined order of action (Gilbert & Troitzsch, 1999, p. 6), and in which we cannot reasonably assume homogeneity and perfect mixing within compartments (Rahmandad & Sterman, 2008). Agent based modelling makes a commitment to methodological individualism, tracing all collective phenomena back to individuals but, as Epstein and Axtell (1996, p. 16) point out, it still allows emergent institutions to have feedback effects on individual agents. This, as we have suggested, is an important characteristic of social risk amplification. Although agent-based approaches appear not to have been used in the development and application of risk amplification, they have been reported in somewhat similar areas – for example the modelling of warning message dissemination through multiple channels (Nagarajan, Shaw, & Albores, 2012), the mutual influence of a society's members on their choice of transport modes (Sunitiyoso & Matsumoto, 2009), and the diffusion of new products (Amini, Wakolbinger, Racer, & Nejad, 2012).

In the agent model development that follows, we first deal with the core model of risk perceivers’ social interaction in Section 3. We then explore how to represent the role of behaviour in Section 4, and then add the representation of inter-group communication in Section 5.

The first key element is the proposition that social actors find out about a societal risk almost entirely from other actors, not from direct physical observation of experience. The ‘observations’ that shape risk beliefs, come from within the social system. Most obviously actors’ beliefs are shaped by those of their peers and a model therefore requires a commitment to a specific mechanism through which social actors interact. Our choice is to draw on Kuran and Sunstein's (1999) notion of availability cascades, which itself derived from Tversky and Kahnemann's (1973) work on the heuristics and biases that arise in human decision making under uncertainty. Kuran and Sunstein (1999) show that an expressed risk perception has increasing plausibility through rising availability in public discourse. They argue that, of all the cognitive heuristics, the availability heuristic is the most fundamental to the social response to risk events in which people tend to form their risk judgments largely on the basis of information exchanged through a social process. Kuran and Sunstein's framework contains several basic elements that need to be modelled: (1) people have internal or espoused beliefs; (2) people have external or expressed beliefs, which may differ from their espoused beliefs; (3) espoused beliefs are influenced by the availability of a risk perception in public discourse for informational reasons (they tell people something about the risk); (4) expressed beliefs are influenced by the availability of a risk perception in public discourse because people are motivated for reputational reasons to conform; (5) there are actors, organisational or individual, who knowingly exploit the availability effect to raise or lower societal risk perceptions. Kuran and Sunstein provide a compelling argument for these elements. They describe how a focus on purely informational effects (found in some parts of the prior literature) is invariably under-socialised, neglecting the way in which people have to manage social reputations; and how a focus on purely reputational effects is over-socialised, neglecting the rationality of relying on social discourse for information about a risk

The availability of a risk perception exists in some social network in which N agents are connected according to some graph G by bi-directional links such that Gij
                      = 1 if i and j are social neighbours but 0 otherwise. We fix this network for the rest of the analysis, which seems reasonable in the context of an individual risk issue, but is clearly a simplification of a reality in which unacquainted individuals can be brought together in dealing with a common threat. Each agent i has an espoused (that is, internal) belief, or not, in some proposition in public discourse, besp,i
                      ∈ {0, 1}, and an expressed belief, bexp,i
                      ∈ {0, 1}. For example, in the BSE crisis (Beck, Asenova, & Dickson, 2005) the central risk proposition was that a disease crossed the species barrier from cattle to human. In the UK MMR triple vaccine crisis (Stroud, 2005) the risk proposition was that the vaccine caused autism. The defining aspect of the availability heuristic (Tversky & Kahnemann, 1973) is that the probability of a proposition is estimated by its availability, so at any given time t at which i is active its belief is a function of the proportion qi
                      of its social neighbours expressing that belief, 
                        
                           
                              q
                              i
                           
                           =
                           
                              (
                              
                                 ∑
                                 
                                    j
                                    |
                                    G
                                    i
                                    j
                                    =
                                    1
                                 
                              
                              
                              
                                 b
                                 
                                    e
                                    x
                                    p
                                    ,
                                    j
                                 
                              
                              )
                           
                           /
                           
                              |
                              
                                 {
                                 j
                              
                              |
                           
                           
                              G
                              
                                 i
                                 j
                              
                           
                           =
                           1
                           
                              }
                              |
                           
                        
                     .


                     Kuran and Sunstein (1999) link espoused beliefs to the informational role of risk communications and expressed beliefs to the reputational role. Internal beliefs about the truth of some hazard are based on the information contained in public discourse. But expressed beliefs are based on reputational motives: on the extent to which individuals feel they should agree with those around them. At around the same time that Kuran and Sunstein's work emerged another study, from Gardner, Kleinman, and Butler (2000), argued that informational and reputational motives led to different functional forms of response. Informational motives made the likelihood of influence a concave function of how widely an idea was accepted among a local reference group. Reputational motives made it a convex function. It therefore becomes natural to model the availability effect in this way. Given some positive parameter C we simply update i’s beliefs after a discrete time interval to besp,i
                      (t + 1) = 1 with probability qi
                     (t)1/
                     
                        C
                      and bexp,i
                      (t + 1) = 1 with probability qi
                     (t)
                        C
                      and otherwise set them to zero.

This heuristic process of belief updating reflects the fact that agents are characteristically adaptive rather than rational, given their cognitive limitations (Doran, Palmer, Gilbert, & Mellars, 1994), and follow simple procedures when giving and receiving influence (Axelrod, 1997, p. 153). The basic notion that individuals are willing to set aside what beliefs they formerly had in favour of those received from social interaction underlies thinking about information cascades that has gone on for some time: Kuran and Sunstein cite a number of earlier studies, including the commonly-cited work of Banerjee (1992) and Bikhchandani, Hirshleifer, and Welch (1998). In practice, the availability effect is not determinate. It will vary between issues and individuals, and quite probably within individuals from one time to another. And individuals may sometimes misperceive the expressed beliefs of others, given the ambiguity of natural language and limited bandwidth of human communications – especially when conducted via social media. It is therefore necessary to incorporate noise in the belief updating process, for example by switching from belief to non-belief or vice versa at random with some relatively small probability ν.

Kuran and Sunstein also make an important point about the existence of ‘availability entrepreneurs’. Certain agents have incentives to amplify or attenuate risk in public discourse. Providers of protective products and services, for instance, may benefit from a widespread belief in some hazard, whereas providers of products and services that put people at risk may benefit from an attenuated hazard perception. In a detailed case study, Lofstedt (2008) clearly portrays an organisational actor (a cancer research foundation) as an availability entrepreneur, deliberately raising the availability of a specific hazard (the carcinogenic effects of aspartame) in the public discourse. The modelling of this requires that certain agents can spontaneously develop expressed beliefs, rather than simply express beliefs determined by availability. It also requires that these agents have a strong social capacity to promote their beliefs. The simplest, general representation of this is – for every agent – to set some low probability Q with which it spontaneously has an expressed belief value, which is 1 or 0 with equal probability. The entrepreneur's deliberately engineered social influence can then be represented in various ways. Perhaps most simply, availability in all interactions is biased by the entrepreneur's spontaneous expressed belief value by taking a mean of the social neighbourhood availability qi
                      with the entrepreneur's expressed belief in the S subsequent social interactions, where S is a model constant. Much more complex representations of availability entrepreneurship can readily be envisaged – for example, allowing entrepreneurs to search in the social network for highly connected hubs and influence their expressed beliefs. But in this simple form Fig. 1
                      illustrates the agent's decision rules, at this point, using pseudocode.

The outcome of this representation, before a more meaningful level of complexity is introduced, is indicated in Fig. 2
                     
                     
                      by two sample traces from a simulation of 1000 agents of the proportion believing in a risk proposition over 20,000 model periods, in each of which one agent is selected at random with equal probability for activation. The relevant population will vary from case to case, depending on the specificity and localisation of the risk event in question. Responses to even relatively global crises such as the BSE outbreaks were sometimes studied as socially local phenomena in small networks (Lehmkuhl, 2008). Using relatively small numbers also helps avoid ‘epistemic opacity’ (Miller, 2015). And there is some evidence that important emergent behaviours appear insensitive to network size (Santos & Pacheco, 2005). But modelling a particular situation will require a specific judgment of the appropriate N. The black line shows the time series of mean espoused beliefs, and the grey line that of expressed beliefs. Two successive runs of the model with identical parameters are shown in the upper and lower parts of the figure, indicating the extent to which the belief trajectories are path dependent. For the agent network structure we use a scale-free network with a power law distribution of link numbers k in which the number of nodes with k links is proportional to k
                     −
                     
                        γ
                     . This seems to apply to many actual networks of social contacts, in which γ generally lies in the range of 2 to 3 (Barabasi, 2009; Santos & Pacheco, 2005). At t = 0, agents are randomly assigned an espoused belief of 1 with some probability Iesp
                     , otherwise 0; and an expressed belief of 1 with some low probability Iexp
                     , otherwise 0.

The availability mechanism specified so far produces growth in risk perception up to some quite high, but not saturated level with very little distinction between expressed and espoused beliefs. The process shows some drift with fairly well-defined turning points. Parameter values are C = 2, ν = 0.01, Q = 0.001, S = 200, γ = 2.5. Sensitivity to these and subsequent parameters is discussed later.

A central element of Kasperson et al. (1988) social risk amplification framework is that social actors act on their perceptions of risk. These actions are themselves observed by other social actors, and responded to. Behaviour is the product of amplified risk perceptions and it simultaneously shapes those perceptions. For example, in relation to risks such as pharmaceutical and food contamination (Ingelfinger, 2008; Wolnik, Fricke, Bonnin, Gaston, & Satzger, 1984), heightened risk perception typically reduces consumption, and so reduces exposure, the reported prevalence of Liu, Huang, and Brown's (1998) study of a milk contamination crisis showed an obvious connection between heightened risk perception and reduced consumption. If the risk is to the availability of a commodity, rather than its contamination, heightened risk perception might increase or bring forward consumption, and ultimately magnify perception. But in the example that follows we concentrate on the first case.

Although we refer to the risk bearer's exposure path as being ‘consumption’ it is really any discretionary aspect of the risk bearer's behaviour that shapes the risk. Then what we call consumption is most simply another binary variable ci
                      ∈{0, 1}, equated with the negation of internal belief, ci
                      = 1 − besp,i
                     , such that if i believes in some hazard it does not consume, but otherwise does consume. Consumption in a population is, to varying degrees, observable by the same population. In the case of major risk events, global consumption levels are widely reported with reasonable credibility – for example, travel and tourism levels and their changes during the SARS crisis (Brahmbhatt & Dutta, 2008). In the case of more minor events, individuals may only observe consumption behaviours in their direct social network. When general reports are available, individuals will be able to estimate the mean public consumption ∑
                        i ∈ [1, N]
                     ci
                     /N, and thereby the mean espoused belief. Probably the most parsimonious model of how this affects perception is then to revise an individual's espoused beliefs (and its state of consumption) if the discrepancy between the mean public consumption and its current espoused belief (0 or 1) exceeds some threshold T, a model constant. Thus:

                        
                           
                              
                                 
                                    
                                       
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             
                                                t
                                                +
                                                1
                                             
                                             )
                                          
                                          =
                                          0
                                          
                                          if
                                          
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                          −
                                          
                                             (
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   [
                                                   1
                                                   ,
                                                   N
                                                   ]
                                                
                                             
                                             
                                                (
                                                1
                                                −
                                                
                                                   c
                                                   
                                                      e
                                                      s
                                                      p
                                                      ,
                                                      j
                                                   
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                )
                                             
                                             )
                                          
                                          /
                                          N
                                          >
                                          T
                                          ;
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             
                                                t
                                                +
                                                1
                                             
                                             )
                                          
                                          =
                                          1
                                          
                                          if
                                          
                                          
                                             (
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   [
                                                   1
                                                   ,
                                                   N
                                                   ]
                                                
                                             
                                             
                                                (
                                                1
                                                −
                                                
                                                   c
                                                   
                                                      e
                                                      s
                                                      p
                                                      ,
                                                      j
                                                   
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                )
                                             
                                             )
                                          
                                          /
                                          N
                                          −
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                          >
                                          T
                                          ;
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             
                                                t
                                                +
                                                1
                                             
                                             )
                                          
                                          =
                                          
                                             b
                                             
                                                e
                                                s
                                                p
                                                ,
                                                i
                                             
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                          
                                          otherwise
                                          .
                                       
                                    
                                 
                              
                           
                        
                     
                  


                     Fig. 3 illustrates the additional pseudocode.

Example traces are shown in Fig. 4 in which T = 0.5 and the other parameters are set at previous values. The main effect is to separate the espoused and expressed beliefs more clearly in value.

This way of representing the effect of observed behaviour on perception is simplistic in various aspects. For example, we have taken no account of the way in which people might avoid inconsistency between expressed beliefs and consumption behaviour. It therefore illustrates only one way of making the commitment to incorporating the perception-behaviour link in a risk amplification model.

Probably in all risk cases there will be one or more risk principals. These are the social actors, generally organisations, responsible for a risk. Often they include producers of good and services who are causally responsible for a risk – for example through contamination events in food processing installations, disease outbreaks in healthcare facilities and so on. They may well also include state agencies that regulate such producers and carry some moral if not causal responsibility. The members of a society are clearly influenced in their risk beliefs not only by their peers but also by such risk principals.

Risk principals are, generally, either sources or users of expert, objective risk assessment – typically estimating the probability of harm given consumption, σ ∈ [0, 1]. This might be the probability of fatality per unit of consumption (for example 1 kg of contaminated foodstuff, or period of exposure to an air-borne disease, or a single inoculation). In most cases there will be some non-zero background level of hazard, σnormal
                     , but during a crisis (for example a food contamination event, or disease outbreak) lasting for some period tinitiation
                      to tresumption
                      some heightened level, σraised
                     . In complex risk issues, the group of experts may well be ill-defined, consisting of independent academics, individuals employed by state regulatory agencies and those employed by commercial interests. There is evidence that expert risk beliefs converge with increasing inter-communication (Muter et al., 2013) but clearly in any particular case there may be no consensus. In what follows we assume a single, consensual expert assessment. In some contexts, however, a better approach might well be a more socialised model of the expert process.

The public are not exposed to expert risk assessment continually, and perhaps the simplest representation of the timing of risk communication is that it is triggered when there is a discrepancy greater than some threshold D between the harm probability σ and the probability a member of the public has a positive expressed belief ∑
                        i ∈ [1, N]
                     b
                     
                        exp, i
                     /N, for example as indicated by public surveys. Again, it is possible to represent this in quite different ways, but some commitment needs to be made to how risk communications from risk principals are triggered. However, it is unlikely that general members of the public receive expert estimates in an unmoderated form. We made the point earlier that the way in which actor A communicating about a risk to actor B does so with some expectation of whether B is under- or over-sensitive to communications from A. We described how Rayner's (1988) early critique of social risk amplification, and a later revision of the framework (Busby & Duckett, 2012), requires that we think of social actors as deciding how to interpret risk messages based on their expectations about bias and distortion in those messages. We also cited other studies showing individuals correct for others’ expected distortions (Frewer, 2004; Petts & Niemeyer, 2004; Renn & Levine, 1991). This involves actors engaged in ‘theory of mind’ (for example De Weerd, Verbrugge, & Verheij, 2013): holding representations of what is in the mind of other actors when interpreting what they hear from them. A commitment therefore has to be made in any modelling process to what these theories of mind are, and how they influence agents’ communicative actions.

The simplest possible approach is to assume that public actors believe that a risk principal, in the context of a specific type of belief, has a fixed level of bias in its communications, βprincipal
                     , where βprincipal
                      = 0.5 indicates neutrality, 1 indicates maximal exaggeration, and 0 maximal understatement of risk. Similarly a risk principal attributes a fixed bias βpublic
                      to the public as a group. Putting the βprincipal
                      constant assumes that actors learn their theories of mind from one crisis to another, rather than within the course of a specific crisis. For the principal a basic decision rule about what to communicate is to say that if (
                        
                           
                              ∑
                              
                                 i
                                 ∈
                                 [
                                 1
                                 ,
                                 N
                                 ]
                              
                           
                           
                              b
                              
                                 e
                                 x
                                 p
                                 ,
                                 i
                              
                           
                           
                              (
                              t
                              )
                           
                           /
                           N
                           −
                           σ
                        
                     ) is positive (the public as a group are over-stating the risk) and βpublic
                      > 0.5 (they are normally expected to do so), the communication m after some delay A should be m(t + A) = 0, telling the public there is nothing to worry about. If (
                        
                           
                              ∑
                              
                                 i
                                 ∈
                                 [
                                 1
                                 ,
                                 N
                                 ]
                              
                           
                           
                              b
                              
                                 e
                                 x
                                 p
                                 ,
                                 i
                              
                           
                           
                              (
                              t
                              )
                           
                           /
                           N
                           −
                           σ
                        
                     ) is negative (the public are under-stating the risk) and βpublic
                      < 0.5 (they normally do so) the communication m(t + A) = 1, telling them there is something to worry about. But if (
                        
                           
                              ∑
                              
                                 i
                                 ∈
                                 [
                                 1
                                 ,
                                 N
                                 ]
                              
                           
                           
                              b
                              
                                 e
                                 x
                                 p
                                 ,
                                 i
                              
                           
                           /
                           N
                           −
                           σ
                        
                     ) is positive and βpublic
                      < 0.5 there should be some non-zero probability that the communication m = 1, rather than 0, because it is generally believed the public under-estimate even though, on this occasion, it appears to be exaggerating. The closer the value of βpublic
                      to 0 the more it under-estimates, so probability (m(t + A) = 1) = 0.5 − βpublic
                      in this case. Similarly, if (
                        
                           
                              ∑
                              
                                 i
                                 ∈
                                 [
                                 1
                                 ,
                                 N
                                 ]
                              
                           
                           
                              b
                              
                                 e
                                 x
                                 p
                                 ,
                                 i
                              
                           
                           
                              (
                              t
                              )
                           
                           /
                           N
                           −
                           σ
                        
                     ) < 0 and βpublic
                      > 0.5, probability (m(t + A) = 0) = βpublic
                      − 0.5.

The risk communication m is broadcast to the public agents as ‘news’. An agent has a finite probability that it will be influenced by the news. This probability is a function of individual susceptibility, λi
                      ∈ [0, 1], a quantity that is fixed for a given agent but randomly endowed. News is persistent, and there can be some difference in its age τnews
                      when attended to by different agents, and it is reasonable to discount it by some universal factor δ, so that the probability of an agent i updating its belief to be consistent with the news is λi
                      (1 + δ) 
                        −τnews
                     . Only the most recent item of news is considered by a public agent.

Given this probability that a public agent pays attention to the news, it needs to be given some rule for interpreting communications from the risk principal. For instance, if besp,i
                     (t) = 0 = m(t), or if besp,i
                     (t) = 1 = m(t), the agent's current belief and the news are consistent so it should retain its current belief. But if besp,i
                      = 0 and m = 1 then, if also βprincipal
                      > 0.5, the principal tends to amplify so the communication that the belief is true is simply a manifestation of this bias, indicating that the agent's posterior belief should definitely stay at zero. But if βprincipal
                      < 0.5, the principal tends to attenuate and this gives strength to the news that the belief is true. So with some finite probability 0.5 − βprincipal
                      the agent should update its belief to 1. If besp,i
                      = 1 and m = 0 then, if also βprincipal
                      < 0.5, the principal tends to attenuate and the communication is simply a manifestation of this bias, indicating that the agent's posterior belief should definitely stay at 1. But if βprincipal
                      > 0.5, the principal tends to amplify so it seems reasonable to follow its communication stating that the belief is false with some probability βprincipal
                      − 0.5.


                     Fig. 5
                      shows the pseudo-code for the risk communications processes. It seems likely that in practice these theories of mind will be highly context specific, varying between actors and situations, because they are a product of individual histories. The main point is that some kind of commitment has to be made to a mechanism describing how people adjust for their preconceptions about other people when acting on and forming their communications.


                     Fig. 6
                      shows a typical trace with D = 0.1, A = 100, and the operative risk levels σraised
                      andσnormal
                      set at 0.8 and 0.01 with tinitiation
                      = 10,000 and tresumption
                      = 13,000. The attributed biases βpublic
                      and βprincipal
                      are 0.9 and 0.1. The figure shows the public expressed value on the black trace, the amplification of the actual risk level in mid-grey (showing mostly attenuation in this case), and the density of changes in belief in light grey. The change density is the proportion of the population changing either or both of their expressed and espoused beliefs within each 10 cycle period of the model. As expected, belief changes occurred much more frequently around the change of the objective risk change, but also occurred from endogenous activity – at somewhat lower levels – at two distinct points in the trace before and after the objective risk change.

A general view (Midgley, Marks, & Kunchamwar, 2007; Moss & Edmonds, 2005) is that the validation of agent based models is essentially of two kinds: micro, the validation of the component assumptions and decision rules, and macro, the validation of the outcomes that emerge in the model's behaviour. But as Midgley et al. (2007) argue such validation is inherently difficult, given the heterogeneity of agents and the shaping of behaviour at the macro level by interaction at the micro level. They suggest that ‘even the “simple” step of establishing face validity may itself be a significant challenge’. In Table 1
                        
                         we summarise the elements on which Sections 3–5 were based. The table does not list all the work we draw on in Section 3, and it obscures the fact that some of the key contributions – such as Kuran and Sunstein's (1999) – themselves draw on other research, most of it empirical. In some ways this is beneficial, as it helps synthesise and interpret prior work. Its limitation is that it creates more distance between original empirical work and the modelling that is ultimately based on it. In all cases the evidence lacks (1) support for specific functional forms, and (2) indication of specific values for model parameters. A large part of the problem is context specificity: as the table indicates, the various studies arise in various, quite different contexts.

However, modelling only where calibrating data exist would unduly restrict the extent to which modelling could contribute to theory development (Miller, 2015). Part of its value is to identify the empirical research needed on social constants, and to show what decision makers need to know about specific, contextual parameters in order to understand the potential for social risk amplification in specific cases. The effort devoted to measuring such parameters can be guided by some kind of sensitivity estimate, such as that shown in Table 2. Our outcome measure Ŷ is the mean discrepancy over time between objective risk level and the mean public expressed belief during the period indicated on the traces in previous figures (in which there is a single episode of an increased objective risk level). This discrepancy is expressed instantaneously as a probability, with values greater than 0.5 indicating amplification and less than 0.5 attenuation, Y(t) = 0.5 + 0.5 (
                           
                              (
                              
                                 ∑
                                 
                                    i
                                    ∈
                                    [
                                    1
                                    ,
                                    N
                                    ]
                                 
                              
                              
                                 b
                                 
                                    e
                                    x
                                    p
                                    ,
                                    i
                                 
                              
                              
                                 (
                                 t
                                 )
                              
                              )
                              /
                              N
                              −
                              σ
                           
                        ). Ford and Flynn (2005) suggest using the simple product moment correlation between model outcome and model constants to measure the relevance of each constant's role, so we randomly sample the constants 100 times from their plausible ranges, assuming uniform distributions for each, and run the model 10 times for each sample. The question of how to establish plausible ranges for model constants is problematic, and ultimately subjective. The table suggests that in the current setup the outcomes are insensitive to the network parameter (the exponent defining the link degree distribution). They are moderately sensitive to specific parameters defining the social context, notably the ‘noise’ or probability of random changes in belief, and to the bias attributed to the public by a communicating risk principal.
                     

The basis for macro-validity needs to be empirical time series of risk perceptions, risk responses or indications of risk beliefs in social groups, in response to identifiable risk events of societal significance. What we know from the literature is that such time series can exhibit very different forms, with few qualitative features in common. Deploying a model in practice, to support decisions in the course of specific risk episodes, requires a comparison of model output with observations in episodes that are obviously similar in some relevant way.


                        Loewenstein and Mather's (1990) empirical work records time series of public concern in a variety of different issues, all of which they regard as societally significant risks. Table 3 summarises the measures used and the qualitative features of these series, in our words. All the issues show measures of concern that fluctuate substantially more than the underlying, objective conditions – sometimes to extreme degrees. But the qualitative features vary substantially across contexts, illustrating how important it is to avoid over-generalisation. Loewenstein and Mather's work is now dated, given changes in social communication and interaction. The measures of concern are, in many cases, only indirectly connected with the extent of some risk belief in a society. The variety in patterns of response for different issues is striking, however.

It is notable that there are no flat peaks in Loewenstein and Mather's (1990) data, nor in those of Chung (2011) – nor in those of our simple simulation model. The exogenous threat takes the form of a finite impulse, and so has a rectangular profile, but the dynamics of the social response mean that risk beliefs grow towards a peak, sometimes repeated, before immediately declining. Similarly, in the absence of threat the processes show a continual drift, with turning points. Klimek, Bayer, and Thurner (2011) also found evidence for public attention more commonly arising for endogenous reasons than in response to a clear exogenous event. And Midden and Verplanken (1990) found that risk perceptions around nuclear power showed considerable instability over time.

A more recent empirical study of the dynamics of risk perceptions around a pandemic influenza outbreak (Ibuka, Chapman, Meyers, Li, & Galvani, 2010) produces a similar indication. Over the survey period, the objective incidence of cases increased monotonically. But two measures of aggregate risk perception show substantial instability. The former broadly looks like ‘noise’ – an aperiodic, low amplitude, apparently random movement; the latter looks more like ‘instability’ – movements of large amplitude with an approximate periodicity. Generally, though, longitudinal data on risk perception is hard to come by. And, because typically it only covers a period in which some crisis is established, it cannot show the dynamics prior to an exogenous change in risk. A good example is Lau, Yang, Tsui, and Kim (2003) study during the SARS outbreak, which was used as an empirical comparison for a system dynamics model of social risk amplification (Busby & Onggo, 2012). It shows a clear peak, but the sparsity of observations and the short window of data collection preclude the possibility of showing the kind of endogenous fluctuation in risk perception that our model indicates.

Finally, Moss and Edmonds (2005) argue that it is such turning points in time series, unpredictably clustered volatility, and consequent leptokurtosis, that appears beyond the reach of econometric models. Yet such a feature is common in the behaviour of aggregated social phenomena, and arises because agents are socially embedded and have ‘meta-stable’ decision rules that only respond when thresholds are crossed. Fig. 7
                         shows the distribution of proportional period-by-period changes in the mean public espoused risk belief from a single simulation with modal parameter values, for windows of 10 model ‘ticks’, (b(t + 10) − b(t))/b(t  + 10). It clearly shows strong leptokurtosis. The value of excess kurtosis (defined in terms of fourth and second central moments, μ
                        4 and μ
                        2, as μ
                        4
                        /μ
                        2
                        2 − 3) is 815, which is very high.

Clearly, the possibilities for validation of any specific model of social risk response are limited. But this reflects the state of our knowledge generally about the subject in question. The model produces certain features that simply have not been examined empirically, despite their potential theoretical interest, such as the drift in a population's mean belief that occurs for internal, systemic reasons rather than as a result of external signals or events.

@&#DISCUSSION AND CONCLUSION@&#

The outcomes of the modelling and simulation point to the need to update our theorising about the social amplification of risk in two main ways. First, the simple finding that dynamics are interesting matters to theory. Amplification is not a simple case of constant multiplication of some risk level over time, even when that risk level is constant. Past work (with the exception of the systems dynamics studies of Burns and Slovic (2007), and Busby and Onggo (2013)) has said little about dynamics. The original framework (Kasperson et al., 1988) points to ‘ripple effects’ that by definition follow some initiating risk event, but pays little attention to how much amplification fluctuates over a crisis, to what extent it pre-figures it, and to what degree there is an aftermath. Our simulation shows one possible pattern, and the simple, underlying structure of agents interacting through availability-based rules provides a mechanism that can be assimilated in the theory of social risk amplification.

The internally-produced change evident in the simulation of social risk response also matters. Endogenous peaks in the simulation are not as large as peaks that follow crises in which objective risk suddenly increases (for example in a disease outbreak) – but they look significant and would create a material consequence for a risk manager, whether economic or political. The social amplification of risk literature does not deal with this, perhaps because the original framework (Kasperson et al., 1988) stresses the way in which social risk amplification is initiated by some ‘risk event’. Our theory of social risk amplification needs updating to allow for the possibility of a public anxiety that has no basis in some specific, objective occurrence. Such a proposition is almost impossible to confirm in practice, because in a complex society there is always some event occurring near the start of some growth of public concern that, in hindsight, can be claimed as its trigger. But neither is there any theoretical justification in assuming the opposite: that an identifiable event is necessarily required for an acute growth in social concern about some risk.

The way to revise theory to take account of such outcomes is to incorporate the commitments that have had to be made in the basic model proposed here. These commitments may need to be made differently in different contexts, reflecting the diversity of outcomes found, for example, by Loewenstein and Mather (1990). Such commitments include specific mechanisms of interaction, the relationship between espoused and expressed beliefs, and the role of informational and reputational motivations during interactions (Kuran & Sunstein, 1999). They include processes of deliberate distortion (Busby & Duckett, 2012; Lofstedt, 2008). And they include some representation of theory of mind, in which observers of risk responses base their own responses not only on the responses they observe but the models they have of those producing such responses.

It is also worth commenting on the connection between the basic notion of social risk amplification and the dissemination of warnings – as also analysed in the literature with agent based models (Nagarajan et al., 2012). Warning dissemination through peer networks as well as broadcast channels is an important mechanism not just for communicating information but also exerting influence, given limited compliance with official warnings. Zechman's (2011) model of water contamination events provides an example. The notion of risk amplification is that dissemination does not occur without distortion of some initial risk signal. But, equally, distortion does not occur without dissemination. So although social amplification can be seen as undesirable and problematic for risk managers it also achieves a dissemination of risk understanding that is often desirable if not vital in certain risk events, particularly if large-scale public action such as evacuation is needed. Both kinds of problem – anticipating distortions of public risk beliefs, and achieving active public response to risks – are faced by risk managers as aggregate effects across a population. But they are produced by individual agents interacting with one another and exchanging information about something that is exogenous to each of them yet endogenous to the population of which they are members. Agent-based modelling is logically central to our understanding of both facets of social responses to danger: productive dissemination and unproductive distortion.

The intended contribution is to make the understanding of social risk amplification more precise and therefore more operational – both as a basis for more directed empirical work and as a basis for theorising about what we mean by social risk amplification. As Miller (2015) has recently argued, a critical realist view calls for explanations in terms of underlying mechanisms, and agent-based modelling fundamentally represents the interaction of social actors, rather than variables, providing a process perspective rather than a variance perspective. An agent-based model such as ours explains social risk amplification as a mechanism, and the simulation of that mechanism allows us then to identify interesting consequences that have so far received little attention. The model is not intended to be definitive, but to show how some key elements of social risk responses can be represented:

                           
                              1.
                              The endogeneity of risk observation. Most risks of societal significance are not experienced or observed physically by most people: most people rely on other people, and the beliefs they express.

The endogeneity of risk behaviour. Risk beliefs shape risk behaviours (such as withdrawing from consumption of activities or products that expose people to the risk in question), and behaviours are observed, so shape risk beliefs.

The endogeneity of risk communication. Actors receive communications that have been adjusted or moderated to reflect the communicator's experiences and expectations about those communicated to, and communications received influence communications subsequently made.

We showed simple ways in which these elements can be represented, drawing particularly on Kuran and Sunstein's (1999) well-developed notion of availability cascades, itself built on more fundamental observations of the role of the availability bias in human responses to uncertainty. This gives insight into the mechanisms that risk managers dealing with public responses have to deal with, and indicate the range of outcomes they should be prepared for.

There are some obvious limitations of the approach taken here. First, there are important types of actor and related social processes that have been omitted from the model. The most obvious is the role of the media, quite often referred to in the literature (for example Petts & Niemeyer, 2004), and often exploited by availability entrepreneurs – as demonstrated by Bakir (2005). Second, the model does not deal with homophily, the affinity of individuals within groups, and related issues such as cultural polarisation (for example Flache & Macy, 2011). The literature on cultural risk selection (for example Douglas & Wildavsky, 1982) suggests that this is an important next step in developing the model. And the model has concentrated on the representation of single issues. Any real society has to come to terms with many risk issues that come into prominence at broadly the same time, making it important to understand how public anxiety can be attenuated simply through distraction. There were also limitations in verification and validation. As we discussed, these strongly limit any claims that can be made about the outcomes from the simulation, and clearly indicate that making models of this kind operational to support managerial practice or policy making has to involve investigation of what happens in specific contexts. Relying on generalised models with tentative parameters could be highly misleading.

Finally, there are of problems in the use of agent based computational modelling generally. Macy and Willer (2002) argue that ‘Computer simulation is more tractable (but less generalisable) than mathematical modelling and more rigorous (but less nuanced) than natural language’. In terms of representational richness and fidelity, on the one hand, and transparency, on the other, it is a half-way house and does not avoid the need for more formal treatments of social risk amplification. But it nonetheless represents a reasonable direction for representing amplification more precisely, and working out the consequences of such a representation. It broadly avoids falling into the ‘trap of verisimilitude’ (Doran & Gilbert, 1994) – of trying to say too much about the world – or the ‘trap of tractability’ – saying too little in order to be analytical. And it helps to enhance our explanatory spaces. If we were asked to explain a peak in risk perceptions, or a drift one way or the other, we would probably to try to find a news item, or some event in the world, that could cause such an outcome. But an equally plausible alternative is that peaks and drift come from the structures and mechanisms of social observation and reaction alone.


                        
                           List of notation


                           
                              G
                           
                           
                              non-directed graph s.t. Gij
                                  = 1 if agent i and agent j are neighbours, else 0


                                 
number of public agents

agent i’s espoused (private) and expressed (public) beliefs at time t
                              


                                 
fraction of agent i's neighbours expressing a belief


                                 
probability of random belief switching when an agent active


                                 
exponent determining probability of influence from belief availability


                                 
spontaneous adoption of belief as an availability entrepreneur


                                 
number of continuing interactions of availability entrepreneur's influence


                                 
exponent defining distribution of link degrees in network


                                 
consumption of agent i at t
                              


                                 
margin at which consumption observation revises a belief


                                 
objective risk level at t
                              


                                 
margin at which risk principal communicates


                                 
bias in expressed risk attributed to risk principal and public

lag before communication from risk principal

agent i’s susceptibility to influence by risk principal's communication

age discount factor for risk principal's communication

@&#ACKNOWLEDGEMENTS@&#

Many thanks are due to the reviewers of an earlier version of this paper for their considerable insights and incisive advice.

@&#REFERENCES@&#


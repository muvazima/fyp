@&#MAIN-TITLE@&#An adaptable navigation strategy for Virtual Microscopy from mobile platforms

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The JPEG2000 standard is very suitable to access and interact with WSIs.


                        
                        
                           
                           The decoding strategy allows a granular, independent and efficient decompression.


                        
                        
                           
                           Index files enable a fast access to specific JPEG2000 data regardless the WSI size.


                        
                        
                           
                           This architecture permits to adapt content to user, device and network bandwidth.


                        
                        
                           
                           This model exploits the client resources and lightens the server loading.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Virtual Microscopy

Whole Slide Images

Visualization

JPEG2000

Mobile devices

Telepathology

@&#ABSTRACT@&#


               
               
                  Real integration of Virtual Microscopy with the pathologist service workflow requires the design of adaptable strategies for any hospital service to interact with a set of Whole Slide Images. Nowadays, mobile devices have the actual potential of supporting an online pervasive network of specialists working together. However, such devices are still very limited. This article introduces a novel highly adaptable strategy for streaming and visualizing WSI from mobile devices. The presented approach effectively exploits and extends the granularity of the JPEG2000 standard and integrates it with different strategies to achieve a lossless, loosely-coupled, decoder and platform independent implementation, adaptable to any interaction model. The performance was evaluated by two expert pathologists interacting with a set of 20 virtual slides. The method efficiently uses the available device resources: the memory usage did not exceed a 7% of the device capacity while the decoding times were smaller than the 200ms per Region of Interest, i.e., a window of 
                        
                           256
                           ×
                           256
                        
                     
                     pixels. This model is easily adaptable to other medical imaging scenarios.
               
            

@&#INTRODUCTION@&#

Virtual Microscopy (VM) may be thought of as a collection of techniques that facilitate a set of Whole Slide Images (WSIs) can be examined from any place and at any time. Typically, a histopathological specimen is digitized at the higher possible magnification to provide the pathologist with the required information for diagnostic, research, training or educational tasks [1]. During the last decade, the dynamic interpretation of WSIs has been integrated with many pathology activities such as teaching, research, digital archiving, teleconsultation, and quality assurance testing [2]. Different works have studied the viability and agreement of diagnoses by using WSIs, reporting promising results [3,2,4]. Recently, medical schools in the United States have introduced digital pathology courses and virtual slide laboratories, promoting a generation of pathology trainers who may prefer digital pathology imaging over the traditional hands-on light microscopy [5]. A large variety of technical solutions supported these studies, e.g., Aperio ImageScope [3], home systems such as U-DPS [2], DMetrix Digital Eyepiece [5] or WebScope [4], indicating little agreement has been so far accomplished.

Several technical and logistical barriers have delayed WSI becomes a widely accepted pathology modality [6]. A proper management of the number of files generated by a WSI demands large memory, processing and storage resources since the size of a WSI is typically on the order of gigabytes. Furthermore, since there is not a common image format for virtual slides, a large number of proprietary or vendor-specific formats has been constantly modified as long as new scanners have been introduced [7]. Standardization not only allows an user to perform certain functions in an optimal way, but it also offers quality guarantees, interoperability, independency from vendors and equipments, access to new technologies and possibilities to scale applications according to new requirements. A wider VM use will require full integration with laboratory information systems, seamless connectivity over broadband networks, efficient workstations, cost-effective storage solutions and standards-based informatics transactions for integrating information with WSI [5,6,8]. Lately, image quality improvements, smaller scan times and image-viewing browsers have converted digital pathology into an actual opportunity [6]. Overall, actual clinical scenarios require access to these files from any location, reason by which mobile devices might be considered as the support nodes of a VM network. However, such devices are still very resource limited [9] and, yet communication channels have remarkably improved, network bandwidths are frequently insufficient.

This problem has been addressed using a variety of approaches, the most common consisting in constructing pyramidal data structures that deal with different image scales that are stored as independent files [10]. For a requested Region of Interest (RoI) to be displayed, a complex combination of pyramidal files must be composed and this is usually computationally expensive. These pyramidal approaches have been evaluated from a VM standpoint, HD View, Zoomify, Gigapan and Google Earth, reporting pleasant interaction experiences when navigating a single WSI from a conventional computer [10]. Nevertheless, these approaches might be very limited when displaying a WSI from a low resource mobile device since in such a case, applications should deal with variable storage requirements, low compatibility, high processing demand and poor adaptation to different displays. Likewise, limited devices may have trouble managing a large number of files since their cache space may be easily overflowed. Aperio [11], a commercially available software allows an user to pan and zoom in and out virtual slides, but this system is computationally very demanding and requires a powerful infrastructure. Similar approaches are OpenSlide [12], NYU Virtual Microscope [13] and Deep Zoom (formerly called Seadragon) [14], among them, Openslide is an open source library devised to display WSIs and is compatible with different image formats. The NYU Virtual Microscope uses the Google Maps API and Deep Zoom is part of the Microsoft Silverlight platform, a proprietary software with a very limited mobile version. These last three applications are based on a pyramidal structure and share the limitations aforementioned for mobile devices. A different approach was proposed by Hadwiger et al. who introduced a multi-resolution virtual memory that performs dynamic updates and deals with missing data [15]. This system is not based on any standard, uses the lossy JPEG version and was devised to display data at a full resolution, a bottleneck in limited devices.

VM demands highly flexible, efficient, manufacturer independent and standard-based tools [7,16]. An alternative to the artificial pyramidal approach is the JPEG2000 standard, founded on the concept of making available any piece of required information, i.e., a particular spatial region at any desired quality and magnification. The standard appears to be flexible enough as to address the issue of streaming and visualizing demanding content in mobile devices [17], such as WSIs. This standard was smartly conceived to be granular, i.e., an image can be decomposed and compressed in small independent parts (grains) of information at different levels of magnification, several degrees of quality and independent spatial representation, facilitating a separated access and process of specific regions of the image, while also supporting large file sizes and a larger dynamic range of the pixel representation [18]. In addition, by the JPIP (JPEG2000 Interactive Protocol) standard, the client may demand specific RoIs from the server, instead of remotely accessing the whole JPEG2000 content [19]. Nevertheless, the JPEG2000 standard complexity may make it very expensive in computational terms [7] and therefore unrealistic at supporting a VM network. Basically, data allocation can be an actual burden of the navigation while the decoding process may be on the order of 2–5s, even when decoding a small VS of 
                        
                           9000
                           ×
                           12
                           ,
                           000
                        
                     
                     pixels. There exist some applications using different JPEG2000 implementations, all of them decompressing data at the server side and leaving to the client a purely passive role at receiving the raw decoded information to be displayed, for instance IIPImage [20], Djatoka [21], JVSMicroscope [7] and Web Microscope [22], being the latter a reference in certain academic and clinical institutions. This strategy throws away the JPEG2000 high compression rates since only uncompressed data are transmitted and ignores the potential processing improvement at the client side. Other works have explored the JPEG2000 as an interaction tool for VM by modifying the decoder implementation, retrieving and decompressing specific portions of the codestream [23–25], unfortunately, this tightly-coupled solution could be hardly extended to different platforms. Finally, Rosenbaum et al. proposed to send only the RoI encoded information and to complete the missing codestream (untransmitted) at the client side with a pre-defined template [17], but then the decompression times result equivalent because of the size of data.

This work introduces an adaptable and low computational cost VM framework that exploits the JPEG2000 potentiality at both the server and client sides. The possibility of meeting any requirement, i.e., any spatial region at any size, with a desired magnification and quality, makes this proposal adaptable to new scenarios, in particular to the training and educational VM. In that case, a group of pathologists or students, might simultaneously access the same WSI and therefore saturate the network. The main contributions of this work are:
                        
                           •
                           Unlike most existent solutions, this strategy has been devised to maximally exploit the processing resources at both the client and the server so the server sends compressed data and the client decompresses data, even under very limited computational capacity.

A smart decoding strategy addressed to construct any RoI by setting the requested region to an image which can then be decompressed by any standard decoder.

A flexible and scalable data management strategy that efficiently retrieves JPEG2000 compressed data at the server side, independently of the image size, by a coupled designed meta level index file.

A loosely-coupled architecture, web service oriented, providing functionalities that support interoperable and standard interaction over the network. This highly adaptable architecture adjusts the content to the user requirements, the device capacity and the network bandwidth, while it offers a progressive lossless visualization.

JPEG2000 is a highly flexible image coding standard that optimizes interaction with compressed data [26,27]. A key feature of this standard is that it encodes multiple resolution levels and quality layers. Resolution is related with the number of pixels that are needed to ensure that, at a particular image size, the displayed information is maximum. In contrast, the quality is a function of the number of bits that are used to represent a pixel. Resolution flexibility implies that an image can be retrieved at a low resolution (a small version of the image) and can be enlarged (by a factor of two) by adding the missing data and only these data [28]. The quality is connected with the concept of progressive user interaction and consists in displaying a very basic version of the image, with few details, that are progressively added as long as the user demands more information, until reaching a full lossless visualization, if needed [28].

The JPEG2000 norm is based on the Discrete Wavelet Transform (DWT) and the Embedded Block Coding with Optimal Truncation (EBCOT), both endowing the data representation with high granularity [29] (see Fig. 1
                        ). The DWT decomposes the input image into frequency subbands, producing a natural multi-resolution decomposition, with basically two wavelets: the Daubechies 9-7 for lossy compression, and the reversible Daubechies 5-3 for lossless compression [30]. The DWT image is divided into tiles that allow random access to spatial regions with different frequential information. The EBCOT compresses the image into small blocks (code-blocks) that encode the DWT coefficients of each subband. Each of the codeblocks, composed of a set of bit-planes, is ordered by levels of relevancy known as the quality layers, each containing a part of the whole information. Finally, the packet, the basic JPEG2000 information unit, is responsible for storing compressed data at a particular resolution level, a single spatial region and a unique quality level. The standard allows a progressive reconstruction of the original image by dynamically adding missing packets, improving the visualization of the image until a perfect reconstruction is obtained [18].

The JPEG2000 decompression process is expensive because of the decoding and the inverse transforming processes, a fact that has limited the JPEG2000 application in VM. A partial remedy to this bottleneck has consisted in assigning the processing responsability to a server which decodes the codestream and sends the resultant raw data [20,21,7,22]. The client acts as a simple information receptor and the potential client resources are never used, overloading the communication channel by transporting uncompressed data. Furthermore, the transmission of raw data necessarily reduces the possibility of storing relevant information at the client side and thus the potentiality of implementing effective cache policies that may reduce the network traffic. The option of decoding at the client side has been introduced either by decompressing the whole image, a real problem with the WSI sizes, or by adapting the decoder implementation to decompress specific packets [24,25]. The main drawback of this last solution is the inevitable dependence on the decoder implementation, or the problem of managing the dynamic organization of data, which in some cases has been approximated by completing the requested codestream with zeros [17], but then the decompressing times result to be equivalent to those obtained with the whole image. In summary, most of the existent VM applications have ended up by using JPEG2000 as a simple compression format, without exploiting its flexibility at representing the data.

Unlike previous approaches, the proposed strategy effectively integrates the client to the processing by generating, for each requested RoI, a new small JPEG2000 coded image that meets the desired RoI, i.e, same dimensions, resolution levels and quality layers. This is achieved by modifying the image main header and assembling that header with the packets associated with the RoI. In this way, an efficient decompression is accomplished by processing exactly the required image portion, at any desired quality and magnification. A resultant side advantage of this strategy is the independence of the implementation, i.e., any decoder can be used (see Fig. 2
                        ).

In an actual navigation scenario, the retrieval of specific data from a JPEG2000 file demands an intensive search within the codestream to localize the desired packets, whose location is coded in structures known as tag-trees [30]. Any individual query requires these structures to be decoded [30], a process that may take about 2s for a single packet of a large WSI. This problem has been overcome by using index files [29]. The herein used index files are based on the JPIP standard specification [31] and they are simple text files that provide an organized structure of the general image data at two different levels (see Fig. 3
                        ), the global image information (width, height, progression order, number of components, number of quality layers, number of decomposition levels, etc.) and the particular local configuration at the level of packets (quality layer, component, resolution, precinct number and byte ranges), thereby facilitating any application to identify and to extract bytes directly from the JPEG2000 files and therefore to meet complex user requirements.

In general, when navigating an image, a user requests Windows of Interest (WoI) that are identified by their image location, size (weight and height), resolution and quality. The system must therefore use a parser that maps the user request to the specific packets in the compressed image or codestream, after the image information box in the index file (see Fig. 3). Using the WoI coordinates, the parser computes the identifiers of those precincts
                           1
                           Precincts are a JPEG2000 image spatial partition.
                        
                        
                           1
                         associated to the spatial query. This information, together with the specific requested resolution and layer, is used to calculate the corresponding packet IDs. Once these IDs are found, a search in the index file determines the initial and final locations in the codestream of the specific bytes, i.e., the position of this packet in the compressed file. Finally, these bytes are extracted directly from the compressed file.

While these index files are very important to accelerate the time required to locate a packet within the codestream, they require an associated efficient access technique. Depending on the WSI size, the index files may result as large as a WSI and the search process may become as slow as to become an actual navigation bottleneck. For this reason, indexation was herein optimally managed by designing a hash-based structure composed of multiple small index files that may be selectively loaded to meet a client request. Each file stores data from a given set of packets. When a packet information is required, its identification number is used to determine the index file containing the necessary data. This strategy provides scalability and proper performance regardless the image size, since just one index file must be accessed and loaded in memory.

The proposed strategy exploits and extends the benefits of both the JPEG2000 and JPIP standards, adapting the content to the device capacity and user needs (see Fig. 4
                        ). Basically, any navigation request may be assembled and resources may be optimized if a flexible architecture is capable of implementing the standard granularity [32,17]. In particular, the level of quality is a variable of the user needs and hence the navigation might be speeded up by setting a maximum quality. Likewise, navigation may also be accelerated if the decoding policies, at both the server and client sides, are completely adaptable to the bandwidth. Any architectural approach must then be flexible enough as to cope with all these different scenarios.

The proposed architecture is loosely coupled and allows integration of different caching and prefetching models, which speed up the browsing performance [33,25]. Furthermore, the transmitted content can be adapted to the screen size, supporting several devices with different capacities (not only mobile ones). This architecture consists of three loosely coupled layers, described hereafter. Fig. 5
                         illustrates the information flow through the different modules of the proposed architecture.

This layer is the repository of the JPEG2000 compressed images and their respective index files, which facilitate access to such image files. When a new compressed image is stored, its index file is constructed using the information of the main header and the packet markers in the codestream. The proposed approach is independent of any database engine since data are stored as files. This layer is platform independent, i.e., it can be run from any operating system (Windows or UNIX based) and the required storage space depends exclusively on the image sizes. The application that generates the index files was developed using the Java SE platform, which is also platform independent.

This layer provides web service interfaces for a client accesses to data in the storage layer. The web services were developed using the Java EE platform and run over any Java Enabled Application Server. Such web services are interoperable and may be consumed by any client application. Four main services are available: List sends a list of the available images. Header receives an image name and returns the image main header. Metadata takes as input an image name and sends specific information, namely dimensions, progression order, number of precincts, number of components, number of quality layers, number of resolution levels, among others. Finally, for the Packets service, given an image name and a list of packet IDs, it sends the bitstream of each packet. The Data Manager module is an intermediate between the web services and the storage layer.

Alternatively, the Pixels service takes an image name and a WoI request (coordinates, resolution and layer), and returns the pixels of that window. This service may be suitable when decoding cannot be performed at the client side, for example devices with very low capacities or for web-based applications, which generally have no support for the JPEG2000 standard. This service connects to a Server Processor module which is responsible for packet calculation and generates a compliant codestream to be uncompressed using a JPEG2000 decoder.

It is composed of several modules for a user may visualize and interact with the WSI. A first module is a graphic user interface (GUI) with panning, zooming-in/out and quality operations. A second module is the cache manager that administrates the memory where previously requested data may be stored. This module removes old/unused data when this is full and takes advantage of spatial, resolution and quality scalability. The size of this cache memory is configurable according to the device capacity and adaptable to different models, for example, the Least Recently Used or the Least Frequently Used. The fact that the data representation is so granular facilitates the design of more complex cache policies that are constructed, after the principle of storing only what is relevant and will be used in the future. A third module is the Request Processor that demands the required data either to the cache manager (if they were previously requested) or to the corresponding web service. This module uses the Packet Calculator to identify the packets that are requested. In the smart decoding module, the retrieved data from the codestream are mapped to a JPEG2000 image which then can be decompressed using any standard decoder. Finally, raw data (pixels) are displayed by the GUI.

From any mobile device the first view is a dynamic list of the available WSIs. The user then selects that one to be examined and may easily switch between different WSIs of the dataset, as illustrated in Fig. 6
                        (a) and (b). Each thumbnail image is associated to a list of metadata, containing clinical information, that is pop out when long pressing the thumbnail image. If the pathologist picks a WSI, the navigation starts by displaying two views, a guide window that displays a low magnification version of the WSI and serves for the expert to be oriented within the WSI, and an exploration window showing a RoI (Fig. 6(c)). At each WSI, the expert may pan, zoom in or out and refine the quality by using some gestures and interface elements.

Experiments were performed with a dataset consisting of twenty skin biopsies of patients, stained with Hematoxylin–Eosin. Most of these cases are skin basal cell carcinomas, two were lentigines, a melanocytic nevus and an irritated seborrheic keratosis. The diagnosis difficulty was considered as moderate by our expert pathologist and, in general, they took less than a minute to perform a diagnosis. The WSIs were JPEG2000 compressed using 10 quality layers, 4 decomposition levels (5 resolutions), the lossless filter (W5x3) and precinct sizes of 
                           
                              64
                              ×
                              64
                           
                         for the first resolution level and dyadic increasing sizes for the other levels. The WSI resolutions vary from 104 to 340 mega pixels, and their sizes range between 630MB and 972MB. The proposed approach was compared with two baseline approaches: the lossy and lossless versions of the JPEG standard, constructing two pyramidal structures with different scale (spatial scalability) and quality (Signal-to-noise ratio scalability) versions of the original image, based on the Google Earth API documentation [34]. Images were JPEG and JPEG-lossless (JPEG-LS) compressed using 10 quality layers, 5 resolution levels, and tiles of 
                           
                              64
                              ×
                              64
                           
                         for the first resolution level and dyadic increasing sizes for the other levels. Finally, the experiments were run using a 1Mbps network. Table 1
                         shows a quantitative comparison of some representative WSIs in terms of formats, resolution, file size and number of files.

The server application was developed using the Java EE 1.5 platform and was deployed on the GlassFish Application Server. The storage and data provider layers run on a computer with 4GB RAM memory and 2.4GHz quad core processor. The client application for a single user navigation was implemented in the Android platform. The tests were performed using the Samsung GT-i9100 (Galaxy S2) device, with operating system Android 4.1.2, 
                           
                              800
                              ×
                              480
                           
                         display size, 1024MB RAM memory and 1.2GHz dual-core processor. Decoding was carried out using the Kakadu library [35] version 2.2.3 and the JasPer library [36] version 1.900.1, under the Java Native Interface.

Simultaneous access experiments were run on a desktop client device that randomly executed recorded requests of actual expert navigations. The client application was developed in the Java platform and tests were performed on a computer with 4GB RAM memory and 2.71GHz dual core processor, using The Kakadu library version 2.2.3 as the decoder.

@&#EVALUATION@&#

Provided that limited processing power, memory and bandwidth are the most critical constraints of any mobile device, evaluation is addressed to measure an efficient trade off between the navigation time and the percentage of used resources. The evaluation of the presented strategy was carried out by addressing the following quality attributes:
                           
                              •
                              Efficacy: The system complies the user requirements and the diagnostic task is not altered by the system.

Efficiency: The tasks are performed using the system resources appropriately (low response times and low memory consumption).

Concurrency: The system can simultaneously attend a given number of users without affecting the response times.

According to the previously mentioned considerations, the experiments assessed: the global perception of the user during the diagnosis and its accuracy, size of the image representations, memory consumption, and response times in transmission and decoding. These last were measured for a single and multiple users. For doing that, two sets of experiments were executed, a mobile client device was firstly used to evaluate the system performance during a single user navigation, and then, a desktop client device was used to evaluate concurrent access.

Given that efficiency does not depend on the image content, but on its size and diagnostic information, the single user navigation experiments were carried out using one WSI, the one that spanned the largest navigation times, i.e., the largest number of requests.

@&#EXPERIMENTAL RESULTS@&#

An initial test was made with two pathologists with at least ten years of professional experience. They were requested to diagnose the 20 WSIs, using a custom GUI design with a list of the available WSI. Overall, pathologists are not familiar with computer, so for avoiding any navigation bias because of an inappropriate use of the GUI, before the first navigation, each pathologist was instructed about this interface with a test image. Each of the navigation operations were then previously assessed by them, the different zooms, the resizing operations, the spatial jumps and the quality improvement. When they picked a particular WSI, the application displayed two windows: the exploration and guide views. The guide view resulted very useful since it facilitated a preliminar diagnosis that drove the navigation. This view may be hidden, if needed, to increase the exploration area. Pathologists performed different exploration paths, identifying relevant regions and diagnosing them, by using different gestures, namely taps, drags, pinches and stretches.

At the end of the navigations, the pathologists reported a pleasant interaction experience, they agreed for all the cases and they concluded that the application might then be suitable to perform diagnosis tasks. In average, the experts spent about 1min per WSI and 3.6s per examined region. During the first 10 navigation steps, the average response time remained below the 800ms (Fig. 7
                           (a)) and the system memory consumption remained below the 38MB, only a 3.7% of the testing mobile device capacity (Fig. 7(b)). Finally, expert’s requests were recorded to perform the concurrency tests and to compare the proposed model performance with the baseline (JPEG and JPEG-LS). In such tests, variables such as size of the representations, transmission, decoding and memory usage were measured. Results are shown in the following sections.

The WSIs were JPEG2000 encoded and their average file size, including indexes, was 151.9MB. Likewise, after construction of the JPEG and JPEG-LS pyramidal structures, an average of 12,850 files were generated per image, resulting from splitting the image into different blocks, each coded in 5 resolutions and 10 quality layers. The JPEG pyramidal construction had a final average size of 532MB, while the JPEG-LS structure, a final average size of 1.514GB (Fig. 8
                           ). Intergroup comparison under a one-way analysis of variance (ANOVA) showed significant differences (
                              
                                 p
                                 <
                                 0.05
                              
                           ) and pair-wise post hoc test (Bonferroni) indicating that these differences could be attributed to differences between JPEG2000 and the other formats. It should be strengthen out that while JPEG2000 data organization allows progressive reconstruction by size, resolution and quality refinement as long as more data are received, the pyramidal representation for JPEG and JPEG-LS requires storage and transmission of redundant data.

Latency was estimated by means of the data size and the bandwidth, measuring the transmitted bytes per request. Fig. 10(a) shows these results for the WSI with the largest number of requests. The ANOVA test showed no significant differences among the means of the three formats (
                              
                                 p
                                 <
                                 0.05
                              
                           ) and the pair-wise post hoc test (Bonferroni) indicated that these differences may be attributed to differences between JPEG2000 and the other formats. When quality refinements and magnifications were required (requests 9–14), it can be seen that JPEG-LS is highly demanding.


                           Fig. 10(b) presents the decoding time for each of the requested regions during a navigation. In this case, the ANOVA indicates significant differences (
                              
                                 p
                                 <
                                 0.05
                              
                           ) and the post hoc Bonferroni test showed insignificant difference between JPEG y JPEG-LS. Results show that these times were larger for the JPEG2000 approach. Nevertheless, it is important to keep in mind that this experiment in particular was performed using the JasPer library [36]. In contrast, the decoding times for the previous navigation path using Kakadu library [35] were about one third, a figure that could even decrease more with the Intel IPP based JPEG2000 library (
                              
                                 ×
                                 10
                              
                            more rapid) [37] or the last Kakadu release (version 7.3.3) that includes a “speed pack” that speeds up to 40% or 50% the decoding process [35]. Hence, the use of more efficient or hardware-based decoders might improve the decoding times.

The effect of the WSI size on the speed and efficiency of the system was assessed by including 3 new WSI images with compressed sizes of 3.89GB, 2.6GB and 1.3GB and whose raw sizes were 12.5GB, 9GB and 4GB, respectively. This experiment consisted in measuring the response times of requesting the image dimensions and the main header from the index file by the respective web services. Likewise, three different requests were also measured, namely, a 
                              
                                 256
                                 ×
                                 256
                              
                            spatial, panning and zoom-in queries. Results, shown in Fig. 9
                           , demonstrate that in spite of the large size differences in the set of images, the response times are quite similar, not exceeding the 120ms, i.e., the WSI size has a moderate impact on the system performance.


                           Fig. 10
                           (c) presents the use of memory for the three assessed strategies, recording the quantity of used memory in Megabytes each second during the navigation. The ANOVA indicated significant differences (
                              
                                 p
                                 =
                                 0.002
                              
                           ) while the post hoc Bonferroni test showed no significant difference between JPEG2000 and the other formats. These results show that both strategies, JPEG and JPEG-LS, present a higher memory consumption that rapidly increases during the navigation. As long as the navigation lasts, more complex variable requests must be met, namely overlapped regions, magnifications or quality refinements, making the device memory to fill quickly. It is worthy to mention that during experimentation, consecutive execution of different navigation protocols using the JPEG and JPEG-LS approaches caused memory overflows.

The access times were measured for several concurrent clients, using a client desktop device that randomly executed the diagnostic paths previously recorded. Each of these observation paths is composed of a set of requests, for which the application recorded the time spanned between a particular request and the data display.


                           Fig. 11
                            presents the results for interaction of multiple concurrent users. Subfigure (a) presents the results with five simultaneous clients requesting data to the server, not exceeding the 280ms. In subfigure (b), ten simultaneous clients did not go beyond the 300ms. Finally, Subfigure (c) shows the results of twenty simultaneous clients remaining below the 600ms. For the first experiment (5 simultaneous clients), significant differences were not demonstrated under an ANOVA analysis (
                              
                                 p
                                 >
                                 0.05
                              
                           ). However, the ANOVA for the other two experiments showed significant differences (
                              
                                 p
                                 <
                                 0.05
                              
                           ). In general terms, the system presented response times under half a second even if a basic server was used (4GB RAM memory and 2.4GHz quad core processor) and the system was overloaded with a large number of concurrent users. Of course, much more powerful servers may attend a larger number of users.

@&#DISCUSSION@&#

This work has presented a system fully integrated with an actual VM workflow that easily adapts to the device capacity and the expert interaction needs. This is achieved by means of three key elements. A smart decoding strategy, a flexible data management and an architecture devised to adapt the navigation to the device resources and the network bandwidth, while it maintains the granular data representation of the JPEG2000 standard.

Dynamic interaction with WSIs is a very complex and challenging task due to their large sizes, on the order of Gigabytes [1]. Currently, the most common visualization state-of-the-art strategy consists in constructing a pyramidal structure composed of different magnifications of the same WSI. Each of these WSI enlargements is then split into small tiles that facilitate access to specific information and each tile is stored in a separate file, while each level of the pyramid (magnification) is stored in a separate folder. This artificial granularity enables applications to fetch only the required tiles, instead of downloading the entire image. However such pyramids present important limitations and disadvantages, i.e., construction, management and uploading of thousand of files that result heavy, wasteful and cumbersome to manage [10]. Furthermore, neither the client cache management nor the communication channel are efficiently administered, for instance operations such as zoom and quality refinement end up by transmitting redundant data and by rapidly overflowing the system memory, as herein demonstrated. In addition, some applications that use these approaches are computationally very demanding, requiring a powerful and expensive infrastructure. During some experiments of the present investigation, the pathologists assessed the v10 stand alone version of Aperio [11] and found out that such application allows interaction with three WSI, but ten of them blocked a standard computer (2.8GHz quad-core processor and 5GB RAM memory). Therefore, at least with this version, it would be complicated to serve a large number of concurrent pathologists. Other disadvantage of these pyramidal approaches is related to the particular image formats, most of them use lossy compression formats such as JPEG, an actual issue in medical applications, i.e., Physicians hardly have accepted a compression rate of 2:1 [23]. Other lossless formats, such as BMP or JPEG-LS, are not suitable because of their high storage and transmission costs, as illustrated by the set of experiments herein presented. Unlike these approaches, the system herein introduced takes advantage of the multiresolution nature of the JPEG2000 standard and easily deals with many requests using a single structure. Although JPEG2000 has many advantages regarding data management, the decoding time is longer than other standards and the actual access to the content can be slow [23]. Furthermore, the J2K decoder implementations are partially granular, complicating a selective RoI decoding at the client side. Different approaches have attempted to improve the degree of granularity. On the one hand, some works [20,21,7] have developed solutions with a lazy client, that is to say, the client just receives the decoded data to be displayed, but these approaches may increase the server loading when attending several clients. On the other hand, some approaches [23–25] have opted for tightly-coupled decoder adaptations that enable decoding of specific RoIs, but these solutions can hardly evolve. Other approach [17] aimed to optimally use the channel bandwidth by sending the specific packets of a particular request, while the untransmitted codestream positions were completed with predefined data, but at the price of demanding important processing resources at the client side when processing large datastreams. In contrast, the proposed system achieves an adaptable and selective decompression at the client side, exploits the potential of the available devices, allows the smart use of advanced cache models and lightens the server loading. Regarding mobile applications, some works have explored interaction with WSIs, concluding that a successful interpretation is feasible from such devices [38,39]. Nevertheless, some of these applications are just viewers that connect to VM pyramidal systems such as Zoomify or Aperio, inheriting some of the previously mentioned limitations. A mobile tele-radiology imaging system using JPEG2000 was proposed by Kim et al. [40], using low resolution and lossy versions of tomography images. Nonetheless, the authors conclude that the size of mobile devices was not functional because the magnification and details needed for diagnosis require zooming, RoI selection and high quality, characteristics that were not therein offered. On the contrary, the proposed approach achieves a selective lossless RoI visualization on the mobile device and accomplishes random spatial access of RoIs at any magnification and quality.

Different strategies have been proposed to improve interaction with large images. Some have explored JPEG2000 as an interaction tool, speeding up the navigation by implementing cache and prefetching techniques [41,23,25]. In this work, a simple and loosely coupled cache technique avoided redundant transmission. Interaction can also be enhanced by selectively compressing the more relevant areas with lossless quality and the rest of the image [42] with some loses. Different works have adapted and implemented wavelet-based [43,44] and JPEG2000 approaches [42,45] to ease the access to specific image areas. In the proposed approach the entire WSI was assumed to be relevant and a free lossless navigation was so possible. In this case, the granular RoI was dynamically constructed in real time, i.e., while the user was interacting with the WSI and not during compression. However, some studies have shown that a pathologist need not explore the entire slide, but instead she/he focuses her/his analysis on a few number of visual fields [46,47]. Recognition of such relevant regions may be a potential source of knowledge for diagnostic tasks, medical training and reduction of computational and transmission costs. Integration of the proposed technique with RoI coding approaches might also be very useful.

Yet the discussed elements strengthen out the proposed approach, the presented system shows some limitations. The main issue is related to the fact that few web applications offer support for the JPEG2000 format, and then external decoders are required. This weakness was herein mitigated by uncoupling the system from the particular decoder and constructing general plug-ins or interfaces that communicate with any decoding standard implementation. Another important limitation is the time for decoding, larger for the proposed approach when compared with the state-of-the-art JPEG pyramidal approach, but still appropriate in terms of a seamless navigation experience. In fact, the authors conducted a short usability evaluation, consisting in 4 questions for the two pathologist that assessed the system: From 1 to 5, what was their opinion about the user friendliness, relevance, response times and functionality. Results showed scores of 4.8, 4.8, 4 and 3.8 for each of the respective items. Pathologists pointed out that this prototype was very friendly and very useful for academic and clinic environments. Regarding the User Interface and functionality, this was considered as basic since it just displays a RoI at a time, and some extra functions should be added, for instance, interaction with the thumbnail, diagonal panning and zoom in based on a selected point. Likewise, they agree about the response times were appropriated but some work is still required to improve the transition between frames. Finally, yet only two pathologists were part of the evaluation, these experiments conclude a proper performance of the proposed architecture. Future work includes to enhance the GUI design and to perform a deeper usability test and to release stable prototype of the system.

@&#ACKNOWLEDGMENTS@&#

The authors are indebted with the Departament of Pathology of the Universidad Nacional de Colombia, in particular Viviana Arias, Lucía Roa, Jinneth Acosta and Yobany Sánchez, who supplied the slides, provided advising and helped to perform the experiments. This work was developed in the framework of a cooperation work between the Medicine School from Universidad Nacional de Colombia and the Universidad Militar Nueva Granada (UMNG), in particular from the projects ING-986 and ING-729, granted by the Research Vice-Rectory of the UMNG, validity period 2012.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Inferring robust decision models in multicriteria classification problems: An experimental analysis

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We examine the robustness of inferring multicriteria classification models.


                        
                        
                           
                           Analysis of the relationship between robustness and the quality of the models.


                        
                        
                           
                           Introduction of a new model inference procedure based on the Chebyshev center.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multiple criteria analysis

Robustness

Disaggregation analysis

Monte Carlo simulation

@&#ABSTRACT@&#


               
               
                  Recent research on robust decision aiding has focused on identifying a range of recommendations from preferential information and the selection of representative models compatible with preferential constraints. This study presents an experimental analysis on the relationship between the results of a single decision model (additive value function) and the ones from the full set of compatible models in classification problems. Different optimization formulations for selecting a representative model are tested on artificially generated data sets with varying characteristics.
               
            

@&#INTRODUCTION@&#

The elicitation, modeling, and representation of preferential information are crucial steps in providing decision-makers (DMs) with sound decision analysis and aiding tools. Multiple criteria decision aid (MCDA) provides a wide arsenal of techniques and approaches to address such issues in the context of decision problems involving multiple (conflicting) criteria. Among others, MCDA techniques employ information on the preferential system of the DM to build criteria aggregation models for evaluating a set of alternative ways of action.

Information on the DM’s preferential system and judgment policy can be obtained either directly or indirectly. In this paper we concentrate on the latter approach, referred to as “preference disaggregation analysis” (PDA, Jacquet-Lagrèze & Siskos, 2001). The disaggregation framework does not require the DM to provide the analyst with specific details on the parameters that define the criteria aggregation model. Instead, the model building process is based on the analysis of a small set of representative decision instances (reference set), using non-parametric regression techniques.

The quality of models resulting from disaggregation techniques depends not only on the information embodied in the sample of decision instances but also on the properties of the model fitting process. In this context, the issue of robustness has recently received much attention (Roy, 2010). The research in the area of building robust multicriteria decision models and obtaining robust recommendations with disaggregation techniques has adopted two main approaches. The first is based on the use of analytic methodologies for: (a) formulating preference relations and recommendations based on characterizations of the range of decision models compatible with the DM’s judgments on the reference set (Greco, Mousseau, & Słowiński, 2010; Kadziński, Greco, & Słowiński, 2012) and (b) building robust decision models that best represent the information embodied in the reference data (Bous, Fortemps, Glineur, & Pirlot, 2010; Doumpos & Zopounidis, 2007; Greco, Kadziński, & Słowiński, 2011). The second line of research has focused on using simulation techniques to sample different decision models compatible with the DM’s preferences in order to form robust recommendations (Kadziński & Tervonen, 2013), thus enriching analytic procedures with a more detailed/explicit view of the outputs that can be obtained from the universe of compatible models.


                     Vetschera, Chen, Hipel, and Kilgour (2010) conducted an experimental investigation of the robustness of the information embodied in a reference set in the context of multicriteria classification problems. In this study we extend this analysis by focusing on the robustness and performance of representative decision models fitted on a set of reference alternatives using different optimization formulations. Using a good decision model that best represents the information provided by the DM on the reference data and provides robust results is of major importance in the context of decision aiding. Having an analytic or simulation-based characterization of all compatible models provides the DM with a comprehensive view of the range of possible recommendations that can be formed. On the other hand, a single representative model is easier to use as it only requires the DM to “plug-in” the data for any alternative into a functional, relational, or symbolic model. Furthermore, the aggregation of all evaluation criteria in a single decision model enables the DM to get insight into the role of the criteria and their effect on the recommendations formulated through the model (Greco et al., 2011).

Traditional disaggregation techniques such as the family of the UTA methods (Siskos, Grigoroudis, & Matsatsinis, 2005) use post-optimality techniques based on linear programming in order to build a representative additive value function (AVF) defined as an average solution of some characteristic models compatible with the DM’s judgments. Recently, a number of other approaches have been proposed. For example, Greco et al. (2011) proposed a procedure (which implements max–min optimization models) for building a representative AVF that provides recommendations on possible assignments corresponding to the most stable results of a robust ordinal regression analysis. The proposed procedure is iterative allowing the DM to specify (interactively) at each iteration different targets that a representative model should achieve. Similar processes can also be used for the construction of representative AVFs in a group decision making context (Kadziński, Greco, & Słowiński, 2013). Kadziński and Tervonen (2013) extended this approach through its combination with a simulation process, which enhances the results of robust ordinal regression with assessments on the acceptability (i.e., confidence) of the assignments and proposed an optimization model to construct a model that best represents the simulation results. Instead of interactive and iterative model building procedures, other studies have focused on the introduction of optimization formulations based on new model fitting criteria. For instance, Doumpos and Zopounidis (2007) proposed a formulation based on the regularization principle of statistical learning, whereas Bous et al. (2010) presented a model based on the concept of the analytic center.

In this study we analyze such approaches (also introducing a new linear programming model) in order to examine the way in which their results represent the information provided by the DM’s reference judgments and their relationship with the robust recommendations that can be formulated on the basis of this information. Among others, the objectives of the analysis include the investigation of: (a) the association between robustness and the selection of representative decision models defined by parameters that lie near the “center” of the set that consists of all models compatible with the DM’s preferences, (b) the connection between the complexity of a decision model and its robustness and accuracy, and (c) the ability of different model inference procedures to cope with models of increasing complexity and the impact that the characteristics of the data have on the robustness of the inference process. The analysis is based on simulated data generated with different characteristics, in the context of multicriteria classification problems, which have recently received much attention among MCDA researchers (Zopounidis & Doumpos, 2002). We focus on decision models expressed in the form of linear and piecewise AVFs, which are widely used in MCDA. The results of the analysis contribute in improving the understanding of the features of disaggregation approaches that aim towards identifying representative decision models, as well as clarifying the relationship between the results of such approaches with the concept of robustness in decision aid.

The rest of the paper is organized as follows. Section 2 presents different optimization-based approaches for constructing AVFs in classification problems that best represent the set of models compatible with the DM’s judgments on some decision examples. Section 3 discusses the experimental setting used for the comparison of the selected approaches, whereas Section 4 presents and analyzes the obtained results. Finally, Section 5 concludes the paper and outlines some future research directions.

AVFs constitute a simple and easy to use modeling approach to decision aiding problems. They are based on a sound theoretical framework (multiattribute value theory), and despite their reliance on specific preferential independence conditions (Keeney & Raiffa, 1993), they are widely used in decision aiding and modeling.

Assuming that K criteria are used in a multicriteria evaluation context, an AVF introduces a criteria aggregation model, under which the global value (performance) of an alternative i is obtained as follows:
                           
                              (1)
                              
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       w
                                    
                                    
                                       k
                                    
                                 
                                 
                                    
                                       v
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       ik
                                    
                                 
                                 )
                              
                           
                        where 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              =
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                    1
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    i
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    iK
                                 
                              
                              )
                           
                         is the vector with the data for alternative i on the evaluation criteria, 
                           
                              
                                 
                                    w
                                 
                                 
                                    k
                                 
                              
                              ⩾
                              0
                           
                         is the trade-off coefficient for criterion k (the normalization 
                           
                              
                                 
                                    w
                                 
                                 
                                    1
                                 
                              
                              +
                              
                                 
                                    w
                                 
                                 
                                    2
                                 
                              
                              +
                              …
                              +
                              
                                 
                                    w
                                 
                                 
                                    K
                                 
                              
                              =
                              1
                           
                         is often used) and 
                           
                              
                                 
                                    v
                                 
                                 
                                    k
                                 
                              
                              (
                              ·
                              )
                           
                         is the marginal value function of criterion k. The marginal value functions define the partial performance of the alternative on each criterion, usually in a scale between 0 and 1.

Under the decision model (1) an alternative i is preferred over an alternative j if and only if 
                           
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                              >
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              )
                           
                        , whereas the alternatives are indifferent if 
                           
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              )
                           
                        . In a multicriteria classification setting, each alternative should be classified in a set of N pre-defined categories 
                           
                              {
                              
                                 
                                    C
                                 
                                 
                                    1
                                 
                              
                              ,
                              …
                              
                                 
                                    C
                                 
                                 
                                    N
                                 
                              
                              }
                           
                         ordered such that category 
                           
                              
                                 
                                    C
                                 
                                 
                                    1
                                 
                              
                           
                         includes the best alternatives and category 
                           
                              
                                 
                                    C
                                 
                                 
                                    N
                                 
                              
                           
                         the worst ones. An AVF model can be easily used to classify any alternative i as follows:
                           
                              (2)
                              
                                 
                                    
                                       t
                                    
                                    
                                       ℓ
                                    
                                 
                                 <
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 <
                                 
                                    
                                       t
                                    
                                    
                                       ℓ
                                       -
                                       1
                                    
                                 
                                 ⇔
                                 Alternative
                                 
                                 i
                                 
                                 belongs to class
                                 
                                 
                                    
                                       C
                                    
                                    
                                       ℓ
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    t
                                 
                                 
                                    0
                                 
                              
                              =
                              1
                              >
                              
                                 
                                    t
                                 
                                 
                                    1
                                 
                              
                              >
                              
                                 
                                    t
                                 
                                 
                                    2
                                 
                              
                              ⋯
                              >
                              
                                 
                                    t
                                 
                                 
                                    N
                                    -
                                    1
                                 
                              
                              >
                              
                                 
                                    t
                                 
                                 
                                    N
                                 
                              
                              =
                              0
                           
                         is a set of thresholds that distinguish the categories. Cases where 
                           
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              
                                 
                                    t
                                 
                                 
                                    ℓ
                                 
                              
                           
                         clearly lead to some ambiguity in the assignment of alternative i to one of the predefined categories (i.e., it can be assigned to 
                           
                              
                                 
                                    C
                                 
                                 
                                    ℓ
                                 
                              
                           
                         or 
                           
                              
                                 
                                    C
                                 
                                 
                                    ℓ
                                    +
                                    1
                                 
                              
                           
                        ). In the context of this study we assume that any test alternative i with 
                           
                              V
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              
                                 
                                    t
                                 
                                 
                                    ℓ
                                 
                              
                           
                         is assigned to category 
                           
                              
                                 
                                    C
                                 
                                 
                                    ℓ
                                 
                              
                           
                        .

The construction of the AVF can be simplified by setting 
                           
                              
                                 
                                    u
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    k
                                 
                              
                              )
                              =
                              
                                 
                                    w
                                 
                                 
                                    k
                                 
                              
                              
                                 
                                    v
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    k
                                 
                              
                              )
                           
                        , which leads to a rescaled set of marginal value functions 
                           
                              
                                 
                                    u
                                 
                                 
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    u
                                 
                                 
                                    K
                                 
                              
                           
                         normalized in 
                           
                              [
                              0
                              ,
                              
                                 
                                    w
                                 
                                 
                                    k
                                 
                              
                              ]
                           
                        . With this transformation, the AVF model (1) is expressed in the following equivalent form:
                           
                              (3)
                              
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       u
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       ik
                                    
                                 
                                 )
                              
                           
                        
                     

The AVF model can be linear or nonlinear depending on the form of the marginal value functions. A convenient and flexible way to take into consideration a wide class of monotone marginal value functions, is to assume that they are piecewise linear. Under this scheme the scale of each criterion k is split into 
                           
                              
                                 
                                    s
                                 
                                 
                                    k
                                 
                              
                              +
                              1
                           
                         subintervals defined by 
                           
                              
                                 
                                    s
                                 
                                 
                                    k
                                 
                              
                           
                         break-points 
                           
                              
                                 
                                    β
                                 
                                 
                                    0
                                 
                                 
                                    k
                                 
                              
                              <
                              
                                 
                                    β
                                 
                                 
                                    1
                                 
                                 
                                    k
                                 
                              
                              <
                              ⋯
                              <
                              
                                 
                                    β
                                 
                                 
                                    
                                       
                                          s
                                       
                                       
                                          k
                                       
                                    
                                    +
                                    1
                                 
                                 
                                    k
                                 
                              
                           
                        , between the least and the most preferred levels of the criterion (denoted by 
                           
                              
                                 
                                    β
                                 
                                 
                                    0
                                 
                                 
                                    k
                                 
                              
                           
                         and 
                           
                              
                                 
                                    β
                                 
                                 
                                    
                                       
                                          s
                                       
                                       
                                          k
                                       
                                    
                                    +
                                    1
                                 
                                 
                                    k
                                 
                              
                           
                        , respectively). Thus, the marginal value of any alternative i on criterion k can be expressed as:
                           
                              (4)
                              
                                 
                                    
                                       u
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       ik
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          r
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                s
                                             
                                             
                                                k
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       p
                                    
                                    
                                       ik
                                    
                                    
                                       r
                                    
                                 
                                 
                                    
                                       d
                                    
                                    
                                       kr
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    d
                                 
                                 
                                    kr
                                 
                              
                              =
                              
                                 
                                    u
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    β
                                 
                                 
                                    r
                                 
                                 
                                    k
                                 
                              
                              )
                              -
                              
                                 
                                    u
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    β
                                 
                                 
                                    r
                                    -
                                    1
                                 
                                 
                                    k
                                 
                              
                              )
                              ⩾
                              0
                           
                         is the difference between the marginal values at two consecutive break-points of criterion k and
                           
                              (5)
                              
                                 
                                    
                                       p
                                    
                                    
                                       ik
                                    
                                    
                                       r
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         ik
                                                      
                                                   
                                                   <
                                                   
                                                      
                                                         β
                                                      
                                                      
                                                         r
                                                         -
                                                         1
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ik
                                                            
                                                         
                                                         -
                                                         
                                                            
                                                               β
                                                            
                                                            
                                                               r
                                                               -
                                                               1
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               β
                                                            
                                                            
                                                               r
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                         -
                                                         
                                                            
                                                               β
                                                            
                                                            
                                                               r
                                                               -
                                                               1
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         ik
                                                      
                                                   
                                                   ∈
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  β
                                                               
                                                               
                                                                  r
                                                                  -
                                                                  1
                                                               
                                                               
                                                                  k
                                                               
                                                            
                                                            ,
                                                            
                                                               
                                                                  β
                                                               
                                                               
                                                                  r
                                                               
                                                               
                                                                  k
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         ik
                                                      
                                                   
                                                   >
                                                   
                                                      
                                                         β
                                                      
                                                      
                                                         r
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Therefore, the AVF (3) can be expressed as a linear function of the step differences in the marginal values between consecutive break-points in the criteria’s scale:
                           
                              (6)
                              
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       p
                                    
                                    
                                       ik
                                    
                                    
                                       ⊤
                                    
                                 
                                 
                                    
                                       d
                                    
                                    
                                       k
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    p
                                 
                                 
                                    ik
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             ik
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             p
                                          
                                          
                                             ik
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             p
                                          
                                          
                                             ik
                                          
                                          
                                             
                                                
                                                   s
                                                
                                                
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 
                                    d
                                 
                                 
                                    k
                                 
                              
                              =
                              (
                              
                                 
                                    d
                                 
                                 
                                    k
                                    1
                                 
                              
                              ,
                              
                                 
                                    d
                                 
                                 
                                    k
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    d
                                 
                                 
                                    
                                       
                                          ks
                                       
                                       
                                          k
                                       
                                    
                                 
                              
                              )
                           
                        .

In a preference disaggregation framework for classification problems, the DM provides a reference set consisting of decision examples for M alternatives. The reference alternatives are classified into the pre-defined categories, and the objective is to infer the parameters of the AVF model (i.e., the vectors 
                           
                              
                                 
                                    d
                                 
                                 
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    d
                                 
                                 
                                    K
                                 
                              
                           
                         and the classification thresholds) that are consistent with the classification of the alternatives. Thus, the inferred model of the form (6) should satisfy the following set of linear constraints:
                           
                              (7)
                              
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ⩾
                                 
                                    
                                       t
                                    
                                    
                                       ℓ
                                    
                                 
                                 +
                                 δ
                                 
                                 ∀
                                 
                                 alternative
                                 
                                 i
                                 
                                 from category
                                 
                                 
                                    
                                       C
                                    
                                    
                                       ℓ
                                    
                                 
                                 
                                 (
                                 1
                                 ⩽
                                 ℓ
                                 ⩽
                                 N
                                 -
                                 1
                                 )
                              
                           
                        
                        
                           
                              (8)
                              
                                 V
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ⩽
                                 
                                    
                                       t
                                    
                                    
                                       ℓ
                                       -
                                       1
                                    
                                 
                                 -
                                 δ
                                 
                                 ∀
                                 
                                 alternative
                                 
                                 i
                                 
                                 from category
                                 
                                 
                                    
                                       C
                                    
                                    
                                       ℓ
                                    
                                 
                                 
                                 (
                                 2
                                 ⩽
                                 ℓ
                                 ⩽
                                 N
                                 )
                              
                           
                        
                        
                           
                              (9)
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       1
                                    
                                    
                                       ⊤
                                    
                                 
                                 
                                    
                                       d
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 1
                              
                           
                        
                        
                           
                              (10)
                              
                                 
                                    
                                       d
                                    
                                    
                                       k
                                    
                                 
                                 ⩾
                                 0
                                 
                                 k
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 K
                              
                           
                        where 
                           
                              1
                              =
                              (
                              1
                              ,
                              1
                              ,
                              …
                              ,
                              1
                              )
                           
                         is a vector of ones. Constraints (7) and (8) ensure that the model is consistent with the classification of the reference alternatives on the basis of the classification rule (2). In these constraints 
                           
                              δ
                           
                         is a small positive constant used to avoid arbitrary results that arise when the global value of an alternative equals a classification threshold. Constraint (9) normalizes the AVF such that an ideal alternative (i.e., with the most preferred levels in each criterion) receives a global value equal to one, whereas the non-negative constraints (10) on the parameters of the AVF model ensure that the marginal value functions are non-decreasing (assuming that all criteria are expressed in maximization form).

If the DM’s classifications of the reference alternatives are consistent with an AVF evaluation model, then the polyhedron defined from the above constraints will be non-empty, thus implying that there is an infinite number of alternative AVFs (each corresponding to a feasible solution) consistent with the DM’s judgments of the reference set. This raises the issue of how can a single representative AVF be chosen from the set of feasible solutions of the above constraints. This issue is even relevant when inconsistencies exist in the decision examples of the reference set, as these inconsistencies can be resolved (algorithmically or interactively with the DM; Mousseau, Figueira, Dias, Gomes da Silva, & Clímaco, 2003), thus making the robustness concern still relevant in this case too.

In the following subsections we present the alternative approaches considered in this study for selecting a single AVF representing the DM’s classifications of the reference alternatives. The selected approaches, include: (a) a post-optimality procedure that was the first to be introduced in order to explore some characteristic feasible solutions to the polyhedron (7)–(10) and obtain a “central” decision model, (b) a max–min formulation that has been used in several studies in a robust PDA context, (c) a recently proposed analytic center formulation that operationalizes the “centrality” concept in a more rigorous manner (compared to ad hoc post-optimality procedures), and (d) a new model based on the concept of the Chebyshev center of a polyhedron, which can be identified with a linear programming formulation.

To cope with the existence of multiple decision models compatible with the DM’s evaluations of the reference alternatives, Jacquet-Lagrèze and Siskos (1982) introduced a heuristic post-optimality procedure, which involves the solution of K pairs of linear programs, corresponding to the maximization and the minimization of the trade-off constant for each criterion k, i.e.:
                           
                              (11)
                              
                                 
                                    max
                                 
                                 /
                                 
                                    min
                                 
                                 
                                 
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                ⊤
                                             
                                          
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          |
                                          s.t.
                                          :
                                          
                                          
                                             (7)–(10)
                                          
                                       
                                    
                                 
                              
                           
                        The 
                           
                              2
                              K
                           
                         solutions obtained from this post-optimality process are some characteristic extreme solutions of (7)–(10), and their average can be used to form a “representative” AVF model as an approximation of the polyhedron’s centroid solution. Such a centroid solution can be considered as representative of the feasible polyhedron of compatible models as it is less likely to be affected by changes in the DM’s judgments on the reference alternatives (i.e., thus being more robust).

Max–min optimization formulations are often used in PDA in order to infer the parameters of decision models from assignment examples. For instance, in the context of multicriteria classification problems, such formulations have been used by Zopounidis and Doumpos (2000) in the MHDIS method, Dias, Mousseau, Figueira, and Clímaco (2002) in the ELECTRE method, whereas Greco et al. (2011) used max–min formulations to infer a representative value function in robust multiple criteria classification procedure. Similar models, in the context of ranking problems where also considered by Beuthe and Scannella (2001).

In the PDA setting considered in this study, a max–min formulation to infer a model compatible with the DM’s judgments on a set of reference decision instance can be expressed as follows:
                           
                              (12)
                              
                                 
                                    max
                                 
                                 
                                    
                                       
                                          δ
                                          
                                          |
                                          s.t.:
                                          
                                          
                                             (7)–(10)
                                          
                                       
                                    
                                 
                              
                           
                        
                     

This formulation seeks to maximize the minimum separating gap between two consecutive classes. Bous et al. (2010) note that such a formulation shrinks the original polyhedron, thus forming a more “central” set and yielding solutions that are away from the boundaries of the original polyhedron (i.e., the obtained decision model satisfies the DM’s preferences in a clearer and more robust manner).

The above max–min approach can also be explained on the grounds of the regularization principle, which is a popular approach in statistical and machine learning for improving the robustness of prediction models with respect to changes in the reference set (Hastie, Tibshirani, & Friedman, 2001). Based on this approach, Doumpos and Zopounidis (2007) introduced a formulation, which in the case of a consistent reference set, can be expressed as follows (a regularization approach to construct an additive preference model in the context of the dominance-based rough set approach has also been presented by Dembczyński, Kotłowski, & Słowiński (2006)):
                           
                              (13)
                              
                                 
                                    min
                                 
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   K
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                ⊤
                                             
                                          
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          
                                          |
                                          s.t.
                                          :
                                          
                                          
                                             (7), (8), (10)
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The main feature of the model is that the normalization constraint (9) is no longer taken into consideration. Instead, the AVF model is normalized after the solution of the above problem is obtained. In particular, denoting by 
                           
                              
                                 
                                    F
                                 
                                 
                                    ∗
                                 
                              
                           
                         the optimal objective function value of (13), the normalized AVF model is simply obtained by dividing the optimal solution of (13) with 
                           
                              
                                 
                                    F
                                 
                                 
                                    ∗
                                 
                              
                           
                         (Doumpos & Zopounidis, 2007 described the conditions under which it is possible to have 
                           
                              
                                 
                                    F
                                 
                                 
                                    ∗
                                 
                              
                              =
                              0
                           
                        ; nevertheless, this is not possible when the reference set is consistent). The following theorem shows the connection between formulations (12) and (13).
                           Theorem 1
                           
                              The solutions of problems 
                              
                                 (12)
                               
                              and 
                              
                                 (13)
                               
                              are equivalent.
                           

Suppose that (13) is solved for some user-defined 
                                 
                                    δ
                                    =
                                    
                                       
                                          δ
                                       
                                       
                                          0
                                       
                                    
                                    >
                                    0
                                 
                               and let 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          ∗
                                       
                                    
                                    >
                                    0
                                 
                               be the optimal objective function value. The optimal solution of (13) normalized with the procedure described above, is feasible to (12) and yields an objective function value for (12) equal to 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          0
                                       
                                    
                                    /
                                    
                                       
                                          F
                                       
                                       
                                          ∗
                                       
                                    
                                 
                              . If there was a solution to (12) with 
                                 
                                    δ
                                    >
                                    
                                       
                                          δ
                                       
                                       
                                          0
                                       
                                    
                                    /
                                    
                                       
                                          F
                                       
                                       
                                          ∗
                                       
                                    
                                 
                              , then rescaling it (i.e., multiplying) by 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          0
                                       
                                    
                                    /
                                    δ
                                 
                               leads to a feasible solution for (13) with objective function value 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          0
                                       
                                    
                                    /
                                    δ
                                    <
                                    
                                       
                                          F
                                       
                                       
                                          ∗
                                       
                                    
                                 
                              , which contradicts the initial hypothesis that 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          ∗
                                       
                                    
                                 
                               is the minimum value for the objective function of problem (13).

Similarly, suppose that (12) is solved and let 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          ∗
                                       
                                    
                                    >
                                    0
                                 
                               denote its optimal objective function value. This solution is feasible to (13) for 
                                 
                                    δ
                                    =
                                    
                                       
                                          δ
                                       
                                       
                                          ∗
                                       
                                    
                                 
                               and the corresponding objective function value is equal to one. If there was another solution to (13) with objective function value F such that 
                                 
                                    0
                                    <
                                    F
                                    <
                                    1
                                 
                              , then dividing it by F leads to a solution that is feasible to (12) with objective function value 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          ∗
                                       
                                    
                                    /
                                    F
                                    >
                                    
                                       
                                          δ
                                       
                                       
                                          ∗
                                       
                                    
                                 
                              , which contradicts the initial hypothesis that 
                                 
                                    
                                       
                                          δ
                                       
                                       
                                          ∗
                                       
                                    
                                 
                               is the maximum objective function value for problem (12).

Thus, the optimal solutions of the two problems only differ by a scaling factor. In that regard they are equivalent. □

The third modeling approach used in this study is based on the analytic center formulation introduced by Bous et al. (2010). The analytic center of a polyhedron is defined by a feasible solution that maximizes the logarithmic barrier function of the constraints’ slacks. In the context of this study we adapt the optimization model of Bous et al. (2010) to find the analytic center of the polyhendron defined by (7)–(10). This is performed through the solution of the following convex nonlinear program, which is easily solvable with existing algorithms (e.g., Newton’s method).
                           
                              (14)
                              
                                 
                                    
                                       
                                          
                                             max
                                          
                                          
                                       
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                
                                                   M
                                                
                                             
                                          
                                          
                                             
                                                
                                                   ln
                                                   
                                                      
                                                         s
                                                      
                                                      
                                                         i
                                                      
                                                      
                                                         +
                                                      
                                                   
                                                   +
                                                   ln
                                                   
                                                      
                                                         s
                                                      
                                                      
                                                         i
                                                      
                                                      
                                                         -
                                                      
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   K
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                ⊤
                                             
                                          
                                          ln
                                          
                                             
                                                y
                                             
                                             
                                                k
                                             
                                          
                                       
                                    
                                    
                                       
                                          subject to
                                          :
                                          
                                       
                                       
                                          V
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                             
                                          
                                          -
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                             
                                                +
                                             
                                          
                                          =
                                          δ
                                          
                                          
                                          ∀
                                          
                                          i
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          1
                                          ⩽
                                          ℓ
                                          ⩽
                                          N
                                          -
                                          1
                                       
                                    
                                    
                                       
                                       
                                          V
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                                -
                                                1
                                             
                                          
                                          +
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                             
                                                -
                                             
                                          
                                          =
                                          -
                                          δ
                                          
                                          ∀
                                          
                                          i
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          2
                                          ⩽
                                          ℓ
                                          ⩽
                                          N
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                k
                                             
                                          
                                          =
                                          0
                                          
                                          
                                          
                                          
                                          k
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          K
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   K
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                ⊤
                                             
                                          
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          =
                                          1
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                             
                                                +
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                             
                                                -
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                y
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          ⩾
                                          0
                                          
                                          ∀
                                          
                                          i
                                          ,
                                          ℓ
                                          ,
                                          k
                                       
                                    
                                 
                              
                           
                        
                     

Compared to the previous approaches, this formulation is based on a more rigorous definition of “centrality” for the resulting decision model. Furthermore, from an optimization perspective the solution to the above problem is unique (Bous et al., 2010), thus minimizing the ambiguity that often arises due to the existence of multiple optimal solutions in linear programming formulations for inferring the parameters of decision models.

The last model that we test in this study is a new variant-extension of model (12). Effectively, (12) constructs an AVF such that the minimum “satisfaction” of the constraints (7) and (8) is maximized (i.e., the minimum separating gap between the categories). However, there is no rigorous association between this optimality objective with the characteristics of the polyhedron (7)–(10) and its robustness. The analytic center model described earlier seeks to address this issue, by focusing on identifying the analytic center of the polyhedron.

Alternatively, it is possible to construct an AVF model from the Chebyshev center of the polyhedron. The Chebyshev center corresponds to a feasible solution from which the largest possible ball of radius r can be inscribed within the polyhedron (Boyd & Vandenberghe, 2004). In this study we employ this approach to find the Chebyshev center of the polyhedron (7)–(10). The following linear programming model is used for this purpose (for details see Boyd & Vandenberghe, 2004):
                           
                              (15)
                              
                                 
                                    
                                       
                                          
                                             max
                                          
                                          
                                       
                                       
                                          r
                                       
                                    
                                    
                                       
                                          subject to
                                          :
                                          
                                       
                                       
                                          V
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                             
                                          
                                          -
                                          
                                             
                                                a
                                             
                                             
                                                i
                                             
                                          
                                          r
                                          ⩾
                                          0
                                          
                                          ∀
                                          
                                          i
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          1
                                          ⩽
                                          ℓ
                                          ⩽
                                          N
                                          -
                                          1
                                       
                                    
                                    
                                       
                                       
                                          V
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                                -
                                                1
                                             
                                          
                                          +
                                          
                                             
                                                b
                                             
                                             
                                                i
                                             
                                          
                                          r
                                          ⩽
                                          0
                                          
                                          ∀
                                          
                                          i
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          2
                                          ⩽
                                          ℓ
                                          ⩽
                                          N
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          -
                                          1
                                          r
                                          ⩾
                                          0
                                          
                                          
                                          
                                          
                                          k
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          K
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   K
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                ⊤
                                             
                                          
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          =
                                          1
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                d
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                          
                                             
                                                t
                                             
                                             
                                                ℓ
                                             
                                          
                                          ,
                                          
                                          r
                                          ⩾
                                          0
                                          
                                          
                                          
                                          ∀
                                          
                                          ℓ
                                          ,
                                          k
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    a
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    b
                                 
                                 
                                    i
                                 
                              
                           
                         are the Euclidean norms of the decision variables’ (the vectors 
                           
                              
                                 
                                    d
                                 
                                 
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    d
                                 
                                 
                                    K
                                 
                              
                           
                         and the classification thresholds) coefficients in each of the constraints (7) and (8), e.g. 
                           
                              
                                 
                                    a
                                 
                                 
                                    i
                                 
                              
                              =
                              ‖
                              (
                              
                                 
                                    p
                                 
                                 
                                    i
                                    1
                                 
                              
                              ,
                              
                                 
                                    p
                                 
                                 
                                    i
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    p
                                 
                                 
                                    iK
                                 
                              
                              ,
                              -
                              1
                              )
                              
                                 
                                    ‖
                                 
                                 
                                    2
                                 
                              
                           
                        .

The models presented in the previous section are tested and compared through a Monte Carlo simulation study based on artificially generated data, adopting an approach similar to the one used by Vetschera et al. (2010).

All data used in the experimental analysis are generated from the multivariate normal distribution with zero mean, unit variance and correlations uniformly distributed in [0,0.2]. Similarly to Vetschera et al. (2010) we take into consideration different settings for the dimensionality of the data, as defined by the number of alternatives in the reference set, the number of criteria and classes, as follows:
                        
                           •
                           Number of classes: 
                                 
                                    N
                                    =
                                    2
                                    ,
                                    3
                                    ,
                                    4
                                 
                              .

Number of reference alternatives per class: 
                                 
                                    M
                                    /
                                    N
                                    =
                                    3
                                    ,
                                    5
                                    ,
                                    10
                                    ,
                                    15
                                 
                              .

Number of criteria: 
                                 
                                    K
                                    =
                                    3
                                    ,
                                    5
                                    ,
                                    7
                                 
                              .

With these specifications, the reference sets used in the analysis involve both low dimensionality and complexity data (e.g., six alternatives from two categories with three criteria), up to larger and more complex ones (up to 60 alternatives in four classes with seven criteria). In all cases, a secondary test sample is also used consisting of 50 alternatives from each category.

For each combination of the above three factors, 100 simulation runs are performed.
                        1
                        As a robustness check, the analysis was repeated with an additional set of 100 simulations. The differences between the two tests were found to be statistically insignificant even at the 10% level according to the Mann–Whitney non-parametric test.
                     
                     
                        1
                      To generate the data in each run, two data pools are first generated, each consisting of 1000 alternatives. The first pool is used to select (at random) the alternatives of the reference set, whereas the test alternatives are drawn from the second pool.

The classification of the alternatives is performed with the following procedure. First, all alternatives in the two data pools are evaluated with a random AVF and their global values (scores) are obtained. Then, appropriate classification thresholds 
                        
                           1
                           >
                           
                              
                                 t
                              
                              
                                 1
                              
                           
                           >
                           
                              
                                 t
                              
                              
                                 2
                              
                           
                           >
                           ⋯
                           >
                           
                              
                                 t
                              
                              
                                 N
                                 -
                                 1
                              
                           
                           >
                           0
                        
                      are specified at predefined percentiles of the global values of the alternatives in the data pool used to formulate the reference set (i.e., the definition of the thresholds is done independently of the data pool from which the test data are derived). In particular, for two-class problems the threshold 
                        
                           
                              
                                 t
                              
                              
                                 1
                              
                           
                        
                      that distinguishes between the two categories is set equal to the median of the global values. For the three-class problems we use the 30% and 70% percentiles to set 
                        
                           
                              
                                 t
                              
                              
                                 2
                              
                           
                        
                      and 
                        
                           
                              
                                 t
                              
                              
                                 1
                              
                           
                        
                     , respectively, whereas for the four-class problems the 20%, 50%, and 80% percentiles are used to define the thresholds 
                        
                           
                              
                                 t
                              
                              
                                 3
                              
                           
                           ,
                           
                           
                              
                                 t
                              
                              
                                 2
                              
                           
                           ,
                           
                           
                              
                                 t
                              
                              
                                 1
                              
                           
                        
                     . Thus, in the multi-class instances, more alternatives are distributed in intermediate categories than the extreme ones, which is a realistic assumption. With these thresholds, all alternatives in the two data pools are assigned to the predefined number of categories. Finally, from each category a random selection is performed to formulate the reference and test sets with the composition (number of alternatives per category) noted above.

For simplicity, it is assumed that the DM’s preferences are compatible with a linear AVF. Thus, a randomly generated linear AVF is used in each run of the simulation experiment to classify the alternatives in the two data sets. It should be noted, however, that employing a linear AVF model is not a restrictive setting, as piecewise linear additive models are also linear with respect to their parameters (i.e., they are expressed in the linear form (6)). Nevertheless, given that, in realistic cases, the actual preferential structure of the DM is not really known, an analyst may decide to employ a more general modeling form (e.g., piecewise linear AVF) than the one implied by the reference data in order to be able to get more general conclusions and gain insights that a simpler model (e.g., linear AVF) may fail to capture. When working with additive value models, this is based on the fact that a piecewise linear AVF completely covers a linear AVF, and consequently whatever result is derived by a linear AVF can also be obtained with a piecewise linear model, while the opposite is generally not true. However, as piecewise linear AVFs have more degrees of freedom, their robust inference from small reference sets is more involved and a poor PDA formulation may fail to provide good results. Thus, the robustness properties of the feasible polyhedron (7)–(10) are not only affected by the characteristics of the reference data, but also by the form of the decision model (e.g., as the AVF model becomes more complex, the polyhedron widens and the choice of a representative solution becomes more challenging). From this perspective, we also consider the inference of piecewise linear AVFs (with three subintervals for all marginal value functions of the criteria) from the reference data described above, in order to analyze how the above issue affects the robustness and quality of the results obtained with different PDA formulations (i.e., how the results of PDA formulations are affected when the set of alternative compatible models becomes larger).

All computational experiments were performed in MATLAB® R2012b using a PC with a quad-core Intel i7-2600K/3.4GHz processor and 16GB of RAM.

@&#RESULTS@&#

In order to investigate the robustness features of the selected formulations, first we analyze the polyhedron induced by the constraints (7)–(10), for each of the artificially generated reference sets. In particular, for each reference set a hit-and-run sampling approach (Kroese, Taimre, & Botev, 2011; Tervonen, van Valkenhoef, Baştürk, & Postmus, 2013) is used to generate 5000 AVFs uniformly distributed in the polyhedron of all AVFs compatible with the classification of the reference alternatives. As previously mentioned, the sampling of compatible AVFs is repeated twice, first with a linear AVF and then with a piecewise linear model.

With each of the 5000 sampled compatible models, two assignment rules are employed to classify the alternatives in the test samples:
                           
                              •
                              
                                 Robust assignment rule: Each alternative i is classified into one of the predefined categories using all sampled AVFs and a class acceptability index (
                                    
                                       
                                          
                                             CAI
                                          
                                          
                                             i
                                             ℓ
                                          
                                       
                                    
                                 ) is calculated as the frequency of the assignment of alternative i in a category 
                                    
                                       
                                          
                                             C
                                          
                                          
                                             ℓ
                                          
                                       
                                    
                                  (Kadziński & Tervonen, 2013; Tervonen, Figueira, Lahdelma, Dias, & Salminen, 2009). Thus, the CAI represents the likelihood that an alternative is classified into a specific category, on the basis of the information provided by the DM’s judgments in the reference set. The aggregate assignment is then defined by the majority rule (i.e., alternative i is assigned to the most likely category with the maximum CAI).
                                    2
                                    Under this majority rule it is possible that the maximum CAI is attained for two or more different classes, which would lead to an ambiguous assignment. Such cases were not observed in the simulation experiment. Nevertheless, avoiding such ambiguous situations can be easily done by using an odd number of models in the majority rule.
                                 
                                 
                                    2
                                 
                              


                                 Centroid assignment rule: The sampled AVFs are averaged to produce a single AVF corresponding to the centroid of the feasible polyhedron. This centroid AVF is then employed to classify the alternatives from the test set.

The robust assignment rule provides a benchmark for analyzing the robustness of the results obtained from the optimization formulations presented in Section 2. In general, the assignments of the robust assignment rule cannot be reproduced (exactly) by a single decision model, as they result from the combination of multiple models. On the other hand, the use of multiple decision models makes it very difficult for the DM to get straightforward insights on how the final recommendations are obtained from the available data. The centroid assignment rule overcomes this shortcoming as it is based on a single AVF constructed by averaging all compatible decision models. The results of the average (centroid) AVF are expected to approximate the robust assignments, but discrepancies between the two averaging procedures may occur.

With the sampled compatible AVFs, the following measures are used to analyze the robustness of the preferential information that the reference data provide:
                           
                              •
                              
                                 Mean class acceptability index (MCAI). As defined above, the class acceptability index 
                                    
                                       
                                          
                                             CAI
                                          
                                          
                                             i
                                             ℓ
                                          
                                       
                                    
                                  indicates the percentage of compatible AVFs that assign alternative i in category 
                                    
                                       
                                          
                                             C
                                          
                                          
                                             ℓ
                                          
                                       
                                    
                                 . The MCAI is then defined by averaging the acceptability indices over all test alternatives, under a particular classification rule (e.g., robust or centroid).
                                    3
                                    
                                       Vetschera et al. (2010) referred to this index as “overall robustness index”.
                                 
                                 
                                    3
                                  In particular, let 
                                    
                                       
                                          
                                             y
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             y
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             y
                                          
                                          
                                             
                                                
                                                   M
                                                
                                                
                                                   test
                                                
                                             
                                          
                                       
                                    
                                  denote the class assignments for 
                                    
                                       
                                          
                                             M
                                          
                                          
                                             test
                                          
                                       
                                    
                                  test alternatives, obtained with a given decision model (i.e., classification rule), such that 
                                    
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       ∈
                                       {
                                       
                                          
                                             C
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             C
                                          
                                          
                                             N
                                          
                                       
                                       }
                                    
                                 , for all 
                                    
                                       i
                                       =
                                       1
                                       ,
                                       2
                                       ,
                                       …
                                       ,
                                       
                                          
                                             M
                                          
                                          
                                             test
                                          
                                       
                                    
                                 . Then, the MCAI is defined as follows:
                                    
                                       
                                          MCAI
                                          =
                                          100
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   
                                                      M
                                                   
                                                   
                                                      test
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                
                                                   
                                                      
                                                         M
                                                      
                                                      
                                                         test
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                CAI
                                             
                                             
                                                
                                                   
                                                      iy
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

A MCAI close to 100 indicates that the assignments obtained with the considered classification rule for the test alternatives are robust as they are verified by all AVFs compatible with the information provided in the reference set. It should be noted that given a set of AVFs sampled uniformly from the feasible polyhedron, the MCAI can be computed for any classification rule (even with a single additive value function), as it only requires the comparison of some specific class assignments (e.g., the ones of a classification model) to the ones of the randomly generated AVFs.


                                 Mean entropy of the assignments obtained from all sample AVFs. While MCAI focuses on a specific assignment of the alternatives, entropy is used to consider the variability (randomness) in the results of all sampled models. In this study we employ the following entropy measure for the classifications of an alternative i by all AVFs:
                                    
                                       
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                          
                                          =
                                          100
                                          
                                             
                                                
                                                   1
                                                   +
                                                   
                                                      
                                                         1
                                                      
                                                      
                                                         ln
                                                         N
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            ℓ
                                                            =
                                                            1
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         CAI
                                                      
                                                      
                                                         i
                                                         ℓ
                                                      
                                                   
                                                   ln
                                                   
                                                      
                                                         CAI
                                                      
                                                      
                                                         i
                                                         ℓ
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Alternatives for which this entropy measure is close to 100 are classified in a single category by all AVFs compatible with the reference set, whereas the ambiguity is maximum for alternatives with entropy close to zero (i.e., in such cases 
                                    
                                       
                                          
                                             CAI
                                          
                                          
                                             i
                                             ℓ
                                          
                                       
                                       ≈
                                       1
                                       /
                                       N
                                    
                                 , for all 
                                    
                                       ℓ
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                 ). The mean entropy is then employed by averaging the above entropy measure over all alternatives in a test sample.


                                 Mean coefficient of variation (CV) of the criteria trade-offs in the sampled AVFs. The previous two measures focus on the classification assignments of the alternatives. However, it may happen that robust assignments are obtained from models with very different specifications of their parameters. Naturally this leads to some ambiguity on how a single decision model can be specified that will best represent the different compatible sets of the model’s parameters. In that sense, the robustness concern is not solely restricted to the outputs of alternative decision models, but it also involves the structural form of these models and their parameters. In this experimental analysis we analyze this issue by measuring the variability of all compatible criteria trade-offs through the following CV measure:
                                    
                                       
                                          CV
                                          =
                                          
                                             
                                                1
                                             
                                             
                                                K
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   K
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      σ
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            ‾
                                                         
                                                      
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

where 
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             k
                                          
                                       
                                    
                                  is the standard deviation of the trade-off constant of criterion k in the sampled AVFs and 
                                    
                                       
                                          
                                             
                                                
                                                   w
                                                
                                                
                                                   ‾
                                                
                                             
                                          
                                          
                                             k
                                          
                                       
                                    
                                  is the corresponding mean value. The CV is close to zero in cases where the criteria trade-offs are almost the same in all AVFs compatible with the information provided by a reference set (i.e., 
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             k
                                          
                                       
                                       ≈
                                       0
                                    
                                 ), whereas CV becomes higher in cases where the variability of the trade-offs increases, thus indicating that the DM’s judgments on the reference alternatives can be represented by a set of very different AVFs.


                        Table 1
                         summarizes the results from an ANOVA on ranks nonparametric full factorial analysis (Conover & Iman, 1981; Sawilowsky, 1990) for the above three robustness indicators as well the classification accuracy (CA) of the robust assignment rule for the test alternatives. The factors considered in the analysis include the characteristics of the reference set (number of criteria, classes, and alternatives from each class) and the AVF modeling form. Under the entropy and the CV indexes all main effects and interactions are found significant at the 1% level. The same applies to the four main effects and all two-way interactions for the CA and the MCAI. As far as the higher-order interactions are concerned, the combination of the AVF modeling form, with the number of criteria, and the number of categories is insignificant under both the CA and the MCAI, whereas the three way interaction of the three factors that describe the data (criteria, classes, alternatives per case) is significant only at the 5% level.

More detailed summary results for the robustness indicators are presented in Table 2
                        . The entries in the table are averages computed over all data sets with the number of criteria (K), categories (N), and reference alternatives per category (
                           
                              M
                              /
                              N
                           
                        ) indicated in the first column. In accordance with the results of Vetschera et al. (2010), all three measures clearly indicate that robustness improves significantly as more information is embodied in the reference set (i.e., when the number of alternatives in the reference set from each category (
                           
                              M
                              /
                              N
                           
                        ) increases). On the other hand, as the number of criteria (K) increases, robustness gets lower. This is explained by the increase in the variability of the decision models, which is evident in the CV for the criteria’s trade-offs.

As far as the effect of the number of categories (N) is concerned, the entropy measure and the CV of the criteria trade-offs indicate that robustness increases in problems with more than two categories. The MCAI, on the other hand provides mixed indications with minor differences in the case where a linear AVF is inferred (according to the Kruskal–Wallis test, the differences between the different settings for the number of categories are not significant at the 1% level), whereas with a piecewise linear AVF the MCAI decreases as the number of categories increases. The observed discrepancies for the three robustness indicators imply that in classification problems, robustness comparisons between problems with different number of categories should be made with caution when based on such measures of robustness.

The variability of the classification results as measured with the entropy index and the MCAI is consistently higher when a piecewise AVF decision model is employed. On the other hand, the coefficient of variation for the criteria trade-offs is lower for piecewise linear models compared to the case where a linear AVF is used. However, it should be noted that for a piecewise linear AVF, the criteria trade-offs are not the only parameters that define the decision model (the form of the marginal value functions is an additional important parameter). Thus, even though the trade-offs may exhibit lower variability in this case, the implications of this result are not directly comparable to the case of a linear model.

Overall, it is worth noting that except for the data characteristics of the reference data and the problem, the results confirm that the specification of an appropriate modeling form is an important factor related to the robustness of the results (this issue has also been highlighted by Stewart (1993, 1996)). In particular, using a more complex model than the one that actually expresses the DM’s judgments in the reference set has a significant negative effect on the robustness of the information that the reference set provides.

As shown in Table 3
                         this has further implications for the performance (classification accuracy) of the models when applied to evaluate alternatives outside the reference set (i.e., test sample). The reported results for the robust assignment rule clearly indicate that increasing the degrees of freedom of the inferred decision model has a negative effect (the significance of the differences between the linear and the piecewise linear models was confirmed with the Wilcoxon signed-rank test at the 1% level). The effects of the number of criteria, the number of classes, and the number of reference alternatives in each category are very similar to the findings discussed above for the three robustness indicators. This is in line with the results reported by Vetschera et al. (2010) on the positive association between classification accuracy and robustness. Nevertheless, similarly to the remark made earlier on the interpretation of the robustness indicators for problems with different number of categories, it should again be noted that establishing a robustness–accuracy connection when referring to problems with such different characteristics, seems to be troublesome and deserves further analysis.

As far as the discrepancies between the robust and centroid assignment rules are concerned, they were found to be very limited, as the percentage of test alternatives for which the two rules provided different results was limited to 1–1.5% (on average) for reference sets with three alternatives per class and less than 1% for larger reference sets. This finding confirms that recommendations obtained from a decision model defined by the centroid of the set of solutions which are compatible with the DM’s judgments, are robust in the sense that the likelihood of obtaining different recommendations with other compatible models is minimized. This justifies the attempts made in past studies to development formulations and approaches that aim to build decision models corresponding to some central solutions (e.g., the post-optimality of Section 2.2 or the formulations in Sections 2.4 and 2.5). The results in the next subsection focus on the comparison of the results obtained from such approaches, in light of the robustness results presented above.

The analysis in the previous section focused on providing some basic results on the characteristics of the polyhedron defined by the set of decision models compatible with DM’s judgments on the reference alternatives. These results constitute the basis for comparing the four approaches described in Section 2 for building a decision model that best represents the reference data, namely:
                           
                              •
                              the basic post-optimality approach (11),

the max–min model (12),

the analytic center model (14), and

the Chebyshev center model (15).

The comparative results presented in this section will be discussed in relation to: (a) the class acceptabilities (confidence) of the assignments of the models constructed with each approach, (b) the relationship between the parameters of the models and the ones corresponding to the actual and centroid models, and (c) the classification performance of the models when applied to the test samples.


                           Tables 4–6
                           
                           
                            summarize the results for the MCAI obtained from the four approaches, under the three main design factors (criteria, alternatives, classes). Each table presents the relative percentage differences between the MCAI obtained with the robust assignment rule and the ones from each of the four tested approaches. Obviously this difference is by definition non-positive as the robust rule assigns the alternatives into the most likely category. Having a single decision model providing similar results to the robust rule would be convenient in the context of robust decision aid.

The obtained results indicate that the decision models constructed with the analytic center formulation are the best performers overall, followed by the models obtained with the Chebyshev model, whereas the basic post-optimality approach and the max–min model provide worse results. This holds for both linear and piecewise linear AVFs, with the only difference being that the max–min model outperforms (overall) the post-optimality approach in the latter case, whereas in the former case the relative performance of these two approaches is reversed. Overall, and in accordance with the results reported in the previous section, the divergences between the models obtained with the four approaches and the robust rule become much larger as the degrees of freedom of the decision model increase. Nevertheless, this effect is weaker for the Chebyshev and the analytic center models.

As far as the number of criteria is involved (Table 4), the divergences between the four approaches and the robust rule, become larger as the number of criteria increases. This negative effect is higher for the max–min model compared to the other approaches (e.g., the divergence with seven criteria is more than double the one with three criteria).

The increase in the number of reference alternatives has a strong positive effect on the acceptability of the assignments produced by the four approaches (Table 5). Under a linear AVF with 15 references alternatives from each category, the MCAI for the results of the four approaches is very close to the MCAI of the robust assignment rule and the differences between the alternative approaches are limited (with the post-optimality approach producing slightly better results). In cases where a piecewise linear AVF is inferred, the post-optimality approach together with the max–min model and the Chebyshev center formulation improve the most with the use of more reference alternatives, whereas the results for the analytic center model appear to slightly worsen.

Finally, with respect to the number of categories (Table 6), all models provide better results in cases with four categories when a linear AVF is inferred, whereas with a piecewise linear model the effect of the number of categories appears mixed and less clear.


                           Table 7
                            provides a summary comparison of the four approaches in terms of their performance on MCAI. For each combination of the design factors (criteria, alternatives, classes; 36 combinations overall), the differences between each pair of approaches were assessed in terms of their statistical significance with a one-tailed Wilcoxon signed-rank test (at the 1% significance level with the Bonferroni–Holm correction to account for multiple comparisons). The table reports the number of factor combinations in which an approach (row) performed significantly better than another (column). As shown in the obtained results, the analytic center approach was never significantly outperformed by the other approaches. On the other hand, under a linear AVF setting it performed significantly better than the other approaches in a considerable number of factor combinations (19–21), mostly in cases with a small number of reference alternatives. With the piecewise linear setting, the number of cases where the analytic center model performed significantly better than the rest of the approaches is higher, again involving mostly cases with small references sets (for instance, no significant differences were observed in comparison to the Chebyshev model with references consisting of 10–15 alternatives from each category).

The above results on the relationship between the most robust assignments and the ones obtained with the models constructed with the four approaches, were also confirmed through the examination of the percentage of test alternatives for which the robust assignment was different from the results of the inferred AVFs. Under the linear AVF setting, this was found to be 3.88% for the analytic center model (on average), as opposed to 6.05% for the Chebyshev model, 6.78% for the post-optimality approach, and 7.08% for the max–min model. On the other hand, with the piecewise linear AVF, the frequency with which differences were observed from the robust assignment was high consistently higher for all approaches (6.94% for the analytic center, 9.06% for the Chebyshev model, 13.54% for the max–min model, and 15.46% for the post-optimality approach).

Except for the analysis of the assignments of the models developed with the four considered approaches we also examine the estimations obtained with regard to the criteria trade-offs in the constructed AVFs. It is worth noting that three of the approaches used in the comparison (i.e., the post-optimality approach, as well as the Chebyshev and analytic center models) are based on the identification of central solutions within the feasible set of a model’s parameters. In that regard, we examine the relationship between the trade-offs in the models obtained with the considered formulation in comparison to the centroid model. Furthermore, comparisons are also performed with the trade-offs in the actual decision model used to classify the data. The mean absolute deviations (MAD) in the trade-off vectors for these comparisons are summarized in Tables 8–10
                           
                           
                           .

With a linear AVF the centroid solution obtained by averaging the simulated compatible decision models, is the one that is closer to the actual trade-offs in the decision model used to classify the data (with an overall MAD equal to 4.29%), followed by the analytic center model. The Chebyshev model performs slightly better than the post-optimality approach, mainly in more complex cases (i.e., problems with seven criteria, four classes, and 10–15 reference alternatives from each category). Overall, the differences between the two methods were found significant at the 1% level according to the Wilcoxon signed-rank test. The Chebyshev model even outperforms the analytic center approach in problems with four categories (the difference being significant at the 1% level), as well as when larger reference sets are employed (i.e., 10–15 reference alternatives in each category; differences significant at the 1% level). On the other hand, the trade-offs in the models obtained with the max–min model are the ones that are most different from the actual trade-offs (with an overall MAD equal to 6.1%), even though its results improve significantly in multi-class instances (e.g., with four classes) as well as with larger reference sets.

As the degrees of freedom of the decision model increase (piecewise linear AVF), the trade-offs obtained with the analytic center model are the ones that best match the actual trade-offs (overall MAD equal to 5.5%), followed by the Chebyshev model and the centroid solution, which both produce similar results. In this case, the post-optimality approach provides the worst results (overall MAD equal to 8.83%).

The trade-offs estimated through the analytic center model are also the ones that are most similar to the centroid solution, under both a linear and piecewise linear modeling setting (overall MAD equal to 2.58% and 2.65%, respectively). With a linear AVF the trade-offs produced with the post-optimality approach are closer to the centroid than the ones of the Chebyshev and max–min models, whereas under the piecewise linear case the Chebyshev model outperforms the two other approaches. These results indicate that, generally, the two approaches that operationalize the centroid concept directly into the model inference process (i.e., analytic and Chebyshev centers) do produce results that are indeed closer to the actual centroid of the feasible polyhedron, particularly in more constrained cases (i.e., with large reference sets, more criteria, and categories). However, with larger polyhedra derived from small-size reference data, such models may still provide poor proxies of centroid solutions.

At the final stage of the analysis, the classification accuracy of the models is examined for the test alternatives (out of sample accuracy). In this context, we define classification accuracy as the ratio between the number of correct classifications produced by a model (for the test alternatives) to the number of alternatives in a test sample. Detailed results are presented in Tables 11–13
                           
                           
                           .

The overall results indicate that the analytic center formulation provides the highest accuracies, under both the linear and piecewise linear setting for the form of the AVF models, followed by the Chebyshev and max–min models, whereas the post-optimality approach provides the worst results. Compared to the robust assignment rule (cf. Table 3) the accuracies of the four approaches are consistently lower. With a linear AVF, the overall differences compared to the robust rule range between 0.98% for the analytic center model and 2.75% for the post-optimality approach, whereas for the piecewise linear setting they even higher (2.14% for the analytic center model up to 7.65% for the post-optimality approach). These results further confirm the association between robustness and classification performance which was found in Section 4.1 and also identified by Vetschera et al. (2010).

The classification performance of the analytic center model shows lower variability (compared to the other approaches) across the different settings for the number of criteria and alternatives. On the other hand, the improvement obtained with larger reference sets is stronger for the other approaches. In fact, the max–min and the Chebyshev models outperform the analytic center approach in problems with 15 reference alternatives under both the linear and the piecewise linear modeling settings (the differences being significant in favor of the max–min and Chebyshev models under the piecewise linear setting in multi-category problem instances, according to a one-tailed Wilcoxon signed-rank test at the 1% significance level with the Bonferroni–Holm correction to account for multiple comparisons). Finally, similarly to the results discussed previously, the effect of the number of categories seems to be mixed, as higher accuracies are obtained in multi-class problems when a linear AVF is employed, whereas under the piecewise linear AVF setting the accuracies are higher in two-class problems.


                           Table 14
                            presents a summary comparison of the four approaches in terms of the statistical significance of the differences in their classification accuracies (at the 1% level). With the linear modeling setting there were 11 factor combinations where the analytic center model outperformed the post-optimality approach, 12 cases where it outperformed the max–min model, and three cases where it performed significantly better than the Chebyshev center model (all three cases involved small data sets with three alternatives from each category and two or three categories). With a piecewise linear AVF, there is an increase in the number of factor combinations in which the analytic center model outperformed the other approaches, but the same is also observed in the opposite direction. In particular, the post-optimality approach performed significantly better than the analytic center model in two instances, the max–min model in three cases, and the Chebyshev model in five cases. Again, all these instances involved multi-class data with 15 reference alternatives from each category.

@&#CONCLUSIONS@&#

In this study we presented an experimental investigation of some typical and recently proposed approaches for building a single AVF decision model representing the DM’s judgments on a set of reference examples in a PDA framework for classification problems. A new approach based on the Chebyshev center of the feasible polyhedron for the decision model’s parameters was also introduced.

The obtained results lead to conclusions and suggestions, which analysts, researchers, and DMs should consider when using PDA approaches for inferring preferential information and constructing decision models from data. Among others, the following main points can be highlighted:
                        
                           •
                           There is a strong positive association between the robustness of the recommendations obtained from a multicriteria decision model with central solutions of the polyhedron that describes the model’s parameters. This was confirmed by the similarity of the results obtained under the robust and centroid classification rules as well as the good results that the analytic and Chebyshev center formulations provided compared to other model inference approaches.

The differences between alternative model inference formulations become larger in cases where the polyhedron of the model’s parameters is wide.

Among the characteristics of the reference data, the number of reference alternatives from each category seems to be the most decisive factor, whereas on the modeling side, the number of free parameters of a model (i.e., its degrees of freedom) is also critical issue. On the other hand, robustness comparisons between problems with different number of categories can be troublesome (as alternative robustness measures may lead to conflicting indications).

These findings suggest that the use of a good model inference formulation can indeed make a significant difference in a PDA context, particularly when working with small reference sets and complex models. Approaches that operationalize the search for central solutions seem to be the best options in such situations. On the other hand, the aggregation of a limited set of (rather arbitrary selected) extreme feasible solutions generated with post-optimality techniques may yield poor results. In any case, larger reference sets should be sought (whenever possible), which will not only improve the formulation of more robust recommendations and accurate models, but also reduce the impact of the model inference approach employed.

However, the results of this study indicate that there is still room for developing new improved model inference formulations. Despite the good performance (relative to the other approaches considered in this study) of the models based on the concepts of the Chebyshev and the analytic center, their results were found to be inferior compared to the ones obtained with the robust and centroid rules. Thus, it is worthwhile to investigate the possibility of introducing new approaches (including interactive procedures, e.g., Greco et al. (2011)) that will facilitate the inference of better and more robust models, based on improved considerations of the concept of “centrality” for the feasible polyhedron.

Except for the above issue, the robustness concern should also be explored in a more general context of model selection, considering not only model complexity (that was considered in this study), but also the effect of using different modeling forms (i.e., other functional, relational or symbolic models such as outranking methods and decision rule approaches), including cases where the selected type of model has incompatibilities with the DM’s system of preferences (e.g., when a model is inadequate to represent a complex preference structure). Other problem settings such as ordinal regression and choice problems can also be considered, together with further experimentation on real-world data. Finally, emphasis should be given to the construction of well-founded and meaningful indicators for measuring robustness with PDA approaches in a unified context applicable to different instances.

@&#ACKNOWLEDGMENT@&#

This research has been co-financed by the European Union (European Social Fund) and Greek national funds through the Operational Program “Education and Lifelong Learning”.

@&#REFERENCES@&#


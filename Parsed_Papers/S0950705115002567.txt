@&#MAIN-TITLE@&#Feature selection with redundancy-complementariness dispersion

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We use inter-correlation of features to represent redundancy and complementariness.


                        
                        
                           
                           We add a modification item for feature complementariness in the evaluation function.


                        
                        
                           
                           Redundancy-complementariness dispersion is used to address the interference effect.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Classification

Feature selection

Relevance

Redundancy

Pairwise approximation

Redundancy-complementariness dispersion

@&#ABSTRACT@&#


               
               
                  Feature selection has attracted significant attention in data mining and machine learning in the past decades. Many existing feature selection methods eliminate redundancy by measuring pairwise inter-correlation of features, whereas the complementariness of features and higher inter-correlation among more than two features are ignored. In this study, a modification item concerning feature complementariness is introduced in the evaluation criterion of features. Additionally, in order to identify the interference effect of already-selected False Positives (FPs), the redundancy-complementariness dispersion is also taken into account to adjust the measurement of pairwise inter-correlation of features. To illustrate the effectiveness of proposed method, classification experiments are applied with four frequently used classifiers on ten datasets. Classification results verify the superiority of proposed method compared with seven representative feature selection methods.
               
            

@&#INTRODUCTION@&#

With the fast development of the world, the dimensional and size of data is fast-growing in most kinds of fields which challenge the data mining and machine learning techniques. Feature selection is an important and useful approach that can effectively reduce the dimensionality of feature space while retaining a relatively high accuracy in representing the original data. Thus, it plays a fundamental role in many data mining and machine learning tasks, particularly in pattern recognition, knowledge discovery, information retrieval, computer vision, bioinformatics, and so forth. The effects of feature selection have been widely recognized for its abilities in facilitating data interpretation, reducing acquisition and storage requirements, increasing learning speeds, improving generalization performance, etc. [1]. Therefore, feature selection has attracted significant attention of more and more researchers [2–8].

Generally speaking, the feature selection methods can be divided into two types: Wrapper and filter. Wrapper methods depend on specific learning algorithms. Thus the performance of wrapper methods is affected by the selected learning methods. This may makes wrapper methods computationally expensive in learning, since they must train and test classifiers for each feature subset candidate. Conversely, filter methods do not rely on any learning schemes. Instead, it is only based on some classifier-irrelevant metrics, including Fisher score [9], 
                        
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                        
                     -test [10], mutual information [11–14], Symmetrical Uncertainty(SU) [15], etc., to estimate the discrimination power of features. Recently, new criteria and techniques such as sparse logistic regression attract increasing attention (e.g. [16]) since they have potential ability to handle very high-dimensional datasets. In this study, we only focus on filter methods.

Filter methods can also divided into feature subset selection and feature ranking ones, with regard to their search strategy. The evaluation unit for subset selection methods is a set of features, thus the set with best discrimination power is trying to be discovered [17–19]. Nevertheless, to find the best feature subset, a total of 
                        
                           
                              
                                 2
                              
                              
                                 m
                              
                           
                           -
                           1
                        
                      candidate subsets (where m is # features in the original data) are possible to be traversed for feature selection task cannot be solved optimally in polynomial-time unless 
                        
                           P
                           =
                           NP
                        
                      
                     [20]. Thus it is computationally intractable in nowadays practice, particularly in the context of big data. Unlike subset methods, feature ranking methods individually take features as the evaluation units and rank them according to their discrimination power [21,22]. These methods usually employ heuristic search strategies such as forward search, backward search, and sequential floating search.

However, whatever feature ranking or feature subsets selection methods, there are two problems possibly leading to wrong rankings or lower capacity for classification. One is that neglecting feature interaction or dependence may lead to redundancy, as some feature selection methods like MIM [23] take the assumption of independence of features. For real-world datasets, particularly those high-dimensional ones, such strong assumption may produce results far from optimal. The other problem is that group capacity of features is usually ignored, since many methods only measure the relationship between two features [11,24,22]. For example, a feature that has low individual classification capacity but is highly dependent on other features may be overlooked and even misidentified as a redundant one by only measuring its pairwise relationship with other features. However, since it is highly dependent on other features, it is also possible that it contributes largely to the discrimination power of the subset consisting of such features. Thus, it should be evaluated as a salient feature and then selected. Since the dependence among features is related to both redundancy and complementariness, it is imperative to develop more precise correlation analysis in order to distinguish them effectively. To this end, we propose a novel feature selection algorithm which tries to modify the redundancy analysis applied in prior methods by introducing a modification item and a dynamic coefficient to effectively adjust redundancy-complementariness identification. The main contributions that distinguish our work form extant studies are listed as follows:
                        
                           •
                           Complementary correlation of features is explicitly separated from redundancy.

Redundancy-complementariness dispersion is taken into account to adjust the measurement of pairwise inter-correlation of features.

The remainder of the paper is organized as follows: Section 2 reviews related work. Section 3 presents the Information theoretic metrics and evaluation criteria. A new feature selection method is included in Section 4. In Section 5, experimental study is conducted and the results are discussed. Finally, Section 6 concludes this study and proposes possible further work.

@&#RELATED WORK@&#

In recent decades, many kinds of feature selection methods have been studied. In general, there are two aims in these feature selection methods. One is to search the most class-relevant features, the other is to remove redundancy. Most feature selection algorithms can effectively find relevant features [25]. A well-known example is Relief, which is developed by Kira and Rendell [21]. The main idea of Relief is to rank features in terms of the weight corresponding to their ability to both discriminate instances with different class labels and cluster those with same class labels based on the distance between instances. However, Relief method may be ineffective since similar weights of two or more features cannot be removed by this method. In other words, this implies that redundant features cannot be identified. A typical and widely used extension of Relief is ReliefF [26], which is competent to the noisy and incomplete datasets. However, it is still unable to remove redundant features. Redundant features are considered to have negative effects on the accuracy and speed of classification methods, hence many feature selection methods are proposed to address this problem by statistic-based merics [22,27,17]. For example, Correlation based Feature Selection (CFS) algorithm proposed by Hall [27] adopts cor value to simultaneously measure a feature subset’s correlation to the class and inter-correlation among features in it. CFS selects the subset which obtains the maximum cor value. However CFS does not designate specific search approaches, thus how to select feature subsets still remains to be a problem.

Minimum Redundancy and Maximum Relevance (mRMR) criterion and its variants [11,24,22] apply information theoretic metrics to separately measure class-relevance and pairwise correlation between features. A comprehensive score consisting of the two indices is applied to evaluate and select features. Fast Correlation Based Feature selection algorithm (FCBF) proposed by Yu and Liu [17] is another typical method that separately handles relevance and redundancy. FCBF utilizes Symmetrical Uncertainty (SU) as the metric to represent class-relevance and pairwise correlation. If the class-relevance of a feature is lower than that of another and the correlation between them, it would be identified as a redundant features and thus to be removed. Recently, an extension of FCBF, namely fast clustering-based feature selection algorithm (FAST), is proposed [28]. In this algorithm, features are firstly divided into clusters. Then for each cluster, an approximate Markov blanket based elimination strategy is applied to finally determine the selected feature subset. All of the above mentioned methods take pairwise correlation as the redundancy index and identify features with high such index to be redundant, while ignoring (1) complementary correlation between features (which we will discuss detailed in Section 3.2) and (2) correlation among more than two features, which still remain to be problems that impair the performance of feature selection.

Much effort has been made to tackle the former problem mentioned above [18,29–32,13–15,33]. Flueret [18] and Wang et al. [29] propose Conditional Mutual Information Maximization (CMIM) criterion for feature selection. CMIM harnesses Conditional Mutual Information (CMI) to measure the intensity of relevance and redundancy since CMI can implicitly identify complementary correlation between features, i.e. a large value of 
                        
                           CMI
                           (
                           F
                           ;
                           C
                           |
                           
                              
                                 F
                              
                              
                                 ∼
                              
                           
                           )
                        
                      implies (1) F is relevant to class C, and (2) F is highly complementary with 
                        
                           
                              
                                 F
                              
                              
                                 ∼
                              
                           
                        
                     , many information theoretic feature selection methods apply it to build up their evaluation criteria [34,31,30,35]. Algorithm based on Cumulate Conditional mutual information Minimization (CCM) criterion [13] is one of the typical algorithms that apply CMI to directly evaluate and select features. It generates candidate feature subset during the incremental step and eliminates redundancy during the shrinking step. Algorithms based on class-separability strategy extend the traditional usage of CMI in feature selection by measuring conditional mutual information between a feature and each class label [14]. Recentely, a feature selection framework basd on Data Anvelopment Analysis (DEA) is proposed [15]. Algorithm with this framework may apply MI and CMI as the evaluation indices to establish the feature evaluation system. Meanwhile, there are also several methods explicitly identifying redundancy and complementary correlation without CMI. Algorithms based on Joint Mutual Information (JMI) [32,36] take into account mutual information between a group of features and class. A typical algorithm taking JMI as metric can be found in [36], which applies JMI to measure mutual information between k features and class. Since the feature relevant to class and the one complementary to salient features will obtain high JMI values, they both will be identified as salient ones and thus is more possible to be selected. Although the above mentioned methods try to recognize complementariness from the pairwise correlation of features, measuring pairwise correlation is actually an approximation to measuring the correlation among more than two features [37]. Under this circumstance, features that are strongly complementary to the certain selected feature(s) but not significantly correlated with the feature group are possible to be selected using such approximation, which will in turn intervene the later selection process.

Entropy, mutual information, and conditional mutual information are the most frequently used metrics in feature selection method [38]. In this section, some essential information theoretic metrics used in our method will be described. The entropy, a fundamental unit of information, is used to quantify the uncertainty preset in the distribution of X, which is formed as [38]
                        
                           
                              
                                 H
                                 (
                                 X
                                 )
                                 =
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 p
                                 (
                                 x
                                 )
                                 log
                                 p
                                 (
                                 x
                                 )
                                 ,
                              
                           
                        where 
                           
                              x
                              ∈
                              X
                           
                         denotes the possible value assignments of 
                           
                              X
                              ,
                              p
                              (
                              x
                              )
                           
                         is the distribution of x (for convenience, we hereafter use the notation 
                           
                              log
                           
                         to denote the base 2 logarithm instead of 
                           
                              
                                 
                                    log
                                 
                                 
                                    2
                                 
                              
                           
                        ). According to the probability theory, one can use conditional entropy to quantify the uncertainty one variable conditioned on another one. The conditional entropy of X given Y is defined as [38]
                        
                           
                              
                                 H
                                 (
                                 X
                                 |
                                 Y
                                 )
                                 =
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          y
                                          ∈
                                          Y
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 p
                                 (
                                 xy
                                 )
                                 log
                                 p
                                 (
                                 x
                                 |
                                 y
                                 )
                                 ,
                              
                           
                        Mutual Information (MI) between two random variables X and Y can be described as follows [38]
                        
                           
                              
                                 I
                                 (
                                 X
                                 ;
                                 Y
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          y
                                          ∈
                                          Y
                                       
                                    
                                 
                                 p
                                 (
                                 xy
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       xy
                                       )
                                    
                                    
                                       p
                                       (
                                       x
                                       )
                                       p
                                       (
                                       y
                                       )
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              x
                              ∈
                              X
                           
                         and 
                           
                              y
                              ∈
                              Y
                           
                         are the possible value assignments of X and Y, respectively. MI can be considered as the amount of information shared by two variables. In feature selection field, it is one of the most widely used metrics for measuring the correlation intensity of two features. Note that the MI is a symmetric merci, i.e. 
                           
                              I
                              (
                              X
                              ;
                              Y
                              )
                              =
                              I
                              (
                              Y
                              ;
                              X
                              )
                           
                        . 
                           
                              I
                              (
                              X
                              ;
                              Y
                              )
                              =
                              0
                           
                         implies that X and Y are statistically independent. Conditional mutual information (CMI), which is an extension of MI for measuring the conditional dependence between two random variables given the third, is defined as [38]
                        
                           
                              
                                 I
                                 (
                                 X
                                 ;
                                 Y
                                 |
                                 Z
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          z
                                          ∈
                                          Z
                                       
                                    
                                 
                                 p
                                 (
                                 z
                                 )
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          y
                                          ∈
                                          Y
                                       
                                    
                                 
                                 p
                                 (
                                 xy
                                 |
                                 z
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       xy
                                       |
                                       z
                                       )
                                    
                                    
                                       p
                                       (
                                       x
                                       |
                                       z
                                       )
                                       p
                                       (
                                       y
                                       |
                                       z
                                       )
                                    
                                 
                                 .
                              
                           
                        
                     


                        
                           
                              I
                              (
                              X
                              ;
                              Y
                              |
                              Z
                              )
                           
                         can be interpreted as the information shared between X and Y given the value of a third variable (Z). MI and CMI can also be expressed with entropies as follows:
                           
                              
                                 I
                                 (
                                 X
                                 ;
                                 Y
                                 )
                                 =
                                 H
                                 (
                                 X
                                 )
                                 -
                                 H
                                 (
                                 X
                                 |
                                 Y
                                 )
                              
                           
                        and
                           
                              
                                 I
                                 (
                                 X
                                 ;
                                 Y
                                 |
                                 Z
                                 )
                                 =
                                 H
                                 (
                                 X
                                 |
                                 Z
                                 )
                                 -
                                 H
                                 (
                                 X
                                 |
                                 Y
                                 ,
                                 Z
                                 )
                                 .
                              
                           
                        
                     

The motivation of using MI to solve feature selection problem is that a larger MI between the feature and the class should imply a potentially greater discrimination ability when using the feature. In addition, a commonly cited justification for using MI in feature selection is that MI can be used to write both an upper and lower bound on the Bayes error rate [39]. It can simply be applied as the criterion of a filter taking the form of
                           
                              (1)
                              
                                 J
                                 (
                                 F
                                 )
                                 =
                                 I
                                 (
                                 F
                                 ;
                                 C
                                 )
                                 ,
                              
                           
                        where 
                           
                              J
                              (
                              ·
                              )
                           
                         denotes the evaluation criterion, F denotes a candidate feature and C denotes the class. Intuitively, the top m candidates which maximize 
                           
                              J
                              (
                              ·
                              )
                           
                         could be selected, where m is a predefined number or decided by some stop criterion. In fact, this criterion takes the assumption that each feature is independent to all other features, which makes the criterion very efficient. However, such an assumption is so strong in practice that almost all the features may be mutually dependent to others, which makes the criterion shown in Eq. (1) be far from optimal. In general, it is widely recognized that a salient set of features should not only be individually relevant to class, but also should not be redundant to other features in the set. In order to identify redundancy, mRMR and its variants are proposed which can be generally formed as
                           
                              (2)
                              
                                 J
                                 (
                                 F
                                 )
                                 =
                                 D
                                 (
                                 F
                                 )
                                 -
                                 R
                                 (
                                 F
                                 )
                              
                           
                        where 
                           
                              D
                              (
                              F
                              )
                           
                         represents relevance between F and class 
                           
                              C
                              ,
                              R
                              (
                              F
                              )
                           
                         describes redundancy between F and the selected features in the subset 
                           
                              S
                           
                        . Usually, like in mRMR [11], 
                           
                              D
                              (
                              F
                              )
                           
                         and 
                           
                              R
                              (
                              F
                              )
                           
                         take the forms of MI. This criterion can efficiently find the features with high class-relevance and low dependence with respect to each other in 
                           
                              S
                           
                        . However, term “redundancy” not only implies that features are highly dependent to each other, but also indicates which one would be substitutable, i.e. their discrimination power would be significantly impaired when some other feature(s) are(is) given. From this viewpoint, only considering dependence between features is not enough to effectively identify redundancy. In other words, a feature which is dependent on another may not definitely imply to be redundant. Instead, the two features may complementary to each other, i.e. they would have stronger discriminatory power as a group (but may weak as individuals), particularly in microarray data analysis [40,41]. To this end, a complementary modification item is introduced as
                           
                              (3)
                              
                                 J
                                 (
                                 F
                                 )
                                 =
                                 D
                                 (
                                 F
                                 )
                                 -
                                 (
                                 R
                                 (
                                 F
                                 )
                                 -
                                 M
                                 (
                                 F
                                 )
                                 )
                              
                           
                        where 
                           
                              M
                              (
                              F
                              )
                           
                         is an item to identify complementary correlation between F and selected features in 
                           
                              S
                           
                        . In the context of MI, if 
                           
                              R
                              (
                              C
                              )
                           
                         takes the form of 
                           
                              
                                 
                                    ∑
                                 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    ∈
                                    S
                                 
                              
                              I
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                         (as in mRMR), 
                           
                              M
                              (
                              F
                              )
                           
                         could thus be denoted as 
                           
                              
                                 
                                    ∑
                                 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    ∈
                                    S
                                 
                              
                              I
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              |
                              C
                              )
                           
                        , which represents the information shared between F and 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                         given class C. In order to illustrate this, we first show the relationship between 
                           
                              R
                              (
                              F
                              )
                           
                         and 
                           
                              M
                              (
                              F
                              )
                           
                         as follows
                           
                              (4)
                              
                                 R
                                 (
                                 F
                                 )
                                 -
                                 M
                                 (
                                 F
                                 )
                                 =
                                 I
                                 (
                                 F
                                 ;
                                 
                                    
                                       F
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 -
                                 I
                                 (
                                 F
                                 ;
                                 
                                    
                                       F
                                    
                                    
                                       s
                                    
                                 
                                 |
                                 C
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       
                                          
                                             ff
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                    
                                       p
                                       (
                                       f
                                       )
                                       p
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                 
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 p
                                 (
                                 c
                                 )
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 |
                                 c
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       
                                          
                                             ff
                                          
                                          
                                             s
                                          
                                       
                                       |
                                       c
                                       )
                                    
                                    
                                       p
                                       (
                                       f
                                       |
                                       c
                                       )
                                       p
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       |
                                       c
                                       )
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 c
                                 )
                                 log
                                 
                                    
                                       
                                          
                                             
                                                p
                                                (
                                                
                                                   
                                                      ff
                                                   
                                                   
                                                      s
                                                   
                                                
                                                )
                                             
                                             
                                                p
                                                (
                                                f
                                                )
                                                p
                                                (
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      s
                                                   
                                                
                                                )
                                             
                                          
                                          ·
                                          
                                             
                                                p
                                                (
                                                f
                                                |
                                                c
                                                )
                                                p
                                                (
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      s
                                                   
                                                
                                                |
                                                c
                                                )
                                             
                                             
                                                p
                                                (
                                                
                                                   
                                                      ff
                                                   
                                                   
                                                      s
                                                   
                                                
                                                |
                                                c
                                                )
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 c
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       
                                          
                                             ff
                                          
                                          
                                             s
                                          
                                       
                                       )
                                       p
                                       (
                                       fc
                                       )
                                       p
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       c
                                       )
                                    
                                    
                                       p
                                       (
                                       f
                                       )
                                       p
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       )
                                       p
                                       (
                                       c
                                       )
                                       p
                                       (
                                       
                                          
                                             ff
                                          
                                          
                                             s
                                          
                                       
                                       c
                                       )
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 c
                                 )
                                 log
                                 
                                    
                                       
                                          
                                             
                                                p
                                                (
                                                fc
                                                )
                                             
                                             
                                                p
                                                (
                                                f
                                                )
                                                p
                                                (
                                                c
                                                )
                                             
                                          
                                          ·
                                          
                                             
                                                p
                                                (
                                                
                                                   
                                                      ff
                                                   
                                                   
                                                      s
                                                   
                                                
                                                )
                                                p
                                                (
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      s
                                                   
                                                
                                                c
                                                )
                                             
                                             
                                                p
                                                (
                                                
                                                   
                                                      ff
                                                   
                                                   
                                                      s
                                                   
                                                
                                                c
                                                )
                                                p
                                                (
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      s
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 p
                                 (
                                 fc
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       fc
                                       )
                                    
                                    
                                       p
                                       (
                                       f
                                       )
                                       p
                                       (
                                       c
                                       )
                                    
                                 
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                f
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          f
                                          ∈
                                          F
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       ff
                                    
                                    
                                       s
                                    
                                 
                                 c
                                 )
                                 log
                                 
                                    
                                       p
                                       (
                                       fc
                                       |
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                    
                                       p
                                       (
                                       f
                                       |
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       )
                                       p
                                       (
                                       c
                                       |
                                       
                                          
                                             f
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                 
                                 =
                                 I
                                 (
                                 F
                                 ;
                                 C
                                 )
                                 -
                                 I
                                 (
                                 F
                                 ;
                                 C
                                 |
                                 
                                    
                                       F
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 .
                              
                           
                        We now explain 
                           
                              R
                              (
                              F
                              )
                              -
                              M
                              (
                              F
                              )
                           
                         using Eq. (4), since the relationship between 
                           
                              I
                              (
                              F
                              ;
                              C
                              )
                           
                         and 
                           
                              I
                              (
                              F
                              ;
                              C
                              |
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                         is straightforward: If 
                           
                              I
                              (
                              F
                              ;
                              C
                              )
                           
                         is much great than 
                           
                              I
                              (
                              F
                              ;
                              C
                              |
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                        , the relevance between F and class C would become significantly weak after given the information of 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        . In other words, F is redundant to 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        . Conversely, if 
                           
                              I
                              (
                              F
                              ;
                              C
                              )
                           
                         is much small than 
                           
                              I
                              (
                              F
                              ;
                              C
                              |
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                        , the relevance between F and class C would become significantly strong after given the information of 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        , i.e. F is complementary to 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        . Thus, 
                           
                              R
                              (
                              F
                              )
                              -
                              M
                              (
                              F
                              )
                           
                         could be applied to simultaneously measure redundancy and complementary correlation: When 
                           
                              R
                              (
                              F
                              )
                              -
                              M
                              (
                              F
                              )
                              >
                              0
                           
                        , it captures the magnitude of redundancy between F and 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        ; when 
                           
                              R
                              (
                              F
                              )
                              -
                              M
                              (
                              F
                              )
                              <
                              0
                           
                        , it captures the magnitude of complementary correlation between F and 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                           
                        . In the context of MI, the following expression could be applied to be the evaluation criterion according to Eq. (4)
                        
                           
                              (5)
                              
                                 J
                                 (
                                 ·
                                 )
                                 =
                                 I
                                 (
                                 F
                                 ;
                                 C
                                 )
                                 -
                                 Pair
                                 _
                                 Cor
                                 (
                                 F
                                 ;
                                 S
                                 )
                              
                           
                        where 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                           
                         takes the form of
                           
                              (6)
                              
                                 Pair
                                 _
                                 Cor
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          S
                                       
                                    
                                 
                                 
                                    
                                       
                                          I
                                          (
                                          F
                                          ;
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          )
                                          -
                                          I
                                          (
                                          F
                                          ;
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          |
                                          C
                                          )
                                       
                                    
                                 
                                 .
                              
                           
                        For the sake of convenience for the discussion in the following sections, we denote 
                           
                              cor
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                              =
                              I
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                              -
                              I
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              |
                              C
                              )
                           
                         and thus Eq. (6) can be rewritten as
                           
                              (7)
                              
                                 Pair
                                 _
                                 Cor
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          S
                                       
                                    
                                 
                                 cor
                                 (
                                 F
                                 ;
                                 
                                    
                                       F
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 .
                              
                           
                        It is noted that although Eq. (7) can measure both redundancy and complementary correlation, it is still a pairwise-based criterion since it only catches the relationship between two features. Criteria that only concern pairwise correlation among features is also called first-order approximation in literature [37]. We will further discuss the limitation of Eq. (7) in detail in the next section.

First-order approximation is a prevailing strategy that seems to bring the best trade-off between executional efficiency and the selected features’ quality. Yet ignoring the group effect of features is still known to be suboptimal although taking the pairwise relevance effect into account. As mentioned before, feature selection methods that only handle individual relevance take the assumption of mutual independence among features. Similarly, first-order approximation in redundancy analysis only concentrates on individual redundancy. In other words, it takes the assumption that all the selected features are mutually independent. Since the first-order approximation only identify pairwise correlation, it is not able to take high inter-feature correlation into account, thus may misidentify and select actually-redundant features (i.e. False Positives, which is denoted as FPs hereafter in the paper; Similarly, we use the term True Positives (TPs) to denote the selected actually-salient features hereafter in the paper), which will in turn intervene the later selection process.

More specifically, only focusing on pairwise correlation may give chance to FPs to intervene the evaluation of candidates. Suppose the selected feature subset already contains FPs, the pairwise correlation between the candidate and each FP is an interference that prompts the candidate to be given unduly high status if such correlation is influential to the value of the evaluation criterion 
                           
                              J
                              (
                              ·
                              )
                           
                        . recall that the correlation between candidate and each selected features is denoted as 
                           
                              cor
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                         where 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              ∈
                              S
                           
                         (
                           
                              S
                           
                         is the selected feature subset) and thus 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    ∈
                                    S
                                 
                              
                              cor
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                        , the interference effect of FPs can be illustrated in two possible scenarios shown in Fig. 1
                         (a) and (b), where node in yellow, nodes in red, and nodes in green denote the candidate, FPs, and TPs, respectively. Distance between yellow node and any other node is in proportion to the strength of their pairwise correlation, e.g. a short distance corresponds to the complementary correlation, while long corresponds to the redundant correlation.


                        Scenario 1: FPs are close to the candidate. As shown in Fig. 1 (a), most of TPs are distant to the candidate, which implies that the candidate is more likely to be redundant rather than complementary to FPs (which corresponds to positive cor value in terms of Eq. (4)) and thus it is possibly a redundant feature. However, as FPs are very close to the candidate, they are more likely to be complementary and the corresponding cor value tend to be negative. Under this circumstance, the complementary correlation between candidate and FPs impairs the reliability of the estimation of 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                           
                         and thus makes the candidate to be overestimated.


                        Scenario 2: FPs are distant to the candidate. Fig. 1(b) shows that most of TPs are close to the candidate. This implies that the candidate is more complementary to TPs and thus more likely to be a salient feature that should be selected. However, it is redundant to the distant FPs and the corresponding cor value tend to be positive, thus also impairs the reliability of the estimation of 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                           
                         and makes the candidate to be underestimated.

Actually, the interference effect of FPs revealed in the above scenarios can be depicted by the dissimilarity of the selected features. That is, the magnitude of the interference effect of FPs depends on the extent of the dispersion of the correlation between candidate and the selected features. When a certain value of 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                           
                         is given, the correlation between F and FPs in 
                           
                              S
                           
                         more likely to be complementary corresponding to larger negative cor values would lead to the correlation between F and TPs in 
                           
                              S
                           
                         more likely to be redundant corresponding to larger positive cor values, and vice versa. We call such dissimilarity as redundancy-complementariness dispersion. As a heuristic, we apply standard deviation of cor to capture such dispersion in order to possibly identify the interference effect of FPs, for standard deviation is always the best index for risk estimation and instability identification. The standard deviation of 
                           
                              cor
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                         given the selected feature subset 
                           
                              S
                           
                         takes the form of
                           
                              (8)
                              
                                 σ
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ∑
                                                      
                                                      
                                                         
                                                            
                                                               F
                                                            
                                                            
                                                               s
                                                            
                                                         
                                                         ∈
                                                         S
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               cor
                                                               (
                                                               F
                                                               ;
                                                               
                                                                  
                                                                     F
                                                                  
                                                                  
                                                                     s
                                                                  
                                                               
                                                               )
                                                               -
                                                               μ
                                                               (
                                                               F
                                                               ;
                                                               S
                                                               )
                                                            
                                                         
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                                
                                                   |
                                                   S
                                                   |
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             1
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              μ
                              (
                              F
                              ;
                              S
                              )
                           
                         is the mean value of 
                           
                              cor
                              (
                              F
                              ;
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              )
                           
                         calculated as
                           
                              (9)
                              
                                 μ
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       Pair
                                       _
                                       Cor
                                       (
                                       F
                                       ;
                                       S
                                       )
                                    
                                    
                                       |
                                       S
                                       |
                                    
                                 
                                 .
                              
                           
                        Thus, the smaller the value of 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                        , the less influential the interference effect of FPs. We try to find salient candidates not only with more complementariness and less redundancy, but also less redundancy-complementariness dispersion, i.e. a small value of 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                        , to heuristically avoid the interference effect of FPs. To this end, we use 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         to adjust the value of 
                           
                              Pair
                              _
                              Cor
                           
                        . Recall that 
                           
                              Pair
                              _
                              Cor
                           
                         simultaneously measures two types of correlation, i.e. redundancy (where the value of 
                           
                              Pair
                              _
                              Cor
                           
                         is positive) and complementariness (where the value of 
                           
                              Pair
                              _
                              Cor
                           
                         is negative). Taking this into account, we use the following criterion
                           
                              (10)
                              
                                 
                                    
                                       J
                                    
                                    
                                       RCD
                                    
                                 
                                 =
                                 D
                                 (
                                 F
                                 ;
                                 C
                                 )
                                 -
                                 ϕ
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 ·
                                 Pair
                                 _
                                 Cor
                                 (
                                 F
                                 ;
                                 S
                                 )
                              
                           
                        where
                           
                              (11)
                              
                                 ϕ
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                   +
                                                   σ
                                                   (
                                                   F
                                                   ;
                                                   S
                                                   )
                                                
                                                
                                                   Pair
                                                   _
                                                   Cor
                                                   (
                                                   F
                                                   ;
                                                   S
                                                   )
                                                   ⩾
                                                   0
                                                
                                             
                                             
                                                
                                                   1
                                                   -
                                                   σ
                                                   (
                                                   F
                                                   ;
                                                   S
                                                   )
                                                
                                                
                                                   Pair
                                                   _
                                                   Cor
                                                   (
                                                   F
                                                   ;
                                                   S
                                                   )
                                                   <
                                                   0
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        to evaluate and select features among candidates. Note that 
                           
                              ϕ
                              (
                              F
                              ;
                              S
                              )
                           
                         is defined piecewise for different types of correlation. Also, we use 
                           
                              1
                              +
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         or 
                           
                              1
                              -
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         rather than 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         or 
                           
                              -
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         as the coefficient of 
                           
                              Pair
                              _
                              Cor
                              (
                              F
                              ;
                              S
                              )
                           
                         in order to reduce the estimation bias of 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         particularly when there are only a few features selected in 
                           
                              S
                           
                        .

@&#PROPOSED METHOD@&#

Based on the above analysis, we propose our feature selection framework shown in Fig. 2
                        . Different from traditional feature selection frameworks, proposed one extends traditional redundancy analysis to redundancy-complementariness analysis, and conducts dispersion analysis before feature evaluation. It not only considers class-relevance and pairwise inter-correlation of features, but also takes into account the effect of redundancy-complementariness dispersion. Similar to most of the feature selection methods, proposed method also applies the sequential forward search strategy to select features. That is, only one candidate features would be selected at each iteration.

We show the pseudo code of proposed algorithm in Algorithm 1.
                           Algorithm 1
                           RCDFS: Redundancy-Complementariness Dispersion-based Feature Selection 
                                 
                                    
                                 
                              
                           


                        Algorithm 1 contains a ‘repeat’ loop and two ‘for’ loops and a calculation process of 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                         (line 11 in Algorithm 1) which takes at least 
                           
                              |
                              S
                              |
                           
                         loops for the calculation. Thus, the worst iteration complexity of Algorithm 1 is 
                           
                              O
                              (
                              δ
                              ·
                              |
                              F
                              
                                 
                                    |
                                 
                                 
                                    2
                                 
                              
                              )
                           
                        , where 
                           
                              δ
                           
                         is the predefined number of selected features. Taking into account the cost of (conditional) mutual information estimation (
                           
                              O
                              (
                              |
                              D
                              |
                              +
                              r
                              )
                           
                        ) [13], the worst computational complexity of Algorithm 1 is 
                           
                              O
                              (
                              δ
                              ·
                              (
                              |
                              D
                              |
                              +
                              r
                              )
                              ·
                              |
                              F
                              
                                 
                                    |
                                 
                                 
                                    2
                                 
                              
                              )
                           
                        , where 
                           
                              |
                              D
                              |
                           
                         denotes the number of samples in the dataset and 
                           
                              r
                              =
                              
                                 
                                    max
                                 
                                 
                                    F
                                    ∈
                                    F
                                 
                              
                              |
                              F
                              |
                           
                         (
                           
                              |
                              F
                              |
                           
                         is the number of values of F). Since there is only one candidate to be selected at the end of each iteration when traversing 
                           
                              
                                 
                                    F
                                 
                                 
                                    s
                                 
                              
                              ∈
                              S
                           
                        , we only need to get the additional information of the newly-added feature rather than traversing 
                           
                              S
                           
                         again. As for the calculation of 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                        , we could apply an alternative formulation of variance, i.e. 
                           
                              Var
                              (
                              X
                              )
                              =
                              E
                              (
                              
                                 
                                    X
                                 
                                 
                                    2
                                 
                              
                              )
                              -
                              
                                 
                                    E
                                 
                                 
                                    2
                                 
                              
                              (
                              X
                              )
                           
                         to make use of ‘for’ loops in Algorithm 1. That is, to get 
                           
                              σ
                              (
                              F
                              ;
                              S
                              )
                           
                        , we have
                           
                              
                                 σ
                                 (
                                 F
                                 ;
                                 S
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   P
                                                   -
                                                   
                                                      
                                                         Q
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                   /
                                                   |
                                                   S
                                                   |
                                                
                                                
                                                   |
                                                   S
                                                   |
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             1
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where we use P to record the summation of 
                           
                              
                                 
                                    cor
                                 
                                 
                                    2
                                 
                              
                           
                         and Q to record the summation of cor. Taking the above into account, we show the fast improvement of Algorithm 1 as Algorithm 2.
                           Algorithm 2
                           A fast implementation of RCDFS 
                                 
                                    
                                 
                              
                           

By utilizing the additional information gained at the latest iteration, the worst iteration complexity of Algorithm 2 is reduced to 
                           
                              O
                              (
                              δ
                              ·
                              |
                              F
                              |
                              )
                           
                         (accordingly, the worst computational complexity is reduced to 
                           
                              (
                              O
                              )
                              (
                              δ
                              ·
                              (
                              |
                              D
                              |
                              +
                              r
                              )
                              ·
                              |
                              F
                              |
                              )
                           
                        ), which is in the same level with that of mRMR and CMIM. Thus, we implement proposed method according to Algorithm 2 in the experiments to verify the performance of RCDFS.

In order to evaluate the performance and effectiveness of proposed method, the most representative and well-performed feature selection methods (CMIM [18], mRMR [11], FCBF [17], MIM [23], ReliefF [26], DEAFS [15], and kASSI [36]) are used to compare with proposed algorithm. Brief reviews on above seven selected feature selection algorithms are described as follows:
                        
                           •
                           CMIM (Conditional Mutual Information Maximization) [18]: This well-known algorithm makes use of CMI to simultaneously measure class-relevance and inter-correlation of features, applying the following function
                                 
                                    
                                       J
                                       (
                                       F
                                       )
                                       =
                                       
                                          
                                             
                                                min
                                             
                                             
                                                
                                                   
                                                      F
                                                   
                                                   
                                                      ∼
                                                   
                                                
                                                ∈
                                                S
                                             
                                          
                                       
                                       I
                                       (
                                       F
                                       ;
                                       C
                                       |
                                       
                                          
                                             F
                                          
                                          
                                             ∼
                                          
                                       
                                       )
                                    
                                 
                              as the evaluation criterion, taking the heuristic that 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          ∼
                                       
                                    
                                 
                               satisfying 
                                 
                                    
                                       
                                          min
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                ∼
                                             
                                          
                                          ∈
                                          S
                                       
                                    
                                    I
                                    (
                                    F
                                    ;
                                    C
                                    |
                                    
                                       
                                          F
                                       
                                       
                                          ∼
                                       
                                    
                                    )
                                 
                               could best represent the conditioning set 
                                 
                                    S
                                 
                              .

mRMR (minimum Redundancy and Maximum Relevance) [11]: It is a very famous feature selection algorithm that uses MI to measure class-relevance and pairwise dependence. It selects feature satisfying
                                 
                                    
                                       J
                                       (
                                       F
                                       )
                                       =
                                       I
                                       (
                                       F
                                       ;
                                       C
                                       )
                                       -
                                       
                                          
                                             1
                                          
                                          
                                             |
                                             S
                                             |
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                
                                                   
                                                      F
                                                   
                                                   
                                                      s
                                                   
                                                
                                                ∈
                                                S
                                             
                                          
                                       
                                       I
                                       (
                                       F
                                       ;
                                       
                                          
                                             F
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                 
                              in a greedy manner, where 
                                 
                                    I
                                    (
                                    F
                                    ;
                                    C
                                    )
                                 
                               measures the class-relevance of F and 
                                 
                                    
                                       
                                          1
                                       
                                       
                                          |
                                          S
                                          |
                                       
                                    
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          ∈
                                          S
                                       
                                    
                                    I
                                    (
                                    F
                                    ;
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    )
                                 
                               measures the average pairwise dependence between F and 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    ∈
                                    S
                                 
                              . Note that we have already introduced it in Section 3.2.

FCBF (Fast Correlation-Based Feature selection) [17]: In this algorithm, Symmetrical Uncertainty (SU) is used as the evaluation merci. It first ranks features in descending order. Then it eliminates redundant features in terms of an approximate Markov blanket criterion: If 
                                 
                                    SU
                                    (
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                    ;
                                    C
                                    )
                                    >
                                    SU
                                    (
                                    
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                    ;
                                    C
                                    )
                                 
                               and 
                                 
                                    SU
                                    (
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                    ;
                                    C
                                    )
                                    >
                                    SU
                                    (
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                    ;
                                    
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                    )
                                    ,
                                    
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                 
                               is thus identified as a redundant feature of 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                 
                               and thus would be eliminated. For this method, we set the predefined threshold 
                                 
                                    γ
                                    =
                                    0
                                 
                               as suggested by [17].

MIM (Mutual Information Maximization) [23]: It is the most basic feature ranking algorithms based on mutual information that only concerns the class-relevance of features. We have also introduced it in Section 3.2. It applies
                                 
                                    
                                       J
                                       (
                                       F
                                       )
                                       =
                                       I
                                       (
                                       F
                                       ;
                                       C
                                       )
                                    
                                 
                              as the criterion to select the top m features with the highest value of 
                                 
                                    I
                                    (
                                    F
                                    ;
                                    C
                                    )
                                 
                              . It is one of the most typical benchmark algorithms in the field of feature selection.

ReliefF [26]: It is a well-known distance-based feature ranking method that searches nearest neighbors of samples for each class label and then weights features in terms of how well they differentiate samples for different class labels. As for the parameter settings, we use 5 neighbors and 30 instances throughout the experiments as suggested by [26].

DEAFS [15]: It is a feature ranking algorithm based on Data Envelopment Analysis (DEA). It evaluates features according to more than one criterion (i.e. relevance, redundancy, conditional dependence, etc.), and applies a DEA-based evaluation approach to get the efficiency score of a feature by considering its class-relevance and conditional dependence to every other feature in the feature space. However, DEAFS will always generate a 
                                 
                                    |
                                    F
                                    
                                       
                                          |
                                       
                                       
                                          2
                                       
                                    
                                 
                               matrix (where 
                                 
                                    F
                                 
                               denotes the feature size) to record the conditional dependence between every two features, it is thus not executable on large-scale datasets.


                              kASSI [36]: It is a feature ranking algorithm based on joint mutual information criterion. It aims at maximizing joint mutual information among features [36]:
                                 
                                    
                                       
                                          
                                             F
                                          
                                          
                                             S
                                          
                                          
                                             k
                                             ASSI
                                          
                                       
                                       =
                                       arg
                                       
                                       
                                          
                                             
                                                max
                                             
                                             
                                                
                                                   
                                                      F
                                                   
                                                   
                                                      S
                                                   
                                                
                                                ⊂
                                                F
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ∑
                                                      
                                                      
                                                         V
                                                         ⊂
                                                         S
                                                         :
                                                         |
                                                         V
                                                         |
                                                         =
                                                         k
                                                      
                                                   
                                                
                                                I
                                                (
                                                
                                                   
                                                      F
                                                   
                                                   
                                                      V
                                                   
                                                
                                                ;
                                                Y
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           

In our experiments, sequential forward search strategy is applied for kASSI and k (i.e. the number of features in 
                                 
                                    |
                                    V
                                    |
                                 
                              ) is set as 2 to make kASSI only consider pairwise correlation among features.

Weka (Waikato environment for knowledge analysis) [42] is chosen as the classification platform. Since FCBF, MIM, and ReliefF have already been integrated in Weka, we directly use them to generate datasets with their selected features before classification. CMIM, mRMR, DEAFS, kASSI and the proposed method are implemented in Java and with Weka interfaces. All experiments are conducted on a 2.60 GHz CPU, 8 GB RAM personal computer with Windows 7.

In order to validate the performance of the proposed method, ten frequently used datasets are applied in our experiments, where six of them (mushroom, kr-vs-kp, sonar, multiple features ka, DNA, and isolet5) are well known UCI datasets and the rest (Colon Tumor, BCR_ABL, Prostate Cancer, and Breast Cancer) are gene microarray datasets with high dimensionality (i.e. containing more than 2000 features). General information of these datasets are summarized in Table 1
                        . For the continuous and mixed datasets, a supervised discretization method called Minimum Descriptive Length (MDL) method [43] is employed to discrete continuous features before feature selection and classification.

In our experiments, four famous and most frequently used classifiers – Naïve Bayesian Classifier (NBC) [44], Support Vector Machine (SVM) [45], k-Nearest Neighbor (kNN) [46] and C4.5 decision tree [47] are adopted to generate classification error rates on the datasets with selected features preprocessed by different feature selection methods. We set 
                              
                                 k
                                 =
                                 1
                              
                            for kNN and employ Gaussian RBF kernels for SVM.

First, we show the classification results of the four classifiers on 
                              
                                 1
                                 ,
                                 …
                                 ,
                                 m
                              
                            selected features for each feature selection method, where m in our experiments is set to be 
                              
                                 min
                                 
                                    
                                       
                                          50
                                          ,
                                          
                                             
                                                
                                                   F
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           . 10-fold cross validation is applied in this part. Note that the nature of the learning process of each classifier is different. Since we are interested in checking the quality of the selected features, independently from the type of classification rule applied, the average result of the four classifiers is thus reported.

In addition, we compare the best classification results for the eight feature selection methods among their selected features. That is, we check the average classification results for each feature selection method on the datasets with selected features ranging from 1 to 
                              
                                 min
                                 
                                    
                                       
                                          50
                                          ,
                                          
                                             
                                                
                                                   F
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           , and report the best one. In order to achieve stable results, a 
                              
                                 (
                                 M
                                 =
                                 10
                                 )
                                 ×
                                 (
                                 N
                                 =
                                 10
                                 )
                              
                           -fold cross-validation is applied, i.e. 10-fold validation will be conduct ten times for each classifier on each dataset. Thus, a total of one hundred result samples (i.e. average results from four classifiers) can be collected where each sample is an average classification result of the four classifiers. Finally, the average of one hundred samples is reported in our paper. Wilcoxon rank-sum test is applied to determine the statistical significance of the difference of the results (where the significant level is set to be 0.05).

To further test the stability of the performance on different datasets, average classification results of different datasets, in ranges from 1 to 5, from 1 to 10, from 1 to 15, from 1 to 20, from 1 to 25, from 1 to 30, from 1 to 35, from 1 to 40,from 1 to 45, and from 1 to 50 selected features, are reported and analyzed respectively for each classifier and feature selection method. Friedman test is applied to analyze the statistical significance of the results. These ten average classification results have been considered to be the approximate transitory period to reach a stable performance for the datasets used.

At last, execution time of selected feature selection methods and proposed RCDFS are reported. For CMIM, mRMR, kASSI, and RCDFS, we compare their runtime with respect to different sizes of selected features. Meanwhile, we also report their runtime on the feature size that corresponding to the best average classification results. For MIM, ReliefF, FCBF, and DEAFS, we only report the runtime of them on certain feature sizes corresponding to their best average classification results since they are all one-time ranking methods and their time complexity is irrelevant to the number of selected features.


                        Figs. 3–12
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                         show the 10-fold cross-validation average classification error rates of the different types of classifiers (NBC, SVM, kNN, and C4.5) on the ten datasets to illustrate the effectiveness of proposed method RCDFS, where the consecutive numbers of selected features are described by X axis, and the average classification error rate is represented by Y axis. According to the results shown in Figs. 3–12, the superiority of RCDFS can be verified in the majority of cases. Particularly on seven datasets namely mushroom (Fig. 3), kr-vs-kp (Fig. 4), sonar (Fig. 5), DNA (Fig. 7), Colon Tumor (Fig. 9), BCR_ABL (Fig. 10), and Breast Cancer (Fig. 12), RCDFS significantly outperforms CMIM, mRMR, FCBF, MIM, ReliefF, DEAFS, and kASSI (DEAFS cannot execute on gene microarray datasets because of its capability limitation mentioned previously). More precisely, RCDFS usually perform better at the beginning of feature selection process on several datasets such as sonar (Fig. 5) and Colon Tumor (Fig. 9). This is probably because the redundancy and complementariness are both considered by RCDFS, rather than only measuring pairwise redundancy like mRMR or ignoring redundancy like MIM, FCBF and ReliefF. For other datasets, e.g. BCR_ABL dataset, the classification error rate corresponding to RCDFS is almost the same as (or a little higher than) those to CMIM, mRMR, and kASSI on the first seven features, whereas after the eighth feature being selected, RCDFS performs better (i.e. the classification error rate is lower) than other methods and will be never exceeded. This is possibly due to the fact that the dispersion of redundancy-complementariness correlation becomes influential to feature evaluation process after several features being selected, i.e. the interference effect of FPs in the selected subset impairs the evaluation ability of the selected compared algorithms. On the whole, it can be seen that RCDFSs select less features corresponding to the lowest error rates than other methods (e.g. it corresponds to the best classification results only selecting five and sixteen features on Colon Tumor and DNA, respectively). It is also found that the performance of RCDFS is not always outstanding and sometimes inferior to CMIM (e.g. results shown in Fig. 11). This may also lie in the dispersion of the redundancy-complementariness correlation since there may exist alternative causes leading to high dispersion which cannot be captured by the variance between TPs and FPs.


                        Table 2
                         records the number of features selected by each feature selection algorithm corresponding to the best average classification results. We observe from the table that the average number of selected features of RCDFS (18.7) is smallest compared to other algorithms used in our experiment. This indicates the advantage of RCDFS: The best classification result can be obtained with a significantly small set of features.


                        Table 3
                         show the average classification error rates of NBC, SVM, kNN, and C
                           
                              4.5
                           
                         on ten datasets over 
                           
                              (
                              M
                              =
                              10
                              )
                              ×
                              (
                              N
                              =
                              10
                              )
                           
                        -fold cross validation, respectively. For each dataset, Wilcoxon test is conducted to evaluate the statistical significance of the difference between the two groups of result samples, i.e. groups of the result samples that corresponds to RCDFS and any other feature selection method. In Table 3, “Err” column records the average classification error rate of 
                           
                              (
                              M
                              =
                              10
                              )
                              ×
                              (
                              N
                              =
                              10
                              )
                           
                        -fold cross-validation. “p-val” column records the p-value associated with Wilcoxon test, where p-value less than 0.05 indicates the statistical significance of the difference between the two average values. Notation “
                           
                              •
                           
                        ”/“
                           
                              ∘
                           
                        ” are used to show that the classification error rate corresponding to the current feature selection method is significantly lower/higher than that to proposed method (corresponding to “RCDFS” column) under the test. Bold value in each row indicates that it is the best result among eight feature selection methods. The average error rate of ten datasets is given in the last row.

As can be seen from Table 3, average classification error rates on ten datasets show that RCDFS outperforms other methods on mushroom, sonar, DNA, BCR_ABL, Prostate Cancer, and Breast Cancer. According to the values of “Err” given in the last row, the best one is obtained by our method (
                           
                              7.35
                           
                        ) and the worst is by MIM (
                           
                              12.02
                           
                        ). Also, the average error rate of CMIM (
                           
                              7.56
                           
                        ) is better than other algorithms (mRMR (
                           
                              8.11
                           
                        ), FCBF (
                           
                              10.34
                           
                        ), ReliefF (10.60), DEAFS (10.78), and kASSI (10.54)).

For further analysis, the diagram (Fig. 13) is applied to visualize the statistical significance of RCDFS comparing with the selected methods under four classifiers on ten datasets. The blue box in Fig. 13 describes that the classification error rate of RCDFS is significantly better than compared algorithm in current dataset. The yellow box represents that there is no significant difference between the results of RCDFS and compared algorithm. The red box implies that the classification error rate of RCDFS is significantly worse than compared algorithm. The white box with a crossing mark in it implies that Wilcoxon test is not conducted owing to capability limitation of the compared algorithm. Results shown in Fig. 13 indicate that RCDFS achieves better performance in most of datasets compared with selected feature selection algorithms.


                        Tables 4–7
                        
                        
                        
                         show the statistical significance of average error using Friedman test under different classifiers on ten datasets. Results in column 
                           
                              k
                              =
                              5
                           
                        , 10, 15, 20, 25, 30, 35, 40, 45, and 50 represents the average classification error in ranges from 1 to 5, from 1 to 10, from 1 to 15, from 1 to 20, from 1 to 25, from 1 to 30, from 1 to 35, from 1 to 40,from 1 to 45, and from 1 to 50 features, respectively. Note that FCBF may select less features than other methods, e.g. it only selects 4 features on mushroom dataset, thus the average up to 4 features is described in row 
                           
                              k
                              =
                           
                         25, 30, 35, 40, 45, and 50. A very small p-val (i.e. p-val<0.05) indicates the significant difference among the average values. In addition, we use S/N given in the last row of the tables to represent statistically significant/not significant difference among the average values under Friedman test with significant level 
                           
                              0.05
                           
                        . Bold value in each column shows the best classification result among seven feature selection methods (DEAFS is excluded since its capability limitation).


                        Table 4 shows that the average classification error rate of Naïve Bayesian Classifier (NBC) corresponding to RCDFS is lowest among all methods and p-val is smaller than 0.05. This indicates that the performance of RCDFS is best using NBC with the number of selected features in all ranges. Similar to NBC, the average error rate of SVM corresponding to RCDFS shown in Table 5 is also lowest with the number of selected features in most of the ranges. In addition, the CMIM is superior to other methods with SVM in the ranges of k
                        =1–45 and to 50. From Tables 6 and 7, the average error rates of kNN and C4.5 corresponding to RCDFS are both the lowest and the p-val is also smaller than 0.05, which verifies the effectiveness of RCDFS.


                        Figs. 14–23
                        
                        
                        
                        
                        
                        
                        
                        
                        
                         show the runtime of four feature selection algorithms (RCDFS, CMIM, mRMR, kASSI) under different selected feature sizes. Recall that all features will be evaluated and ranked one time by MIM, ReliefF, FCBF, and DEAFS, thus we only report their runtime corresponding to the best average classification results in Table 8
                        . To show the efficiency improvement of Algorithm 1, we implement RCDFS using both Algorithms 1 and 2, which are denoted as O-RCDFS (Original-RCDFS) and RCDFS, respectively. Results show that RCDFS, CMIM, mRMR, and kASSI execute in the same level of time and all significantly faster than O-RCDFS (particularly on gene microarray datasets), indicating the effectiveness of the fast implementation shown in Algorithm 2. More specifically, the runtime of RCDFS is faster than O-RCDFS, CMIM, mRMR, and kASSI on mushroom (Fig. 14), kr-vs-kp (Fig. 15), sonar (Fig. 16), multiple feature kahunen (Fig. 17), and Colon Tumor (Fig. 20). We notice that the runtime of RCDFS is slower than mRMR on DNA (Fig. 18), isolet5 (Fig. 19), BCR_ABL (Fig. 21), Prostate Cancer (Fig. 22), and Breast Cancer (Fig. 23), this is because mRMR never considers the complementary correlation among features and only two correlations (i.e. class-relevance and pairwise redundancy between features) are calculated.


                        Table 8 records the runtime of seven selected feature selection algorithms corresponding to their best average classification results shown in Table 3. Note that DEAFS is not executable on gene microarray datasets namely Colon Tumor, BCR_ABL, Prostate Cancer, and Breast Cancer owing to its capability limitation. Results show again that RCDFS, CMIM, mRMR, and kASSI are in the same level of runtime. We also notice that MIM, ReliefF, and FCBF run much faster than RCDFS, CMIM, mRMR, kASSI, and DEAFS (e.g. in some cases the running time of MIM and ReliefF is even lower than 
                           
                              
                                 
                                    10
                                 
                                 
                                    -
                                    2
                                 
                              
                           
                         ms) because they all contain constant iterations (one-time for MIM and ReliefF to calculate the evaluation scores of all features) whereas the number of iterations of RCDFS, CMIM, and mRMR is determined by the feature size.

@&#CONCLUSIONS AND FUTURE WORK@&#

Relevance and redundancy are two important feature properties attracting much attention in the study of feature selection. Many algorithms eliminate redundancy by measuring pairwise inter-correlation between features, while they cannot identify the complementariness of features and the correlation among more than two features. Although the former problem can be effectively addressed by introducing a modification item, high inter-correlation of features still makes the result far from optimal. Specifically, pairwise approximation of high inter-correlation may misidentify and select FPs which will in turn impair the effectiveness of feature evaluation. In order to identify the interference effect of FPs, the redundancy-complementariness dispersion is taken into account in proposed method to adjust the measurement of pairwise inter-correlation of features. To illustrate the effectiveness of proposed method RCDFS, classification experiments are conducted with four frequently used classifiers on ten datasets.In the experiments, RCDFS is compared with seven representative feature selection methods namely CMIM, mRMR, FCBF, MIM, ReliefF, DEAFS and kASSI. Classification results have been proven to perform satisfactorily of RCDFS. To verify the stability of RCDFS, Wilcoxon test as well as Friedman test are adopted to assess the statistical significance of the differences among the results of the feature selection method. According to the test results, RCDFS performs better than the selected methods in most of the cases.

Although the superiority of RCDFS has been verified in the experiments, there still remain challenges which are imperative to be solved in our future work. One is that how to properly set the weights of three objectives, i.e. coordinate relevance, redundancy-complementary, and dispersion of pairwise inter-correlation, is needed to be studied. Possible directions include multi-objective programming and multi-index evaluation techniques such as data envelopment analysis. Moreover, since there is no causal relationship between FPs and the dispersion of pairwise inter-correlation, only concerning such dispersion may not always be effective in feature evaluation. How to design more effective heuristics in the context of first-order approximation will be further studied. In addition, optimization techniques like sparse logistic regression [16] will be introduced to deal with high-dimensional data in our future work.

@&#ACKNOWLEDGEMENTS@&#

We thank the editors and two anonymous reviewers for their constructive comments and suggestions. This work is partially supported by the National Natural Science Foundation of China (51178364, 61104158, 51208401, and 61203236), National Key Technology Support Program (2014BAG01B0503), National Key Projects in the Science & Technology of China (2014BAG01B03), the Fundamental Research Funds for the Central Universities (2013-YB-011), the Doctorate Fellowship Foundation of Huazhong University of Science & Technology (D201177780), the Fundamental Research Funds for the Central Universities, HUST (CXY12Q044, CXY13Q035), the Graduates’ Innovation Fund of Huazhong University of Science & Technology (HF-11-20-2013), and China Scholarship Council (201406950047 and 201406160046).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Reflecting on Jens Rasmussen's legacy (2) behind and beyond, a ‘constructivist turn’

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This article is the second part of a study on the legacy of Jens Rasmussen.


                        
                        
                           
                           The first article looks back on his 30 years of scientific contribution, from 1969 to 2000.


                        
                        
                           
                           This second article explores and investigates some of his intellectual roots.


                        
                        
                           
                           It uses them as a basis to understand some limits and move forward.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Rasmussen

Constructivism

Safety

Sociotechnical systems

Model

@&#ABSTRACT@&#


               
               
                  This article is the second part of a study on the legacy of Jens Rasmussen. The first article, subtitled ‘A Strong Program for a Hard Problem’, looks back on his 30 years of scientific contribution, from 1969 to 2000. This second article explores and investigates some of the intellectual roots which influenced his thinking, using them as a basis to understand some limits and move forward. Indeed, historically oriented studies such as this one are not only tributes to researchers, but a way to differentiate and contrast our present situation with the past in order to integrate contemporary trends, be they theoretical or empirical, or oriented towards research and new models.
                  In the first section of this article, I offer a synthesis of the background covered in the previous article, but I use a tree here as a graphical complement. Branches of the tree show the many fruitful directions opened by Jens Rasmussen, directions which inspired many researchers. In the second part, I address what I believe to be behind this wealth of engineering legacy: cybernetics. I contend that cybernetics has had a profound influence on his thinking and provided him key principles for his inspiring and successful models. To develop the tree image, one might say that cybernetics is the trunk of the tree. Finally, in the third part, I take the opportunity to explore the relevance of extending and sensitising his program to constructivist discourses. After an introduction to this discourse, identifying four types of constructivisms (cognitive, social, epistemological and anthropological), I characterise this move as a ‘constructivist turn’.
               
            

One is captivated, when looking back upon Jens Rasmussen's legacy, by his ability to convey complex topics ranging from cognition, accident, safety or sociotechnical systems in meaningful graphical representations. In the first article (Le Coze, 2015a), I have argued that this was one of his great and lasting contributions: powerful visual heuristics designed to grasp complex phenomena. They are taken for granted now, as part of our basic knowledge for different research areas (e.g. cognition, safety, accidents, errors, etc.), but were highly innovative at the time and have kept their intrinsic value ever since. If one uses a tree to account for his scientific work, the branches represent the many fruitful theoretical orientations shaped by these heuristics, which many authors adopted to pursue and establish new research directions (Fig. 1
                     ). Let's comment upon these branches without repeating at length what was already introduced and discussed in the previous article of the series.

Cognitive task (work) analysis (CTA/CWA) in relation to ecological interface design is a very good example to start with. It is located near the first branch of the tree on the left (represented here by ‘abstraction hierarchy’). CTA/CWA in ecological design is a methodology relying on a specific understanding of cognition (e.g. Vicente, 1999, Sheridan, 2002, Boy, 2010, Bennett & Flach, 2011, Naikar, 2013). Its purpose is to design appropriate physical and symbolic environments suitable to the ecological nature of cognitive processes within work constraints. The first branch is SRK (skill, rule, knowledge), indicating this specific model of cognition. This model, developed as an approach to cognition that is relevant for human machine interface designers, also provides a framework for a taxonomy of human errors. Reason (1990) is probably the most famous author in this area, referring indeed directly to the virtues of SRK for this purpose. But the SRK model was rooted in an ecological approach to cognition, a view that in fact diverted research away from a taxonomic perspective of errors, towards a naturalistic one instead. Within this naturalistic view, the scientific and practical strategy consisting of categorising errors to eliminate them misses the fact that they are part of adaptive and learning cognitive processes (Amalberti, 1996). Errors are an intrinsic feature of individuals' experiences while exploring boundaries of acceptable practices. This idea developed into a more positive view of operators with the topic of resilience (Hollnagel, 1993, Hollnagel et al., 2006, Reason, 2008) but can also be found in the naturalistic decision making (NDM) research tradition (Klein, 1989, 1998, Lipshitz et al., 2001) or in macro-cognition. This constitutes a third branch (top left of the tree).

This micro view of cognition, rooted in an ecological orientation of psychology, was expanded, thanks to an analogy, into a macro view of safety/accident. This fourth branch, found on the right side of the tree, indicates a move towards a broader sociotechnical intention. Whereas the left branches concern micro layers of scientific investigation, the right ones represent attempts to frame issues at a wider or macro layer of conceptualisation. For Jens Rasmussen, the degree of freedom (1), self-organising and adaptive properties of individuals (2), and the notion of boundaries defining an envelope of viable/acceptable practices (3) combined fairly well for a move from a micro to a macro interpretation of safety/accident. The principle of “defence in depth fallacy” captured the idea of that accidents resulted from local practices of individuals under working constraints creating a migration beyond acceptable performance. The concept was subsequently applied and transformed by other authors into “practical drift” (Snook, 2000) and “resonance” (Hollnagel, 2004). By conceptualising accidents this way, it shaped early what has become known as a complexity perspective, with topics such as emergence, self-organisation and complex adaptive systems as key conceptual building blocks. I suggest that it delineates a specific interpretation of the “normal accident” thesis of Charles Perrow (Le Coze, 2015a, Fig. 7).

This appealing idea that one can translate micro into macro processes was also complemented by the so-called sociotechnical view. This is the fifth branch of the tree. In this view, a layered architecture symbolised by a vertical column brings together scientific disciplines associated with different layers (management, regulation, etc.) and open to the environment of the system (technological change, etc.). This is what I have defined as the “strong program for a hard problem”, namely the ambition to address vertically the dynamic behaviour of sociotechnical systems (or, in the words of Jens Rasmussen, a functional instead of a structural perspective of safety). The “strong program” is the cross-disciplinary challenge both from a conceptual and empirical point of view.

The “hard problem” is the ability to both better understand and anticipate accidents through a cross-disciplinary functional analysis. This was as much a theoretical as an empirical challenge. But it is a challenge that authors have tackled in different ways, some with a strong engineering angle, relying for instance on system dynamics (e.g. Leveson, 2012), while others employed what I will call here a more “human factors” approach (e.g. Vicente, 2003). Finally, the last branch, at the top right of the tree, derives directly from the sociotechnical view by promoting an ACCIMAP vision of accidents, developed jointly with Inge Svedung (Rasmussen and Svedung, 2000), a proposition that was applied, for instance, by authors such as Hopkins (2000, 2012), and which is now part of multiple ways of approaching accidents (Underwood and Waterson, 2013).

At the end of this highly abridged tour of Jens Rasmussen's work, one must acknowledge the wealth of insights he provided to various authors, who in turn moved on to advance both practice and theory in many areas including cognitive engineering, the ecological view of cognition, investigating/representing accidents or modelling safety. An interesting comment can now be made, one that needs further development but is nevertheless worth mentioning. It concerns the power and lasting influence of graphical representations. If one compares Jens Rasmussen's legacy with that of Charles Perrow, it is striking to see that what seems to remain for both researchers are their graphical contributions. Both Charles Perrrow's square combining coupling/complexity and Jens Rasmussen's graphics have remained for most readers and researchers the most enduring features of their work on “normal accidents”. Although Charles Perrow made use of a vast amount of data covering a great number of diverse case studies across high-risk systems, what one remembers is the square locating different systems in relation to their proneness to accidents. This comment is in my view quite consistent with findings in the philosophy, history, anthropology and sociology of science of the past thirty years which stress the importance of writings and graphical representations in thinking processes. Don Ihde conceptualises it as a “scientific visualism,” with roots in the artistic/engineering/scientific work of Leonardo Da Vinci (Ihde, 2004). In this respect, it is not, in my opinion, far-fetched to see Jens Rasmussen as one of his distant heirs.

In this second article, I would like to consider Jens Rasmussen as one of the many members of the cybernetics movement or family. Cybernetics is one of Jens Rasmussen's intellectual matrices. To introduce it very briefly before more developments, cybernetics was the product of a network of a diversity of thinkers who conceptualised issues of circular causality, control and communication or self-organising systems. Many of his intuitions and analytical insights denote strong cybernetic influences. This is, I think, quite clear when reading the first article, which shows the diversity of topics covered when one is familiar with the principles of cybernetics. The field of cybernetics and its numerous implications have attracted the attention of philosophers, historians and sociologists over the past thirty to forty years (e.g. Morin, 1977, 1981, Luhmann, 1984, Noble, 1984, Richardson, 1991; Bowker, 1992, Harraway, 1981−82, Gallison, 1994; Dupuy, 1999; Fox Keller, 2002; Pickering, 1995, 2005, 2011; Cassou-Nogues, 2014). The influence of cybernetics is quite profound in the second part of the 20th up to the 21st century. Many contemporary scientific fields (e.g. the science of complexity, cellular automata, neural networks, enactive cognition, new artificial intelligence, etc.) find some of their roots and influences in the 1940's and 50's in the US and UK.

It is therefore not surprising to find it behind Jens Rasmussen's thinking: as an engineer operating in a world in which psychology and social sciences play key roles in conceptualising process operators, organisation, safety and accidents, the concepts elaborated through cybernetics served him well. He was not initially trained as a psychologist, and no references or discussions of any of the classic psychologists (e.g. Wundt, Sigmund Freud, William James, Jean Piaget), who constitute the common reference points of this discipline, appear in his papers. I argue in the first article of this series dedicated to his legacy that this was a clear difference with an author such as James Reason who, as a trained psychologist, developed his ideas on errors with authors such as William James or Sigmund Freud in mind. This is made explicit, for instance, in an article in which James Reason discusses the difference between conceptualising subconscious (or automatic) processes in cognitive sciences and in psychoanalysis (Reason, 2000).

Of course, I do not imply that Jens Rasmussen lacked a background and understanding of the field of psychology and cognitive sciences, areas in which he was deeply involved and in which he participated in their development. He relied heavily, of course, as his articles testify, on the input of researchers such as Herbert Simon, Jerome Bruner or James Gibson, to name a few. What I mean instead is that his knowledge of the fields that he explored and from which he found his inspiration was related to engineering purposes rather than a theoretical addition or comment of canonical texts in psychology. And, because of the breadth of his interests, from micro to macro issues of complex systems, he had to rely on principles that could be translated beyond the scope and results of psychological studies. I argue that it is for this reason that cybernetics played a key role.

Jens Rasmussen was not initially trained either as an anthropologist, sociologist or political scientist. Thus, no classic authors in these domains (e.g. Alexis de Tocqueville, Karl Marx, Emile Durkheim, Max Weber, Talcott Parsons) can be seen as influencing his ideas in any explicit manner, even in references. This is in sharp contrast, for instance, with an author such as Charles Perrow who, as a sociologist, carried out research with an organisational and sociotechnical view of safety and accident with direct links to founding works of general sociology and organisational sociology (Perrow, 1984). I believe that cybernetics made up for Rasmussen's lack of initial training in these areas for treating issues that cannot be dealt with employing ‘classic’ engineering rationales used, for instance, in the calculation of the reliability of components. Cybernetics provided this rationale. However, it also created limitations that I will discuss later in this article. I now turn to a brief introduction of this field.


                        
                           1
                           This section draws heavily on Andrew Pickering's extensive literature survey on cybernetics (Pickering, 2011).
                        Cybernetics is a very dense field, including sophisticated mathematics and different disciplines to varying degrees such as neurophysiology, physiology, psychology, anthropology, as well as philosophy, with implications in many areas of investigations such as the mind, science, language and biology. It was also part of and contemporary to developments in radars, computer science, information theory, as well as artificial intelligence. The Macy conferences are widely recognised as the moment when scientists from different backgrounds first discussed the trans-disciplinary concepts constituting the cybernetics imprint (Dupuy, 1999). However, due to its interdisciplinary nature and the many important thinkers who contributed to shaping its contours, this field is open to many possible angles of description and interpretation. I seek to indicate briefly some of these many angles here to illustrate the point.

Some interpretations from historians and sociologists of science and technology have emphasised the military origin of cybernetics in the context of the Second World War (Gallison, 1994; Harraway, 1981−82, Pickering, 1995). This approach contains a critical tone. The point of departure for this interpretation is Wiener's attempt to design weapon systems that could anticipate the trajectory of enemy planes in order to destroy them. Wiener is one of the main initiators of the movement, with two books that helped spread the ideas of cybernetics to a wide audience (Wiener, 1948, 1956). Command and control and information theory were combined to create machines showing intriguingly similar behavioural patterns to those that were up until then mostly known in biological and human domains.

The spirit of cybernetics lies in the intellectual stimulation of manipulating concepts with potential relevance across usually distinct orders of reality (physical, biological, human, social). Cybernetics blurred the boundaries between animals, humans (mind, society) and machines, and created as such both excitement and ambition (Bowker, 1993). “Cyberneticians argued that we were now at an historical conjuncture where machines were becoming sufficiently complex and the relationship between people and machines sufficiently intense that a new language was needed to span both: the language of cybernetics” (Bowker, 1993, 117).

Recent interpretations differ from the military genealogy of cybernetics first by including more explicitly or even solely focussing on British cyberneticians (e.g. Ross Ashby, Stafford Beer, Gordon Pask, Gregory Bateson) rather than Americans (e.g. Norbert Wiener), and secondly by stressing the different interests of those cyberneticians who were involved in brain or management research rather than weapon machinery (Pickering, 2011). One aspect of Andrew Pickering's research is its emphasis on the properties of self-organisation introduced by cybernetic thinkers, such as Ross Ashby, Ernst Von Foerster, Stafford Beer, but also Ilya Prigogine. Self-organisation has strong implications for both determinism and realism, something that he particularly develops as part of his involvement in a ‘post humanist’ trend in science and technology studies (S&TS). Andrew Pickering stresses first the unpredictability (or emergence) of (exceedingly) complex systems as described by Stafford Beer (Beer, 1959). Second, he analyses the constructed (rather than discovered, as in realism) nature of knowledge that is conveyed by British cyberneticians. By doing so, he establishes bridges between different constructivist discourses in cognitive and social sciences, a subject I consider later in this article.

A last approach that is briefly commented here consists of seeing cybernetics as one of two important threads, along with that of servo mechanisms, which bring the concepts of feedback loop into the domain of social sciences (Richardson, 1991). Although one can see the principles of circular causality applied in social sciences before—without its conceptualisation (e.g. Karl Marx, John Dewey, Robert Merton)—never had this concept been defined before cybernetics or in a “servo mechanism” thread. The interest of Richardson's study is to contrast their similarities and differences with important contemporary developments. According to Richardson, while cybernetics and its legacy or contemporary movements (e.g. general system theory) are dominated by the idea of equilibrium or homeostasis, the servo mechanism and its offshoots, most notably system dynamics (Forrester, 1968), describe and predict patterns or structures made of negative and positive feedback loops with the help of differential equations, leading to counterintuitive behaviour. According to the author, the cybernetics thread, describes system stability; the latter, the “servo mechanism” thread, finds patterns of movement in dynamic systems.

Despite this very large repertoire of interpretations and the many subtleties therein, I wish to remain here at a relatively simple level in my exploration of cybernetics in order to indicate the aspects that are part of Jens Rasmussen's intellectual matrix in order to account for his ability to cover convincingly both micro and macro aspects. Although cybernetics contains a strong formalised and mathematical side, its qualitative implications are far ranging and easy to grasp, as explained above. At its most simple level, cybernetics concerns teleology and circular causality, including the issue of feedback command and control through information. It also concerns self-organising systems (Ashby, 1962; Von Foerster & Zopf, 1962), epistemology and the introduction of a constructivist view of cognition (Von Foertser, 1962). Let's comment these four characteristics and their influences in Rasmussen's writings at various occasions (Table 1
                        ).

Teleology is another word for intentionality. The article that (re)introduced it in opposition to a principle of strict causality in science was written by Arturo Rosenblueth, Norbert Wiener and Julian Bigelow and presented the concept of negative feedback as used in engineering. It asserted the principle that systems exhibiting intentional – teleological - properties relied on a negative feedback loop for directing their behaviour (i.e. machines, cells, animals, humans). Indeed, to be able to adjust behaviour in relation to an intention, a system must control the results with some kind of sensors. “All purposeful behaviour may be considered to require negative feedback. If a goal is to be attained, some signals from the goal are necessary at some time to direct the behaviour” (Rosenblueth et al., 1943)

To model (or understand) the behaviour of such systems requires introducing their purpose. Rasmussen was cognisant of this issue, which had to be substituted for the traditional scientific rationale “the alternative is to consider such systems as intentional systems, controlled in their response to external influence within their range of capability by their ‘intention’ to act derived from the individual value structure and internal goals. Prominent examples are humans and social systems” (Rasmussen, 1985). It is also by stressing teleology that he criticised the idea of human reliability analysis. “We have to consider that humans are not simply deterministic input–output devices but goal oriented creatures who actively select their goals and seek relevant information. The behaviour of human is teleological by nature” (Rasmussen, 1983).

The circular causality or feedback principle of control and command was also part of Rasmussen's reasoning, and it is obviously what constitutes the socio-technical levels. However, he believed that a distinction had to be made between technological and human social systems. “In order for ‘general system science’ to be useful to the kind of analysis of the potential for systematic break down of large scale socio technical systems with adaptive features, the classical cybernetic modelling approach needs to be modified to include semantic and intentional aspects of human systems” (Rasmussen and Batstone, 1989). This awareness may be linked with both his empirical experience of describing real-life tasks but also to his epistemological concern about the quantitative and qualitative in scientific explanations.

However, it appears that Jens Rasmussen was quite influenced by Ashby cybernetics (as described in the first article of the series (Le Coze, 2015), where feedforward thinking goes hand in hand with requisite variety (Ashby, 1956). Requisite variety concerns the issue of regulating self-organised complex systems and is combined with the black box concept, for which the internal mechanism cannot be fully described and predicted. We thus see the influence of Ross Ashby's cybernetics: “Systems with a high degree of autonomous internal functioning, with self organising and adaptive features, may change their internal functional organisation frequently in order to meet the requirements of the environment and to suit their internal goals or performance criteria. Even though such systems are basically causal and controlled by law of nature, their complexity makes it impractical, if not impossible, to explain or predict their performance by functional analysis during real life decision making” (Rasmussen, 1985).

Finally, second-order cybernetics, with Heinz Von Foerster on constructivism, may have inspired in some ways the views Rasmussen expressed in his papers. Constructivism is an epistemological position that challenges the idea that models attain reality as it is, introducing instead the notion of the “observer in his observation”. This type of argument can be found in some of Jens Rasmussen's papers, although I have yet to find it explicitly endorsed as a constructivist one. Here is an early example: “The transformation models used by an ordinary car driver will be completely different from the models available to the car designer, and somewhere between these extremes in dependence upon the internal anatomy and functioning of the car, are the models used by the repair man” (Rasmussen and Jensen, 1974).

Another good example of this contention is the investigation goals and stop rules upon which he relies for his criticism of objectivity. “Perception of occurrences as events in causal connection does not depend on categories which are defined by lists of objective attributes but on categories which are defined by typical examples, prototypes” (Rasmussen, 1988) and, as a consequence, “identification of accidents causes is controlled by pragmatic, subjective stop rules which to a large extent also depend on the aim of the analysis, i.e. whether the aim is to explain the course of events, to allocate responsibility and blame, or to identify possible system improvements in order to avoid future accidents” (Rasmussen, 1988). I contend that while this epistemological ‘constructivist’ option was not fully advocated by Jens Rasmussen, it could have been, given its strong cybernetics background. This is the aim of the next section, namely sensitising Jens Rasmussen's research to new orientations, and in particular in this article, to constructivist discourses.

I am interested, in this section, in sensitising Jens Rasmussen's work to other sources of inspiration, whether they are contemporary ones or sources that he did not incorporate in his models at the time of their development. I focus on what I define as “the strong program for a hard problem”, illustrated by the sociotechnical view, although there are also implications for domains such as human machine interaction. Works in the field of safety have been carried out in the past 20 years from a very diverse range of scientific disciplines including engineering, psychology, sociology, anthropology, history, management or political science. Those interested in safety may now access a very diverse range of studies, empirical data and conceptual insights of many research traditions that were not available 20 years ago. I argue that Jens Rasmussen had a rather ambiguous but also somehow superficial relationship with some of these fields, especially the social sciences (e.g. management, sociology, and political science).

Although he promoted and developed an interdisciplinary research program, it appears that he had a limited use of fields such as management and sociology. Of course, hindsight is always 20–20. It is easy now to look back critically. Doing so does not undermine the value of his work, which remains valuable in many ways, a value that needs to be understood with his engineering purposes. I want nevertheless to begin to ground this contention with the help of two quotes. The first refers to his incorporation of some of the outcomes of high reliability organisation research (HRO) into his cybernetics framework: “Rochlin characterises the relationships between technology and organisations with respect to complexity, error, and risk against the background of the influential studies of the Berkeley group of the evolution of the high-reliability organisation of an American aircraft carrier. Even if the context is that of a social science study, the notions used to analyse the organisation in evolutionary and ‘self-designing’ terms often mirrors concepts of cybernetic theories of self-organisation (e.g. Ashby's requisite variety)” (Rasmussen, Batstone, 1989). In this example, Gene Rochlin's description indeed fits nicely in his mindset where the degree of freedom of self-organised and adaptive individuals leads to patterns (e.g. migration) to be grasped and understood to understand and design safe systems. The fact that empirical studies show the presence of such patterns supported the relevance of his cybernetics matrix.

Secondly, he identified one problem in the social sciences that his conceptual approach was trying to overcome: “Results of field studies, consequently, are often only specified by the name of the system studied, such as ‘power plant control room’, ‘steel rolling mill’, and the subjects are identified in terms of their profession such as ‘process operators’. Unless, however, the characteristics of the ‘process’ environment and of the process ‘operators’ can be explicitly formulated, the danger exists that the results will be judged narrative journalism rather than scientific investigations” (Rasmussen, 1992). This is an interesting comment referring to his strong engineering mindset and intention to formalise his findings into a generic and normative framework for design of work situations across a diversity of systems. According to this strategy, both work and operator processes need to be specified with a level of abstraction that would allow them to be applied in any social contexts for engineering purposes.

This is indeed a very different approach than the descriptive studies that one can find in some traditions of the social sciences, which are often very careful not to produce normative statements and/or start with models to process data. The empirical and qualitative sides of social studies to which he refers pay close attention to the diversity of real life situations, creating indeed obstacles to generalisations for social scientists subscribing to this type of relationship with data. In this tradition, if one pays attention to the specificity of any historical and social situation, for instance between one chemical plant and another, one always finds differences between cases. One will indeed never find two similar chemical plants: processes and control room layout will differ, but also obviously individuals, organisational structures, markets, etc.

This makes some social scientists very reluctant to simplify findings into broader, normative and generic models that could be relevant across cases. Instead, what is valued is fine descriptions that rely on detailed observations and interviews of real life situations, which are considered each time to be historically unique. Of course, there are also examples of social scientists with more theoretically oriented ambitions. In the field of safety, one thinks of Karl Weick and Kathleen Sutcliffe's conceptualisation of “collective mindfulness” (Weick and Sutcliff, 2003). And, although this is a tradition which differs from Rasmussen's intellectual background and engineering ambition, it is not incompatible. This second quote is very indicative of his engineering intention to reach a higher level of normative conceptualisation than that found in descriptive case studies (i.e. “journalism versus scientific investigations”), but also indicative of his grasp and understanding of the social sciences.

Based on these two quotes, I argue that cybernetic influences combined with his idea of producing a framework for engineering purposes (e.g. designing safe systems) versus what he saw as the “journalistic” tendencies of the social sciences might have diverted him from a proper exploration of other studies coming from these fields. There was indeed other research already available than HRO to be explored in organisational sociology, sociology of science and technology, but also in management science, but they are not explicitly mentioned in his work. Here are some of the works that could have already contributed to sensitise Jens Rasmussen's work differently in the 1980's.

One thinks first of Barry Turner's work on the sociology of organisation (1976, 1978), who was also part of a network of multi-disciplinary colleagues (David Blockley and Nick Pidgeon), who endeavoured in the 80's in the UK (a similar type of situation as the US-based HRO tradition), combining psychology, engineering and sociology (e.g. Pidgeon and Turner, 1986; Pidgeon et al., 1986).
                           2
                        
                        
                           2
                           For a historical account, see Pidgeon (2010).
                         Certainly, there was also Charles Perrow's influential thesis that Jens Rasmussen comprehended through his own interpretive lenses, while leaving aside the sociological tradition and simplifying, as many did, the author's message as to the technologically oriented idea of the impossibility of preventing accident in certain systems (Perrow, 1984). But there were also other social science orientations available in the 80's. A variety of papers were published in the late 80's and early 90's about strategy and organisation decision with a focus on managers (e.g. Starbuck and Milliken, 1988a, 1988b; Weick, 1987) or safety management systems (e.g. Hale, 1985; Hale et al., 1991).

There were also studies in the sociology of science and technology applied to the issue of accidents (e.g. Wynne, 1982, 1988, Pinch, 1991). And, in parallel to Rasmussen's own cognitive engineering development to human–machine interface in the 80's, there was an ethnographic/social approach with a similar design ambition, but based on other intellectual inspirations coming from interactionist, work and social science studies. These developments of the 80's became known as the field of computer supported cooperative work (CSCW) and originated from Risoe's research team where Jens Rasmussen worked (e.g. Schmidt, 1991).

During the 90's and in the first decade of the 21st century, these diverse topics in social sciences flourished to form certain identifiable research traditions, with established seminars, conferences and journals. Within these traditions, some seminal contributions distinguished themselves by promoting a social perspective of safety that opened new prospects towards an empirical understanding of the socio-technological nature of disasters. An example is the acclaimed study of Diane Vaughan's (Vaughan, 1996). This article does not pretend to be exhaustive, but seeks to indicate that there were and are multiple conceptual options to reappraise the model of migration and sociotechnical view as initially promoted by Jens Rasmussen.

Indeed, although a powerful model, Jens Rasmussen's sociotechnical system view is not built on social science input. This has also been its strength, because he elaborated a graphical representation of great significance for cognitive engineering communities and beyond, but also its weakness, for it lacks the basis on social theory to account for a diversity of problems related to our grasp of (techno)society as a whole. These ideas were available at the same period in Charles Perrow's book, Normal Accident, but had remained underappreciated in favour of his technological rationale (Le Coze, 2015b). One wonders why Jens Rasmussen distanced himself from social theory, as one finds comments indicating his awareness of its related treatment in the social sciences: “This complex adaptation of performance to work requirements, eliminating the necessity of continuous choice, will result in stereotype practices depending on the individual performance criteria of the agents. These criteria will be significantly influenced by the social norms and culture of the group and organisation” (Rasmussen, 1990).

A first reason for his superficial and ambiguous relationship with social sciences has been discussed above (the influence of his engineering purposes and cybernetics framework), but there might be others. One is possibly his lack of training in sociology or anthropology, which may have prevented him from having a better grasp of the importance of these social science concepts. A second may be that these concepts were difficult to integrate into an analytical framework dominated by a cognitive individual rather than a social, political or cultural actor in a restricted period of time. Jens Rasmussen was the first to admit the difficulties associated with interdisciplinary research: “complex, cross –disciplinary issues, by nature, require an extended time horizon. It takes considerable time to be familiar with the paradigms of other disciplines and often time consuming field studies are required” (Rasmussen, 1997). This ‘asocial’ tendency was already pointed out in the first article of this series when discussing his contribution to the normal accident thread (Le Coze, 2015a).

But there might also be another reason worth evoking here. Many social science studies in the 80's had a critical view of technology and challenge some deep assumptions that Jens Rasmussen's may have held about engineering and technology concerning the control of high risk systems. Rasmussen's writings infer that proper safety models can be designed to handle complex systems, even though it remains a challenging task. In his view, the challenge of safety does not arise from technology, but rather from humans.

“Technical components are well defined object prototypes with widely accepted failure modes, and the course of events is largely dictated by the plant anatomy. A rather well defined completeness can, therefore, be obtained by hazard identification methods following all causal paths found in the pipe and instrumentation diagram of a plant (…). It is very difficult to state explicitly the completeness of a causal analysis including human activities” (Rasmussen, 1988). This quote expresses Jens Rasmussen's firm belief that technology could be mastered and that accidents were caused by the difficulty of being exhaustive when it came to including humans in technological risk assessment. In fact, it is worth noting that his model of migration was created to conceptualise accident and safety targets, specifically actors' behaviours, and not technological “failure”. In this model, accidents do not result from technological breakdown but rather from self-organised properties of individuals applied to sociotechnical systems.

For this reason, his ambition was to design or engineer models able to master the human (and organisational) interface as much as possible in order to master technology through proper design and risk assessment. This assumption about technology contrasts sharply with that of many of the aforementioned studies of the social sciences, which relied on various sources but challenged the engineering belief of control. They indeed consider technology to also be a source of uncertainty. In this orientation, engineers can be faced retrospectively with ‘errors’ in their appreciation of technological behaviour. “One of the lessons of the new sociology of science is that even the most technical and seemingly ‘hard’ areas of knowledge can be questioned and disputed by experts (…). At the heart of the social constructivist viewpoint is the notion of interpretative flexibility. This is the idea that scientific or technological facts can be given different meanings by different actors” (Pinch, 1991, 148–149).

A recent example of this is found in John Downer's work, who suggests defining the notion of “epistemic accident” that extends the notion of normal accidents (Downer, 2011). One could argue, however, that authors such as Barry Turner, Karl Weick or Diane Vaughan had already extended normal accident in this direction, and I define this thread, out of two others, as a constructivist one deriving from Thomas Khun notion of paradigm shift (Le Coze, 2015). Engineers do indeed elaborate temporary ‘constructs’ without the certainty that they are the ‘right’ ones, something that Diane Vaughan's explored in depth in her analysis of the Challenger case (Vaughan, 1996). This idea conveys a constructivist stance that I wish now to introduce as a way of sensitising Jens Rasmussen's program to current trends in the cognitive and social sciences.

Constructivism is currently a popular cross-disciplinary term across the sciences, which took off in the 60's and 70's in various research areas. Its roots are found in many different fields, including cognitive psychology (Neisser, 1967), social psychology and management (Weick, 1969), sociology of knowledge (Berger and Luckmann, 1966), sociology of science and technology (Latour and Woolgar, 1977) as well as biology and epistemology (Piaget, 1967; Morin, 1977; Glasersfeld, 1981). Many authors in the field of safety with backgrounds in different disciplines have endorsed this discourse. I have attempted to delineate a constructivist program in the field of safety based on my study of different authors who proved themselves to be constructivists while studying high-risk systems from various angles. They focus on errors, organisation reliability, risk assessment, investigation reports, networks, etc. (Le Coze, 2012). My conclusion from this study is that different constructivisms cannot be conflated into one. There are indeed many subtleties, and I have been able to roughly distinguish, in what I hope is a helpful way, several possible combinations of cognitive/social and strong/mild constructivisms.

To briefly introduce this classification, one must be aware that some works are strong in the sense that they challenge the ability of science to be objective, whether they do this from a cognitive or social point of view, be it in an application to physics, astronomy, chemistry or molecular biology, cognitive or social sciences. These postures have great significance when one considers their implications to pillars of modern society, that is the discourse of truth that science is supposed to purport and the notion of reason and rationality that it is expected to convey. The debate led, at the end of the 90's, to the “science wars” (Hacking, 1999), between those who wanted to defend science from this kind of relativistic endeavour and those who believed that it was salutary to undermine the pretention of science. On the contrary, some constructivist branches can be classified as rather mild in comparison because they do not challenge the discourse of the objectivity of science or do not enter into a debate with domains such as physics, astronomy, chemistry or molecular biology so as to claim that they are subjective constructs of society which do not allow us to get closer to real processes. They are more confined to psychological or social topics in which such constructivist discourses have had more success and fewer opponents because of the nature of the ‘soft’ phenomena studied and the lower social status of these disciplines.

Of course, this presentation is a bit simplistic, but is sufficient to indicate that, from mild to strong, from cognitive to social, a range of constructivist discourses needs to be acknowledged. This is a situation, which, outside the field of safety, has not escaped the scrutiny of some philosophers (Sismondo, 1996, Hacking, 1999). One way to treat it is to compose with the various constructivist options available, a strategy advocated by Sergio Sismondo. “Heterogeneous construction can involve all of the other types of construction mentioned to this point, combining the construction of accounts with the construction of parts of social reality, with the construction of phenomena and the construction of the broader environment” (Sismondo, 2010, 59). For the sake of simplification, one can consider that a common ground within the diversity of constructivisms is the importance granted to the active role that cognition or society play within their environment. This idea is found in the work of several authors in the field of safety, and I will add another strong constructivist dimension in this paper. I select several quotes, among many others, to illustrate three embedded layers of constructivisms that I combine here from the literature: cognitive, social and epistemological. I then add a fourth, an anthropological (anti-dualist) one (Le Coze, 2013) that has been quasi-absent so far in this field. They do not exclude each other; they overlap and also contain many sources of tensions. But, I see them, broadly, as complementary. I start by describing the two ‘mild’ versions, and then address the two ‘strong’ ones.

I first quote Karl Weick who describes, from a cognitive point of view, for air traffic control, the fact that “controllers can also hold planes on the ground, slow them, accelerate them, turn them sooner, line them up sooner, stack them, or refuse to accept them, to build an environment in which reliability is higher (…). “While a stack is a good example of an enacted environment, it also illustrates that when people construct their own environments, they create problems as well as solutions” (Weick, 1987, 338). From a cognitive point of view, individuals actively construct their world, and if one wants to understand and model pilots in an aircraft or a process operator supervising a nuclear power plant in a control room, these active cognitive processes must be acknowledged. This rationale applies equally in investigation as well as in the study of daily operations or for the design of work situations.

Karl Weick has therefore been a strong advocate of a constructivist, also called sensemaking, view of safety and accidents (Weick, 1993). Jens Rasmussen was not explicitly constructivist when it came to modelling cognition, but some of his comments show how compatible it is with his thinking. An example among others already introduced in the first article of the series (Le Coze, 2015) is: “The figure is not meant to show human as passive and subject to information ‘input’. On the contrary, they actively seek information, guided by their dynamic ‘world model’” (Rasmussen, 1993). His idea of cognition was not of a passive relationship with the environment (i.e. perception, action), but rather an active one. I think that this leaves open the possibility of diverting it toward a more constructivist view.

Erik Hollnagel captures this idea well when representing the circular nature of cognition through a cyclical model which introduces the idea of construct as part of a conceptualisation of joint cognitive systems (Hollnagel and Woods, 2005). This, I believe, was partly inspired by Ulrich Neisser (1976). Despite criticising the limits of information processing metaphor and proposing another option with the notion of construct, stressing the active side of cognition, it is not entirely incompatible with Jens Rasmussen's view, as asserted by the quote above. Hollnagel's drawing is also appealing because it represents cognition (joint cognitive system) with the help of an individual in a specific environment which makes it highly compatible, from a graphical standpoint, with the post-cognitivist works of the past 20 years (i.e. situated, embodied, extended, embedded, distributed cognition). Of course, there are many shortcuts taken here when compiling the work of these different authors (Karl Weick has for instance distinctive philosophical sources of inspiration in phenomenology and pragmatism as opposed to the cognitive engineers and psychologists introduced in this section), but what is important is that they share a view of cognition as an active process rather than a passive reception of information.

While one may find other citations of a social view of constructivism in the work of Karl Weick, Mathilde Bourrier aptly expresses it: “Since organisational reliability is socially constructed, I maintain that an understanding of it cannot be separated from a minute study of social interactions and the uncovering of employee's strategies” (Bourrier, 1999, 45–46). What interests me in this quote is that here, individuals become active in the context of social interactions rather than man–machine interfaces. Constructivism is of course not restricted to the study of operators in relation to their material environment (e.g. a pilot in a cockpit in front of a computer, a process operator in a control room in front of screens) and can be applied first, to social interactions and second, to other actors of high risk systems.

Indeed, like operators, managers and engineers make decisions in an uncertain world, constructing views about unruly technologies, organisations and markets in the context of interacting with various categories of people from a broad range of organisations. They are not passively applying rules, procedures and processes designed to channel behaviours in organisations, but rather actively interacting with each other to create specific dynamics. And, they have indeed, as asserted by Jens Rasmussen, certain degrees of freedom in their choices of strategies when choosing daily options in their social environments, strategies embedded in social stratification and differentiation, hierarchy and power status. But, from a social point of view, what complements the material and ecological nature of work situations targeted by Jens Rasmussen is the presence of macro structures (or institutions) shaping their behaviours through processes of socialisation. This move extends a cognitive aspect of constructivism towards a social one (e.g. Berger, Luckman, 1966, Giddens, 1984).

A citation of Brendan Wallace and Alastair Ross also serves to ground this notion of a ‘constructivist turn’. “In the last twenty years, work by sociologists of science and philosophers has demonstrated that the popular image of physics and chemistry (of neutral objective scientists discovering timeless laws of nature) is not sustainable. Rather, it has been demonstrated that scientists have biases and prejudices like everyone else; that there are influences of gender, ethnicity, and power; and that there really is no single scientific method that applies at all times and to all situations (…) when we try to understand something (discourse, actions, or anything else), this is not a passive action, but an active act of interpretation, and it will always be done from our own specific point of view …” (Wallace and Ross, 2006, 1, 186). Another important point captured by these authors is that scientists are not outside society as purely external and objective observers. Scientists also construct temporary models (just as operators, managers or engineers in safety critical systems) to make sense of the phenomena that they seek to understand, predict or design, and their works have to be understood within socio-historical contexts.

They participate in opening technological or intellectual opportunities for different types of actions while thinking that their actions will participate with or without their consent to shape a new kind of world, but they also find their inspiration in specific historical moments. Science and technology are not ‘value free’ or practiced outside of society, sheltered from its influence. They too, for instance engineers or sociologists in research and development positions, influence situations even if they choose to remain behind the neutral discourse of science or technology. Society is not detached from the currently held scientific and philosophical worldviews and obviously is not isolated from the consequences of science and technological developments. Rasmussen has, at many times, introduced the question of the purpose of scientists (see for instance the first article on accident investigations and cross-disciplinarity), and I argue therefore that he was not far from the reflexivity implied by the constructivist discourse as advocated here by challenging the externality and objectivity of science. This is the third move, from cognitive and social, to an epistemological type of constructivism.

The last vision of constructivism introduced in this turn is grounded in a self-organised and networked creativity of nature and life extended to humans and societies into an ecological vision of our world. This posture rejects the philosophical tradition of the dualism between nature and culture. I classify this as strong constructivism because it challenges the humanist stance (also described as anthropocentrism) that is engrained in contemporary social sciences. Important continental philosophers who are shaping the contours of this recent anti-dualistic mode of thinking are Edgar Morin (1977, 2007) and Michel Serres (1977, 2007). The view they promote is an ecological
                           3
                        
                        
                           3
                           Ecological as used here differs from the notion of ecological psychology. For an introduction in English to these French thinkers in relation to political ecology, see the presentation of Kerry Whiteside (2005).
                         and interactive one, favouring a very active circular or networked relationship between a diverse range of entities (e.g. biological, material, cognitive or social) into an investigation of the limits of our deterministic, reductionist, objectivist and linear mode of thinking about our relationship with the world. Circular causalities replace here linear ones into a decentred, complex and networked world leading to the possibility of events (against the mechanistic and deterministic, ‘clockwork’, worldview).

Based on contemporary outcomes of a wide range of sciences (physics, biology, ecology, ethology, molecular biology, neuroscience, cognitive psychology, sociology, anthropology, linguistics, etc.) and beyond the divide between ‘soft’ and ‘hard’ sciences (or the two cultures) (Snow, 1959), they offer intelligible ways and convincing accounts for including ourselves in nature without reductionist biases of, say, assimilating social phenomena to biological ones. The now popular and debated notion of emergence is at the heart of their work. Bruno Latour is another continental philosopher who has developed empirical strategies to overcome these dualisms, offering alternative methodological tools to sociology but also offering a new anthropological perspective, by using the idea of constructivism through the figure of networks (Latour, 1987, 2007). As one understands now, ‘anthropological’ refers here to our conceptualisation of human nature, and the idea that we construct the world not as outsiders but rather from within nature.

I would now like to offer a graphical way of indicating this ‘constructivist turn’ relying on these four layers of cognitive, social, epistemological and anthropological constructivism to challenge Jens Rasmussen's sociotechnical view (Fig. 3
                     ).

I proceed in three steps. First, this new model visually includes typical individuals borrowed from Erik Hollnagel's drawing (Fig. 2 in this article). Instead of representing an abstract socio-technical system made of hierarchical levels, it seems relevant to include ‘flesh and bones’ actors in order to symbolise the fact that there are real people in sociotechnical systems (operators, engineers, managers, authorities, inspectors as well as journalists, politicians, lawyers, citizens etc.) with their own history, experience, background, culture and relations to different communities with varying degrees of power and influence. Including real individuals also helps to materialise that safety is the product of a multitude of different types and forms of localised and distributed expertises of operators, engineers, line and top managers, authority inspectors, etc., all in interaction within an increasingly techno-sociological world. Borrowing Erik Hollnagel's cyclical representation seemed to me relevant to visually stress this dimension. Showing actors also implies socialising processes represented by different milieu and institutions (state, for profit & public organisations, justice, university, professions, etc.). This entails also therefore introducing a macro view of society shaped by processes of globalisation.

Secondly, individuals and institutions represented in the new view now include scientists and their institutions (universities, institutes, industry research departments) or communities (e.g. disciplines, networks, associations). This illustrates the broad constructivist idea that no one can pretend to be outside the system or to produce an external objective or neutral view. This includes, for example, issues of research funding, the relation between industry and research, but also of the philosophical preconceptions embodied in any scientific endeavour. A distinction is also represented between ‘soft’ and ‘hard’ science in the model. Consistent with a constructivist discourse, the loop between the two symbolises of course their interactions, namely the impossibility of one to think independently of the other, either for the purpose of engineering systems or describing, understanding or predicting phenomena.

Thirdly, networks of positive and negative feedback loops leading to unpredictable self-organised patterns connect a range of entities together including individuals (managers, engineers, operators, regulators, etc.) interacting with each other but also written media or inscriptions (procedures, charts, models, formulas), technology (e.g. valves, pipes, sensors, computers, etc.) and nature (e.g. geological pressure, fog, tsunami, storm, atmosphere). The circularity of Hollnagel's initial drawing as a basic unit conveys very well this idea when multiplied. This representation challenges determinism, the dualisms of nature/culture but also linear causalities. The hierarchical (top down) rationale of Rasmussen's sociotechnical view is also dropped in favour of a more ‘acentralised’ or ‘polycentric’ version (no identifiable top and down). Although human machine interface (or cooperation) is at the centre of this drawing, this does not indicate that is the starting point; any loop is a potential starting point, depending on the discipline involved and the purpose of the study.

Put together, these moves illustrate a ‘constructivist turn.’ This model could also be subtitled as ‘There is No Outside’: we always act somewhere, making sense of these exceedingly complex systems on the basis of our (limited) experience and (limited) intellectual background(s). This presentation of the model is a simplified version of the analytical background presented in Le Coze (2015c).

The new sociotechnical view involves in this article three main moves away from Jens Rasmussen's thinking:
                           
                              1.
                              ‘Socialising & materialising’ the view introducing the interaction of individuals, technology and nature.

Representing the observers/scientists as part of the system/networks.

Dropping the top down representation in favour of a ‘polycentric’ or ‘acentric’ view and showing the complexity of the self-organised – negative-positive feedback loops – dynamics of phenomena.

This new model (Fig. 4
                        ) can be read as follows (Fig. 5
                        ). Where the two lines meet, one finds process operators interacting with high risk systems through interfaces. Then, the first quadrant (bottom left) contains operating individuals, engineers, managers or subcontractors and other institutional actors such as unions, professions or regulators. The second quadrant (bottom right) represents designers as well as civil society including media, justice or associations. The third (top right) and the fourth (top left) quadrants introduce ‘hard’ and ‘soft’ scientists within their scientific ‘paradigms’, communities and institutions (university, private companies or national institutes). The interaction between the ‘two cultures’ can be seen at the juncture of quadrants 3 and 4.

Have we, by moving beyond, left cybernetics (Jens Rasmussen's intellectual matrix) behind? If one considers teleology, circular causality, self-adaptive properties and constructivism to be key aspect of cybernetics as developed by authors such as Stafford Beer, Ross Ashby or Gregory Bateson and included, for instance, in philosophical projects such as Edgar Morin's “generalised complexity” (Morin, 2007) or the alternative historical narrative by Andrew Pickering (Pickering, 2011), it would be difficult to say that cybernetics has been left behind. It has remained a powerful source of inspiration.

@&#CONCLUSION@&#

This article, which is the second part of a study on the legacy of Jens Rasmussen (Le Coze, 2015a) reconsiders his main scientific contributions. After introducing a tree with six branches leading to a host of different developments amongst which cognitive work/task analysis, ecological interface design, error taxonomy, resilience, naturalistic decision making, safety/accident and sociotechnical model and accident investigation tool, the article looks ‘behind’. Behind this wealth of insights, cybernetics is seen as the trunk of the tree allowing Jens Rasmussen to elaborate engineering models across micro and macro layers of issues. But, this cybernetics background also contains limitations that are discussed in particular in relation to his superficial and ambiguous use of social science inputs.

This point is discussed to open ways to sensitise alternatively what has been described previously as his “strong program for a hard problem.” In this article, it is a question of thinking “beyond”. While taking great care of reminding the reader about the comfortable position which consists in looking back to the past from the present, a ‘constructivist turn’ is sketched with the help of a series of steps. Cognitive, social, epistemological and anthropological constructivisms are embedded and interwoven to provide the analytical grounds of a renewed version of Jens Rasmussen's sociotechnical view. Moving from the top-down, vertical and hierarchical view to a polycentric one, socialising and materialising the figure by introducing typical individuals, representing circular causalities and introducing scientists in the picture shift are a means to visualise this ‘constructivist turn’.

@&#REFERENCES@&#


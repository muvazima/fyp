@&#MAIN-TITLE@&#Efficient dictionary learning for visual categorization

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An efficient dictionary learning method is proposed.


                        
                        
                           
                           Fast kNN graph construction is well integrated with submodular dictionary learning.


                        
                        
                           
                           The proposed method finds a balance between accuracy and efficiency.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Visual categorization

Efficient dictionary learning

Submodular optimization

Fast graph construction

@&#ABSTRACT@&#


               
               
                  We propose an efficient method to learn a compact and discriminative dictionary for visual categorization, in which the dictionary learning is formulated as a problem of graph partition. Firstly, an approximate kNN graph is efficiently computed on the data set using a divide-and-conquer strategy. And then the dictionary learning is achieved by seeking a graph topology on the resulting kNN graph that maximizes a submodular objective function. Due to the property of diminishing return and monotonicity of the defined objective function, it can be solved by means of a fast greedy-based optimization. By combing these two efficient ingredients, we finally obtain a genuinely fast algorithm for dictionary learning, which is promising for large-scale datasets. Experimental results demonstrate its encouraging performance over several recently proposed dictionary learning methods.
               
            

@&#INTRODUCTION@&#

Visual categorization is a challenging task in pattern recognition and machine learning, and it has become a hotspot due to the large number of potential applications of categorizing large-scale data in real-world scenarios [1,2]. Intermediate feature representation serves as an important part in visual categorization. As the low-level visual features are often noisy and redundant, the intermediate features are widely exploited to obtain compact and discriminative representations for visual data, which can be leveraged to bridge the semantic gap between low-level visual features and high-level categories [3]. In particular, the sparse coding based approaches have achieved many impressive results [4]. Generally speaking, sparse coding approximates a query datum as a sparse linear combination of items from an over-complete dictionary, which coincides with the fact discovered in neural science that the human vision system utilizes a small number of words in a visual vocabulary to represent the input image [5].

The performance of sparse coding is closely related to the quality of the dictionary. In [6,7], the dictionary is obtained using methods that minimize the reconstruction error. In [8,9], the local coding methods are proposed by imposing the locality constraints on the data-sets. Many efforts have been dedicated to embedding the discriminative information into the representations via supervised learning [10–12]. However, most of these methods are of high time complexity. Efficient dictionary learning on large-scale data remains a challenging task.

Recently, submodular optimization has emerged as a powerful optimization facility in a variety of computer vision tasks such as superpixel segmentation [13], data clustering [20] and video retrieval [21]. A submodular function can be intuitively characterized as a diminishing return property, i.e., adding an element to a smaller set is more helpful than adding it to a larger set. On the other hand, submodularity can be viewed as a discrete analog of convexity, which shares some properties with convex optimization. Maximization of a submodular function is a typical instance of discrete combinational optimization, and finding the global optimum is very difficult due to its NP-hard property. However, provided that the solution is of a matroid structure, the greedy algorithm can be used to obtain a bound of 
                        
                           
                              
                                 1
                              
                              
                                 2
                              
                           
                        
                      on the optimal solution. This useful property has led to some efficient algorithms for superpixel segmentation [13] and dictionary learning [14].

The work in [14] can be viewed as a supervised extension of [13] for dictionary learning. In [14], the entropy rate term of its submodular objective function is the same as that in [13], which is used to enable compact and homogenous clusters. Besides, the discriminative term instead of the balancing term is employed to ensure class purity of each cluster. As their objective functions are submodular and subject to a matroid constraint, the greedy solution is quite efficient for clustering (see the analysis of time complexity in Section 4). The clustering procedure in [13,14] is essentially graph partition so that both of these two works involve the issue of graph construction. In [13], the construction of a kNN graph can be achieved with linear time complexity as the neighboring points can be promptly obtained via image grids. However, as for the data points, the construction of a kNN graph is not a trivial task and its time complexity is even higher than that of the clustering procedure with the implementation in [14], where all the possible pairwise distances need to be computed and then the k-nearest neighborhoods are exhaustively searched by comparing the pairwise similarities. Therefore, the algorithm presented in [14] does not meet the demand of efficient dictionary learning on large-scale data, although the time performance of its clustering procedure is fairly good.

To address the aforementioned issues, we present an efficient submodular dictionary learning approach based on an approximate kNN graph, where the divide-and-conquer strategy is utilized to speed up the graph construction. As a result of the low time complexity of the approximate kNN graph construction, the computational time of the proposed approach is far less than that of [14] when evaluated on several canonical datasets. Moreover, the classification accuracies delivered by our approach are also comparable to those produced by the method presented in [14]. In Fig. 1
                     , we show the pipeline of the classification procedure based on our dictionary learning approach.

The rest of this paper is organized as follows. An overview of related work is presented in Section 2. In Section 3, we introduce some preliminaries, including sparse coding and submodular dictionary learning. In Section 4, we elaborate the details of the proposed approach. Some experimental evaluations are provided in Section 5. Finally, we summarize this paper in Section 6.

@&#RELATED WORK@&#

The supervised dictionary learning enables more discriminative power compared with the unsupervised learning approaches. Mairal et al. [11] modeled dictionary learning as logistic regression of label information. Similarly, the discriminative term is represented as the Fisher criterion in [15]. Some other discriminative representations such as optimal sparse coding error, hinge loss function, and linear predictive classification error can be found in [12,16,17]. Zhou et al. [18] presented a joint dictionary learning method to obtain a globally-shared dictionary and multiple category-specific dictionaries. Shen et al. [19] reported a hierarchical dictionary learning approach, where the learnt dictionaries in different layers are used to capture the discriminative information of different scales.

It is worth noting that submodular optimization has become a sensible trend to solve the large scale problems in computer vision and machine learning. In [20], submodular optimization is applied to clustering, where the single linkage and the minimum description length are used to find an approximately optimal result. Cao et al. [21] proposed to use the graph-based influence maximization method to bridge the pooling and hashing stages in video retrieval. As the influence maximization model is submodular, a greedy optimization method is utilized to attain a nearly optimal solution. Kim et al. [22] used a submodular function, the temperature maximization on anisotropic heat diffusion, to jointly segment common regions from multiple images.


                     kNN graph construction is an important approach in computer vision and other related fields. As the brute-force method is of high time complexity, it is only applicable for small datasets. Chen et al. [23] adopted a divide-and-conquer strategy to generate an approximate kNN graph, where an efficient Lanczos procedure is used to perform recursive spectral bisection in the dividing stage. According to a simple principle that a neighbor of a neighbor is also probably a neighbor (e.g., given three data items a, b and c, if b
                     ∊neighbor(a),
                     c
                     ∊neighbor(b), then probably c
                     ∊neighbor(a)), Dong et al. [24] presented an efficient kNN algorithm based on local search. Additionally, some parallel algorithms are developed to speed up the construction of kNN graph [25].

In our work, we mainly focus on the effective combination of the submodular clustering and the fast kNN graph construction, which finally yields a dictionary learning approach with very low time complexity.

Let Y be an M-dimensional data set, which contains N instances, i.e., Y
                     =[y
                     1,
                     y
                     2,…,
                     yN
                     ]∊
                     RM
                     
                     ×
                     
                        N
                     . With a given dictionary D
                     =[d
                     1,
                     d
                     2,…,
                     dK
                     ]⊆
                     RM
                     
                     ×
                     
                        K
                     , the sparse representation Z
                     =[z
                     1,
                     z
                     2,…,
                     zN
                     ]∊
                     RK
                     
                     ×
                     
                        N
                      for Y can be obtained by solving the following optimization problem:
                        
                           (1)
                           
                              Z
                              =
                              arg
                              
                                 
                                    
                                       min
                                    
                                    
                                       Z
                                    
                                 
                              
                              ‖
                              Y
                              -
                              DZ
                              
                                 
                                    ‖
                                 
                                 
                                    2
                                 
                                 
                                    2
                                 
                              
                              
                              s
                              .
                              t
                              .
                              
                              ∀
                              i
                              ,
                              ‖
                              
                                 
                                    z
                                 
                                 
                                    i
                                 
                              
                              
                                 
                                    ‖
                                 
                                 
                                    0
                                 
                              
                              ⩽
                              s
                           
                        
                     where 
                        
                           |
                           |
                           Y
                           -
                           DZ
                           |
                           
                              
                                 |
                              
                              
                                 2
                              
                              
                                 2
                              
                           
                        
                      is the construction error and 
                        
                           |
                           |
                           
                              
                                 z
                              
                              
                                 i
                              
                           
                           |
                           
                              
                                 |
                              
                              
                                 0
                              
                           
                           ⩽
                           s
                        
                      is the sparsity constraint.

The performance of sparse coding depends heavily on the dictionary D. Although the strategy of using all the training samples as the dictionary is applicable [4], this method suffers from considerable time overhead during the computation of sparse representation. Consequently, a number of attempts have been made to learn a small-sized dictionary, in which the most well-known are the K-SVD algorithm and its extensions in various forms [6,12,17]. Nonetheless, dictionary learning via K-SVD is a long iterative update procedure and contains the time-consuming singular value decomposition (SVD). The extensions of K-SVD are generally achieved by adding some extra discriminative terms into the objective function, in which the optimization method for K-SVD is still used. Therefore, the efficient computation for dictionary learning remains a significant challenge. To address these problems, Jiang et al. [14] extended a clustering model previously used in superpixel segmentation [13] to learn a discriminative dictionary. The objective function of their model comprises two components: the entropy rate of a random walk on a graph and a regularized item for enhancing representative power. And the dictionary is constructed by finding a graph topology which maximizes the objective function. As the objective function is submodular and monotonically increasing, the time complexity of its solving procedure is more than an order of magnitude lower than many available dictionary learning approaches. However, despite the efficiency of the optimization, their graph construction is a brute-force approach and the overall algorithm is still of relatively high time complexity, which hinders its application in large-scale data.

In the following sections, we will demonstrate that the submodular clustering model can be flawlessly integrated with the technique of fast approximate kNN graph construction [23], which finally results in a genuinely efficient method for dictionary learning.

We map the dataset Y to a kNN graph G
                        =(V,
                        E) with vertices denoting the data points and the edge set denoting the pairwise similarities between data points. The edge weight is defined as:
                           
                              (2)
                              
                                 
                                    
                                       w
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   exp
                                                   (
                                                   -
                                                   β
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   )
                                                   )
                                                
                                                
                                                   if
                                                   
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   
                                                   and
                                                   
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   
                                                   are neighbors
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where d(vi
                        ,
                        vj
                        ) is the distance between vi
                         and vj
                         and β is a smoothing coefficient. We set β
                        =(2〈d
                        2(vi
                        ,
                        vj
                        )〉)−1 empirically, where〈⋅〉means the average over all the pairwise distances.

The key idea of the proposed algorithm is to partition the graph into exactly K connected components by selecting a subset A of E (A
                        ⊆
                        E). In order to satisfy the adopted random walk model, we assume that each vertex of the graph has a self-loop. When an edge is not included in A, the edge weight wij
                         is redistributed to the self-loops of its associated nodes vi
                         and vj
                         as follows: wii
                        
                        =
                        wii
                        
                        +
                        wij
                        , wjj
                        
                        =
                        wjj
                        
                        +
                        wij
                        . The purpose of such an operation is to keep the total incident weight for each vertex constant so as to make the distribution 
                           μ
                         in Eq. (11) stationary.

Next we describe the details of computing an approximate kNN graph. The adopted method falls into the framework of dividing and conquering: dividing the data set into subsets, recursively computing the (approximate) kNN graphs and conquering the results into a final kNN graph. The implementation of conquering is relatively simple: If a data item belongs to more than one subset, its k nearest neighbors are chosen from its neighbors in each subset. The dividing step is based on the technique of spectral bisection. Let 
                           
                              
                                 
                                    Y
                                 
                                 
                                    ^
                                 
                              
                              =
                              [
                              
                                 
                                    
                                       
                                          y
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    
                                       
                                          y
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    
                                       
                                          y
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    N
                                 
                              
                              ]
                              =
                              Y
                              -
                              
                                 
                                    ce
                                 
                                 
                                    T
                                 
                              
                           
                        , where c is the centroid and e is a column vector of all ones. The spectral bisection separates 
                           
                              
                                 
                                    Y
                                 
                                 
                                    ^
                                 
                              
                           
                         into halves by using a hyperplane. Let (σ,
                        u,
                        q) be the largest singular triplet of 
                           
                              
                                 
                                    Y
                                 
                                 
                                    ^
                                 
                              
                           
                        , then we have:
                           
                              (3)
                              
                                 
                                    
                                       u
                                    
                                    
                                       T
                                    
                                 
                                 
                                    
                                       Y
                                    
                                    
                                       ^
                                    
                                 
                                 =
                                 σ
                                 
                                    
                                       q
                                    
                                    
                                       T
                                    
                                 
                              
                           
                        
                     

The hyperplane is denoted by〈u,
                        y
                        −
                        c〉=0, which separates the data set into two subsets:
                           
                              (4)
                              
                                 
                                    
                                       Y
                                    
                                    
                                       +
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       u
                                    
                                    
                                       T
                                    
                                 
                                 
                                    
                                       
                                          
                                             y
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                    
                                 
                                 ⩾
                                 0
                                 }
                                 
                                 and
                                 
                                 
                                    
                                       Y
                                    
                                    
                                       -
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       u
                                    
                                    
                                       T
                                    
                                 
                                 
                                    
                                       
                                          
                                             y
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                    
                                 
                                 <
                                 0
                                 }
                              
                           
                        
                     

According to the property of SVD, the bisection technique can alternatively separate the set by using
                           
                              (5)
                              
                                 
                                    
                                       Y
                                    
                                    
                                       +
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 ⩾
                                 0
                                 }
                                 
                                 and
                                 
                                 
                                    
                                       Y
                                    
                                    
                                       -
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 <
                                 0
                                 }
                              
                           
                        where qi
                         is the ith entry of the right singular q. The largest singular triplet (σ,
                        u,
                        q) can be efficiently computed by using the Lanczos algorithm [27,28]. Based on the spectral bisection technique, we can divide the current set into two disjoint subsets and use a third set, namely the gluing set, to help merging the two resulting disjoint kNN graphs in the conquering stage. This approach is called the glue method in [23]. Fig. 2
                         depicts the partition of the data set in the glue method.

Formally, we divide the set Y into two disjoint subsets Y
                        1 and Y
                        2 with a gluing subset Y
                        3:
                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   ∪
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                   =
                                                   Y
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   ∩
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                   =
                                                   ∅
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   ∩
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         3
                                                      
                                                   
                                                   ≠
                                                   ∅
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                   ∩
                                                   
                                                      
                                                         Y
                                                      
                                                      
                                                         3
                                                      
                                                   
                                                   ≠
                                                   ∅
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Let the set Q be defined as Q
                        ={|qi
                        ||i
                        =1,2,…,
                        N}. The criterion for constructing these subsets is given by:
                           
                              (7)
                              
                                 
                                    
                                       Y
                                    
                                    
                                       1
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 ⩾
                                 0
                                 }
                                 ,
                                 
                                    
                                       Y
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 <
                                 0
                                 }
                                 
                                 and
                                 
                                 
                                    
                                       Y
                                    
                                    
                                       3
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 -
                                 
                                    
                                       f
                                    
                                    
                                       α
                                    
                                 
                                 (
                                 Q
                                 )
                                 ⩽
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 ⩽
                                 
                                    
                                       f
                                    
                                    
                                       α
                                    
                                 
                                 (
                                 Q
                                 )
                                 }
                              
                           
                        where 
                           
                              
                                 
                                    f
                                 
                                 
                                    α
                                 
                              
                              (
                              ·
                              )
                           
                         is a function returning the items larger than 100α% of the items in the data set.

Moreover, the graph can be further refined during each iteration following the conquering step. The key idea is to recompute the k-nearest neighbors for each point by searching a pool containing its neighbors and the neighbors of its neighbors.

In a nutshell, the glue method for constructing an approximate kNN graph can be summarized in Algorithm 1. As we can see, a typical divide-and-conquer strategy is used in this algorithm. When the size of the set is smaller than a given number nk
                        , the kNN-BRUTEFORCE procedure is performed. Otherwise, the current set is recursively divided into smaller sets. The CONQUER procedure is used to merge the graphs computed from the subsets. And the REFINE procedure is employed to further improve the quality of the constructed graph.
                           
                              
                                 
                                 
                                    
                                       
                                          Algorithm 1. The glue method for constructing an approximate kNN graph.
                                    
                                    
                                       
                                          function 
                                          G
                                          
                                          =
                                          
                                          kNN-GLUE(Y,
                                          k,
                                          α)
                                    
                                    
                                       
                                          
                                          if |Y|<
                                          nk
                                           
                                          then
                                       
                                    
                                    
                                       
                                          
                                             
                                             G
                                          ←
                                          kNN-BRUTEFORCE(Y,
                                          k)
                                    
                                    
                                       
                                          
                                          else
                                       
                                    
                                    
                                       
                                          
                                          (Y
                                          1, Y
                                          2, Y
                                          3)←DIVIDE-GLUE(Y,α)
                                    
                                    
                                       
                                          
                                          
                                          G
                                          1
                                          ←
                                          kNN-GLUE(Y
                                          1,
                                          k,α)
                                    
                                    
                                       
                                          
                                          
                                          G
                                          2
                                          ←
                                          kNN-GLUE(Y
                                          2,
                                          k,α)
                                    
                                    
                                       
                                          
                                          
                                          G
                                          3
                                          ←
                                          kNN-GLUE(Y
                                          3,
                                          k,α)
                                    
                                    
                                       
                                          
                                          
                                          G
                                          ←CONQUER(G
                                          1, G
                                          2, G
                                          3, k)
                                    
                                    
                                       
                                          
                                          REFINE(G, k)
                                    
                                    
                                       
                                          
                                          end if
                                       
                                    
                                    
                                       
                                          end function
                                       
                                    
                                 
                              
                           
                        
                     

The entropy rate of the random walk is used to enable compact and homogenous clusters to render the structural semantics of the constructed dictionary more meaningful. In mathematics, the entropy rate evaluates the uncertainty of a stochastic process 
                           X
                        
                        ={Xt
                        |t
                        ∊
                        T} where T is an index set. For a discrete random process, the entropy rate is denoted by an asymptotic measure:
                           
                              (8)
                              
                                 H
                                 (
                                 X
                                 )
                                 =
                                 
                                    
                                       
                                          lim
                                       
                                       
                                          t
                                          →
                                          ∞
                                       
                                    
                                 
                                 H
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       t
                                    
                                 
                                 |
                                 
                                    
                                       X
                                    
                                    
                                       t
                                       -
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       t
                                       -
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 ,
                              
                           
                        which quantifies the remaining uncertainty of the random process given the past. As for the stationary 1st-order Markov process, the entropy rate is denoted by:
                           
                              (9)
                              
                                 H
                                 (
                                 X
                                 )
                                 =
                                 
                                    
                                       
                                          lim
                                       
                                       
                                          t
                                          →
                                          ∞
                                       
                                    
                                 
                                 H
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       t
                                    
                                 
                                 |
                                 
                                    
                                       X
                                    
                                    
                                       t
                                       -
                                       1
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          lim
                                       
                                       
                                          t
                                          →
                                          ∞
                                       
                                    
                                 
                                 H
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       2
                                    
                                 
                                 |
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 =
                                 H
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       2
                                    
                                 
                                 |
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 )
                              
                           
                        
                     

The first equality arises from the property of the 1st-order Markov process whilst the second one is the result of the stationary state.

Let 
                           X
                        
                        ={Xt
                        |t
                        ∊
                        T,
                        Xt
                        
                        ∊
                        V} be a random walk on graph G
                        =(V,
                        E), and the transition probability is defined as:
                           
                              (10)
                              
                                 
                                    
                                       p
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 Pr
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       t
                                       +
                                       1
                                    
                                 
                                 =
                                 
                                    
                                       v
                                    
                                    
                                       j
                                    
                                 
                                 |
                                 
                                    
                                       X
                                    
                                    
                                       t
                                    
                                 
                                 =
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             w
                                          
                                          
                                             ij
                                          
                                       
                                    
                                    
                                       
                                          
                                             w
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    w
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                    :
                                    
                                       
                                          e
                                       
                                       
                                          ij
                                       
                                    
                                    ∈
                                    E
                                 
                              
                              
                                 
                                    w
                                 
                                 
                                    ij
                                 
                              
                           
                         is the sum of the incident weights of vi
                        , and the stationary distribution is denoted by:
                           
                              (11)
                              
                                 μ
                                 =
                                 
                                    
                                       (
                                       
                                          
                                             μ
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             μ
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             μ
                                          
                                          
                                             |
                                             V
                                             |
                                          
                                       
                                       )
                                    
                                    
                                       T
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         S
                                                      
                                                   
                                                
                                             
                                             ,
                                             
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         S
                                                      
                                                   
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         |
                                                         V
                                                         |
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         S
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       T
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    w
                                 
                                 
                                    S
                                 
                              
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    |
                                    V
                                    |
                                 
                              
                              
                                 
                                    w
                                 
                                 
                                    i
                                 
                              
                           
                         is the sum of the total weights of all the vertices. 
                           μ
                         is easily validated to be a stationary distribution.

The aforementioned definition on the edge weight leaves the stationary distribution 
                           μ
                         unchanged. The set functions for the transition probabilities pij
                        :2
                           E
                        
                        →
                        R with respect to A are given by:
                           
                              (12)
                              
                                 
                                    
                                       p
                                    
                                    
                                       ij
                                    
                                 
                                 (
                                 A
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   i
                                                   
                                                   ≠
                                                   
                                                   j
                                                   
                                                   and
                                                   
                                                   
                                                      
                                                         e
                                                      
                                                      
                                                         ij
                                                      
                                                   
                                                   ∉
                                                   A
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               ij
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   i
                                                   
                                                   ≠
                                                   
                                                   j
                                                   
                                                   and
                                                   
                                                   
                                                      
                                                         e
                                                      
                                                      
                                                         ij
                                                      
                                                   
                                                   ∈
                                                   A
                                                
                                             
                                             
                                                
                                                   1
                                                   -
                                                   
                                                      
                                                         
                                                            
                                                               ∑
                                                            
                                                            
                                                               j
                                                               :
                                                               
                                                                  
                                                                     e
                                                                  
                                                                  
                                                                     ij
                                                                  
                                                               
                                                               ∈
                                                               A
                                                            
                                                         
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               ij
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   i
                                                   =
                                                   j
                                                
                                             
                                             
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

As a result, the entropy rate of the random walk on G
                        =(V,
                        A) can be defined as a set function:
                           
                              (13)
                              
                                 H
                                 (
                                 A
                                 )
                                 =
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    
                                       μ
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                       
                                    
                                 
                                 
                                    
                                       p
                                    
                                    
                                       ij
                                    
                                 
                                 (
                                 A
                                 )
                                 log
                                 (
                                 
                                    
                                       p
                                    
                                    
                                       ij
                                    
                                 
                                 (
                                 A
                                 )
                                 )
                              
                           
                        
                     

The entropy rate given in Eq. (13) is a monotonically increasing and submodular function. Its proof can be found in the technical report for [13].

In order to favor the sparse representation of the data from the same class to be similar, a submodular function for enhancing the discriminative power is used together with the entropy rate as the objective function [14]. We first describe the notation set for defining the discriminative function. Let m be the number of object categories. The count matrix 
                           
                              N
                              =
                              [
                              
                                 
                                    N
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    N
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    N
                                 
                                 
                                    N
                                 
                              
                              ]
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    m
                                    ×
                                    N
                                 
                              
                           
                         represents the number of data from each object class associated with each cluster. Let 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    [
                                    
                                       
                                          N
                                       
                                       
                                          1
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                       
                                          N
                                       
                                       
                                          2
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          N
                                       
                                       
                                          m
                                       
                                       
                                          i
                                       
                                    
                                    ]
                                 
                                 
                                    t
                                 
                              
                           
                        , where 
                           
                              
                                 
                                    N
                                 
                                 
                                    m
                                 
                                 
                                    i
                                 
                              
                           
                         denotes the number of objects from the mth class categorized into the ith cluster. Let N
                        A be the number of connected components, and the graph partition for the edge set A be 
                           
                              
                                 
                                    S
                                 
                                 
                                    A
                                 
                              
                              =
                              {
                              
                                 
                                    S
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    S
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    S
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          A
                                       
                                    
                                 
                              
                              }
                           
                        . The class purity for cluster Si
                         is denoted by 
                           
                              P
                              (
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              
                                 
                                    1
                                 
                                 
                                    
                                       
                                          C
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              
                                 
                                    max
                                 
                                 
                                    y
                                 
                              
                              
                                 
                                    N
                                 
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                           
                        , where y is a class label, and 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    y
                                 
                              
                              
                                 
                                    N
                                 
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                           
                         is the sum for objects of all classes associated with cluster i. And hence the total purity for 
                           
                              
                                 
                                    S
                                 
                                 
                                    A
                                 
                              
                           
                         is 
                           
                              P
                              (
                              
                                 
                                    S
                                 
                                 
                                    A
                                 
                              
                              )
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          A
                                       
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          C
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    C
                                 
                              
                              P
                              (
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          A
                                       
                                    
                                 
                              
                              
                                 
                                    1
                                 
                                 
                                    C
                                 
                              
                              
                                 
                                    max
                                 
                                 
                                    y
                                 
                              
                              
                                 
                                    N
                                 
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                           
                        , where C
                        =∑
                           iCi
                        . The discriminative term can be given by:
                           
                              (14)
                              
                                 N
                                 (
                                 A
                                 )
                                 ≡
                                 P
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       A
                                    
                                 
                                 )
                                 -
                                 
                                    
                                       N
                                    
                                    
                                       A
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                N
                                             
                                             
                                                A
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       1
                                    
                                    
                                       C
                                    
                                 
                                 
                                    
                                       max
                                    
                                    
                                       y
                                    
                                 
                                 
                                    
                                       N
                                    
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       N
                                    
                                    
                                       A
                                    
                                 
                              
                           
                        
                     

The item 
                           
                              P
                              (
                              
                                 
                                    S
                                 
                                 
                                    A
                                 
                              
                              )
                           
                         favors clusters with homogenous class labels whilst NA
                         encourages a smaller number of clusters. The proof of its property of submodularity and monotonically increasing is provided in the supplementary material for [14].

The final objective function combines the entropy rate and the discriminative function together to yield compact and class purity clusters. Intuitively, when these cluster centers are utilized as dictionary items, the sparse coding for the data with the same class label tends to be similar. The clustering is achieved by maximizing the objective function 
                           
                              F
                              (
                              A
                              )
                              =
                              H
                              (
                              A
                              )
                              +
                              γ
                              N
                              (
                              A
                              )
                           
                         with respect to the edge set:
                           
                              (15)
                              
                                 
                                    
                                       
                                          max
                                       
                                       
                                          A
                                       
                                    
                                 
                                 H
                                 (
                                 A
                                 )
                                 +
                                 γ
                                 N
                                 (
                                 A
                                 )
                                 
                                 s
                                 .
                                 t
                                 .
                                 
                                 A
                                 ⊆
                                 E
                                 
                                 and
                                 
                                 
                                    
                                       N
                                    
                                    
                                       A
                                    
                                 
                                 ⩾
                                 K
                              
                           
                        where 
                           
                              γ
                              ⩾
                              0
                           
                         weighs the discriminative term. γ is computed by 
                           
                              γ
                              =
                              λ
                              
                                 
                                    
                                       
                                          max
                                       
                                       
                                          
                                             
                                                e
                                             
                                             
                                                ij
                                             
                                          
                                       
                                    
                                    H
                                    (
                                    
                                       
                                          e
                                       
                                       
                                          ij
                                       
                                    
                                    )
                                    -
                                    H
                                    (
                                    φ
                                    )
                                 
                                 
                                    
                                       
                                          max
                                       
                                       
                                          
                                             
                                                e
                                             
                                             
                                                ij
                                             
                                          
                                       
                                    
                                    N
                                    (
                                    
                                       
                                          e
                                       
                                       
                                          ij
                                       
                                    
                                    )
                                    -
                                    N
                                    (
                                    Φ
                                    )
                                 
                              
                           
                        , where 
                           
                              λ
                           
                         is a predefined coefficient and we set 
                           
                              λ
                              =
                              1
                           
                         throughout this paper. As nonnegative linear combination retains submodularity and monotonicity [26], the objective function given in Eq. (15) is also submodular and monotonically increasing.

Although the optimal solution to the maximization of a submodular function is NP-hard, an approximate solution can be achieved by means of greedy algorithm [26]. The algorithm begins with an empty set 
                           
                              A
                              =
                              ∅
                           
                         and iteratively adds edges to the set A. At each iteration, it always chooses the edge that produces the largest gain. The iterative procedure is terminated when the number of connected components reaches a predefined number. The pseudocode of this algorithm is given in Algorithm 2. After the optimization procedure is completed, the cluster centers are employed as the dictionary items.
                           
                              
                                 
                                 
                                    
                                       
                                          Algorithm 2. The greedy algorithm for graph partition.
                                    
                                    
                                       
                                          function 
                                          A
                                          =GraphPartition (
                                             
                                                G
                                                ,
                                                w
                                                ,
                                                K
                                                ,
                                                λ
                                                ,
                                                
                                                   
                                                      N
                                                   
                                                   
                                                      A
                                                   
                                                
                                             
                                          )
                                    
                                    
                                       
                                          
                                          A
                                          ←
                                          ϕ
                                       
                                    
                                    
                                       
                                          
                                          while 
                                          NA
                                          
                                          >
                                          K
                                       
                                    
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      ̃
                                                   
                                                
                                                =
                                                arg
                                                
                                                   
                                                      max
                                                   
                                                   
                                                      A
                                                      ∪
                                                      {
                                                      e
                                                      }
                                                      ∈
                                                      I
                                                   
                                                
                                                F
                                                (
                                                A
                                                ∪
                                                {
                                                e
                                                }
                                                )
                                                -
                                                F
                                                (
                                                A
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                          
                                          
                                             
                                                A
                                                ←
                                                A
                                                ∪
                                                {
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      ̃
                                                   
                                                
                                                }
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                          end while
                                       
                                    
                                    
                                       
                                          end function
                                       
                                    
                                 
                              
                           
                        
                     

In order to speed up the procedure of greedy search, a cycle-free constraint is used to reduce the solution space. That is, the edges that lead to cycles in the graph are not included in A, which arises from the simple fact that these edges take no effect on the graph partition. Moreover, the cycle-free constraint together with the connected component constraint result in a matroid constraint 
                           
                              M
                              =
                              (
                              E
                              ,
                              I
                              )
                              .
                              I
                           
                         is the set of subsets A
                        ⊆
                        E which satisfies: A is cycle-free and the number of connected components from a graph partition constituted by A is more than or equal to K. The greedy algorithm for maximization of a submodular function with a matroid constraint can give a 
                           
                              
                                 
                                    1
                                 
                                 
                                    2
                                 
                              
                           
                         approximation bound on the optimality of the solution [26].

The overall algorithm includes two stages: the graph construction and the graph based clustering. Next we thoroughly analyze the time complexity of the proposed approach and compare it with Submodular Dictionary Learning (SDL) [14]. SDL adopts a brute-force method for graph construction: firstly, all the possible pairwise distances (similarities) are computed, and its time complexity is O(MN
                        2); secondly, the k-nearest neighbors of each data item are selected, and it takes O(N
                        2) time. So the time complexity of the brute-force kNN graph construction is O(MN
                        2). The analysis of the time performance of constructing the approximate kNN graph is relatively complex, and here we only introduce some conclusions. Refer to [23] for more details of the analysis. Its time complexity is 
                           
                              Θ
                              (
                              
                                 
                                    MN
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          g
                                       
                                    
                                 
                              
                              /
                              α
                              )
                           
                        , where tg
                         is the solution to the equation 
                           
                              
                                 
                                    2
                                 
                                 
                                    
                                       
                                          2
                                       
                                       
                                          t
                                       
                                    
                                 
                              
                              +
                              
                                 
                                    α
                                 
                                 
                                    t
                                 
                              
                              =
                              1
                           
                        . tg
                         is monotonically increasing with respect to α. Table 1
                         shows some corresponding values of tg
                         and α. Considering the fact that N is much greater than M for a large-scale data set, we set α
                        =0.05 (tg
                        
                        =1.06) throughout this paper to achieve a fast graph construction. Thus we only need the time complexity Θ(MN
                        1.06) to compute the approximate kNN graph here. It is obvious that the time complexity of constructing the approximate kNN graph is far less than that of the brute-force approach.

As for the graph based clustering, we follow the work of [13,14] and use the lazy greedy algorithm [26] to solve it. We use a max heap structure to store the gain of adding each edge to A. At each iteration, the edge with the maximum gain is popped from the heap and added to A. As this operation affects the gains of some remaining edges in the heap, the heap should be updated to maintain the heap structure. It is important to note that the diminishing return property is helpful to efficiently update the heap. The key idea is that the gain for each edge never increases so that we only need to update the gain of the top element. As the top element of the heap is updated and the value of the other elements can only decrease, the top element is still the maximum value even after the update. In the worst case, we need O(N
                        2log
                        N) to implement the lazy greedy algorithm. However, in practice only a few updates are performed on the heap at each iteration, and hence the time complexity of the clustering is approximately O(Nlog
                        N).

According to the analysis of these two stages, it is obvious that the proposed approach makes a great improvement over SDL on time performance.

Following [14], we also apply a linear classifier to the task of recognition, in which the multivariate ridge regression with the quadratic loss and L
                        2 norm regularization:
                           
                              (16)
                              
                                 W
                                 =
                                 arg
                                 
                                    
                                       
                                          min
                                       
                                       
                                          W
                                       
                                    
                                 
                                 |
                                 |
                                 H
                                 -
                                 WZ
                                 |
                                 
                                    
                                       |
                                    
                                    
                                       2
                                    
                                 
                                 +
                                 η
                                 |
                                 |
                                 W
                                 |
                                 
                                    
                                       |
                                    
                                    
                                       2
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        where W
                        ∊
                        Rm
                        
                        ×
                        
                           K
                         denotes the linear classifier parameters and H
                        =[h
                        1,
                        h
                        2,⋯,
                        hN
                        ]∊
                        Rm
                        
                        ×
                        
                           N
                         denotes the class label of Y, and the nonzero element indicates the class of an input data point within each column [0,⋯,1,⋯,0]
                           T
                        
                        ∊
                        Rm
                        . Eq. (16) has a closed form solution:
                           
                              (17)
                              
                                 W
                                 =
                                 
                                    
                                       (
                                       
                                          
                                             ZZ
                                          
                                          
                                             T
                                          
                                       
                                       +
                                       η
                                       I
                                       )
                                    
                                    
                                       -
                                       1
                                    
                                 
                                 
                                    
                                       ZH
                                    
                                    
                                       T
                                    
                                 
                              
                           
                        
                     

Given a test datum yi
                        , its sparse representation can be computed using Eq. (1), and its label lj
                         is predicted as:
                           
                              (18)
                              
                                 
                                    
                                       l
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 arg
                                 
                                    
                                       
                                          max
                                       
                                       
                                          j
                                       
                                    
                                 
                                 (
                                 l
                                 =
                                 
                                    
                                       Wz
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           
                        
                     

@&#EXPERIMENTS@&#

We conduct our experiments on the UIUC-Sports [29], the Scene15 [30] and the Caltech256 [31] datasets. The UIUC-Sports dataset contains 8 sport event categories: rowing (250 images), badminton (200 images), polo (182 images), bocce (137 images), snowboarding (190 images), croquet (236 images), sailing (190 images), and rock climbing (194 images). The Scene15 dataset is composed of 15 scene categories, and each class has about 200 to 400 images. The Caltech256 dataset contains 30,607 images from 256 categories. There are at least 80 images per category. Compared to the UIUC-Sports and the Scene15 datasets, it is much more difficult due to its large intra-class variability. Some examples from the evaluated datasets are shown in Fig. 3
                        .

Following [29], we select 70 and 60 images per class for training and test in the evaluation on the UIUC-sports dataset, respectively. As for the Scene15 dataset, we use the protocol in [30], where 100 images per class are selected for training and the rest for testing. The Caltech256 dataset is evaluated with a typical setting: 30 images and 25 images per class for training and test. Spatial pyramid feature [30] and its many variants (e.g., [32]) are popular in visual categorization. Undoubtedly, we can use its improved version to enable higher accuracy. However, as we concentrate on the problem of efficient dictionary learning, we still use the original one [30] and reduce it to 3000 dimensions by PCA. K-SVD [6], LC-KSVD [12] and SDL [14] are chosen as the baseline methods for comparison. The sparsity s is set to 30 throughout the experiments. The number of the nearest neighbors in constructing kNN graphs is set to 10. As the training and test samples are randomly selected from these datasets, we repeat the experiments for 10 times and the classification accuracies are reported as the average. The standard deviations are also given together with the accuracies for the proposed approach. All these methods are implemented with C++ and invoked as Matlab mex functions, and the results of running time are obtained on a Ubuntu 12.04 Intel i5 3.2GHz PC with 16GB RAM.

@&#RESULTS@&#

We first investigate the experimental results on the UIUC-sports dataset. Table 2
                      shows the comparative classification accuracies with the dictionary size ranging from 160 to 280. Table 3
                      summarizes the running time for all the compared methods. In Fig. 4
                     , we plot the confusion matrix obtained from our method when the dictionary size is 280. With respect to classification accuracy, the proposed approach and SDL outperform LC-KSVD and K-SVD while our method is comparable to SDL. From Table 3, we can observe that the proposed approach and SDL are several orders of magnitude faster than LC-KSVD and K-SVD. Our method is about 2 times faster than SDL, and the improvement is due largely to that our graph construction is more efficient than that in SDL.

Next we turn our attention to the results on the Scene15 dataset with the dictionary size ranging from 450 to 750. Table 4
                      reports the comparison of classification accuracies for our method and the other baseline approaches. The time consumption is shown in Table 5
                     . Fig. 5
                      shows the confusion matrix produced by our approach when the dictionary size is 750. The proposed approach and SDL make a significant improvement over LC-KSVD and K-SVD on classification accuracy. Similar to the previous experiment, the accuracy difference between our method and SDL is very slight. As the size of the Scene15 dataset is much larger than that of the UIUC-sports dataset, K-SVD and LC-KSVD need more than 20min to construct a dictionary and the running time increases considerably when the dictionary size becomes large. The computational time of SDL and our method remains nearly constant with the variation of the dictionary size. Our method is the most efficient and about 4 times faster than SDL, which reveals that the graph construction is not a trivial task and it is more time-consuming than the clustering procedure when the sample size is relatively large. In Fig. 6
                     , we plot the performance curves with different parameter settings of 
                        
                           λ
                        
                     . We can observe that 
                        
                           λ
                        
                      is not a sensitive parameter for our approach. Hence we use a fixed value (
                        
                           λ
                           =
                           1
                        
                     ) throughout this paper.

Finally we study the results on the Caltech256 dataset. We evaluate our method with different dictionary sizes from 771 to 3855. Table 6
                      summarizes the classification accuracies. We can observe that our method is comparable to SDL and LC-KSVD and these three methods outperform K-SVD. As shown in Table 7
                     , K-SVD and LC-KSVD suffer from an extremely heavy computational load. Our method only needs about 30s to construct a dictionary. Even when compared with SDL, our method provides a remarkable improvement on computational efficiency.

In summary, the promising results demonstrate that the proposed approach finds a balance between precision and efficiency. It can be applied to large-scale data sets due to its excellent time performance.

@&#CONCLUSION@&#

Although dictionary learning has been intensively studied, how to efficiently learn a discriminative dictionary is still a challenging task. To address this problem, we have presented a fast algorithm based on graph partition. We first employ a divide-and-conquer strategy to construct an approximate kNN graph on the data set. And then an efficient greedy-based approach is used to partition the graph by finding a graph topology that maximizes the objective function with the property of submodularity. The experiments conducted on three canonical datasets as well as comparison with some recently proposed approaches demonstrate the efficiency and effectiveness of our method.

@&#ACKNOWLEDGMENTS@&#

This work was supported by the National Basic Research Program of China (973 Program) under Grant 2012CB316400, and by the National Natural Science Foundation of China under Grants 61125106, 61127127 and 61201396.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#SmartFABER: Recognizing fine-grained abnormal behaviors for early detection of mild cognitive impairment

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           SmartFABER is an innovative hybrid activity and anomaly recognition framework.


                        
                        
                           
                           It supports early diagnosis of MCI.


                        
                        
                           
                           It overcomes the shortcomings of purely statistical methods.


                        
                        
                           
                           We experimented SmartFABER with real-world datasets.


                        
                        
                           
                           SmartFABER detects most anomalies producing a small number of false positives.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Mild cognitive impairment

Cognitive decline

Abnormal behavior detection

Activity recognition

Pervasive computing

@&#ABSTRACT@&#


               
               
                  Objective
                  In an ageing world population more citizens are at risk of cognitive impairment, with negative consequences on their ability of independent living, quality of life and sustainability of healthcare systems. Cognitive neuroscience researchers have identified behavioral anomalies that are significant indicators of cognitive decline. A general goal is the design of innovative methods and tools for continuously monitoring the functional abilities of the seniors at risk and reporting the behavioral anomalies to the clinicians. SmartFABER is a pervasive system targeting this objective.
               
               
                  Methods
                  A non-intrusive sensor network continuously acquires data about the interaction of the senior with the home environment during daily activities. A novel hybrid statistical and knowledge-based technique is used to analyses this data and detect the behavioral anomalies, whose history is presented through a dashboard to the clinicians. Differently from related works, SmartFABER can detect abnormal behaviors at a fine-grained level.
               
               
                  Results
                  We have fully implemented the system and evaluated it using real datasets, partly generated by performing activities in a smart home laboratory, and partly acquired during several months of monitoring of the instrumented home of a senior diagnosed with MCI. Experimental results, including comparisons with other activity recognition techniques, show the effectiveness of SmartFABER in terms of recognition rates.
               
            

@&#INTRODUCTION@&#

Independent living and pro-active healthcare are becoming strategic application areas for major research programmes all over the world, considering that the senior population (aged over 65) is projected to double as a percentage over the whole population in the next decades  [1]. Among the most frequent threats to independent living is cognitive decline, whose early symptoms often lead to a mild cognitive impairment (MCI) diagnosis. According to the International Working Group on MCI, there are evidences of subtle differences in performing instrumental activities of daily living (IADLs) among MCI patients compared to both healthy older adults and individuals with dementia  [2]. Other studies [3,4] observed how a closer examination of functional skills in individuals with MCI may enhance our understanding of the natural history and cognitive correlates of functional deterioration associated with dementia. They pointed out the limits of informant-based reports on subject abilities and proposed to extend well known performance evaluation tests (e.g., NAT  [5]) with subtle errors recognition. Hence, from a medical point of view there is a clear interest in methods to monitor daily living activities of the elderly with the goal of identifying specific abnormal behaviors as indicators of cognitive decline.

Ubiquitous computing technologies coupled with intelligent data analysis have a recognized potential in the automatic recognition of IADLs. Indeed, several research projects, and numerous research papers have tried to detect behavioral markers of MCI onset through ubiquitous computing technologies, obtaining a correlation between the predicted and actual cognitive status of the patient. Some of these approaches require the execution of ability tests about the performance of IADLs in an instrumented smart home of a medical institution; hence, they incur in high costs and cannot be applied on a continuous basis. Some of them deploy cameras and sensor networks in controlled environments and use video and audio for activity recognition: these systems are often perceived as too invasive for the elderly's privacy. Other works rely on continuous monitoring of low-level behavioral markers (steps taken, walking speed, …) and trigger alarms whenever they detect situations sufficiently distant from the expected (modeled) behavior.

We have joined this research effort by designing and implementing SmartFABER, a pervasive system for fine-grained abnormal behavior recognition. SmartFABER is intended as a tool for clinicians for analysing the decline of functional abilities, supporting the diagnosis of MCI or even distinguishing between different MCI subtypes. SmartFABER has a sensor network component intended to be installed in the home of the senior and continuously acquiring data. Video and audio acquisition are excluded as too intrusive, while sensors are used to detect presence in particular locations, opening and closing of drawers, fridge and cabinet doors, use of appliances, as well as use of specific tools and food items.

With respect to other activity recognition systems, SmartFABER is designed to go beyond the recognition of the activity being performed by identifying the anomalies that can be observed in carrying out the activity (e.g., inappropriate timing in assuming food or medicine intake, improper use of equipment, unnecessary repetitions of actions). This is a challenging task for at least two reasons: (a) only certain anomalies or patterns of anomalies are relevant indicators for clinicians and they need to be properly modeled based on cognitive neuroscience expertise and (b) most approaches to activity recognition lack the ability to identify the fine-grained anomalies that are of interest to clinicians.

Our main contributions can be summarized as follows:
                        
                           •
                           We describe SmartFABER, a complete pervasive system that can be used by clinicians to identify and analyse even mild functional difficulties in elderly subjects performing daily activities at home;

We explain the technical approach of SmartFABER that combines statistical and knowledge based methods to achieve the fine-grained anomaly detection goal;

We experimentally compare the activity recognition ability of SmartFABER with a state of the art technique proposed in the literature showing its superiority both on a lab-acquired dataset and on a real-home dataset; we also show the improvements in anomaly detection over a preliminary version of our system;

We report on the experience of deploying SmartFABER in the house of a senior diagnosed with MCI with the positive outcome of detecting most targeted anomalies with small number of false positives.

The rest of the paper is structured as follows. Section 2 discusses related work. Section 3 reports our model of activities and abnormal behaviors. Section 4 presents the SmartFABER method. Section 5 reports experimental results. Finally, Section 6 concludes the paper.

@&#RELATED WORK@&#

Activity recognition systems proved to be effective for supporting the diagnosis and improving healthy ageing  [6,7]. In the literature, various strategies have been proposed to devise effective and unobtrusive activity monitoring systems by exploiting pervasive computing technologies  [8]. A popular research direction for activity recognition consists in exploiting audio-visual information recorded by cameras and microphones with the help of sound, image and scene recognition software. Audio data can be used to assess mood and other emotional conditions  [9]. Speech and voice recordings have been used for diagnosis of early-stage dementia  [10]. However, those methods are considered too invasive in a home environment, due to the privacy issues that they determine. Hence, in the following we restrict our attention to non-invasive sensor-based techniques.

Several techniques were proposed to recognize simple activities, which rely on data acquired from body-worn sensors and on the application of supervised learning methods  [11,12]. Early attempts in this sense were mainly based on the use of data acquired from multiple body-worn accelerometers  [13], possibly coupled with biometrical sensors and integrated in clothes  [14], to recognize locomotion types and simple physical activities. A major limitation of these early systems is that they did not consider contextual information, such as current location, environmental conditions, and surrounding objects, that could be usefully exploited to improve the accuracy of recognition. Hence, other activity recognition approaches take into account the user's context by acquiring environmental data from several sensors  [15]. For instance, in  [16] the authors proposed the use of machine learning and data acquired from body-worn sensors (an ear microphone, sensor collar integrating electromyogram and microphone, and four upper body accelerometers) to accurately monitor food intake activities (movement, chewing and swallowing). However, being mainly based on body-worn sensors, those methods are not well suited to recognize more complex activities, like IADLs executed at home, which are characterized by the interaction of the individual with several objects and furniture.

The recognition of complex activities, like ADLs that we consider in our work, relies on the usage of sensors to detect the user's movements and the interaction with objects and furniture. For instance, in  [17], the authors propose a time series data analysis method to segment sequences of sensor events in order to recognize ADLs. The application of Hidden Markov Models inference is proposed in  [18] to recognize activities based on features extracted from recent sensor events according to a sliding window. However, the recognition of complex activities turns out to be challenging using solely supervised learning methods. Indeed, complex activities are characterized by large inter- and intra-personal variability of execution, and it is very hard to acquire a sufficiently comprehensive training set to include most of the possible ways of executing activities. Hence, different frameworks for knowledge representation and reasoning have been investigated to appropriately model complex human activities by means of ontologies. In particular, description logics  [19] have emerged among other symbolic formalisms, mostly because they provide complete reasoning supported by optimized automatic tools.

In  [20], ontological descriptions of activities are used for the segmentation of sensor data streams acquired in a smart home. In particular, a shrinking time window algorithm is proposed to segment temporal sequences of sensor events, in order to discover sequences of events that match the ontological description of a human activity. Our approach is different: we recognize activity instances by aggregating the individual inferences of a machine learning algorithm, considering semantic conditions that the sensor sequence generated by an activity must satisfy. A Web mining technique to derive semantic dependencies among IADLs and used objects is proposed in  [21]; those dependencies are used for activity segmentation. Our segmentation method considers more complex conditions about the necessary sensor events that must be observed during an activity execution. A further method to segment activities based on their semantic description is proposed in  [22]; that method also supports the recognition of overlapped activities. However, as illustrated in  [23], both expressiveness and efficiency issues strongly limit the feasibility of ontological approaches to activity recognition. Moreover, the recognition of some complex activities through ontological reasoning has to start from a set of basic observations (e.g., the user's posture, basic gestures, mode of locomotion); this task requires the use of statistical methods to derive semantic information from raw sensor data (e.g., body-worn accelerometers).

Given the limitations of both statistical and symbolic approaches, a few hybrid activity recognition systems have been proposed in the literature, which vary on the adopted reasoning techniques and on their interaction mechanisms. An interesting instance of those approaches is Markov Logic Networks (MLN)  [24], a probabilistic first-order logic. Given a training set, and a set of probabilistic formulas, with MLN it is possible to learn a weight for each grounded formula by iteratively optimizing a pseudo-likelihood measure. Those weights represent the confidence value of the formula. Deterministic formulas can be added to probabilistic ones to express deterministic knowledge about the domain of interest. Different reasoning tasks can be executed to infer additional information based on formulas and facts. MLN has been used in a previous version of our work  [25]. A similar approach was adopted in  [26] to model and recognize activities at different levels of complexity using probabilistic description logic. Hybrid ontological and statistical reasoning is proposed in  [27] to continuously assess the fall risk of a senior at home, by integrating data acquired from different fall detection systems and environmental sensors. In this work, we propose a hybrid method to recognize the start- and end-time of ADLs based on a combination of supervised learning and knowledge-based conditions to refine the statistical predictions. Moreover, in order to enhance interoperability, we use an OWL 2  [28] ontology to represent the semantics of sensor event types, actions, and complex activities.

Several studies in the neuropsychology research field show that it is possible to distinguish between cognitively healthy adults and cognitively impaired individuals based on subtle differences in their behavioral patterns  [2,29]. For instance, in  [30], subjects were asked to execute a set of predefined IADLs in the observation room of a clinical center, while two cameras recorded their activities. Researchers annotated the dataset manually based on the observation of the video recordings, giving partial scores to the performed activities considering different factors, including activity duration, omitted steps, and number of repeated steps. The partial scores were then aggregated to obtain a comprehensive score, who proved to be effective in distinguishing MCI subjects from Alzheimer's patients, and cognitively healthy seniors from MCI subjects. There is a growing interest in exploiting pervasive computing technologies to automatically capture and measure those differences  [7].

Machine learning methods applied to accelerometer data and video recordings were used in  [31] to distinguish between cognitively healthy seniors and Alzheimer's patients based on activity execution and gait events. Similarly, sensors and video recordings were used in  [32] to distinguish between MCI and Alzheimer's patients. Those methods were applied in controlled environments, while we aim at monitoring the elderly's activities at a fine-grained level at home.

Several European projects have addressed the usage of ICT technologies for enhancing active and healthy aging  [33–35] and for supporting people with dementia at home  [36]. Based on this line of research, different works have proposed to apply machine learning techniques on data acquired in sensor-rich environments, for assessing the cognitive health status of an individual performing a set of ADLs. For instance, motion sensors and contact sensors have been used in  [37] to measure low-level activity patterns, such as walking speed and activity level in the home; results have shown that the coefficient of variation in the median walking speed is a statistically significant measure to distinguish MCI subjects from healthy seniors. A sensor-based infrastructure has been used in  [38] to unobtrusively monitor the execution of IADLs by older adults in a smart-home; the results have shown a significant correlation between the cognitive health status of the subject and the level of assistance that he needs to complete the activities. In the work of Dawadi et al.  [39], patients were invited to execute a list of routines (e.g., write a letter, prepare lunch) inside a hospital smart-home. Different kinds of sensors were used to detect movements inside the home and to track the use of furniture and appliances. Based on data coming from the home sensors, supervised learning methods were used to assign a score to each performed activity; the score measures the ability of the subject to perform the activity correctly. The achieved scores were used to predict the cognitive status of the patient (cognitive health or dementia). The supervised learning approach has been applied in other works, including  [40–42], using several other learning methods. However, while a significant correlation exists between the inferred activity scores and the cognitive health status of the individual, those methods do not provide a description of the observed behavioral anomalies. On the contrary, the medical assessment would benefit from detailed knowledge of the abnormal behavior of the patient. For this reason, in our approach we do not rely on statistical deviations from the “normal” behavior; instead, we aim at recognizing fine-grained anomalies, modeled according to neuroscience experts as possible indicators of MCI, using a hybrid statistical and knowledge-based approach.

A short conference contribution that reports preliminary results of our investigation was presented in  [25]. In this paper we present several additional contributions, including a thorough description of modeling of activities and anomalies, new technical results like the SmartAggregation algorithm that improves significantly the effectiveness of the system, an extensive experimental evaluation of the system with a dataset acquired during several months from the instrumented home of a senior diagnosed with MCI, and an experimental comparisons with other activity recognition methods.

In the aforementioned works, the detection of abnormal behaviors is mostly done on a short-term basis and does not take into account the patient's personal habits. Other works have proposed methods to model the patient's usual behavior from the activities performed in the past and use this model to detect anomalies as changes from his/her usual behavior. In  [43], a method has been proposed to monitor the circadian (24-h) variability of the patient's activities using location sensors and statistical calculations were performed regularly on sensors data to recognize possible deviations in the patient's behavior. In  [44] in-home activities and sleep restlessness were captured using different sensors and a simple alert system was implemented to detect changes in the activity patterns and generate health alerts that were sent to clinicians to be rated for their clinical relevance. These ratings were then used as ground truth in developing classifiers to recognize relevant alerts. In  [45], the authors propose a technique to detect recurrent ADLs patterns, as well as their variations, by mining heterogeneous multivariate time-series from sensor data acquired in a smart home.

Another approach based on temporal data mining was presented in  [46]. Frequently-occurring temporal relationships between activities were extracted from the observed history of sensor events and used to model the probability that a particular event should or should not occur on a given day. A technique based on unsupervised learning is proposed in  [47] to automatically discover ADL patterns and their variations. That technique is coupled with an activity recognition module and with visualization tools to allow practitioners inspecting the trend of activity patterns. Visualization of spatio-temporal data extracted from the long-term observation of elderly's activities at home is used in  [48] to identify potential risk situations.

In our work, we also aim at monitoring the elderly's behavior on the long term. However, as explained before, we do not rely on statistical measures about activity patterns, but we consider specific anomalies modeled by neuroscience experts. As explained in Section 3.2, our framework takes into account the user's profile by customizing anomalies based on personal habits and other contextual factors.

In the following, we explain how we model human activities and fine-grained abnormal behaviors.

In order to model activities, we adopt the multilevel framework proposed in  [26]. We have extended the OWL 2 ontology presented in that work to include complex activities, actions, and sensor event types used in our work. Our SmartFABER ontology is available online
                           1
                        
                        
                           1
                           
                              http://webmind.di.unimi.it/care/smartfaber.owl.
                        . Each IADL consists of a sequence of simple actions. For instance, a patient could perform the IADL “taking medicines” by executing this sequence of actions: open the medicine repository, retrieve the medicine box, return the medicine box, and close the medicine repository. Formally, that activity is represented in our SmartFABER ontology through the following axiom:
                           
                              
                                 
                                    TakingMedicines
                                 
                                 ⊑
                                 
                                    ComplexActivity
                                 
                                 ⊓
                                 ∀
                                 
                                 
                                    hasActor
                                 
                                 .
                                 
                                    
                                       
                                          
                                             Person
                                          
                                          ⊓
                                          ∃
                                          
                                          
                                             action
                                          
                                          .
                                          (
                                          
                                             OpenMedicineRepository
                                          
                                          ⊓
                                          
                                          ∃
                                          
                                             hasOrder
                                          
                                          =
                                          1
                                          )
                                          ⊓
                                          ∃
                                          
                                          
                                             action
                                          
                                          .
                                          (
                                          
                                             RetrieveMedicineBox
                                          
                                          ⊓
                                          
                                          ∃
                                          
                                             hasOrder
                                          
                                          =
                                          2
                                          )
                                          ⊓
                                          ∃
                                          
                                          
                                             action
                                          
                                          .
                                          (
                                          
                                             ReturnMedicineBox
                                          
                                          ⊓
                                          
                                          ∃
                                          
                                             hasOrder
                                          
                                          =
                                          3
                                          )
                                          ⊓
                                          ∃
                                          
                                          
                                             action
                                          
                                          .
                                          (
                                          
                                             CloseMedicineRepository
                                          
                                          ⊓
                                          
                                          ∃
                                          
                                             hasOrder
                                          
                                          =
                                          4
                                          )
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Of course, the same activity can be performed by executing different sequences of actions. For instance, “taking medicines” can be performed by these actions: open the medicine repository, retrieve the medicine box, and return the medicine box (leaving the medicine repository open). Each sequence corresponds to a different axiom in our ontology. Since we concentrate on IADLs, we assume that each action corresponds to a manipulative gesture or other body movement involving an object (e.g., “open the silverware drawer”, “sit on the kitchen chair’).

By fine-grained abnormal behaviors (also called anomalies for short) we define those behaviors, observed during the execution of everyday tasks by a subject, which diverge from the expected ones, according to a given model provided by clinicians. In particular, in this work we consider models of abnormal behaviors that may indicate the onset of MCI, and more generally of a cognitive decline. In order to formally specify those models, we considered previous studies on these indicators [3,4] as well as medical practice results  [49], and we collaborated with cognitive neuroscience experts from the Institute Fatebenefratelli
                           2
                        
                        
                           2
                           IRCCS (Research and Care Institute) St John of God Clinical Research Centre, Brescia – http://www.irccs-fatebenefratelli.it.
                        , Lombardy –a leading center in the field of mental health research and research on neurodegenerative disorders– within the SECURE
                           3
                        
                        
                           3
                           SECURE: Intelligent System for Early Diagnosis and Follow-up at Home, http://secure.ewlab.di.unimi.it/.
                         research project funded by Lombardy region and MIUR Italian ministry.

The anomalies, also called errors in many studies, can be categorized following  [3] as omissions (when they reveal that an action or a sequence of actions composing an activity is not performed), commissions (when actions are performed inaccurately), and additions (when actions unnecessary to complete the current activity are performed). Examples of omissions include “not assuming a prescribed medicine at the prescribed time” or “forgetting to put water when preparing coffee”. Examples of additions include “retrieving milk from the fridge when not needed for lunch preparation”. Commissions include a variety of types of anomalies as shown in Table 1
                        .

The clinicians also required an orthogonal classification of anomalies into critical and non-critical identifying the first category as a stronger indicator of possible MCI onset:
                           
                              •
                              Non-critical anomaly. An anomaly is considered as non-critical when the subject skips a relevant action while performing a IADL, or spends too much time to perform the activity, but still he is able to complete the activity correctly. For instance, we consider a non-critical anomaly to occur when the patient forgets to close a repository after taking something from it (non-critical omission).

Critical anomaly. A critical anomaly occurs when the subject skips some necessary action while performing an activity, forgets to execute a required activity, or performs the activity more times than expected. For example, forgetting to turn on the stove when cooking pasta is a critical omission.

Our term fine-grained refers to the ability of distinguishing each type of anomaly through the identification of single actions and on the analysis of their sequence, frequency and relation to specific activities. We also believe that this is related to the notion of subtle errors investigated in  [4] that proved to be important indicators of early phases of cognitive decline. These errors include specific gestures or manipulation of objects. For example, “Picks up and puts down sugar bowl without using it”.

For the sake of this work, with the help of our medical partners, we have selected a list of fine-grained anomalies related to food preparation, food consumption, and compliance to medical prescriptions covering the whole spectrum of anomaly classification illustrated above. The anomalies are defined in natural language by the clinicians as exemplified in Table 1, taking into account the user's profile: in particular, anomalies are fine-tuned based on the individual's habits (e.g., typical time of food consumption) and other contextual factors (e.g., medical prescriptions). In Section 4.4 we show how the natural language specification is translated in a formal language using computational logic, so that their recognition can be automated based on sensor readings and activity recognition.

In this section, we illustrate the SmartFABER method to recognize fine-grained abnormal behaviors. The overall framework is shown in Fig. 1
                     . The hybrid reasoning framework of SmartFABER, shown in Fig. 2
                     , exploits both statistical and knowledge-based methods. In particular, knowledge-based methods are used by the semantic integration layer to recognize simple events from raw sensor data; by the smart aggregation module to identify activity instances; and by the knowledge-based inference engine to detect the anomalies according to the clinicians’ models. Statistical reasoning, taking into account temporal features, is used to classify events into activities and to recognize activity instances. In the following, we describe in detail the main components of SmartFABER.

A non-invasive sensor network system including environmental, presence, and contact sensors is deployed at the elderly's home. The smart-home monitoring system, running on a mobile device (e.g., a tablet) within the home, collects in real-time the raw sensed events data from the sensor nodes in order to execute the SmartFABER recognition algorithms. The semantic integration layer module is in charge of applying simple inference methods to derive high-level events from raw sensor events. In particular, we adopt rules to express conditions about the type of detected raw events, which determine the recognition of high-level events. Those rules may include conditions about the temporal occurrence of raw sensor events. Consider the example below.
                           Example 1
                           Suppose that the infrastructure includes one presence sensor covering the kitchen table area, and one pressure sensor installed on a chair to detect the weight of the person sitting on it. Then, the following rule is used to detect that the person is sitting on a chair at the kitchen table: “if at time t the presence sensor detects a presence near the kitchen table, and after a short lapse of time (at t′) the pressure sensor detects that a person sits on the chair, then the current event at t′ is sitting on a chair at the kitchen table”.

We define E as the set of all the considered event types (e.g. E
                        = {Door_is_opened, Door_is_closed}). We adopt a simple temporal model for the events. We denote as T the set of all the possible timestamps. A sequence of events is represented as follows:
                           
                              
                                 〈
                                 
                                 ev
                                 (
                                 
                                    E
                                    1
                                 
                                 ,
                                 
                                    t
                                    1
                                 
                                 )
                                 ,
                                 ev
                                 (
                                 
                                    E
                                    2
                                 
                                 ,
                                 
                                    t
                                    2
                                 
                                 )
                                 ,
                                 …
                                 ,
                                 ev
                                 (
                                 
                                    E
                                    m
                                 
                                 ,
                                 
                                    t
                                    m
                                 
                                 )
                                 
                                 〉
                                 ,
                              
                           
                        where ev(E
                        
                           i
                        , t
                        
                           i
                        ) indicates that an instance of the event type E
                        
                           i
                        
                        ∈
                        E occurred at timestamp t
                        
                           i
                        
                        ∈
                        T. A unique timestamp is assigned to each event, based on the time at which the related raw sensor events are received by the central mobile device. In this way we impose a total order on event timestamps 〈
                        t
                        1, t
                        2, …, t
                        
                           m
                        
                        〉.
                           Example 2
                           Formally, the rule expressed in natural language in Example 1 is encoded in propositional logic as follows:


                              
                                 
                                    
                                       ev
                                       (
                                       SitOnChairAtKitchenTable
                                       ,
                                       t
                                       ′
                                       )
                                       ←
                                       ev
                                       (
                                       PresenceAtKitchenTable
                                       ,
                                       t
                                       )
                                          
                                       ∧
                                       ev
                                       (
                                       SitOnChair
                                       ,
                                       t
                                       ′
                                       )
                                          
                                       ∧
                                          
                                       t
                                       ′
                                       ≥
                                       t
                                          
                                       ∧
                                          
                                       (
                                       t
                                       ′
                                       −
                                       t
                                       )
                                       ≤
                                       5
                                       sec
                                       .
                                    
                                 
                              
                           

In this work, we do not adopt ontological reasoning to recognize high-level events. Instead, we use formal ontologies for the sake of interoperability. In particular, event types are represented using our OWL 2 SmartFABER ontology of events, actions, and activities. For instance, the event type sit on chair at kitchen table is defined as follows:
                           
                              
                                 
                                    ETSitOnChairAtKitchenTable
                                 
                                 ⊑
                                 
                                    EventType
                                 
                                 ⊓
                                 ∀
                                 
                                 
                                    hasActor
                                 
                                 .
                                 
                                    
                                       (
                                    
                                 
                                 
                                    Person
                                 
                                 ⊓
                                 ∃
                                 
                                 
                                    hasLocomotion.Sit
                                 
                                 ⊓
                                 ∃
                                 
                                 
                                    hasObject.Chair
                                 
                                 ⊓
                                 ∃
                                 
                                 
                                    hasLocation.KitchenTableArea
                                 
                                 
                                    
                                       )
                                    
                                 
                                 .
                              
                           
                        The sequence of pre-processed events, labeled with their ontological description, is provided to the SmartFABER recognition algorithms.

We define A
                        ={A
                        1, A
                        2, …, A
                        
                           k
                        } as the set of k considered high-level activity classes (e.g.: A
                        ={Preparing Meal, Eating Meal, Taking Medicines}). An instance a of an activity class A
                        ∈
                        A is an occurrence of A during a timespan. Intuitively, a timespan is a particular time interval represented by a start time and an end time, where not every timestamp between the boundaries necessarily belongs to the timespan. This representation allows us to consider activities performed in an interleaved fashion. More formally, we define a timespan ts as a non-convex time interval characterized by a finite set of non overlapping temporal intervals {[x
                        1, y
                        1], [x
                        2, y
                        2]…, [x
                        
                           n
                        , y
                        
                           n
                        ]} where ∀i x
                        
                           i
                        , y
                        
                           i
                        
                        ∈
                        T. Given a timestamp t
                        ∈
                        T and a timespan ts, we say that t belongs to the timespan ts if it belongs to one of its intervals. We denote with 
                           
                              a
                              ts
                              A
                           
                         an instance of the activity class A
                        ∈
                        A occurred during the timespan ts. Given a sensor-equipped environment, an activity instance 
                           
                              a
                              ts
                              A
                           
                         generates a sequence of events that we call “
                           
                              a
                              ts
                              A
                           
                         observations”, formally denoted by 
                           Obs
                           (
                           
                              a
                              ts
                              A
                           
                           )
                           =
                           〈
                           ev
                           (
                           
                              E
                              1
                           
                           ,
                           
                              t
                              1
                           
                           )
                           ,
                           ev
                           (
                           
                              E
                              2
                           
                           ,
                           
                              t
                              2
                           
                           )
                           ,
                           …
                           ,
                           ev
                           (
                           
                              E
                              k
                           
                           ,
                           
                              t
                              k
                           
                           )
                           〉
                        , where ∀i E
                        
                           i
                        
                        ∈
                        E and t
                        
                           i
                        
                        ∈
                        ts. In the following, we explain how activity instances are recognized based on the observation of occurred events.

At each pre-processed event, SmartFABER applies a time-based supervised learning technique to assign the most probable activity class. The classified events are then post-processed in order to identify the most probable activity instances.

The events produced by the Semantic integration layer are communicated to the time-based feature extraction module. For each event ev(E
                           
                              i
                           , t
                           
                              i
                           ), this module is in charge of building a feature vector representing the sequence S of the n most recent events:


                           
                              
                                 
                                    S
                                    =
                                    〈
                                    
                                    ev
                                    (
                                    
                                       E
                                       
                                          i
                                          −
                                          n
                                          +
                                          1
                                       
                                    
                                    ,
                                    
                                       t
                                       
                                          i
                                          −
                                          n
                                          +
                                          1
                                       
                                    
                                    )
                                    ,
                                    …
                                    ,
                                    ev
                                    (
                                    
                                       E
                                       
                                          i
                                          −
                                          1
                                       
                                    
                                    ,
                                    
                                       t
                                       
                                          i
                                          −
                                          1
                                       
                                    
                                    )
                                    ,
                                    ev
                                    (
                                    
                                       E
                                       i
                                    
                                    ,
                                    
                                       t
                                       i
                                    
                                    )
                                    
                                    〉
                                    .
                                 
                              
                           We adopt the feature extraction technique proposed in  [50], since it takes into account temporal aspects, and proved to be effective in recognizing activities based on streams of sensor events. We consider the features listed in Table 2
                           . Some of the features (i.e., from feature 1 to feature 11) measure the number of events happened in S that are related to the usage of a particular object or to the presence in a particular area of the home. When computing the value of those features, we use a weighting factor to fine-tune the contribution of each event in S, so that recent events contribute more than older ones. In particular, we use an exponential function to compute the weight for each ev(E
                           
                              j
                           , t
                           
                              j
                           )∈
                           S based on the time distance between t
                           
                              j
                            and t
                           
                              i
                            (the latter is the most recent event in S):
                              
                                 
                                    w
                                    (
                                    
                                       t
                                       j
                                    
                                    ,
                                    
                                       t
                                       i
                                    
                                    )
                                    =
                                    exp
                                    (
                                    −
                                    χ
                                    (
                                    
                                       t
                                       i
                                    
                                    −
                                    
                                       t
                                       j
                                    
                                    )
                                    )
                                    ,
                                 
                              
                           where the factor χ determines the time-based decay rate of the events. The value of feature F
                           
                              k
                           (S) (with k
                           =1…11) is computed as:
                              
                                 
                                    
                                       F
                                       k
                                    
                                    (
                                    S
                                    )
                                    =
                                    
                                       ∑
                                       
                                          ev
                                          (
                                          
                                             E
                                             j
                                          
                                          ,
                                          
                                             t
                                             j
                                          
                                          )
                                          ∈
                                          S
                                       
                                    
                                    w
                                    (
                                    
                                       t
                                       j
                                    
                                    ,
                                    
                                       t
                                       i
                                    
                                    )
                                    ·
                                    
                                       f
                                       k
                                    
                                    (
                                    ev
                                    (
                                    
                                       E
                                       j
                                    
                                    ,
                                    
                                       t
                                       j
                                    
                                    )
                                    )
                                    ,
                                 
                              
                           where f
                           
                              k
                           (ev(E
                           
                              j
                           , t
                           
                              j
                           )) is the time-independent contribution of ev(E
                           
                              j
                           , t
                           
                              j
                           ) to the computation of the F
                           
                              k
                            value. For instance, when we consider F
                           3 that measures the number of events in S related to the usage of the fridge, the value of f
                           3(ev(E
                           
                              j
                           , t
                           
                              j
                           )) is 1 if E
                           
                              j
                            corresponds to either “open fridge” or “close fridge”; it is 0 otherwise. The feature vector computed based on S is given as input to a supervised machine learning algorithm to infer the most probable class of the activity instance carried out at t
                           
                              i
                           . The algorithm is trained using a dataset of activities and feature vectors.

The next step is to infer the actual activity instances from the output of the machine learning algorithm by grouping together those events which can be considered observations generated by the same activity instance. Intuitively, temporally close events classified with the same activity class are most likely generated by the same activity instance. We first discuss the baseline approach, named naive aggregation. The basic idea of this algorithm is the following: if two consecutive events occurred respectively at t
                           
                              i
                            and t
                           
                              i+1 are classified with the same activity class A
                           
                              i
                           
                           =
                           A
                           
                              i+1, they are considered as observations generated by the same instance of an activity of class A
                           
                              i
                           . Otherwise, they are considered observations generated by different activity instances.


                           
                              Example 3
                              Consider the case illustrated in Table 3
                                 . This table illustrates in the first three columns a sequence of events associated with activity classes predicted by the machine learning algorithm; in the fourth column, the ground truth about activity instances; and in the last column the output of the naive aggregation method. The naive aggregation algorithm produces 5 different instances of activities. However, it is easy to see that this aggregation is not correct. Indeed, the events E
                                 2, E
                                 4 and E
                                 6 share the same activity class and are temporally close. With high probability, the inferred activity classes for the events E
                                 3 and E
                                 5 are mispredictions, since the “Eating meal” and the “Preparing meal” activity instances would have a too short duration. Moreover, consider the case where events E
                                 1 and E
                                 2 correspond respectively with Presence in the kitchen and Open the medicine repository. These two events alone cannot be considered as the only observations generated by an instance of a Taking Medicines activity: the medicine repository can possibly contain items not related with medicines and it is also possible that it may be opened just to check the content. Another issue of this technique is that two consecutive events labeled with the same activity class but temporally distant (like E
                                 6 and E
                                 7) would be grouped together, while they most likely belong to separate activity instances. Hence, the particular sequence of events illustrated in Table 3 should identify a single instance of “Taking medicines” that generated the events from E
                                 1 to E
                                 6.


                           
                              Algorithm 1
                              Smart aggregation 
                                    
                                       
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              


                           
                              Algorithm 2
                              Segmentation of activity instances 
                                    
                                       
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

In order to overcome the limitations of the naive aggregation algorithm, illustrated in Example 3, we refined our recognition method. We introduce for each activity class A
                           ∈
                           A a set of conditions that are necessary for a sequence of events to be considered observations generated by an instance of that class. For example, assuming that the infrastructure includes sensors to detect the stove usage, any instance of the activity Preparing a hot meal should generate some observations related to the usage of the stove. Other examples of conditions may be constraints on the duration of the activity instance or on the number of generated events. Among those conditions, we consider the upper bound about the duration of activity interruptions: the time distance between every pair of consecutive events within the observations generated by an activity instance 
                              
                                 a
                                 ts
                                 A
                              
                            must be lower than maxDelay
                           
                              A
                           . The value of the upper bound maxDelay
                           
                              A
                            depends on the activity class A. Those values are determined statistically; as a result, for example, “Preparing meal” will have a higher maxDelay than “Taking medicines”. Formally, let C
                           (A)
                           ={c
                           1, c
                           2, …, c
                           
                              k
                           } be a set of necessary conditions expressed in logic over a sequence of events that are observations of any instance of a class A
                           ∈
                           A (e.g. {“The sequence of events must last more than 3min”, “The sequence of events must contain an event regarding the usage of the stove”, …}). A sequence of events s
                           =〈ev(E
                           1, t
                           1), ev(E
                           2, t
                           2), …, ev(E
                           
                              k
                           , t
                           
                              k
                           )〉 can be considered as observations generated by an activity instance 
                              
                                 a
                                 ts
                                 A
                              
                            if it satisfies every condition in C
                           (A). The set of conditions for each class are determined after a detailed analysis of the semantics of the activity class and on statistics about the available observations acquired from the sensor infrastructure. For instance, the previously discussed condition about the duration of the interruption of an activity A
                           ∈
                           A over a sequence of events s can be expressed as:
                              
                                 
                                    ∀
                                    i
                                    :
                                       
                                    ev
                                    (
                                    
                                       E
                                       i
                                    
                                    ,
                                    
                                       t
                                       i
                                    
                                    )
                                    ,
                                    ev
                                    (
                                    
                                       E
                                       
                                          i
                                          +
                                          1
                                       
                                    
                                    ,
                                    
                                       t
                                       
                                          i
                                          +
                                          1
                                       
                                    
                                    )
                                    ∈
                                    s
                                    →
                                    (
                                    
                                       t
                                       
                                          i
                                          +
                                          1
                                       
                                    
                                    -
                                    
                                       t
                                       i
                                    
                                    <
                                    
                                       
                                          maxDelay
                                          A
                                       
                                    
                                    )
                                 
                              
                           
                        

We now introduce the smart aggregation algorithm, a refined activity instance recognition method. The pseudo-code is shown in Algorithm 1. The first step of the algorithm is a segmentation over the output of the machine learning algorithm: all the events associated with the same activity class A and temporally close (according to maxDelay
                           
                              A
                           ) are grouped together. For each group g of events classified with an activity class A, it is checked if it satisfies all the conditions in C
                           (A). If all the conditions are satisfied, an activity instance 
                              
                                 a
                                 ts
                                 A
                              
                            that generated the observations contained in g is recognized. All the events contained in those groups which did not satisfy the conditions of their class are considered as mispredictions. Hence, the algorithm tries to include them in one of the activity instances recognized at the previous step. For each misprediction ev(E, t), the algorithm builds a set I of activity instances 
                              
                                 a
                                 ts
                                 A
                              
                            (that have been recognized in the previous step) such that t lies between the boundaries of the timespan ts and 
                              {
                              ev
                              (
                              E
                              ,
                              t
                              )
                              }
                              ⋃
                              Obs
                              (
                              
                                 a
                                 ts
                                 A
                              
                              )
                            satisfies all the conditions in C
                           (A). When |I|>1 we choose the most probable instance based on a function freq, which computes the frequency of an event being an observation of the instances of a particular activity class. The values of freq for each possible combination of event type and activity class are computed offline based on the annotated dataset. The event ev(E, t) is added to the observations of the instance 
                              
                                 a
                                 ts
                                 A
                              
                              ∈
                              I
                           , where A is the most frequent activity class. If I is empty, ev(E, t) is considered an observation of an “other activity” instance.


                           
                              Example 4
                              Continuing Example 3, suppose to apply the smart aggregation algorithm to the same sequence of events considered in Table 3. The fourth column of Table 4
                                  shows the result of the first step of the algorithm, which applies a segmentation based on the predictions of the machine learning algorithm for the occurred events. Four groups are created at this step. The first group g
                                 1, classified as Taking medicines, is formed by the first, second, fourth and sixth events, which are temporally close according to maxDelay
                                 
                                    takingMedicines
                                  and associated with the same activity class. The seventh event does not belong to g
                                 1 since it is not temporally close to the events in that group; hence, it is assigned to another group g
                                 2, together with other subsequent events. The other two groups are g
                                 3, classified as Eating meal and formed by the third event only, and g
                                 4, classified as Preparing meal and formed by the fifth event only. Note that g
                                 3 and g
                                 4 are interleaved with g
                                 1. Then, for each group, the algorithm check if it satisfies the conditions C
                                 (A) for its activity class. Suppose that both g
                                 1 and g
                                 2 satisfy the conditions for Taking medicines; hence, the algorithm creates an activity instances for each of them (TakingMedicines1 and TakingMedicines2, respectively). Then, the algorithm considers g
                                 3 and checks if it satisfies the conditions for Eating meal. Suppose that g
                                 3 does not satisfy the conditions, since it violates the constraint about the minimum temporal duration of Eatingmeal. Hence, the predicted activity class for the third event is considered a misprediction. Since the third event has happened during the timespan of TakingMedicines1, the algorithm tries to include it in that activity instance, and checks if the conditions for Taking medicines are still respected. Suppose that the conditions are respected; hence, the third event is included in TakingMedicines1. Similarly, suppose that the group g
                                 3 (containing the fifth event only) violates the constraint about the minimum temporal duration of Preparing meal. Hence, the activity class Preparing meal associated to the fifth event is considered a misprediction. Supposing that no condition for Taking medicines is violated, the algorithm includes the third event in TakingMedicines1. The predicted instances, which correspond to the actual ones, are reported in the fifth column.

We remind that we denote as “anomalies” the deviations from the “normal” way of carrying out activities. The description of activity modeling in our framework can be found in Section 3.2. Anomalies are described in natural language by cognitive neuroscience experts. In order to automatically reason with anomalies, we represent them in propositional logic. Anomalies are represented by the predicate anomaly(Categ, Obj, Time). Categ defines the category of the anomaly. Obj defines the objects or activities involved in the anomaly; for example, in case of a critical omission, the missed medicine may be the object related to that anomaly. Time defines the time instant at which the anomaly is detected.


                        Table 5
                         shows the representation of a few anomalies. The semantics of not is the one of negation as failure  [51]. Predicate prescribed(m, t
                        1, t
                        2
                        ) states that the patient must take medicine m from time t
                        1 to time t
                        2 of the current day. Medicine(o) (resp. Food(o)) states that object o is a medicine box (resp. food item). Action(a, o, o′, t) states that the patient executed action a on objects o and o′ at time t. Holds(s, o, t
                        1
                        , t
                        2
                        ) states that the status of object o has been “s” from t
                        1 to t
                        2 (for instance, “the microwave oven has been on from 11:30 to 11:55”).

Our SmartFABER OWL 2 ontology includes a taxonomy of food items, objects, and furniture, which is used to instantiate facts in the knowledge base. In particular, food items are classified in those that must be refrigerated, and those that must not. Similarly, cabinets are classified in refrigerated and non-refrigerated ones. For each instance of food item, object, and furniture in the ontology, a corresponding fact is automatically added to the knowledge base. For example, the ontological axiom Milk
                        ⊑
                        RefFood – meaning that all the instances of class Milk are also instances of Food that must be kept refrigerated – is translated in propositional logic to the fact RefFood(milk) and added to the knowledge base. The ontology also includes a class Prescription to store the prescribed medicines, as well as their prescription times. Using the same mechanism explained before, axioms about prescriptions are automatically translated into propositional logic facts and added to the knowledge base.

The Holds predicate allows us to express temporal conditions that are useful in the definition of different anomalies. Temporal expressions that we use in our rule-based definitions include the interval of time during which an action is performed, the temporal distance between two actions, the temporal duration of an activity, the temporal order among activities.

Abnormal behaviors are recognized by the knowledge-based inference engine, which periodically (e.g., at the end of each day) evaluates the rule-based anomaly definitions considering the data acquired and inferred during the considered time period: inferred activity instances and preprocessed events, as well as external knowledge acquired from the OWL 2 ontology, including the medical prescriptions of the patient and the classification of food and objects in categories.
                           Example 5
                           Consider an elderly person living independently at home. Suppose that furniture and devices, including food cabinets and the fridge, are equipped with a magnetic sensor to detect the open and close actions. Bluetooth Low Energy beacons equipped with 3-axis accelerometers are attached to some food boxes (e.g., rice, milk, coffee, sugar boxes) to detect which item has been retrieved or returned. Suppose that at 08:05 AM the patient opens the fridge f and retrieves the milk box m to prepare breakfast. After a few minutes, he mistakenly puts the milk box in the non-refrigerated food cabinet c and closes its door. Hence, based on the sensed events, the following axioms are automatically added to the knowledge base:
                                 
                                    
                                       
                                          
                                             
                                                action
                                                (
                                                
                                                   open
                                                   ,
                                                   door
                                                
                                                ,
                                                fridge
                                                ,
                                                8
                                                :
                                                05
                                                :
                                                00
                                                
                                                AM
                                                )
                                                .
                                             
                                          
                                          
                                             
                                                action
                                                (
                                                retrieve
                                                ,
                                                milk
                                                ,
                                                fridge
                                                ,
                                                8
                                                :
                                                05
                                                :
                                                07
                                                
                                                AM
                                                )
                                                .
                                             
                                          
                                          
                                             
                                                action
                                                (
                                                return
                                                ,
                                                milk
                                                ,
                                                cabinet
                                                ,
                                                8
                                                :
                                                12
                                                :
                                                30
                                                
                                                AM
                                                )
                                                .
                                             
                                          
                                          
                                             
                                                action
                                                (
                                                
                                                   close
                                                   ,
                                                   door
                                                
                                                ,
                                                cabinet
                                                ,
                                                8
                                                :
                                                12
                                                :
                                                35
                                                
                                                AM
                                                )
                                                .
                                             
                                          
                                       
                                    
                                 
                              Since the knowledge base contains the axioms RefFood(milk), and NonRefStorage(cabinet) (stating that cabinet belongs to the class of non-refrigerated storages), Rule 1 in Table 5 fires, recognizing an abnormal behavior.

We have developed a prototype of SmartFABER, and we have extensively evaluated our techniques with two large datasets of both normal and abnormal behaviors: one acquired in a smart home lab with actors simulating the daily routines of 21 patients, and one acquired during three months of experimentation in the home of an elderly diagnosed with MCI.

A prototype implementation of the whole system has been developed within the activities of the SECURE project. Since the SmartFABER system is intended to run on a mobile device at the patient's home, the core software modules have been implemented in Java for the Android platform. Fig. 3
                         shows the application running the SmartFABER software. In particular, in order to implement the technique for activity recognition we have used the machine learning libraries of Weka.
                           4
                        
                        
                           4
                           
                              http://www.cs.waikato.ac.nz/ml/weka/.
                         In order to evaluate the rule-based definitions of anomalies we used the APIs of TuProlog  [52], a lightweight Java implementation of an inference engine for the well-known Prolog logic programming language.

For this prototype, we use sensor motes available on the market, which communicate using the ZigBee protocol. Since currently there is no standard interface for that protocol on most Android devices, we use a gateway installed in the home to receive ZigBee messages from sensors and forward them via Bluetooth to the Android device. Sensor motes have been programmed in the C++ language to communicate new data to the gateway at the occurrence of each sensor event. For instance, the pressure sensor attached to the kitchen chair seat communicates the measured pressure when it exceeds or falls behind given thresholds, to detect when the patient stands up or sits down on the chair. Such thresholds have been determined empirically. The sensor event message includes the timestamp of the sensor reading, the sensor ID and the detected value. A C++ application running on the gateway is in charge of: receiving data from sensors, assigning the unique timestamps, locally storing the data in a PostgreSQL database, and periodically communicating the data to the Android application. At the end of each day, the Android app runs the SmartFABER algorithms for activity boundary detection and anomaly recognition, and communicates the results through the Internet to the backend of the hospital center, where the data are stored.

We have also developed a Web-based dashboard, shown in Fig. 4
                        , to allow practitioners analyzing the history and trends of IADLs as well as the anomalies’ history.

We experimented our method using two datasets; one acquired in a smart home laboratory, and one acquired in the instrumented home of a senior with an MCI diagnosis.

We have acquired a dataset of IADLs and anomalies, asking to voluntary actors to reproduce the daily routine of 21 elderly persons in our smart home lab. Executed IADLs and anomalies have been carefully designed in collaboration with neuroscience experts to realistically mimic the behavior of two groups: 7 healthy seniors (group 1), and 14 elderly persons with early symptoms of MCI (group 2). We assume that individuals of both groups live alone and independently in their respective homes. During their one-day routine, individuals in group 1 do not execute any critical anomaly, but may execute a few non-critical ones. Individuals in group 1 are mainly used to evaluate the number of false positives produced by our anomaly recognition method. Group 2 individuals may perform several non-critical and critical anomalies during the day.

During the execution of the daily routines, we have acquired the timestamped data coming from the sensors deployed in the smart home (Fig. 5
                           ) and manually annotated the dataset with the start- and end-time of specific activities and anomalies. The following IADLs have been selected to validate our method:
                              
                                 •
                                 Preparing food: the patient has to prepare the daily meals (breakfast, lunch, dinner) at appropriate times.

Consuming meal: when the patient prepares a meal, he has to consume it within a reasonable time period.

Taking medicines: the patient has to take the prescribed medicines in the due time. We assume that no smart dispenser is used; instead, we assume that the patient keeps all the medicines in a dedicated cabinet.

Non-critical anomalies. They happen when the individual: (NC1) forgot a repository open; (NC2) did not return a medicine to its cabinet; (NC3) retrieved a food item which must be cooked, but did not use the stove burner; (NC4) does not prepare a meal.

Critical anomalies. They happen when the individual: (C1) did not retrieve a prescribed medicine in the due time; (C2) took a medicine that was not prescribed; (C3) took a prescribed medicine in the due time but multiple times, resulting in inappropriate dosage; (C4) did not turn off the stove burner after finishing to prepare a hot meal; (C5) did not take the silverware before consuming meal; (C6) did not consume the meal after having prepared it; (C7) turned the stove burner on but did not take any cooking pan.

As a first step towards the evaluation of our methods in the actual home of elderly persons, we took advantage of our cooperation with a medical institution and a tele-medicine company as partners of the SECURE project, and deployed our prototype inside the home of an elderly woman aged 74, with a diagnosis of MCI and medical co-morbidities, who lives alone. We will call her Mary in the following. Fig. 6
                            shows part of the deployed sensors. Details about the technical implementation of the system in Mary's home are reported in  [53].

We acquired a dataset consisting of 55 days of IADLs performed by Mary. In that period of time, we collected data for about 200 instances of activities. We considered the same type of IADLs as for the smart home lab dataset. For this experimentation, the clinicians provided us with a set of fine-grained abnormal behaviors to be detected, together with Mary's time prescriptions for meals (i.e., breakfast, lunch, and dinner) and medicines intakes. These anomalies are divided in three levels of seriousness:
                              
                                 •
                                 Green anomalies (low level). This type of anomalies occur when the individual: prepares (G1) or consumes (G2) a meal at a different time than prescribed.

Yellow anomalies (medium level). This type of anomalies occur when the individual: misses to consume (Y1) or prepare (Y2) a meal; takes a prescribed medicine outside the prescribed time (Y3); consumes (Y4) or prepares (Y5) the same meal multiple times during the same day.

Red anomalies (high level). This type of anomalies occur when the individual: does not take a prescribed medicine (R1); takes a medicine that was not prescribed (R2).

For the sake of this project, it was not feasible to directly observe the execution of the activities, except for limited periods of time during the setup of the system, due to obvious privacy reasons. Hence, we manually labeled most of the activities offline, based on the observation of raw sensor data; this was possible since the considered activities are relatively easy to distinguish by a human observer based on the collected sensor readings. We labeled the anomalies by executing their respective rule-based definitions on the dataset of sensor events and labeled activities.

Recognizing the activity being performed and the (possibly approximate) activity boundaries is a prerequisite to detect anomalies. For both datasets, we implemented and compare the following activity recognition techniques:
                           
                              •
                              The method used in FABER, which was based on Markov Logic Network (MLN)  [54];

The machine learning algorithm used in SmartFABER with the naive aggregation algorithm;

The machine learning algorithm used in SmartFABER with the smart aggregation algorithm;

A different approach for activity recognition based on Hidden Markov Models.

For each technique, we performed a leave-one-day-out cross-validation, evaluating the prediction's quality in terms of the standard measures of precision, recall and F
                        1 score (the latter is the harmonic mean of precision and recall). In the following we explain how these measures are computed.

Each predicted activity instance 
                           
                              a
                              ts
                              A
                           
                         is characterized by three parameters: the class A of the activity, its start time t
                        
                           s
                         (i.e., the initial timestamp of ts), and its end-time t
                        
                           e
                         (i.e., the last timestamp of ts). For each prediction 
                           
                              a
                              ts
                              A
                           
                        , we count a true positive (TP) when an activity instance of type A actually started in a neighborhood of t
                        
                           s
                        ; i.e., between t
                        
                           s
                        
                        −
                        α and t
                        
                           s
                        
                        +
                        α. For the sake of these experiments, we set α to 15min; indeed, in order to recognize the addressed anomalies, it is sufficient to know the approximated boundaries of activity instances. In the other case, we count the prediction as a false positive (FP). Finally, for each activity instance of type A that actually started at t we count a false negative (FN) when no prediction exists for an activity of class A having its start-time in a neighborhood of t. Similarly, we count TP, FP and FN for the end-time of predictions and actual activity instances. Precision, recall and F
                        1 scores are computed as follows:
                           
                              
                                 precision
                                 
                                 p
                                 =
                                 
                                    TP
                                    
                                       TP
                                       +
                                       FP
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 recall
                                 
                                 r
                                 =
                                 
                                    TP
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    F
                                    1
                                 
                                 =
                                 
                                    
                                       2
                                       ·
                                       p
                                       ·
                                       r
                                    
                                    
                                       p
                                       +
                                       r
                                    
                                 
                              
                           
                        
                     

We preliminarily performed cross-validation to select the most appropriate classifier for the machine learning module of SmartFABER considering the available datasets. As a result, we chose to use a Random Forests classifier  [55].

We first report the results of the experimental evaluation of the first three methods since they represent the progressive refinement of our approach. In particular, FABER was proposed in  [25] but experimental results were never presented in detail.

Since the anomaly recognition technique relies on detected activity boundaries, the FABER and SmartFABER algorithms require the preliminary step of experimentally choosing the value of parameter n, corresponding to the length of the temporal sequence of sensor events to be used. The results of activity boundary recognition on the smart home lab and real home datasets are shown in Figs. 7 and 8
                           
                           , respectively. With the smart home lab dataset, very positive results have been achieved (with F
                           1 score that exceeds 0.96) with all the three considered methods. With the MLN-based technique used in FABER, the highest recognition rate is achieved with n
                           =3. This means that, with this dataset, the temporal sequence of the 3 most recent sensor events is sufficient to reliably detect the start or end of an activity. This is due to the quite repetitive way in which activities have been executed in the lab; longer sequences of sensor events may be needed when activities are executed in more variable ways. Values of n lower than 3 produce worse results, while larger values strongly increase the execution times of the learning phase, without increasing recognition rates. With the new boundary detection method used in SmartFABER, the highest recognition rates are achieved using with n
                           =2 or n
                           =3. The naive aggregation and the smart aggregation methods achieve similar recognition rates; however, the former produces a larger number of false positives (i.e., detection of activity instances that did not actually occur), which may result in the recognition of several anomalies (especially repetitions of activities) that did not actually happen. On the contrary, the smart aggregation method provides more balanced and slightly higher values of precision and recall.

In general, with the real home dataset we achieve lower recognition rates. This is due to the intrinsic variability of activity execution in a real-world situation, with respect to the relatively stable activity execution patterns reproduced in the smart home lab. Moreover, the level of sensor noise due to missing or incorrect sensor readings is inevitably larger in a real home environment than in the lab. With the real home dataset, the MLN-based method used in FABER is the least effective among the ones that we evaluated. The highest recognition rates with MLN are achieved with n
                           =5. We were not able to test the performance with larger values of n, since the execution of the learning algorithm did not terminate in a reasonable amount of time. Independently from the value of n, the FABER method achieved particularly low values of recall; this could result in the detection of several false anomalies related to missed execution of expected activities. The technique used in SmartFABER achieves better results. In particular, the smart aggregation method leads to the highest values of F
                           1 score (slightly above 0.8 with n
                           =4), and very well balanced values of precision and recall. The naive aggregation method achieves lower recognition rates, producing a large number of false positives.

Summarizing, with both datasets, the smart aggregation algorithm of SmartFABER reduces the number of false positives with respect to the FABER method, and improves the overall accuracy.

In order to compare our activity recognition method with a well-known technique, we implemented the method proposed by Van Kasteren et al.  [18]. That method is based on the usage of Hidden Markov Models (HMMs)  [56]. HMMs are generative probabilistic models consisting of a temporal sequence of hidden variables and observable variables. The general structure of HMMs is shown in Fig. 9
                           . A hidden variable at time t, named x(t), depends only on the hidden variable at time t
                           −1 (named x(t
                           −1)). An observable variable at time t, named y(t), depends only on the hidden variable x(t). In our case, the observable variable y(t) corresponds to the observations of the occurrences of sensor events during t, while the hidden variable x(t) corresponds to the class of the activity instance performed during t.

HMMs are specified using three probability distributions:
                              
                                 •
                                 The probability distribution over initial hidden states;

The probability distribution of transitions among hidden states;

The probability distribution of an hidden state x(t) generating an observation y(t).

Those distributions are estimated using an annotated dataset. Thanks to this model, the prediction of an activity at t depends not only on the current observations, but also on the activity predicted at the previous time slice t
                           −1. Applying the method proposed in  [18], the temporal sequence of sensed events is divided into time slices of constant length (60s). The sensor events occurred during the time slice t are represented by a binary feature vector 
                              
                                 
                                    
                                       F
                                       ¯
                                    
                                 
                                 t
                              
                              =
                              〈
                              
                                 F
                                 
                                    
                                       E
                                       1
                                    
                                 
                              
                              ,
                              …
                              ,
                              
                                 F
                                 
                                    
                                       E
                                       m
                                    
                                 
                              
                              〉
                           , in which every event type E
                           
                              i
                           
                           ∈
                           E corresponds to a feature 
                              
                                 F
                                 
                                    
                                       E
                                       i
                                    
                                 
                              
                            (we remind that E is the set of all the considered event types). Among different feature extraction methods, the most effective proved to be the following:
                              
                                 •
                                 
                                    Change point: The value of the feature F
                                    
                                       E
                                     at t is 0 if no instances of the event type E occurred during t; it is 1 otherwise.


                                    Last: The value of the feature F
                                    
                                       E
                                     at t is 1 if the type of the most recent event occurred within or before t is E; it is 0 otherwise.

The above feature extraction methods can be combined to obtain the Change point+last method, in which feature vectors are built by concatenating the vectors obtained using the change point and the last representations.


                           
                              Example 6
                              Consider three event types: E
                                 1, E
                                 2 and E
                                 3. The following tables show a possible event sequence and the corresponding time slices representations.

Inferencing to derive the most probable sequence of hidden states generated by the sequence of observations is performed by applying the well known Viterbi algorithm  [56]. In order to identify the boundaries of the activities instances, we applied a segmentation of the time slices considering the predicted hidden states: consecutive time slices classified with the same activity class are considered as part of the same instance. A leave-one-day-out cross-validation was performed on both datasets in order to obtain the measures of precision and recall. The comparison with SmartFABER using smart aggregation and n
                           =3 is shown in Tables 6 and 7
                           
                           .

The results show that, with both datasets, SmartFABER achieves better values of precision and recall than the HMM-based technique, with all the three feature extraction methods. In particular, with the smart lab dataset, the improvement in the recall rate obtained by SmartFABER is very relevant (i.e., from 0.925 to 0.989). The precision rate also improves consistently (i.e., from 0.929 to 0.957). This trend is confirmed with the real home dataset.

We performed experiments about anomaly recognition using the activity boundaries detected by the different techniques with the most effective value of n.

Detailed results with the smart home lab dataset are shown in Tables 8 and 9
                        
                        . The results of SmartFABER with the naive aggregation method are identical to the ones obtained with the smart aggregation method; hence, we omit them. Each row of the table corresponds to a specific anomaly considered in our experiments. The TP column reports the number of true positives for that anomaly; i.e., the number of actual occurrences of that anomaly that were recognized by the technique. FP reports the number of false positives; i.e., the number of anomalies reported by the technique that did not actually occur. FN reports the number of actual occurrences of that anomaly that were not recognized by the technique.

As anticipated, group 1 individuals performed a few non-critical anomalies (NC) and no critical anomaly (C). FABER correctly recognized 5 NCs out of 7. During the 7 days activities of group 1 individuals, the system did 4 false positives. Two of them regarded NC4 (meal not prepared), while the other two regarded C1 (missed a prescribed medicine). Those errors were due to mispredictions of the MLN-based activity boundary detection technique, which in two cases did not recognize the occurrence of activity “preparing meal” and in two cases did not recognize the occurrence of “taking medicine”. With SmartFABER we were able to avoid the occurrence of both false positives and false negatives. This result was due to the high accuracy of activity recognition in the smart home lab environment.

Group 2 individuals performed a larger number of NCs and several Cs. For this group, FABER correctly recognized all the occurrence of both critical and non-critical anomalies; i.e., no false negatives happened. During the 14-days activities of that group, the system reported only 2 false positives: one was related to NC4 (meal not prepared) and the other one to C6 (prepared meal not consumed). Even in these cases, false positives were due to mispredictions of the activity boundary detection technique. The performance of SmartFABER was comparable: all the anomalies were recognized, and only two false positives occurred.

Overall, FABER produced 6 false positives during the 21-days activities, while SmartFABER produced only 2 false positives. We claim that the number of false positives is compliant with the requirements of clinicians, especially considering that the individuals totally performed more than 150 instances of activities during the experimentation. Table 10
                         summarizes the results in terms of precision, recall and F1 score.

Results regarding the real home dataset are shown in Tables 11, 12, and 13
                        
                        
                        , and summarized in Table 14
                        . The SmartFABER method with smart aggregation achieves the best results in terms of F
                        1; moreover, the measures of precision and recall are well balanced. Those measures are less balanced using the naive aggregation method, which achieves high recall (only a few actual anomalies were not recognized) at the price of low precision (several anomalies have been predicted by mistake). This result depends on the fact that the naive aggregation method produces a relatively large number of false positives, which fire the recognition of several anomalies about repetition of activities (Y4 and Y5). The F
                        1 results with FABER and the MLN-based method are comparable with those of SmartFABER with naive aggregation, but precision and recall are better balanced with the former.

Overall, we can conclude that SmartFABER with smart aggregation achieves the best results in terms of F
                        1, obtaining a good balance between precision and recall. A preliminary clinicians’ assessment of our system can be found in  [53].

@&#CONCLUSIONS AND FUTURE WORK@&#

In this paper, we addressed the challenging issue of unobtrusively recognizing behaviors exhibited by elderly persons at home that have been identified by clinicians as relevant for the early diagnosis of MCI. Our SmartFABER hybrid technique to recognize abnormal behaviors differs from previous approaches for combining supervised learning with knowledge-based reasoning to more precisely recognize specific anomalies in carrying out daily living activities. We designed the models of anomalies collaborating with cognitive neuroscience experts. Hence, instead of identifying only generic deviations from normal behavior as most related works do, we provide clinicians with a fine-grained description of the recognized abnormal behaviors identified as indicators of MCI.

Of course, human behaviors are characterized by wide variability; factors such as contextual conditions, individual habits and personality traits may determine the execution of various anomalies that are not necessarily due to cognitive impairment. This is especially true for non-critical anomalies, as leaving repositories open, which may be normally done by cognitively healthy people for negligence or hastiness. Hence, while the considered anomalies are indicators of possible abnormal behaviors, they are not intended to provide an automatic diagnosis of the patient's cognitive status, especially when they occur in isolation. For instance, the fact that the subject has taken a medicine that was not prescribed is critical if he does it unintentionally (e.g., for a memory disorder). In other cases it may be a normal behavior; e.g., if the patient intentionally takes an over-the-counter drug that does not interfere with his medical prescriptions. Therefore, our system is not intended to provide a diagnosis hypothesis, but simply as a powerful data analysis tool at the service of practitioners reporting the type, frequency, correlation and temporal trend of detected anomalies. By joining this information with other methods and with the subject profile and therapy, it is also possible to set personalized trigger alarms.

We implemented a prototype of the system in both a smart home lab and in the real home of an elderly person. Experiments with datasets of activities and anomalies show that SmartFABER achieves high recall while generating a small number of false positives.

The achieved results are promising, but we plan to improve this work in several directions. Our current anomaly recognition method is based on logic rules that strictly determine the detection of an abnormal behavior based on a user-defined set of observations. We consider extending this rigid system with probabilistic reasoning. We are working on integrating data analysis tools in the dashboard offered by the system to clinicians to automatise some of the reasoning that they currently do by looking at long term activity data. Other future work also includes addressing the case of multi-inhabitants. Finally, we plan to work closely with clinicians to extend the set of activities and associated significant anomalies to be monitored, and to extend the experiments to multiple real homes.

@&#ACKNOWLEDGEMENTS@&#

This work has been partially supported by the project “SECURE: Intelligent System for Early Diagnosis and Follow-up at Home”, funded by a grant of Lombardy Region and Italian Ministry of Education, University and Research.

@&#REFERENCES@&#


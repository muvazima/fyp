@&#MAIN-TITLE@&#Thickness related textural properties of retinal nerve fiber layer in color fundus images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A texture analysis approach for assessment of the retinal nerve fiber layer thickness in color fundus images.


                        
                        
                           
                           Suitable for computer-aided diagnosis of glaucoma.


                        
                        
                           
                           Advanced texture analysis methods – local binary patterns and Gaussian Markov random fields.


                        
                        
                           
                           Results compared to measurements provided by optical coherence tomography.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Glaucoma

Retinal nerve fiber layer

Texture analysis

Fundus images

Local binary patterns

Markov random fields

@&#ABSTRACT@&#


               
               
                  Images of ocular fundus are routinely utilized in ophthalmology. Since an examination using fundus camera is relatively fast and cheap procedure, it can be used as a proper diagnostic tool for screening of retinal diseases such as the glaucoma. One of the glaucoma symptoms is progressive atrophy of the retinal nerve fiber layer (RNFL) resulting in variations of the RNFL thickness. Here, we introduce a novel approach to capture these variations using computer-aided analysis of the RNFL textural appearance in standard and easily available color fundus images. The proposed method uses the features based on Gaussian Markov random fields and local binary patterns, together with various regression models for prediction of the RNFL thickness. The approach allows description of the changes in RNFL texture, directly reflecting variations in the RNFL thickness. Evaluation of the method is carried out on 16 normal (“healthy”) and 8 glaucomatous eyes. We achieved significant correlation (normals: ρ
                     =0.72±0.14; p
                     ≪0.05, glaucomatous: ρ
                     =0.58±0.10; p
                     ≪0.05) between values of the model predicted output and the RNFL thickness measured by optical coherence tomography, which is currently regarded as a standard glaucoma assessment device. The evaluation thus revealed good applicability of the proposed approach to measure possible RNFL thinning.
               
            

@&#INTRODUCTION@&#

Glaucoma is one of the most common causes of permanent blindness worldwide. Quigley [40] introduced a model of glaucoma prevalence showing that there are 60.5 million people with glaucoma in 2010, which will increase up to 79.6 million in 2020. One of the glaucoma symptoms is progressive atrophy of the retinal nerve fiber layer (RNFL) resulting in permanent decrease of the layer's thickness. Glaucoma symptoms appear many years before the patients are able to observe any changes in their visual field. Therefore, it is extremely desirable to detect the disease as soon as possible. Generally, glaucoma diagnosis is currently based on evaluation of the optic nerve head (ONH) morphology and the RNFL thickness in the peripapillary area (area surrounding the ONH) [20]. Many ophthalmologists still use ophthalmoscope or fundus camera to evaluate the retina only visually. Nevertheless, such a qualitative diagnostic is subjective and barely reproducible. Optical coherence tomography (OCT) is recently regarded as a standard glaucoma diagnostic device, since it provides a straightforward measurement of the RNFL thickness; thus allowing to make diagnostic procedures well reproducible. Unfortunately, OCT examinations are still quite expensive and not generally available at many ophthalmic clinics around the world. In contrast to OCT, fundus imaging is still considered as a fundamental diagnostic tool, since it allows much faster and cheaper image acquisition.

Fundus images (Fig. 1
                     ) are successfully used for diagnosis of various eye and even systemic diseases, e.g. various retinopathies, diabetes, hypertension, arteriosclerosis, age-related macular degeneration, or glaucoma; by evaluation of different retinal features and diagnostically interesting structures (Fig. 1a) [13]. The RNFL can be observed as a bright striped pattern that appears on the background of red-free fundus photographs (Fig. 1). It is assumed that the pattern changes its visual appearance according to variations in the RNFL thickness. This has been already proven by several studies, although so far evaluated by subjective methods only [42,14,33]. The thickness variations can be caused by glaucoma process, or even in the healthy retina, the RNFL thickness varies anatomically depending on angular position around the ONH. These aspects bring an idea to analyze these RNFL changes via advanced image processing methods. Thus, fundus imaging can provide new useful and easy-to-access information about the RNFL structure to aid glaucoma assessment, optionally also in connection with other features that can be derived from fundus images (C/D ratio or GRI – glaucoma risk index) [3].

Several scientific papers concerning assessment of RNFL status in fundus photographs have been already published by different authors. An attempt to utilize fundus camera for evaluation of the RNFL has been first introduced by Lundström et al. in the 1980 [21]. Black-and-white photographs were used for subjective evaluation of the RNFL textural appearance. Then, other authors have been investigating analog photographs in a more or less similar way [35,44,7,18]. Peli et al. [35] performed one of the first semi-automatic analysis of the RNFL texture using digitized black-and-white fundus photographs. They analyzed intensity information about the RNFL presence and tried to detect darkening caused by the RNFL atrophy. Only 5 images of normal subjects, 5 images of glaucomatous subjects, and 5 images of subjects suspected of glaucoma were included in this study. Tuulonen et al. [44] performed microtexture analysis of images of 7 normal subjects, 9 subjects with distinctive glaucoma damage, and 8 subjects with higher intraocular pressure (suspicious of glaucoma). Digitized fundus photographs with 1280×1024 pixels were analyzed. The hypothesis that changes in the RNFL structure can be seen as changes in the microtexture of digital images has been investigated. Although they achieved some positive results, the differences were not statistically significant because of small sample size. Recently, an intensity information about the RNFL texture was utilized by Dardjat et al. in [7]. The authors evaluated intensity differences in the RNFL texture along the intensity profiles between two concentric circles placed in center of the ONH. Other contribution also utilizing intensity criterion was published by Lee et al. [18]. A pilot study to search for RNFL thinning in color fundus images with size of 2256×2032 pixels was presented by Oliva et al. [33]. They presented a semi-automatic method to texture analysis based on evaluation of the RNFL intensity along 24 concentric circles centered in the ONH. Only small datasets of 9 images of normal and 9 images of glaucomatous subjects were tested. The results revealed correlation only 0.424 between the intensity-related parameters extracted from fundus images and the RNFL thickness measured by OCT.

In the case of glaucomatous damage, the RNFL appears darker in comparison with the healthy areas in fundus image. Hence, many authors try to involve only the intensity criteria for detection of glaucomatous changes, even in the recent state in this field of applied research [12,27,39,1]. Hayashi et al. [12] used an approach with Gabor filters to enhance certain regions with the RNFL pattern and to classify these regions toward glaucoma detection. The paper presents preliminary results that were followed up by the same group in [27] (Muramatsu et al.). In comparison with their preliminary approach, the authors extended the proposed concept and carried out evaluation of the method using a larger dataset (81 images of each normal and glaucomatous subjects). However, these images have size of 768×768 pixels, which is still relatively low resolution to provide enough texture information about the RNFL. Detection of thin focal or even diffuse RNFL losses is not possible due to low resolution. Thus, the method is suitable only for detection of focal and even wider RNFL losses expressed by significant changes in image intensity. However, in spite of some lacks, this publication first presented a fully automatic method for the RNFL assessment that was evaluated using a rather large dataset. Prageeth et al. [39] published a method for glaucoma detection using intensity criterion as well. They analyzed a dataset consisted of 829 (300 normals and 529 glaucomatous) fundus images with size of 768×576 pixels. Although, the results were promising, utilization of intensity criteria used alone is probably not a good solution. Intensity changes in the RNFL pattern can be detected only if the RNFL atrophy is so distinctive than the patient has rather large vision loss already. Moreover, image intensity can be influenced by many factors, e.g. non-homogenous illumination, reflection of the retina, light power used for acquisition, etc. Acharya et al. [1] proposed a method to analyze the RNFL texture using higher order spectra, run-length and co-occurrence matrices. The method was tested on 60 images (30 normals and 30 glaucomatous). However, the images had a size still too small (560×720 pixels). The authors used several supervised classification techniques to classify normal and glaucomatous images. Although, the classification accuracies were more than 80%, the article does not thoroughly explain the process of feature extraction and which area of the image was analyzed. Moreover, the images presented in the paper seem to be of rather low quality and the RNFL texture is not visible.

The diagnostic potential of current fundus images increases, since their quality and resolution are still getting better. The RNFL pattern is thus well recognizable in these high-resolution fundus images and it offers a possible use of advanced texture analysis techniques taking into account not only the intensity criteria, but also various spatial characteristics of adjacent pixels in the RNFL texture. Hence, as an addition to the state of the art, we have contributed with several advanced texture analysis methods for assessment of the RNFL status in color fundus images and published this work in several papers [16,28,30,31]. However, as presented in these earlier papers, the methodology was focused mainly on detection of the RNFL presence and classification of the texture roughly into two binary classes – RNFL and non-RNFL using red-free fundus images. Now, we came out from our previous approaches utilizing Gaussian Markov random field (GMRF) texture modeling and local binary patterns (LBP) and extended the potential of these advanced methods to capture continuous variations in the RNFL thickness via different regression models. The main contribution to the recent state of the art is the ability of the proposed methodology to predict the RNFL thickness using commonly available color fundus images. Furthermore, the proposed approach is evaluated using the RNFL thickness measured via OCT as a gold standard modality.

@&#MATERIAL AND METHODS@&#

The dataset has been created on the basis of cooperation with the Eye clinic at the Erlangen University Hospital, Germany. The dataset so far contains 16 image sets of healthy subjects without any signs of glaucoma disease and 8 image sets of glaucomatous subjects with the focal wedge-shaped RNFL loss. Only one eye of each subject was imaged. Each image set contains an image acquired by the common non-mydriatic digital fundus camera CANON CR-1 (EOS 40D) with 60-degree field of view (FOV). The images have size of 3504×2336 pixels, which is a common resolution for many current fundus cameras. Standard CANON raw data format (CR2) was used for storage of the images.

The image set then contains three-dimensional volume data, which were acquired by spectral domain OCT system (Spectralis HRA – OCT, Heidelberg Engineering) for each of the 24 subjects. Infrared reflection images (scanning laser ophthalmoscope, SLO) and OCT B-scan images of the dual laser scanning system were acquired simultaneously. From 61 to 121 B-scans per one eye were acquired, which corresponds to the spacing between B-scans from 124.3μm to 63.1μm (in 30° FOV). Acquisition of the OCT image volume was performed within the peripapillary area.

The fundus images of healthy and glaucomatous subjects were preprocessed in several steps. First, standard uncompressed image in TIFF format was reconstructed from the raw data using DCRAW freeware software [6], whereas a linear gamma transfer function was used in the reconstruction process. Usual image conversion into JPEG format, as is common in many digital cameras, uses nonlinear gamma transfer function disallowing any quantitative measurement in the image. Thus, the first step is important, because we can obtain linear relation between image gray levels and intensity of reflected light from the retina. Secondly, non-uniform illumination of fundus images was corrected together with an increase of image contrast using the contrast limited adaptive histogram equalization technique (CLAHE) [37]. The most information of the RNFL appearance lies in the green (G) and the blue (B) spectral part of the visible light. Therefore, an average of G and B channel (the GB image) was computed for each fundus image. Further, only the GB images were analyzed (Fig. 1).

For the first step of analysis and for the training of regression models, we manually selected square-shaped image regions of interest (ROIs) with size of 61×61 pixels from the retinal images of 16 normal subjects (∼23 ROIs per subject). Extraction of ROIs was performed uniformly in the peripapillary area to the maximum distance not exceeding 1.5× diameter of the ONH; whereas individual ROIs were not allowed to overlap and only locations without the blood vessels were taken into account (Fig. 2
                           ). In this way, a number of 354 ROIs was collected. Particular ROIs represent the typical RNFL pattern depending on the position in the peripapillary area for normal subjects without any signs of glaucoma disease (see few examples in Fig. 2). The RNFL thickness varies with respect to position on the retina also for healthy subjects (Fig. 3a). Selection of ROIs at particular positions in the peripapillary area thus covers sufficiently wide range of the RNFL thicknesses (approx. 20–200μm) for the analysis that follows up.

The OCT volume data were preprocessed in order to get the RNFL thickness in the peripapillary area of each subject. The RNFL was segmented and the corresponding RNFL thickness map was created using research software, which is freely available online at the webpage: http://www5.cs.fau.de/research/software/octseg/.

The software uses a gradient-based method in combination with diffusion techniques to segment the retinal layers [26]. Segmentation of the RNFL was performed automatically with very high precision. However, after the automatic segmentation, the results were checked by specialist, and minor manual corrections were made using the same software package. These corrections were made only in few B-scans and only at the locations of large blood vessels (shadowed areas). Segmentation result of the RNFL in one B-scan and the reconstructed thickness map can be seen in Fig. 3. The RNFL thickness usually varies from the thinnest (blue color) to the thickest (red color) structures as can be seen in Fig. 3a.

Our previously developed landmark-based retinal image registration approach with manually selected landmarks and second-order polynomial transformation model [17] was applied for registration of fundus to OCT–SLO image data. This registration step was necessary in order to be able to compare the proposed texture features with the RNFL thickness at the specific positions on the retina. Nevertheless, different approaches could be used as well, e.g. see state of the art in [9,17].

Two advanced texture analysis methods were applied for feature extraction – Gaussian Markov random fields (GMRF) and local binary patterns (LBP). Markov random field texture modeling has been proven as an efficient tool enabling description of a probability of spatial interactions in a textural image so it has been extensively used in many image processing applications [38]. LBP-based texture analysis is relatively new and widely popular approach suitable for texture analysis of various image data [32]. Both methods were selected because of their robustness to noise and rotation- and illumination-invariant properties.

The first set of features is given by GMRF non-causal two-dimensional autoregressive model. The model assumes that image texture is represented by a set of zero mean observations y(s) [38]:
                              
                                 (1)
                                 
                                    
                                       y
                                       (
                                       s
                                       )
                                       ,
                                       s
                                       ∈
                                       Ω
                                       ,
                                       Ω
                                       =
                                       {
                                       s
                                       =
                                       (
                                       i
                                       ,
                                       j
                                       )
                                       :
                                       0
                                       ≤
                                       i
                                       ,
                                       j
                                       ≤
                                       M
                                       −
                                       1
                                       }
                                       ,
                                    
                                 
                              
                           for a rectangular M
                           ×
                           M image lattice Ω. An individual observation is then represented by the following difference equation [38]:
                              
                                 (2)
                                 
                                    
                                       y
                                       (
                                       s
                                       )
                                       =
                                       
                                          ∑
                                          
                                             r
                                             ∈
                                             
                                                N
                                                s
                                             
                                          
                                       
                                       
                                          
                                             ϕ
                                             r
                                          
                                          y
                                          (
                                          s
                                          +
                                          r
                                          )
                                          +
                                          e
                                          (
                                          s
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where N
                           
                              s
                            is a neighborhood set centered at pixel s, ϕ
                           
                              r
                            is the model parameter of a particular neighbor r, and e(s) is a stationary Gaussian noise process with zero mean and unknown variance σ. A neighborhood structure depends directly on the order and type of the model. We assume a fifth-order symmetric rotation-invariant neighborhood structure, as shown in Fig. 4
                           . This structure considers five parameters depicted by particular numbers.

These five parameters describe relation between the central pixel and its neighbors. Gaussian variance σ is considered as the sixth parameter of the model. Then, these six parameters of the model represent features, which are used for the RNFL texture description. The standard least square error (LSE) method is used for estimation of the model's parameters according to the following equations [38]:
                              
                                 (3)
                                 
                                    
                                       ϕ
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      Ω
                                                   
                                                   
                                                      q
                                                      (
                                                      s
                                                      )
                                                      
                                                         q
                                                         T
                                                      
                                                      (
                                                      s
                                                      )
                                                   
                                                
                                             
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                Ω
                                             
                                             
                                                q
                                                (
                                                s
                                                )
                                                y
                                                (
                                                s
                                                )
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           
                           
                              
                                 (4)
                                 
                                    
                                       σ
                                       =
                                       
                                          1
                                          
                                             
                                                M
                                                2
                                             
                                          
                                       
                                       
                                          ∑
                                          Ω
                                       
                                       
                                          
                                             
                                                (
                                                y
                                                (
                                                s
                                                )
                                                −
                                                
                                                   ϕ
                                                   T
                                                
                                                q
                                                (
                                                s
                                                )
                                                )
                                             
                                             2
                                          
                                       
                                       ,
                                    
                                 
                              
                           where
                              
                                 (5)
                                 
                                    
                                       q
                                       (
                                       s
                                       )
                                       =
                                       c
                                       o
                                       l
                                       
                                          
                                             
                                                ∑
                                                
                                                   r
                                                   ∈
                                                   
                                                      N
                                                      i
                                                   
                                                
                                             
                                             
                                                y
                                                (
                                                s
                                                +
                                                r
                                                )
                                                ;
                                                   
                                                i
                                                =
                                                1
                                                ,
                                                …
                                                ,
                                                I
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           for an ith-order neighborhood structure.

The second applied method – LBP is based on conversion of a local texture into the binary code. The local image texture around the central pixel (x
                           
                              c
                           , y
                           
                              c
                           ) can be characterized by the LBP code derived via equation [32]:
                              
                                 (6)
                                 
                                    
                                       L
                                       B
                                       
                                          P
                                          
                                             P
                                             ,
                                             R
                                          
                                       
                                       (
                                       
                                          x
                                          C
                                       
                                       ,
                                       
                                          y
                                          C
                                       
                                       )
                                       =
                                       
                                          ∑
                                          
                                             p
                                             =
                                             0
                                          
                                          
                                             P
                                             −
                                             1
                                          
                                       
                                       
                                          s
                                          (
                                          
                                             g
                                             p
                                          
                                          −
                                          
                                             g
                                             c
                                          
                                          )
                                          
                                             2
                                             p
                                          
                                       
                                       ;
                                        
                                       s
                                       (
                                       x
                                       )
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      1
                                                   
                                                   
                                                      
                                                         x
                                                          
                                                         ≥
                                                          
                                                         0
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      
                                                         x
                                                          
                                                         <
                                                          
                                                         0
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where g
                           
                              c
                            corresponds to gray value of the central pixel (x
                           
                              c
                           , y
                           
                              c
                           ) of a local neighborhood and g
                           
                              p
                           (p
                           =0,…, P
                           −1) corresponds to gray values of P equally spaced pixels on a circle of radius R (R
                           >0) that form a circularly symmetric neighborhood structure. Eq. (6) represents a basic rotation variant version of LBP
                           
                              P,R
                            operator. Nevertheless, the proposed approach utilizes a rotation-invariant and uniform version of the basic LBP
                           
                              P,R
                            operator, i.e. 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            
                           [32], which is the most common for many pattern recognition applications assuming so-called “uniform” patterns. The “uniformity” of a pattern is formally defined via a uniformity measure U of a neighborhood G
                           
                              P
                            
                           [32]:
                              
                                 (7)
                                 
                                    
                                       U
                                       (
                                       
                                          G
                                          P
                                       
                                       )
                                       =
                                       
                                          
                                             s
                                             (
                                             
                                                g
                                                
                                                   P
                                                   −
                                                   1
                                                
                                             
                                             −
                                             
                                                g
                                                C
                                             
                                             )
                                             −
                                             s
                                             (
                                             
                                                g
                                                0
                                             
                                             −
                                             
                                                g
                                                c
                                             
                                             )
                                          
                                       
                                       +
                                       
                                          ∑
                                          
                                             p
                                             =
                                             1
                                          
                                          
                                             P
                                             −
                                             1
                                          
                                       
                                       
                                          |
                                          s
                                          (
                                          
                                             g
                                             P
                                          
                                          −
                                          
                                             g
                                             c
                                          
                                          )
                                          −
                                          s
                                          (
                                          
                                             g
                                             
                                                p
                                                −
                                                1
                                             
                                          
                                          −
                                          
                                             g
                                             c
                                          
                                          )
                                          |
                                       
                                       .
                                    
                                 
                              
                           Then, patterns with a U value of less than or equal to two are considered as “uniform”.

Using the uniformity measure, the 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            operator is derived as [32]:
                              
                                 (8)
                                 
                                    
                                       L
                                       B
                                       
                                          P
                                          
                                             P
                                             ,
                                             R
                                          
                                          
                                             r
                                             i
                                             u
                                             2
                                          
                                       
                                       (
                                       
                                          x
                                          c
                                       
                                       ,
                                       
                                          y
                                          c
                                       
                                       )
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               p
                                                               =
                                                               0
                                                            
                                                            
                                                               P
                                                               −
                                                               1
                                                            
                                                         
                                                         
                                                            s
                                                            (
                                                            
                                                               g
                                                               p
                                                            
                                                            −
                                                            
                                                               g
                                                               c
                                                            
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         U
                                                         (
                                                         
                                                            G
                                                            P
                                                         
                                                         )
                                                         ≤
                                                         2
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         P
                                                         +
                                                         1
                                                      
                                                   
                                                   
                                                      
                                                         o
                                                         t
                                                         h
                                                         e
                                                         r
                                                         w
                                                         i
                                                         s
                                                         e
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       .
                                    
                                 
                              
                           
                        

In practice, 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            can be simply implemented via using a look-up table for conversion of the basic LBP
                           
                              P,R
                            codes into their 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            correspondents. For more details about the implementation of LBP approach, please follow [32].

Two options of LBP were utilized in the proposed method. Both options are based on rotation–invariant and uniform 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       16,2
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            operator (i.e. P
                           =16, R
                           =2). The first one uses only LBP distribution computed from an input image. Then, the gray-level histogram of such parametric image is computed and extraction of 6 statistical features follows [32]: mean value, standard deviation, skewness, kurtosis, total energy and entropy. In the second option, LBP distribution is supplemented with computation of local contrast C:
                              
                                 (9)
                                 
                                    
                                       
                                          C
                                          
                                             P
                                             ,
                                             R
                                          
                                       
                                       =
                                       
                                          1
                                          P
                                       
                                       
                                          ∑
                                          
                                             p
                                             =
                                             0
                                          
                                          
                                             P
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             
                                                (
                                                
                                                   g
                                                   p
                                                
                                                −
                                                μ
                                                )
                                             
                                             2
                                          
                                       
                                       ,
                                          
                                       where
                                        
                                       μ
                                       =
                                       
                                          1
                                          P
                                       
                                       
                                          ∑
                                          
                                             p
                                             =
                                             0
                                          
                                          
                                             P
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             g
                                             p
                                          
                                       
                                    
                                 
                              
                           
                        

Then, in turn, a joint histogram of 
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       r
                                       i
                                       u
                                       2
                                    
                                 
                              
                            and C
                           
                              P,R
                            (LBP/C) is computed. A feature vector is then obtained from LBP/C joint histogram by extraction of 12 standard Haralick's features [11] and 2 additional features called cluster shade and cluster prominence [34].

Finally, we get a 26-dimensional feature vector assembled via connection of particular approaches (GMRF+LPB+LBP/C). These features are computed for an original resolution of the fundus image and even for each of the two levels of Gaussian's pyramid decomposed images [4]. In this way, we obtain a 78-dimensional feature vector (26×3).

A feature vector was computed for each of the 354 ROIs (Section 2.2.1) and the relation between particular features and the RNFL thickness was investigated. Standard Spearman's rank correlation coefficient (p-value <0.05) [15] was computed between each feature and the RNFL thickness showing mostly significant statistical relation (Fig. 5
                        ).

Then, different regression models – linear regression [15], two types of support vector regressions (nu-SVR, epsilon-SVR) [5], and multilayer neural network (NN) [24] were tested in order to predict values of the RNFL thickness using the proposed features. Only features significantly correlated (Fig. 5) were considered for regression analysis. Standard repeated random sub-sampling cross-validation technique was used for evaluation of the models performance. Seventy and thirty percent of randomly selected ROIs was used for training and testing the regression models, respectively. This random sub-sampling procedure was repeated 100 times. Spearman's rank correlation coefficient (ρ) and root mean squared error of prediction (RMSEP) computed between the predicted output and the RNFL thickness were used to measure performance of the models (Figs. 6 and 7
                        
                        ). The averaged results of ρ and RMSEP are then presented in Table 1
                        .

@&#RESULTS AND DISCUSSION@&#

According to the cross-validation described in a previous section, epsilon-SVR model was further utilized for prediction of the RNFL thickness. Fig. 8a shows a significant statistical relation (ρ
                     =0.7691, RMSEP
                     =19.41μm) between the model predicted output and the RNFL thickness. The Bland–Altman plot of the differences between the proposed method and the RNFL thickness against their average values is depicted in Fig. 8b. Two horizontal lines in the plot represent limits of agreement between the particular methods. Most of the points are between the limits, thus showing a good agreement between the RNFL thickness derived by the proposed method and the RNFL thickness measured by OCT. Some outliers can be observed particularly for higher values of the RNFL thickness. We suppose that the estimation of high RNFL thickness is influenced by the fact that the thickest RNFL lies in the area of major blood vessel branches (in superior and inferior part of the retina). These blood vessels are wide and usually very close to each other, which may influence the results of texture analysis in their close surroundings. Then, the ROIs selected at these positions can reduce performance of the method. However, even the RNFL thickness measured by different OCT devices (based on the same physical principle) can differ significantly of about ∼10–25μm, as reported by several studies [10,19,41]. Moreover, differences between various OCT devices were also found significantly higher for higher values of the RNFL thicknesses [10,19,41]. This can be probably caused by the frequent occurrence of the thick blood vessel structures in respective areas as well. Hence, we assume that the error of the proposed methodology is acceptable, moreover when it is intended primarily for screening purposes and not as an exact estimator of the RNFL thickness.

In the next step, the proposed method was evaluated in the peripapillary area of each retinal image from the dataset described in Section 2.1. Usually, the OCT device acquires a circular scan (with diameter 3.4mm) around the ONH and the RNFL thickness is then evaluated within this single scan [2]. Hence, we performed evaluation of the RNFL utilizing the proposed texture analysis approach in a similar way in fundus images (Figs. 9 and 10
                     
                     ).

First, the blood vessels in fundus images were extracted by our matched filtering algorithm (previously published in [29]) to be able to conduct analysis only in the non-vessel areas. A circular scan pattern (depicted by the blue color in Figs. 9 and 10) was placed manually in the ONH center for each image. This scan pattern consisted of five particular circles (to make the scan reasonably thick). The scanning was performed for individual circles and a final profile was interpolated, whereas a standard linear interpolation method was used. The same interpolation method was used also for interpolation of particular profiles within the blood vessel areas. We compared straightforward intensity criterion, which is usually subjectively utilized by physicians (thinner RNFL appears darker irrespectively to texture in fundus images, Figs. 9a and 10a), with the proposed method (Figs. 9b and 10b). Then, both approaches were compared with the RNFL thickness measured by OCT (Figs. 9c and 10c). Approximated profiles are provided for each scan as well (red curves in Figs. 9 and 10), showing typical double-peak circular scan profiles of the RNFL. For the case of glaucoma (Fig. 10b), the RNFL loss can be seen approximately at the angular position around 270°, which truly corresponds with findings revealed by OCT (Fig. 10c). ρ and RMSEP were computed for each circular scan extracted from the images of normal and glaucomatous subjects at the non-vessel locations only (Tables 2 and 3
                     
                     ). Note, that interpolation of particular profiles at the locations of blood vessels does not influence evaluation of the method, since these locations are not included in computation of the evaluation parameters. The evaluation results show that the proposed texture analysis method achieved significantly higher correlation than a basic intensity criterion. Significance of the results was statistically validated by t-test at the 5% significance level. Lower mean correlation values of glaucoma subjects can be caused by variations in image quality (blurring and presence of noise due to cataracts and unclear ocular media) as well as by limited size of the dataset. Mean values of RMSEP signalize limited precision of the proposed method. However, these error values are acceptable, since they are still around the level of differences between various OCT devices (∼10–25μm) [10,19,41]. Moreover, the mean values of RMSEP are also comparable with the general difference between normal and glaucomatous RNFL thickness (∼20–25μm), as reported by studies [22,23]. As mentioned above, one drawback concerns the blood vessels that cover rather large area of the retina, especially in the ONH surroundings. Directly at the locations of blood vessels and its near neighborhood, the texture representing RNFL is missing in fundus images. Hence, the texture analysis needs to be carried out at the locations without the blood vessels. Due to this issue, the predicted values are reduced particularly at locations of the major blood vessel branches. However, despite the drawbacks, the evaluation shows that the proposed methodology can significantly contribute to the RNFL assessment based only on fundus camera. Moreover, in comparison to the basic intensity criteria, the main advantage of this texture approach is that the features are not dependent on illumination and light reflection. In the future, a study using a larger dataset of color fundus images and the OCT RNFL thickness measurements, especially of glaucomatous subjects, need to be carried out as well. Our final goal is to create a normative database (similarly as in OCT [2]), which could be used for classification of the RNFL at different angular positions around the ONH. In such way, the proposed concept may then be utilized in glaucoma screening program, for example also in connection with other diagnostic parameters, such as Cup/Disk ratio or GRI – glaucoma risk index [3].

The method was implemented using MATLAB 7.9.0 (R2009b) programming software and LIBSVM toolbox [5]. Evaluation of the algorithm was performed on a personal computer with Intel® Core™ i7 processor, 4GB system memory, and Windows® 7 Professional 64-bit operating system. An average computational time of one image was approx. 10min. During this time, first, the blood vessels need to be segmented and then, the model‘s output is computed in a predefined area surrounding the ONH. However, it must be noted that the tested implementation of the presented method has not been optimized for computational complexity yet. To achieve better computational performance, different programming languages (e.g. C-based languages) and parallel image processing should be considered for implementation of the proposed method. So far, the current implementation works in a semi-automatic way. The user is required to place a scan pattern into the ONH center. However, further development can lead to implementation of some ONH detection algorithm (e.g. as in [45]) to have the proposed approach fully automatic.

@&#CONCLUSIONS@&#

A complex approach for texture analysis of the RNFL in color fundus images has been introduced. Our evaluation revealed that the proposed texture features could be applied for quantitative estimation of the RNFL thickness and even better than intensity criterion used alone. Obtained values of ρ and RMSEP confirmed usability of the proposed approach for prediction of the RNFL thickness using only color fundus images and thus for measurement of possible RNFL thinning. One limitation of the proposed approach is availability of high quality fundus images. However, this will be probably no longer a problem due to progressive development of advanced fundus cameras. In addition, some preprocessing approaches could also be considered for enhancement of the RNFL in fundus images (e.g. as in [8]) or for improving the image quality using image restoration techniques (e.g. as in [25,36]). Moreover, using a contrast enhancing optical filter may also help to equalize color channels and to improve visibility of the RNFL [43]. Acquisition to RAW enables reconstruction of fundus images with linear gamma correction, which is also an advantage enabling quantitative measurement. The proposed methodology is not limited to utilization of presented texture analysis methods. Other approaches, with respect to noise robustness and rotation- and illumination- invariant properties, can be used as well. Then, different texture feature set could be used as an input to regression models. Hence, in the further development, possible addition of other texture features could be considered.

@&#ACKNOWLEDGMENTS@&#

Department of Biomedical Engineering, FEEC, Brno University of Technology: This work has been supported by European Regional Development Fund – Project FNUSA-ICRC (No. CZ.1.05/1.1.00/02.0123) and by Czech-German project no. 7AMB12DE002 under Ministry of Education, Youth and Sports.

Pattern Recognition Lab and Erlangen Graduate School in Advanced Optical Technologies (SAOT) University of Erlangen – Nuremberg: The authors gratefully acknowledge funding of the Erlangen Graduate School in Advanced Optical Technologies (SAOT) by the German Research and also German-Czech project no. 54447730 supported by DAAD (Deutscher Akademischer Austausch Dienst).

@&#REFERENCES@&#


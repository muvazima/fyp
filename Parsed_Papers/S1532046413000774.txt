@&#MAIN-TITLE@&#Assessing the reliability of an automated dose-rounding algorithm

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We describe a novel algorithm for converting weight-based dosing guidelines into administerable doses for children.


                        
                        
                           
                           This algorithm features combines medication knowledge, dosing knowledge, and dose administering knowledge.


                        
                        
                           
                           We report the performance of this approach, and discuss the limitations encountered thus far.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Biomedical informatics

Electronic prescribing

Clinical practice

Computer software

Prescriptions

Medical informatics

@&#ABSTRACT@&#


               
               
                  Objective
                  Pediatric dose rounding is a unique and complex process whose complexity is rarely supported by e-prescribing systems, though amenable to automation and deployment from a central service provider. The goal of this project was to validate an automated dose-rounding algorithm for pediatric dose rounding.
               
               
                  Methods
                  We developed a dose-rounding algorithm, STEPSTools, based on expert consensus about the rounding process and knowledge about the therapeutic/toxic window for each medication. We then used a 60% subsample of electronically-generated prescriptions from one academic medical center to further refine the web services. Once all issues were resolved, we used the remaining 40% of the prescriptions as a test sample and assessed the degree of concordance between automatically calculated optimal doses and the doses in the test sample. Cases with discrepant doses were compiled in a survey and assessed by pediatricians from two academic centers. The response rate for the survey was 25%.
               
               
                  Results
                  Seventy-nine test cases were tested for concordance. For 20 cases, STEPSTools was unable to provide a recommended dose. The dose recommendation provided by STEPSTools was identical to that of the test prescription for 31 cases. For 14 out of the 24 discrepant cases included in the survey, respondents significantly preferred STEPSTools recommendations (p
                     <0.05, binomial test). Overall, when combined with the data from all test cases, STEPSTools either matched or exceeded the performance of the test cases in 45/59 (76%) of the cases. The majority of other cases were challenged by the need to provide an extremely small dose. We estimated that with the addition of two dose-selection rules, STEPSTools would achieve an overall performance of 82% or higher.
               
               
                  Conclusions
                  Results of this pilot study suggest that automated dose rounding is a feasible mechanism for providing guidance to e-prescribing systems. These results also demonstrate the need for validating decision-support systems to support targeted and iterative improvement in performance.
               
            

@&#INTRODUCTION@&#

E-prescribing has emerged as a core component of an assumed safe national healthcare system [1–6]. Federal initiatives such as the HITECH (Health Information Technology for Economic and Clinical Health) Act specifically require the use of e-prescribing by all medical specialties [7].

However, despite this widespread enthusiasm for e-prescribing, not all e-prescribing systems support the needs of all specialties. A recent AHRQ report [8] noted issues of usability with these systems. There is less data to support the use of e-prescribing in the ambulatory pediatric community [9], despite the challenges associated with pediatric patient medication management [10]. A study by Kaushal noted the potential for e-prescribing to prevent up to 21% of adverse drug events in outpatient settings, including those related to drug frequency and weight/dose checks [11].

Pediatric prescribing is a complex process that requires the prescriber to calculate a medication dose that is appropriate for the treatment goals and for the child’s weight or body surface area [6]. While some medications are relatively tolerant of inaccurate dosing, others with narrow therapeutic indices (e.g., Digoxin) have a great potential for adverse consequences if dosed improperly [12–14]. This process is sufficiently complicated that most pediatricians rely on prescribing guides in print or electronic form to practice safely [15,16]. Recent advances in medications available to treat severe conditions also impact children with these conditions [15,17].

One particular area of concern is the lack of sophistication used when e-prescribing systems automatically calculate doses. Should a 4.7kg child receiving 5mcg/kg/dose of digoxin, totaling 23.5mcg, receive 0.5ml (25mcg, or 10.6mcg/kg/day) or 0.4ml (20mcg, or 8.51mcg/kg/day)? Or should the child receive the exact dose of 0.47ml, which would likely be complicated to administer at home or require asking for a custom formulation, which can be expensive?

In the spirit of “a rising tide lifts all boats,” one method to systematically improve dose-rounding decision support in pediatric e-prescribing is through the use of cloud-based tools that may be developed and maintained by knowledge experts and adopted by all e-prescribing systems with a minimum of effort. This approach goes by many names, including “Software as a Service,” or web services. The goal of this project was to design, develop and evaluate an algorithm for use in this manner.

@&#METHODS@&#

We used a combination of data sources to develop the dosing algorithm. First, as a part of a previous study, we used literature about the pharmacokinetic and potential adverse drug event to develop rounding tolerances for each medication [18]. These rounding tolerances were combined with the following knowledge sources to develop a range of allowable doses for each prescription:
                           
                              •
                              Medication knowledge (STEPSTools knowledgebase): frequencies of administration, rounding tolerances, minimum and maximum daily and per-dose amounts.

RxNorm, developed by the National Library of Medicine, to provide a mapping between any string representation of a generic or brand medication and all dosage forms of that medication.

Finally, we convened a number of expert panels as described in [18]. Using example prescribing cases to create discussion, pediatricians and pharmacists in these panels provided a number of heuristics they use to create a safe and administrable prescription. These heuristics became the foundation for selecting an easily administered dose.

The final algorithm for dose selection and rounding prefers as input the patient’s age in months, the patient’s weight in kilograms, the medication name, and desired mg/kg/day dosing formula. The service also accepts the number of doses per day, a code for the medication name, and a coding scheme as optional parameters. Once these data are received, the algorithm goes through three steps, each of which is discussed below.

We use a version of RxNorm concepts distilled into a lookup table for all medications in the knowledgebase. This table matches up the inputted medication name with an RxCUI. If we are unsuccessful in matching the name to a CUI, we query RxNorm using the RxNorm API. We use this process to improve the performance of the web service. Once the RxCUI is found, the service retrieves the medication frequency, absolute minimum dose, maximum dose, and rounding tolerance.


                           Fig. 1
                            summarizes the key steps in creating a set of safe and administrable doses. The rounding process requires 4 steps. First, STEPSTools retrieves information about the minimum and maximum therapeutic dose from its medication knowledgebase (based on data from the Harriet Lane Handbook, 18th Edition [19]) to set the absolute range of doses that can be calculated. Second, STEPSTools uses patient age and weight information, in addition to published formulae for weight-based dosing and the rounding tolerance for the medication’s active ingredients to calculate a relative rounding range. Third, STEPSTools determines a working range, taking into account both the optimal and relative rounding ranges. In cases where the rounding range is completely within the absolute range, the relative rounding range is used as the working range; however, in other cases, STEPSTools defaults the lowest working dose to either the minimum rounded dose or the minimum absolute dose, whichever is higher. It performs a similar filter at the high end of the dosing range if necessary, selecting the lower dose of the two highest allowable doses. Finally, STEPSTools applies heuristics about home dosing capabilities to select doses within the working range that are easily administered. These doses are based on a review of common dosing implements available through pharmacies. For example, 1ml syringes can typically be dosed in 0.1mL increments, while 10mL syringes are easily dosed in increments of 0.5mL. Most capsules may not be split, but some pills may be. This list of possible doses and formulations within the working range is stored.

STEPSTools returns dose recommendations based on the list of possible doses and dosage forms previously described combined with heuristics derived from expert panels, which are weighted using cases from our test suite. The heuristics encompass information about the ideal ages for each formulation and the amounts that are best tolerated by children to score each dosing suggestion, as described below:
                              
                                 1.
                                 If the age of the patient is less than 7years, and the dose is in liquid, suppository, or patch, boost the score by 8 points; if the form is chewable, boost the score by 4 points; if form is melt away, boost the score by 2 points.

If the form is
                                       
                                          a.
                                          Liquid and
                                                
                                                   i.
                                                   The dose is divisible by 0.5ml, boost by 1 point for patients 7 or older, and 2 points for patients under age 7.

The dose is divisible by 1ml; add two points for patients 7 or older, and 4 points for patients under age 7.

The volume is less than 10mL, add one point for patients 7 and older, and 2 points for patients under age 7.

Tablet and
                                                
                                                   i.
                                                   The dose is divisible by dosage form, add 2 points
                                                         
                                                            1.
                                                            If the dose quantity is less than 2 tablets, add 2 additional points.

The dose is not divisible, half the current score (and exclude if a capsule)

If the administrable dose is closest to the calculated dose, add 4 points.

If more than one dose has the highest score, break the tie by adding one point to the dose with the lowest number of pills or lowest volume of liquid.

In addition, STEPSTools generates a natural language explanation for each score. The entire set of doses and formulations that are scored are returned to the calling system.

To assess the validity of the dosing algorithm’s responses, we used a two-part design. First, we created an automated test suite of cases for each medication. Second, we included cases with discrepant doses in a survey distributed to provider subjects. Each part will be described below.

The test suite of cases consisted of a 6-month sample of electronically generated prescriptions from one academic center. For each prescription, we obtained data that would serve as input parameters (weight, age in months, medication, medication code, coding scheme, frequency, and mg/kg/day dosing) and data that would serve as the output validation (formulation, dose, frequency). Prescriptions were excluded if they (1) were generated for medications not in the STEPSTools knowledge base, (2) were for patients weighing 60kg or over (3) were missing the mg/kg/day rationale needed to calculate a dose. The final set of prescriptions was divided randomly into two groups. We used 60% of the sample chosen at random as the training set, and the remaining 40% as the test set. The training set was used to improve the capabilities of the rounding algorithm and to identify any performance issues in the web services. For example, initially, the rounding algorithm would select as an optimal dose an arbitrarily high number of tablets or capsules if that dosing instruction would generate a precise, but intolerable amount of the medication to take. We used the training set and additional heuristics to improve the way STEPSTools handles such issues. Once all issues were resolved, we entered the test cases into our testing suite, which was a toolset provided by the FitNesse Acceptance Testing Framework (http://www.fitnesse.org). This tool allows us to put both input and expected results into a table, then compares the actual results with the expected results. For the purposes of this test, we considered the rate at which the highest scoring dose and formulation was in agreement with the test case, recognizing that the test case’s result may have been present in the STEPSTools result set in another position. Any test cases that were not in agreement with the sample prescription were flagged as discrepant. Test cases included antibiotics, anti-arrhythmics, diuretics, antipyretics and anti-inflammatory medications.

Discrepant cases were then stratified by medication name and incorporated into a survey such that there was one case on the survey for each medication, ensuring that the survey would include the minimum number of questions to address the discrepancy. The 24-item survey was piloted with 10 subjects and then distributed to a pool of 174 pediatricians at CCHMC and VCH with 111 and 63 providers recruited, respectively. The pool consisted of providers in General Pediatrics (51%) and specialties in Neurology (21%) and Cardiology (28%). We received 44 complete responses after 6 mass email and 3 personalized email reminders over the course of 3months, for an overall response rate of 25%. Our final sample consisted of 20 CCHMC and 24 VCH providers with the following self-reported specialties (proportion of our sample shown in parentheses): General (55%), Neurology (16%), Cardiology (25%), Internal Medicine (2%), and Hospitalist (2%). Data were collected and managed using REDCap (Research Electronic Data Capture) tools hosted at Vanderbilt University [20]. REDCap is a secure, web-based application designed to support data capture for research studies, providing: (1) an intuitive interface for validated data entry; (2) audit trails for tracking data manipulation and export procedures; (3) automated export procedures for seamless data downloads to common statistical packages; and (4) procedures for importing data from external sources. Survey respondents were compensated for their time with a $15 gift card mailed to their provided mailing addresses. An example question from the survey (full version available in the Appendix) is shown below:
                           
                              
                           
                        
                     

Our team conducted an exploratory analysis of survey data using R statistical software (http://www.R-project.org). Our unit of analysis was the survey question, with each survey question corresponding to a medication. We used a binomial test to determine whether STEPSTools’ recommendation was chosen more often than a non-STEPSTools recommendation (dose originally prescribed for the test case or an alternative dose provided by the respondent), i.e., more than 1/3 of the time. If a respondent indicated that s/he does not prescribe the given medication, his/her response was not included for that case. Descriptive statistics were used to summarize remaining survey items.

@&#RESULTS@&#


                     Fig. 2
                      summarizes the results of test case selection and analysis. After creating a candidate set of test cases (8966 cases), we excluded cases from analyses if they were generated for patients 50kg or over (n
                     =1738), were for medications not in the STEPSTools knowledge base (n
                     =3714), were missing the mg/kg/day rationale needed to calculate a dose (n
                     =3199), or were exact duplicates of weight, medication and medication dosing strategies (n
                     =236). The final set included in analyses contained 79 test cases. As shown in Table 1
                     , there was complete concordance between the recommended dose/formulation and the prescribed dose/formulation for 31 cases (39% of the 79 test cases). Concordant cases were from the same categories of medications as discordant cases. Concordance was more likely with tablet or capsule doses, as well as for medications with fewer possible formulations. The two most frequent reasons for discordance were related to dose rounding up to a whole milliliter dose, or selecting a different formulation from the one that was prescribed. There were 28 cases where STEPSTools recommended a different formulation or dose than the originally furnished the test case result (due to rounding up or rounding down). Four of these cases were excluded from the survey because they were too similar to cases already included in the set, i.e., the same medication for the same size child. The remaining 24 cases were included in the survey distributed to providers. The flowchart in Fig. 2 shows the derivation of the 24 unique cases used in the survey from the original test set.

Of note, for 20 cases, STEPSTools was unable to generate a rounded dose. In every case, a recommendation was sought for a medication for which STEPSTools’ rounding algorithm was unable to generate an administrable dose within the dosing range because the dose required was too small (<0.10mL or mg). For example, in one case a 5.86kg, 6-month-old infant, was prescribed lorazepam at a recommended dose of 0.03mg/kg/day. STEPSTools attempted to find a dosage form to safely administer a dose between 0.293mg and 0.30765mg. Using this dosing range, each administrable dose is either below the range (0.1ml=0.20mg) or above the range (0.2ml=0.40mg). Because STEPSTools considers dosing by 1/100th of a milliliter un-administrable, it does not return a dose, although it does return an explanation to explain this logic.

The 24-item survey was piloted with 10 subjects and then distributed to a pool of 174 pediatricians at CCHMC and VCH with 111 and 63 providers recruited, respectively. The pool consisted of providers in General Pediatrics (51%) and specialties in Neurology (21%) and Cardiology (28%). We received 44 complete responses after 6 email and 3 personalized reminders over the course of 3months, for an overall response rate of 25%. Our final sample consisted of 20 CCHMC and 24 VCH providers with the following self-reported specialties (proportion of our sample shown in parentheses): General (55%), Neurology (16%), Cardiology (25%), Internal Medicine (2%), and Hospitalist (2%).

Overall, the answer proposed by STEPSTools was chosen significantly more often than either the original provider-furnished answer or a respondent-provided alternative choice in over half of the cases (58.3% of 24 cases). The figure below summarizes these data for each of the 24 survey cases.

In Fig. 3
                     , the frequency of respondents who chose one of four different recommendations is shown for each survey case. Survey case numbers and medication names are shown to the left of the stacked histogram; the number to the right indicates the average confidence level of the respondents, ranging from 0 (not at all confident) to 100 (completely confident). Actual frequencies for each response are shown embedded in the stacked bar plot. STEPSTools’ recommendations were significantly preferred for 14 of the 24 questions with a >80 score of confidence for all but one case (question 3, azathioprine). When combined with the data from all test cases, STEPSTools either matched or exceeded the performance of the test cases in 45/59, or 76% of the cases where it was able to provide a recommendation.

An analysis of the respondents’ reasons for their preferred recommendations revealed that the two most popular reasons for respondents choosing one recommendation over others was believing there was a better dose amount for weight, or believing there was a better dosage form for age (see Table 2
                     ). Among other reasons that respondents offered as reasons for their preferred recommendation, the most common reason was that the preferred dose is easier for the parent or caretaker to administer.

Based on these results, we were able to identify two additional rules:
                        
                           1.
                           if a dose is too small to find an admisterable dose within the working range, select the smallest administerable dose.

If there is more than one weight-based dosing strategy based on indication, run STEPSTools once for each strategy and include the indication for each as a field in the resulting output.

Adding rule #1 to the STEPSTools algorithm, we found that all 20 excluded cases for which no STEPSTools recommendation was generated would have resulted in a dose rounded to the minimum allowable dose consistent with the dosing that was prescribed in the test case set. This would improve the overall performance to 65/79 cases, or 82%. We identified an additional 8 excluded cases that may be impacted by the addition of rule #2.

@&#DISCUSSION@&#

Pediatric dosing is both complex and knowledge intensive. With the rapid increase in adoption of e-prescribing, developing algorithms to integrate this knowledge into provider decision-making has the potential to impact the care of children relatively quickly. However, an important part of making complex services available is testing the performance of algorithms within these services. The data above describe both a process of and results related to testing a dosing algorithm. This testing confirmed our belief that the STEPSTools rounding algorithm was able to perform well for many medication cases. Testing also disclosed a number of issues related to specific medications, especially issues related to recommending small doses in infants. All these issues appear to be readily addressed. Finally, testing identified some situations where STEPSTools’ recommendations were preferred over those of the test cases.

These results are limited to an analysis of a small dataset from only one institution, although this institution has one of the largest outpatient volumes of any pediatric care center. The total number of usable test cases was significantly smaller than we had anticipated because the e-prescribing system used to create the data set did not require mg/kg dosing detail to be provided, challenging our ability to use many of the cases provided. It is possible that in many cases where respondents did not prefer STEPSTools’ recommendation even though the STEPSTools algorithm performed correctly, respondents might have chosen STEPSTools’ recommendations had we provided the explanation for the selected dose. For example, in case #10, STEPSTools did not recommend the dose amount of 80mg that was provided by our test data set, because according to its algorithm, the minimum dose for age should have been 148mg/dose. We elected not to present these explanations on the survey, so that we could preserve the blinding of which dose was manually versus automatically calculated.

STEPSTools did not make recommendations for a number of medications where minute doses were required. Part of the challenge with these small dose calculations relates to the inferences that can be made on the part of the algorithm. For example, clonidine is a medication often used to treat hypertension in infants and falls into the class of medications whose dosing is related to avoiding toxicity related to hypotension.[18] Although the published dosing is between 5 and 10mcg/kg/day divided into four doses daily, it would be incorrect to assume that “sliding” the dose beyond whatever integer option was selected by the prescriber would always be acceptable, because of the known risks of overdosing (e.g., rounding 6mcg/kg/day up to 7mcg/kg/day automatically) Therefore, in designing our dosing algorithm, we did not take into account the option the prescriber has to select a higher therapeutic dose if STEPSTools cannot find a dose within the rounding tolerance for the chosen dosing that can be administered in a 1/10thml volume. In reality, most prescribers would likely round up to the nearest 1/10thml regardless of the rounding tolerance (as was described in Section 3), or the patient would be prescribed an extemporaneously compounded (and less concentrated) formulation that allows for an easier to administer dose. This sort of tradeoff was actively discussed by our team of developers, pharmacist experts, and pediatricians during development. After reviewing training data, we elected to err on the side of not providing a choice outside of the rounding tolerance, pending the results of this analysis. Results from our study suggest that additional refinements to the existing algorithm may be warranted to examine safe ways to provide recommendations for small dose cases.

Part of the rationale behind this project was the recognition that errors may be introduced when humans modify automatically calculated doses in e-prescribing systems [21]. It was our hope that STEPSTools would be able to recommend one and only one dose for each scenario. However, as is evident from our survey data, and as we discovered innumerable times during the training phase of this project (leading to some of our heuristics for weighting a dose) there are numerous equally safe doses, especially when generic forms of medications come in a variety of formulations. Which dose to select may be based on child and family preferences regarding the dosage form (liquid versus tablet/capsule), the dosing volume strategy (larger volume of better tasting or easy-to-administer medications), and even the frequency of administration (more frequent dosing may lead to less physiologic fluctuations, for example). Therefore, it is clear that a more customized user experience may involve using the same dosing algorithm to generate a small set of potential dosing strategies based on a palette of preferences. In the absence of information about personal preferences, algorithms for dose rounding, drug selection, or other decisions that rely on these preferences should simply provide this subset, along with explanatory text that differentiates each option. This approach would allow a series of safe doses to be “selectable” by the user, thereby avoiding errors, such as misplaced decimal points or ambiguous dosing instructions to be entered.

Future work in this area will undoubtedly focus on these challenges, as well as the challenge of developing safe and usable ways to exploit the range of dosing formulae, as noted above. Future work also will need to increase the number of medications included in the STEPSTools rounding knowledgebase to support both pediatric and common adult liquid outpatient medications, given the potential for this algorithm to help with outpatient dosing of liquid formulations in any age group.

@&#ACKNOWLEDGMENTS@&#

This research project was funded by AHRQ, under grant number R18HS17216. REDCap is funded by the Vanderbilt Institute for Clinical and Translational Research grant support (1 UL1 RR024975 from NCRR/NIH). The authors thank AHRQ for their support and thoughtful comments throughout this project. The authors thank the members of the STEPSTools Working Advisory Group. They have all played a key role in the development of this tool. Their contributions to this article are greatly appreciated.
                     
                        
                           
                           
                           
                              
                                 John Canning
                                 Physician’s Computer Company
                              
                              
                                 Coda L. Davison, MPA, BBA
                                 Vanderbilt University School of Medicine
                              
                              
                                 Cynthia S. Gadd, PhD, MBA
                                 Vanderbilt University School of Medicine
                              
                              
                                 Robert Grundmeier, MD
                                 Children’s Hospital of Philadelphia
                              
                              
                                 Chip Hart
                                 Physician’s Computer Company
                              
                              
                                 Jill S. Helmke, D.Ph., N.Ph.
                                 Vanderbilt University School of Medicine
                              
                              
                                 Yun- Xian Ho, PhD.
                                 Vanderbilt University School of Medicine
                              
                              
                                 Carlton K.K. Lee, Pharm. D., MPH
                                 Johns Hopkins University
                              
                              
                                 Jennifer Mansour, MSW, CPHIT, CPEHR
                                 American Academy of Pediatrics
                              
                              
                                 Eugenia Marcus, MD, FAAP
                                 Pediatric Health Care
                              
                              
                                 Beki Marshall, CPHIT, CPEHR
                                 American Academy of Pediatrics
                              
                              
                                 Jerome A. Osheroff, MD
                                 Thomas Reuters
                              
                              
                                 Marvin Palmer
                                 Vanderbilt University School of Medicine
                              
                              
                                 Mark M. Simonian, MD, FAAP
                                 American Academy of Pediatrics Liaison
                              
                              
                                 S. Andrew Spooner, MD, MS
                                 Cincinnati Children’s Hospital
                              
                              
                                 Stuart T. Weinberg, MD, FAAP
                                 Vanderbilt University School of Medicine
                              
                           
                        
                     
                  
               

@&#REFERENCES@&#


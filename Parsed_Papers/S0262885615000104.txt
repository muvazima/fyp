@&#MAIN-TITLE@&#Robust stereo matching using adaptive random walk with restart algorithm

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We develop a robust stereo matching algorithm using a random walk with restart.


                        
                        
                           
                           The proposed method considers occlusion and depth discontinuities.


                        
                        
                           
                           The method achieves high accuracy with low computational costs in the reconstruction.


                        
                        
                           
                           Our method works well on the varying illumination and exposure test.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Global optimization

Random walk with restart

Stereo matching

Superpixels

@&#ABSTRACT@&#


               
               
                  In this paper, we propose a robust dense stereo reconstruction algorithm using a random walk with restart. The pixel-wise matching costs are aggregated into superpixels and the modified random walk with restart algorithm updates the matching cost for all possible disparities between the superpixels. In comparison to the majority of existing stereo methods using the graph cut, belief propagation, or semi-global matching, our proposed method computes the final reconstruction through the determination of the best disparity at each pixel in the matching cost update. In addition, our method also considers occlusion and depth discontinuities through the visibility and fidelity terms. These terms assist in the cost update procedure in the calculation of the standard smoothness constraint. The method results in minimal computational costs while achieving high accuracy in the reconstruction. We test our method on standard benchmark datasets and challenging real-world sequences. We also show that the processing time increases linearly in relation to an increase in the disparity search range.
               
            

@&#INTRODUCTION@&#

Depth perception is a fundamental issue in the study of computer vision. Depth information is used in object recognition, human tracking, and image segmentation, as well as in robotics applications, including navigation, localization, and mapping. The depth is therefore an important measure in order to understand space and the objects within it. The stereo camera is a popular method to measure a 3D point cloud. Stereo matching algorithms attempt to determine corresponding objects between the two scenes. There has been considerable progress in this field. Scharstein and Szeliski [1] showed that the majority of stereo matching algorithms can be built from four basic components:
                        
                           •
                           Computation of local matching costs for all pixels.

Aggregation of pixel-wise matching costs in the support regions.

Search for the global optimal disparity values.

Refinement of the resultant disparity map.

The stereo algorithms can be classified into two groups, local and global, depending on whether the global search and refinement are performed. Initially, the pixel-wise matching costs between the reference and target images are calculated. The pixel-wise costs are often noisy, and contain minimal information in texture-less regions. Therefore, the costs of neighboring support regions are aggregated together. A local algorithm would finish at this stage and assign the best disparity value based on the aggregated costs at each pixel. Thus, local methods are typically faster, yet less accurate in comparison to a global technique.

In contrast, a global method takes account of the overall scene structure and depth smoothness in order to determine the disparity map. Recently, stereo algorithms have achieved impressive results using the Markov Random Field (MRF). The labeling of an MRF is known to be NP-hard. Due to this factor, belief-propagation (BP) and graph cut (GC) methods are widely used to approximate the optimal solution of the global method. However, BP- or GC-based stereo matching algorithms require substantial computational resources. In this study, we present a novel stereo matching algorithm that utilizes a random walk with restart (RWR) to optimize the matching cost without the need for the conventional BP or GC algorithms. The proposed method provides two benefits: computational efficiency, and theoretical optimality. These factors enable the proposed method to achieve high-quality matching results at relatively low computational cost.

We also propose an adaptive RWR algorithm (ARW) that is suited for practical applications. The use of a stereo camera presents many problems, including low texture, occlusion, and depth discontinuities. A general energy minimization formulation contains data and smoothness terms, which are effective when considering the low-texture areas of an image. However, this approach will often fail when conserving occlusion or depth discontinuities, resulting in an overall unsatisfactory matching. In order to solve this problem, our proposed algorithm includes two additional procedures. Firstly, the occluded regions are detected through a left-right consistency check. Secondly, we introduce a robust penalty function to compute an additional fidelity term that allows us to preserve the depth discontinuity. These two advances play an important role in improving the performance.

This paper's primary contribution lies in its introduction of a novel global optimization method for stereo matching. Our proposed algorithm is based on the RWR method, instead of the conventional GC or BP. We describe a new interpretation of the RWR method, and outline its benefits, in relation to stereo matching and classical optimization algorithm. In addition, we modify the conventional RWR algorithm for our purposes, by taking account of regions of occlusion and discontinuity. With these modifications, we achieve high-accuracy stereo reconstruction at little computational cost in comparison to GC- and BP-based methods. This is our main contribution to the literature. Our experimental results quantitatively demonstrate that the performance of our method is comparable to existing state-of-the-art techniques. We also implement our proposed method in a real-world test environment, and reveal its minimal processing time requirements.

@&#RELATED WORK@&#

We mentioned in the preceding section that stereo matching algorithms can be classified as local or global. Some local methods are comparable to global methods with respect to their accuracy. Yoon and Kweon [2] proposed an adaptive weighting method similar to a bilateral filter because of the way the filtered result is a weighted average of neighboring pixels. Their algorithm preserves depth edge information, yet the full-kernel implementation is very slow. Rhemann [3] proposed a cost–volume filtering algorithm, an approximation of the bilateral filter, and Yang [4] improved the cost–volume filtering to be more efficient. These approaches both require a substantial window size in order to accurately estimate the disparity. This increases their computational cost in comparison to other local methods such as that developed by Geiger [5]. De-maeztu [6] proposed linear stereo matching in order to overcome these weaknesses.

In comparison to local methods, a global algorithm will typically skip the cost aggregation step, and instead aim to minimize a global cost function consisting of a data and a smoothness term. Significant advances have been made in global optimization-based stereo matching algorithms over the past decade. The majority of global stereo matching algorithms treat the problem as one of energy minimization, which is often formulated through inference on a MRF. The problem of finding an exact optimal solution in a looping MRF is known to be NP-hard. To alleviate this factor, approximation methods, such as GC- [7] or BP-based stereo matching [8] have been proposed. These algorithms have been extended further, including the integration of multiple cues, such as segmentation [9–11], and left-right consistency [12]. The multiple cues are typically used to address occlusion, depth discontinuity, and low-texture areas. Yang [13] proposed a color-weighted hierarchical BP algorithm. This allows global matching algorithms to account for depth discontinuities using segmentation as a soft constraint, and was shown to converge quickly.

In comparison, stereo matching algorithms, including both local and global methods, usually assume a fronto-parallel plane in the window-based matching cost aggregation stage. There have been several algorithms proposed to deal with the limitation of the fronto-parallel assumption. Li and Zucker [14] introduced surface geometric constraints in the global optimization framework. In contrast, Bleyer [15] proposed a PatchMatch-based stereo matching algorithm, while Yamaguchi [16] developed a slanted-plane MRF-based algorithm.

However, almost all existing high-performance algorithms are limited in real-time implementation. A semi-global matching (SGM) algorithm has been proposed in order to reduce the optimization complexity of the global cost function. Hirschmuller [17] presented a SGM algorithm that approximated a global cost function using path-wise optimizations. In recent years, modified algorithms based on SGM have been proposed [18]. SGM methods have been successfully applied to stereo matching.

MRF-based energy minimization has been used in stereo matching algorithms for the last decade. The GC, BP, and SGM algorithms generally form the basis of current state-of-the-art methods. In this paper, we instead employ the RWR algorithm to optimize the matching cost. Several applications have successfully used RWR, including Google's famous PageRank algorithm [19], content-based image retrieval [20], and image segmentation [21]. However, RWR is not as widely used in the stereo matching problem as GC- and BP-based methods.

In this section, we describe our proposed stereo matching algorithm. In Fig. 1
                     , an overview of the proposed algorithm is illustrated. The method computes the initial matching cost for each pixel and all disparities using a combination of a census transform and gradient image matching. We describe this further in Section 3.1. The cost of matching is aggregated into the superpixel that each pixel belongs to. We describe this process further in Section 3.2. Finally, the aggregated matching cost is updated via the RWR algorithm to determine the optimum disparity. Our modified RWR algorithm takes into account the occluded and discontinuity regions based on our current understanding. This is described further in Section 3.3. Our proposed method uses gray-scale images, as well as Gaussian smoothing (3×3, σ
                     =1.0) to reduce minor noise.

In this stage, the initial pixel-wise matching costs are calculated. Local matching methods are used to develop a measure that provides optimal high-quality matching. Of these, the gradient image, census transform, rank transform, and mutual information are known to be both robust and accurate. In our local matching algorithm, we use both census transform and gradient image matching as inspiration.

The census-based matching technique was originally introduced by Zabi and Woodfill [22]. The pixels of both left and right images are transformed into a binary vector and compared to the surrounding pixels within finite support regions:
                           
                              (1)
                              
                                 T
                                 
                                    u
                                    v
                                 
                                 =
                                 
                                    
                                       ⊗
                                       
                                          
                                             
                                                u
                                                w
                                             
                                             
                                                v
                                                w
                                             
                                          
                                          ∈
                                          w
                                          
                                             u
                                             v
                                          
                                       
                                    
                                 
                                 H
                                 
                                    
                                       I
                                       
                                          u
                                          v
                                       
                                       ,
                                       I
                                       
                                          
                                             u
                                             w
                                          
                                          
                                             v
                                             w
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where I(u,
                        v) and I(u
                        
                           w
                        ,
                        v
                        
                           w
                        ) denote the intensity values of the input pixel and the surrounding pixels, respectively; ⊗ denotes concatenation, w is the window around (u,
                        v), and H is a binary function returning 0 or 1. We use a 5×5 window in order to encode each pixels binary vector in the census transform. The binary vector is encoded by comparing the intensity values of a center and its surrounding pixels:
                           
                              (2)
                              
                                 H
                                 
                                    
                                       I
                                       
                                          u
                                          v
                                       
                                       ,
                                       I
                                       
                                          
                                             u
                                             w
                                          
                                          
                                             v
                                             w
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             0
                                             
                                             if
                                             
                                             I
                                             
                                                u
                                                v
                                             
                                             <
                                             I
                                             
                                                
                                                   u
                                                   w
                                                
                                                
                                                   v
                                                   w
                                                
                                             
                                             ,
                                          
                                       
                                       
                                          
                                             1
                                             
                                             if
                                             
                                             I
                                             
                                                u
                                                v
                                             
                                             ≥
                                             I
                                             
                                                
                                                   u
                                                   w
                                                
                                                
                                                   v
                                                   w
                                                
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The binary vector is assigned to each pixel in the left and right images. The matching cost is computed using the Hamming distance of two binary vectors:
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             C
                                             r
                                          
                                          
                                             u
                                             v
                                             d
                                          
                                          =
                                          Hamming
                                          
                                             
                                                
                                                   T
                                                   l
                                                
                                                
                                                   u
                                                   v
                                                
                                                ,
                                                
                                                   T
                                                   r
                                                
                                                
                                                   
                                                      u
                                                      +
                                                      d
                                                      ,
                                                      v
                                                   
                                                
                                             
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                             C
                                             l
                                          
                                          
                                             u
                                             v
                                             d
                                          
                                          =
                                          Hamming
                                          
                                             
                                                
                                                   T
                                                   r
                                                
                                                
                                                   u
                                                   v
                                                
                                                ,
                                                
                                                   T
                                                   l
                                                
                                                
                                                   
                                                      u
                                                      −
                                                      d
                                                      ,
                                                      v
                                                   
                                                
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where C(u,
                        v,
                        d) is the Hamming distance based cost function at disparity d, and the subscripts l and r denote the left and right images, respectively. The census transformation is robust to radiometric variations and image noise owing to the local image structures being encoded based on the relative ordering of pixel intensities. However, matching ambiguities can be caused in some regions as a result of this property; for example, repetitive or similar texture patterns are a particular problem. In order to tackle these problems, we incorporate further information into the local matching algorithm.

The gradient image matching is defined as:
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             G
                                             r
                                          
                                          
                                             u
                                             v
                                             d
                                          
                                          =
                                          |
                                          
                                             ∇
                                             x
                                          
                                          
                                             I
                                             l
                                          
                                          
                                             u
                                             v
                                          
                                          −
                                          
                                             ∇
                                             x
                                          
                                          
                                             I
                                             r
                                          
                                          
                                             
                                                u
                                                +
                                                d
                                                ,
                                                v
                                             
                                          
                                          |
                                          +
                                          |
                                          
                                             ∇
                                             y
                                          
                                          
                                             I
                                             l
                                          
                                          
                                             u
                                             v
                                          
                                          −
                                          
                                             ∇
                                             y
                                          
                                          
                                             I
                                             r
                                          
                                          
                                             
                                                u
                                                +
                                                d
                                                ,
                                                v
                                             
                                          
                                          |
                                          ,
                                       
                                    
                                    
                                       
                                          
                                             G
                                             l
                                          
                                          
                                             u
                                             v
                                             d
                                          
                                          =
                                          |
                                          
                                             ∇
                                             x
                                          
                                          
                                             I
                                             r
                                          
                                          
                                             u
                                             v
                                          
                                          −
                                          
                                             ∇
                                             x
                                          
                                          
                                             I
                                             l
                                          
                                          
                                             
                                                u
                                                −
                                                d
                                                ,
                                                v
                                             
                                          
                                          |
                                          +
                                          |
                                          
                                             ∇
                                             y
                                          
                                          
                                             I
                                             r
                                          
                                          
                                             u
                                             v
                                          
                                          −
                                          
                                             ∇
                                             y
                                          
                                          
                                             I
                                             l
                                          
                                          
                                             
                                                u
                                                −
                                                d
                                                ,
                                                v
                                             
                                          
                                          |
                                          ,
                                       
                                    
                                 
                              
                           
                        where ∇
                           x
                        
                        I and ∇
                           y
                        
                        I represent the horizontal and vertical gradient images. The gradient images are computed using 5×5 Sobel filters. Gradient-based methods are known to be as equally robust as the census transform method to camera gain or non-Lambertian surfaces. We use a combination of census transformation and gradient image matching in our technique. Two measurements are truncated and combined with a weighted sum.


                        
                           
                              (5)
                              
                                 
                                    P
                                    r
                                 
                                 
                                    u
                                    v
                                    d
                                 
                                 =
                                 
                                    σ
                                    c
                                 
                                 min
                                 
                                    
                                       
                                          C
                                          r
                                       
                                       
                                          u
                                          v
                                          d
                                       
                                       ,
                                       
                                          τ
                                          c
                                       
                                    
                                 
                                 +
                                 
                                    σ
                                    g
                                 
                                 min
                                 
                                    
                                       
                                          G
                                          r
                                       
                                       
                                          u
                                          v
                                          d
                                       
                                       ,
                                       
                                          τ
                                          g
                                       
                                    
                                 
                                 ,
                              
                           
                        where σ
                        
                           c
                         and σ
                        
                           g
                         are the weight parameters to balance the census and gradient terms, and τ
                        
                           c
                         and τ
                        
                           g
                         truncate the matching costs. This approach will limit the impact of outliers. Such a measurement combination has been shown to be resilient to illumination changes and is commonly used [3,15,23,24]. This matching model is also robust with respect to outliers. In Section 4.1, we will discuss the parameter settings further.

The purpose of the applied superpixel segmentation is twofold. Firstly, the local measurements are more robust to noise variations, since an entire superpixel is matched to the target image, instead of performing pixel-wise matching. Secondly, the computation time is decreased due to the reduction in graph size, which also leads to a reduction in memory requirements. In the proposed framework, the simple linear iterative clustering (SLIC) algorithm [25] is used for superpixel segmentation. The superpixel-wise cost function is given by:
                           
                              (6)
                              
                                 
                                    F
                                    r
                                 
                                 
                                    s
                                    d
                                 
                                 =
                                 
                                    1
                                    
                                       n
                                       s
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          
                                             u
                                             v
                                          
                                          ∈
                                          s
                                       
                                    
                                    
                                 
                                 
                                    P
                                    r
                                 
                                 
                                    u
                                    v
                                    d
                                 
                                 ,
                              
                           
                        where n
                        
                           s
                         is the number of pixels belonging to the superpixel s and F(s,
                        d) is the superpixel-wise cost function. The left matching cost, F
                        
                           l
                        (s,
                        d), and right matching cost, F
                        
                           r
                        (s,
                        d), are individually computed. Our cost function will truncate the outliers during the pixel-wise matching process. Superpixel-wise cost functions are non-linear, and more robust than pixel-wise matching owing to this truncation.

We briefly present the relationship between RWR and BP before progressing to describe the proposed algorithms. The GC and BP algorithms have been used extensively in stereo matching applications. Tappen and Freeman [26] presented a comparison of GC and BP using an identical MRF model. Their results showed that the two algorithms are comparable with respect to accuracy, yet BP is faster than GC. The standard BP algorithm is:
                              
                                 (7)
                                 
                                    
                                       m
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       
                                          p
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             p
                                             i
                                          
                                       
                                       
                                    
                                    
                                       ϕ
                                       i
                                    
                                    
                                       
                                          p
                                          i
                                       
                                    
                                    
                                       φ
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       
                                          p
                                          i
                                       
                                       
                                          p
                                          j
                                       
                                    
                                    
                                       
                                          ∏
                                          
                                             n
                                             ∈
                                             N
                                             
                                                i
                                             
                                             \
                                             j
                                          
                                       
                                       
                                    
                                    
                                       m
                                       
                                          n
                                          i
                                       
                                    
                                    
                                       
                                          p
                                          i
                                       
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (8)
                                 
                                    
                                       b
                                       i
                                    
                                    
                                       
                                          p
                                          i
                                       
                                    
                                    =
                                    κ
                                    
                                       ϕ
                                       i
                                    
                                    
                                       
                                          p
                                          i
                                       
                                    
                                    
                                       
                                          ∏
                                          
                                             j
                                             ∈
                                             N
                                             
                                                i
                                             
                                          
                                       
                                       
                                    
                                    
                                       m
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       
                                          p
                                          i
                                       
                                    
                                    ,
                                 
                              
                           where m represents the message between node i and j; N(i) denotes neighborhoods; and ϕ
                           
                              i
                           (p
                           
                              i
                           ) and φ
                           
                              ij
                           (p
                           
                              i
                           ,
                           p
                           
                              j
                           ) are unary and pair-wise potentials in the MRF model.

In contrast, the RWR algorithm proceeds as follows:
                              
                                 •
                                 Form the weighted graph matrix W with diagonal elements equal to zero.

Compute the matrix 
                                       
                                          W
                                          ¯
                                       
                                       =
                                       
                                          D
                                          
                                             −
                                             1
                                             /
                                             2
                                          
                                       
                                       W
                                       
                                          D
                                          
                                             −
                                             1
                                             /
                                             2
                                          
                                       
                                    , where D is a diagonal matrix whose diagonal elements are the sum of the row elements of matrix W.

Iteratively update 
                                       
                                          X
                                          
                                             t
                                             +
                                             1
                                          
                                       
                                       =
                                       c
                                       
                                          W
                                          ¯
                                       
                                       
                                          X
                                          t
                                       
                                       +
                                       
                                          
                                             1
                                             −
                                             c
                                          
                                       
                                       
                                          X
                                          0
                                       
                                     until convergence, where the parameter (1−
                                    c) denotes the restart probability.

During the iteration of the third step, each node interacts with its neighboring nodes, and is also influenced by its own initial information. This update method converges, and its result is equivalent to 
                              
                                 X
                                 t
                              
                              =
                              
                                 
                                    1
                                    −
                                    c
                                 
                              
                              
                                 
                                    I
                                    −
                                    c
                                    
                                       W
                                       ¯
                                    
                                 
                              
                              
                                 X
                                 0
                              
                           .

There are two benefits to using RWR instead of the conventional BP for cost optimization in stereo matching. The first merit is computational efficiency. The primary computational cost of the BP algorithm is in the message update step, and is proportional to the number of edges in the graph. Given graph G
                           =(ν,
                           ε), the BP algorithm updates 2×
                           ε messages per iteration. In comparison, the computational cost of RWR increases by ν per iteration. In most stereo matching algorithms, graph G is constructed based on the adjacency between nodes. As a result, the number of nodes is much smaller than the number of edges, i.e., ε
                           >
                           ν. Therefore, RWR has a lower computational complexity than the standard BP.

The second benefit is that RWR provides a theoretical guarantee of global optimality. The standard BP algorithm is only effective in tree-like graphs, but is widely used in loopy graphs. In principle, BP does not guarantee convergence to an optimal solution if the graph has cycles. In contrast, RWR provides one of the local minima in the quadratic energy function, where the global cost function is defined as:
                              
                                 (9)
                                 
                                    E
                                    
                                       X
                                    
                                    =
                                    μ
                                    
                                       E
                                       data
                                    
                                    
                                       X
                                    
                                    +
                                    
                                       E
                                       smooth
                                    
                                    
                                       X
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (10)
                                 
                                    
                                       E
                                       data
                                    
                                    
                                       X
                                    
                                    =
                                    
                                       
                                          ∑
                                          i
                                       
                                       
                                    
                                    
                                       
                                          
                                             
                                                x
                                                i
                                             
                                             −
                                             
                                                y
                                                i
                                             
                                          
                                       
                                       2
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (11)
                                 
                                    
                                       E
                                       smooth
                                    
                                    
                                       X
                                    
                                    =
                                    
                                       
                                          ∑
                                          i
                                       
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             j
                                             ∈
                                             N
                                             
                                                i
                                             
                                          
                                       
                                       
                                    
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       
                                          
                                             
                                                1
                                                
                                                   
                                                      D
                                                      
                                                         i
                                                         i
                                                      
                                                   
                                                
                                             
                                             
                                                x
                                                i
                                             
                                             −
                                             
                                                1
                                                
                                                   
                                                      D
                                                      
                                                         j
                                                         j
                                                      
                                                   
                                                
                                             
                                             
                                                x
                                                j
                                             
                                          
                                       
                                       2
                                    
                                    .
                                 
                              
                           
                        

The data energy term, E
                           
                              data
                           , comes from the observations made at each node, which means the final output cost x should not vary too much from the initially observed value y. The second term, the smoothness energy, E
                           
                              smooth
                           , is computed by considering the interaction between neighboring nodes, and requires the desired result to have only small differences between neighbors. Elements of the weighted matrix 
                              
                                 W
                                 ¯
                              
                            are denoted by w. The trade-off between these data and the smoothness terms is controlled by a positive parameter μ.

By differentiating the energy function E with respect to X, we can compute the minimum energy
                              
                                 (12)
                                 
                                    
                                       
                                          ∂
                                          E
                                       
                                       
                                          ∂
                                          X
                                       
                                    
                                    =
                                    X
                                    −
                                    
                                       W
                                       ¯
                                    
                                    X
                                    +
                                    μ
                                    
                                       
                                          X
                                          −
                                          Y
                                       
                                    
                                    =
                                    0
                                    ,
                                 
                              
                           and Eq. (12) is easily transformed into
                              
                                 (13)
                                 
                                    X
                                    −
                                    
                                       1
                                       
                                          1
                                          +
                                          μ
                                       
                                    
                                    
                                       W
                                       ¯
                                    
                                    X
                                    −
                                    
                                       μ
                                       
                                          1
                                          +
                                          μ
                                       
                                    
                                    Y
                                    =
                                    0
                                    ,
                                 
                              
                           and
                              
                                 (14)
                                 
                                    X
                                    =
                                    β
                                    
                                       
                                          
                                             I
                                             −
                                             α
                                             
                                                W
                                                ¯
                                             
                                          
                                       
                                       
                                          −
                                          1
                                       
                                    
                                    Y
                                    .
                                 
                              
                           
                        

Here, 
                              α
                              =
                              
                                 1
                                 
                                    1
                                    +
                                    μ
                                 
                              
                           , 
                              β
                              =
                              
                                 μ
                                 
                                    1
                                    +
                                    μ
                                 
                              
                           , and α
                           +
                           β
                           =1. When Y
                           =
                           X
                           0, Eq. (14) is identical to the closed form expression of the iterative update algorithm 
                              
                                 X
                                 t
                              
                              =
                              
                                 
                                    1
                                    −
                                    c
                                 
                              
                              
                                 
                                    I
                                    −
                                    c
                                    
                                       W
                                       ¯
                                    
                                 
                              
                              
                                 X
                                 0
                              
                           . Therefore, the RWR algorithm is guaranteed to provide one of the local minima of the global cost function; for a more detailed derivation, please refer to [27,28]. This smoothness constraint will tend to over-smooth the details of an image, causing problems in regions of occlusion or depth discontinuity. To improve these weaknesses, we propose an adaptive RWR algorithm (ARW) that is better suited to stereo matching.

The standard RWR algorithm is defined as:
                              
                                 (15)
                                 
                                    
                                       X
                                       
                                          t
                                          +
                                          1
                                       
                                       d
                                    
                                    =
                                    c
                                    
                                       W
                                       ¯
                                    
                                    
                                       X
                                       t
                                       d
                                    
                                    +
                                    
                                       
                                          1
                                          −
                                          c
                                       
                                    
                                    
                                       X
                                       0
                                       d
                                    
                                    ,
                                 
                              
                           where X
                           0
                           
                              d
                           
                           =[F(s,
                           d)]
                              k
                              ×1 denotes an initial matching cost, X
                           
                              t
                           
                           
                              d
                            represents the updated matching cost with t as the number of iterations, and k is the number of superpixels. The weighted matrix W
                           =[w
                           
                              ij
                           ]
                              k
                              ×
                              k
                            contains edge weights, and 
                              
                                 W
                                 ¯
                              
                            is obtained by normalizing the rows of W. The left and right matching costs are individually calculated.

The matching costs are propagated to neighboring nodes using a probability that is proportional to the edge weights, where the edge weights are influenced by the intensity similarity between neighboring superpixels:
                              
                                 (16)
                                 
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          1
                                          −
                                          
                                             τ
                                             e
                                          
                                       
                                    
                                    exp
                                    
                                       
                                          −
                                          
                                             
                                                
                                                   
                                                      I
                                                      
                                                         
                                                            s
                                                            i
                                                         
                                                      
                                                      −
                                                      I
                                                      
                                                         
                                                            s
                                                            j
                                                         
                                                      
                                                   
                                                
                                                2
                                             
                                             
                                                σ
                                                e
                                             
                                          
                                       
                                    
                                    +
                                    
                                       τ
                                       e
                                    
                                    ,
                                 
                              
                           where I(s
                           
                              i
                           ) and I(s
                           
                              j
                           ) are the intensities of the i
                           −th and j
                           −th superpixels, respectively, τ
                           
                              e
                            and σ
                           
                              e
                            are parameters that control the shape of the function. The superpixel intensity is computed by averaging the intensity of its corresponding pixels. Eq. (16) assumes that superpixels that have similar intensity are more likely to have greater influence.

The matching costs are updated iteratively until convergence is achieved. The RWR method provides one local minima, but the limitations of the smoothness constraint mean that it will often fail to provide a good solution. Thus, we have modified the standard update algorithm to adaptively update the matching costs based on the current determination of which superpixels are located in regions of occlusion or depth discontinuity.

The smoothness assumption will typically fail at occlusion or depth discontinuity regions. The smoothness constraint assumes that the disparities of the neighboring pixels are similar. It is often modeled by penalizing different disparities with additional costs in the optimization framework. However, the pixels located in occlusion regions cannot observe a ground truth matching point. In order to account for the occlusion problem, we formulate a visibility constraint within the RWR framework that requires an occluded pixel to have no match on the target image, and a non-occluded pixel to have at least one match.


                           
                              
                                 (17)
                                 
                                    
                                       O
                                       t
                                    
                                    
                                       s
                                    
                                    =
                                    
                                       
                                          
                                             
                                                1
                                                
                                                if
                                                
                                                |
                                                
                                                   D
                                                   r
                                                
                                                
                                                   
                                                      u
                                                      s
                                                   
                                                   
                                                      v
                                                      s
                                                   
                                                
                                                −
                                                
                                                   D
                                                   l
                                                
                                                
                                                   
                                                      
                                                         u
                                                         s
                                                      
                                                      +
                                                      
                                                         D
                                                         r
                                                      
                                                      
                                                         
                                                            u
                                                            s
                                                         
                                                         
                                                            v
                                                            s
                                                         
                                                      
                                                      ,
                                                      
                                                         v
                                                         s
                                                      
                                                   
                                                
                                                |
                                                ≤
                                                1
                                                ,
                                             
                                          
                                          
                                             
                                                0
                                                
                                                if
                                                
                                                |
                                                
                                                   D
                                                   r
                                                
                                                
                                                   
                                                      u
                                                      s
                                                   
                                                   
                                                      v
                                                      s
                                                   
                                                
                                                −
                                                
                                                   D
                                                   l
                                                
                                                
                                                   
                                                      
                                                         u
                                                         s
                                                      
                                                      +
                                                      
                                                         D
                                                         r
                                                      
                                                      
                                                         
                                                            u
                                                            s
                                                         
                                                         
                                                            v
                                                            s
                                                         
                                                      
                                                      ,
                                                      
                                                         v
                                                         s
                                                      
                                                   
                                                
                                                |
                                                >
                                                1
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where D
                           
                              l
                            and D
                           
                              r
                            are the current disparity maps of the left and right images, respectively, and u
                           
                              s
                            and v
                           
                              s
                            are the x and y centroids of the superpixel s. The disparity value from the reference and target disparity maps must be consistent for the left–right check. If this relation is not satisfied, then the superpixel is classified as an occluded superpixel. After the superpixels are validated, the detection result is vectorized as v
                           
                              t
                           
                           =[O
                           
                              t
                           (s)]
                              k
                              ×1. The matching costs are multiplied by the validation vector:
                              
                                 (18)
                                 
                                    
                                       V
                                       t
                                       d
                                    
                                    =
                                    
                                       X
                                       t
                                       d
                                    
                                    ⊙
                                    
                                       v
                                       t
                                    
                                 
                              
                           where ⊙ denotes the element-wise product function.

In addition, the smoothness assumption is easily violated in depth discontinuity regions. A depth discontinuity is typically caused where disparity values between the foreground and background vary considerably. In these areas, the depth boundaries are blurred due to the smoothness penalties. In order to prevent such problems, we include an additional fidelity term. A superpixel calculates its optimal disparity value based on the current matching cost:
                              
                                 (19)
                                 
                                    
                                       
                                          d
                                          i
                                       
                                       ′
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                ∈
                                                N
                                                
                                                   i
                                                
                                                ∪
                                                i
                                             
                                          
                                          
                                             
                                                w
                                                
                                                   i
                                                   j
                                                
                                             
                                             
                                                
                                                   d
                                                   ¯
                                                
                                                j
                                             
                                             
                                                O
                                                t
                                             
                                             
                                                
                                                   s
                                                   j
                                                
                                             
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                ∈
                                                N
                                                
                                                   i
                                                
                                                ∪
                                                i
                                             
                                          
                                          
                                             
                                                w
                                                
                                                   i
                                                   j
                                                
                                             
                                             
                                                O
                                                t
                                             
                                             
                                                
                                                   s
                                                   j
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where w
                           
                              ij
                            is the similarity between two neighboring superpixels computed in Eq. (16), j denotes the index of the neighboring superpixel of the i-th superpixel, O
                           
                              t
                           (s
                           
                              j
                           ) is the result of the left–right consistency check, 
                              
                                 
                                    d
                                    ¯
                                 
                                 j
                              
                            is the optimal disparity of the neighboring superpixel in the current state, and 
                              
                                 d
                                 
                                    i
                                    ′
                                 
                              
                            is the weighted disparity value of itself.

The fidelity term is calculated using the disparity value. We introduce a robust penalty function, defined as:
                              
                                 (20)
                                 
                                    
                                       ψ
                                       t
                                    
                                    
                                       d
                                       
                                          d
                                          ′
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  d
                                                                  ′
                                                               
                                                               −
                                                               d
                                                            
                                                         
                                                         /
                                                         
                                                            σ
                                                            ψ
                                                         
                                                      
                                                   
                                                   2
                                                
                                                ,
                                                
                                                if
                                                
                                                |
                                                
                                                   d
                                                   ′
                                                
                                                −
                                                d
                                                |
                                                ≤
                                                
                                                   τ
                                                   ψ
                                                
                                                ,
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            τ
                                                            ψ
                                                         
                                                         /
                                                         
                                                            σ
                                                            ψ
                                                         
                                                      
                                                   
                                                   2
                                                
                                                ,
                                                
                                                if
                                                
                                                |
                                                
                                                   d
                                                   ′
                                                
                                                −
                                                d
                                                |
                                                >
                                                
                                                   τ
                                                   ψ
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where d′ is the disparity computed in Eq. (19), σ
                           
                              ψ
                            is the scaling parameter, and τ
                           
                              ψ
                            denotes the truncation parameter. These two parameters play an important role in order to control the robust penalty function.

The purpose of this function is twofold. Firstly, it preserves the depth boundaries by conserving the intensity difference of neighboring superpixels; general smoothness constraints tend to blur small objects into the background, but this retains small details. Secondly, it is used to approximate the data term. In relation to the former purpose, the truncation parameter, τ
                           
                              ψ
                           , of Eq. (20) denotes the disparities between neighborhoods, which may vary within τ
                           
                              ψ
                           . Otherwise, it will allow a depth discontinuity. Therefore, the fidelity term can preserve the depth boundaries. In relation to the latter purpose, when the local matching is performed, the matching cost of each superpixel can be heavily saw-toothed and contain many local minima. This is the main reason why the local minimum computed from the optimization process provides an unsatisfactory result. To reduce the chance of being trapped in an unfavorable local minimum, several optimization methods have been proposed, such as convex-hull filtering [29]. Similarly, our penalty function helps avoid undesired solutions by preventing the model from over-fitting.

The proposed algorithm updates the matching cost iteratively as:
                              
                                 (21)
                                 
                                    
                                       X
                                       
                                          t
                                          +
                                          1
                                       
                                       d
                                    
                                    =
                                    c
                                    
                                       W
                                       ¯
                                    
                                    
                                       
                                          
                                             
                                                1
                                                −
                                                λ
                                             
                                          
                                          
                                             V
                                             t
                                             d
                                          
                                          +
                                          λ
                                          
                                             Ψ
                                             t
                                             d
                                          
                                       
                                    
                                    +
                                    
                                       
                                          1
                                          −
                                          c
                                       
                                    
                                    
                                       X
                                       0
                                       d
                                    
                                    ,
                                 
                              
                           where Ψ
                           
                              t
                           
                           
                              d
                           
                           =[ψ
                           
                              t
                           (d
                           
                              i
                           
                           ′)]
                              M
                              ×1 is the robust fidelity term computed in Eq. (20), V
                           
                              t
                           
                           
                              d
                            denotes the visibility term computed from Eq. (18), and λ leverages the visibility and fidelity terms. The visibility and fidelity terms are determined based on the current matching cost X
                           
                              t
                           
                           
                              d
                           . The matching costs are propagated along the graph 
                              
                                 W
                                 ¯
                              
                           , with the initial matching costs being aggregated to the current matching costs, which are proportional to the restart probability (1−
                           c). The final disparity map is constructed by combining the superpixel and pixel-wise matching cost.


                           
                              
                                 (22)
                                 
                                    
                                       d
                                       ^
                                    
                                    =
                                    
                                       
                                          arg
                                          
                                          min
                                       
                                       d
                                    
                                    
                                       
                                          
                                             X
                                             t
                                             d
                                          
                                          
                                             s
                                          
                                          +
                                          γ
                                          P
                                          
                                             u
                                             v
                                             d
                                          
                                       
                                    
                                 
                              
                           where s is the superpixel corresponding to pixel (u,
                           v), and γ denotes the weighting of the superpixel and pixel-wise matching cost.

The proposed algorithm proceeds as follows:
                              
                                 •
                                 Compute the local matching cost for each pixel using the truncated weighted sum of the census transform and gradient image matching: Eq. (5).

Aggregate the matching costs inside each superpixel: Eq. (6).

Compute the visibility term based on the current matching cost: Eq. (18).

Compute the fidelity term using the robust penalty function: Eq. (20).

Update the matching costs: Eq. (21).

Iterate Steps 3 to 5, and determine the final disparity from the minimum cost: Eq. (22).

The next section is organized as follows. The parameter settings are first described. The quantitative results are then presented and compared with existing state-of-the-art methods using benchmark test sets, and an extensive analysis of the experimental results is performed.

We used the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) training dataset to select our parameters. The KITTI training dataset contains 194 high-resolution images with accurate ground truths. Our parameters were tested on this training dataset. The disparity maps are computed using the proposed algorithm, and then compared with the ground truths. If the difference between the computed disparity and the ground truth is greater than 3pixels, it is classified as an error pixel. The 3-pixel error threshold is the default value in the benchmark system. We measured the percentage of mislabeled pixels with the initial, empirically chosen parameter values. We then varied these parameters incrementally until the mean errors were bounded. The parameters were then trained with this method.

We set four truncation parameters, τ
                        
                           c
                        
                        =5, τ
                        
                           g
                        
                        =1.7, τ
                        
                           e
                        
                        =0.2, and τ
                        
                           ψ
                        
                        =7, and four scale parameters, σ
                        
                           c
                        
                        =0.2, σ
                        
                           g
                        
                        =1.0, σ
                        
                           e
                        
                        =20, and σ
                        
                           ψ
                        
                        =85. In our ARW algorithm, the restart probability was set to (1−
                        c)=0.0015, and the weight parameters were set to λ
                        =0.5 and γ
                        =0.005. These control the balance between the visibility and penalty (λ), and the superpixel and pixel-wise matching costs (γ). The number of iterations was set to 15, because the mean error for the KITTI training dataset was almost unchanged beyond this number. The SLIC parameters, which determine the desired number of superpixels and the weighting between color similarity and spatial proximity, were set to K
                        =16,000 and M
                        =5, respectively. Fig. 2
                         shows the stereo matching results on the KITTI training dataset. The average error of the proposed algorithm with trained parameters was 5.85%.

The Middlebury benchmark has been widely used over the last decade to evaluate the performance of stereo matching algorithms. Many algorithms have been tested against the benchmark, with those that score highly demonstrating small errors. Specifically, many highly scoring algorithms recorded errors less than 0.5% on the Venus image. However, Geiger [30] proposed an additional novel challenging benchmark called the KITTI benchmark. Geiger also described the difference between the two datasets. The Middlebury benchmark dataset is well textured and provides a smaller label set, and the benchmark images are also largely fronto-parallel and Lambertian. In contrast, the KITTI dataset images are captured in outdoor environments. Thus, the images contain many non-Lambertian regions, specularities, and strongly slanted regions. The KITTI dataset requires a large label set due to a wide base-line. Geiger demonstrated that conventional algorithms that do well on the Middlebury benchmark, such as pixel-wise GC [31] and cost–volume filtering [3], had much higher errors on the KITTI benchmark. They claimed that the algorithms are over-fitted to the small set of images (Tsukuba, Venus, Teddy, and Cones). We use both datasets for more thorough evaluation.

In the remainder of this section, we give a quantitative analysis of our proposed method using both benchmarks. We use the KITTI benchmark to evaluate the proposed algorithm by comparing against existing state-of-the-art methods. The traditional Middlebury dataset is also used to compare with other algorithms, and to measure the robustness of the proposed method in the presence of radiometric changes. The proposed method is then tested on challenging real-world sequences. We use the parameters that were validated on the KITTI training dataset. All experiments are conducted on a single Intel Core i7 CPU running at 3.4GHz.

The KITTI dataset provides a collection of high-resolution images, demonstrating an outdoor stereo dataset with an accurate ground truth. The ground truth was obtained using a Velodyne HDL-34E sensor. The dataset is composed of 194 training and 195 test images, and was captured using an autonomous driving system in an urban environment. The image resolution is approximately 124×376. The ground truth of the training dataset is provided, while the ground truth of the testing dataset has not been released, in order to prevent parameter tuning.

We tested our proposed algorithm using the KITTI benchmark dataset in order to quantitatively evaluate its performance. In Table 1
                           , the performance results on the KITTI benchmark test dataset are shown. The KITTI benchmark provides four different error thresholds. The main ranking is computed using a 3-pixel error threshold and 195 test images. Out-All is the percentage of error pixels in total, Out-Noc is the percentage of erroneous pixels in non-occluded regions, Avg-Noc is the computed average disparity over the end-point error in the non-occluded areas, and Avg-All is the calculated total. These results demonstrate that our proposed algorithm ranks quite highly with the existing methods. The proposed method recorded 6.87% Out-All errors and 5.20% Out-Noc errors on the benchmark test. The performance of our algorithm is comparable to SGM and other SGM variants, such as iterative SGM (iSGM) and weighted SGM (wSGM) with respect to accuracy and processing time. The original SGM gives 7.00% Out-All errors and 5.76% errors, where iSGM and wSGM are slightly better. In our tests, the processing time of SGM was 3.7s, while our method took 4.6s. The increase seen in our method is because we compute both left and right disparity maps, and the maximum search range was set to a disparity of 150. In comparison, when SGM was performed on a maximum disparity of 100, only one disparity map was computed. Setting the maximum search range of the proposed method to a disparity of 100 produced a runtime of 3.27s (local matching took 1.37s, superpixel segmentation took 0.73s, and optimization took 1.17s). Yamaguchi [16] and their extended version [32] proposed a slanted-plane MRF model, demonstrating its high performance. However, their method required significant computational time (more than five minutes). It can be seen that the traditional pixel-wise GC [31] and cost–volume filtering [3] methods give sufficiently high errors on the benchmark test set.

The Middlebury dataset has been used to evaluate the performance of many classical algorithms. The test dataset is composed of four stereo pairs (Tsukuba, Venus, Teddy, and Cones). We tested the proposed algorithm using the Middlebury dataset, and compared with other well-known stereo matching algorithms [3,5,13]. All experiments were conducted in the same environment and with the same maximum disparity set-up. The input images and resultant disparity maps are shown in Fig. 3
                           . The accuracy and processing time of the algorithms for each stereo pair are given in Table 3
                           
                           . The results show that CostFilter was the most accurate algorithm, and ELAS was the fastest. However, CostFilter required an average computation time of 2min, and ELAS exhibited relatively poor accuracy. The accuracy of the proposed algorithm was comparable to that of DBP and CostFilter, while being much faster. (Note that CostFilter produced much higher error rates on the KITTI dataset; see Table 2.)

In a real-world environment, there are various factors that can impact or distort the intensity value of corresponding pixels. The primary reason for this is due to radiometric changes, including variations in illumination and camera exposure fluctuations. Some image pairs in the Middlebury dataset provide nine images, which are taken with three different exposures and under three different illumination conditions. In order to perform a quantitative investigation of the effects of radiometric variation, we perform experiments using these images. We used the test bed images (dolls, moebius, reindeer, books, aloe, baby1, cloth1, rocks1, and wood1). The error threshold was fixed to 3pixels. In Fig. 4
                           , the stereo matching results on the varying illumination and exposure test set are shown. The left and right images are taken under very different illumination and exposure conditions. The reference image was set to the (I1, E2) condition, while the target image varies by the nine different combinations. It can be seen that the proposed method works quite well, because of its robust local matching and cost aggregation functions. In Table 4
                           , the percentage of mislabeled pixels is shown, where it can be seen that the total average error is 7.03%.

The Middlebury dataset has been used by many classical algorithms to determine their performance. The dataset provides various images and accurate ground truths. However, it suffers from a few limitations, such as the large proportion of fronto-parallel and rich texture images. Due to this, some algorithms that rank quite highly on the Middlebury dataset do not perform particularly well in outdoor environments. In this work, we tested our proposed method on a real-world outdoor environment using a stereo camera. The images were gathered using a Point Grey Bumblebee stereo camera (BB2-08S2C-38) in a commercial street. We qualitatively compared our ARW algorithm with ELAS, DBP, and CostFilter. The results are shown in Fig. 5
                           . It can be seen that the input images contain challenging areas, such as sensor saturation, strongly slanted planes, and areas of low texture. The results demonstrate how the DBP algorithm fails to obtain the correct disparity map; pixels are incorrectly matched at texture-less areas, and details become over smoothed. ELAS and CostFilter produced better results than DBP. However, the disparity map given by ELAS is less dense and blurred. CostFilter also over-smooths in slanted regions such as roads, and generates more mislabeled disparities. In comparison, our ARW method produces superior results.

In this experiment, we compared the computation time of the proposed algorithm and a BP-based stereo algorithm. Yang [13] proposed the DBP algorithm, and demonstrated that it is very fast while maintaining similar accuracy to BP. They suggested that the runtime of DBP is sub-linear with respect to the number of iterations. The computational time for local matching and optimization depends on the maximum search range (maximum disparity). We measured the processing time on the KITTI training dataset and our outdoor images. In Fig. 6
                           , the processing time with increasing search range is presented, showing that the computational time actually increases linearly. In comparison, our proposed method was faster than DBP for both images. The runtime on a 470×360pixel image with a maximum disparity of 50 was approximately 0.86s (local matching took 0.23s, superpixel segmentation took 0.21s, and optimization took 0.42s). In addition, unlike DBP, the runtime of the ARW algorithm does not increase rapidly with the image size. The experimental results show that our method is more efficient than the BP-based algorithm, making it ideal for high-resolution and large baseline images.

Illumination and exposure variations in an outdoor environment hinder the determination of an accurate correspondence between scenes. The simplest local matching methods are the sum of squared intensity differences (SSD), and the sum of absolute intensity differences (SAD). As these methods are sensitive to changes in illumination and to image noise, many methods have been developed to overcome such problems. We compared four different local matching methods that are known to be robust to radiometric changes: normalized cross correlation (NCC), combination of SAD and gradient, SAD and census transform, and gradient and census transform. We used these methods for the local matching in our ARW framework. The window size for the Sobel filter, census transform, and NCC or SAD was set to 5×5. Each algorithm was tested on the KITTI training dataset to enable a quantitative comparison. The test results are shown in Table 5
                           . In this experiment, all matching methods were found to be comparable, with the census transform and gradient matching giving the best results (average of 5.85% error on the dataset; SAD and gradient: 6.02%, SAD and census: 7.07%, and NCC: 8.21%).

We employed the superpixel segmentation technique to improve performance, and investigated the effect of varying the superpixel size. We adjusted the parameter K to vary the superpixel size from approximately 3×3 to 10×10. This experiment was conducted on the KITTI training dataset with a maximum disparity of 150. The experimental results for the average error and runtime are shown in Fig. 7
                           . This graph shows that the proposed algorithm achieves a good compromise at the 5×5 size, with 5.85% error and a runtime of 4.61s.

In this paper, we proposed an adaptive RWR algorithm. We introduced visibility and robust fidelity terms and compared the modified method with the original RWR algorithm to evaluate the effect of these additional terms. In Fig. 8
                           , the stereo matching results are shown for the two different methods. The circles show the regions where the original RWR algorithm over-smooths in low-texture regions, and faces border bleeding effect at depth boundaries. Specifically, small and thin objects, such as the streetlights and trees, have been blended into the background. In addition, highly slanted features, such as the roads, are over-smoothed. ARW solves this problem and is seen to produce superior results. The errors of two example images were significantly reduced from 6.54% and 11.38% to 1.58% and 4.62%, respectively. We verified that the proposed method reduced the average errors from 11.16% to 5.85% on the KITTI training dataset. This demonstrates the optimization effectiveness of the two terms.

The proposed method introduces a robust penalty function, of which there are many forms. We tested the proposed method with various widely used penalty functions. In Fig. 9
                           , some common functions are shown, namely the truncated quadratic, truncated linear, truncated log, and Huber functions. The Huber function is quadratic for values below the truncation value, and linear for values above. We adjusted the parameters of our method to be suitable for each penalty function, and tested on the KITTI training dataset. The results were 5.85%, 6.97%, 7.26%, and 6.08% for the truncated quadratic, truncated linear, truncated log, and Huber functions, respectively. The performance of the Huber function in our experiments was comparable to the truncated quadratic. However, the truncated linear and truncated log functions demonstrated a lower accuracy.

@&#CONCLUSION@&#

In this paper, we designed and evaluated a novel stereo matching algorithm. The proposed method employs a random walk with restart algorithm to efficiently optimize the matching cost. This removes the requirement for a conventional optimization algorithm. We introduced the visibility and fidelity terms within the optimization framework in order to improve the matching quality. We demonstrated that these two terms play an important role in improving the accuracy. The proposed method used a combination of the census transform and gradient matching in the local matching step to then aggregate the pixel-wise matching costs to the respective superpixels. Although lighting conditions between two images can vary widely, corresponding features were matched accurately due to these factors.

We used the KITTI and Middlebury datasets to evaluate the performance of our proposed method. It was shown that our algorithm is comparable to existing state-of-the-art algorithms. Our experiments using the Middlebury dataset also demonstrated its tolerance to radiometric variations. In addition, we demonstrated the method's applicability to outdoor environments using a stereo camera. In many parts of the proposed algorithm, such as superpixel segmentation, local matching, and optimization, the left and right images are individually processed. This will allow a reduction in processing time by the application of multi-core programming concepts, and will form the basis of our future work.

@&#ACKNOWLEDGMENT@&#

This work was supported by the ICT R&D programs of MSIP/IITP (No. 10047078) and by the Industrial Strategic Technology Development Program (10044009) funded by the Ministry of Trade, Industry and Energy (MOTIE, Korea).

The following is the supplementary data to this article.
                        
                           
                              Supplementary video.
                           
                           
                        
                     
                     
                        
                           
                              Supplementary material.
                           
                           
                        
                     
                  

Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2015.01.003.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Person identification using vascular and non-vascular retinal features

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Novel methods for personal identification using retinal images.


                        
                        
                           
                           Vascular based method involves the use of vessel properties of retinal images with improved vessel segmentation algorithm by catering pathological lesions.


                        
                        
                           
                           Non-vascular based method uses novel structural features structure to perform person identification.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Biometric system

Retina recognition

Vascular-based retinal recognition

Non-vascular-based retinal recognition

@&#ABSTRACT@&#


               
               
                  Retina recognition is the most stable and reliable biometric system due to its stability, uniqueness and non-replicable nature of vascular pattern. On the other hand, the complexity of vascular pattern in diseased retina makes the extraction of blood vessels very hard, which majorally effects the recognition rate. The main aim of this paper is to design a robust retinal recognition system with reduced computational complexity and to explore novel retinal features. This paper presents two different approaches for retinal recognition; one is vascular-based feature extraction with an improved vessel segmentation algorithm and second is non-vascular based feature extraction. Vascular-based method uses vessel properties of retinal images and aims to improve the efficiency of retinal recognition system. Whereas, non-vascular based method intends to analyze non-vessel properties of retinal images in order to reduce time complexity. The proposed system is assessed on two local and three public databases.
               
            

@&#INTRODUCTION@&#

Nowadays biometrics technology plays a vital role in public security and information security domains [1]. The technique of automatic identification of an individual based on his physiological and behavioral traits is called biometric authentication. Biometric is the most reliable authentication system in digital security systems. The main contribution of biometrics is in security systems for authentication purposes [2]. Traditional methods use PIN number, passwords and keys etc., for person’s identification which provide a low level security [3]. A biometric system provides a high security access system. It also provides more reliable features than password based authentication system. Moreover, these features cannot be lost, forgotten, duplicated and require the person to be present for authentication process.

In general a biometric authentication system is a pattern recognition system which compares a registered biometric sample with a query biometric sample [2]. Depending on the scenarios, a biometric system can either be an identification system (one-to-many) which determines person’s identity without his consent or a verification system (one-to-one) which verifies person’s identity. Generally it works by capturing feature sample such as acquiring digital retinal image for retinal recognition, then sample is transformed into biometric template to get the discriminative representation of the feature [1]. At the end, these samples are compared with other samples to determine the identity.

A number of biometric traits are developed and used for person identification. The key idea is to use special traits for person identification such as face, iris, retina, hand and palm geometry, signature, voice etc. The critical attributes of these traits for reliable recognition are the variations of these traits across the human population, uniqueness and their immutability over time [1]. Human retina is the best characteristic when we consider the above attributes for a biometric recognition system. It provides many advantages over other traits such as blood vessels pattern in retina are unique, studies have revealed this fact that they are unique even in identical twins [4]. They ultimately make a good differentiation among people. Furthermore, they cannot be duplicated and do not change over the time [2]. Owing to these properties, retina based identification and recognition system is the most stable and accurate biometric system.

A reliable and efficient retina recognition system is characterized by the accuracy of the system. However in these systems, recognition rate is greatly affected by the vasculature complexity of retinal images. Generally, healthy retina has neat pattern of blood vessels as shown in Fig. 1
                     . Segmentation of these blood vessels is not a challenging task, as they don’t have any abnormalities in their pattern and neither do they effect the recognition rate. However, this vascular pattern becomes very complex in diseased retinal images due to the presence of pathological signs. These pathological signs appear as holes and bunches in the retinal vascular map as shown in Fig. 2
                     . These false structures appear as false positives and cause misidentification and increase false recognition rate. Therefore, we need an automated segmentation algorithm which can remove these abnormalities before matching and can also reduce false recognition rate.

Furthermore in any retinal recognition system, matching is an important phase which makes the final decision [1]. Matching greatly depends on the feature extraction phase which has great impact on the performance of retinal recognition system. In this context, this paper addresses aforementioned issues and proposes two different feature extraction methods for retina recognition. First method is vascular-based method with an improved vessel segmentation algorithm. It caters the issue of presence of false positives due to pathological structures in retinal images. This method first intends to remove false vessels due to pathological signs and segments out true vessels only. In next step, it extracts features based on vessels properties to perform matching. On the other hand, second proposed approach is non-vascular-based method which extracts novel structural features from retinal color images i.e., luminance, contrast and structure followed by matching. This paper also signifies the advantages of both methods in the light of system’s performance.

Rest of the paper is structured as follows, Section 2 highlights some previous techniques on person identification using various retinal features. Section 3 explains proposed methodology and results are given in Section 4 while Section 5 concludes the paper at the end.

@&#RELATED WORK@&#

Several techniques for person identification using retinal features have been proposed in past few years. Some methods use vascular pattern properties to extract retinal features for person recognition, while other methods use other properties of retinal images by using either the optic disk (OD) or image organization properties. Based upon these different kind of features, feature extraction phase is divided into two main categories; vascular-based feature extraction and non-vascular-based feature extraction.

In general, vascular-based methods use vessel properties by extracting minutiae points from segmented blood vessel pattern. It requires a neat blood vessel pattern with true vessels only, which becomes challenging in the presence of lesions in diseased retinal images. A lot of research has been done on retinal blood vessel segmentation using different techniques. A novel algorithm for extraction of blood vessels and bifurcation points to perform personal identification was proposed by M. B. Patwari et al. [5]. It used Histogram equalization in pre-processing step to enhance image, followed by morphological operations and 2-D median filtering for the extraction of blood vessels. Blood vessels center lines were extracted by morphological skeletonisation process. Minutiae point extraction technique was applied for the extraction of bifurcation points. Finally, product moment correlation co-efficient based matching was performed on 300 images to assess system’s performance. Another efficient vascular based retina recognition algorithm (RPRA) using the intersection points was proposed in [6] by Islam et al. In first step, fovea center and optic nerve center were detected as reference points. Blood vessel segmentation was performed using maximum principal curvature of Hessian matrix, followed by thresholding and thinning algorithm. Intersection points were extracted as matching features which collectively form a matching template in last stage of matching using local database having 18 images. Wang et al., [7] came up with a supervised hybrid approach for vessel segmentation. Convolutional Neural Network (CNN) classifier was used to extract hierarchical features. This classifier extracted some scale and rotational invariant features. Then, Random Forests (RFs) classifier along with the “winner-takes-all” technique was used to classify pixels into vessels and non-vessels parts. Method was assessed on the STARE and DRIVE databases. Imani et al., [8] presented an improved method on vessels detection using Morphological Component Analysis (MCA). First of all, MCA algorithm with the suitable transforms was employed to separate lesions and vessels parts. Then, Morlet Wavelet transform was used for image enhancement. Finally, accurate vessel map was extracted by adaptive thresholding. Proposed system was evaluated with DRIVE and STARE databases.

On the other hand, non-vascular based methods perform personal identification using other properties of retinal images like use of optic disk features or image organization’s attributes. Rehman et al., [9] presented a non-vascular based algorithm for retinal features extraction. It was based on image analysis and image statistics which worked in four stages; background elimination using threshold technique, local contrast enhancement for the identification of region of interest (ROI), followed by feature extraction and matching phase. In image analysis, ROI was extracted and its histogram was analyzed to generate a feature vector. In next step, shape based features from HSV (Hue Saturation Value) color space was extracted along with texture features using Gray-Level Co-Occurrence Matrix (GLCM) in four different directions. A local database of 60 images of 30 individuals was used to assess algorithm’s performance based on Euclidean distance based classifier. An efficient person identification algorithm using blood vessels around OD of human retina was stated in [10]. In first stage, OD was localized and rotation compensation is performed using template matching. In second stage, ring shaped vessels region around OD (ROI) was extracted. Polar transformation was applied on selected ROI followed by vessel enhancement. In next step, radon transformation was applied on polar image in order to generate feature vector. Each feature vector was containing both directional and local information determining the location of vessel. Feature vector for all train images were enrolled in database. Test feature vector was formed in same manner and matched with enrolled ones by first applying 1D Discrete Fourier Transform (DFT) on both test and enrolled templates. Absolute value of DFT was taken in feature vector and matching decision was made on the basis of minimum Euclidean Distance Classifier. System was tested on 40 DRIVE images of 40 different images, each of which was rotated five times using different angles making a database of 200 images. Another robust retina identification algorithm using Fourier transform and special partitioning was presented by A. Zahedi et al. [11]. Proposed method performed feature extraction without pre-processing phase in order to reduce time complexity. Firstly, rotation compensation method was applied using template matching technique. In feature extraction phase, Fourier transform was applied on rotational compensated image which was then partitioned into several half circles with same center. Energy of each partition of upper half circle was calculated and used as Fourier Energy Feature (FEF). Each feature vector included FEFs of all partitions for train persons which formed database. While FEF feature vector of test image was matched with all registered vectors using Manhattan Distance using database of 200 images of 20 different individuals.

It is observed from the literature that most of the previously presented retina recognition techniques are vascular-based methods. These methods perform retina recognition using vessel properties of retinal vascular pattern as features. They perform well in terms of recognition rate but they have become computationally expensive. Furthermore, they fail to work well in the presence of lesions. This motivates us to design a vascular-based method which would be able to perform well even in the presence of lesions. Moreover, very less work has been observed on retina recognition using features other than vessel properties. This gives us a motivation to explore other novel features of retina images such as use of retina image organization, optic disk etc., and design a system which is computationally efficient in terms of processing time and recognition rate. In this context, this paper proposes two different retina recognition methods; vascular-based method and non-vascular-based method. First approach is vascular-based feature extraction with an improved blood vessels segmentation technique. It first removes false vessels due to lesions from segmented blood vessels, then extracts minutiae points and generates feature vector using minutiae points to perform matching. Second approach is non-vascular-based feature extraction, which uses original color image to extract structural features in order to perform matching. This paper also highlights the significance of both methods.

@&#PROPOSED METHOD@&#

In this section, we explain our proposed techniques in detail. The proposed technique has two retina recognition algorithms; first is vascular-based feature extraction method with an improved blood vessel segmentation algorithm and second technique is non-vascular-based feature extraction. Vascular-based method uses vascular properties of retinal image while non-vascular based method uses other properties like OD boundaries and image organization properties etc.

The proposed method presents a vascular-based feature extraction which uses minutiae points for person recognition. It requires segmentation of blood vessels for the extraction of minutiae points. Segmentation of blood vessels becomes challenging in the presence of abnormal structures like lesions which produce false positives and ultimately result in high false recognition rate. To address aforementioned issue, this method presents an improved blood vessel segmentation algorithm before feature extraction. Flow diagram of this algorithm is shown in Fig. 3
                        . The proposed algorithm has two modules; enrollment module and identification module as shown in Fig. 3. Enrollment is an offline processing where retinal image is given as input, firstly it undergoes the preprocessing and then blood vessels are segmented using proposed vessel segmentation algorithm. It gives a neat retinal vascular map which contains true vessels only. In next step, minutiae (bifurcations and ending points) are extracted from segmented vessels which generates feature vectors and are stored into the database as enrolled templates. On the other hand, Identification module is an online module where query image undergoes the same steps till feature extraction and its feature set is formulated likewise. In matching phase, query feature vector is compared with enrolled feature vectors by using matching technique of Cosine Similarity Index to determine identity as genuine match or imposter match.

In the proposed retinal recognition system, first stage is reliable segmentation of blood vessels. The blood vessels are enhanced using 2D Gabor Wavelets [12]. Gabor wavelets are tuneable according to any specific frequencies and orientations which is useful for both thick and thin vessels for enhancement. The expressions for Gabor wavelet and its Fourier transform are defined as

                              
                                 (1)
                                 
                                    
                                       
                                          Φ
                                          G
                                       
                                       
                                          (
                                          x
                                          )
                                       
                                       =
                                       exp
                                       
                                       
                                          (
                                          j
                                          
                                             R
                                             0
                                          
                                          x
                                          )
                                       
                                       
                                          exp
                                          
                                          (
                                          −
                                       
                                       
                                          1
                                          2
                                       
                                       
                                          
                                             |
                                             a
                                             Ax
                                             |
                                          
                                          2
                                       
                                       
                                          )
                                       
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             Φ
                                             ^
                                          
                                          G
                                       
                                       
                                          (
                                          x
                                          )
                                       
                                       =
                                       
                                          
                                             (
                                             d
                                             e
                                             t
                                             
                                                A
                                                
                                                   −
                                                   1
                                                
                                             
                                             )
                                          
                                          
                                             1
                                             /
                                             2
                                          
                                       
                                       exp
                                       
                                       
                                          (
                                          −
                                          
                                             1
                                             2
                                          
                                          
                                             (
                                             
                                                A
                                                
                                                   −
                                                   1
                                                
                                             
                                             
                                                
                                                   (
                                                   R
                                                   −
                                                   
                                                      R
                                                      0
                                                   
                                                   )
                                                
                                                2
                                             
                                             )
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

Here 
                              
                                 x
                                 =
                                 [
                                 x
                              
                            
                           y]
                              T
                            and 
                              
                                 R
                                 0
                              
                            is a vector that defines the frequency of the complex exponential. A defines the wavelet anisotropy and elongation of filter in any desired direction. For each pixel position with fixed values of b and a, the Gabor wavelet transform 
                              
                                 
                                    W
                                    Φ
                                 
                                 
                                    (
                                    b
                                    ,
                                    θ
                                    ,
                                    a
                                    )
                                 
                              
                            is computed for θ spanning from 0
                              o
                            up to 165
                              o
                            at steps of 15
                              o
                            and the maximum is taken.

This wavelet application enhances the blood vessels but the response varies among the vessels due to variable thickness of vessels. So it is hard to find one optimal threshold value for accurate vascular extraction without any supervised algorithm. In proposed method, we have used a recursive supervised multilayered thresholding-based method for reliable blood vessel segmentation [12]. Afterwards, the output vessel map is given as input to vessel validation algorithm [13,14]. This method targets to remove all false vessels from the priori segmented vascular pattern in order to improve matching results. It consists of two main phases i.e., region based Feature extraction and Classification as illustrated in blood vessel segmentation block in Fig. 3 
                           [13].

                              
                                 1.
                                 Region based Feature extraction

In diseased retinal images, false vessels appear in the form of holes and bunches along with the true vessels. This step analyzes the retinal vascular regions and extracts region based features based on the morphological properties of true and false vessels. Each connected white pixels segment is taken as an input region for which a feature vector is formulated. This step extracts eleven discriminating features from segmented vessels as discussed in [13]. Fig. 4
                                     shows a clear shape based discrimination between true and false vessels and these changes are defined by shape based features i.e., Euler Number, Eccentricity, Convex Area, Extent, Filled Area, Major Axis Length, Minor Axis Length, and Solidity. Another difference between true and false vessels is that false vessels appear due to bright lesions and this difference is captured using intensity based features i.e., Max Intensity, Min Intensity, and Mean Intensity [13].

Classification

SVM classifier with RBF kernel is used to perform classification. It optimizes two parameters; penalty factor (C) and sigma (S) by applying 100 × 100 search grid with 2-folds cross validation. In next step, SVM uses best S and C values with 3-folds cross validation over 100 iterations to classify each vascular region into two classes i.e., true vessels or false vessels as shown in Fig. 4. This step of blood vessel segmentation algorithm results in neat binary vessel maps with true vessels only.

This step performs vascular-based feature extraction using vessel properties by extracting minutiae points (bifurcations and endings) using a windowing technique Crossing Number (CN) method [15]. Bifurcations are points where vessel splits into two branches while endings are points where vessel terminates. These feature points are extracted by using the expression given below:

                              
                                 (3)
                                 
                                    
                                       C
                                       
                                          (
                                          p
                                          )
                                       
                                       =
                                       
                                          1
                                          2
                                       
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          8
                                       
                                       ∣
                                       g
                                       
                                          (
                                          
                                             p
                                             
                                                i
                                                m
                                                o
                                                d
                                                8
                                             
                                          
                                          )
                                       
                                       −
                                       g
                                       
                                          (
                                          
                                             p
                                             
                                                i
                                                −
                                                1
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

where g is image and p is its vessel pixel. g(p) is vessel pixel and its value is one for vessel pixel otherwise its zero. C(p) is one and three for ending and bifurcation respectively.

Feature points extracted in previous step are used to form the feature vector for matching. This step forms the feature vector using Adjacent Orientation and distance. For every feature point, four nearest features are considered in order to calculate relative angle and relative distance between them. This adjacent distance and orientation based feature set gives a 1 × 8 rotation and translation invariant feature vector for each feature point. As shown in Fig. 5
                           , f
                           1 is taken as a candidate feature point with an orientation 
                              
                                 
                                    θ
                                    
                                       f
                                       1
                                    
                                 
                                 ,
                              
                            where f
                           2, f
                           3, f
                           4 and f
                           5 are four nearest feature points with the orientations 
                              
                                 
                                    θ
                                    
                                       f
                                       2
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 
                                    θ
                                    
                                       f
                                       3
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 θ
                                 
                                    f
                                    4
                                 
                              
                            and 
                              
                                 θ
                                 
                                    f
                                    5
                                 
                              
                            respectively. The orientation of each feature point actually shows the orientation of vessel segment to which each feature point is connected. Relative angles are computed by calculating difference between orientation of candidate feature point and orientations of four neighbor feature points as 
                              
                                 
                                    θ
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          2
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 
                                    θ
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          3
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 
                                    θ
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          4
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 θ
                                 
                                    
                                       f
                                       1
                                    
                                    
                                       f
                                       5
                                    
                                 
                              
                           . Similarly, distance between candidate feature point and its four nearest neighbors are computed based on Euclidean distance as 
                              
                                 
                                    d
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          2
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 
                                    d
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          3
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 
                                    d
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          f
                                          4
                                       
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 d
                                 
                                    
                                       f
                                       1
                                    
                                    
                                       f
                                       5
                                    
                                 
                              
                           . Using these features, for each feature point a feature set is formed as:

                              
                                 (4)
                                 
                                    
                                       <
                                       
                                          θ
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                2
                                             
                                          
                                       
                                       ,
                                       
                                          θ
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                3
                                             
                                          
                                       
                                       ,
                                       
                                          θ
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                4
                                             
                                          
                                       
                                       ,
                                       
                                          θ
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                5
                                             
                                          
                                       
                                       ,
                                       
                                          d
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                2
                                             
                                          
                                       
                                       ,
                                       
                                          d
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                3
                                             
                                          
                                       
                                       ,
                                       
                                          d
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                4
                                             
                                          
                                       
                                       ,
                                       
                                          d
                                          
                                             
                                                f
                                                1
                                             
                                             
                                                f
                                                5
                                             
                                          
                                       
                                       >
                                    
                                 
                              
                           
                        

In this way, feature vector for each feature point is generated and stored in the database and is used for comparison with query feature vector in matching phase.

In this step, a query image is taken and is gone through the same steps till the formation of feature vector. Then the query feature vector is compared with the feature vectors of enrolled templates using the Cosine Similarity Index Matching [16]. It measures the similarity between two vectors by computing cosine angle between them. Therefore, it considers the orientation of vectors rather than their magnitudes. Mathematically cosine similarity between the two vectors is represented as:

                              
                                 (5)
                                 
                                    
                                       C
                                       o
                                       n
                                       S
                                       i
                                       m
                                       
                                          (
                                          x
                                          ,
                                          y
                                          )
                                       
                                       =
                                       
                                          
                                             x
                                             ·
                                             y
                                          
                                          
                                             
                                                ∥
                                                x
                                                ∥
                                             
                                             
                                                ∥
                                                y
                                                ∥
                                             
                                          
                                       
                                       =
                                       
                                          
                                             
                                                ∑
                                                i
                                             
                                             
                                                x
                                                i
                                             
                                             
                                                y
                                                i
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      i
                                                   
                                                   
                                                      x
                                                      i
                                                      2
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      i
                                                   
                                                   
                                                      y
                                                      i
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Where numerator represents dot product (inner product) of vectors x and y. While in denominator ‖x‖ and ‖y‖ are the Euclidean lengths of vectors x and y respectively which normalize the dot product for cosine similarity. This gives a bounded value between zero and one if x and y are non-negative. All train feature vectors are already enrolled into the database. When a test feature vector comes, it is matched with all train feature vectors one by one. Eq. 5 takes two feature vectors x and y of same size at one time. In the proposed method, x is test feature vector and y is train feature vector of fixed length eight. For every test feature vector, scores are computed against all train feature vectors. Finally, matching decision is made based on the highest score value.

This paper presents another method for retinal recognition which uses non-vascular properties of retinal images. This method performs non-vascular-based feature extraction by using the structural information of retinal image. Structural information defines the structure of the objects in the image, independent of the average luminance and contrast. This method obtains the similarity score between the candidate images based upon their structural features; luminance, contrast and structure. It consists of two main phases i.e., feature extraction and matching. The complete work flow of this method is shown in Fig. 6
                        . It takes input image and query image at the same time and computes their structural features i.e., luminance, contrast and structure, giving a feature vector of length three. In last phase, matching is performed by combining these features using an empirically obtained function to get a similarity score between them.

This step takes color retinal image and extracts three structural feature as discussed below:

                              
                                 •
                                 
                                    f
                                    1: Luminance l(x, y)

Luminance function l(x, y) is a measure of mean intensity μx
                                     and μy
                                     for two input images x and y. Luminance function, l(x, y) is given as

                                       
                                          (6)
                                          
                                             
                                                l
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   
                                                      2
                                                      
                                                         μ
                                                         x
                                                      
                                                      
                                                         μ
                                                         y
                                                      
                                                      +
                                                      C
                                                   
                                                   
                                                      
                                                         μ
                                                         x
                                                         2
                                                      
                                                      +
                                                      
                                                         μ
                                                         y
                                                         2
                                                      
                                                      +
                                                      C
                                                   
                                                
                                             
                                          
                                       
                                    
                                 


                                    C is a constant which is used to avoid instability and it is the square of product of K and L. Where L is dynamic range of pixel values (255 for 8-bit grayscale images), and K ≪ 1. Value of K is computed empirically i.e., 0.01.


                                    f
                                    2: Contrast c(x, y)

Contrast function c(x, y) is the measure of standard deviation σx
                                     and σy
                                     of candidate images x and y. Mean intensity is removed from image as 
                                       
                                          
                                             x
                                             i
                                          
                                          −
                                          
                                             μ
                                             x
                                          
                                       
                                     is used for contrast comparison. Contrast function c(x, y) is given as:

                                       
                                          (7)
                                          
                                             
                                                c
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   
                                                      2
                                                      
                                                         σ
                                                         x
                                                      
                                                      
                                                         σ
                                                         y
                                                      
                                                      +
                                                      C
                                                   
                                                   
                                                      
                                                         σ
                                                         x
                                                         2
                                                      
                                                      +
                                                      
                                                         σ
                                                         y
                                                         2
                                                      
                                                      +
                                                      C
                                                   
                                                
                                             
                                          
                                       
                                    
                                 


                                    f
                                    3: Structure s(x, y)

For structure feature, the image is normalized by its own standard deviation so that two images being compared have unit standard deviation. Structure function s(x, y) is computed on these normalized images, expressed as

                                       
                                          (8)
                                          
                                             
                                                s
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   
                                                      2
                                                      
                                                         σ
                                                         
                                                            x
                                                            y
                                                         
                                                      
                                                      +
                                                      C
                                                   
                                                   
                                                      
                                                         σ
                                                         x
                                                      
                                                      
                                                         σ
                                                         y
                                                      
                                                      +
                                                      C
                                                   
                                                
                                             
                                          
                                       
                                    
                                 

where,

                                       
                                          (9)
                                          
                                             
                                                
                                                   σ
                                                   
                                                      x
                                                      y
                                                   
                                                
                                                =
                                                
                                                   
                                                      (
                                                      
                                                         1
                                                         
                                                            N
                                                            −
                                                            1
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                               i
                                                            
                                                            −
                                                            
                                                               μ
                                                               x
                                                            
                                                            )
                                                         
                                                         
                                                            (
                                                            
                                                               y
                                                               i
                                                            
                                                            −
                                                            
                                                               μ
                                                               y
                                                            
                                                            )
                                                         
                                                         )
                                                      
                                                      )
                                                   
                                                   
                                                      1
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 

In matching phase, all structural features are combined to yield a single similarity score value for the two images being compared. In order to compute a single similarity score between two images, the previously computed feature function are combined using a dot product function as given in expression below.

                              
                                 (10)
                                 
                                    
                                       S
                                       C
                                       
                                          (
                                          x
                                          ,
                                          y
                                          )
                                       
                                       =
                                       
                                          
                                             [
                                             l
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                             
                                             ]
                                          
                                          α
                                       
                                       ·
                                       
                                          
                                             [
                                             c
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                             
                                             ]
                                          
                                          β
                                       
                                       ·
                                       
                                          
                                             [
                                             s
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                             
                                             ]
                                          
                                          γ
                                       
                                    
                                 
                              
                           
                        

Where α > 0, β > 0, γ > 0 [17]. These three parameters are used to adjust the importance of three comparisons. Values of parameters α, β, γ are empirically computed i.e., α = β = γ =1 so that the similarity score (SC) comes in the range of zero and one.

Similarity index (SC) value is computed locally rather than globally due to varying luminance and contrast over the scene of the image. A local 8x8 window is used to move it pixel by pixel over the entire image. At each step, local statistics μx, ρx
                            and ρxy
                            and local SC index are computed within the 8x8 window, latterly mean of SC (MSC) is computed to get overall similarity index of two images.

                              
                                 (11)
                                 
                                    
                                       MSC
                                       
                                          (
                                          X
                                          ,
                                          Y
                                          )
                                       
                                       =
                                       
                                          1
                                          M
                                       
                                       
                                          ∑
                                          
                                             j
                                             =
                                             1
                                          
                                          M
                                       
                                       SC
                                       
                                          (
                                          
                                             x
                                             j
                                          
                                          ,
                                          
                                             y
                                             j
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

Where X and Y are two images being compared, xj
                            and yj
                            are image contents at 
                              
                                 j
                                 th
                              
                            local window. M is the number of local windows in an image. At the end final decision is made based on the highest value of matching score (MSC).

@&#EXPERIMENTAL RESULTS@&#

Proposed system is evaluated using two locally gathered databases i.e., Retina Identification DataBase (RIDB) and Diseased image Retina Identification DataBase (DRIDB) [18]. RIDB database is a healthy images database which consists of 100 images of 20 different individuals with five samples per person. DRIDB is 60 images database of diseased persons. It includes 20 individuals with three samples per person. Each image of both datasets is of dimensions 1504 × 1000 and compressed in JPEG format. Images from RIDB and DRIDB databases are shown in Figs. 7
                         and 8
                         respectively.

For each database, Genuine and Imposter matching are performed. For both cases, dataset is divided into training and testing set. In genuine matching, a sample of a particular person is matched with all enrolled samples of all persons in order to identify true identity of the person being tested. In imposter matching, a sample of a particular person is compared with samples of all other persons. Under imposter matching, test sample is completely unseen to the training data.


                        Table 1
                         shows the complete specifications of RIDB and DRIDB databases

Proposed system’s performance is validated by using four performance measures i.e., Recognition rate (RR), False Rejection Rate (FRR), False Acceptance Rate (FAR) and Equal Error rate (EER). Recognition rate is the percentage of correctly classified samples. FAR is the percentage of invalid inputs accepted incorrectly whereas FRR is the percentage of valid inputs rejected incorrectly.ERR is the point of intersection of FAR and FRR. These performance measures are calculated by using the expressions given below:

                           
                              (12)
                              
                                 
                                    R
                                    e
                                    c
                                    o
                                    g
                                    R
                                    a
                                    t
                                    e
                                    =
                                    
                                       
                                          N
                                          o
                                          .
                                          o
                                          f
                                          m
                                          a
                                          t
                                          c
                                          h
                                          e
                                          d
                                          i
                                          m
                                          a
                                          g
                                          e
                                          s
                                       
                                       
                                          T
                                          o
                                          t
                                          a
                                          l
                                          n
                                          o
                                          .
                                          o
                                          f
                                          i
                                          m
                                          a
                                          g
                                          e
                                          s
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (13)
                              
                                 
                                    F
                                    A
                                    R
                                    =
                                    
                                       
                                          T
                                          o
                                          t
                                          a
                                          l
                                          f
                                          a
                                          l
                                          s
                                          e
                                          a
                                          c
                                          c
                                          e
                                          p
                                          t
                                          a
                                          n
                                          c
                                          e
                                          s
                                       
                                       
                                          T
                                          o
                                          t
                                          a
                                          l
                                          i
                                          d
                                          e
                                          n
                                          t
                                          i
                                          f
                                          i
                                          c
                                          a
                                          t
                                          i
                                          o
                                          n
                                          a
                                          t
                                          t
                                          e
                                          m
                                          p
                                          t
                                          s
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (14)
                              
                                 
                                    F
                                    R
                                    R
                                    =
                                    
                                       
                                          T
                                          o
                                          t
                                          a
                                          l
                                          f
                                          a
                                          l
                                          s
                                          e
                                          r
                                          e
                                          j
                                          e
                                          c
                                          t
                                          i
                                          o
                                          n
                                          s
                                       
                                       
                                          T
                                          o
                                          t
                                          a
                                          l
                                          i
                                          d
                                          e
                                          n
                                          t
                                          i
                                          f
                                          i
                                          c
                                          a
                                          t
                                          i
                                          o
                                          n
                                          a
                                          t
                                          t
                                          e
                                          m
                                          p
                                          t
                                          s
                                       
                                    
                                 
                              
                           
                        
                     

@&#RESULTS@&#


                        Fig. 9
                         shows results obtained after applying improved vessel segmentation algorithm (proposed in Method I) on diseased images. It cleans the diseased retinal images from false vessels before extracting feature points. This step majorally increases matching accuracy as false positives are reduced significantly.

FAR is computed by counting the number of false acceptances when we compare each sample of a particular person with rest persons excluding itself. While FRR is computed by counting the number of false rejections when we compare each sample of a particular person with same persons. Fig. 10
                         shows FAR vs FRR curves along with ERR for RIDB and DRIDB databases using the proposed Method I. ERR is the point where both curves of FAR and FRR intersects. Similarly Fig. 11
                         shows FAR vs FRR curves along with ERR for RIDB and DRIDB databases using the proposed Method II.

The receiver operating characteristics (ROC) curves is another way to illustrate the performance of biometric algorithms [19]. Fig. 12
                         shows the ROC curves for both methods. These curves shows the relationship between FAR and genuine acceptance rate (1-FRR).


                        Table 2
                         shows summary of evaluation results of proposed system on DRIDB and RIDB databases. This table sums up the performance measures for both methods and compares the performance of Method I with Method II. Performance is evaluated on the basis of two parameters; recognition rate and elapsed time (processing time). It is observed that there comes a tradeoff between the two parameters. Method I gives high recognition rate but needs more processing time, however Method II has low processing time and preserves system’s good performance. This computational time improvement by Method II can easily be compared by explaining matching phase only. If we assume that there are on average m feature points extracted by Method I for each test image and there are total N images in training set. Method I also computes a feature vector of size 1 × 8 for each feature point which makes it m × 8 for one image. Similarly, it makes n × 8 feature vectors for one train image. While matching, a test image with a train image using their respective feature vectors m × 8 and n × 8, it gives m × n number of comparisons for one image and N × m × n number of comparisons for all N images. Whereas in Method II, each image gives a feature vector of size 1 × 3. Therefore, it gives one comparison for one image and N comparisons for all images. This has shown a significant difference in processing time of just matching phase of two methods proposed in this paper.


                        Table 3
                         illustrates the comparison of proposed method with existing techniques using VARIA. It is found that previously less work has been carried out on VARIA database, some of the methods with their results are illustrated in Table 3. Proposed system have shown promising results with VARIA. It is important to highlight that reported methods in Table 3 have used subset of VARIA instead of using whole database. Out of 233 images of VARIA, 135 images of 57 individuals were used by [20] while 152 images of 59 individuals were tested in [21] and [22] used only 4 individuals with 5 or more images per person. Whereas all 233 images of 159 different individuals have been included for evaluation of our proposed system.

It is also observed that most of the methods presented in literature have been tested on DRIVE and STARE databases or using local databases. DRIVE and STARE consist of 40 and 20 images respectively having one sample per person. These databases are mainly designed to detect blood vessel segmentation accuracy. The researchers have used these databases for person recognition by creating multiple images by rotating each image into five different angles [23]. New STARE and DRIVE datasets have been created using same procedure and 100 % recognition rate has been observed using both databases. This has proved rotational invariant nature of the proposed method. Table 4
                         illustrates results for DRIVE and STARE databases by applying proposed system. Results have been shown for local databases in Table 5
                         using proposed methodology.

Retina-based authentication systems are the most stable biometric systems. We have proposed two methods for retina recognition. The vascular-based method improves the recognition rate by catering the issue of presence of lesions. It removes false blood vessels before extraction of feature points. Rotation and translation invariant feature vectors are extracted using detected minutiae points to perform matching by applying cosine similarity index. This method gives high recognition rate but add computational complexity to the system. Addressing this issue, second method (non-vascular-based method) extracts novel non-vascular features i.e., luminance, contrast and structure from color retinal images and reduces computational complexity. We have designed a complete new retinal images database for retina recognition and have made it publicly available. There is always a tradeoff between time and accuracy. First method performs good in terms of accuracy while second is preferable for time constraint applications. Such recognition systems are mostly required by high security areas so under such condition, time can be compromised but efficiency cannot be compromised otherwise it opens doors to frauds and threats. There stills lies a room for improvement in second method, so images with pathologies will be catered in future to enhance system’s efficiency.

The authors declare that there is no conflict of interests regarding the publication of this manuscript

@&#ACKNOWLEDGMENT@&#

This research is funded by National ICT R&D fund, Pakistan. We are also thankful to armed forces institute of ophthalmology (AFIO) for their clinical support and help.

@&#REFERENCES@&#


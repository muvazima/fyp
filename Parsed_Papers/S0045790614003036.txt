@&#MAIN-TITLE@&#Finger knuckle biometrics – A review

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Describes the role of finger knuckle surface in biometric authentication.


                        
                        
                           
                           Enumerates various available open datasets for finger knuckle biometric trait.


                        
                        
                           
                           Presents different view point in the classification of various finger knuckle feature recognition methods.


                        
                        
                           
                           Elaborates on finger knuckle surface preprocessing, feature extraction, classification and fusion methodologies.


                        
                        
                           
                           Addresses significant issues that are mandatory for deploying finger knuckle biometric system.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Finger knuckle surface

Geometric analysis

Texture analysis

Genuine acceptance rate

Equal error rate

@&#ABSTRACT@&#


               
               
                  Biometric-based personal authentication is receiving a widespread interest in the area of research due to its high applicability in a wide range of security applications. Among these, hand-based biometric systems are considered to be more successful in terms of accuracy and computational complexity. In hand-based biometrics, finger knuckle surface is considered as one of the emerging potential biometric traits for personal authentication. This is due to its stable and unique inherent patterns present in the outer surface of the finger back knuckle region. Further, this finger knuckle has a high potentiality towards discriminating individuals with high accuracy. In this paper, we present a review of various system models that are implemented for personal authentication using finger knuckle biometrics. Furthermore, the challenges that could arise during the implementation of the large scale real time biometric system with finger knuckle print are explored.
               
            

@&#INTRODUCTION@&#

Biometric authentication is the technology used for recognizing a human identity based upon their physiological or behavioral attributes. Biometric system is also defined as a pattern recognition system which captures biometric traits from humans and extracts their pattern information. Further, the extracted pattern information must be measured quantitatively for authenticating a person in a simple and automated way [1]. The invariant, measurable, acceptable, permanence properties of biometric traits makes it highly suitable to be incorporated in human identification. The biometric trait is said to be highly accepted by the user, when it is easily scanned or read by the system. The physical traits depend upon the morphological characteristics of human beings, while the behavioral traits quantify unique actions performed by the subjects. Some of the universally accepted physiological biometric traits are fingerprint, face, hand-geometry, iris, retina, palm print, etc., and the list of behavioral biometric traits are voice, gait, signature and keystroke dynamics. According to the application context, a biometric authentication system can act either in verification mode or in identification mode. In verification mode, an individual is identified through one to one matching process between the feature information extracted from the captured biometric trait and the stored pattern template. In case of identification mode, authentication of an individual is carried out by performing one to many matching process among the extracted pattern information with all the registered pattern templates of the system [2].

Biometric systems are classified into two categories based on the number of modalities used for biometric authentication, viz., unimodal biometric system and multimodal biometric system. The unimodal biometric system incorporating single biometric trait for recognition has a number of limitations viz., i) lack of uniqueness in the chosen biometric trait ii) spoof attacks which may affect the accuracy of the system are highly probable and iii) errors in the enrollment of sensor captured data may result in poor accuracy. But still, these problems can be overwhelmed by the use of multimodal biometrics. The multimodal biometric system uses the evidence of multiple sources extracted from different biometric identifiers like fingerprints, face, palm prints, iris and hand geometry. The advantage of the multimodal biometric is highly sustainable to noise which improves the matching accuracy and also provides high resilience to attacks [3].

Hand-based biometric authentication systems are widely used in most of the access control applications due to i) their low cost data capturing units ii) their high potentialities toward the identification of individuals iii) their high user acceptance rate and iv) their performance especially in terms of speed [4]. The researchers have proposed comprehensive models for personal recognition which uses well promising methods to exploit the highly unique patterns present in the inner and outer surface of the hand as biometric traits and they have also reported in the literature that these technologies are successful both in terms of performance and usability. The various hand patterns include finger prints, palm prints, hand shape features, hand vein structures and finger knuckle surfaces [5,6].

Finger knuckle surface is one of the emerging hand-based biometric traits for personal identification. These unique patterns of finger knuckle surface have greater potentiality toward the distinctive identification of individuals which in turn contributes a high precise and computationally economic biometric system [7]. This paper focuses on reviewing the current state of art for personal authentication using finger knuckle surface. In this paper, the extensive analysis of various available methodologies for feature extraction, feature information representation, fusion of generated information and classification are emphasized. The performance evaluation of the existing methodologies and their reported results in terms of accuracy are summarized. This paper also highlights various issues and challenges encountered during the design and implementation of finger knuckle biometric system.

The remaining part of the paper is organized as follows. Section 2 presents the description of finger knuckle surface features that are used for identifying individuals and also elaborates on the available open source datasets for finger knuckle surface. Sections 3 and 4 investigate the various existing preprocessing methods, feature extraction methods, fusion methods and classification methods for finger knuckle print matching based on geometric and texture analysis respectively. Section 5 illustrates the performance evaluation parameters and the comparative results analysis of the existing methodologies. Section 6 concludes the paper with future research recommendations.

Basically, knuckle surface is defined as the skin patterns that are present in the finger back region of the hand. Each finger back region of the hand has three phalangeal joints. The joint that connects the finger with the hand surface is called as Metacarpophalangeal joint, the joint that is formed in the middle surface of the finger is called as Proximal Inter Phalangeal (PIP) joint and the joint that is present in the tip surface of the finger back region is known as distal joint. The presence of these joints in the finger back region forms the flexion shrinks on the outer surface of the skin which creates the dermal patterns consisting of lines, wrinkles, contours, etc. The pattern generated by the PIP joint on the finger back region is referred as Finger Knuckle Print (FKP). The following Fig. 1
                     (a) and (b) shows the device used to capture the finger knuckle print and the captured image of the finger knuckle print respectively.

Similarly, the skin patterns generated by all the three joints of the finger back region which is referred as finger back knuckle surface (FBKS) features are captured and utilized as biometric trait [15]. Fig. 2
                     (a) and (b) illustrates the image acquisition system used for capturing the finger back knuckle surface and the captured image respectively. On the whole, different skin patterns present in the knuckle surfaces are rich in texture information for the reliable identification of the individuals [8].

In this PolyU Finger Knuckle Print Database, knuckle images were collected from 165 individuals that include 125 males and 40 females using an automated low resolution camera in a peg free environment. This finger knuckle image capturing system collects the knuckle images from persons in two different sessions. In each session, a person submits 6 images of his/her four different finger knuckle surfaces. The four finger knuckle images were captured from left index finger knuckle, left middle finger knuckle, right index finger knuckle and the right middle finger knuckle regions. Therefore, 24 images were collected from each person in one session. Totally, 48 images were submitted by each person in two sessions. The database of the finger knuckle surface images consists of totally 7920 images. These images were obtained from 660 different finger knuckle surfaces. The time interval between two sessions of the finger knuckle capturing system is considered to be on an average of 25days. This database also provides ROI images of captured finger knuckle print by constructing a coordinate system for each FKP image. The ROI sub-image is extracted from the FKP image consists of most prominent features that are ideal for personal authentication. The following Table 1
                            shows the description about the data sets available for finger knuckle print.

This database has been created by capturing finger back knuckle region using low resolution digital camera in a contact less manner. This database consists of finger knuckle images collected from 158 users belonging to the age group from 16 to 55years. Totally, there are 790 finger knuckle images present in the database. These images are sequentially numbered using integer identification for each and every user. Since the entire finger back region has been captured, the ROI with respect to proximal phalanx is extracted using edge and line detection algorithms.

In hand-based biometric authentication, most of the research works proposed in the past decade used different modalities viz., fingerprint, palm print, hand geometry, hand vein patterns, finger knuckle print and palm side finger knuckle print. Among these biometric traits, finger print is a very old trait and also known to be the first modality used for personal identification. Apart from its beneficial aspects, finger print also possesses some limitations such as (i) its vulnerability toward intrusion of acquired image, and (ii) its features like minutia, singular points, delta points, are highly distracted by means of wounds and injuries created on the finger surface [11]. Unlike finger print, finger knuckle print patterns are very difficult to scrap because they concentrate on the inner surface of the hand and also it has been captured in a contact-less manner.

On the other hand, palm print recognition system captures large area for identification which contains limited number of features like principal lines and wrinkles. But, in case of finger knuckle print, the outer surface of the finger in the phalangeal joint contains more number of lines and creases. Moreover, the size of the finger knuckle print captured for recognition is very small and hence reduces space complexity. Likewise, finger geometry and hand geometry features [12] are not distinctive enough to identify the individuals when the number of users grows exponentially. In hand vein system [13], the vein structures present in the dorsum of the hand and in the palm area of the hand are captured by means of high resolution devices, whereas finger knuckle print can be even captured by means of low cost imaging devices in a user acceptable manner. Table 2
                         illustrates the various characteristics of the finger knuckle print by comparing it with other hand-based biometric traits.

From the table, it is clear that the internal texture patterns of finger knuckle surface are unique birth features which are highly robust toward personal identification and these traits are captured in user friendly manner.

In the literature, researchers have proposed various promising methods for hand-based biometrics. These methods can be broadly classified into two categories viz., geometric based methods and texture based methods. Generally, geometrical analysis based feature extraction methods utilizes several edge detecting approaches for extracting features like edge points, lines, creases, and wrinkles from various hand biometric traits. The extracted edge information is either utilized directly or converted into a form of geometrical feature information to represent the feature vector for matching. A number of geometrical analysis methods for extracting feature information from the finger knuckle surface are available in the literature. Since, the geometrical method exploits features like lines, edges, contours of finger knuckle surface and aid in quantifying the feature information in terms of its length, width, area, perimeter, etc. [14].

Woodard and Flynn were the first authors to introduce finger knuckle print as a biometric trait by capturing it in a 3D sensor [15]. Feature extraction for identification is carried out by extracting the curvature shape information of the finger knuckle print. The main drawback of this work is that, it involves more computations for 3D data processing. This limitation is dealt by capturing a finger knuckle print using 2D acquisition device and then incorporating line orientation coding scheme for feature extraction.

Kumar and Ravikanth [16] have proposed a number of techniques for personal authentication based on line and edge detection algorithms incorporating hand biometric traits. Initially, Kumar et al. has proposed a novel approach for personal authentication using finger knuckle surface based on textural analysis and edge detection. In this work, a peg free image acquisition setup has been configured using high resolution camera for capturing the finger back knuckle region in a contact less manner. The captured finger knuckle images are in the resolution of 1600×1200 pixels. Since, the finger knuckle images are captured in a white background setup, simple preprocessing steps were sufficient to identify the feature points. The contour pixel point, a palm wrist point (M) and extreme finger knuckle base point were identified through the process of binarization performed on the acquired finger knuckle image. From the identified edge points and lines of the finger knuckle surface, the geometrical based feature information viz., finger width, finger length, finger perimeter and finger area were derived for each finger and represented in the form of feature vectors. Totally, 24 shape based information were extracted from each finger knuckle image. The values of obtained feature vectors are found to be in different ranges. Hence, two different normalization schemes viz., Min Max normalization scheme and Z-score normalization scheme were used to normalize the obtained feature vectors. It is also found that Min Max normalization achieves better performance than Z-score normalization.

Texture exhibited by the knuckle image has both local features and global features and the texture analysis is performed with the finger knuckle images by enrolling the discrepancy in the band of knuckle. This method of texture analysis can be termed as appearance based approach. In this paper, this appearance recording approach is implemented by means of Principal Component Analysis (PCA), Independent Component Analysis (ICA) and Linear Discriminant Analysis (LDA). The feature information obtained from the texture analysis method is also represented in the form of vectors. Score generation is done by calculating Euclidean distance between the values of the feature vectors of reference and input images. Fixed fusion rules such as SUM and PRODUCT rules were used to merge obtained matching scores. Totally twenty different combinations were identified from the three implementation methods. From this, the matching score is obtained from the best combination of these implementations and further it is fused with the score obtained from the geometrical information. This work also addresses the problems due to appearance of rings in the finger back surface. Experiments were conducted with newly created database with 105 users 630 images for the implementation of the proposed knuckle feature extraction methods yielded promising results.

Kumar and Prathyusha [17] in their second work introduced a new modality known as hand vein structure for personal authentication. In this paper, a new acquisition setup was configured to capture the dorsum surface of the hand using a low cost contact less Infra-red imaging. Initially, the acquired image is subjected to adaptive histogram equalization for the enhancement of the image, so that the vein structures present in the hand dorsum surface can be viewed and analyzed clearly. The extraction of the key points from the structure of the vein is performed by means of binarizing the enhanced image. From the identified key points, the distinctive feature information is extracted by means of a geometrical method known as Delaunay triangulation method. This work also recommends a novel method for the simultaneous extraction of finger knuckle shape information in order to achieve better performance. Experiments were conducted using 300 hand dorsum images captured from 100 users of resolution 768×576. Results of the experiment demonstrate that the equal error rate generated from the combined matching score is 1.77%.

Kumar and Zhang [18] have further explored their work on the finger knuckle surface by incorporating the quality feature of the trait which is highly dependent on the capturing device. This paper focuses quality based analysis for the hand-based biometric modalities viz. palm print and finger knuckle print. The basic idea behind this work lies on the quantification of quality of the data acquired from the user and information is taken to estimate consistent matching score. The entire hand image was captured in a contact less manner and subjected to binarization in order to extract the hand shape information. Totally, 17 distinct features such as perimeter, four finger lengths, eight finger widths, palm width, palm length, hand area, and hand length were extracted as feature information. The acquired hand images are preprocessed to segment the region of interest of the palm print and texture pattern analysis is done by using discrete cosine transform decomposition. In addition to this, simultaneous extraction of finger knuckle surface features were demonstrated to obtain high accuracy. Furthermore, angular geometric methods such as (a) tangents and secants method [19], (b) triangulation methods [20] which extracts angular based feature information from finger knuckle print were also recommended in the literature.

In texture analysis methods, the feature information is extracted by means of analyzing the spatial variations present in the image. In this analysis, the mathematical models are used to characterize spatial variation and represent it in terms of feature information. The spatial quantifiers of an image can be derived by analyzing the different spectral values that are regularly repeated in a region of large spectral scale. Texture analysis on the digital image results in a characterization of the image by quantifying the texture properties. This quantification is performed by means of the following steps viz., (i) partitioning the ROI of the captured image into several blocks, (ii) representing the features of each block and (iii) representing the variations exhibited by each block with all other blocks.

Generally, the texture analysis methods for feature extraction are categorized as three types viz., (i) model based texture analysis, (ii) transform oriented texture analysis and (iii) statistical texture analysis methods. Model based texture analysis methods quantify the characteristics of image texture using fractal and stochastic models, while the transform based texture analysis methods represent the image in a spatial coordinate system and interprets the characteristics of the texture. Whereas, the statistical texture analysis methods represent the image texture using the parameters that are related to the distribution and relationship among the gray level pixels of the image [21].

Kumar and Ravikanth [16] were first to explore texture analysis method for finger knuckle biometrics. In their work, the feature information of captured finger knuckle print is extracted by means of appearance based methods. Next, Zhang et al. [22] contributed a new method for personal authentication using finger knuckle print as a trait. A novel device was used to capture the inherent skin pattern of the finger knuckle surface and the ROI is extracted from the acquired image by determining the coordinated axis of the image. From the obtained ROI image of two FKPs, the matching algorithm determines the similarities between them. The matching algorithm is implemented by means of Band Limited Phase Only Correlation Method (BLPOC). Two images are said to be similar if the POC function returns a peak value and if the images are not similar, the peak value gets decreased significantly. Further in 2010 [23], authors have presented an efficient finger knuckle print recognition algorithm based on Gabor filters which results in the combination of orientation and magnitude feature information of FKP images. This work also contributes a new scheme for preprocessing and ROI extraction based on local convex directional mapping of the finger knuckle images. Furthermore, authors of paper [24] introduced a novel mechanism which hierarchically codes the finger knuckle prints using monogenic code. This code is generated by applying monogenic signal to each image pixel, which reflects in both phase and orientation information of that particular position. This information was stored in 3-bit vector format. The evaluation results state that the proposed system using monogenic code is two times faster when compared to the matching speed of the other methods because the feature extraction stage of this is found to be less complex without any extra operation.

Chora and Kozik [25] have proposed an authentication system using simple, robust texture extraction techniques in a finger back knuckle surface using a Probabilistic Hough Transform (PHT) and Speeded Up Robust Features (SURF). In this work, the knuckle images were acquired by means of simple and user friendly accessing environment. The acquired knuckle images were preprocessed to obtain edge characteristics and threshold characteristics. This system identifies most prominent knuckle texture features as lines. The extraction of knuckle lines was coded using PHT and that was defined in the basic feature vector. Each feature vector consists of line descriptions calculated from Cartesian coordinates. Further, Euclidean metric is used to find similarity matching between the basic feature vector obtained from the reference and input image. Robust image detection and SURF were used to identify the points which determine the closest matching between the reference and input pair selected by means of PHT. Experiments were conducted in a newly created knuckle database consists of images obtained from 158 volunteers. The results predict that, this authentication mechanism yields a good result of 1.12% of EER.

Yin et al. [26] proposed a novel method for the classification of features extracted from two different traits like palm print and finger knuckle print based on weighted linear embedding technique. This discriminant embedding analysis considers local and non-local information for eliminating the limitations of Linear Discriminant Analysis. Further, this weighted linear embedding mechanism incorporates Gaussian weighting scheme through the mapping vector formulated from the ratio of weighted inter class values with weighted intra class values. Further, the proposed method is compared with Linear Discriminant Analysis of palm print texture analysis.

Shen et al. [27] proposed a biometric system based on fusion of palm print and finger knuckle print. Feature extraction is done by means of 2D Gabor filters for both palm print and finger knuckle print. The Gabor feature information is obtained by subjecting the image to the filters. The filtered image produces information related to magnitude and phase. Hamming distance metric is used to identify the similarities and differences between the reference and input images of palm print and finger knuckle print. In this system, the matching process is done by fusing scores obtained from the feature extraction process of both the traits. This type of fusing methodology is known as decision level fusing. This is achieved by mixing the distance obtained from both the palm print and finger knuckle print. The results obtained from the proposed system are compared with unimodal biometric system using single trait of palm print and finger knuckle print.

An efficient multimodal biometric system which fuses palm print and knuckle print by matching score level to provide a high security feature is presented by Meraoumia et al. [28]. This is achieved by means of efficient matching algorithm called as Phase Correlation Function (PCF). Linear phase shift in the frequency domain of palm print images is derived by Discrete Fourier Transforms. The observations based on PCF are calculated by means of cross correlation and results were further analyzed by locating similarity between the reference images and input image. The reported results of this work prove that the performance of the multimodal biometric system with matching score level fusion is outstanding when compared to the unimodal biometric system. Further, Morales et al. [29] recommended a new approach for FKP recognition based on Scale Invariant Feature Transform (SIFT). In this work, initially the captured finger knuckle images were subjected to Gabor filtering process in order to enhance the line features of FKP. Secondly, the filtered FKP image is subjected to adaptive histogram equalization method for enhancing the contrast of knuckle line features. Thirdly, the key points were identified in the input image and the gallery image based on the similarity properties that exist among the images. Finally, the common key points present in the input and gallery images aids in the measuring the similarity.

Hegde et al. [30] proposed an effective method for personal authentication using finger knuckle print. The proposed method provides two modes of security viz., normal mode and advanced mode. In this approach, radon transform is utilized for feature extraction in order to provide the basic mode of security. Matching score was generated by finding the minimal distance between Eigenvalues generated from the reference and input image. To provide advanced mode of security, the matching process is done through radon graphs by finding the difference between distance vector of reference and input image. The results of the experiments were promising in both the modes with the FAR of about 6.79% and FRR of about 0.0517% in basic mode and about 1.55% of FAR and 1.02% of FRR in the advanced mode

Hanmandlu et al. [31] used Fourier transform functions for deriving the feature information from the finger knuckle and palm region. This approach improves the accuracy by enhancing the feature selection process. Local binary pattern from the ROI image has been obtained by processing with the Sobel operator. This approach also focuses on the issue of mitigating the problem of high dimensionality in representing several feature vectors generated from finger knuckle print image through T-norms divergence method. In this divergence method, absolute difference between two features representing the same pattern is calculated for matching reference and input images.

Zhang et al. in 2011 [32], proposed a biometric system which implements a novel approach for feature extraction and representation based on texture analysis of finger knuckle print. Authors suggested a new method for feature recognition based on Riesz transform and used a 6 bit coding scheme namely RieszCompCode to encode it. This coding scheme mainly depends upon selecting filters according to the assumption that the image signal has few frequencies. Experiments were conducted by implementing the proposed method in the verification mode and the results show that the proposed method is efficient and effective in terms of accuracy. Further, in 2012 [33], authors have contributed a new FKP recognition scheme which extracts both local and global feature information of FKP images. In this work, the captured FKP images were subjected to Gabor filters which results in the coding of orientation information which is given by (1)
                     
                        
                           (1)
                           
                              G
                              (
                              x
                              ,
                              y
                              )
                              =
                              exp
                              
                                 
                                    
                                       -
                                       1
                                       /
                                       2
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  ́
                                                               
                                                            
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            σ
                                                         
                                                         
                                                            x
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                                +
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  y
                                                               
                                                               
                                                                  ́
                                                               
                                                            
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            σ
                                                         
                                                         
                                                            y
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                              exp
                              (
                              i
                              2
                              π
                              f
                              
                                 
                                    x
                                 
                                 
                                    ́
                                 
                              
                              )
                           
                        
                     
                  

The local orientation information from the Gabor filtering method was considered as the local feature of the FKP images which is obtained through competitive coding scheme given in (2),
                        
                           (2)
                           
                              Compcode
                              (
                              x
                              ,
                              y
                              )
                              =
                              arg
                              
                                 
                                    min
                                 
                                 
                                    j
                                 
                              
                              {
                              I
                              (
                              (
                              x
                              ,
                              y
                              )
                              )
                              ∗
                              
                                 
                                    G
                                 
                                 
                                    R
                                 
                              
                              (
                              x
                              ,
                              y
                              ,
                              
                                 
                                    θ
                                 
                                 
                                    j
                                 
                              
                              )
                              }
                           
                        
                     
                  

The matching of two competitive codes is achieved based on manipulating Hamming distance. The global features of FKP images was obtained by changing the scaling factor of Gabor filters to infinity, which results in Fourier transform of an image yielding Fourier coefficients. The linking process between local and global information is performed based on time frequency analysis. Furthermore, Zhang et al. in [34] investigated a feature extraction mechanism to extract local features of FKP based on phase congruency model. This work computes the phase congruency, local orientation and local phase information of the subjected FKP image using a set of quadrature pair filters such as two dimensional complex Gabor filter or log-Gabor filters. The local orientation information is obtained through competitive coding scheme. The extraction of phase congruency (PC) information using (3) and (4)
                     
                        
                           (3)
                           
                              PC
                              (
                              x
                              )
                              =
                              
                                 
                                    E
                                    (
                                    x
                                    )
                                 
                                 
                                    ε
                                    +
                                    
                                       
                                          ∑
                                       
                                       
                                          n
                                       
                                    
                                    
                                       
                                          A
                                       
                                       
                                          n
                                       
                                    
                                    (
                                    x
                                    )
                                 
                              
                           
                        
                     
                     
                        
                           (4)
                           
                              
                                 
                                    PC
                                 
                                 
                                    2
                                 
                              
                              (
                              x
                              )
                              =
                              
                                 max
                              
                              PC
                              
                                 
                                    θ
                                 
                                 
                                    j
                                 
                              
                              (
                              x
                              )
                           
                        
                     
                  

Finally, the local phase information can be obtained through (5)
                     
                        
                           (5)
                           
                              phase
                              (
                              x
                              ,
                              y
                              )
                              =
                              arctan
                              2
                              (
                              I
                              (
                              x
                              ,
                              y
                              )
                              )
                              ∗
                              
                                 
                                    G
                                 
                                 
                                    1
                                 
                              
                              (
                              x
                              ,
                              y
                              ,
                              
                                 
                                    θ
                                 
                                 
                                    m
                                 
                              
                              )
                              ,
                              I
                              (
                              x
                              ,
                              y
                              )
                              ∗
                              
                                 
                                    G
                                 
                                 
                                    R
                                 
                              
                              (
                              x
                              ,
                              y
                              ,
                              
                                 
                                    θ
                                 
                                 
                                    m
                                 
                              
                              )
                              )
                           
                        
                     
                  

The integration process of the three local features was performed using matching score level fusion. In addition to this, Zhang and Li in [35] proposed a novel coding scheme based on Riesz transform in order to encode the local feature information of palm print and finger knuckle print images. In this work, two coding mechanisms viz., Rcode1 and Rcode2 were examined by incorporating first and second order Riesz transform to the image respectively. First, the captured image is subjected to pre-filtering process with an aid of the band pass filter known as Gabor filter, which is given in (6)
                     
                        
                           (6)
                           
                              
                                 
                                    h
                                 
                                 
                                    BP
                                 
                              
                              (
                              X
                              )
                              =
                              exp
                              
                                 
                                    
                                       -
                                       
                                          
                                             ‖
                                             X
                                             
                                                
                                                   ‖
                                                
                                                
                                                   2
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             2
                                             
                                                
                                                   ς
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                              cos
                              (
                              2
                              π
                              
                                 
                                    μ
                                 
                                 
                                    0
                                 
                              
                              ‖
                              X
                              
                                 
                                    ‖
                                 
                                 
                                    2
                                 
                              
                              )
                           
                        
                     Secondly, the filtered hBP
                     (X) images were subjected to Riesz transform by incorporating various filters viz, hx
                     ,
                     hy
                     ,
                     hxx
                     ,
                     hyy and hxy
                     . The response of FKP image to the filters such as hBP
                     ,
                     hx
                     
                     -
                     
                        BP and hy
                     
                     -
                     
                        BP
                      corresponds to Rcode1. For Rcode2, the image responses to the filters viz., hxx
                     
                     -
                     
                        BP
                     ,
                     hyy
                     
                     -
                     
                        BP and hxy
                     
                     -
                     
                        BP
                      were binarized. Matching between test and registered images was done by calculating Hamming distance that exists among the Rcode of the respective images.

Hegde et al. [36] in their second work implemented a real time personal authentication using finger knuckle print. The features of the finger knuckle surface were extracted using three unique algorithms. The first algorithm is based on Radon transform in which two levels of security are provided using Eigen values obtained from the Eigen region of the knuckle surface and the peak points derived from the Radon graphs. The second algorithm utilizes the Gabor wavelet transform for extracting the feature information from the knuckle region. The third algorithm authenticates a person even when there is an injury or damage in the finger knuckle surface. The feature matching between the registered image and input image is done in a module-wise manner.

Further, Yu et al. [37] have proposed an effective personal identification method using finger knuckle print. In this approach, the feature extraction from the finger knuckle print is done by dividing the ROI image of FKP into sets of sub-blocks from which the local features are extracted and stored in the form of local binary pattern. These binary patterns are formed as histograms of FKP image blocks from which the feature vector are formulated. The matching process of two FKP images is done by calculating the histogram intersection distance between the registered and input images. Furthermore, Aoyama et al. [38] proposed a novel finger knuckle print recognition algorithm based on local block matching. The captured finger knuckle print is subjected to two dimensional Discrete Fourier Transforms to obtain the phase information that is considered as the feature information. The matching of two FKP images (one is registered image and the other is input image) is done by means of phase based matching and also block based matching. In this approach block based matching is done by means of a Band-Limited Phase-Only Correlation method which incorporates global and local information of patterns of FKP images. Shariatmadar et al. [39] proposed a new finger knuckle print recognition scheme for both personal identification and verification. Authors have incorporated a new coding scheme in which the ROI of the captured image is divided into several blocks and subjected to bank of Gabor filters from which binary patterns are generated and represented in the form of histograms. Bio hashing method is incorporated to perform matching process between the obtained fixed length feature vectors of registered image and input image.

Additionally, Gao et al. [40] addresses the issue of handling scaling, rotational and translation variant FKP which is a result of flexibility in positioning the finger knuckle during capturing process. This work recommends a reconstruction method of query images with an aid of template samples based on dictionary learning process in order to handle scaled and rotated images. The dictionary learning process can be formulated by means of minimization problem as given in (7), which can be defined as the joint optimization of dictionary D and the coefficient matrix W
                     
                        
                           (7)
                           
                              
                                 
                                    J
                                 
                                 
                                    D
                                    ,
                                    W
                                 
                              
                              =
                              arg
                              
                                 
                                    min
                                 
                                 
                                    D
                                    ,
                                    W
                                 
                              
                              {
                              ‖
                              X
                              -
                              DW
                              
                                 
                                    ‖
                                 
                                 
                                    F
                                 
                                 
                                    2
                                 
                              
                              +
                              λ
                              ‖
                              W
                              
                                 
                                    ‖
                                 
                                 
                                    1
                                 
                              
                              }
                           
                        
                     
                  

The input FKP images can be coded using (8)
                     
                        
                           (8)
                           
                              
                                 
                                    w
                                 
                                 
                                    ^
                                 
                              
                              =
                              arg
                              
                                 
                                    min
                                 
                                 
                                    w
                                 
                              
                              ‖
                              y
                              -
                              D
                              ·
                              w
                              
                                 
                                    ‖
                                 
                                 
                                    2
                                 
                                 
                                    2
                                 
                              
                              +
                              λ
                              ‖
                              w
                              
                                 
                                    ‖
                                 
                                 
                                    1
                                 
                              
                           
                        
                     
                  

The reconstruction of an image can be done by (9)
                     
                        
                           (9)
                           
                              
                                 
                                    y
                                 
                                 
                                    ^
                                 
                              
                              =
                              D
                              ·
                              
                                 
                                    w
                                 
                                 
                                    ^
                                 
                              
                           
                        
                     In this work, authors have also investigated a novel score level fusion known as adaptive binary fusion rule for fusing the matching scores obtained before and after reconstruction of FKP images. Gao et al. in their further work in [41] presented a novel mechanism which integrates multiple orientation coding and texture feature information obtained from finger knuckle print image for personal recognition. In this work, initially the captured FKP image is subjected to Gabor filter and each obtained output is passed through the multilevel image thresholding scheme which results in multiple orientation code. The texture feature information is extracted by performing the local binary pattern on each output of the Gabor filter. Finally, the integration of orientation code and texture feature information is performed through matching score level fusion.

Yet another method for verifying human identities using finger knuckle surface was proposed by Kumar in 2014 [42]. In this work, the author has explored minor finger knuckle patterns along with major finger knuckle print in order to achieve improved performance in personal recognition. This work also presents the detailed study about the finger knuckle dorsum surface and its significance in forensic analysis. Author has also contributed an open data set consisting of 650 minor finger knuckle images. The captured finger knuckle images are initially subjected to coarse and fine segmentation process to extract the portion of minor finger knuckle. This work utilizes various texture analysis approaches such as (i) local binary pattern, (ii) improved local binary pattern, (iii) Band Limited Phase Only Correlation and (iv) one dimensional log Gabor filtering method. The reported experimental results show that the minor finger knuckle region serves as a stable and unique biometric identifier.

The performance of finger knuckle biometric system can be evaluated based on two categories of evaluation viz., closed set and open set evaluation methods. The closed set evaluation method assumes that only registered users can access the biometric system. Whereas, the open set evaluation methods allow the unknown users to access the system for exhaustive evaluation of the finger knuckle biometric system.

The evaluation techniques defined for biometric authentication utilizes a number of performance related metrics. Some of the performance metrics are summarized below.


                        Genuine acceptance rate (GAR): The genuine acceptance rate (GAR) is computed as the ratio of the number of genuine matches found by the system to the total number of matches actually performed by the biometric system. GAR values of the biometric system identify the strength of the system.


                        Equal error rate (EER): Equal error rate is defined as the point at which the false acceptance rate and false rejection rate becomes equal. The lower ERR values of the biometric system show that the system is more accurate. The EER value is derived from the receiver operational characteristics curve (ROC) by taking the point at which false accept rate and false reject rate are equal.


                        False acceptance rate (FAR): False acceptance rate is defined as the measure of probability of invalid matches performed by the system.


                        False rejection rate (FRR): False rejection rate is defined as the measure of probability of rejections from valid inputs.


                        Receiver operational characteristics (ROC): The ROC curve illustrates the performance of the classification component present in the biometric system by varying its discrimination index. This curve is generated by plotting the ratio of false acceptance out of total number of actual acceptances against the ratio of false rejection out of total number of actual rejections at various index levels.

Researchers have shown well promising results for personal authentication with finger knuckle surface as a biometric trait. The comparative analysis is performed for the methods which are experimented only with PolyU Finger Knuckle Print Database are elaborated. Table 3
                         reports the average genuine acceptance rates obtained during the experimentation of various texture based feature extraction methods with the fixed values of false acceptance rate ranging from 1.1×10−4 to 1.1×102 values. Table 4
                         illustrates the summary of reported results of existing feature recognition methodologies in terms of EER value.

From the above tabulated results, it is obvious that the finger knuckle surface is an effective biometric identifier that achieves better performance than any other hand biometric traits such as finger prints, and palm prints. It is also observed that, the accuracy of the system is considerably good even when a single sample of finger knuckle surface is used. Further, the accuracy gets improved based on the fusion of either two or three knuckle regions. The best part of the accuracy can be accomplished by fusing different finger knuckle region of the same person which gives rise to an efficient intra model biometric system. Furthermore, in case of multimodal biometric systems discussed in this paper, feature information obtained from the knuckle regions plays a vital role in discriminating the individuals without increasing the complexity of the entire system.

Additionally, the comparative analysis of existing recognition methods derives the following conclusions:
                           
                              1.
                              The geometrical methods are employed to derive the shape information of finger knuckle surface, which provides lower degree of discrimination within a large population.

The statistical based texture analysis techniques like PCA, and LDA reduce the number of features considered for matching process. This leads to phenomenal decrease in computational time and also results in lower spatial requirements for storage templates.

The transform based texture analysis method achieves better performance when compared to other feature representation techniques. But, the results of this transform based methods are highly dependent on preprocessing and segmentation techniques. Moreover, high accuracy rate can be obtained only with the more accurate segmentation. This will result in tradeoffs between two performance characteristics viz., accuracy and computational complexity.

In case of model based texture analysis method, the differences in appearances are recorded to generate unique feature information which could lead to performance degradation when low intensity images are captured for processing.

@&#CONCLUSION@&#

From the review conducted on finger knuckle biometric techniques, we conclude that, the development of the finger knuckle biometric system with the following considerations may lead to its suitability in a real time environment with large population. The recommended considerations are (i) development of texture analysis techniques which makes use of subset of finger knuckle features for the generation of feature templates and, (ii) incorporating knuckle shape information along with its angular measurements into the feature template. Further, it may lead to drastic improvement in performance in terms of both accuracy and computational complexity. Furthermore, development of multimodal biometric system which combines the finger knuckle surface with other modalities such as finger prints, and iris patterns could result in high accuracy rate.

Based on these considerations, there are still some of the areas yet to be explored in finger knuckle biometrics, which can be considered as the key issues for future research direction. They are,
                        
                           1.
                           A novel finger knuckle capturing system that acquires the entire finger back knuckle surface image in a peg free and contactless manner resulting in a high quality finger knuckle images for effective feature information extraction can be developed.

A multimodal or Intra modal biometric system using finger knuckle surface can be developed and further extended by explicitly considering the sample of the input biometric signals and weights of various pieces of evidences collected through the objective measures of multiple features present in the biometric traits.

Novel feature recognition methodologies which could handle distorted knuckle patterns by generating highly unique information based on its texture features and shape oriented information that includes angular parameters into account for authenticating an individual can be implemented.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A multi-threaded algorithm for computing the largest non-colliding moving geometry

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Introduce a novel algorithm to compute largest volume to pass along a path.


                        
                        
                           
                           Introduce also a multi-threaded version of the algorithm.


                        
                        
                           
                           Novel use of the existing data structures that scale linearly with the problem size.


                        
                        
                           
                           Abstracts away the geometry so it can be used with any combination of geometries.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Collision detection

Multi-threaded

Largest non-colliding volume

@&#ABSTRACT@&#


               
               
                  In this article we present an algorithm to compute the maximum size of an object, in three dimensions, that can move collision-free along a fixed trajectory through a virtual environment. This can be seen as a restricted version of the general problem of computing the maximum size of an object to move collision-free from a start position to a goal position. We compute the maximum size by dividing the object into numerous small boxes and computing which ones collide with the virtual environment during the movement along the given trajectory. The algorithm presented is optimized for multi-threaded computer architectures and also uses data structures that leave a small memory footprint making it suitable for use with large virtual environments (defined by, e.g., millions or billions of points or triangles).
               
            

@&#INTRODUCTION@&#

Being able to determine whether a virtual object can pass through a virtual environment without collision is a fundamental problem in virtual design. Depending on the exact problem at hand, there exist hundreds of papers addressing this problem from all sorts of aspects. In this paper we focus on a lesser studied problem of utmost importance for industrial designers. We are interested in being able to compute the largest object that can travel collision-free from a start configuration to a goal configuration. By the largest object we mean the object that has the largest volume according to some user defined way of measuring volume (as explained below). In this paper, we confine the object to travel along a fixed trajectory through a fixed virtual environment.

This academic investigation is motivated by numerous real life problems (see below) and the basic motivation for this article is the virtual verification of car designs. In particular, one wants to know if a new car design can pass through an assembly line without colliding with other objects and if it does collide, what are the minimal design changes that need to be made to avoid the collisions. This information can also be used for future design problems if the environment and trajectory remain the same (as is typical for factory installations).

Another motivation for this study was to improve the sustainability of current technologies. In particular, the results of this paper are intended to allow companies to reuse the existing facilities by giving designers a guarantee that their new designs fit in the current industrial installation and also letting them know the minimum changes to both the object they are designing and/or the industrial environment if necessary. This virtual verification saves the designer significant time much earlier in the design phase. Currently to determine whether a new model design fits along an assembly line or not, one is required to build a physical mock-up of a car (or whatever is being produced) and run it through an assembly line to check for collisions. Such a process is obviously much slower and costlier than having a simple virtual tool to directly test a new design and suggest which minimal changes need to be made.

Significant design changes are often very costly, hence the goal of many designers is to know what the minimal structural design changes are to make sure objects do not collide with each other. Typical applications where computing the largest non-colliding designs plays an important role include, inter alia, the ability to route and path plan objects through tight spaces such as engines  [1] and other assembly components, designing robots for tight spaces in path planning applications  [2,3], etc. Once the set of colliding parts has been discovered one can then apply any of the numerous algorithms to effect the necessary design changes to avoid collisions (e.g.  [4,5]).

The problem we are interested in can be defined more exactly as follows. Let 
                        A
                      be some geometrical object (set of NURBs, polygon soup, points, etc.) that bounds some volume of space and 
                        B
                      another geometrical object (representing the surrounding environment). We wish to compute the remaining non-colliding space bounded by 
                        A
                      after 
                        A
                      has traveled along a given trajectory (motion, path, etc.) defined by a set of rigid transformations. We would like to remove all parts of the space bound by 
                        A
                      that collide with any part of 
                        B
                      during the set of rigid transformations. From the design perspective, the remaining non-colliding volume can be used to alter the original geometry so that it can pass along the original path collision-free. In addition, we are also interested in determining how much larger 
                        A
                      can be and still have parts of the enlarged volume not colliding with any part of 
                        B
                     .

To compute the largest remaining non-colliding volume to travel along a given path, we developed an algorithm as follows. Our algorithm first allows the user to specify the largest volume object they are interested in, say 
                        A
                     . We then compute a bounding box around 
                        A
                      and divide the box into smaller subboxes with fixed side lengths defined by the user (so-called tolerance). This size represents the level of error acceptable to the user. An hash-based octree containing the surrounding environment is then created and used to compute collisions between the environment and the object during its motion. As collisions are detected between the subboxes and the octree, subboxes are removed. The final remaining set of subboxes left at the end of the motion represents the largest shape that can pass through the environment along the path with the given user tolerance. The algorithms used here are located at the confluence of algorithms for finding the maximum empty subset of a given domain  [6], collision detection  [7] and being able to compute boolean operations for arbitrary geometries  [8].

The remainder of this paper is organized as follows. In the next section, we present our algorithm and its analysis as well as the existing literature relevant to each part of the algorithm. We then present our experimental results, which are followed by a discussion of the results from the previous section. In the final section we conclude.

@&#METHODS@&#

In this section, we describe an algorithm that solves the problem stated in the introduction. When designing the algorithm we wish to bear a few goals in mind. First of all, if the algorithm is to be run in the main memory, then it needs to have minimal space requirements because it will be used for point clouds with millions (or billions) of points. In spite of this, we do not want an unnecessarily slow algorithm for computing the final non-colliding geometry because the algorithm will be used for design purposes. When designing either the trajectory or the geometry one often requires the ability to make small changes and then rerun the simulation to see the effect of the changes. Hence, the given algorithm should also be fast.

To achieve these goals we chose to solve the problem in the following way. To represent the moving object we computed its bounding box and subdivided it into a number of smaller subboxes. The size of the subboxes were defined by a tolerance chosen by the user. Simultaneously we chose to represent the cloud via a hash-based octree,  [9], whereby the user also specifies a minimum tolerance level which defines the octree’s leaf cells’ side lengths. Allowing the user such a choice is natural because for scanned point clouds one has a level of error in the scan results as well as a certain minimum distance between each scanned point. However, the biggest advantage of representing the geometries as such, is that it could be used to represent other types of geometries than merely points. One could also build a similar octree based on triangles or other geometric primitives and simply mark cells as occupied if they contain a point or part of a triangle. We describe now these choices in more detail as well as a justification for the choices.

As stated in the introduction, it is useful for the designer to be able to not just know if the original object can pass along the trajectory collision free but also the extra space around it. This extra volume can be used to compute the maximum amount of clearance a certain part of the object has with its surroundings when traveling along the trajectory. This can be easily facilitated by our choice of using the bounding box of the object to represent the object. To find the maximum clearance around the object, one can increase the size of the bounding box in each dimension which can then be used to find the largest set of boxes that can move along the trajectory collision free.

So, we first find the bounding box of the object that is to pass along the trajectory. We then divide the box up into smaller subboxes with equal side lengths, equal to a user-defined tolerance, see Fig. 1
                     . We then move the collection of boxes along the trajectory and check whether the boxes collide with the surrounding environment or not with help of the environment’s octree representation. The interpretation of this representation is that the point cloud represents a solid object and if a point (represented by an octree leaf cell) intersects one of the subboxes then some solid part of the environment would intersect the subbox too. This interpretation also puts a minimum bound on the octree leaf cell size, which should not be smaller than the average spacing between points so that we do not miss intersections caused by solid parts of the environment.

Apart from using an octree to facilitate collision detection, one could carry out the collision detection using other methods. One possibility is to compute a swept volume of the object for the whole path and then check for collision,  [10]. However, such methods have been shown to be very time consuming, often taking minutes for short paths and small meshes  [11]. We intend to use our algorithm to compute the motion of an arbitrarily complex object over hundreds of meters, which would mean any swept volume computation would be completely impractical. Hence, the use of swept volumes in our case is inappropriate. Other possibilities are to calculate the minimum distance of each subbox to all points along the entire path. This can be efficiently done by conservative advancement  [12,13] and is similar to the way we have chosen to solve the problem, however, for non-convex geometries the algorithms we use are much simpler and also avoid the extra memory overhead that  [13] imposes (which is too large for point clouds with millions or billions of points). In addition, to use the conservative advancement for non-convex geometries, as developed in  [13], requires one to build a bounding volume hierarchy around the point cloud (as done in, e.g.,  [14]) which can be impractical for an algorithm to be run in the main memory for point clouds with billions of points.

In addition to providing fast collision queries via our octree, we also naturally wish to provide a guarantee that all possible collisions will be found. To do so, we use results from  [15] to repeatedly move each subbox as far as possible along the trajectory in a movement that is guaranteed to be collision-free. This would result in the least number of possible collision tests over all movements along the trajectory. In our case it is simple to apply the results from  [15] because we do not need to work in c-space. It suffices to work directly with the Euclidean metric to measure distances because we are moving the object through space via rigid motions.

Another way to carry out translations of the subboxes is via the bisection method  [16]. However, such a method can result in a large number of unnecessary tests that can be avoided using the adaptive bisection method presented in  [15]. In particular, certain sections of the trajectory can be traversed in one step using the adaptive bisection method (e.g. movements that involve a large minimum distance between the moving object and the point cloud), however, with the bisection method one is still required to test the traversed trajectory to a specified level of precision.

To apply Schwarzer et al.’s adaptive bisection method, we need to be able to compute the distance a subbox has moved during a motion. For a movement along a given trajectory, in the usual three dimensional space without rotations, distances can be easily computed as the arc length of the trajectory traversed so far. For sections of the movement that also contained rotations we applied Schwarzer et al.’s method as follows. To be able to compute the distance any subbox had moved during a rotation, we found the furtherest distance, say 
                        r
                     , of any of the subbox’s vertices from the rotation’s axis. We then multiplied 
                        r
                      with the angle rotated around the axis, say 
                        θ
                     , to find the maximum distance moved by any subbox, 
                        r
                        θ
                     . For combinations of rotations and translations along some trajectory we simply added the rotation distance and the arc length of the path to determine the maximum distance moved.

When applying Schwarzer et al.’s adaptive bisection method one has to decide upon a distance for the object to move when testing for collisions between start and finish positions. In our case we always chose twice the current minimum distance to the surrounding point cloud. To compute the minimum distance between the subboxes and the point cloud, we used the hash-based octree structure (as mentioned earlier), which will we now describe in more detail.

To efficiently detect collisions between the subboxes and the surroundings as well as to measure distances, we created a hash based octree for our point cloud using the hash structure described in  [9]. As is well known,  [17,18], the use of hash based octrees can be faster than pointer based and they also consume about a third of the memory of pointer-based octrees (depending on the data stored in the leaf cells). Such an advantage is essential due to the size of the octree that will be created to contain the millions (or even billions) of points in the point cloud.

The point clouds used in our simulations only had a fixed level of precision
                        1
                     
                     
                        1
                        The scanned point clouds had an inaccuracy of about 5 mm.
                      and so it is very natural to model this inaccuracy by having the octree leaf cells’ side lengths equal to this level of precision in the point cloud. This minimum size also, in some sense, “filled in” all the missing geometry that the scanned point cloud represented. In addition, a trade-off could be made between the memory consumption of the octree and the size of the octree leaf cells (which affects the volume of remaining non-colliding subboxes). If one had more memory available, then one could choose a smaller octree leaf cell size and vice versa. In addition, certain sections of the octree could be created on the fly when the subboxes reached that section of the octree and unused sections could also be dumped to save memory. We also only created octree leaf cells for those cells that contained a point. If a leaf cell did not contain a point there was no need to create it, hence saving memory.

If we were unable to guarantee a collision free movement with the algorithm’s from  [15], we tested for collision between subboxes and octree cells at the relevant positions as follows. We first searched for the potentially colliding octree leaf cell at the maximum octree depth (i.e. bottom-up). If a leaf cell existed, then a collision was reported. The use of this style of traversal is motivated by the fact that, in practice, one almost always requires a higher tolerance for the moving geometry than the point cloud and so the subboxes representing the moving geometry will tend to be smaller in size than those of the environment and hence often contained in a single octree leaf cell.

To test for collision between an arbitrarily oriented subbox and an octree leaf cell, we used the well-known oriented bounding box collision test,  [19]. This has been shown to be the fastest test, out of existing methods, for testing oriented bounding boxes,  [20].

When moving the object, in order to minimize the number of subboxes for which we had to compute collisions, we only computed the motions of the boundary subboxes that had not collided with anything yet. If, at some point during the trajectory, a subbox 
                        b
                      collided with the environment, then we added 
                        b
                     ’s neighbors to the set of boundary subboxes. At the same time 
                        b
                      was removed from the set of boundary subboxes and we tested 
                        b
                     ’s list of neighboring subboxes starting at 
                        b
                     ’s last non-colliding position. In addition, the subboxes were not stored, they were created on the fly for collision testing when needed. In Fig. 2
                     , we schematically demonstrate the removal of subboxes surrounding the triangle mesh (the ones being removed are in red) that are colliding with octree cells that contain points.


                     
                        
                           
                        
                     
                  

The final improvement we made to our algorithm was to make it multi-threaded to take advantage of current computer architectures. This was carried out in the for loop in Step 5 in Algorithm 1. To do so we used a task based parallel paradigm. We allocated an individual thread to each subbox that had not yet completed the trajectory and computed the steps in the for loop in Algorithm 1. Carrying out the multi-threaded part of the algorithm in such a fashion resulted in a good workload balance amongst the threads because there were so many boxes to test and the time it took to compute the trajectory for each box was roughly constant (if it did not collide with anything along the path).

The entire algorithm is presented in Algorithm 1.

@&#RESULTS@&#

The bounding box of the object that moved through the point cloud had a volume of 
                        8.2
                        
                        
                           
                              
                                 m
                              
                           
                           
                              3
                           
                        
                     . It is dimensions were 4.80 m by 2.37 m by 0.68 m. We present the number of subboxes for each of the object tolerances in Table 1
                     
                      (recall that when testing for collision we only tested against the outer boundary of the subboxes). The trajectory that the object followed was 222 m long had 14 nonlinear section where the object rotated either downwards and then upwards (to the horizontal plane) or vice versa. All rotations were around a single axis and this axis remained constant during the entire motion (see Fig. 4). The point cloud’s bounding box dimensions were 272 m by 27 m by 10 m and the spacing between the points was 5 mm on average.

Four tests were carried out to analyze different aspects of our algorithm. The first test we did was to investigate the dependence of the time taken to compute the motion on the size of the point cloud. The second test we did was to investigate the effects of the environment and object tolerances on computation times, memory consumption and solution quality. The third test we did investigated the effects of the size of the moving object on computation times as well as the final volume. The final test investigated the scaling of our algorithm with the number of cores. We now describe these tests in more details.

For the first test, we examined our algorithm on three point cloud levels-of-detail (LOD). The finest LOD contained over 42 million points (see Fig. 3
                     ), the second finest contained over 10 million points and the coarsest contained 1 million points. The different LODs were created by removing points with a grid based simplification method. We first created a grid with a fixed grid cell size containing the original point cloud. Then all points contained in a single grid cell were removed and replaced by a point located at the weighted average of the positions of all the points in the cell. By choosing an appropriate sized grid we were able to generate the point clouds with the aforementioned number of points. In each test case the tolerances were 5 cm and 2 cm for the environment and object respectively. The results of this test are presented in Table 4.

For the second test, we investigated the effect of different tolerances for our octree and subbox subdivision on numerous dependent variables. The results are presented in Table 3
                     . In all simulations we measured the time taken to compute the remaining subboxes, memory consumption, the remaining volume and its ratio in comparison to the best result computed with the given simulation as well as the number of non-empty octree leaf cells. In the Table 3, Points stands for the number of points, Memory is the Peak Memory Consumption in MB (just the memory used by the algorithms and not the actual geometries themselves), Volume is the remaining volume in 
                        
                           
                              
                                 m
                              
                           
                           
                              3
                           
                        
                      after traversing the trajectory, Percent is the percentage of the largest volume that the given test run achieved. We tested the environment tolerance down to 5 mm because the spacing between the points was (on average) 5 mm.

For the third test, we examined the performance and memory consumption of our algorithm with respect to the size of the moving object. This was done by extending the vertical (
                        z
                     -axis) dimension of the object. In the first case we ran the test with the original object, in the second case we doubled the length in the positive vertical direction and in the third case we quadrupled the length in the positive vertical direction. In each case the tolerances were 5 cm and 2 cm for the environment and object respectively. The results of this test are presented in Table 2.

In the final test, we investigated the performance (the time taken to carry out the object’s movement) of our algorithms with respect to the number of cores available. The results are presented in Fig. 7. In each case we had the same fixed trajectory for our object (see Fig. 4) and for each simulation we used the point cloud with 42 million points and the same tolerances.

We also provide a picture of the original and remaining volumes of the moving object as well as a picture of the subboxes moving along the trajectory. In each case we show the object for the point cloud with 42 million points and with 10 cm and 5 cm tolerances for the point cloud and moving object respectively. In Fig. 5
                      one can see the set of subboxes during traversal through the point cloud. In Fig. 6
                     
                      we show the set of non-colliding subboxes before and after they have completed the movement along the trajectory through the point cloud.

We ran our simulations on an Intel Core i7 3.2 GHz with 4 cores and 8 GB of RAM on Windows 7, and the parallelization was carried out using the Parallel Processing Library in Visual Studio 2010. To carry out the analysis and visualization we used IPS™: software.
                        2
                     
                     
                        2
                        
                           http://www.industrialpathsolutions.com/.
                     
                  

@&#DISCUSSION@&#

In Table 4 we can see the results of the first test. They demonstrate a good relationship between the number of points and the other variables. We can see that the octree build time scales linearly with the number of points and, apart from the anomalous result for the one million point cloud, the movement time is approximately independent of the density of the points. The anomalous result for the one million point case is due to the larger number of boxes on the boundary of the moving object while it was moving. This is an artifact of the simplification process and with a slightly different simplification process one could have the movement time being the same as for the other two results. Hence, one should not read too much into this result. Therefore one can say, ceteris paribus, that a higher scanning resolution should not negatively effect the speed of the algorithm. Memory consumption also scales linearly.

The second test also demonstrates the good performance behavior of the algorithm as shown in Table 3. First of all, one can see that the memory consumption and the number of active octree cells scale approximately linearly with the environment tolerance. The movement time also scales linearly with the object tolerance (halving the object tolerance results in an approximate five times longer computation) and environment tolerance (halving the environment tolerance results in an approximate doubling to trebling of the computation time). An interesting result from the data collected is the relationship between the remaining volume and the tolerances. One can see that the remaining volume seems to converge to a fixed value but, nonetheless, one obviously needs to take a precise enough tolerance to get an answer that corresponds to what the answer would have been had we not approximated our object with small boxes. However, reducing the combined environment and object tolerance by a factor of 10 from the largest tolerances results in a three times increase in the volume and reducing both by a factor of 20 from the 5 and 1 cm case merely results in a 40% increase in the volume. These results are presented in Fig. 8
                     . Another important result to notice is the good memory consumption and octree build time of the algorithm as we approach the octree cell size that contains only one point on average (as stated earlier the resolution of the point cloud was 5 mm between points on average). We see that both build time and memory consumption become approximately constant after the 1 cm environment tolerance.

It is important to note that when looking at the results in Table 3, the practical requirements are around the 1 cm level for the surrounding point cloud and about 5 cm for the moving object. This is due to errors in the scanned point cloud (on the order of 5 mm) and for the moving body one needs to take into account factors such as manufacturing tolerances (between 0.1 mm and 1 mm depending on the part) as well as incorrect modeling of the motion of the object (which was required to be around 5 cm). Hence, in the real test case, the actual values chosen by our industry partner were fixed. The results here simply demonstrate how much more volume could be gained for the manufacturer by increasing the accuracy of their data.

The results of the third test are presented in Table 2 where one can see that the algorithm’s performance as well as the final volume scale linearly with the volume. Obviously there is a limit to the scaling of the final volume with respect to the original volume (limited by the size of the passage the object follows along the trajectory). This linear scaling is to be expected because we only test against the boundary subboxes for collision and we only increased the size of the object in one dimension.

The results of the fourth test are presented in Fig. 7. The results presented here demonstrate that the algorithm scales well as long as there is enough work for the cores to do. In the first case the scaling is sublinear but this is due to there not being enough work for all cores to be used optimally. In the second case we see the linear scaling for up to four cores.

The conclusions of the current paper are restricted somewhat by our choice of benchmark cases. The simulation scenario was chosen because it reaches a compromise between the extremes of a moving object passing through the point cloud without any collisions and all subboxes of the moving object colliding with something. Another drawback was that the object’s trajectory was quite simple. It was a path restricted to a plane with only rotations around a single axis.

@&#CONCLUSION@&#

In this article we have presented an algorithm to solve the designer’s problem of determining the minimal volume reduction of an object so that it can move collision free along a given path. The paper fills an important gap at the intersection of many areas of research as outlined in the introduction. When developing our algorithms we attempted to not restrict ourselves to specific geometries or movements. There were no physical restrictions on the object’s movements and the algorithm also abstracts away the underlying geometries and so is applicable to just about any type of geometric model. Hence, the area of application of such an algorithm is as broad as possible. The presented algorithm gives a guarantee that the remaining geometry is collision-free along the specified path. We also demonstrated that the algorithm is fast on moderate sized test cases. We also showed that the algorithm can be created by a simple application of the existing algorithms.

Our results revealed that the choice of algorithms for our algorithm leads to good scaling with the number of cores, the size of the environment and object tolerances as well as the octree build time with respect to the number of points. The algorithm also has the very desirable property that the computing time for the movement of the object is independent of the number of points in the point cloud for a fixed environment tolerance level. The results also demonstrated the dependence of the algorithm on the environment and object tolerances showing the important role they play and the need for them to be chosen sufficiently small to produce an accurate result.

Future work will address increasing the number of points by orders of magnitude so that the point clouds no longer fit in the main memory and hence one is required to use out-of-core techniques. We also wish to test more complex paths for the movement of the object and the effect they have on the algorithm. In addition, it would be interesting to approximate the moving object with something other than a bounding box and its subdivision into subboxes, so another avenue for further work would be testing these choices (for example having an adaptive subdivision of the bounding box so areas that are more important are subdivided into smaller subboxes). We would also like to look at a wider set of benchmark cases on other geometric primitives than point clouds and triangle meshes to more thoroughly test the performance and quality of the algorithm.

However, the most important question that we would like to address in the future is the following problem faced by all designers trying to assemble objects in restricted spaces. Instead of having a fixed trajectory for the object to move along, we would like to be able to compute the largest volume that can be moved from a start position to some goal position. For cluttered environments such a computation would invariably need to combine a path planning algorithm with our current algorithm as well as other optimization methods to find the path that allows the largest possible volume to move along it collision-free.

@&#ACKNOWLEDGMENTS@&#

The authors sincerely thank Mathias Sundbäck and Magnus Rönnäng from Volvo Cars for their support and assistance in carrying out this research. We also thank Volvo Cars for their kind allowance of the simulation photos and data used in this paper. This work was carried out at the Wingquist Laboratory VINN Excellence Centre, and is part of the Sustainable Production Initiative and the Production Area of Advance at Chalmers University of Technology. It was supported by the Swedish Governmental Agency for Innovation Systems.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Face recognition in low resolution thermal images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Facial feature detector for face thermal image resolution more than 64*64pixels.


                        
                        
                           
                           BRIEF and LBP have a good recognition rate compare with SIFT and ORB.


                        
                        
                           
                           BRIEF shows a good face signature, accurate, compact, and efficient in matching.


                        
                        
                           
                           PCA is the best recognition rate in very low resolution less than 16*16pixels.


                        
                        
                           
                           LBP shows the worst degradation in performance with decreasing the resolution.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Thermal imaging

MAP

Probabilistic model

Features detection

@&#ABSTRACT@&#


               
               
                  This paper proposes an accurate, rotation invariant, and fast approach for detection of facial features from thermal images. The proposed approach combines both appearance and geometric information to detect the facial features. A texture based detector is performed using Haar features and AdaBoost algorithm. Then the relation between these facial features is modeled using a complex Gaussian distribution, which is invariant to rotation. Experiments show that our proposed approach outperforms existing algorithms for facial features detection in thermal images. The proposed approach’s performance is illustrated in a face recognition framework, which is based on extracting a local signature around facial features. Also, the paper presents a comparative study for different signature techniques with different facial image resolutions. The results of this comparative study suggest the minimum facial image resolution in thermal images, which can be used in face recognition. The study also gives a guideline for choosing a good signature, which leads to the best recognition rate.
               
            

@&#INTRODUCTION@&#

Biometrics has received a lot of attention during the last few years both from the academic and business communities. It is a preferable way for human identification; since it captures physical characteristics of a subject. Face recognition is one of the main topics in the set of biometric applications as it does not need human cooperation and it is a user-friendly approach for human recognition. Research into face recognition has been biased towards the visible spectrum for a variety of reasons. Among those is the availability and low cost of visible band cameras. However, visible spectrum images have high variability since they are constructed by a reflection on surfaces. A dependence on the reflectivity makes it possible to fool the system by using photographs or dummy faces. These problems encouraged the interest in the use of thermal images, which can achieve high immunity to illumination changes and other variabilities in the image acquisition process. Therefore, thermal IR face recognition techniques can be used to identify faces when there is little or no control over lighting conditions.

Usually, a face recognition pipeline consists of four modules: face detection, face alignment, face representation and face matching. Face detection is the first step in any face recognition framework where the facial region is segmented from its background before further processing. face alignment aims to detect facial feature points. Accurate detection of these points is crucial to the success of the later stages of the pipeline. Face representation is the most important step in face recognition pipeline where the extraction of distinguish feature vector for the person is required. This step is challenging from low resolution face images. Unfortunately, this is the case in many applications e.g., small-scale stand-alone camera applications in banks and supermarkets, large-scale multiple networked close-circuit television (CCTV) in law enforcement applications in public streets, etc. Therefore, researchers have recently focused on face recognition from low resolution visible images. Empirical studies [1] showed that minimum face image resolution between 32×32 and 64×64pixels is required for existing algorithms in visible images but there is no study about low resolution face recognition from thermal images.

In this work, we propose an accurate, rotation invariant, and fast approach for detection of facial features (i.e., eyes, nose, and mouth) from thermal images. The proposed approach combines both appearance and geometric information to detect the facial features. First, an appearance matching is applied between a feature candidate and the facial points that are learned off-line. Then, detected points should match the geometric constraints that govern the layout of facial features. Experiments are conducted to evaluate the accuracy of the proposed detector. After that the proposed approach is used in a face recognition framework. This framework is based on extracting a local signature around each facial feature points. To highlight the accuracy of the proposed facial features detection approach, recognition results with proposed automatic detection of facial features, as well as manually annotated detection, at different face image resolutions are presented.

@&#RELATED WORK@&#

In thermal images, the face is distinct from that of the environment, and emissivity values of the IR spectrum are relatively uniform among faces of different skin color. Therefore, robust segmentation detection of face in thermal images can be achieved. Most of existing techniques for face detection in thermal images, e.g., [2], are threshold-based techniques, where the facial region has higher intensities than other regions in the thermal image; because it has the highest thermal content.

Most of facial feature points cannot even be detected manually in thermal images since the iris is hardly visible and there is no contrast with the sclera. The eyebrows are not consistently visible since this depends on their density. Also, the lips are in many cases undistinguishable, therefore, the mouth is hardly distinguishable if it is closed. Trujillo et al. [3] proposed a detector for two eyes and mouth for expression recognition. This detector applies Harries algorithm to extract critical points in the thermal face image. Then k-means clustering is performed under the assumption that the cluster will be coincident with the facial component. However, authors did not report the accuracy of the detection results. Martinez et al. [4] proposed a detector for eyes and the nostrils using Haar features and GentleBoost algorithm. The classifier has many false outputs because the search for a feature is performed in the whole image. However, these outliers are filtered by applying shape constraints.

Recently, several comparative studies [5–7] of thermal face recognition approaches have been developed. Most of the developed approaches e.g., [8,9], make use of appearance-based methods for face representation, such as PCA (Principal Component Analysis), LDA (Linear Discriminant Analysis), and ICA (Independent Component Analysis). These methods achieve an 80% recognition rate. Other thermal face recognition frameworks use a local-matching approach such as Local Binary Pattern (LBP) [10], Gabor Jet Descriptors [11], and histograms of Weber Linear Descriptor features [12]. In these approaches, the facial image is divided into blocks and descriptors are extracted from each block and concatenated in a one vector. Finally, global matching approaches such as Scale Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF) [6] are used. These methods are based on detection of the critical points then extraction the descriptor around them.

Unlike previous approaches, which can be applied on both visible and thermal images, other approaches are specified for thermal images only. Some of these approaches e.g., [13,14] use vascular information, which is extracted from thermal images. This is usually accomplished by detecting thermal minutia points, and then matching them using a similar approach to the one used for fingerprint identity verification.

In addition, many methodologies e.g., [15–18] are proposed to integrate information from visible and thermal spectrum images. This fusion compensates for the lack of information in one modality by the abundance of information in the other.

The texture and shape prior models are the main components for detection of facial features. For the texture model, the local texture around a given facial feature is modeled; while for the shape model, the relationship among facial features is modeled. Both models are learned from labeled exemplar images. In this work, the texture based detector is performed using Haar features and the adaBoost algorithm. Then, the relation between the facial features is modeled using a complex Gaussian distribution. The facial features detection is formulated as an energy minimization function that incorporates the uncertainty of the texture model response and the shape prior model. This work is close to the work proposed by Martinez et al. [4]. However, there are many differences which include: (i) the texture based detector response is soft, since the output is a probability of each point being a feature. This facilitates the combination with the shape prior model. On the other hand, Martinez’s texture based detector is hard so the shape used as a filter of the output in a second stage; (ii) the shape is modeled using a complex normal distribution, which is invariant to rotation; (iii) the output of the texture is regularized for decreasing the false positive rate; and (iv) the texture based detector is running over a part of the face image not the whole image of the face to decrease the false positive and to increase the speed.

Haar-like features are chosen as the descriptor of the local appearance. The main advantage of Haar-like features over most other features is its computation speed. Using integral images, a Haar-like feature of any size can be computed in a constant time. In the training stage, we generate positive and negative samples for each facial feature. The positive samples are taken at manually annotated locations of feature points. The negative samples are taken at least 20pixels away from the annotated locations. These samples are fed to a feature/non-feature classifier. This classifier is trained using the AdaBoost learning algorithm. In the testing stage, for facial feature points, a sliding window is run over the image and the AdaBoost-based classifier which assigns a score for each pixel’s probability of being the correct position. The score at position Z is given by
                           
                              (1)
                              
                                 S
                                 (
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             Z
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          t
                                          =
                                          1
                                       
                                       
                                          r
                                       
                                    
                                 
                                 
                                    
                                       α
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 
                                    
                                       Ϝ
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    α
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is the weight of the weak classifier t for the feature i, and 
                           
                              
                                 
                                    Ϝ
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is the binary response of this weak classifier.

In the case of a perfect texture-based detector, the response of the classifier is homogenous, as the probability of a pixel being a feature is high at the true position and decreases smoothly going away from this position. Therefore, we regularize the output of the classifier with a variance normalization factor by dividing the output probability of the classifier with σ
                        ℵ(Z) to handle false positives. This idea is similar to the idea of clustering, which is proposed in the facial detector [3].σ
                        ℵ(Z) is the standard deviation of the output probability among the neighborhood 
                           
                              ℵ
                              (
                              Z
                              )
                           
                        .Then, the probability of a position Z being a feature i based on the texture detector can be written as:
                           
                              (2)
                              
                                 P
                                 (
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             Z
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       K
                                    
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             ℵ
                                             (
                                             
                                                
                                                   Z
                                                
                                                
                                                   i
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          t
                                          =
                                          1
                                       
                                       
                                          r
                                       
                                    
                                 
                                 
                                    
                                       α
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 
                                    
                                       Ϝ
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                              
                           
                        where K is a normalization constant.

Faces come in various shapes due to differences among people, pose, or facial expression of a subject. However, there are strong anatomical and geometric constraints that govern the layout of facial features. We propose to use the circular symmetric complex normal distribution [19] for our facial features detection approach. The advantage of using this distribution is that shapes do not need to be aligned with respect to rotation parameters. The probability distribution function of the circular symmetric complex normal is
                           
                              (3)
                              
                                 P
                                 (
                                 Z
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             π
                                          
                                          
                                             N
                                          
                                       
                                       det
                                       (
                                       Γ
                                       )
                                    
                                 
                                 
                                    
                                       e
                                    
                                    
                                       -
                                       
                                          
                                             (
                                             
                                                
                                                   Z
                                                
                                                
                                                   ¯
                                                
                                             
                                             -
                                             
                                                
                                                   μ
                                                
                                                
                                                   ¯
                                                
                                             
                                             )
                                          
                                          
                                             T
                                          
                                       
                                       
                                          
                                             Γ
                                          
                                          
                                             -
                                             1
                                          
                                       
                                       (
                                       Z
                                       -
                                       μ
                                       )
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              Γ
                              =
                              E
                              (
                              Z
                              
                                 
                                    
                                       
                                          Z
                                       
                                       
                                          ¯
                                       
                                    
                                 
                                 
                                    T
                                 
                              
                              )
                           
                        , 
                           
                              
                                 
                                    Z
                                 
                                 
                                    ¯
                                 
                              
                           
                         is the complex conjugate of Z, and N is the number of features.

Since the circular symmetric complex normal distribution is invariant to rotation, it is suitable to represent the shape in the pre-shape domain, in which shapes are zero-offset and unit-scale. In our work, we use the classical way of transforming from the original shape vector to the pre-shape domain by simply multiplying with Helmert sub-matrix (H) then performing a normalization step [19].

The facial feature detection is formulated as a Bayesian framework of maximum a posteriori (MAP) estimation. We need to find the vector Z, which maximizes the response probability for the texture and the shape models.
                           
                              (4)
                              
                                 
                                    
                                       Z
                                    
                                    
                                       ^
                                    
                                 
                                 =
                                 arg
                                 
                                    max
                                 
                                 P
                                 (
                                 I
                                 |
                                 Z
                                 )
                                 P
                                 (
                                 Z
                                 )
                                 .
                              
                           
                        
                        P(I—Z) represents the probability of the similarity between the texture of the face to an off-line model given the facial features vector. Since the similarity of the face can be expressed in the similarity of the windows around each facial feature, it can be written as P(W(Z
                        
                           i
                        ),
                        W(Z
                        2)⋯
                        W(Z
                        
                           N
                        )—Z). Where W(Z
                        
                           i
                        ) is the image window around the facial point Z
                        
                           i
                        . P(W(Z
                        
                           i
                        )—Z
                        
                           i
                        ) can be interpreted as the probability of a pixel being a feature based on the texture model. Thus, based on the boosted classifier and Haar-like feature vector Eq. (2) the probability can be written as
                           
                              (5)
                              
                                 P
                                 (
                                 W
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 |
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 P
                                 (
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             Z
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       K
                                    
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             ℵ
                                             (
                                             
                                                
                                                   Z
                                                
                                                
                                                   i
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          t
                                          =
                                          1
                                       
                                       
                                          r
                                       
                                    
                                 
                                 
                                    
                                       α
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 
                                    
                                       Ϝ
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 .
                              
                           
                        Since each feature has its corresponding sub-image, which has a sliding window classifier running over it, the output of each texture detector can be considered independent from the others. Therefore, the overall probability
                           
                              (6)
                              
                                 P
                                 (
                                 I
                                 |
                                 Z
                                 )
                                 =
                                 P
                                 (
                                 W
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                                 W
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 ⋯
                                 W
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       N
                                    
                                 
                                 )
                                 |
                                 Z
                                 )
                                 =
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 P
                                 (
                                 W
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 |
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 .
                              
                           
                        
                     

Therefore, from Eqs. (3), (4) and (6), the maximum-a posteriori estimate of the facial features can be formulated as an energy minimization of function 
                           
                              E
                              (
                              Z
                              )
                           
                        
                        
                           
                              (7)
                              
                                 E
                                 (
                                 Z
                                 )
                                 =
                                 -
                                 
                                    
                                       
                                          
                                             (
                                             
                                                
                                                   HZ
                                                
                                                
                                                   ¯
                                                
                                             
                                             -
                                             
                                                
                                                   μ
                                                
                                                
                                                   ¯
                                                
                                             
                                             )
                                          
                                          
                                             ′
                                          
                                       
                                       
                                          
                                             Γ
                                          
                                          
                                             -
                                             1
                                          
                                       
                                       (
                                       HZ
                                       -
                                       μ
                                       )
                                    
                                    
                                       ‖
                                       HZ
                                       
                                          
                                             ‖
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 log
                                 P
                                 (
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             Z
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 .
                              
                           
                        
                     

This energy function is non-linear and not amenable to gradient descent-type algorithms. It is solved by a classical stochastic energy minimization technique, simulated annealing, where maximum number of iterations is empirically set 100 iteration.

Although the main goal of this work is facial features detection, in any biometric system, features detection is just a tool and recognition is the ultimate goal. Therefore, we extract a local signature around each detected facial feature. Then these signatures are used in a face recognition framework. Recently, there has been a growing interest in using local features like Scale Invariant Feature Transform (SIFT) [20] for matching facial images. Local feature descriptors describe a pixel in an image through its local neighborhood content. Recent studies have shown the effectiveness of local features for the task of face recognition in unconstrained environments with variations in pose and illumination [20]. Additionally, unlike most holistic face representations, these local descriptors allow for direct comparison of images across resolutions with suitable scale changes while computing the descriptors. Local Binary Pattern (LBP) has achieved state of the art face recognition highest performance in this scenario when only one sample per person is used for training [21]. We use LBP with a radius 3 and 8 neighbors for a window 21×21. LBP, SIFT and Binary Robust Independent Elementary Features (BRIEF) are the three different signature extraction approaches, which are used in this work. These signatures are extracted in an ROI around the detected facial points (eyes, nose, and mouth). The size of the ROI of 21×21pixels in a face image resolution of 128×128pixels (i.e., Inter-Pupil Distance (IPD) 48pixels) is empirically estimated for the best performance. Vectors lengths of the signatures are 1020 and 128 for LBP, SIFT, and BRIEF, respectively. The recognition matching is performed using a nearest neighbor classifier in the computed feature space using Chi square distance for LBP, Euclidean distance (L2-norm) for SIFT, and Hamming distance for BRIEF.

@&#EXPERIMENTS@&#

To evaluate the proposed approach, we use two datasets: The thermal and visible dataset (X1 Collection) from the University of Norte-Dame (UND) and the IRIS Thermal/Visible Face Database. To show that the algorithm is unbiased for the training dataset, we select a training set, which is completely different than the test set. We use the IRIS Thermal/Visible Face Database for training and the UND dataset for testing. The testing partition of the UND dataset contains 82 subjects with multiple thermal and visible images for each subject, in total 2292 images. Each subject has at least an image in natural expression and smile expression with mugshot and FERET lighting. The IRIS Thermal/Visible Face dataset contains 30 subjects each subject has 176−250 images. It contains 3 different expressions and 5 lighting conditions with varying poses.

The performance of the proposed facial features detector is evaluated on a subset of the UND dataset. This subset consists of 328 thermal images. This subset contains 82 subjects with 4 different images each (i.e., different illuminations and expressions). Fig. 1
                         illustrates examples of the proposed facial features detector results for different subjects using thermal images with different resolutions.

We measure the accuracy of our detector using the distance (d) between the detected facial feature and its corresponding manually annotated one. This measure depends on the resolution and face size so it is normalized by dividing d by the distance between the eyes, Inter-Pupil Distance (IPD). This normalized distance has the form 
                           
                              ∊
                              =
                              
                                 
                                    d
                                 
                                 
                                    IPD
                                 
                              
                           
                        . To figure out the proposed algorithm performance at different resolution, the images are scaled down to different sizes. For the sake of comparison, for each detected feature in thermal images i.e., tip of the nose and center of the mouth, we calculate the mean of the normalized distance ∊. Also for both the center of the left eye and center of the right eye, we calculate the mean of the average normalized distances i.e., the mean of ∊
                        
                           eyeCenter
                        
                        =(∊
                        
                           leftEye
                        
                        +
                        ∊
                        
                           rightEye
                        )/2. These statistics are calculated for the proposed detector and for other detectors [3,4] and are shown in Fig. 2
                        .

The results of Fig. 2 show that the detection error of the center of the eye is the least, compared to other facial features. This good result is due to the clarity of the texture around the eyes. Also the results show that the detection of the mouth has the highest error. This can be explained, in thermal images, as follows: at low resolutions the edges are diffused and this makes mouth hardly distinguishable, specially, if it is closed. The results of Fig. 2 also show that Martinez et al. [4] gives a better performance than Trujilo et al. [3] at the different resolutions. This is due to the authors in [4] add constraints to the relation among facial features. Finally, we can conclude that our proposed approach outperforms these algorithms for facial features detection in thermal images; since it captures the advantages of both algorithms by soft combining the texture and shape models. Also, detection results using the texture information only are shown, to clarify the importance of adding the shape information to our model. It is worth mentioning that there are many other algorithms, which are used in the literature to detect facial features in visible images. However, we cannot compare with these approaches because they cannot be applied directly to thermal images. This is because most of them depend on detection of many facial points (around 68 points) and identifying these points, in thermal images, is a very tough problem; even if it is done manually.

More statistical results are shown in Fig. 3
                        . Fig. 3a shows the cumulative error distributions of the proposed detector and other detectors in thermal images at IPD=24. Fig. 3b shows the cumulative error distributions of the proposed detector at different resolutions. The y-axis captures the percentage of facial feature points that have displacement error less than or equal to the x-axis value. The detection performance in the face resolutions 128×128pixels and 64×64pixels (i.e., IPD=48 and 24pixels) have almost the same performance. The degradation of the detection performance is large at the face resolution 16×16pixels (i.e., IPD=6pixels).

Recognition experiments are conducted to illustrate the impact of the proposed facial features detector in the recognition pipeline. In the following set of experiments, the gallery set is chosen as neutral expression images with FERET lighting condition while different probe sets are chosen under different imaging conditions e.g., illumination variation and expression. Also, each experiment is repeated after switching the probe and gallery datasets. Then the average recognition rate is computed.

In this experiment, we present a comparative study for different signature techniques with different facial image resolutions and under different imaging conditions e.g., illumination variation and expression. The motivations of this study are: (i) The lack of performance evaluation of existing techniques with different facial image resolution. (ii) Identifying the recognition rate with the proposed technique using different signatures. (iii) Presenting a performance of a recently proposed signature, which is used for the first time in face recognition. (iv) Studying the effect of different face recognition problems e.g., illumination variation and expression on recognition rate in thermal images. The results of this comparative study are intend to suggest the minimum facial image resolution in thermal images, which can be used in face recognition, and to give a guideline for choosing a signature. LBP and SIFT are included in this study; due to their good performance in former face recognition studies [22]. BRIEF is recently proposed as efficient alternatives to SIFT and SURF [23]. The recognition rates of the three different signatures are evaluated. Finally, to highlight the accuracy of the proposed automatic detection w.r.t. the manually annotated features, the recognition performance using the different signatures are computed based on both manually annotated features and automatically obtained ones.


                        Fig. 4
                        (a) shows the 1st rank recognition rate when the gallery and probe sets differ in expression, and Fig. 4(b) shows the 1st rank recognition rate when the gallery and probe sets differ in illumination. Fig. 5
                         shows the 1st rank recognition rate of thermal images where the gallery and probe sets differ in both illumination and expression. The LBP and BRIEF are less sensitive to the difference between automatic and manual annotated facial features. Then SIFT comes in second for robustness of recognition performance with detected facial features. The LBP is less sensitive to the face image resolution. LBP, BRIEF, and SIFT show sudden performance degradation with less face resolution. The sudden degradation presents itself in the face resolution from 32×32pixels to 64×64pixels (i.e., IPD=24pixels).

The previous recognition results, in Figs. 5 and 4, illustrate the following: (i) The proposed facial features detection is accurate enough to give good recognition rates, which are very close to the rates that are generated using the manually annotated facial features. (ii) We still get a good recognition rate at low resolution thermal image where IPD
                        =24 (i.e., 64×64pixels facial image). (iii) The thermal images have a better performance in illumination variation than expression variation, but a problem like pose is better to be solved in visible images since it usually depends on accurately detecting a large number of facial points. (vi) Finally, BRIEF and LBP are competitive signatures, since they generate almost similar recognition rate. However, we should note that the size of LBP signature (1020) is much larger than the size of BRIEF signature (128). Also, the BRIEF consists of binary strings. Therefore, the descriptor similarity is evaluated using the Hamming distance, which is very efficient to compute, instead of the Chi square distance in case of LBP.

@&#CONCLUSIONS@&#

In this work, we proposed an accurate, rotation invariant, and fast detection approach of facial features from thermal images. The facial features detection was formulated as an energy minimization function that incorporates the uncertainty of the texture model response and the shape prior model. Experiments confirmed that the accuracy of the proposed approach is better than the accuracies of many other existing algorithms for facial features detection in thermal images. Also, the performance of the proposed approach was tested in a face recognition framework. Recognition results showed that our proposed detector has the same effect of accurate manual detection in the recognition framework. Moreover, the effect on the recognition rate of using different signatures with the proposed technique was addressed. The results of this study concluded that facial features can automatically extracted from a 64×64pixels facial thermal image. Then we can get an accurate and fast face recognition using BRIEF signature.

@&#REFERENCES@&#


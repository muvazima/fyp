@&#MAIN-TITLE@&#Alveolar bone-loss area localization in periodontitis radiographs based on threshold segmentation with a hybrid feature fused of intensity and the H-value of fractional Brownian motion model

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Present an effective threshold segmentation method for localizing alveolar bone-loss areas in periodontitis images using a hybrid feature=0.15 fBm-H+0.85 (1−
                              I), both fBm-H and I are normalized.


                        
                        
                           
                           (TPF, FPF) of 31 tested radiograph images (used and unused in weight training)∼(92.5%, 14%).


                        
                        
                           
                           ∼14% lower FPF than level set, Bayesian, KNN, SVM classification using the same two features.


                        
                        
                           
                           The method would be useful for dentists in evaluating degree of bone-loss for periodontitis patients.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Periodontitis radiographs

Alveolar bone-loss

fBm model

Hybrid feature

Leave-one-out cross validation

@&#ABSTRACT@&#


               
               
                  Background and objective
                  Periodontitis involves progressive loss of alveolar bone around the teeth. Hence, automatic alveolar bone-loss (ABL) measurement in periapical radiographs can assist dentists in diagnosing such disease. In this paper, we propose an effective method for ABL area localization and denote it as ABLIfBm.
               
               
                  Method
                  ABLIfBm is a threshold segmentation method that uses a hybrid feature fused of both intensity and texture measured by the H-value of fractional Brownian motion (fBm) model, where the H-value is the Hurst coefficient in the expectation function of a fBm curve (intensity change) and is directly related to the value of fractal dimension. Adopting leave-one-out cross validation training and testing mechanism, ABLIfBm trains weights for both features using Bayesian classifier and transforms the radiograph image into a feature image obtained from a weighted average of both features. Finally, by Otsu's thresholding, it segments the feature image into normal and bone-loss regions.
               
               
                  Results
                  Experimental results on 31 periodontitis radiograph images in terms of mean true positive fraction and false positive fraction are about 92.5% and 14.0%, respectively, where the ground truth is provided by a dentist. The results also demonstrate that ABLIfBm outperforms (a) the threshold segmentation method using either feature alone or a weighted average of the same two features but with weights trained differently; (b) a level set segmentation method presented earlier in literature; and (c) segmentation methods based on Bayesian, K-NN, or SVM classifier using the same two features.
               
               
                  Conclusion
                  Our results suggest that the proposed method can effectively localize alveolar bone-loss areas in periodontitis radiograph images and hence would be useful for dentists in evaluating degree of bone-loss for periodontitis patients.
               
            

@&#INTRODUCTION@&#

Periodontitis is a set of inflammatory diseases affecting the periodontium, the tissues that surround and support the teeth. It is caused by microorganisms that adhere to and grow on the tooth's surfaces, along with an overly aggressive immune response against these microorganisms [1]. Periodontitis involves progressive loss of the alveolar bone around the teeth; hence, its diagnosis can be established from (a) clinical examination by inspecting the soft gum tissues around the teeth with a probe, and (b) radiographic examination by evaluating the patient's X-ray films (radiographs) to determine the amount of alveolar bone loss around the teeth.

Alveolar bone-loss measurement has been a difficult task for most dentists. Recently, two reports on validation of a dental image analyzer tool to measure the degree of alveolar bone loss are available in periodontitis research literature [2,3], in which the degree of bone loss is determined by identifying the position of the alveolar crest (i.e., the lowest position of the intersection of bone-loss area and tooth contour) relative to the ruler's marking [2] or by a defect angle between the two lines that represent the root surface of the tooth involved and the surface of the bone defect, respectively [3]. However, the critical points/positions of bone-loss areas for measurement by both methods are manually drawn by dentists. For automatic measurement of degree of alveolar bone loss, bone-loss areas must firstly be localized automatically.

Very little studies on automatic bone-loss area localization in periodontitis radiographs have been reported in literature. However, studies on osteoporosis using dental radiograph images are quite a few. Computer-assisted subtraction radiography, introduced in the late 1990s, subtracts all unchanging structures from a set of two radiographs taken at different examinations. It highlights the changes in bone level due to bone loss as dark shaded areas; whereas those changes due to bone gain are highlighted as light shaded areas [4]. Subsequently, analyzing bone changes using texture analysis in single X-ray image was introduced. Structural analysis methods using morphological operators were applied to analyze and segment the trabecular in dental periapical X-ray images for osteoporosis screening [5,6]. Statistical analysis using Gray Level Co-occurrence Matrix (GLCM), along with other feature, was applied in dental computed tomography (CT) to make a better classification of bone quality [7]. Fractal dimension (FD), which is model-based texture analysis, was applied for quantifying the degree of irregularity of a bony region of interest (ROI) and reflecting the changes of bone mineral content in that ROI [8]. Methods using FD with box-counting to evaluate radiographic changes in mandibular bone texture were presented and demonstrated effective in [9,10]. FD analysis based on fractional Brownian motion model (fBm) to distinguish osteoporotic fracture groups was introduced in [11]. Transform methods of texture analysis, such as Fourier, Gabor and wavelet transforms, had also been applied for investigating osteoporosis in [12]. Lately, a study to predict low bone mineral density or osteoporosis from a dental panoramic radiograph was presented, in which cortical and trabecular features of the mandible were extracted then a combinational model of both features and age was developed to classify subjects as normal and low bone mineral density [13]. A support vector machine (SVM) method based on a radial basis function (RBF) for measurement of the cortical width of the mandible on dental panoramic radiographs was also presented and demonstrated its usefulness for identifying postmenopausal women with low skeletal BMD [14].

In periodontitis radiograph images, normal alveolar-bone regions appear brighter and rougher than bone-loss regions, because normal regions have higher density of alveolar bones. In other words, both texture and intensity of alveolar tissues in radiograph images can be used for differentiating bone-loss regions from normal regions. However, when dental radiographs suffer from uneven illumination, the intensity of normal regions in one side of the image could become similar to the intensity of bone-loss regions in the opposite side of the image. Thus, intensity becomes not effective for classification between normal and bone-loss regions in these images. On the other hand, texture feature such as singularity, fractal dimension, and homogeneity had been demonstrated effective for segmenting tooth contours in dental periapical radiograph images [15]. Nevertheless, serious bone-loss areas in periodontitis radiograph images generally appear very dark with insignificant texture, i.e., its intensity characteristic is more significant than texture characteristic. Thus, using texture alone may also not be effective enough for localizing serious bone-loss areas in periodontitis radiograph images.

Studies on using multiple features to improve segmentation/classification accuracy for medical images have been reported often in literature. For example, both intensity and homogeneity were used for segmenting dental radiograph images and demonstrated effective for detecting periapical lesion and bifurcation lesion [16,17]. In [18], intensity histogram, continuous wavelet transform, and GLCM descriptors are combined for segmenting carotid artery ultrasound images. In [19], grayscale features, local binary patterns, and wavelet based features were combined for detecting the condition coronary artery disease.

Since the past decade, level set segmentation technique has been applied to various kinds of medical images [16,17,20,21] because it is robust against uneven illumination and complex topology, from which medical images commonly suffer. Although level set segmentation has gained popularity in medical images, it is sensitive to the placement of initial contours. On the other hand, “image thresholding enjoys a central position in application of image segmentation, because of its intuitive properties, simplicity of implementation and computational speed” [22].

For efficiently and effectively localizing alveolar bone-loss areas in evenly or unevenly illuminated periodontitis radiograph images, we propose a threshold segmentation method using a hybrid feature fused of both intensity and fBm-H in this paper, where the H-value is the Hurst coefficient in the expectation function of a fBm curve (intensity change) and is directly related to the value of fractal dimension.

The remainder of this paper is organized as follows. In Section 2, the adopted/adapted existing methods including fractional Brownian motion model and the H-value of this model, Bayesian classifier that is used for feature-weight training, and receiver operating characteristic curve for evaluating classification effectiveness of image features used for segmenting periodontitis radiograph images are briefly described followed by the detailed description of the proposed method. In Section 3, experimental results, performance assessment, and comparisons with other methods are provided. Finally, conclusions are given in Section 4.

Thirty-one periodontitis radiograph images of various alveolar bone-loss degrees are used in this study. All images are provided by Chung Sun Medical University Hospital in Taiwan.

In this sub-section, we briefly describe the existing methods that we adapted/adopted in this paper, as well as our investigation on classification effectiveness of several features that are used for segmenting alveolar bone-loss areas in periodontitis radiograph images.

The fractional Brownian motion (fBm) model is probably the most useful and popular model to describe the natural fractal phenomenon [23]. It belongs to the class of statistically self-affine fractals [24] and regards naturally occurring rough surfaces as the end result of random walks [25]. Thus, the fBm model is suitable for the use in medical image analysis because the intensity surface of a medical image can also be viewed as the end result of random walks.

A fBm surface I(x, y) must satisfy the following relationship [25]:
                              
                                 (1)
                                 
                                    
                                       E
                                       (
                                       |
                                       I
                                       (
                                       x
                                       2
                                       ,
                                       y
                                       2
                                       )
                                       −
                                       I
                                       (
                                       x
                                       1
                                       ,
                                       y
                                       1
                                       )
                                       |
                                       )
                                       ∝
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               (
                                                               x
                                                               2
                                                               −
                                                               x
                                                               1
                                                               )
                                                            
                                                            2
                                                         
                                                         +
                                                         
                                                            
                                                               (
                                                               y
                                                               2
                                                               −
                                                               y
                                                               1
                                                               )
                                                            
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          H
                                       
                                       ,
                                    
                                 
                              
                           where H is called the Hurst coefficient, and 0<
                           H
                           <1. E(·) represents an expectation value.

By defining ΔI
                           Δr
                           
                           =|I(x2, y2)−
                           I(x1, y1)|, 
                              
                                 
                                    Δ
                                    r
                                 
                                 =
                                 
                                    
                                       
                                          
                                             (
                                             x
                                             2
                                             −
                                             x
                                             1
                                             )
                                          
                                          2
                                       
                                       +
                                       
                                          
                                             (
                                             y
                                             2
                                             −
                                             y
                                             1
                                             )
                                          
                                          2
                                       
                                    
                                 
                              
                           , we can obtain
                              
                                 (2)
                                 
                                    
                                       E
                                       (
                                       
                                          Δ
                                       
                                       
                                          I
                                          
                                             
                                                Δ
                                             
                                             r
                                          
                                       
                                       )
                                       ∝
                                       
                                          Δ
                                       
                                       
                                          r
                                          H
                                       
                                       ,
                                    
                                 
                              
                           which can be rewritten as E(ΔI
                           Δr
                           )=
                           KΔr
                           
                              H
                           , where K is a constant [25]. Then, we can easily obtain the following formula by applying the log function to both sides of (2):
                              
                                 (3)
                                 
                                    
                                       log
                                       (
                                       E
                                       (
                                       
                                          Δ
                                       
                                       
                                          I
                                          
                                             
                                                Δ
                                             
                                             r
                                          
                                       
                                       )
                                       )
                                       =
                                       H
                                        
                                       log
                                       (
                                       
                                          Δ
                                          r
                                       
                                       )
                                       +
                                       K
                                       (
                                       constant
                                       )
                                       .
                                    
                                 
                              
                           
                        

From (3), it is clear that the H value can be estimated from the slope of the line approximated by least-squares linear fitting for log(E(ΔI
                           Δr
                           )) vs. log(Δr) over a chosen range from the lower scale Δr
                           min to the upper scale Δr
                           max. Since fractal dimension FD=3-H, and higher FD indicates rougher texture [26]. Thus, lower H value implies higher fractal dimension, which in turn stands for higher degree of texture roughness.

Bayesian classifier [27] theoretically is optimal with respect to minimizing the classification error probability.

Given a multivariate feature vector x, classify it to class c
                           
                              i
                            if P(c
                           
                              i
                           |x)>
                           P(c
                           
                              j
                           |x) ∀
                           j
                           ≠
                           i, or equivalently if p(x|c
                           
                              i
                           )P(c
                           
                              i
                           )>
                           p(x|c
                           
                              j
                           )P(c
                           
                              j
                           ) ∀
                           j
                           ≠
                           i, based on Bayes formula. Thus, Bayes decision function can be defined as: g
                           
                              i
                           (x)=ln(p(x|c
                           
                              i
                           ))+ln(P(c
                           
                              i
                           )), as ln (natural logarithm) is a monotonic function. Further assume that the feature vector x has a multivariate normal (Gaussian) distribution with mean vector μ
                           
                              i
                            and covariance matrix Σ
                              i
                           . Then, Bayes decision function can be obtained as 
                              
                                 
                                    g
                                    i
                                 
                                 (
                                 
                                    x
                                 
                                 )
                                 =
                                 −
                                 (
                                 1
                                 /
                                 2
                                 )
                                 
                                    
                                       (
                                       
                                          x
                                       
                                       −
                                       
                                          μ
                                          i
                                       
                                       )
                                    
                                    T
                                 
                                 
                                    ∑
                                    i
                                    
                                       −
                                       1
                                    
                                 
                                 (
                                 
                                    x
                                 
                                 −
                                 
                                    μ
                                    i
                                 
                                 )
                                 −
                                 1
                                 /
                                 2
                                  
                                 ln
                                 |
                                 
                                    ∑
                                    i
                                 
                                 +
                                 ln
                                  
                                 P
                                 (
                                 
                                    c
                                    i
                                 
                                 )
                                 |
                              
                            where |∑
                              i
                           | and 
                              
                                 
                                    ∑
                                    i
                                    
                                       −
                                       1
                                    
                                 
                              
                            are the determinant and inverse of the covariance matrix for class c
                           
                              i
                           , respectively. Thus, the feature vector x will be classified to c
                           
                              i
                            if g
                           
                              i
                           (x)>
                           g
                           
                              j
                           (x), ∀
                           i
                           ≠
                           j, where i, j
                           ∈{1,2,…,C}, C is the total number of classes.

Receiver operating characteristic (ROC) curve is a two-dimensional graph in which true positive rate (TPR) is plotted on the Y-axis and false positive rate (FPR) is plotted on the X-axis, where TPR and FPR are, respectively, defined as [27]:
                              
                                 (4)
                                 
                                    
                                       TPR
                                       =
                                       
                                          
                                             TP
                                          
                                          
                                             TP
                                             +
                                             FN
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (5)
                                 
                                    
                                       FPR
                                       =
                                       
                                          
                                             FP
                                          
                                          
                                             FP
                                             +
                                             TN
                                          
                                       
                                    
                                 
                              
                           in which TP is true positive, FN is false negative, FP is false positive, and TN is true negative. In other words, ROC curve depicts relative tradeoffs between benefits (true positives) and costs (false positives), and hence can be used for illustrating the performance of a binary classifier system at varied discrimination threshold.

ROC curve can also be expressed mathematically as follows [28]. Given the probability of belonging to the class as a function of a decision/threshold parameter T, denoted as P
                           1(T), and the probability of not belonging to the class as P
                           0(T). An ROC curve plots parametrically TPR(T) vs. FPR(T) with varying T, where TPR(T) and FPR(T) are given by: 
                              
                                 TPR
                                 (
                                 T
                                 )
                                 =
                                 
                                    ∫
                                    T
                                    ∞
                                 
                                 
                                    
                                       P
                                       1
                                    
                                    (
                                    T
                                    )
                                     
                                    d
                                    T
                                 
                              
                           , 
                              
                                 FPR
                                 (
                                 T
                                 )
                                 =
                                 
                                    ∫
                                    T
                                    ∞
                                 
                                 
                                    
                                       P
                                       0
                                    
                                    (
                                    T
                                    )
                                     
                                    d
                                    T
                                 
                              
                           .

Area under the ROC curve (AUC) is defined as 
                              
                                 A
                                 U
                                 C
                                 =
                                 
                                    ∫
                                    
                                       −
                                       ∞
                                    
                                    ∞
                                 
                                 
                                    T
                                    P
                                    R
                                    (
                                    T
                                    )
                                    
                                       P
                                       0
                                    
                                    (
                                    T
                                    )
                                     
                                    d
                                    T
                                 
                              
                            
                           [28]. It can be viewed as a measure based on pair-wise comparisons between classifications of two classes. A larger AUC indicates higher performance of the classification rule applied [27].

We conducted an experiment on detecting bone-loss areas in 28 periodontitis radiograph images by transforming the regions containing alveolar bone tissues (i.e., ROI) into their respective feature image (intensity, fBm-H, GLCM-contrast, -correlation, -energy, -entropy, -homogeneity) and classifying each feature image into bone-loss and normal areas using threshold 0.01–1.0 at interval of 0.01. The segmented bone-loss areas in each image were compared with the ground truth provided by a dentist to generate a pair of TPR and FPR using (4) and (5) at each threshold setting. Then the average of TPRs and the average of FPRs of all tested images are computed and the ROC curve of each feature is plotted, as depicted in Fig. 1
                           . Observing Fig. 1, we can clearly see that intensity, fBm-H, GLCM-energy, and GLCM-correlation are four possible good features for classifying the data in ROI into normal and bone-loss classes, with intensity and fBm-H being the best two as they provide with the two largest AUC.

The above investigation suggested that using intensity or fBm-H as the classification feature should be able to result in quite accurate bone-loss area localization in average. Nevertheless, we also noticed that using either feature alone did not work well for some radiograph images. In general, in radiographs not suffering from uneven illumination, serious bone-loss areas usually appear quite dark in intensity with insignificant texture; whereas early or medium stage bone-loss areas appear darker in intensity and smoother in texture than those of normal tissues. However, dental radiographs often suffer from uneven illumination. Thus, the intensity of some normal and bone-loss areas become quite close to each other and texture differences become insignificant, if both types of tissues locate at different illuminated part of radiographs. In other words, using intensity or texture alone for bone-loss area localization could result in either falsely classifying normal areas as bone-loss or falsely classifying bone-loss areas as normal, if we regard low-intensity or smooth texture as the only characteristic of bone-loss areas. To better locate both serious and early/medium-stage bone-loss areas simultaneously in evenly-/unevenly-illuminated radiograph images, we propose an alveolar bone-loss-area localization method and denoted it as ABLIfBm. The proposed method involves four stages: region-of-interest identification, feature fusion, coarse segmentation, and fine segmentation.

Periodontitis radiograph images contain white borders, characters, air/background, teeth, and alveolar bone tissues. Since periodontitis is a set of inflammatory diseases affecting the tissues that surround and support the teeth, and our goal is to localize bone-loss areas around the teeth, the first step of the method is to identify the areas surround the teeth (i.e., region of interest). Adopting our recently developed teeth segmentation method presented in [15], we firstly select a region from each periodontitis radiograph image excluding the white borders and characters and apply the automatic teeth segmentation method to obtain almost all the teeth contours in that image. We then perform morphological dilation to the teeth contours to form the region of interest in each image.

After identifying the region of interest (i.e., areas surround teeth) in the image, the next step is to transform the image within the region of interest into a hybrid of texture and intensity image.

We use weighted average of both texture feature fBm-H and intensity I as the hybrid feature for segmentation, where the weights are determined based on a training-and-testing mechanism. That is, the hybrid feature image I
                           IfBm can be obtained from
                              
                                 (6)
                                 
                                    
                                       
                                          I
                                          
                                             IfBm
                                          
                                       
                                       =
                                       
                                          w
                                          
                                             fBm
                                          
                                       
                                       
                                          I
                                          
                                             fBm
                                          
                                       
                                       +
                                       
                                          w
                                          
                                             int
                                          
                                       
                                       
                                          I
                                          ′
                                       
                                    
                                 
                              
                           where I
                           fBm is the normalized feature image based on fBm-H, I′ (=1−
                           I) is the normalized inverse of I, 0≤
                           w
                           fBm, w
                           int
                           ≤1 are the weight of I
                           fBm and I′, respectively. Notice that we use I′ (the inverse of I) instead of I in (6) to make both features consistent numerically, because the bone-loss areas appear smoother in texture (i.e., larger fBm-H) and darker intensity (smaller I and hence larger I′) than those of normal areas.

Among the three widely used training and testing mechanisms: random sampling, k-fold cross validation, and leave-one-out cross validation [29], we choose leave-one-out cross validation because of small sample size. And, among the popular supervised classifiers, we choose Bayesian classifier because that it theoretically is optimal with respect to minimizing the classification error probability [27]. That is, for each periodontitis image to be validated, we use the rest periodontitis images as the training data along with Bayesian classifier to train the weight for that particular image. However, periodontitis images contain teeth, which are not part of the region of interest for this method. Thus, instead of using the entire periodontitis image as the training image, we construct each training/testing image by randomly selecting a block from bone-loss areas and a block from normal areas in each periodontitis image then combining both blocks. The weight training algorithm is as follows, where I
                              1, I
                              2,…, I
                              
                                 K
                               represent the K radiograph images.


                              Algorithm: Weight-training
                           


                              Input: I
                              1, I
                              2,…, I
                              
                                 K
                              
                           


                              Output: w
                              fBm, w
                              int
                              
                                 
                                    1.
                                    For i
                                       =1 to K, do

Randomly select a block from bone-loss areas and a block from normal areas from each I
                                       
                                          i
                                       .

Combine both blocks to form a training image and transform it to feature image I
                                       fBm,i
                                        and 
                                          
                                             
                                                
                                                   I
                                                   ′
                                                
                                                i
                                             
                                          
                                       , respectively, using the feature fBm-H (the H value in (3)) and the inverse of normalized intensity I′.

For j
                                       =1 to 99, do

Set w
                                       
                                          fBm
                                       
                                       =0.01*j, w
                                       int
                                       
                                       =
                                       1−
                                       w
                                       fBm
                                    

For k
                                       =1 to K, do

Obtain the training sets I
                                       IfBm,i
                                        (i
                                       =1,…,K ∧ i
                                       ≠
                                       k) and the test set I
                                       IfBm,,k
                                        by combining (I
                                       fBm,i
                                       , 
                                          
                                             
                                                
                                                   I
                                                   ′
                                                
                                                i
                                             
                                          
                                       ) and (IfBm,k
                                       , 
                                          
                                             
                                                
                                                   I
                                                   ′
                                                
                                                k
                                             
                                          
                                       ), respectively, using (6).

Classify the test set by using Bayesian classifier with the training set.

Calculate error rate E
                                       
                                          j,k
                                        using

Calculate E
                                       
                                          j
                                        using

Obtain the desired w
                                       fBm
                                       =0.01*j, w
                                       int
                                       
                                       =
                                       1−
                                       w
                                       fBm with 
                                          
                                             j
                                             =
                                             
                                                
                                                   arg
                                                
                                                j
                                             
                                             min
                                             
                                                E
                                                j
                                             
                                          
                                       .

Return w
                                       fBm, w
                                       int
                                    


                              Fig. 2
                               provides an illustration of two periodontitis radiograph images and their three corresponding feature images, where Fig. 2(a-1) and (a-2) are the original image, Fig. 2(b-1) and (b-2) are the hybrid-feature image I
                              IfBm generated from (4) with the weights trained by the weight-training algorithm using 28 periodontitis radiograph images. Fig. 2(c-1) and (c-2) are the normalized inverse of intensity image I′, and Fig. 2(d-1) and (d-2) are the texture fBm-H image I
                              fBm, respectively. Notice that in Fig. 2(b-1), the areas corresponding to the ground truth (the areas within the red contour) appear significantly brighter than the rest areas containing normal alveolar bone tissues. Notice also that in Fig. 2(c-1), the areas within the red contour appear significantly brighter than most of the rest areas as well, but the left-most normal areas also appear nearly as bright. As for Fig. 2(d-1), the areas within the red contour appear not as bright and the size of bright areas is rather different. The similar finding can be observed from the other set of images in Fig. 2(a-2), (b-2), (c-2), and (d-2). This example suggests that the hybrid-feature image I
                              IfBm provides with either more significant differences between bone-loss areas and normal areas or with more accurate localized bone-loss areas than the intensity-feature image I′ and the texture-feature image I
                              fBm can provide.

Analyzing the histogram of the images in Fig. 2(b-1) and (b-2), as shown respectively in Fig. 3(a) and (b), we found that both histograms have one small mode in the range of high intensity. This suggests that the hybrid feature image can be divided into two types of areas: bone-loss areas (areas with intensity in the range of the small mode) and normal areas (areas with intensity not in the range of the small mode) by simple thresholding. Thus, we threshold the hybrid feature image into classes C
                           0 and C
                           1 using a threshold T obtained from Otsu's method [30] defined as:
                              
                                 (9)
                                 
                                    
                                       T
                                       =
                                       arg
                                       
                                          
                                             max
                                          
                                          
                                             0
                                             ≤
                                             t
                                             <
                                             L
                                          
                                       
                                       {
                                       
                                          ϖ
                                          0
                                       
                                       
                                          
                                             (
                                             
                                                μ
                                                0
                                             
                                             −
                                             
                                                μ
                                                T
                                             
                                             )
                                          
                                          2
                                       
                                       +
                                       
                                          ϖ
                                          1
                                       
                                       
                                          
                                             (
                                             
                                                μ
                                                1
                                             
                                             −
                                             
                                                μ
                                                T
                                             
                                             )
                                          
                                          2
                                       
                                       }
                                       .
                                    
                                 
                              
                           
                        

Note that T in (9) is the threshold t that maximizes the variation between class C
                           0 containing all pixels with gray level in the range [0,t] and C
                           1 containing all pixels with gray level in the range [t
                           +1, L
                           −1], respectively, L is the total number of gray levels of the image, ω
                           0 and ω
                           1 are the probabilities of the two classes, μ
                           0 and μ
                           1 are the mean of the two classes, respectively, and μ
                           
                              T
                            is the global mean of the image. As a result, areas classified to C
                           1 in each feature image are bone-loss areas.

After coarse segmentation, we obtain several connected components that are classified as bone-loss areas. However, some may not be true bone-loss areas. To achieve a more accurate result, we perform a refinement procedure as follows.
                              
                                 1.
                                 Label each connected component.

Do morphological dilation to each connected component.

Remove those connected components that are not overlapping with the teeth contour.

Apply morphological reconstruction to fill the holes of the remaining connected components [32].


                           Fig. 4
                            shows the segmentation result of the two sets of feature images in Fig. 2(b-1)–(d-1) and (b-2)–(d-2), respectively. Comparing the red-shaded areas (the segmented bone-loss areas) with the ground truth (areas within black contours), we can clearly see that the area difference in the hybrid-feature image I
                           IfBm is smaller than the area difference in the texture-feature image I
                           fBm and in the intensity-feature image I′, respectively. In other words, the result of using the hybrid feature is more conforming to the ground truth.

@&#RESULTS AND DISCUSSION@&#

Two experiments are conducted to test the effectiveness of our proposed method. In the first experiment, we test the same 28 periodontitis radiographs used in weight training, and compare the results with the same threshold-segmentation method using feature I′ alone and using feature fBm-H alone. In the second experiment, we test three periodontitis radiographs not used in weight training. The weights for the hybrid feature are 0.85 and 0.15 for I′ and fBm-H, respectively, in both experiments.

Performance is assessed through four quantitative measures of the segmented bone-loss areas: true positive fraction (TPF), true negative fraction (TNF), false positive fraction (FPF), and false negative fraction (FNF). The definitions of these measures are adapted from [31] and slightly modified as follows.

Let C be the region of the segmented bone-loss areas by our proposed method, C
                        gt be the ground truth of bone-loss areas, and U be the region of interest, |X| be the number of pixels in region X, then
                           
                              (10)
                              
                                 
                                    TPF
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      TP
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      gt
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 
                                    TNF
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      TN
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                U
                                                −
                                                
                                                   C
                                                   
                                                      gt
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (12)
                              
                                 
                                    FPF
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      FP
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                U
                                                −
                                                
                                                   C
                                                   
                                                      gt
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (13)
                              
                                 
                                    FNF
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      FN
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   C
                                                   
                                                      gt
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where C
                        TP
                        =
                        C
                        ∩
                        C
                        gt, C
                        TN
                        =
                        U
                        −(C
                        ∪
                        C
                        gt), C
                        FP
                        =
                        C
                        −
                        C
                        TP, and C
                        FN
                        =
                        C
                        gt
                        −
                        C
                        TP. Note that A–B can only be applied when B is a subset of A.

@&#RESULTS AND ANALYSIS@&#


                        Table 1
                         lists the mean and standard deviation of TPF, TNF, FPF, and FNF of the localized bone-loss areas obtained from both experiments.

From Table 1, we can clearly see that (a) using the proposed hybrid feature can result in the best combination of (TPF, FPF, TNF, FNF) when testing the images used in weight training, (i.e., (92.5±12.9, 13.8±9.1, 86.2±9.1, 7.5±12.9) vs. (91.2±13.7, 15.3±10.5, 84.7±10.5, 8.8±13.7) for intensity only and (89.2±12.2, 24.4±6.4, 75.6±6.4, 10.8±12.2) for fBm-H only; (b) using the proposed hybrid feature can also result in as good segmentation, (i.e., (92.8±6.4, 14.1±9.7, 85.9±9.7, 7.2±6.4) of (TPF, FPF, TNF, FNF)) when testing the images not used in weight training. In other words, the proposed method using hybrid of I′ and fBm-H with respective weight 0.85 and 0.15 can localize nearly the most true bone-loss areas while having nearly the least false segmented areas in images used or unused in weight training than the method using either feature alone.

As mentioned earlier, serious bone-loss areas in periodontitis radiographs generally appear quite dark in intensity with insignificant texture. Thus, using intensity as the sole classification feature should be sufficient for localizing bone-loss areas in radiographs with near even illumination. Since our method uses intensity as the primary classification feature (i.e., weight=0.85), the segmentation result for serious bone-loss areas should be close to the result of using intensity as the only classification feature. In our experimental result, near 1/2 of the test images are such examples; thus the localized bone-loss areas using I′ alone and using hybrid of I′ and fBm-H are very similar to each other, and both are quite conforming to the ground truth.

For early or medium stage bone-loss areas, though they are also darker and smoother than normal tissues, the difference of either feature is not as significant as that of the serious bone-loss areas. The situation becomes even worse when the radiographs are unevenly illuminated. Thus, hybrid feature fused of I′ and fBm-H with proper weight should be able to result in more accurate classification, if both features are well complementary to each other. The result of 1/3 of the test images validates this argument.

However, when radiographs are either poorly uneven-illuminated or both features of radiographs are not well complemented to each other, the result of using hybrid feature may not be lot better than the result of using a single effective feature. For radiographs with the former problem, the weight for fBm-H should be lot higher than the weight for intensity; whereas for radiographs with the latter problem, both weights should be approximately the same as both features are near equally important. Unfortunately, majority of our radiograph images do not have poor uneven-illumination problem so that the trained weight for intensity (0.85) is much higher than that for fBm-H (0.15). Thus, over-/under-segmentation occurred in the result of these types of the tested radiographs.

To the best of our knowledge, the other automatic bone-loss-area localization method for periodontitis radiograph images ever presented in literature is our previous work that segmented bone-loss areas based on a level set function (LSF) [17]. In this section, we first demonstrate the effectiveness of proper weight combination of the hybrid feature then compare the localization performance of the proposed threshold method (ABLIfBm) with the performances of our previous LSF method and of three popular classifiers: Bayesian, K-NN, and SVM, using the same two features. By definitions in (10)–(13), FNF and TNF can be obtained directly from TPF and FPF, respectively. Thus, in the following comparisons, we will only consider TPF and FPF.

For demonstrating the effectiveness of proper weight combination of the hybrid feature, we conduct an experiment on the same 28 radiograph images using the same threshold segmentation method and the same two features but with (a) equal weights (i.e., without training), (b) weights trained based on leave one out cross validation along with respective K-NN and SVM classifier, and (c) weights trained based on 2-fold cross validation, where odd/even-number images are used as training set and even/odd-number images as testing set (denoted 2-OE and 2-EO), along with Bayesian, K-NN, and SVM classifier, respectively. Table 2
                            lists the weights and their corresponding performance in terms of (mean, standard deviation) of TPF and FPF.

From Table 2, we get the following conclusions: (a) the proposed method using the weighted average of features performs better than the method using a pure average of the same features; (b) the weights trained based on leave one out cross validation along with Bayesian, K-NN, or SVM classifier are not much different (i.e., (0.85, 0.15), (0.81, 0.19), and (0.83, 0.17) for I′ and fBm-H, respectively), and hence the respective performance is not different significantly (i.e., the (TPF, FPF) for all three are (92.5, 13.8), (92.6, 15.3), and (92.5, 15.1), respectively); (c) the proposed method using the weights trained based on leave one out validation performs better than it using the weights trained based on 2-fold cross validation ((i.e., (92.5, 13.8) vs. (91.2, 15.4) for 2-OE and (91.4, 15.6) for 2-EO) for Bayesian, ((92.6, 15.3) vs. (91.4, 16.0) for 2-OE and (91.2, 15.4) for 2-EO) for K-NN, and (92.5, 15.1) vs. (91.4, 15.7) for 2-OE and (91.4, 16.0) for 2-EO) for SVM.

We compare the localization performance in terms of (mean, standard deviation) of TPF and FPF of the proposed threshold method ABLIfBm with that of our previous LSF method using the same two features, as well as with that of three popular classifiers: Bayesian, K-NN, and SVM using the same two classification features, respectively. Notice that we did not test the performance of LSF segmentation using intensity and homogeneity as in [17], because we found out that texture fBm-H is more effective than homogeneity for bone-loss area localization in Section 3. The initial LSF is obtained from the intersection of Otsu's segmentation results of each feature image and the weights for the hybrid feature are 0.85, 0.15 for I′ and fBm-H, respectively. The test images are the 28 images used in weight training. Table 3
                            lists the performance comparison of these methods.

From Table 3, we get the following conclusions: (a) the proposed threshold method ABLIfBm using the hybrid feature fused of I′ and fBm-H performs the best, as it has the best combination of (TPF, FPF); (b) the proposed method has significant lower FPF (about 14%) than our previously proposed LSF segmentation method, Bayesian, K-NN, and SVM classification methods using the same two features, while having about the same TPF in average.

@&#CONCLUSIONS@&#

We presented an effective alveolar bone-loss area localization method ABLIfBm for periodontitis radiograph images using threshold segmentation with a hybrid feature generated by 0.85 I′+0.15 fBm-H, where the weights are trained based on leave-one-out cross validation mechanism along with Bayesian classifier. The experimental results on 31 periodontitis radiograph images (used or unused in weight training) are about 92.5% and 14.0% in terms of true positive fraction (TPF) and false positive fraction (FPF), where both TPF and FPF are computed against the ground truth provided by a dentist. The results demonstrated that ABLIfBm is superior to (a) the threshold segmentation method using either feature fBm-H or I′ alone, pure average of both features, and weighted average of both features with the weights trained based on 2-fold cross validation mechanism; (b) the level set segmentation method presented earlier using the same two features; and (c) classification methods Bayesian, K-NN, and SVM using the same two features.

@&#ACKNOWLEDGMENT@&#

The research was partially supported by Ministry of Science and Technology, ROC under Grant # NSC 102-2221-E-126-009, and MOST 103-2221-E-126-006-MY2.

@&#REFERENCES@&#


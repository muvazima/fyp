@&#MAIN-TITLE@&#Two-stage dither to enhance gray scales based on real-time motion detection in plasma display panel

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Gray scale loss is markedly improved by two-stage dither combined with MPS.


                        
                        
                           
                           Dither noises caused by random dither and ordered dither can be reduced obviously.


                        
                        
                           
                           Gray scales in static and moving regions are expressed smoothly as DFC is improved.


                        
                        
                           
                           Motion state of each image block can be obtained by the real-time motion detection.


                        
                        
                           
                           Motion detection is easy to implement and detection accuracy can reach to 99.3%.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Plasma display panel (PDP)

Real-time motion detection

Dither

Minor pixel separation (MPS)

Gray-scale enhancement

@&#ABSTRACT@&#


               
               
                  In order to reduce gray scale loss in low and middle-high gray scale ranges which are caused by inverse gamma conversion and limited gray scale method for dynamic false contour (DFC) improvement, respectively, and enhance gray scales both in static and moving regions of an image, two-stage dither based on real-time motion detection method is proposed. Firstly, the image is divided into blocks, and the motion state of each image block is detected according to real-time motion detection method. So limited gray scale method to improve DFC can only be used in moving image blocks. Then, ordered dither and random dither combined with minor pixel separation (MPS) are used to improve gray scale loss caused by inverse gamma conversion and limited gray scale method, respectively. The experimental results show that motion detection can be implemented easily and the detection accuracy is more than 99.3%. The gray scales in moving and static image regions are all expressed smoothly while DFC is markedly improved.
               
            

@&#INTRODUCTION@&#

Inverse gamma conversion is necessary for plasma display panel (PDP) and gray scale loss will occur, especially in low gray scale range [1]. Dynamic false contour (DFC), a serious problem in PDP, is usually improved effectively by using limited gray scale method [2,3]. However, it can cause gray scale loss, especially in middle-high gray scale range.

Gray scale enhancement is needed for reproducing gray scale loss. Dither is one of the most effective methods to reproduce the gray scales and smooth the luminance among these gray scales which cannot be displayed directly [4]. Dither noise can be reduced by varying dither mask according to the motion vector. However, the motion vector algorithm is complex and high cost to implement in real time for consumer electronics [5]. Subfield dither algorithm can reduce the structural pattern in two smallest-weight subfields with an additional subfield [6]. The structural pattern will occur when error diffuse combined with ordered dither is used for a motion image and image quality in middle-high gray scale range may be worse [7]. Dither algorithm using multi-threshold level can improve the luminous distribution both in spatial and time domains. However, at specific gray scales (e.g. the value of fraction is 1/4 after data conversion), it will induce structural pattern and deteriorates image quality seriously [8]. Different dither methods may cause different dither noise at different gray scale ranges. Besides, minor pixels (MP) which causes uncomfortable visual perception are easily brought by dither or error diffusion for gray scale enhancement [9].

When limited gray scale method is used to improve DFC in the whole image without distinguishing moving or static image regions, poor gray scale expression in static image regions will be brought [10,11]. The complexity and cost of motion detection methods such as new diamond search, novel four-step search, and new three-step search are too high to apply in PDPs although these methods can obtain velocity and direction of movement accurately [12–14]. Therefore, lower cost and easier implementation are the key issues for motion detection in DFC improvement.

Two-stage dither method based on real-time motion detection is proposed to improve gray scale expression in the whole gray scale ranges and reduce dither noise both in static and moving image regions. First, an image is divided into blocks and motion state of each image block is detected according to the brightness differences among image frames. In order to improve DFC occurred in moving regions and ensure the gray scale expression in static regions simultaneously, different numbers of gray scales are applied in the two kinds of image regions, respectively. Then, the two-stage dither combined with minor pixel separation (MPS) is used to enhance the gray scales according to the characteristics of gray scale loss caused by inverse gamma conversion and DFC improvement. The experimental results show that the motion detection is easy to implement and its accuracy can reach 99.3%. The gray scales after inverse gamma conversion and limited gray scale method are both expressed smoothly without periodic dither noise and minor pixels.

The output gray scales are compressed into a narrow gray scale range after inverse gamma conversion, and gray scale loss is brought. The limited gray scales are used to improve DFC. For example, GRAY is a set of the limited gray scales including [0 1 2 4 5 8 9 14 17 23 26 28 37 41 44 58 64 68 71 90 99 105 109 134 148 157 163 166 197 214 228 237 242 255]. Therefore, input gray scales 0 to 255 can only be expressed by GRAY and it also cause gray scale loss.

Assuming l
                        0 is the brightness value of one gray scale and the background brightness g
                        0 is equal to l
                        0, g
                        
                           i
                         is the gray scale after inverse gamma conversion. The brightness of gray scale g
                        
                           i
                         is l
                        0
                        +
                        g
                        
                           i
                        
                        ×
                        l
                        0. According to the Weber Law, human vision system is sensitive to the relative error of brightness differences. The relative errors r
                        
                           1
                         and r
                        
                           2
                         caused by inverse gamma conversion and limited gray scale method, respectively, are calculated by (1).
                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   r
                                                   1
                                                   =
                                                   
                                                      
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         -
                                                         [
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         ]
                                                      
                                                      
                                                         [
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         ]
                                                         +
                                                         
                                                            
                                                               l
                                                            
                                                            
                                                               0
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   r
                                                   2
                                                   =
                                                   
                                                      
                                                         [
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         ]
                                                         -
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               n
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               g
                                                            
                                                            
                                                               n
                                                            
                                                         
                                                         +
                                                         
                                                            
                                                               l
                                                            
                                                            
                                                               0
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where i is from 0 to 255. Integer part of g
                        
                           i
                         is [g
                        
                           i
                        ]. N is the number of gray scales in GRAY, g
                        
                           n
                         is the gray scale in GRAY, and 
                           
                              
                                 
                                    g
                                 
                                 
                                    n
                                 
                              
                              <
                              
                                 
                                    g
                                 
                                 
                                    i
                                 
                              
                              <
                              
                                 
                                    g
                                 
                                 
                                    n
                                    +
                                    1
                                 
                              
                           
                        , n is from 1 to N.

Different gamma and limited gray scales will cause different relative errors. We set gamma as 2.2 and limited gray scales as GRAY, respectively. The relative errors calculated by (1) are shown in Fig. 1
                        . We can find that the relative error caused by inverse gamma conversion in the low gray scale range about 0 to 60 is much higher than that in the middle-high gray scale range over 60. When using limited gray scales for DFC improvement, gray scale loss mainly occurs in the middle-high gray scale range about 55 to 255. It means that the gray scale loss is always much more easily perceived by human vision system both in the low gray scale range after inverse gamma conversion and in the middle-high gray scale range after limited gray scale method.

Dither is as effective method to improve gray scale loss and reproduce gray scales. Assuming gray scales 4 and 8 can be displayed directly in PDPs, gray scale 5 can be expressed with three gray scales 4 and one gray scale 8 by using spatial brightness mixture shown in Fig. 2
                        . Gray scales 6 and 7 can also be expressed using the same way. Dither mask is very important in dither method. The random dither mask and ordered dither mask are usually used in PDPs, which are composed by a series of random numbers and certain matrix, respectively.
                           
                              (1)
                              The characteristic of ordered dither noise.

Bayer matrix is always as ordered dither mask, and the regular stripe shown in Fig. 3
                                 (a) is brought in static image because of the cyclical and certain dither mask. When realizing some certain gray scales (such as 1/4) in moving pictures by ordered dither, another kind of regular lattice pattern will appear as shown in Fig. 3(b). These dither noises can be eliminated by using different dither masks according to the image motion vector. However, the image motion vector detection is high cost and complex to apply in PDPs.

The characteristic of random dither noise.

Random dither uses a series of random numbers as dither mask. When the width of random numbers is the same as the image gray scale decimal fraction, all the gray scales can be represented by decimal fraction of image gray scale in theory. Gray scale 8 realized by random dither is shown in Fig. 4
                                  and no regular pattern noise occurs. However, bright or dark areas can easily gather together because brightness distribution after random dither is not so uniform.

Noise caused by minor pixel.

The brightness of some pixels is much higher or lower than other adjacent pixels when dither method is used for gray scale enhancement. These brighter or darker pixels are called minor pixels (MP) [9]. As shown in Fig. 2, when realizing gray scale 5, the pixel with gray scale 8 is brighter than other adjacent pixels and is called MP. Likewise, the pixel with gray scale 4 is darker than other pixels and is also called MP when realizing gray scale 7. Minor pixels can easily be brought in dither. As human vision system is sensitive to the non-uniform gray scales, MP is easily perceived and cause serious dither noise.

The implementation flow of proposed method is shown in Fig. 5
                     . First, the motion state of each image block is detected by the real-time motion detection method. According to the motion detection results, we use limited gray scales (limited gray scale method) in moving image regions to achieve DFC improvement, and 256 gray scales in static image regions to keep static image rendering. Then, two-stage dither (ordered dither and random dither) combined with MPS are used to enhance gray scales. Ordered dither combined with MPS is used to improve gray scale loss caused by inverse gamma conversion, and random dither combined with MPS is used after limited gray scale method because non-uniform brightness distribution and the gray scale loss mainly occur in middle-high gray scale range.

An image moving from right to left at different frames are shown in Fig. 6
                        . We assume that the brightness calculation value of region A in frames i and j are L
                        
                           i
                         and L
                        
                           j
                        , respectively. ΔL
                        
                           K
                         is brightness difference between L
                        
                           i
                         and L
                        
                           j
                         expressed in (2), where k is the counter which counts the continuous moving times of the image block, when (2) is not true, k plus 1, if the image block is detected as still, k is set to 0. The image region A is considered as moving if ΔL
                        
                           K
                         is larger than brightness difference threshold B
                        
                           th
                        .
                           
                              (2)
                              
                                 Δ
                                 
                                    
                                       L
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                L
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                L
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                 
                                 >
                                 
                                    
                                       B
                                    
                                    
                                       th
                                    
                                 
                              
                           
                        
                     

Supposing that the brightness of dark color stripe and light color stripe are G1 and G2, respectively, in Fig. 6. From the figure, we can get the brightness differences ΔL
                        
                           K
                         between adjacent frames from frame i to i
                        +4 are 0, 0, G2–G1 and 0, respectively. Assuming G2–G1 is bigger than B
                        
                           th
                        , the motion state of the image region A is detected as moving only once. So motion state of image blocks are hard to determine accurately by comparing the brightness differences between adjacent frames directly due to image noise, uniform gray scale distribution, and the complexity of image content. In order to determine the motion state of each image block accurately, the frame interval n between frames i and j must be large enough. The frame interval n corresponds to the content of an image and the division of the image blocks. Also, image movement is continuous and should meet the characteristic of human vision system. Once an image block is determined as moving, the moving state should keep m times. That means if ΔL
                        
                           K
                         is larger than B
                        
                           th
                        , this result should hold m (k
                        =m) times. The moving state of an image block should keep m
                        ×
                        n frames.

The flow of the motion detection is shown in Fig. 7
                        . First, the image is divided into blocks. The size of the image blocks and the parameters m, n and B
                        
                           th
                         should be appropriate value according to the resolution of the display panel and meet the requirement of the motion detection. Then, the brightness differences between frames i and i
                        +
                        n are calculated and the motion state for each image block is determined.

If the brightness difference ΔL
                        
                           K
                         of an image block is larger than B
                        
                           th
                        , the image block is determined as moving. Otherwise, the current motion state of each block depends on the previous detection result. If the previous motion state of an image block is considered as moving and ΔL
                        
                           K
                         is smaller than B
                        
                           th
                         over m times, the image block is considered as static image block. Otherwise, it is a moving image block and k is added by 1. If previous motion state of an image block is static, the current state is static too. For moving image blocks, DFC improvement will be made in the next step.

Two-stage dither combined with MPS is applied to improve gray scale loss caused by inverse gamma conversion and limited gray scale method.
                           
                              (1)
                              Ordered dither combined with MPS.

Gray scale loss is more serious in low gray scale range after inverse gamma conversion. Since human vision system is more sensitive to the contrast in low gray scale range than in middle-high gray scale range, it is very important to reach uniform brightness distribution by dither method. According to what is discussed in the previous section, the uniform gray scale expression can be obtained by ordered dither and the gathered bright or dark areas shown in Fig. 4 will not be aroused. Therefore, the gray scales should be improved by ordered dither method after inverse gamma conversion.

The dither mask should be selected according to the motion states of an image block. For static image blocks, the dither masks shown in Fig. 8
                                  are selected sequentially in continuous 4 frames as one period. As for moving image blocks, any dither matrix should be selected randomly in Fig. 8 as dither mask in a frame. So it will achieve the uniform brightness distribution and effectively reduce the regular pattern noise caused by ordered dither method.

Because the minor pixels caused by dither can be perceived easily, it is important to select minor pixels and process them. After inverse gamma conversion, input gray level is divided into integer value and decimal fraction value. Supposing the gray scale after inverse gamma conversion is T
                                 =
                                 z
                                 +
                                 x, where z is the integer value and x is the fraction value of T. In order to simplify the process of fraction value, x becomes M after normalization to 255. For example, input gray level 250 becomes 244.13 (T) after inverse gamma conversion with gamma 2.2. The integer value (z) is 244 and the fraction value (x) 0.13 will become (M) 33. Supposing that N and N
                                 +1 are selected as displayed gray levels. In dither method, if M is bigger than dither mask value, T will be realized by N
                                 +1. Otherwise, T will be realized by N.

Supposing that M is less than 128, which means T is closer to N and N should be the displayed gray level theoretically. However, in dither process, if M is bigger than dither mask value, N
                                 +1 will be selected to realize T. In this case, the realized gray level is much higher than it is supposed to be. These kinds of pixels are defined as bright minor pixels. In another hand, if M is bigger than 128 and less than dither mask value, which means T should be realized by N
                                 +1, but in fact, in dither method, N is selected to realize T. So the realized gray level is much lower than it is supposed to be. These kind of pixels are defined as dark minor pixels.

To keep the luminance of realized gray scale close to the target gray scale, different ways to process bright and dark minor pixels are proposed. If the minor pixels are detected as bright minor pixels, minor pixel separation (MPS) and fraction doubling process are used. The principle of MPS is to realize the minor pixels over two consecutive frames. Each minor pixel is divided into two channels, namely, R/B channel and G channel. If the pixel is detected as minor pixel, only R/B channel of minor pixel is turned on. Then, G channel is turned on while R/B channel is turned off at the following frame. In this case, the temporal overlaps between minor pixels for a given color channel can be minimized. The exact lighting state for each channel of minor pixels is shown in Fig. 9
                                 . For instance, the lighting state of minor pixels in even row of the display panel is as follows. For even frame, R/B channels are ON while G channels are OFF for minor pixels in even column and G channels are ON while R/B channels are OFF for minor pixels in odd column. In the following frame (odd frame), G channels are ON while R/B channels are OFF for even column minor pixels and R/B channels are ON while G channels are OFF for odd column minor pixels. Therefore, the minor pixels are represented by two consecutive frames as shown in Fig. 9. The lighting state of minor pixels in odd row is processed same as it in even row.

Since only part of minor pixel is lighted in each frame, the luminance of minor pixel will be cut in half and the whole image luminance will decrease. In order to compensate for the luminance variation caused by MPS, fraction doubling process is applied. If fraction value (M) is less than 128, it will be doubled. Otherwise, 255 is subtracted after M is doubled. Supposing M is 51, which is smaller than 128, it becomes 102 after fraction doubling process. Since corresponding decimal fraction value (x) of 51 and 102 are 0.2 and 0.4, respectively, which means 20% and 40% minor pixels are represented in each frame, the luminance variation caused by MPS will be compensated by doubling the number of minor pixels with fraction doubling process.

If the minor pixels are dark minor pixels, the luminance would be darker than it supposed to be. Therefore, only fraction doubling process is applied to increase the luminance by doubling the number of dark minor pixels. Supposing M is 153, which is greater than 128, M becomes 51 (=153×2−255) after fraction doubling process. So the minor pixels are 40% before fraction doubling process, but 80% after fraction doubling process. Therefore, the number of minor pixels in each frame is also doubled and the luminance variation is overcome.

Random dither combined with MPS

After DFC improvement by using limited gray scales, gray scales are richer in low gray scale range than in middle-high gray scale range. For example, gray scale differences between two adjacent displayed gray scales can reach 30 in the middle-high gray scale range, but it is less than 10 in the low gray scale range in GRAY. Random dither method has richer gray scale representation and regular pattern noise will not be brought. Therefore, random dither is used to improve gray scale loss after limited gray scale method.

Supposing the enhanced gray scale after ordered dither combined with MPS is g. The relative error between g and the real displayed gray scale instead of g is Err(g) which can be obtained by (3).
                           
                              (3)
                              
                                 Err
                                 (
                                 g
                                 )
                                 =
                                 
                                    
                                       g
                                       -
                                       
                                          
                                             g
                                          
                                          
                                             n
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   g
                                                
                                                
                                                   n
                                                
                                             
                                          
                                          
                                             +
                                             1
                                          
                                       
                                       -
                                       
                                          
                                             g
                                          
                                          
                                             n
                                          
                                       
                                    
                                 
                                 ,
                                 
                                 (
                                 n
                                 =
                                 0
                                 ,
                                 1
                                 ,
                                 …
                                 ,
                                 m
                                 -
                                 1
                                 )
                              
                           
                        where g
                        
                           n
                         and g
                        
                           n+1 are two adjacent display gray scales in GRAY, and 
                           
                              
                                 
                                    g
                                 
                                 
                                    n
                                 
                              
                              ⩽
                              g
                              <
                              
                                 
                                    g
                                 
                                 
                                    n
                                    +
                                    1
                                 
                              
                           
                        , m is the total number of gray scales contained in GRAY and n is gray scale index. For example, if g is 24, from GRAY, we can get index n is 9, g
                        
                           n
                         and g
                        
                           n+1 are 23 and 26, respectively. The relative error Err(g) is 0.3333 calculated by (3).

Parameter g is divided into integer value g
                        
                           n
                         and fraction value Err(g). If fraction value is less than the dither mask value, dither result is 0, and g
                        
                           n
                         is selected to be displayed gray scale. Otherwise, dither result is 1 and g
                        
                           n+1 is selected. Here, dither mask is constituted by random numbers. Since minor pixels are brought by random dither method, MPS and fraction doubling process are also applied whose processes are the same as described in Section 1) of 3.2. In order to simplify the process, Err(g) is normalized to 255.

We implement the proposed method in 60 inches PDP with resolution 1920×1080. The experimental results of real-time motion detection and gray scale enhancement are described in Sections 4.1 and 4.2, respectively. Section 4.3 is the displaying effect processed by the proposed method.

The motion detection parameters are determined by the experiments with 13 images with resolution 1920×1080. Ten of the images (No. 1 to 10) are the whole image movement and the rest (No. 11 to 13) are only part of the image movement. The image is divided into Nb blocks. If the image cannot be divided into blocks of the same size because its resolution is not divisible by a selected integer, the fringe region can be ignored because DFC that occurs in fringe region is hardly perceived. In the experiment, Nb is 384 blocks by size 60×90 pixels. If an image block is detected as moving, red image will be displayed instead of the original image. Since the motion state of image block is known in advance, the motion detection accuracy r can be computed by using (4), where Ny is the number of image blocks in which the result of motion detection is not correct. If we set the threshold of accuracy, the parameters B
                        
                           th
                         (the brightness difference threshold), m (the threshold count for the number of consecutive movements), and n (the frame interval) can be determined by comparing the detection accuracy and threshold accuracy in the motion detection.
                           
                              (4)
                              
                                 r
                                 =
                                 (
                                 Nb
                                 -
                                 Ny
                                 )
                                 /
                                 Nb
                              
                           
                        
                     

In the experiment, the threshold of accuracy is set 90%. A serial values of B
                        
                           th
                         which is decreased from 1000 is used to detect the accuracy of the motion detection. In the very beginning, when B
                        
                           th
                         is very big, since some images have large areas with uniform gray scales, the intensity difference of image block is small and the detection accuracy is very small, which is less than 50%. After reducing the value of B
                        
                           th
                        , the accuracy of detection is increased dramatically. When B
                        
                           th
                         is around 150, the accuracy can get to 90%. Then, we continue decreasing the value of B
                        
                           th
                         and the detection accuracy still increases gradually. When B
                        
                           th
                         is less than 100, the detection accuracy is decreased. Even when the whole image stops moving, still some red image blocks can be detected in the motion detection, which is caused by error detection. Therefore, B
                        
                           th
                         is set as 100 in the following experiments.

Then, several sets of m and n
                        are selected to determine the proper value of m and n. Since motion blur is more serious than DFC stripes if the velocity of images is too big, the velocities of images in the experiment are 1–4 pixels/frame (p/f). The average motion detection results are shown in Table 1
                        . From Table 1, it can be seen that no matter how small n or m is (e.g. m
                        =1 or n
                        =1), if there are large regions with an uniform intensity in an image and the velocity is low, the moving image block is easily detected as an static image block because intensity difference of an image block between two frames is smaller than threshold B
                        
                           th
                        . We also obtain from the experimental results that if only m or n is large, error detection will occur frequently in some images. Besides, as the result of m
                        ×
                        n increases, the accuracy of motion detection increases obviously. However, it does not mean that m and n are the bigger the better. When both m and n are larger, the change of motion detection result will come later than its real instance and it will affect image processing result.

According to the experimental results and discussion above, when B
                        
                           th
                         is 100, m and n are both 3 to 6, and the product of m
                        ×
                        n is 15 to 30, the motion detection accuracy is much more satisfactory for the DFC improvement.

Another 17 images (No. 14 to 30) are selected to verify the parameters determined above. The image velocity is 1pixel/frame; the parameters of B
                        
                           th
                        , n and m are 100, 4, and 4, respectively. The experiment results of motion detection are listed in Table 2
                        . We find that the average accuracy of motion detection is higher than 99.3% and the lowest accuracy can reach 96.4%. It meets the requirement of motion detection to improve DFC.

The display effect of input gray scales 0 to 22 processed by random dither, ordered dither, and ordered dither combined with MPS are shown in Fig. 10
                        . The spatial brightness distribution of ordered dither is more uniform than random dither in Fig. 10 (b). The minor pixels are not easily perceived when MPS is applied as shown in Fig. 10 (c). Besides, gathered bright or dark areas are not brought when ordered dither combined with MPS is used. Therefore, ordered dither combined with MPS is more satisfactory for gray scale enhancement after inverse gamma conversion.

The results of input gray scales among 67 and 90 processed by different dither methods are shown in Fig. 11
                        (a)–(c). From Fig. 11 (a) and (b), it can be seen that more gray scales can be expressed with random dither compared ordered dither. Also no regular pattern noise can be observed with random dither. However, minor pixels are easily perceived. From Fig. 11(c), it can be seen the image processed by the random dither combined with MPS has a smooth gray scale representation and the affection caused by minor pixels is decreased.

The displaying performance used the proposed method is shown in Fig. 12
                        . Fig. 12(a) is the original image composed of gray scales from 0 to 255 and color images. The moving regions detected by the real-time motion detection method are shown in Fig. 12(b), as well as DFC stripe occurred in the moving regions when the image moves from right to left. Since the division of image blocks does not precisely match the size of color images, the detected moving regions with red dotted rectangle is a little greater than real moving area. From Fig. 12(b), it can be seen that the moving region and static region can be properly distinguished.


                        Fig. 12(c) is enlarged version of partial moving region (A) and partial static region (B) marked with blue rectangle in Fig. 12(b). When full gray scales (256 gray scales) are selected to realize the image, DFC stripe is very serious in moving regions, but the image rendering in static regions is very great as shown in Fig. 12(c). In order to reduce DFC affection to image displaying performance, the limited gray scales (GRAY) are applied, and random or ordered dither method is used in whole image to enhance gray scales in conventional method. Although DFC is decreased, the image rendering in static region is also decreased shown in Fig. 12(d). The image displaying performance processed by the proposed method is shown in Fig. 12(e). From Fig. 12(e), we can see that according to the real-time motion detection result, the limited gray scales (GRAY) are only applied in moving regions, full gray scales are applied in static regions. Therefore, high quality static image rendering is kept when DFC improvement is well achieved. Besides, the gray scale displaying quality enhanced by two-stage dither combined with MPS is much more smooth compared between Fig. 12(d) and (e) in moving region A.

@&#CONCLUSION@&#

From the proposed method, an image is divided into image blocks, and the motion state of each image block can be obtained accurately by real-time motion detection based on brightness differences between image frames. The accuracy of the real-time motion detection can reach 99.3%. It meets the requirement for DFC improvement and can be implemented easily in PDPs. Besides, the gray scale loss after inverse gamma conversion and limited gray scale method is improved obviously by using two-stage dither combined with MPS. The dither noises including pattern noise caused by ordered dither and gathered bright or dark areas caused by random dither are eliminated. Besides, minor pixels cannot be perceived. The image has a smooth gray scale expression both in moving and static regions processed by the proposed method.

@&#REFERENCES@&#


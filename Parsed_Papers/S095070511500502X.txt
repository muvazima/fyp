@&#MAIN-TITLE@&#Multiple learning particle swarm optimization with space transformation perturbation and its application in ethylene cracking furnace optimization

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new variant of PSO, abbreviated as MLPSO-STP, is proposed.


                        
                        
                           
                           A novel learning strategy is used to enhance the global search ability.


                        
                        
                           
                           Space transformation perturbation is used to obtain better solutions.


                        
                        
                           
                           MLPSO-STP outperforms its peers in terms of searching accuracy and reliability.


                        
                        
                           
                           MLPSO-STP is used to optimize the operating conditions of ethylene cracking furnace.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Particle swarm optimization

Learning strategy

Space transformation

Ethylene cracking furnace

@&#ABSTRACT@&#


               
               
                  This paper proposes a new variant of particle swarm optimization (PSO), namely, multiple learning PSO with space transformation perturbation (MLPSO-STP), to improve the performance of PSO. The proposed MLPSO-STP uses a novel learning strategy and STP. The novel learning strategy allows each particle to learn from the average information on the personal historical best position (pbest) of all particles and from the information on multiple best positions that are randomly chosen from the top 100p% of pbest. This learning strategy enables the preservation of swarm diversity to prevent premature convergence. Meanwhile, STP increases the chance to find optimal solutions. The performance of MLPSO-STP is comprehensively evaluated in 21 unimodal and multimodal benchmark functions with or without rotation. Compared with eight popular PSO variants and seven state-of-the-art metaheuristic search algorithms, MLPSO-STP performs more competitively on the majority of the benchmark functions. Finally, MLPSO-STP shows satisfactory performance in optimizing the operating conditions of an ethylene cracking furnace to improve the yields of ethylene and propylene.
               
            

@&#INTRODUCTION@&#

Research on optimization has been highly active in various engineering and science problems, such as in structural design, scheduling, and economic dispatch. As the complexity of the problems increases, traditional optimization algorithms may no longer satisfy problem requirements and consequently entail new effective algorithms. Over the last decades, various meta-heuristic algorithms have been developed as feasible and effective methods for optimization problems. Based on the number of solutions generated in each iteration, meta-heuristic algorithms can be divided into two main categories: individual-based and population-based [1]. For individual-based algorithms, such as Tabu Search (TS) [2] and Simulated Annealing (SA) [3], they start and perform the search process by single solution, thus less computational cost is needed but suffer from premature convergence. In contrary, population-based algorithms can efficiently discourage premature convergence since multiple solutions are involved during the search process. However, the computational cost of population-based algorithms is higher than algorithms with single solution. Many of population-based algorithms, such as Genetic Algorithms (GA) [4], Ant Colony Optimization (ACO) [5], Particle Swarm Optimization (PSO) [6], Artificial Bee Colony (ABC) [7], Gravitational Search Algorithm (GSA) [8], Teaching-Learning-Based Optimization (TLBO) [9–11], and Fruit Fly Optimization (FFO) [12,13], have been successfully implemented in practical problems.

The abovementioned algorithms can solve many challenging real-world problems. However, according to “No Free Lunch” theorem [14], as no single meta-heuristic algorithm is yet able to achieve optimal results for all optimization problems, researchers are currently investing significant efforts to further improve existing algorithms or develop new algorithms inspired by natural phenomena. Some of the recently developed algorithms include Grey Wolf Optimizer (GWO) [15], Ant Lion Optimizer (ALO) [16], Multi Verse Optimizer (MVO) [17], Black Hole (BH) [18], Dragonfly Algorithm (DA) [19], Social Spider Algorithm (SSA) [20], Search Group Algorithm (SGA) [21], Ions Motion Optimization Algorithm (IMO) [22], Charged System Search (CSS) [23], and Moth-Flame Optimization (MFO) [1].

PSO marks one of the most popular classes of nature-inspired optimizers and has its root in artificial life and social psychology. PSO does not require any information on the gradient of the function to be optimized. It uses only primitive mathematical operators and is conceptually simple. As such, PSO has rapidly progressed in recent years and has been successfully applied in diverse areas of science and engineering, such as in artificial neural networks [24–26], power systems [27–29], electricity markets [30,31], and other fields [32–36]. Similar to other population-based optimization techniques, PSO algorithms are subjected to performance evaluation in terms of two critical criteria, namely, convergence speed and global search ability. Each particle in PSO updates its velocity and position by learning from the personal historical best position (pbest) of the particle and the best position (gbest) found by the entire swarm so far. Restricting the social learning aspect to only gbest causes the original PSO to converge rapidly. However, in multimodal problems, the current gbest located at a local optimum may trap the entire swarm and cause premature convergence. The performance of PSO is highly related to particle diversity, especially when attempting to avoid premature convergence and to escape from the local optimum. The performance of PSO has been improved using several PSO variants, including those that resulted from different modifications. These enhancements include tuning the control parameters to balance the local and global search abilities, designing different topologies to replace the traditional global topology, and hybridizing PSO with other search techniques. However, these variants usually preserve swarm diversity at the cost of slow convergence speed or complicated algorithmic structures. Thus, synthetically improving the performance of PSO remains a challenging task in PSO research.

The current paper proposes a new PSO algorithm, namely, multiple learning PSO with space transformation perturbation (MLPSO-STP). This new PSO variant employs a novel learning strategy and STP to increase the global search accuracy and convergence speed of the algorithm. In specific, each particle in the new learning strategy learns from the average information on pbest of all particles and from the information on multiple best positions that are randomly chosen from the top 100p% of pbest. This learning strategy improves swarm diversity and prevents premature convergence. Moreover, STP increases the chance to find optimal solutions. The performance of MLPSO-STP on 21 well-known benchmark functions with various characteristic features is compared with those of eight PSO variants and seven state-of-the-art meta-heuristic search (MS) algorithms. The proposed algorithm performs better than the other tested algorithms in the majority of the test problems.

The monomer ethylene is highly important in the petrochemical industry [37]. Ethylene cracking furnaces are essential process units in ethylene plants; among the equipment used in an ethylene plant, these units have the largest production capacity and the highest energy consumption. Therefore, improving the operating conditions of ethylene cracking furnaces benefits the industry. Aside from ethylene, propylene is also produced using an ethylene cracking furnace. The yields of ethylene and propylene are typical indices of the success of a country's petrochemical industry [38]. Hence, optimizing the operating conditions of a cracking furnace to maximize the yields of ethylene and propylene is highly important to the petrochemical industry. MLPSO-STP exhibits a satisfactory performance on this industrial application.

The article is subsequently organized as follows. Section 2 presents several PSO-related studies. Section 3 briefly introduces the standard PSO algorithm. Section 4 describes our proposed approach. Section 5 provides the experimental settings and results. Section 6 presents the industrial application of the proposed algorithm. Finally, Section 7 concludes this work.

@&#RELATED WORKS@&#

Since the introduction of PSO in 1995 by Kennedy and Eberhart [6], the algorithm has become a popular optimizer and attracted many researchers who have worked on improving its performance in various ways. A brief overview of these variants is presented as follows.

The first area of research concentrates on PSO parameter adaptation strategy. A linearly decreasing inertia weight w with a generation number was proposed in [39], whereas a fuzzy adaptive w method was proposed in [40]. The concept of varying coefficients was also extended to dynamically update the acceleration parameters in [41]. Clerc and Kennedy [42] proposed the inclusion of a constriction factor in PSO. According to their analysis, adding a constriction factor guarantees convergence and improves the convergence speed. Recently, an adaptive PSO (APSO) has been presented in [43]. The APSO provides four evolutionary states and then uses one equation to adjust the inertia weight, acceleration coefficients, and other algorithmic parameters. Tang et al. [44] proposed a feedback learning PSO with quadratic inertia weight (FLPSO-QIW) by introducing a fitness feedback mechanism to control the parameters. The acceleration coefficients were determined by both generation time and search environment. Mirjalili et al. [45] developed an autonomous group PSO (AGPSO) by utilizing different functions to update the acceleration coefficients and confer particles different behaviors. Hu et al. [46] proposed a parameter control mechanism to adaptively change the parameters and consequently enhance the robustness of PSO with multiple adaptive methods. Xu [47] developed a new strategy wherein the inertia weight is dynamically adjusted according to the average absolute value of velocity. In general, tuning parameters can improve the performance of PSO, but this strategy is largely ad hoc [48].

Another promising line of research aims to increase PSO performance by using different population topologies and learning strategies. Kennedy [49] analyzed the effects of neighborhood topology on PSO and proposed four neighborhood topologies. Suganthan [50] applied a dynamically adjusted neighborhood in which the neighborhood size of a particle gradually increases until it covers all particles. Parsopoulos and Vrahatis [51] combined the global and local versions of PSO and proposed a unified particle swarm optimizer (UPSO). Mendes and Kennedy [52] introduced a fully informed PSO (FIPS), in which the velocity update is not only influenced by the best position in the neighborhood of the particle but also by positions in other neighborhoods. Peram et al. [53] presented a fitness-distance-ratio-based PSO (FDR-PSO) with near-neighbor interaction. Liang et al. [54] introduced a comprehensive learning PSO (CLPSO) for multimodal problems. CLPSO abandons the global best information and updates the velocity of a particle on the basis of the historical best information of other particles in different dimensions. Nasir et al. [55] presented a dynamic neighborhood learning particle swarm optimizer (DNLPSO) that uses the learning strategy of CLPSO but selects the exemplar particle from a dynamic neighborhood. Chen et al. [48] transplanted the aging mechanism to PSO and proposed a PSO with an aging leader and challengers (ALC-PSO), in which the aging mechanism provides opportunities for other particles to lead the swarm and thus provide diversity. Cheng et al. [56] introduced social learning mechanisms into PSO to develop a social learning PSO (SL-PSO). Wang et al. [57] developed MLPSO by increasing the two layers of swarms to multiple layers. Lim and Isa [58] proposed a new variant of PSO with increasing topology connectivity (PSO-ITC). These improvements provide reasonable performance enhancements at the expense of increased complexity.

Hybridization by combining PSO with other search strategies to enhance performance has gained increasing attention. Evolutionary operators such as selection [59], crossover [60], and mutation [61,62] have been introduced to PSO to increase population diversity. Cooperative approach [4] and repulsion techniques [63] have also been hybridized with PSO to enhance the performance of the algorithm. Liu et al. [64] have recently proposed a novel algorithm (i.e., PSO-DE) that integrates PSO with differential evolution (DE) to solve constrained numerical and engineering optimization problems. Mirjalili and Hashim [65] combined PSO and GSA (i.e., PSOGSA) and then developed the binary version of PSOGSA named BPSOGSA [66] on the basis of their research on transfer function [67]. Wang et al. [68] developed DNSPSO by employing a diversity-enhancing mechanism and neighborhood search strategies to achieve a trade-off between exploration and exploitation abilities. Han and Liu [69] proposed a diversity-guided hybrid PSO based on gradient search. Ding et al. [70] established a new PSO variant on the basis of local stochastic search and enhancing diversity strategy. Liu et al. [71] embedded the disruption strategy into bare-bone PSO (BPSO) to improve the exploration and exploitation abilities of BPSO. Lim and Isa [72] modified the current existing TLBO algorithm framework and then adopted it into PSO to develop a teaching and peer-learning PSO (TPLPSO). Beheshti and Shamsuddin [73] combined PSO with Newton's laws of motion and proposed the centripetal accelerated PSO (CAPSO) to accelerate the convergence of optimization problems. Mahmoodabadi et al. [74] introduced a high-exploration PSO (HEPSO) by employing the multi-crossover mechanism of GA and the bee colony mechanism. Overall, integrating PSO with other techniques effectively improves performance; however, the hybrid algorithms are difficult to implement and are usually more computationally expensive than the original PSO.

In PSO, a swarm of particles is represented as potential solutions. While searching in a D-dimensional hyperspace, each particle i holds a velocity vector 
                        
                           
                              V
                              i
                           
                           =
                           
                              [
                              
                                 v
                                 i
                                 1
                              
                              ,
                              
                                 v
                                 i
                                 2
                              
                              ,
                              …
                              ,
                              
                                 v
                                 i
                                 D
                              
                              ]
                           
                        
                      and a position vector 
                        
                           
                              X
                              i
                           
                           =
                           
                              [
                              
                                 x
                                 i
                                 1
                              
                              ,
                              
                                 x
                                 i
                                 2
                              
                              ,
                              …
                              ,
                              
                                 x
                                 i
                                 D
                              
                              ]
                           
                        
                      to indicate its current state. Moreover, particle i maintains its own historical best position vector 
                        
                           p
                           b
                           e
                           s
                           
                              t
                              i
                           
                           =
                           
                              [
                              p
                              b
                              e
                              s
                              
                                 t
                                 i
                                 1
                              
                              ,
                              p
                              b
                              e
                              s
                              
                                 t
                                 i
                                 2
                              
                              ,
                              …
                              ,
                              p
                              b
                              e
                              s
                              
                                 t
                                 i
                                 D
                              
                              ]
                           
                        
                     . To this point, the global best position found by all particles is 
                        
                           g
                           b
                           e
                           s
                           t
                           =
                           [
                           g
                           b
                           e
                           s
                           
                              t
                              1
                           
                           ,
                           g
                           b
                           e
                           s
                           
                              t
                              2
                           
                           ,
                           …
                           ,
                           g
                           b
                           e
                           s
                           
                              t
                              D
                           
                           ]
                        
                     . The velocity and position of particle i on dimension d are updated by using Eqs. (1) and (2) as follows:

                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             v
                                             i
                                             d
                                          
                                          
                                             (
                                             t
                                             +
                                             1
                                             )
                                          
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          w
                                          ·
                                          
                                             v
                                             i
                                             d
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                          +
                                          
                                             c
                                             1
                                          
                                          ·
                                          r
                                          a
                                          n
                                          
                                             d
                                             1
                                             d
                                          
                                          ·
                                          
                                             (
                                             p
                                             b
                                             e
                                             s
                                             
                                                t
                                                i
                                                d
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                             −
                                             
                                                x
                                                i
                                                d
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                    
                                       
                                          +
                                          
                                          
                                             c
                                             2
                                          
                                          ·
                                          r
                                          a
                                          n
                                          
                                             d
                                             2
                                             d
                                          
                                          ·
                                          
                                             (
                                             g
                                             b
                                             e
                                             s
                                             
                                                t
                                                d
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                             −
                                             
                                                x
                                                i
                                                d
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              
                                 
                                    x
                                    i
                                    d
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                    
                                    =
                                    
                                    
                                 
                                 
                                    x
                                    i
                                    d
                                 
                                 
                                    (
                                    t
                                    )
                                    +
                                 
                                 
                                    v
                                    i
                                    d
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                           
                        
                     where w is the inertia weight, which is used to balance the global and local search abilities of particles; c
                     1 and c
                     2 are the acceleration parameters reflecting the weights of the stochastic acceleration terms that pull each particle toward the pbest and gbest positions, respectively; 
                        
                           r
                           a
                           n
                           
                              d
                              1
                              d
                           
                        
                      and 
                        
                           r
                           a
                           n
                           
                              d
                              2
                              d
                           
                        
                      are uniformly distributed random numbers independently generated within (0,1); and t = 1, 2,... indicates the iteration number. The velocity of a particle on each dimension is restricted to a maximum magnitude V
                     max to control the flying velocity within a reasonable range. If 
                        
                           
                              |
                           
                           
                              v
                              i
                              d
                           
                           
                              |
                           
                        
                      exceeds 
                        
                           v
                           
                              max
                           
                           d
                        
                     , then it is set to 
                        
                           
                              s
                              i
                              g
                              n
                              (
                              |
                           
                           
                              v
                              i
                              d
                           
                           
                              |
                              )
                           
                           
                              v
                              
                                 max
                              
                              d
                           
                        
                     .

This paper proposes a new PSO variant called MLPSO-STP, which employs a novel learning strategy and STP to improve the performance of PSO.

In the original PSO, each particle learns from its pbest and gbest simultaneously in the evolutionary search. However, in the cognitive learning aspect, each particle only learns from its pbest. In this case, the potential information of the pbest of all other particles is not efficiently used. As a result, the global search ability of PSO is weak. Moreover, learning from a single gbest in the social learning aspect enhances the convergence speed of the original PSO. However, all particles learn from the same gbest despite being far from the global optimum or situated within a local optimum. Hence, particles may easily be attracted to the gbest region and lead to premature convergence because of the reduced population diversity.

To tackle the abovementioned issues, we develop a novel learning strategy by using the velocity updating Eq. (3) as follows:

                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                v
                                                i
                                                d
                                             
                                             
                                                (
                                                t
                                                +
                                                1
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             w
                                             ·
                                             
                                                v
                                                i
                                                d
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                             +
                                             
                                                c
                                                1
                                             
                                             ·
                                             r
                                             a
                                             n
                                             
                                                d
                                                1
                                                d
                                             
                                             ·
                                             
                                                (
                                                m
                                                e
                                                a
                                                
                                                   n
                                                   i
                                                   d
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                −
                                                
                                                   x
                                                   i
                                                   d
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                             
                                                c
                                                2
                                             
                                             ·
                                             r
                                             a
                                             n
                                             
                                                d
                                                2
                                                d
                                             
                                             ·
                                             
                                                (
                                                p
                                                b
                                                e
                                                s
                                                
                                                   t
                                                   p
                                                   d
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                −
                                                
                                                   x
                                                   i
                                                   d
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              m
                              e
                              a
                              
                                 n
                                 i
                              
                              =
                              
                                 [
                                 m
                                 e
                                 a
                                 
                                    n
                                    i
                                    1
                                 
                                 ,
                                 m
                                 e
                                 a
                                 
                                    n
                                    i
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 m
                                 e
                                 a
                                 
                                    n
                                    i
                                    D
                                 
                                 ]
                              
                              =
                              
                                 1
                                 NP
                              
                              
                                 ∑
                                 
                                    g
                                    =
                                    1
                                 
                                 NP
                              
                              
                                 p
                                 b
                                 e
                                 s
                                 
                                    t
                                    g
                                 
                              
                           
                        , which represents the current mean pbest of all particles. NP refers to the population size. pbest records the historical best position of each particle; hence, its average position contains the global promising information of the entire population. Updating the velocity of particle i by considering the mean position of all particles’ pbest maximizes the global promising information and improves the global search ability. 
                           
                              p
                              b
                              e
                              s
                              
                                 t
                                 p
                              
                              =
                              
                                 [
                                 p
                                 b
                                 e
                                 s
                                 
                                    t
                                    p
                                    1
                                 
                                 ,
                                 p
                                 b
                                 e
                                 s
                                 
                                    t
                                    p
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 p
                                 b
                                 e
                                 s
                                 
                                    t
                                    p
                                    D
                                 
                                 ]
                              
                           
                         is randomly chosen as one of the top 100p% of pbest, and p ∈ (0, 1)determines the greediness of the novel learning strategy. pbestp
                         represents the multiple best positions, which include the current global best solution gbest. For each dimension of particle i, any of the top 100p% of pbest can be randomly chosen to play the role of the current global best solution in the novel learning strategy. Therefore, each dimension of the particle can learn from the corresponding dimension of different current global best solutions, thereby enhancing population diversity and preventing premature convergence.

The search process of PSO, similar to many evolutionary optimization methods, begins with initial solutions in an initial population and subsequently improves these solutions until optimal solutions are reached. In some cases, the search process easily stagnates when the population falls into the local optimum. Under premature convergence to a local-optimum circumstance, the current search space hardly contains the global optimum. Hence, achieving optimal solutions for the current population is difficult. In this subsection, a perturbation mechanism based on space transformation [75] is introduced to refine the solutions by translating the current search space to a new search space.

Let x be a solution in the current search space S, x ∈ [a, b]. The new solution x
                           * in the transformed space S* is defined by Eq. (4) as follows:
                           
                              
                                 (4)
                                 
                                    
                                       
                                          x
                                          *
                                       
                                       =
                                       k
                                       
                                          (
                                          a
                                          +
                                          b
                                          )
                                       
                                       −
                                       x
                                    
                                 
                              
                           where k ∈ [0, 1] is a real number and 
                              
                                 
                                    x
                                    *
                                 
                                 ∈
                                 
                                    [
                                    k
                                    
                                       (
                                       a
                                       +
                                       b
                                       )
                                    
                                    −
                                    b
                                    ,
                                    k
                                    
                                       (
                                       a
                                       +
                                       b
                                       )
                                    
                                    −
                                    a
                                    ]
                                 
                              
                           . The diameter of the current search space and the transformed search space maintain the same value of b−a. The difference between the current search space and the transformed space is the center of the search space. In fact, the center of the current space is moved from 
                              
                                 
                                    a
                                    +
                                    b
                                 
                                 2
                              
                            to 
                              
                                 
                                    2
                                    k
                                    (
                                    a
                                    +
                                    b
                                    )
                                    −
                                    a
                                    −
                                    b
                                 
                                 2
                              
                            after the transformation. According to [75], a random value of k obtains favorable performance. Then, the center of the transformed search space is set at a random position in 
                              
                                 (
                                 −
                                 
                                    
                                       a
                                       +
                                       b
                                    
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                       +
                                       b
                                    
                                    2
                                 
                                 )
                              
                           . To explain clearly, we assume that b > a > 0. As a result, the following expressions are easily deduced: 
                              
                                 −
                                 b
                                 ≤
                                 k
                                 (
                                 a
                                 +
                                 b
                                 )
                                 −
                                 b
                                 ≤
                                 a
                              
                            and 
                              
                                 −
                                 a
                                 ≤
                                 k
                                 (
                                 a
                                 +
                                 b
                                 )
                                 −
                                 a
                                 ≤
                                 b
                              
                           . Hence, the search range of x
                           * satisfies 
                              
                                 −
                                 b
                                 ≤
                                 x
                                 *
                                 ≤
                                 b
                              
                           . This solution implies that the transformed space S* holds a larger search range than the current search space S, while both spaces exhibit the same size of search range (b−a).

In this study, we employ the above-mentioned STP to achieve better solutions. For each particle's position Xi
                           (t), a new position 
                              
                                 
                                    X
                                    i
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                            is generated by the novel velocity-updating Eq. (3) and position-updating Eq. (2). One dimension of 
                              
                                 
                                    X
                                    i
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                            is randomly selected and denoted as the jth dimension. The perturbed vector 
                              
                                 
                                    x
                                    i
                                    
                                       *
                                       j
                                    
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                            for the jth dimension of 
                              
                                 
                                    X
                                    i
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                            is generated using Eq. (5) and replaces the corresponding vector 
                              
                                 
                                    x
                                    i
                                    j
                                 
                                 
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                           . Eq. (5) is expressed as follows:

                              
                                 (5)
                                 
                                    
                                       
                                          x
                                          i
                                          
                                             *
                                             j
                                          
                                       
                                       
                                          (
                                          t
                                          +
                                          1
                                          )
                                       
                                       =
                                       r
                                       a
                                       n
                                       d
                                       ·
                                       
                                          (
                                          MI
                                          
                                             
                                                N
                                             
                                             j
                                          
                                          +
                                          MA
                                          
                                             
                                                X
                                             
                                             j
                                          
                                          )
                                       
                                       −
                                       
                                          x
                                          i
                                          j
                                       
                                       
                                          (
                                          t
                                          +
                                          1
                                          )
                                       
                                    
                                 
                              
                           where rand is a random number within (0, 1), and MIN
                              j
                            and MAX
                              j
                            are the minimum and maximum values of the jth dimension in the current population, respectively. Being limited within the interval static boundaries of the variables, the particles jump outside of the already shrunken search space. In this regard, the knowledge of the current reduced search space is lost. Hence, we calculate the transformed value by using the current interval of the variables in the population ([MIN, MAX]). STP expands the current search space and thus increases the chance to find optimal solutions. This strategy provides additional opportunities to escape the local optimum and find optimal solutions; its effectiveness is significant when solving complex problems with multiple local optimal solutions.

The proposed MLPSO-STP algorithm employs a novel learning strategy and STP to improve the performance of PSO. The novel learning strategy aims to enhance the global search ability and swarm diversity, whereas STP increases the chance to find better solutions and enhances the exploitation ability. The main steps of MLPSO-STP are presented in Algorithm 1, where NP is the population size, D is the problem dimension, FE is the number of function evaluations, and MAX_FE is the maximum number of function evaluations.

The performance of the proposed algorithm is tested on 21 benchmark functions [44,72,76]. These test functions, which are shown in Table 1
                        , can be classified into three groups according to their properties. F1–F6 are unimodal functions with a single optimum; hence, they are suitable for benchmarking the exploitation ability of algorithms. F7–F11 are complex multimodal functions whose local optima number exponentially increases with increasing problem dimension. Thus, the exploration ability of algorithms can be tested through these multimodal functions. Finally, F12–F21 are rotated functions developed by multiplying the original x variable with an orthogonal matrix M 
                        [77] to produce a rotated variable 
                           
                              y
                              =
                              
                                 M
                                 *
                              
                              x
                           
                        . Any changes that occur in x will influence all dimensions in y, and the rotated problems will then become nonseparable. These rotated functions are complex and can be used to test the exploitation and exploration abilities of algorithms simultaneously. Table 1 briefly describes the benchmark formulae, their search ranges, global optimal values, and acceptable values (ε). If a solution found by an algorithm is no greater than the acceptable value ε, the run is deemed successful. All of the functions are tested on D = 30 dimensions.

Eight well-established PSO variants are used for thorough comparison with MLPSO-STP. The parameter configurations for all involved algorithms are based on the suggestions in the corresponding literature and summarized in Table 2.
                        
                     

To ensure a fair comparison among all of the PSO variants, they are tested using the same population size (NP) of 40. Moreover, all of the algorithms use the same maximum number of function evaluation (MAX_FE) 2 × 105 in each run for each test function. To minimize statistical errors, each algorithm is tested 30 times independently for every function.

As explained earlier, any of the top 100p% in the pbest solutions can be randomly chosen as the current global best solution in the novel learning strategy. Hence, the new parameter p is introduced in this paper. The value of p determines the greediness of the novel learning strategy and may affect the performance of MLPSO-STP. To select an appropriate p value, we investigate the performance of MLPSO-STP under variant p values. In this section, p is selected from the set (0.025, 0.05, 0.1, 0.15, 0.2, 0.25), which results in a corresponding p × NP ∈ (1, 2, 4, 6, 8, 10), where NP = 40. Notably, p × NP = 1 (p = 0.025) means that only the gbest in the current swarm is used in the social learning aspect, similar to that in the original PSO. All other parameters of MLPSO-STP are set according to the values in Table 2. Table 3
                         illustrates the search accuracy (mean value) exhibited by MLPSO-STP with different p values. The best result is indicated by boldface in the table.


                        Table 3 shows that the search accuracy of MLPSO-STP deteriorates when p is set exceedingly high (i.e., p = 0.1, 0.15, 0.2, 0.25) or exceedingly low (i.e., p = 0.025). As mentioned earlier, a smaller p is exceedingly greedy in maintaining population diversity, which leads to a poor solution obtained by MLPSO-STP. Conversely, population diversity can be overemphasized when p is set exceedingly high. In this extreme scenario, the MLPSO-STP population is oversupplied with diversity, but this oversupply potentially slows down the convergence speed of MLPSO-STP toward the problem's global optimum. Considering the experimental results and aforementioned analysis, we note that MLPSO-STP solves the tested functions with the best search accuracy at a p value of 0.05. Hence, this parameter value of p at 0.05 is used in the following performance evaluation.

In this study, we assess the performance of the PSO in terms of accuracy, reliability, and efficiency through the mean fitness value (Fmean), success rate (SR), mean function evaluation (MFE) required to achieve the predefined acceptable value ε among the successful runs and the mean computational time (Tmean). To determine whether or not the results obtained by MLPSO-STP are statistically different from the results generated by the other algorithms, we perform the nonparametric Wilcoxon rank sum test at a 0.05 level of significance on the results of MLPSO-STP and the eight other PSO variants. We also include the convergence graphs of the selected functions in Fig. 1
                         to qualitatively compare the Fmean and convergence speed of all the algorithms tested.

The Fmean, standard deviation (Std), and Wilcoxon test (h) of all the tested algorithms in 30 independent runs are listed in Table 4. The best results from these algorithms are indicated by boldface in the table. We summarize the Fmean and h comparison results between MLPSO-STP and the other algorithms as “+/=/−” in the last row of Table 4. These data denoted by “+/=/−” indicate the number of functions that MLPSO-STP performs significantly better than, almost the same as, or significantly worse than the tested algorithms, respectively, on the Fmean in the 30 runs. We first rank the algorithms from the lowest Fmean to the highest for each function. Then, we obtain the average and overall ranks by averaging the ranks over the number of functions.


                           Table 4 and Fig. 1 show that the performance of MLPSO-STP surpasses those of all the other algorithms in the majority of the problems. MLPSO-STP achieves the best performance on F1–F3, F5–F7, F11–F16, F19, and F21, which correspond to 14 best performances out of the 21 functions employed.

                              
                                 (1)
                                 
                                    Unimodal functions: For the six unimodal functions F1–F6, Table 4 shows that MLPSO-STP can achieve the best performance on five functions F1–F3, F5, and F6. The Wilcoxon test values (h) in Table 4 also indicate that this superiority is statistically significant. In addition, the plots in Fig. 1 (a)–(c) show the convergence progress in F1–F3; MLPSO-STP apparently has a faster convergence speed than the other algorithms. In F4, none of the involved algorithms reach the global optimum, which is located in a long narrow parabolic-shaped flat valley. This valley is easy to find but difficult to converge to the global optimum. Nevertheless, in the same function, MLPSO-STP outperforms FLPSO-QIW in terms of Fmean, and its standard deviation is relatively small. This superior performance on unimodal functions demonstrates that the proposed MLPSO-STP algorithm has a high exploitation ability, which is due to the STP mechanism that increases the chance to find the better solutions and thus accelerates the convergence speed.


                                    Multimodal functions: F7–F11 are the multimodal functions with many local optima. Table 4 and Fig. 1 (d) and (f) reflect the favorable performance of MLPSO-STP in most of the problems. In specific, only MLPSO-STP can successfully find the global optimum in F7 and F11, and this superiority is statistically significant. In F8–F10, the proposed algorithm satisfactorily avoids the local optima because the algorithm can approximate the global optima in such functions. Considering the characteristics of the multimodal functions and the abovementioned results, we conclude that MLPSO-STP exhibits a satisfactory exploration ability. This attribute is mainly due to the novel learning strategy that enhances the global searching ability and confers MLPSO-STP additional opportunities to search in the global area.


                                    Rotated functions: In F12–F21, the majority of the tested algorithms experience performance degradation, as shown by the worse Fmean values obtained in the rotated problems than in the unrotated counterparts. The rotating operation imposed on the traditional functions increases the complexity of the functions, thereby rendering the rotated problems highly challenging. However, Table 4 and Fig. 1 (g)–(k) reveal that MLPSO-STP performs relatively robustly with regard to the rotated functions. In particular, MLPSO-STP significantly outperforms the other algorithms in F12–F16. Its performance is ranked second in both F17 and F18 and fifth in F20. Moreover, F19 and F21 impose greater challenges to all of the selected algorithms; none of the algorithms are able to solve such problems completely. Nevertheless, the proposed MLPSO-STP obtains the best Fmean values in F19 and F21. This promising performance on rotated functions shows that MLPSO-STP holds an appropriate balance between exploitation and exploration.

In summary, analysis results and overall ranks in Table 4 show that MLPSO-STP provides high exploration and exploitation abilities. The proposed novel learning strategy enhances the exploration ability of MLPSO-STP, assists MLPSO-STP in implementing global search, and consequently prevents premature convergence. Furthermore, STP promotes the exploitation ability, increases the chance to find the better solutions, and consequently accelerates the convergence speed.

The Wilcoxon rank sum test is performed to statistically determine the degree of difference in performance between MLPSO-STP and each of the eight other algorithms for each function, and the statistical results are shown in the last row of Table 4. The number of functions where MLPSO-STP performs significantly better than its contenders (h = “+”) is much larger than that where the former performs significantly worse than the latter (h = “−”). In particular, MLPSO-STP significantly outperforms all of the eight other algorithms in F1–F3, F6, F7, F11–F14, F16, F19, and F21.

To compare the convergence speed and reliability of the algorithms, Table 5 lists the SR and MFE necessary to reach the predefined acceptable accuracy among the successful runs for each algorithm. “−”, which represents no runs reach an acceptable accuracy. The results show that MLPSO-STP has a higher convergence speed than most of the other algorithms. Although MLPSO-STP sometimes performs slower than UPSO, the former has a superior search accuracy and success rate over the latter. Fig. 1 and Table 5 clearly show that MLPSO-STP can achieve the accepted value with a satisfactory convergence speed and search accuracy in most of the functions. Moreover, MLPSO-STP exhibits the most remarkable search reliability among all of the tested algorithms, as indicated by the SR. In particular, MLPSO-STP completely solves (SR = 100%) all of the unimodal functions at the predefined accuracy. The search reliability of MLPSO-STP in the multimodal functions is impressive because it completely solves four out of the five multimodal functions evaluated. The excellent reliability performance of MLPSO-STP can also be observed on the rotated functions; that is, it can completely solve nine out of the ten rotated functions. The average SR and the corresponding rank in descending order are shown in the last row of Table 5. The data indicate that MLPSO-STP exhibits the highest SR at 99.2%, followed by PSO-cf-local, CLPSO, UPSO, FDR, FLPSO-QIW, APSO, FIPS, and PSO-W.
                           
                        

To investigate the computational efficiency of MLPSO-STP, we record the mean computational time (Tmean) of all the selected algorithms in the 21 benchmark functions until MAX_FE = 2 × 105. The Tmean values for all of the algorithms over the 30 runs are obtained on a PC Intel Core 5 Duo 2.39 GHz with a 4 GB RAM that runs on Windows 7 with Matlab implementation. The results are summarized in Fig. 2.
                           
                        

As shown in Fig. 2, FDR-PSO consumes a longer computational time compared with the other algorithms. By contrast, the computational overheads of PSO-cf-local, FIPS, and MLPSO-STP are the lowest in the majority of the functions. Moreover, FIPS and MLPSO-STP both achieve the eight best Tmean values, whereas PSO-cf-local records the four best values out of the 21 employed benchmarks. In most of the benchmarks, the differences among the Tmean values produced by PSO-cf-local, FIPS, and MLPSO-STP are relatively insignificant. This result implies that our proposed algorithm does not incur excessive computational overhead. The fairly satisfactory performance of MLPSO-STP in terms of computational time confirms that the proposed algorithm is highly efficient.

The proposed MLPSO-STP employs two strategies, namely, the novel learning strategy and STP. To investigate the effects of these two strategies, we studied the performance of (1) the MLPSO-STP uses the original instead of the novel learning strategy (MLPSO-STP1), (2) the MLPSO-STP without STP (MLPSO-STP2), and (3) the complete MLPSO-STP. The Fmean values of the 30 independent runs and the comparisons between each of the MLPSO-STP variants and PSO-W are shown in Table 6.
                        
                     

All of the MLPSO-STP variants show better performance than PSO-W. This finding implies that employing any of the strategies enhances the search accuracy of the algorithm. The comparison of MLPSO-STP1 with PSO-W shows that the former performs better than the latter in most of the functions, indicating the effectiveness of STP. However, the performance of MLPSO-STP1 is worse than that of PSO-W in F8. This result suggests that the absence of the novel learning strategy could lead to the poor search accuracy of MLPSO-STP in the mentioned function. Furthermore, MLPSO-STP2 outperforms PSO-W in the majority of the functions, which demonstrates the effectiveness of the novel learning strategy. However, MLPSO-STP2 cannot locate the global optimum in F5, F11, and F15. This observation suggests that the absence of STP (MLPSO-STP2) traps the algorithm in the local optimum as compared with the other MLPSO-STP variants.


                        Table 6 clearly shows that the integration of both the novel learning strategy and STP in MLPSO-STP significantly enhances the performance of the algorithm. MLPSO-STP obtains the best results in four out of the six unimodal functions. MLPSO-STP exhibits the best performance in multimodal and rotated functions F17–F21. Meanwhile, from the overall rank, MLPSO-STP shows the best performance among the compared variants, followed by MLPSO-STP1, MLPSO-STP2, and PSO-W.

In summary, employing a single strategy is insufficient to achieve the desired results, but integrating the two strategies results in excellent performance. This superior performance of MLPSO-STP again verifies its appropriate balance between exploitation and exploration indeed benefit from the proposed strategy in this study.

We compare MLPSO-STP with fast evolutionary strategy (FES) [79], fast evolutionary programming (FEP) [80], covariance matrix adaptation evolution strategy (CMAES) [81], generalized generation gap model with generic parent-centric recombination operator (G3PCX) [82], group search optimizer (GSO) [83], real-coded biogeography-based optimization (RCBBO) [84], and real-coded chemical reaction optimization (RCCRO) [85]. Their parameter values are selected according to the recommendations of their respective authors [79–85]. The MAX_FE and NP of all involved algorithms in the nine functions are summarized in Tables 7
                         and 8
                        , respectively. MLPSO-STP is evaluated with the least MAX_FE in each function, whereas the results for the other selected algorithms are obtained with more MAX_FE, as their data are acquired from the corresponding literature.

We run MLPSO-STP 30 times for each function. The resulting Fmean and Std values are summarized in Table 9
                        . The results of the other MS algorithms were extracted from literature [79–85]. MLPSO-STP exhibits the lowest MAX_FE, but it produces the best search accuracy for successfully solving six out of nine functions (Table 9). Although the CMAES obtains the best solutions in the Rosenbrock and Griewank functions, and RCCRO achieves the best solution in Rastrigin, our MLPSO-STP outperforms these algorithms in the remaining functions. Overall, MLPSO-STP is superior to the other algorithms on the basis of the overall ranks provided in the last row of Table 9.
                     

The cracking process in an ethylene cracking furnace is shown in Fig. 3. The feedstock is first fed into the convection section for preheating and then mixed with the hot dilution steam. In the convection section, the mixture of the feedstock and dilution steam is gasified to the target temperature for cracking. The vaporized mixture subsequently enters the radiant section. The cracking reaction mainly occurs in the radiant section at a high temperature. After the reaction in the radiant section, the cracking products flow out to the downstream equipment for separation. However, the ethylene cracking process, which is multimodal and strongly nonlinear, is difficult to model. Therefore, building the relationship between the operating conditions and the product yield, as well as optimizing the operating conditions to maximize the product yield, is important.

The yields of ethylene and propylene are important indices in evaluating the efficiency of an ethylene cracking furnace. Several factors that affect their yields include feedstock properties, coil output temperature (COT), feedstock flow rate (FLOW), steam hydrocarbon ratio (SHR), and coil output pressure (COP). However, in the actual process occurring in an ethylene cracking furnace plant, COP is usually measured at high temperatures, which complicate the determination of an accurate value. Therefore, COP is calculated according to the pressure of the suction inlet of a cracker gas compressor. In addition, FLOW is assigned by factory scheduling and cannot be altered by the optimization. Feedstock properties are also not tunable. Therefore, COT and SHR are considered as the optimizing variables in our study.
                        
                        
                     

In the practical setting, the volume yields of some gaseous phases in the cracking gas can be measured by an online chromatographic analyzer. However, representing the mass yield of all the components of the cracked gas is impossible to achieve. Accordingly, a yield model based on ColiSim1D [86] is built. CoilSim1D is a cracking reaction software based on the free-radical reaction. The error between CoilSim1D and cracking furnace output can be corrected by the mass ratio of propylene over ethylene, which should be similar between the simulated and measured values. After correction, the mass yields of the whole components can be obtained from the software. The input variables of the model comprise the feedstock properties, including the mole percentages of n-alkanes, iso-alkane, cycloalkane, and aromatics, COT, FLOW, COP, and SHR. The output variables comprise the yields of ethylene and propylene. Accordingly, the optimization of this problem can be defined through Eq. (6) as follows:

                           
                              (6)
                              
                                 
                                    
                                       
                                       
                                       
                                          
                                             max
                                             F
                                             =
                                             
                                                Y
                                                
                                                   C
                                                   2
                                                   H
                                                   4
                                                
                                             
                                             +
                                             
                                                Y
                                                
                                                   C
                                                   3
                                                   H
                                                   6
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             
                                             s
                                             .
                                             t
                                             .
                                             
                                                {
                                                
                                                   
                                                      
                                                         
                                                            
                                                               830
                                                               ∘
                                                            
                                                            C
                                                            ≤
                                                            COT
                                                            ≤
                                                            
                                                               840
                                                               ∘
                                                            
                                                            C
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            0.5
                                                            ≤
                                                            SHR
                                                            ≤
                                                            0.7
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            FLOW
                                                            =
                                                            40
                                                            
                                                               t
                                                               /
                                                               h
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where Y
                        
                           C2H4 is the yield of ethylene and Y
                        
                           C3H6 is the yield of propylene.

The proposed algorithm is applied to optimize the operating conditions and consequently maximize the yields of ethylene and propylene. The properties of three types of feedstock and the values of the process variables are collected from a petrochemical corporation from October 2009 to March 2011. The population size and maximum number of generation are set to 40 and 200 of MLPSO-STP, respectively. The properties of three types of feedstock and the optimal results are shown in Tables 10 and 11, respectively. Table 11 clearly shows that MLPSO-STP can obtain the optimal operating conditions and significantly increase the yields of ethylene and propylene compared with the usual industrial operating conditions. The increase in yield offers considerable benefit to the petrochemical corporation.

This paper proposes an enhanced PSO algorithm called MLPSO-STP, which employs a novel learning strategy and STP. In the novel learning strategy, we utilize the average information on the pbest of all particles and the information on multiple best positions that are randomly chosen from the top 100p% of pbest to update the velocity of a particle. This strategy aims to enhance the global searching ability and consequently improve the exploration strength of the current population. Meanwhile, STP increases the chance to find optimal solutions and enhances the exploitation ability. Comprehensive experimental tests are conducted to investigate the performance of MLPSO-STP on 21 benchmark functions and assess the contribution of each employed strategy in improving the performance of the algorithm. The experimental and statistical analyses demonstrate that MLPSO-STP significantly outperforms other existing PSO algorithms in most of the test functions because of its appropriate balance between exploitation and exploration. The simulation results also indicate that employing a single strategy cannot achieve the desired results, but integrating the two strategies results in excellent performance. Comparisons with some state-of-the-art MS algorithms further confirm the outstanding performance of MLPSO-STP.

The relationship between the operation conditions and the yields of products in an ethylene cracking furnace is built, and then the proposed algorithm is used to optimize the operating conditions and significantly improve the yields of ethylene and propylene. The results indicate that MLPSO-STP is a competitive optimization tool for solving real-life application problems.

In the future, we will extend the application of MLPSO-STP to handling multi-objective optimization problems. We also intend to assess the performance of recently proposed algorithms, such as GWO, IMO, and ALO, in solving real-life application problems.

@&#ACKNOWLEDGMENTS@&#

This research was supported by National Key Scientific and Technical Project of China under Grant No. 2015BAF22B02, National Natural Science Foundation of China under Grant Nos. 21276078, 61422303, Fundamental Research Funds for the Central Universities, Shanghai Natural Science Foundation under Grant No. 14ZR1421800, and the State Key Laboratory of Synthetical Automation for Process Industries under Grant No. PAL-N201404.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Multi-view clustering via spectral partitioning and local refinement

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new multi-view clustering algorithm is proposed.


                        
                        
                           
                           The proposed MVNC algorithm uses spectral partitioning and local refinement.


                        
                        
                           
                           MVNC is compared to state-of-the-art algorithms using three real-world datasets.


                        
                        
                           
                           MVNC significantly outperforms the other algorithms.


                        
                        
                           
                           MVNC is parameter-free unlike existing multi-view clustering algorithms.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multi-view clustering

Spectral clustering

Local refinement

Normalized cuts

@&#ABSTRACT@&#


               
               
                  Cluster analysis using multiple representations of data is known as multi-view clustering and has attracted much attention in recent years. The major drawback of existing multi-view algorithms is that their clustering performance depends heavily on hyperparameters which are difficult to set.
                  
                     In this paper, we propose the Multi-View Normalized Cuts (MVNC) approach, a two-step algorithm for multi-view clustering. In the first step, an initial partitioning is performed using a spectral technique. In the second step, a local search procedure is used to refine the initial clustering.
                  
                     MVNC has been evaluated and compared to state-of-the-art multi-view clustering approaches using three real-world datasets. Experimental results have shown that MVNC significantly outperforms existing algorithms in terms of clustering quality and computational efficiency. In addition to its superior performance, MVNC is parameter-free which makes it easy to use.
               
            

@&#INTRODUCTION@&#

In many real-world applications, datasets are characterized by multiple sets of features. Web pages and scientific papers are typical examples of such datasets where documents can be represented using not only their textual content but also other modalities such link information. Cluster analysis using multiple representations (or views) of data is known as multi-view clustering and has attracted much attention in recent years (see, e.g., Cai, Nie, & Huang, 2013; Chaudhuri, Kakade, Livescu, & Sridharan, 2009; Greene & Cunningham, 2009; Liu, Wang, Gao, & Han, 2013; Zhao, Evans, & Dugelay, 2014; Zhuang, Karypis, Ning, He, & Shi, 2012). Multi-view clustering seeks to take advantage of the complementarity of views to achieve better clustering performance than when relying on a single view. Bickel and Scheffer (2004), for example, show that exploiting both the textual content of web pages and the anchor text of inbound links improves clustering quality over the use of a single modality; Chikhi, Rothenburger, and Aussenac-Gilles (2008) show that combining text and citation information improves document clustering.

To cluster multi-view data using single-view clustering techniques (such as K-means), one has first to combine the available sets of features in an ad-hoc way to form a single view. This can be achieved either by concatenating the sets of features into a single set, or by building a similarity matrix from each view and then computing the overall affinity matrix by averaging the different similarity matrices. In practice, though, these simple combination techniques have been shown to give poor results in comparison to more elaborate techniques such as the convex K-means algorithm described in (Modha & Spangler, 2003). Convex K-means is a generalized version of the classical K-means algorithm which combines views, in a convex fashion, during the assignment step. In the same vein, Zhou and Burges (2007) proposed a multi-view extension of the spectral clustering algorithm of Meila and Shi (2000), where views are combined using a mixture of Markov chains. In (Kumar, Rai, & Daume, 2011), a co-regularized approach to multi-view clustering is presented. Co-regularization consists in introducing constraints in the clustering process to ensure that the clusterings on different views agree with each other. In (Liu et al., 2013), the authors proposed an adaptation of the non-negative matrix factorization technique to work with multiple sets of features. Their algorithm uses a joint factorization process to find a consensus clustering across the views. More recently, Xia, Pan, Du, and Yin (2014) proposed a multi-view spectral algorithm based on Markov chains and noise handling. The basic idea of their algorithm is to combine the transition probability matrices constructed from each view into a shared transition probability matrix via low-rank and sparse decomposition.

The major drawback of existing multi-view clustering algorithms is that they have hyperparameters which are difficult to set and which affect significantly the clustering performance. For instance, the convex K-means algorithm (Modha & Spangler, 2003) and the mixture model of Zhou and Burges (2007) use a weighting parameter to balance the importance of each view. The approach of (Kumar et al., 2011) has a co-regularization parameter which trades-off a spectral (dis)agreement term and a spectral clustering objective during the optimization process. There is also a regularization parameter in the multi-view non-negative matrix factorization (Liu et al., 2013) and the robust multi-views spectral clustering (Xia et al., 2014) algorithms.

In this paper, we propose the Multi-View Normalized Cuts (MVNC) approach, a parameter free multi-view spectral clustering algorithm. MVNC is described in Section 2. Section 3 describes the experimental environment, while Section 4 reports and discusses the experimental results. Section 5 concludes the paper and gives an outlook to future work.

In this section, we present MVNC, a new multi-view clustering algorithm which works in two phases. In the first phase, an initial partitioning is performed using a spectral technique. In the second phase, a local search procedure is used to refine the initial clustering.

Given a set of N data points 
                           
                              X
                              =
                              {
                              
                                 x
                                 1
                              
                              ,
                              
                                 x
                                 2
                              
                              ,
                              …
                              ,
                              
                                 x
                                 N
                              
                              }
                              ,
                           
                         the single-view normalized cut algorithm proposed by Ng, Jordan, and Weiss (2001) partitions X into K clusters by solving the following minimization problem:

                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             
                                                min
                                                
                                                   U
                                                   ∈
                                                   
                                                      R
                                                      
                                                         N
                                                         ×
                                                         K
                                                      
                                                   
                                                
                                             
                                             t
                                             r
                                             
                                                (
                                                
                                                   U
                                                   T
                                                
                                                L
                                                U
                                                )
                                             
                                             ,
                                             
                                             s
                                             .
                                             t
                                             .
                                             
                                             
                                                U
                                                T
                                             
                                             U
                                             =
                                             I
                                          
                                       
                                    
                                 
                              
                           
                        where tr is the matrix trace and L is the normalized Laplacian. Cluster memberships are then obtained by clustering the rows of matrix U using the K-means algorithm.

When the dataset X is represented using V different sets of features (i.e. views), the co-regularized multi-view spectral clustering algorithm of Kumar et al. (2011) divides X into K clusters by solving the following joint optimization problem:

                           
                              (2)
                              
                                 
                                    
                                       min
                                       
                                          
                                             U
                                             
                                                (
                                                1
                                                )
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             U
                                             
                                                (
                                                V
                                                )
                                             
                                          
                                          ∈
                                          
                                             R
                                             
                                                N
                                                ×
                                                K
                                             
                                          
                                       
                                    
                                    
                                    
                                       ∑
                                       
                                          v
                                          =
                                          1
                                       
                                       V
                                    
                                    
                                       t
                                       r
                                       (
                                       
                                          U
                                          
                                             
                                                (
                                                v
                                                )
                                             
                                             T
                                          
                                       
                                       
                                          L
                                          
                                             (
                                             v
                                             )
                                          
                                       
                                       
                                          U
                                          
                                             (
                                             v
                                             )
                                          
                                       
                                       )
                                    
                                    +
                                    λ
                                    
                                       ∑
                                       
                                          
                                             
                                                
                                                   
                                                      1
                                                      ≤
                                                      i
                                                      ,
                                                      j
                                                      ≤
                                                      V
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      i
                                                      ≠
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                    D
                                    
                                       (
                                       
                                          U
                                          
                                             (
                                             i
                                             )
                                          
                                       
                                       ,
                                       
                                          U
                                          
                                             (
                                             j
                                             )
                                          
                                       
                                       )
                                    
                                    
                                    s
                                    .
                                    t
                                    .
                                    
                                    
                                       U
                                       
                                          
                                             (
                                             v
                                             )
                                          
                                          T
                                       
                                    
                                    
                                       U
                                       
                                          (
                                          v
                                          )
                                       
                                    
                                    =
                                    I
                                    ,
                                    ∀
                                    
                                    1
                                    ≤
                                    v
                                    ≤
                                    V
                                 
                              
                           
                        where L
                        (v) is the normalized Laplacian constructed from view v, D(U
                        (i), U
                        (j)) is a measure of disagreement between the clusterings of views i and j, and λ is a hyperparameter to be set by the user.

If we constrain the clusterings of all views to be identical, i.e. 
                           
                              
                                 U
                                 
                                    (
                                    1
                                    )
                                 
                              
                              =
                              
                                 U
                                 
                                    (
                                    2
                                    )
                                 
                              
                              =
                              …
                              =
                              
                                 U
                                 
                                    (
                                    V
                                    )
                                 
                              
                              ,
                           
                         then Eq. (2) reduces to the following minimization problem:

                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                min
                                                
                                                   U
                                                   ∈
                                                   
                                                      R
                                                      
                                                         N
                                                         ×
                                                         K
                                                      
                                                   
                                                
                                             
                                             
                                             
                                                ∑
                                                
                                                   v
                                                   =
                                                   1
                                                
                                                V
                                             
                                             
                                                t
                                                r
                                                (
                                                
                                                   U
                                                   T
                                                
                                                
                                                   L
                                                   
                                                      (
                                                      v
                                                      )
                                                   
                                                
                                                U
                                                )
                                             
                                             ,
                                             
                                             s
                                             .
                                             t
                                             .
                                             
                                             
                                                U
                                                T
                                             
                                             U
                                             =
                                             I
                                          
                                       
                                    
                                 
                              
                           
                        or, equivalently, to

                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                min
                                                
                                                   U
                                                   ∈
                                                   
                                                      R
                                                      
                                                         N
                                                         ×
                                                         K
                                                      
                                                   
                                                
                                             
                                             
                                             t
                                             r
                                             
                                                (
                                                
                                                   U
                                                   T
                                                
                                                
                                                   (
                                                   
                                                      ∑
                                                      
                                                         v
                                                         =
                                                         1
                                                      
                                                      V
                                                   
                                                   
                                                      L
                                                      
                                                         (
                                                         v
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                U
                                                )
                                             
                                             ,
                                             
                                             s
                                             .
                                             t
                                             .
                                             
                                             
                                                U
                                                T
                                             
                                             U
                                             =
                                             I
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The motivation behind the imposed constraint on U
                        (v), 1 ≤ v ≤ V is twofold. First, it allows us to get rid of the co-regularization parameter λ, since the disagreement term in Eq. (2) vanishes. Second, the optimization problem is simplified, as it involves a single matrix, in contrast to the original co-regularization framework which involves V matrices.


                        Eq. (4) is similar to the single-view spectral clustering problem of Eq. (1), where the Laplacian is formed by the sum of the normalized Laplacians constructed from each view. This suggests that the algorithm of (Ng et al., 2001) can be easily extended to multi-view data. Based on this idea, we propose a new multi-view spectral clustering algorithm. The proposed algorithm, summarized in Algorithm 1
                        , is used in the first phase of MVNC.

Spectral clustering is a discrete optimization problem which is known to be NP-hard. Existing spectral clustering algorithms find an approximate solution by adopting the following approach: First, the original intractable (discrete) problem is relaxed into a tractable (continuous) optimization problem; the relaxed problem is then solved, and the resulting continuous solution is discretized using some clustering heuristic (Yu & Shi, 2003).

Discretization techniques used by spectral clustering algorithms, including the K-means algorithm used by MVNC in the first phase, do not guarantee that the obtained clustering corresponds to the optimal solution of the original discrete problem. Therefore, in the second phase of MVNC, we propose to use a greedy algorithm to improve the clustering obtained from the first phase.

The proposed refinement strategy is similar in spirit to the Kernighan–Lin heuristic (Kernighan & Lin, 1970). It consists in parsing the list of data points in a random order, and then moving each data point to its best cluster, that is, the one which decreases the objective function of Algorithm 1 the most. This procedure is repeated until no further improvement of the objective function can be achieved.

The objective function minimized by Algorithm 1 is given by:

                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             f
                                             
                                                (
                                                C
                                                )
                                             
                                             =
                                             
                                                ∑
                                                
                                                   v
                                                   =
                                                   1
                                                
                                                V
                                             
                                             
                                                (
                                                K
                                                −
                                                
                                                   ∑
                                                   
                                                      k
                                                      =
                                                      1
                                                   
                                                   K
                                                
                                                
                                                   
                                                      
                                                         g
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                      v
                                                      o
                                                      
                                                         l
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         )
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        with 
                           
                              
                                 g
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    C
                                    k
                                 
                                 )
                              
                              =
                              
                                 ∑
                                 
                                    
                                       
                                          
                                             i
                                             :
                                             
                                                x
                                                i
                                             
                                             ∈
                                             
                                                C
                                                k
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             j
                                             :
                                             
                                                x
                                                j
                                             
                                             ∈
                                             
                                                C
                                                k
                                             
                                          
                                       
                                    
                                 
                              
                              
                                 S
                                 
                                    i
                                    j
                                 
                                 
                                    (
                                    v
                                    )
                                 
                              
                              ,
                           
                        
                        
                           
                              v
                              o
                              
                                 l
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    C
                                    k
                                 
                                 )
                              
                              =
                              
                                 ∑
                                 
                                    
                                       
                                          
                                             i
                                             :
                                             
                                                x
                                                i
                                             
                                             ∈
                                             
                                                C
                                                k
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             j
                                             =
                                             1
                                             →
                                             N
                                          
                                       
                                    
                                 
                              
                              
                                 S
                                 
                                    i
                                    j
                                 
                                 
                                    (
                                    v
                                    )
                                 
                              
                              ,
                           
                         
                        S
                        (v) the similarity matrix constructed from view v, N the number of data points, V the number of views, and 
                           
                              C
                              =
                              
                                 ⋃
                                 
                                    k
                                    =
                                    1
                                 
                                 K
                              
                              
                                 C
                                 k
                              
                           
                         a set of K clusters.

Note that this objective function corresponds to the sum of the normalized cut values over the V views, and will be referred to as the overall normalized cut.

Moving a data point xi
                         from its current cluster Cj
                         to another cluster Ck
                         changes the overall normalized cut value by

                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             Δ
                                             N
                                             (
                                             
                                                x
                                                i
                                             
                                             ,
                                             
                                                C
                                                k
                                             
                                             )
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             f
                                             (
                                             D
                                             )
                                             −
                                             f
                                             (
                                             C
                                             )
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   v
                                                   =
                                                   1
                                                
                                                V
                                             
                                             
                                                (
                                                
                                                   
                                                      
                                                         g
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            j
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                      v
                                                      o
                                                      
                                                         l
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            j
                                                         
                                                         )
                                                      
                                                   
                                                
                                                +
                                                
                                                   
                                                      
                                                         g
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                      v
                                                      o
                                                      
                                                         l
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         )
                                                      
                                                   
                                                
                                                −
                                                
                                                   
                                                      
                                                         g
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            j
                                                         
                                                         −
                                                         
                                                            {
                                                            
                                                               x
                                                               i
                                                            
                                                            }
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                      v
                                                      o
                                                      
                                                         l
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            j
                                                         
                                                         −
                                                         
                                                            {
                                                            
                                                               x
                                                               i
                                                            
                                                            }
                                                         
                                                         )
                                                      
                                                   
                                                
                                                −
                                                
                                                   
                                                      
                                                         g
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         ∪
                                                         
                                                            {
                                                            
                                                               x
                                                               i
                                                            
                                                            }
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                      v
                                                      o
                                                      
                                                         l
                                                         
                                                            (
                                                            v
                                                            )
                                                         
                                                      
                                                      
                                                         (
                                                         
                                                            C
                                                            k
                                                         
                                                         ∪
                                                         
                                                            {
                                                            
                                                               x
                                                               i
                                                            
                                                            }
                                                         
                                                         )
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              C
                              =
                              
                                 ⋃
                                 
                                    k
                                    =
                                    1
                                 
                                 K
                              
                              
                                 C
                                 k
                              
                           
                         is the current clustering and D is the clustering obtained by moving xi
                         from Cj
                         to Ck
                        .


                        Algorithm 2
                         summarizes the main steps of the local refinement technique used by MVNC.

                           Theorem 1
                           
                              Algorithm 
                              
                                 2
                               
                              is guaranteed to converge
                           

Since 
                                 
                                    v
                                    o
                                    
                                       l
                                       
                                          (
                                          v
                                          )
                                       
                                    
                                    
                                       (
                                       
                                          C
                                          k
                                       
                                       )
                                    
                                    =
                                    
                                       g
                                       
                                          (
                                          v
                                          )
                                       
                                    
                                    
                                       (
                                       
                                          C
                                          k
                                       
                                       )
                                    
                                    +
                                    
                                       ∑
                                       
                                          
                                             
                                                
                                                   i
                                                   :
                                                   
                                                      x
                                                      i
                                                   
                                                   ∈
                                                   
                                                      C
                                                      k
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   j
                                                   :
                                                   
                                                      x
                                                      j
                                                   
                                                   ∈
                                                   C
                                                   ∖
                                                   
                                                      C
                                                      k
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       S
                                       
                                          i
                                          j
                                       
                                       
                                          (
                                          v
                                          )
                                       
                                    
                                    ,
                                 
                               we have vol
                              (v)(Ck
                              ) ≥ g
                              (v)(Ck
                              ).

It follows that the objective function f is bounded below by 0.

Since f is monotonically non-increasing over iterations and is bounded below, Algorithm 2 is guaranteed to converge.□

In practice, we consider that Algorithm 2 has converged when the difference of the overall normalized cut values between two consecutive iterations is below a threshold, or when a maximum number of iterations is reached.

In Algorithm 1, steps 1, 4 and 6 are the most time-consuming. Step 1 involves the calculation of V N × N similarity matrices, which costs O(MVN
                        2), where M is the average number of features over the V views. In step 4, K eigenvectors of an N × N symmetric matrix are computed, which costs O(KN
                        2). In step 6, K-means clustering is performed on a K × N matrix, which costs O(IK
                        2
                        N), where I is the number of iterations. The overall time complexity of Algorithm 1 is then 
                           
                              O
                              (
                              
                                 (
                                 M
                                 V
                                 +
                                 K
                                 )
                              
                              
                                 N
                                 2
                              
                              +
                              I
                              
                                 K
                                 2
                              
                              N
                              )
                           
                        .

The bottleneck in Algorithm 2 is the evaluation of the effect of moving data points (step 3). This step can, however, be carried out efficiently by avoiding redundant computations. For instance, 
                           
                              v
                              o
                              
                                 l
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    C
                                    j
                                 
                                 −
                                 
                                    {
                                    
                                       x
                                       i
                                    
                                    }
                                 
                                 )
                              
                           
                         can be easily obtained, since 
                           
                              v
                              o
                              
                                 l
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    C
                                    j
                                 
                                 −
                                 
                                    {
                                    
                                       x
                                       i
                                    
                                    }
                                 
                                 )
                              
                              =
                              v
                              o
                              
                                 l
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    C
                                    j
                                 
                                 )
                              
                              −
                              d
                              e
                              
                                 g
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 )
                              
                              ,
                           
                         where 
                           
                              d
                              e
                              
                                 g
                                 
                                    (
                                    v
                                    )
                                 
                              
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 )
                              
                              =
                              
                                 ∑
                                 
                                    j
                                    =
                                    1
                                 
                                 N
                              
                              
                                 S
                                 
                                    i
                                    j
                                 
                                 
                                    (
                                    v
                                    )
                                 
                              
                           
                        . deg
                        (v) is a N-dimensional vector which can be computed at the beginning of the algorithm. Similarly, vol
                        (v)(Cj
                        ) can be computed at the beginning of the algorithm, and updated if cluster Cj
                         is modified in step 6.

If Algorithm 2 is implemented as suggested, computing the effect of moving a data point from its current cluster to another cluster using Eq. (6) can be performed in linear time with respect to the number of views V since the terms inside the summation can be evaluated in constant time. The cost of step 3 is therefore O(KV), yielding a time complexity of O(JKNV) for Algorithm 2, with J being the number of iterations required for convergence.

To evaluate the performance of MVNC, we conducted experiments using three real-world datasets:

                           
                              •
                              
                                 Digit dataset: it is a set of images where each image corresponds to a handwritten digit (0–9) (Asuncion and Newman 2007). In this dataset, view-1 corresponds to the Fourier coefficients of the character shapes, and view-2 corresponds to the pixel averages in 2 x 3 windows. The similarity between images in each view is computed using a Gaussian kernel, i.e.,

                                    
                                       
                                          
                                             
                                                S
                                                
                                                   i
                                                   j
                                                
                                             
                                             =
                                             exp
                                             
                                                (
                                                −
                                                
                                                   
                                                      
                                                         ∥
                                                      
                                                      
                                                         x
                                                         i
                                                      
                                                      −
                                                      
                                                         x
                                                         j
                                                      
                                                      
                                                         
                                                            ∥
                                                         
                                                         2
                                                      
                                                   
                                                   
                                                      2
                                                      
                                                         σ
                                                         2
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 where 
                                    
                                       
                                          ∥
                                       
                                       
                                          x
                                          i
                                       
                                       −
                                       
                                          x
                                          j
                                       
                                       
                                          ∥
                                       
                                    
                                  is the Euclidean distance between data points xi
                                  and xj
                                  ; σ is the kernel width which, in our experiments, is set to the median distance between data points.


                                 Cora dataset: it is a collection of scientific papers, with view-1 being the textual content of documents and view-2 being citation links between documents (Sen et al., 2008). Each document belongs to one of the following categories: case based reasoning, genetic algorithms, learning theory, neural networks, probabilistic learning methods, reinforcement learning, and rule learning. The similarity between documents in each view is computed using the cosine measure, which is better suited to text and link data than the Gaussian kernel (Dhillon & Modha, 2000). The cosine similarity of two documents xi
                                  and xj
                                  is defined as:

                                    
                                       
                                          
                                             
                                                S
                                                
                                                   i
                                                   j
                                                
                                             
                                             =
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   ·
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                
                                                   
                                                      ∥
                                                   
                                                   
                                                      x
                                                      i
                                                   
                                                   
                                                      ∥
                                                      ∥
                                                   
                                                   
                                                      x
                                                      j
                                                   
                                                   
                                                      ∥
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where ‖xi
                                 ‖ is the Euclidean norm of vector xi
                                 .


                                 3sources dataset: it is a set of news stories collected from 3 popular online news sources (Greene & Cunningham, 2009). Of these stories, 40% were reported in all three sources, 47% in two sources, and 13% appeared in a single news source. Each story is about one of the following topics: business, entertainment, health, politics, sport, and technology. The cosine measure was used to compute the similarity between news articles in each view.

Characteristics of the three datasets are summarized in Table 1
                        .

To show the effectiveness of the proposed approach, we evaluated and compared the following algorithms:

                           
                              •
                              Best Single View (BSV): Running single-view spectral clustering on each view, and then reporting the results of the view that achieves the best performance.

Feature Concatenation (FeatCon): Concatenating the features of all views to form a single representation, and then applying single-view spectral clustering.

Average Similarity (AvgSim): Combining different similarity matrices into a single matrix by taking their average, and then performing single-view spectral clustering.

Mixture of Markov Chains (MixMC): Using a mixture model whose components are Markov chains constructed from each view of the data (Zhou & Burges, 2007).

Convex K-means (ConvKM): It is a multi-view version of the classical K-Means algorithm (Modha & Spangler, 2003).

Co-Regularizerd multi-view spectral clustering (CoReg): Adopting a co-regularization approach to multi-view spectral clustering (Kumar et al., 2011).

Multi-view Nonnegative Matrix Factorization (MultiNMF): This is a multi-view variant of the Nonnegative matrix factorization algorithm (Liu et al., 2013).

Robust Multi-view Spectral Clustering (RMSC): Applying the idea of low-rank and sparse decomposition to multi-view spectral clustering (Xia et al., 2014).

Multi-View Normalized Cuts (MVNC): This is our proposed algorithm.


                                 MVNC-Lite: It is a “lite” version of MVNC in which no local refinement is performed. This algorithm allows us to study the effect of the local improvement step.

In our experiments, all the algorithms were implemented under the Matlab environment. For CoReg, RMSC and MultiNMF, we used the Matlab code available on the websites of A. Kumar
                           1
                        
                        
                           1
                           
                              http://www.umiacs.umd.edu/~abhishek/papers.html.
                        , Y. Pan
                           2
                        
                        
                           2
                           
                              http://ss.sysu.edu.cn/~py/.
                         and J. Liu
                           3
                        
                        
                           3
                           
                              http://jialu.cs.illinois.edu/.
                        , respectively.

Clustering evaluation using a gold standard dataset consists in assessing how well the output of a clustering algorithm matches the gold standard classes. In the literature, many measures have been proposed to quantify this matching. In our experiments, we used three indices: purity (PUR), F-measure (FM) and normalized mutual information (NMI).

The purity of a single cluster is the fraction of member points belonging to the dominant class in that cluster. The purity of a clustering is obtained by computing the weighted average of the cluster-wise purities (Manning, Raghavan, & Schtze, 2008):

                           
                              
                                 
                                    P
                                    u
                                    r
                                    i
                                    t
                                    y
                                    =
                                    
                                       ∑
                                       i
                                    
                                    
                                       
                                          
                                             n
                                             i
                                          
                                          n
                                       
                                       
                                          P
                                          i
                                       
                                    
                                 
                              
                           
                        where n is the total number of data points, ni
                         is the size of cluster i, and Pi
                         is the purity of cluster i.

The F-measure is defined as the harmonic mean between precision and recall (Manning et al., 2008):

                           
                              
                                 
                                    
                                       F
                                    
                                    −
                                    
                                       measure
                                    
                                    =
                                    
                                       
                                          2
                                          ×
                                          
                                          prec
                                          ision
                                          ×
                                          
                                          reca
                                          ll
                                       
                                       
                                          prec
                                          ision
                                          +
                                          reca
                                          ll
                                       
                                    
                                 
                              
                           
                        
                     

The NMI is an information theoretic measure for the mutual dependence of two random variables. In the context of clustering evaluation, the two random variables correspond to the clustering and the gold standard classification. Given a clustering X and a gold standard classification Y, the NMI between X and Y is defined as (Strehl & Ghosh, 2002):

                           
                              
                                 
                                    N
                                    M
                                    I
                                    
                                       (
                                       X
                                       ,
                                       Y
                                       )
                                    
                                    =
                                    
                                       
                                          H
                                          (
                                          X
                                          )
                                          +
                                          H
                                          (
                                          Y
                                          )
                                          −
                                          H
                                          (
                                          X
                                          ,
                                          Y
                                          )
                                       
                                       
                                          
                                             H
                                             (
                                             X
                                             )
                                             ×
                                             H
                                             (
                                             Y
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        where H(X) and H(Y) are the entropy of X and Y, respectively; H(X, Y) is the joint entropy of X and Y.

@&#RESULTS@&#


                        Tables 2
                        
                        –4
                         show the average clustering scores over ten runs of each algorithm. The algorithms having a hyperparameter are run with different hypermarameter values, and the best results are reported.

For the Digit dataset, Table 2 shows that MVNC achieves the best results and outperforms the other algorithms. The performance of MVNC is superior to that of MVNC-Lite, indicating that the local refinement step improves the clustering results. RMSC performs well and is the second best algorithm. The AvgSim algorithm also performs well with this dataset and is surprisingly better than the Co-regularization approach (Co-Reg). Moreover, we observe from the results that combining the Laplacians (MVNC-Lite) yields better results than combining the similarity matrices (AvgSim) or the normalized similarity matrices (MixMC). However, the feature concatenation algorithm (FeatCon) gives poor results, and is only slightly better than the best single view algorithm (BSV).

According to the results with the Cora dataset (Table 3), MVNC is again the best algorithm. It is followed very closely by RMSC, which performs quite well on this dataset. The local search procedure used by MVNC has also proven to be beneficial, though less than with the Digit dataset.


                        Table 4 gives the results for the 3sources dataset using different numbers of views. The results show that MVNC significantly outperforms the baseline algorithms. They also show that using more views improves the clustering accuracy for all compared algorithms. We note the poor performance of RMSC which is outperformed even by the best single view algorithm (BSV). This observation also applies to the non-spectral algorithms (ConvKM and MultiNMF).

While all algorithms performed well on the Digit dataset, some techniques failed to recover the correct clustering on the other datasets. For instance, MultiNMF gave poor results with the Cora dataset. This is due to the sensitivity of the algorithm to data sparsity: MultiNMF is based on a technique equivalent to Probabilistic Latent Semantic Analysis (PLSA) which was previously found to be inadequate for the analysis of very sparse data such as citation data (Chikhi et al., 2008). Spectral algorithms, on the other hand, have proven to be robust to the problem of data sparsity, except for RMSC which performed poorly on the 3sources dataset. But the poor performance of RMSC is due to the violation of the first assumption on which the algorithm is based (i.e., each individual view is sufficient to find most of the cluster structure) since many stories of the 3sources collection are not represented in all views (incomplete views).

In the rest of this section, we focus on the empirical analysis of the performance and behaviour of multi-view spectral clustering algorithms (MixMC, CoReg, RMSC and MVNC) as they have shown to perform better than the other algorithms.

In this experiment, we evaluate the running time of each algorithm on the three datasets. For MVNC we report the “worst-case” running time, which is obtained by running the local refinement procedure until the overall normalized cut can no longer be improved. Table 5
                         shows that RMSC is very slow, owing to the slow convergence rate of the iterative procedure used by the algorithm for the low-rank and sparse decomposition. The table also shows that Co-Reg is faster than RMSC but still slow compared to MVNC. The high execution time of Co-Reg is caused by the multiple eigendecompositions performed by the algorithm, unlike MVNC and MixMC which perform this time-consuming operation only once. These results suggest that MVNC is more scalable than the other algorithms.

Additionally, we have evaluated the performance of MVNC as a function of the sample size. The obtained results are given in Table 6
                        . We see that the local refinement step (Step 2) is efficient as it requires less computational time compared to the spectral partitioning step (Step 1). The results also confirm the theoretical analysis of Section 2.3: the running time of the spectral clustering phase (resp. of the local refinement phase) appears to increase quadratically (resp. linearly) with the sample size, and the execution time of both phases appears to increase linearly with the number of views. We note that the first step with the Digit and the Cora datasets takes almost the same amount of time even though the size of the former dataset (in terms of number of features) is significantly smaller than the size of the latter dataset. This is explained by the high sparsity of the Cora dataset which reduces considerably the amount of time required for the computation of the similarity matrices and for the eigendecomposition of the Laplacian matrix.

To study how the hyperparameters used by MixMC, CoReg and RMSC affect their performance, we run each of these algorithms with various hyperparameter values and plot the obtained NMI scores. Fig. 1 shows that MixMC achieves the best NMI score when the hyperparameter is set to 0.5 for the Digit dataset and 0.1 for the Cora dataset. In the absence of any information regarding the importance of the different views (which is the case in real-world applications), a natural choice is to give the same importance to all views, i.e., setting the hyperparameter of MixMC to the inverse of the number of views (0.5 in our case since there are 2 views in the Digit and the Cora datasets). While this simple heuristic seems to work well for the Digit dataset (Fig. 1a), it gives poor results for the Cora dataset (Fig. 1b). For CoReg and RMSC, tuning the hyperparameter is even more tricky because their hyperparmeter can take any positive value, unlike the hyperparameter of MixMC whose values are in the range [0,1]. In their paper, (Kumar et al., 2011) suggest to set the hyperparameter of CoReg to a value between 0.01 and 0.05. Fig. 2b shows, however, that CoReg performs poorly in that range. Similarly, the authors of RMSC suggest choosing the hyperparameter value from 0.005 to 0.1; but, according to Fig. 3b, the best results for the Cora dataset are obtained when the hyperparameter value is greater than 1.5. In contrast to MixMC, CoReg and RMSC, MVNC does not use any hyperparameter since the algorithm optimizes a sum of terms (Eq. (5)) which are all bounded from below by 0 and from above by the number of clusters K
                        
                        
                        .

In this paper, we have proposed a new multi-view spectral clustering algorithm. The proposed MVNC approach is a two-step algorithm where the first step performs spectral partitioning using the the sum of the normalized Laplacians constructed from each view, while the second step refines the initial clustering using a local improvement technique.

MVNC has been evaluated and compared to state-of-the-art multi-view clustering approaches using three real-world datasets. Experimental results have shown that MVNC significantly outperforms existing algorithms, in terms of clustering quality and computational efficiency. In addition to its superior performance, MVNC has the advantage of being parameter-free, which makes it easy to use.

The first step of MVNC has a quadratic time complexity with respect to the number of data points, making the algorithm unsuitable for very large datasets. This complexity can, however, be significantly reduced if the data are sparse, as it reduces the computational cost of building the similarity matrices and allows the use of efficient sparse eigen solvers such as ARPACK. In the case of dense data, a “sparsificiation” technique can be used as a preprocessing step.

The local refinement procedure used by MVNC is simple, and it would be interesting to investigate more sophisticated strategies, such as considering moves of an entire group of data points instead of individual data points, when looking for the best move.

@&#REFERENCES@&#


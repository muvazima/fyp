@&#MAIN-TITLE@&#Difference of Gaussians revolved along elliptical paths for ultrasound fetal head segmentation

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A new method for the fetal skull segmentation from 2-D ultrasound images.


                        
                        
                           
                           The method is completely automatic and it requires no user interaction.


                        
                        
                           
                           The idea is to construct a template image of the fetal skull parametrized by both the calvarial thickness (the thickness of the skull) and an ellipse modelling the contour of the skull.


                        
                        
                           
                           This method won the fetal ultrasound segmentation challenge in ISBI 2012.


                        
                        
                           
                           The accuracy automatic segmentations are similar to the accuracy of the manual segmentations.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Biparietal diameter

Head circumference

Energy minimization

Fetal biometry

Image analysis

Global optimization

@&#ABSTRACT@&#


               
               
                  We present a fully automatic method to segment the skull from 2-D ultrasound images of the fetal head and to compute the standard biometric measurements derived from the segmented images. The method is based on the minimization of a novel cost function. The cost function is formulated assuming that the fetal skull has an approximately elliptical shape in the image and that pixel values within the skull are on average higher than in surrounding tissues. The main idea is to construct a template image of the fetal skull parametrized by the ellipse parameters and the calvarial thickness. The cost function evaluates the match between the template image and the observed ultrasound image. The optimum solution that minimizes the cost is found by using a global multiscale, multistart Nelder–Mead algorithm. The method was qualitatively and quantitatively evaluated using 90 ultrasound images from a recent segmentation grand challenge. These images have been manually analyzed by three independent experts. The segmentation accuracy of the automatic method was similar to the inter-expert segmentation variability. The automatically derived biometric measurements were as accurate as the manual measurements. Moreover, the segmentation accuracy of the presented method was superior to the accuracy of the other automatic methods that have previously been evaluated using the same data.
               
            

@&#INTRODUCTION@&#

Ultrasound measurements of fetal biometry is a standard method for dating pregnancies and for assessment of fetal growth. Standard biometric measurements include biparietal diameter (BPD), occipito-frontal diameter (OFD), head-circumference (HC), abdominal circumference (AC), crown-rump length (CRL) and femur length (FL). Based on these measurements, the gestational age and size of the fetus can then be estimated using charts or regression formulae [5,15,8]. In particular, biometrics related to the fetal head, i.e., BPD and HC as shown in Fig. 1
                     , are recommended for measuring the gestational age during second or third semester and are used for assessing the fetal size [5,15,13].

Currently, expert users perform these measurements manually. This is not only time consuming but also it results in high intra- and inter-observer variability of these measurements. Thus, automating measurement processes could provide significant benefits to both pregnant women and clinicians [2]. However, designing a fully automatic procedure is a challenging task because of the highly variable image quality that is a typical characteristic of ultrasound images. In addition, various image artefacts and surrounding tissues further complicate the automatic measurement of fetal biometrics. These problems are easy to appreciate in Fig. 2
                     , whose panels (a) and (b) show two low quality but still typical ultrasound images.

Given the importance of the problem, several automatic and semi-automatic methods for computing biometric measurements from ultrasound images have been proposed. These methods have mostly been based on the segmentation of the ultrasound images [22]. Approaches for the fetal skull segmentation have been based on deformable spline [12] and contour models [4,20], supervised learning [2], and ellipse fitting through (randomized) Hough transform [10,17,27]. The deformable contour or spline model [4,20,12] based approaches rely on the user to indicate a point close to the center of head and construct an initial contour model based on this information. This initial contour model is then deformed by minimizing a cost function.

The ellipse fitting approaches first segment pre-processed ultrasound images through clustering or histogram analysis [10,17] or perform edge detection [27], in either case producing a binary image of the fetal skull. The Hough transform [10] or the randomized Hough transform (RHT) [17,27] is then utilized to fit the ellipse model to the binary image. As Hough transform and RHT are very sensitive to image artifacts, these methods require the user to define an initial region of interest (ROI) [27] or their application is limited to images where head contour is complete and is not overlapped by other structures [10].

The supervised learning approach of [2] is different from the methods cited above as it directly exploits expert annotations of the images to produce the segmentations. More specifically, the method of [2] searches for a minimal bounding box containing the head of the fetus in the ultrasound image. The method works by training a three-stage classifier, termed constrained probabilistic boosting tree, based on manually segmented images.

In this paper, we present a new method for the fetal skull segmentation from 2-D ultrasound images. Based on the skull segmentations, it is then straightforward to compute the biometric measurements of BPD, OFD, and HC. The method is completely automatic and it requires no user interaction unlike many methods cited above. This new method is named Difference of Gaussians revolved along Elliptical paths or DoGEll. The idea is to construct a template image of the fetal skull parametrized by both the calvarial thickness (the thickness of the skull) and an ellipse modelling the contour of the skull. This is unlike previous ellipse fitting methods [10,17,27] that try to fit a single ellipse into the image, i.e., these previous methods do not model the skull as an entity having a finite thickness but instead make use of image processing operations that try to reduce its thickness to a single pixel. In constructing the template image, we assume that the image intensity is high within pixels representing the skull (due to a high acoustic impedance of the bone) and lower immediately inside and outside the skull. The template is then matched to the ultrasound image by minimizing a cost function designed to measure the lack of match between our parametric elliptical image model and the observed image. More specifically, for a given ellipse, we construct a surface that models the pixel values of the skull and surrounding areas by revolving a difference of Gaussians (DoG) along the elliptical path and define the cost function as a negative correlation between the observed image and the surface. This cost function is robust to various image imperfections as demonstrated in Fig. 2. To find the optimum parameters defining the ellipse and calvarial thickness, the cost function is globally minimized by a multiscale multistart Nelder–Mead algorithm [19,14] devised specifically for this purpose. Notice that this new method differs from the previous region based methods [12,2] in that instead of trying to maximize the match the image segmentation (consisting of foreground and background regions) as in the previous methods, it matches a template image constructed based on the skull parameters to the observed image. This way it is possible to reduce the sensitivity of the method to the high intensity artifacts in the background region.

This DoGEll method won the first prize of the head sub-challenge in the Challenge US: Biometric Measurements from Fetal Ultrasound Images, held in conjunction with and supported by the IEEE International Symposium on Biomedical Imaging (ISBI) 2012 in Barcelona, Spain [22]. The contributions of the present paper are two-fold. First, we present a detailed account of the winning DoGEll method for the first time. The method has not been published in peer-reviewed literature. A short account of it has been presented in the Challenge proceedings [9] and one paragraph summary was presented in [22]. Second, we present a new, improved implementation of the DoGEll method typically running in under 5 seconds per image, thus yielding a 60 fold savings in computation time as compared to the one winning the segmentation challenge. The difference in the quantitative results between the implementations due to speed ups is minimal and the new, faster implementation would have won the segmentation challenge as well. The main specific differences between the old [9] and new (this paper) method are (i) the new minimization algorithm that uses considerably fewer restarts and embeds an insertion sort strategy to accelerate the Nelder–Mead algorithm, (ii) a cost function (Eq. (3)) that is modified to be better principled mathematically as explained in more detail in Section 2, and (iii) faster image pre-processing.

The evaluation of our method is carried out with the dataset used in the Challenge US: Biometric Measurements from Fetal Ultrasound Images. This consists of 90 2-D fetal ultrasound images of the head, some of which are purposely of very low quality, acquired on fetuses at different gestational ages. The segmentations and biometric parameters derived from the automatic DoGEll method are compared to the manual analysis of three independent experts. The evaluation in this paper is based on the same principles as in the challenge, i.e., the method development and evaluation were completely independent and the method developers (AF, MM, AP and JT) did not have access to the manual segmentations nor to the biometric measurements. The evaluation results show that the DoGEll method can automatically segment the fetal skull from ultrasound images with an accuracy similar to the inter-expert variability of the manual segmentation.

The paper is organized as follows. In Section 2, we describe the cost function that we minimize to obtain the segmentations. In Section 3, we describe the applied image pre-processing, the algorithm for the minimization of the cost function, and the procedure for computation of biometric parameters based on the segmentation results. Section 4 describes the quantitative validation of the method using ISBI 2012 Challenge data, Section 5 presents the results of the validation, and Section 6 concludes the paper by discussing the methodological contributions and experimental results.

In this section, we describe the cost function to segment fetal skulls from ultrasound images. As already mentioned, we assume that the head contour of the fetus can be modeled by an ellipse. The main rationale behind the proposed cost function, as illustrated in Fig. 3
                     , consists of fitting of an image model which comprises of three nested elliptical annuli to the image: the centermost representing the skull of the fetus characterized by high image intensity values (bright pixels); the inner and the outer representing the surrounding areas, usually exhibiting relatively low image intensity values. The image model is constructed based on a single ellipse and a parameter modeling the thickness of the skull. We use a difference of Gaussians, see Fig. 4
                     (a), along each half line leaving from the center of ellipse in modelling the regions.

In more detail, we parametrize each ellipse E(a) with 5 parameters: center coordinates c
                        1, c
                        2, semiaxis lengths r
                        1, r
                        2, and rotation angle in radians θ, organized into the vector
                           
                              
                                 
                                    
                                       a
                                    
                                 
                                 =
                                 [
                                 
                                    c
                                    1
                                 
                                 ,
                                 
                                    c
                                    2
                                 
                                 ,
                                 
                                    r
                                    1
                                 
                                 ,
                                 
                                    r
                                    2
                                 
                                 ,
                                 θ
                                 ]
                                 .
                              
                           
                        Let 
                           
                              h
                              
                                 (
                                 
                                    x
                                    1
                                 
                                 ,
                                 
                                    x
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                    
                                 
                                 )
                              
                           
                         be the radial half-line leaving from the center (c
                        1, c
                        2) and passing through the point (x
                        1, x
                        2). Using 
                           
                              h
                              
                                 (
                                 
                                    x
                                    1
                                 
                                 ,
                                 
                                    x
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                    
                                 
                                 )
                              
                           
                        , we measure the radial distance d(x
                        1, x
                        2, a) between (x
                        1, x
                        2) and the ellipse E(a), as well as the normalized radial distance r
                        0(x
                        1, x
                        2, a) between (x
                        1, x
                        2) and (c
                        1, c
                        2), i.e. the distance between those two points divided by the radius of the ellipse along 
                           
                              h
                              
                                 (
                                 
                                    x
                                    1
                                 
                                 ,
                                 
                                    x
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                    
                                 
                                 )
                              
                           
                        . Then we define a surface
                           
                              (1)
                              
                                 g
                                 (
                                 
                                    x
                                    1
                                 
                                 ,
                                 
                                    x
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                    
                                 
                                 ,
                                 s
                                 )
                                 =
                                 
                                    
                                       
                                          f
                                          s
                                       
                                       (
                                       d
                                       (
                                       
                                          x
                                          1
                                       
                                       ,
                                       
                                          x
                                          2
                                       
                                       ,
                                       
                                          
                                             a
                                          
                                       
                                       )
                                       )
                                       −
                                       
                                          f
                                          
                                             3
                                             s
                                          
                                       
                                       (
                                       d
                                       (
                                       
                                          x
                                          1
                                       
                                       ,
                                       
                                          x
                                          2
                                       
                                       ,
                                       
                                          
                                             a
                                          
                                       
                                       )
                                       )
                                    
                                    
                                       
                                          r
                                          0
                                       
                                       (
                                       
                                          x
                                          1
                                       
                                       ,
                                       
                                          x
                                          2
                                       
                                       ,
                                       
                                          
                                             a
                                          
                                       
                                       )
                                    
                                 
                                 ,
                              
                           
                        where f
                        
                           s
                         and f
                        3s
                         are two univariate Gaussians centered at zero with standard deviations equal to s and 3s, respectively. This is our image model for a given ellipse. An example of the surface g(x
                        1, x
                        2, a, s) is shown in Fig. 4(b) and the rationale for its design is described in Fig. 4(c).

Before introducing the cost function based on the image model, we provide a few facts about the function g, including the choice of the standard-deviation parameters of the DoG, geometric properties of g, and its zero-mean radial property.

In DoGs, the ratio between the standard deviations of the two Gaussian functions mainly controls the rate at which the negative tails approach zero relative to the width of the central positive lobe. A larger ratio gives longer tails, and hence, in our case, more sensitivity to the surround distant from the skull. As the ratio approaches unity, the DoG approaches the minus second derivative of a Gaussian. In most applications the ratio takes values between 1.5 and 5. For our purposes a value of 3 provides sufficient sensitivity to the surrounding region of the skull [18,16].

The numerator of g enjoys two distinct symmetries. First, it is radially symmetric, i.e., the profile along each radial line is one and the same: it is the DoG. Equivalently we can say that the numerator of g is constant along the contour lines. Second, each radial profile is symmetric about the point of intersection between the radius and the ellipse (a trivial consequence of the symmetry of the DoG). Overall, it means that the numerator of g assumes the same value on any two distinct contour lines sharing the same radial distance from the ellipse (one contour line internal to the ellipse, and the other one external). Even though the DoG is by construction a zero-mean function, after elliptical revolution the integral balance is lost due to the nonuniform radial geometry, as shown in Fig. 4(c). In particular, the green patches illustrate two finite area elements. Riemann integration of a bivariate function is the limiting summation over these elements, as their respective area tends to zero. Observe in the figure that the size of the area elements increases proportionally to their radial distance from the center. Therefore, by dividing the numerator by r
                        0, we restore the integral balance.

Clearly, 
                           
                              ∫
                              
                                 −
                                 ∞
                              
                              
                                 +
                                 ∞
                              
                           
                           
                              f
                              s
                           
                           (
                           ξ
                           )
                           −
                           
                              f
                              
                                 3
                                 s
                              
                           
                           (
                           ξ
                           )
                           d
                           ξ
                           =
                           0
                        . However, when defining g, each radial line is bounded, on one side by the center of the ellipse, and on the other side by the image boundary. This means that the argument d(x
                        1, x
                        2, a) ranges from d(c
                        1, c
                        2, a) to a finite positive value attained at the intersection of the radial line with the image boundary. Therefore, the tails of the DoG are formally missing from g. This notwithstanding, due to their exponential decay, the tails are numerically negligible for all parameter combinations of practical relevance.
                           2
                        
                        
                           2
                           The DoG is numerically negligible outside of the interval 
                                 
                                    
                                       −
                                       18
                                       s
                                       ,
                                       18
                                       s
                                    
                                 
                              , with the radius 18s being the six-sigma range for the standard deviation 3s of the wider Gaussian f
                              3s
                              . All cases of practical relevance satisfy the inequality d(c
                              1, c
                              2, a)>18s by a large margin, which means that tails of the DoG have no numerical relevance.
                         Thus,
                           
                              (2)
                              
                                 
                                    ∬
                                    Θ
                                 
                                 g
                                 (
                                 
                                    x
                                    1
                                 
                                 ,
                                 
                                    x
                                    2
                                 
                                 ,
                                 
                                    
                                       a
                                    
                                 
                                 ,
                                 s
                                 )
                                 
                                    dx
                                    1
                                 
                                 
                                    dx
                                    2
                                 
                                 =
                                 0
                              
                           
                        for any radial support Θ, such as the wedge drawn in yellow in Fig. 4(c), including as maximal Θ the whole image domain Ω.

Consequently, for an image z and an ellipse E(a), the cost function is written as


                        
                           
                              (3)
                              
                                 
                                    
                                       
                                          C
                                          (
                                          z
                                          ,
                                          
                                             
                                                a
                                             
                                          
                                          ,
                                          s
                                          )
                                       
                                       
                                          =
                                       
                                       
                                          −
                                          
                                             ∬
                                             Ω
                                          
                                          z
                                          (
                                          
                                             x
                                             1
                                          
                                          ,
                                          
                                             x
                                             2
                                          
                                          )
                                          g
                                          (
                                          
                                             x
                                             1
                                          
                                          ,
                                          
                                             x
                                             2
                                          
                                          ,
                                          
                                             
                                                a
                                             
                                          
                                          ,
                                          s
                                          )
                                          
                                             dx
                                             1
                                          
                                          
                                             dx
                                             2
                                          
                                       
                                    
                                    
                                       
                                       
                                          +
                                       
                                       
                                          λ
                                          
                                             
                                                (
                                                max
                                                (
                                                0
                                                ,
                                                
                                                   
                                                      max
                                                      (
                                                      
                                                         r
                                                         1
                                                      
                                                      ,
                                                      
                                                         r
                                                         2
                                                      
                                                      )
                                                   
                                                   
                                                      min
                                                      (
                                                      
                                                         r
                                                         1
                                                      
                                                      ,
                                                      
                                                         r
                                                         2
                                                      
                                                      )
                                                   
                                                
                                                −
                                                CI
                                                )
                                                )
                                             
                                             2
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where λ
                        =0.5 is a regularization parameter selected experimentally, and the term CI=1.4 is used to model the inverse of the minimal allowable cephalic index, see, e.g., [13] for a justification of this value. The regularization term is introduced to speed up the convergence of the minimization algorithm in those images where the skull is not fully visible (e.g. see the right-most panels in Fig. 2). Practically, the regularization term allows to reduce the number of the re-starts of the minimization algorithm by preventing the convergence of the algorithm to obviously incorrect solutions.

The cost function C(z, a, s) is affine with respect to z and, due to the characteristics of g(x
                        1, x
                        2, a, s), it is not affected by the presence of large uniform regions in the image. As observed in Eq. (2), the integral ∬Ω
                        g(x
                        1, x
                        2, a, s)dx
                        1
                        dx
                        2
                        =0 for all reasonable a and s, therefore, if the image is noninformative (has a constant value in every pixel), every ellipse receives the score zero. This property is important because it ensures that an addition of a constant to the image intensities does not alter the value of the cost function, i.e. C(z
                        +
                        B, a, s)=
                        C(z, a, s), where B is a scalar and z
                        +
                        B is to be interpreted as adding B to each intensity z(x
                        1, z
                        2).

For an N
                        1
                        ×
                        N
                        2 image z, the integral in Eq. (3) is computed as the following discrete sum:


                        
                           
                              (4)
                              
                                 
                                    
                                       
                                          C
                                          (
                                          z
                                          ,
                                          
                                             
                                                a
                                             
                                          
                                          ,
                                          s
                                          )
                                       
                                       
                                          =
                                       
                                       
                                          −
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                
                                                   N
                                                   1
                                                
                                             
                                          
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                
                                                   N
                                                   2
                                                
                                             
                                          
                                          z
                                          (
                                          i
                                          ,
                                          j
                                          )
                                          g
                                          (
                                          i
                                          ,
                                          j
                                          ,
                                          
                                             
                                                a
                                             
                                          
                                          ,
                                          s
                                          )
                                       
                                    
                                    
                                       
                                       
                                          +
                                       
                                       
                                          λ
                                          
                                             
                                                (
                                                max
                                                (
                                                0
                                                ,
                                                
                                                   
                                                      max
                                                      (
                                                      
                                                         r
                                                         1
                                                      
                                                      ,
                                                      
                                                         r
                                                         2
                                                      
                                                      )
                                                   
                                                   
                                                      min
                                                      (
                                                      
                                                         r
                                                         1
                                                      
                                                      ,
                                                      
                                                         r
                                                         2
                                                      
                                                      )
                                                   
                                                
                                                −
                                                CI
                                                )
                                                )
                                             
                                             2
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where z(i, j) denotes the intensity of z in the spatial position (i, j). Image padding is necessary for the zero-score condition (2) to hold for the noninformative images whenever the integral is approximated as in Eq. (4). We did not implement the image padding in the original challenge submission and had to compensate for it by introducing a multiplicative regularization term and an additional regularization parameter (γ in Eq. (1) of [9]). However, by implementing the image padding, we can safely eliminate this regularization and the corresponding parameter. Based on the same considerations given in Footnote 1, only a narrow innermost portion of the padding border is numerically significant with respect to the image model g. Our implementation uses a 120-pixel wide padding border, which was found to be sufficient in all experiments.

@&#METHODS@&#

The DoGEll method works by minimizing the cost function described in Section 2 based on a modified multiscale, multistart Nelder–Mead algorithm (described in Section 3.2). However, we will start this section by describing the applied image preprocessing in Section 3.1. Finally, we will describe the computation of the biometric parameters based on the segmentation results in Section 3.3.

To minimize the adverse effects caused by the heterogeneous contrast and the black background outside the field of view (see Fig. 2), we carry out the following two preprocessing operations on each unprocessed image, which we denote as z
                        orig. First, we extrapolate the image inside of the scanned area to fill the areas outside the field-of-view as well as a padding border which is appended to the four sides of the images. Without such an extrapolation, the boundary of the field of view might be confused with the boundary of skull that might cause the optimization algorithm in Section 3.2 to fail. This is done by a constrained iterative diffusion process illustrated in Fig. 5
                        . Leaving the content within the field of view untouched, at each iteration we convolve the image with an isotropic smoothing kernel whose support has radius proportional to the maximum distance the between the already diffused image and the image boundary. In this way, as the diffused image reaches the boundary, the smoothing kernel approaches a Dirac delta. By doing so we achieve fast convergence of the diffusion process, as well as a smooth junction between the diffused image and the unmodified image in the scanned area. In particular, as illustrated in Fig. 5, we use a Kaiser 2-D kernel whose support radius is a quarter of the maximum distance between the already diffused image and the image boundary. About 18 iterations suffice for the diffusion to reach the boundary. We denote the extrapolated image as z
                        extr. Note that z
                        extr and z
                        orig coincide within the field of view.

The second preprocessing operation consists of a stabilization of the local contrast and intensities of z
                        extr leveraging discrete cosine transform (DCT) domain smoothing [21]. We achieve a smoothly varying local stabilization of the intensities and contrast of z
                        extr by (1) computing its DCT spectrum, (2) attenuating the low-frequency portion of the spectrum, and (3) by inverting the transform. In particular, the attenuation follows the usual zig-zag sorting of the coefficients [21]. This stabilized image is denoted as z (see Fig. 6
                         for an example). The DCT-domain filtering is a practical tool (but not the only reasonable one) to perform a strong smoothing needed for the stabilization and a better alternative to the convolutive high pass filter that would require a large support and require more computational effort.

The cost function (3) is non-convex with respect to a and s and has several local minima. Therefore, we must use an algorithm which aims to find its global minimum to avoid the sensitivity to the algorithm initialization. We employ a multistart Nelder–Mead (NM) algorithm that repeats the following steps T times (T is defined below):
                           
                              (1)
                              generate an initial a;

execute the NM minimization algorithm and if the minimum found is the best so far, save it;

apply a random perturbation to the best found solution, and go to step 2.

Our implementation of the Nelder–Mead simplex search algorithm, originally proposed in [19], is based on [14]. However, we accelerate the implementation of [14] by incorporating an insertion sort algorithm. This modification is briefly explained next. The Nelder–Mead algorithm is a direct optimisation algorithm designed to iteratively find the minimiser of functions 
                           f
                           :
                           
                              
                                 
                                    ℝ
                                 
                              
                              n
                           
                           →
                           
                              
                                 ℝ
                              
                           
                         (here, n
                        =6). At each iteration, the algorithm transforms the geometry of a (n
                        +1)-points simplex in the domain of f; in particular, the simplex can be reflected, expanded, contracted, or shrunk. Operatively, each iteration of the algorithm first evaluates f in each point of the simplex and optimizes the position of those having the larger values retaining the position of the best one. Then, the n
                        +1 points of the newly formed simplex are sorted based on their functional value, and the best n ones are used to compute a mean point. The shrinkage requires the computation of n new points, whereas the expansion, reflection, and contraction require the computation of just one new point. Thus, the latter cases, which are the most common in practice, can be accelerated by sorting the points of the simplex using an insertion sort algorithm because the old points of the simplex are already ordered [23]. Additionally, the new mean point can be computed by updating the old one by subtracting the removed point and adding the new one, instead of averaging all n points [23]. The coefficients of reflection, expansion, contraction, and shrinkage are as given in [14] for the standard Nelder–Mead algorithm.

The major and minor axes of the ellipse directly correspond to the OFD and BPD, when measured from center-to-center of the skull, respectively. We denote these center-to-center measurements as
                           
                              
                                 
                                    OFD
                                    cc
                                 
                                 :
                                 =
                                 2
                                 max
                                 (
                                 
                                    r
                                    1
                                 
                                 ,
                                 
                                    r
                                    2
                                 
                                 )
                                 
                                    
                                       ,
                                          
                                          
                                          
                                          
                                          
                                       BPD
                                    
                                    cc
                                 
                                 :
                                 =
                                 2
                                 min
                                 (
                                 
                                    r
                                    1
                                 
                                 ,
                                 
                                    r
                                    2
                                 
                                 )
                                 .
                              
                           
                        
                     

To obtain outer-to-outer measurements OFD and BPD definitions, as in the manual analysis in the ISBI 2012 challenge data [22], we should increment the center-to-center measures by the calvarial thickness T:
                           
                              
                                 OFD
                                 :
                                 =
                                 
                                    OFD
                                    cc
                                 
                                 +
                                 T
                                 ,
                                 
                                 BPD
                                 :
                                 =
                                 
                                    BPD
                                    cc
                                 
                                 +
                                 
                                    T
                                    .
                                 
                              
                           
                        
                     

The thickness T is directly proportional to the standard-deviation parameter s of the fitted surface g. Therefore, after minimization of the cost functional, we can estimate the thickness as
                           
                              
                                 
                                    
                                       T
                                       ˆ
                                    
                                 
                                 =
                                 κ
                                 
                                    
                                       s
                                       ˆ
                                    
                                 
                                 ,
                              
                           
                        
                     

where κ
                        =2.45 is the proportionality constant, as illustrated in Fig. 4(a). This specific value of κ was determined through the correction formula of [7], which expresses the typical value of the skull thickness as a function of the BPDcc:
                           
                              (5)
                              
                                 T
                                 
                                    
                                       
                                          
                                             BPD
                                             cc
                                          
                                       
                                    
                                 
                                 =
                                 1.31
                                 −
                                 0.119
                                 
                                    BPD
                                    cc
                                 
                                 +
                                 0.00472
                                 
                                    BPD
                                    cc
                                    2
                                 
                                 −
                                 0.00003627
                                 
                                    BPD
                                    cc
                                    3
                                 
                                 .
                              
                           
                        where BPDcc is expressed in millimeters. This formula provides an alternative estimate of the thickness, which depends on 
                           2
                           min
                           
                              
                                 
                                    
                                       
                                          
                                             r
                                             ˆ
                                          
                                       
                                       1
                                    
                                    ,
                                    
                                       
                                          
                                             r
                                             ˆ
                                          
                                       
                                       2
                                    
                                 
                              
                           
                         and is independent of 
                           
                              s
                              ˆ
                           
                        . The choice of κ must be such that the two alternative estimates of T are consistent. Therefore, given a dataset of ultrasound images, we define κ as
                           
                              
                                 κ
                                 =
                                 
                                    mean
                                    j
                                 
                                 
                                    
                                       
                                          
                                             
                                                T
                                                
                                                   
                                                      
                                                         2
                                                         min
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        
                                                                           r
                                                                           ˆ
                                                                        
                                                                     
                                                                     1
                                                                  
                                                                  
                                                                     
                                                                        j
                                                                     
                                                                  
                                                                  ,
                                                                  
                                                                     
                                                                        
                                                                           r
                                                                           ˆ
                                                                        
                                                                     
                                                                     2
                                                                  
                                                                  
                                                                     
                                                                        j
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      s
                                                      ˆ
                                                   
                                                
                                                
                                                   
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where j is an index of the image in the dataset and the numerator gives the thickness estimate computed from the estimated minor axis through (5). We used the dataset described in Section 4.1 to define κ. Note that this relied only on the automatic segmentations and we did not use any manually generated ground truth to define κ.

@&#EXPERIMENTS@&#

For the evaluation of the DoGEll method, we used the image data and manual analysis of the Challenge US: Biometric Measurements from Fetal Ultrasound Images of the IEEE International Symposium on Biomedical Imaging (ISBI) described in detail by [22]. However, we repeat the most important aspects of the used data here in order to make this paper self-contained. We use 90 ultrasound images of the fetal head acquired by trained clinicians using the same mid-range ultrasound machine Philips HD9 and following the protocols defined in [11]. The 90 images represented three different gestational ages (21, 28, and 33 weeks) with a total of 30 images per gestational age (90 different fetuses). For each gestational age, images were graded as being of low, medium, or high quality and were selected as objectively as possible to create real image data sets as used in clinical practice. The images were in an anonymized DICOM format and automatically cropped to the size of 756×546 pixels. The pixel size varied between the images.

A total of three experts, with different degrees of expertise, participated in defining the fetal head ground truth. The ground truth consisted of (1) manually fitted ellipses to the fetal head and (2) standard clinical measurements of BPD, OFD and HC (derived from BPD and OFD) on each image. All experts fitted the ellipses and performed the measurements twice on each image. Therefore, altogether 540 (2 repetitions × 3 experts × 90 images) manual annotations were used in the experiments. The experts had the following levels of expertise:
                           
                              •
                              
                                 Expert 1: Clinician (fetal medicine specialist) with 10 year postgraduate experience in fetal US scans.


                                 Expert 2: Clinician (obstetrician) with 2 years experience in fetal US scans.


                                 Expert 3: Engineer with 1 year of experience.

To report the quality of automatic segmentations in comparison to the manual ground truth, we have selected three measures from the original corpus of seven measures applied in the challenge.
                           3
                        
                        
                           3
                           The quantitative results of all seven measures are provided in a supplement but we limit the discussion here to the 3 selected ones.
                        
                     

We denote the sets of pixels inside the manually fitted ground truth ellipses by M and inside the automatically fitted ellipses by A. The Dice index [6] between the sets M and A is
                           
                              
                                 Dice
                                 (
                                 A
                                 ,
                                 M
                                 )
                                 =
                                 
                                    
                                       2
                                       |
                                       A
                                       ∩
                                       M
                                       |
                                    
                                    
                                       |
                                       A
                                       |
                                       +
                                       |
                                       M
                                       |
                                    
                                 
                                 .
                              
                           
                        The Dice index measures the overlap of two different fetal head segmentations. It ranges between zero (no overlap) and one (perfect overlap), where higher Dice values indicate a better overlap. The Dice index evaluates the similarity of two segmented regions and is depictive of the overall segmentation quality. The Dice index is not especially sensitive to local differences between the segmentations and it is dimensionless. Therefore, it is complemented by two other evaluation metrics in this work.

Denote the contours of M and A by ∂M and ∂A, respectively. The maximum symmetric contour distance (MSD, also known as the Hausdorff distance) between the two contours is [26]
                        
                           
                              
                                 MSD
                                 (
                                 ∂
                                 A
                                 ,
                                 ∂
                                 M
                                 )
                                 =
                                 max
                                 (
                                 
                                    max
                                    
                                       a
                                       ∈
                                       ∂
                                       A
                                    
                                 
                                 
                                    min
                                    
                                       m
                                       ∈
                                       ∂
                                       M
                                    
                                 
                                 |
                                 |
                                 a
                                 −
                                 m
                                 |
                                 |
                                 ,
                                 
                                    max
                                    
                                       m
                                       ∈
                                       ∂
                                       M
                                    
                                 
                                 
                                    min
                                    
                                       a
                                       ∈
                                       ∂
                                       A
                                    
                                 
                                 |
                                 |
                                 a
                                 −
                                 m
                                 |
                                 |
                                 )
                                 .
                              
                           
                        MSD equals 0 if the two contours are identical and a higher MSD indicates more pronounced differences between the contours. MSD is indicative for even very local differences between the two contours. The average symmetric contour distance (ASD) between the two contours is
                           
                              
                                 ASD
                                 (
                                 ∂
                                 A
                                 ,
                                 ∂
                                 M
                                 )
                                 =
                                 
                                    
                                       
                                          ∫
                                          
                                             a
                                             ∈
                                             ∂
                                             A
                                          
                                       
                                       
                                          min
                                          
                                             m
                                             ∈
                                             ∂
                                             M
                                          
                                       
                                       |
                                       |
                                       a
                                       −
                                       m
                                       |
                                       |
                                       +
                                       
                                          ∫
                                          
                                             m
                                             ∈
                                             ∂
                                             M
                                          
                                       
                                       
                                          min
                                          
                                             a
                                             ∈
                                             ∂
                                             A
                                          
                                       
                                       |
                                       |
                                       a
                                       −
                                       m
                                       |
                                       |
                                       )
                                    
                                    
                                       |
                                       ∂
                                       A
                                       |
                                       +
                                       |
                                       ∂
                                       M
                                       |
                                    
                                 
                                 .
                              
                           
                        ASD equals 0 if the two contours are identical and a higher ASD indicates more pronounced differences between the contours.

We further subjected the values of these metrics to statistical testing to find if there were significant differences between intra- and inter-expert segmentation variabilities and the automatic segmentation accuracy. We used the standard two-tailed t-test for hypothesis testing.

We compared the biometric parameters of interest derived based on the automatic segmentation to manual measurements. The criteria were the average difference 
                           
                              d
                              ¯
                           
                         (that can be considered as a measure of bias) and its standard deviation s
                        
                           d
                         between the automatic and manual biometric measures; the manual measure for each fetus was selected to be the average of the two measurements of an expert to increase its accuracy against intra-expert variability. These quantities are referred to as the Bland-Altman plots by [22] (see [1]). Based on these two quantities, we can compute the root mean squared error 
                           RMSE
                           =
                           
                              
                                 
                                    
                                       d
                                       ¯
                                    
                                    2
                                 
                                 +
                                 
                                    s
                                    d
                                    2
                                 
                              
                           
                        . RMSE provides a single indicator of the difference in the derived biometrics that simplifies the method comparisons. Note that the point made in [1] against the use of correlation as a measure of agreement is particularly relevant here, where the data is such that the biometrics to be determined vary considerably due to different gestational ages of the fetuses. Therefore, we do not provide correlation coefficients between automatic and manual biometrics.

@&#RESULTS@&#

The computation time of a Matlab-based implementation of the algorithm was on average 4.62 seconds per image on a laptop (Intel(R) Core(TM) i5-3320M dual core CPU running at 2.60GHz with 64-bit Windows 7 operating system, Matlab version R2013a). The maximal computation time per image was 5.43s. These timings include the time spent for preprocessing of Section 3.1, cost function optimization of Section 3.2, and computation of biometric parameters of Section 3.3. A significant portion of the computation time (on average 3.62s) was spent on the cost function minimization. Preprocessing required approximately 1s per image.

The current Matlab-based implementation is sequential and single-threaded, where the Nelder–Mead algorithm is implemented in C and compiled into a mex file, and the other parts of the method are written in Matlab. Further improvements in computation time would be gained by exploiting a multicore implementation and by a more significant usage of the more efficient C language. In particular, the early stages of the optimization involving the multistart strategy can be parallelized in a straightforward manner.

The quantitative evaluation results of the DoGEll are provided in Tables 1
                         and 2
                        . Table 1 also provides the corresponding results of the earlier (slower) implementation of DoGEll, which won the ultrasound segmentation challenge [22], and the second best method [24] in the same segmentation challenge. Table 2 presents more detailed results of comparison between DoGEll and manual delineations. To simplify the comparison to the manual segmentation accuracy, we have also reproduced the intra and inter-expert measures from [22] in Table 2. Note that all the results corresponding to [9] are given only for comparison purposes and the discussion about the DoGEll refers to the fast implementation as presented in this work. The results can be summarized as follows.
                           
                              (1)
                              The segmentation accuracy of DoGEll was significantly better than that of any other segmentation method participating to Challenge US: Biometric Measurements from Fetal Ultrasound Images. In particular, the difference between the segmentation accuracy of DoGEll and the second best approach in the challenge [24] was significant (one-sided p
                                 <0.05 for all three measures (Dice, MSD, and ASD)). This was computed only using information from [22] which necessitated the use of an unpaired t-test. The differences in average performance between the slow version of DoGEll in [9] (computation time of 5 min per image) and the fast implementation in this paper (computation time of under 5s per image) were not significant at the alpha-level p
                                 =0.05 (p
                                 >0.3 for all three measures).

The average segmentation accuracy of the automatic DoGEll method was similar to the inter-expert variability of the manual segmentations with all three measures. More specifically, the average Dice coefficient and ASD of DoGEll were better than the corresponding average inter-expert measures between experts 2 and 3. For other cases, the average measures of DoGEll were slightly worse than the inter-expert variability (but not significantly, one-sided p
                                 >0.05 for all expert pairs and validation metrics).

The segmentation accuracy of DoGEll was worse than the intra-rater variability (one-sided p
                                 <0.05 in all cases) as expected. However, it is worth to note that the inter-expert variabilities were also greater than intra-expert variabilities.

An interesting aspect was revealed when comparing the measures between our method and the segmentation by Expert 1 (DoGEll vs Expert 1) - who is the most experienced one - versus the inter-rater variabilities between Expert 1 and other experts (the rows Inter-expert 1 vs 2 and Inter-expert 1 vs 3 in Table 2). If we assume that the ground truth segmentation was the one by Expert 1 then our automatic method would, on average, outperform the manual delineations of the Experts 2 and 3 in terms of Dice index or ASD. However, it must be noted that differences were very small (insignificant at the p
                        <0.05 level) and, if using MSD to judge performance, the Experts 2 and 3 would slightly outperform our method.

It is interesting to study the worst cases in terms of segmentation accuracy. These are best identified by the MSD metric, which is sensitive to very local differences between the two segmentations (automatic and manual). Eight worst cases of the total 90 in terms of the MSD averaged over all expert segmentations are shown in Fig. 7
                        . Fig. 7 shows that the head contour by the automatic segmentation mostly was in the space set by expert segmentations, and only very few clear local differences from all expert segmentations can be observed. Fig. 7 also shows the image with the median (46th) MSD for reference in the bottom right panel.

The mean values (biases) and standard deviations of the differences between the manual and automatic biometric measurements are reported in Table 3
                        . Table 3 also provides inter-observer variabilities reproduced from [22] and the corresponding RMSEs computed based on these. A few observations can be made based on these values.
                           
                              (1)
                              The average differences (
                                    
                                       d
                                       ¯
                                    
                                 ) for the automatic measures by DoGEll were larger than between expert average differences. Moreover, 
                                    
                                       d
                                       ¯
                                    
                                  for DoGEll was always negative meaning that, on average, biometric parameters as estimated by DoGEll were slightly smaller than the corresponding parameters estimated by experts. However, if this bias is considered to be important, it can be easily corrected by tuning the parameter κ of Section 3.3. We here tuned the parameter κ based on automatic segmentations, but to reduce the bias, it could be tuned by manual segmentations. However, in this case, the method development and evaluation would not be independent and we wanted to avoid this.

The standard deviations of the differences (s
                                 
                                    d
                                 ) can be argued to be more important than the average differences (
                                    
                                       d
                                       ¯
                                    
                                 ) because they cannot be improved by simple parameter tuning (unlike the average differences). In Table 3, s
                                 
                                    d
                                  for the automatic measurements as compared to between expert s
                                 
                                    d
                                  were (on average) smaller for the BPD, larger for the OFD, and almost equal for the HC. For example, treating again the measurements of the most experienced expert (E1) as a gold standard and s
                                 
                                    d
                                  as a performance index, the automatic method outperformed the Expert 2 in the measurement of BPD (s
                                 
                                    d
                                 
                                 =1.25mm vs. s
                                 
                                    d
                                 
                                 =1.66mm, F-test between the two 
                                    
                                       s
                                       d
                                       2
                                    
                                  values p < 0.01, one-sided), the expert 2 outperformed the automatic method in the measurement of OFD (s
                                 
                                    d
                                 
                                 =3.12mm vs. s
                                 
                                    d
                                 
                                 =2.36mm, F-test p <0.01, one-sided) and, for HC, the difference in 
                                    
                                       s
                                       d
                                       2
                                    
                                  was non-significant (s
                                 
                                    d
                                 
                                 =4.71mm vs. s
                                 
                                    d
                                 
                                 =4.16mm), according to F-test at the alpha level p
                                 =0.05).

RMSEs for the automatic method were lower for the BPD measures than the inter-observer RMSEs between Expert 1 and Experts 2 or 3. Instead, the BPD measurements of Experts 2 and 3 were well in line, consistently resulting in a RMSE of only 1.00mm, which is less than the corresponding RMSEs for DoGEll (1.37mm and 1.54mm). For OFD and HC, the RMSEs by the automatic method were slightly higher than inter-expert RMSEs.

@&#DISCUSSION@&#

We have presented an automatic method, DoGEll, for the segmentation of the fetal skull from 2-D ultrasound images. The DoGEll method is based on a global optimization of a novel cost function by a multi-start multi-scale Nelder–Mead algorithm. The cost function is based on the assumption that the cross-section of the skull has a roughly elliptical shape. The main difference between our cost function and previous ellipse-fitting methods [10,17,27] are that in our cost function the skull has a finite thickness instead of being modeled with an ellipse contour as in and our cost function models the image intensity also around the skull. Moreover, we do not consider the calvarial thickness to be a user defined constant as in [12] but as a hyper-parameter to be optimized along with the five ellipse parameters. This means that we do not fit an ellipse or some other contour to an image as in [10,17,27,12] but, instead, we first construct a template image of the fetal skull based on the ellipse parameters and then we match the resulting model with the observed ultrasound image. In this way, we are able to circumvent thresholding and skeletonization operations usually required by Hough transform based methods [10,17,27]. Also, our image model is different from the simple two-component (skull and background) mixture model of the region based segmentation method in [12] and we avoid the manual initialization in [12]. As a result, the DoGEll method is fully automatic and, at the same time, extremely robust against image imperfections as demonstrated by experiments presented in this paper.

We have presented a quantitative validation of the DoGEll method based on 90 images from a recent ultrasound segmentation challenge [22]. In particular, the automatic segmentations and the biometric parameters (BFD, OFD, and HC), derived from the segmentations, were validated against the corresponding manual analysis provided by three experts. The images for the challenge were purposefully selected so that the image quality varied between the images. We have shown that, even for the low quality images, our method yielded segmentations with an accuracy comparable to inter-expert variability of segmentations. We statistically tested if the accuracy differences between any two analysis methods were significant. However, we should point out that a statistically significant difference between the measurements by two different analysis methods does not imply that the difference would affect clinical decisions. Likewise, even if the measurement differences were not statistically significant, they could still result in different clinical decisions depending on the patient and the nature of the decision being made.

Only few works on automated segmentation of fetal ultrasound images have addressed the accuracy of head segmentations against manual segmentations. Carneiro et al. [2] reported mean Hausdorff distances (MSDs) of 4.83 mm (their set 1) and 4.15 mm (their set 2) and average distances (ASDs) of 3.39 mm and 2.76 mm when comparing automatic head contour delineations to the delineations by experts. Chalana and Kim [3] reported mean Hausdorff distance of 4.64 mm and the average distance of 2.09 mm. The corresponding error measures for our method, listed in Table 1, were: an average MSD of 2.26 mm and the average ASD of 0.91 mm. Thus, in the light of this comparison, the performance of our method appears superior to these two albeit it must be stressed that the validation results may not be comparable because of the different sets of images used. A majority of the reports on automated fetal ultrasound segmentation have provided quantitative validation in the terms of the derived biometric parameters. For example, Yu et al. [27] reported mean absolute difference (MAE) of 2.5 mm for BPD and 5.7 mm for HC between automatically and manually derived biometric parameters. Noting that the RMSE is always greater than MAE, the biometric parameters by our method appeared more accurate than those reported in [27]; however, we must repeat the earlier note that the validation results cannot be directly compared. In particular, the gestational ages of the fetuses studied in [27] were somewhat higher than those in this paper.

Although comparisons to the previous methods in literature are problematic due to different datasets used for validation and a poor availability of the software implementations of the methods, the segmentation accuracy by our method can be directly compared to the results of other methods which participated in the Challenge US: Biometric Measurements from Fetal Ultrasound Images held in conjunction of the ISBI 2012 conference [22].
                        4
                     
                     
                        4
                        The Challenge data will be made available to the research community. The estimated date for data release to the research community is anticipated to be in autumn 2014. The challenge website: http://www.ibme.ox.ac.uk/challengeus2012 will then be updated to allow new segmentation results to be uploaded for evaluation and comparison to previous methods.
                      As already noted, the segmentation accuracy of our method was superior to that of the other methods which participated in the Challenge (see Section 5.2). Also, when using RMSE as the performance measure, the biometric measurements by our method were the most accurate for OFD and HC (all experts RMSEs 2.97 mm (OFD) and 4.39 mm (HC) against RMSEs of 3.07 mm and 5.33 mm of [24] which was the second best method in the challenge in this respect), and the second most accurate for BPD (RMSE of 1.41 mm compared to RMSE of 1.37 mm of [25]). However, having a small standard deviation s
                     
                        d
                      can be considered more important than having a small bias 
                        
                           d
                           ¯
                        
                      and s
                     
                        d
                      of our method was smaller than that of [25] for all three biometric measurements. The RMSEs for [24,25] were computed based on 
                        
                           d
                           ¯
                        
                        ,
                        
                           s
                           d
                        
                      values presented in [22].

Finally, the source-code of DoGEll is available at: http://www.cs.tut.fi/∼foi/dogell/ under an license permitting free non-commercial use of it.

@&#ACKNOWLEDGEMENTS@&#

The work of A. Foi, M. Maggioni, A. Pepe and J. Tohka was supported by the Academy of Finland under grants 130275 and 252547, and by Tampere Graduate School in Information Science and Engineering (TISE). S. Rueda and J.A. Noble were supported by the Wellcome/EPSRC Centre of Excellence in Medical Engineering – Personalized Healthcare, WT 088877/7/09/Z. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. The ultrasound images were provided by the International Fetal and Newborn Growth Consortium, INTERGROWTH-21st, Nuffield Department of Obstetrics and Gynaecology, Women's Centre, John Radcliffe Hospital, University of Oxford, Oxford, United Kingdom.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.compmedimag.2014.09.006.

The following are the supplementary data to this article:


                     
                        
                           
                        
                     
                  

@&#REFERENCES@&#


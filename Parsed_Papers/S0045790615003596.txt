@&#MAIN-TITLE@&#Synchronous transmission of a Gong-Che notation musical score and its MIDI information

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Achieve synchronous transmission of GCN musical scores and their MIDI information.


                        
                        
                           
                           Examine difference numbers of connected components in original and watermarked scores.


                        
                        
                           
                           Run expansion algorithm on original score to improve note extraction accuracy rate.


                        
                        
                           
                           Minimal added time complexity needed to expand the score and avoid information loss.


                        
                        
                           
                           Our algorithms are suitable for Conventional Musical Notation.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gong-Che notation

Digitizing

Watermarking algorithm

Synchronous transmission

Image processing

Optical music recognition

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Gong-Che notation (GCN) is a traditional Chinese musical notation with a very long history. It originated during the Wu Dai (907–960) and became popular during the Ming Dynasty (1368–1644) and Qin Dynasty (1644–1912). It is the major musical notation preserving traditional Chinese and East Asian musical scores. For example, Ref. [1] is a famous dramatic work that includes more than 360 plays in GCN. Fig. 1
                      shows a representative musical score sheet from [1].

Currently, the dominant musical notation is conventional music notation (CMN). CMN originated in European classical music and is now used by musicians in many different genres throughout the world, including in China. GCN is seldom used in modern China but its musical information may be used in translations to CMN. When a GCN score is converted to a CMN score, the results can differ between translations [2] since GCN is an imprecise musical notation, especially in terms of the duration of a note. So a relatively correct translation, as opposed to a precise translation, is expected in the transmission of a GCN score to CMN.

GCN uses a movable-do musical singing technique, with the basic pitch of note symbols represented by 10 Chinese characters, 
                        
                      the corresponding solfeggio syllables used in English-speaking countries are: sol, la, ti, do, re, mi, fa, sol, la, and ti. GCN does not mark a musical note's duration, but instead gives the beats at regular intervals, with each beat indicated in the corresponding note's upper right corner. Common beat notation comprises eight symbols, 
                        
                     , and two main types of beats are distinguishable, namely, ban, the stronger beat in the melody, and yan, the weaker beat.

Pitch and beat information in GCN are independent of each other, and both use symbolic objects with semantics. A pitch symbol may or may not be attached to a beat symbol. In stave notation, i.e., conventional music notation (CMN), every note symbol contains both pitch and duration information; the duration of every note is a continuous segment of musical time. However, in GCN the beat symbols represent discrete points that divide the music in time. Therefore it is easy to introduce errors when translating GCN, (an ambiguous notation), to stave notation (a precise notation).

Musical instrument digital interface (MIDI) is an industry-standard protocol that enables electronic musical instruments, computers, and other electronic equipment (MIDI controllers, sound cards, and samplers) to communicate and synchronize with each other [3]. MIDI protocol is based on CMN and European classical music theory, and can accurately describe the musical information of a CMN score. A MIDI file requires less storage space than its corresponding score image, so we can embed the MIDI file into the GCN score image using a watermarking algorithm. This prevents ambiguity in the musical information of a GCN score, and allows digitization without translation to CMN.

For present-day readers, stave notation musical scores are better understood than those using GCN; since MIDI originated from CMN, it is also familiar to the reader. Despite the abundant literature regarding GCN, few people can understand GCN musical scores; therefore, this vast resource of musical data cannot be used in modern society. It would be much easier for a reader to understand a GCN score with MIDI information using the proposed technique, because the MIDI information has been provided by a GCN expert.

Published binary image watermarking algorithms include: run-length watermarking of a fax document [4], multiple binary images watermarking in spatial and frequency domains [5], shifting elements in a text document [6], fractal coding method [7], watermarking halftone images [8], and a digital watermarking scheme based on radial-harmonic Fourier moments magnitude [9]. The run-length watermarking algorithm in [4] involves varying the run-length of the file and changing the size of the boundary used to transmit the information. Multiple binary image watermarking in spatial and frequency domains [5] is a scheme in which more data can be inserted into an image in different domains by using various techniques. The element-shifting algorithm in [6] embeds the watermarking data by shifting a whole line of text, a group of characters, or a single character. This algorithm cannot be applied to the GCN musical score image since shifting notes may change the pitch. In [7], an image is coded by the proposed fractal coding method, which is designed for binary images, to insert the watermark uniformly over the entire image. Specific range segments with predefined conditions are selected, and the watermark is added to the fractal code of these segments. The watermarking algorithm for halftone images [8] is not extensible to other image types and is therefore not suitable for musical scores. The digital watermarking scheme based on radial-harmonic Fourier moments magnitude described in [9] proposes a geometrically resilient digital image watermarking scheme, based on radial-harmonic Fourier moments magnitudes. Owing to the nature of musical scores, this methodology can significantly alter the musical information. Thus, novel techniques are necessary for watermarking musical scores.

Embedded watermark data may modify the information of the original score image, and this affects readability for both humans and machines. Thus, we used optical music recognition (OMR) to judge the effect of watermarking on the accuracy of the embedded score image. OMR allows automatic processing and analysis of musical notation images. This process typically employs a scanner or other digital device to convert paper-based musical scores into digital images, which are then processed, recognized, and automatically translated into a standard format for music files, such as the MIDI format. Pruslin [10] conducted the first published OMR work at the Massachusetts Institute of Technology. Pruslin's system primarily recognized musical notes in CMN scores. Before the 1990s, many OMR studies were conducted [11], and research had begun to focus on handwritten formats and ancient (or folk) music, including medieval music [12], GCN [13], white mensural notation [14], early music prints [15], orthodox Hellenic Byzantine music notation [16], and Greek traditional music [17].

In this work, we present a new watermarking algorithm for embedding MIDI file information into GCN score images. The remainder of this paper is organized as follows: Section 2 describes the watermarking algorithm, Section 3 explains the experimental methodology, Section 4 provides experimental results for randomly selected scores, and Section 5 highlights the value of this research.

Suppose I is a binary musical score image, its height and width are H(1 ≤ i ≤ H) and W(W > 64, 1 ≤ j ≤ W), respectively, with pixel (1,1) at the top-left corner of I and pixel (H, W) at the bottom-right corner of I. We use the following binary labeling function:

                        
                           (1)
                           
                              
                                 f
                                 
                                    (
                                    i
                                    ,
                                    j
                                    )
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                1
                                                ,
                                             
                                          
                                          
                                             
                                                if
                                                
                                                pixel
                                                
                                                (
                                                i
                                                ,
                                                j
                                                )
                                                
                                                is
                                                
                                                an
                                                
                                                object
                                                
                                                pixel
                                             
                                          
                                       
                                       
                                          
                                             
                                                0
                                                ,
                                             
                                          
                                          
                                             
                                                if
                                                
                                                pixel
                                                
                                                (
                                                i
                                                ,
                                                j
                                                )
                                                
                                                is
                                                
                                                a
                                                
                                                background
                                                
                                                pixel
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     We denote the MIDI file of the musical score as M, where M is a byte stream. We transform each byte in M into an 8-bit binary code to obtain the watermark data M
                     2. Let Len(M
                     2) denote the length of M
                     2.

The embedding algorithm consists of four steps

                           
                              i.
                              
                                 Select the watermarking area from the GCN musical score image. All of the musical information of a GCN score is located in the central area of a page, because the four page margins of the image are blank spaces or unnecessary information such as page borders (see Fig. 1(1)). Thus, we select only the central area of the image as the watermarking area, such that numbers 1–98 occupy the pixel set in the left sub-figure of Fig. 2.
                                 
                              

It is the expansion of the GCN image, adding two or three pixels in the border of the original GCN image, which avoids the intersection between watermarked region and GCN region, so that the MIDI data can be extracted from the watermarked GCN image.


                                 Prepare the watermark. Our algorithm embeds the watermark by clockwise inward rotation. This entails scanning from left to right at the top of the image (Fig. 2 ①, ⑤), from top to bottom on the right side of the image (Fig. 2 ②), from right to left at the bottom of the image (Fig. 2 ③), and from bottom to top on the left side of the image (Fig. 2 ④). The algorithm begins at the top row of the image from (1,1) to (1,2). If the current bit of M
                                 2 is 1 then the corresponding pixel is an object, otherwise, the pixel is background.


                                 Embed the watermark data. The first 32 pixels of the spiral watermarking area denote “MIDI” in American standard code for information interchange (ASCII), i.e., pixels 1–32 in Fig. 2 are “01001100 01001001 01000100 01001001” to indicate file type “MIDI”. The next 32 pixels specify the length of the MIDI file in ASCII (i.e., pixels 33–64 in Fig. 2 would be “00000000 00000000 00000110 10110000” to signify a file length of 1712 bytes, which is the length of the score in Fig. 1). The binary foreground–background data M
                                 2 are embedded into pixels 65–98 in Fig. 2. For each bit in M
                                 2, let s scan from 1 to Len(M
                                 2), let k denote the order for the spiral embedding process (①–⑤ in Fig. 2), let Dir indicate pixel placement in the watermarking area (i.e., Dir = 1 for a pixel located at the top, Dir = 2 for a pixel on the right, Dir = 3 for a pixel at the bottom, Dir = 4 for a pixel located on the left).

The pixel coordinate (xs, ys
                        ) for sth of M
                        2 was computed as follows:

                           
                              (a)
                              (x
                                 1, y
                                 1) is (1,65) since pixel (x
                                 1, y
                                 1) in the image is first pixel of the spiral watermarking area, it located at the outmost spiral area, the initial value of k is 1, Dir = 1, s = 1.

                                    
                                       Array ADD(4,2) means the change of the position of two adjacent the outmost spiral area for the embedded order, it is initialized as: ADD(1,1) = 0, ADD(1,2) = 1; ADD(2,1) = 1, ADD(2,2) = 0; ADD(3,1) = 0, ADD(3,2) = −1; ADD(4,1) = −1, ADD(4,2) = 0; goto (b).

When Dir = 1, if ys
                                  ≤ W − (k − 1), then xs
                                  = xs
                                 
                                 −1 + ADD(Dir,1), ys
                                  = ys
                                 
                                 −1 + ADD(Dir,2); else xs
                                  = xs
                                 
                                 −1 +1, ys
                                  = ys
                                 
                                 −1, Dir = 2; goto (c).

When Dir = 2, if xs
                                  ≤ H − (k − 1), then xs
                                  = xs
                                 
                                 −1 + ADD(Dir,1), ys
                                  = ys
                                 
                                 −1 + ADD(Dir,2); else xs
                                  = xs
                                 
                                 −1, ys
                                  = ys
                                 
                                 −1 − 1, Dir = 3; goto (d).

When Dir = 3, if ys
                                  > (k − 1), then xs
                                  = xs
                                 
                                 −1 + ADD(Dir,1), ys
                                  = ys
                                 
                                 −1 + ADD(Dir,2); else xs
                                  = xs
                                 
                                 −1 − 1, ys
                                  = ys
                                 
                                 −1, Dir = 4; goto (e).

When Dir = 4, if xs
                                  > (k − 1), then xs
                                  = xs
                                 
                                 −1+ ADD(Dir,1), ys
                                  = ys
                                 
                                 −1+ ADD(Dir,2); else xs
                                  = xs
                                 
                                 −1, ys
                                  = ys
                                  
                                 −1 + 1, Dir = 4, k = k + 1; goto (f).

If s > Len(M2), then finish, else goto (b).

We can thus get the value of a pixel according to its coordinates (xs, ys
                                 ). If the sth pixel of M
                                 2 is 1, then f (xs, ys
                                 ) = 1, otherwise f (xs, ys
                                 ) = 0.


                                 Save the result. We save the embedded MIDI information of I as a new image file I′. Fig. 1(2) shows the embedded result and MIDI data for Fig. 1(1).

The decoding algorithm consists of three steps

                           
                              i.
                              
                                 Verify if the input is a MIDI file. The algorithm scans the top row of I′ and reads pixels 1–32. It converts the 32-bit binary sequence into four bytes to determine if it matches the ASCII for “MIDI”. If there is a match, it continues to (ii), otherwise, it terminates.


                                 Determine file length. The algorithm reads pixels 33–64 of I′ and converts the binary code into bytes. The length of the MIDI file is computed as:
                                    
                                       (2)
                                       
                                          
                                             L
                                             e
                                             n
                                             
                                                (
                                                
                                                   M
                                                   2
                                                
                                                )
                                             
                                             =
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                32
                                             
                                             
                                                
                                                   2
                                                   
                                                      32
                                                      −
                                                      i
                                                   
                                                
                                                ×
                                                
                                                   x
                                                   i
                                                
                                             
                                             .
                                          
                                       
                                    
                                 
                              


                                 Create the MIDI file. The algorithm scans from the first pixel (1, 65) at the top of I′ to the last pixel by clockwise inward rotation. It constructs a binary sequence L of length Len(M
                                 2) then converts this stream to MIDI format with length Len(M
                                 2)/8 bytes.

This algorithm is a spatial domain watermarking process. Reading the watermark does not require the original cover image, thus it is a blind watermarking algorithm. The MIDI format watermark is meaningful and can be perceived by a human being. As shown in Fig. 1(1 and 2), the modified pixels are embedded MIDI information, and they have no effect on the original musical information. As a result, our algorithm is an effective method for the synchronous transmission of a GCN musical score image and its MIDI information. The execution time and storage requirements of the proposed algorithm depend on the length of the input MIDI file and size of the input image, thus, the time complexity and space complexity of the proposed algorithm are linear.

The MIDI data may alter information in the original image (for example, a background pixel of the MIDI data covering an object pixel in the original image). To avoid this situation, we can expand the image outward by the same number of pixels present in the four margins of the original image, so that all of the pixels of the embedding area are background pixels. The expansion algorithm works as follows:

                           
                              i.
                              Let MinDist = H/2, and let ef denote the expanded image;

Scan the original imagef(i, j), 1 ≤ i ≤ H, 1 ≤ j ≤ W, if f(i, j) = 1, it is an object pixel, then:
                                    
                                       (3)
                                       
                                          
                                             M
                                             i
                                             n
                                             D
                                             i
                                             s
                                             t
                                             =
                                             min
                                             
                                                (
                                                
                                                   M
                                                   i
                                                   n
                                                   D
                                                   i
                                                   s
                                                   t
                                                   ,
                                                   i
                                                   ,
                                                   j
                                                   ,
                                                   H
                                                   −
                                                   i
                                                   +
                                                   1
                                                   ,
                                                   W
                                                   −
                                                   j
                                                   +
                                                   1
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              

Let the number of pixels we add in the expansion be EN as:
                                    
                                       (4)
                                       
                                          
                                             E
                                             N
                                             =
                                             L
                                             E
                                             N
                                             
                                                (
                                                
                                                   M
                                                   2
                                                
                                                )
                                             
                                             /
                                             
                                                (
                                                
                                                   H
                                                   ×
                                                   W
                                                
                                                )
                                             
                                             −
                                             M
                                             i
                                             n
                                             D
                                             i
                                             s
                                             t
                                             +
                                             1
                                          
                                       
                                    
                                 
                              

The height and width of the expanded image are
                                    
                                       H
                                       +
                                       2
                                       ×
                                       E
                                       N
                                       and
                                       W
                                       +
                                       2
                                       ×
                                       E
                                       N
                                    
                                 . If the position of a pixel in ef satisfies
                                    
                                       
                                       E
                                       N
                                       +
                                       1
                                       ≤
                                       i
                                       ≤
                                       H
                                       +
                                       E
                                       N
                                       +
                                       1
                                       and
                                       E
                                       N
                                       +
                                       1
                                       ≤
                                       j
                                       ≤
                                       W
                                       +
                                       E
                                       N
                                       +
                                       1
                                    
                                 , then 
                                    
                                       e
                                       f
                                       (
                                       
                                          i
                                          ,
                                          j
                                       
                                       )
                                       =
                                       f
                                       (
                                       
                                          i
                                          −
                                          E
                                          N
                                          ,
                                          j
                                          −
                                          E
                                          N
                                       
                                       )
                                    
                                 ; else 
                                    
                                       e
                                       f
                                       (
                                       
                                          i
                                          ,
                                          j
                                       
                                       )
                                       =
                                       0
                                    
                                 .


                        Fig. 1(3) shows the embedded result for the expanded image of Fig. 1(1) and its MIDI file.

@&#EXPERIMENTAL DESIGN@&#

To examine our algorithm's validity, we used a detailed experimental method. Fig. 3
                      shows the data flow diagram of the algorithm, and a common model of an OMR system. The dashed boxes indicate the focus of our discussion; the three dashed boxes in the data flow diagram of the watermark algorithm were described in Section 2. An image and its MIDI file can be embedded as a MIDI watermarked image; in turn, a MIDI watermarked image can be decoded into an image and a MIDI file. The MIDI file can be recognized from the image or the MIDI watermarked image by using an OMR system. A common model for an OMR system comprises six independent stages: (1) image pre-processing, (2) document image segmentation, (3) feature extraction, (4) musical symbol recognition, (5) musical semantics, and (6) MIDI representation.

An OMR system can recognize an image and its corresponding MIDI watermarked image, yielding a separate MIDI file for each. The two MIDI files may be different; in other words, the embedded watermark influences the result of some part of the OMR system. In particular, pre-processing and image segmentation (the two dashed boxes in Fig. 3) are most affected by watermarking.

Pre-processing involves any of the standard image-processing operations including noise removal, blurring, de-skewing, contrast adjustment, sharpening, binarization, and morphology. Other operations may be necessary to prepare a raw input image for recognition, such as selecting an interest area, eliminating non-musical elements, and correcting image rotation.

Connected-component (CC) labeling is a basic method used to select an area of interest in an image; it is one of the most fundamental operations in pattern recognition. A labeling algorithm transforms a binary image into a symbolic image such that each connected component is assigned a unique label. Various algorithms have been proposed, including the one-scan algorithm [18], two-scan algorithm [19], multi-scan algorithm [20] and parallel algorithm [21], among others [22].

Different images may have different sizes of connected-components; although the heights and widths of two images may be the same, the heights and widths of their CCs are not necessarily the same. Fig. 4
                      shows the number of CCs (Z-axis) for different heights (X-axis) and widths (Y-axis) found in a source image (Fig. 1(1)) and the corresponding MIDI watermarked area image. The left sub-figure shows that Fig. 1(1) has a few larger CCs, despite the dimensions of most of the CCs being small. The right sub-figure emphasizes that the heights and widths of most of the CCs are relatively small, and that the numbers of different heights and widths in the MIDI watermarked area are evenly distributed.

Image segmentation is a key step in an OMR system, especially for a document image such as a GCN musical score. Several document image segmentation methods have been proposed, with the best known being X–Y projection [23], and the run-length smoothing algorithm (RLSA) [24]. A preliminary result of GCN score segmentation is presented in [25], it includes two phases: line–text segmentation and note–line segmentation.

In this work, we used connected-component labeling and a self-adaptive RLSA [26] to analyze the accuracy of the watermarking and expansion algorithms presented above.

@&#EXPERIMENTAL RESULTS@&#

To demonstrate the efficacy of our algorithms, experiments were conducted with randomly selected score images from [1]. Table 1
                         shows basic information about the chosen images, including the number of pages, resolution, number of columns of musical notes, number of connected components, and length of the MIDI file with the corresponding image.

A GCN score typically consists of several columns alternating between Chinese characters and musical notes. The MIDI file of a GCN score includes all of the note columns, so we must consider only those corresponding to musical notes. Table 1 presents the number of musical note columns in each selected image.

@&#RESULTS@&#

Suppose α is the number of connected-components in the original GCN score image I, β is the number of connected-components in the watermark area from the MIDI file, γ is the number of connected-components in the MIDI watermarked GCN score image, and δ is the number of connected components in the MIDI watermarked GCN score image with expanded borders.

The left sub-figure in Fig. 5
                         shows the number of connected components in the 20 selected images (α), their embedded MIDI watermark images (γ) and embedded MIDI watermark images with expanded borders (δ). It shows that the number of connected components in the original image was less than in the watermarked image. The right sub-figure in Fig. 5 shows the number of musical note columns found using the self-adaptive RLSA [26] for the 20 selected images, their embedded MIDI watermark images and embedded MIDI watermark images with expanded borders. It indicates that the number of musical note columns varied between the three types of images.

We used all of the possible pairings of the 20 selected images and the 20 MIDI files to analyze the results of our watermarking and expansion algorithms; the combined results included 400 different watermarked images. In text image segmentation, line or column segmentation is a key phase; thus, we analyzed the change in the number of columns in a score image, and its corresponding watermarked image. The Z-axis of Fig. 6
                         shows the difference in the number of musical note columns between the score image and the corresponding watermarked score image. The columns were determined by using the self-adaptive RLSA [26]. The 20 selected images are represented on the X-axis, while the 20 MIDI files are represented on the Y-axis. The left sub-figure shows the difference in the number of musical note columns in the three images; the total difference was 28 columns. The right sub-figure shows the different musical note column counts between four expanded images and their watermarked pairs, and the total difference was 20. We achieved a higher accuracy rate for the number of musical note columns with the expanded image than with the original image.

We compared the number of connected components in each image type in Fig. 7
                        . The left sub-figure in Fig. 7 shows the difference between the number of CCs found in the 400 watermarked images and the 20 selected images. The right sub-figure in Fig. 7 shows the same information for the 400 watermarked images with expanded borders.

To analyze the expansion algorithm, we expanded the image outward by one pixel in each direction, and calculated the change in the number of CCs. The left sub-figure in Fig. 8
                         shows α + β − γ as the image was expanded, one pixel at a time. When the number of expansions performed was greater than eight, we achieved α + β − γ = 0. This indicates that we effectively avoided information loss with minimal time complexity. The right sub-figure in Fig. 8 shows the number of CCs in the MIDI watermarked images as we expanded them one pixel at a time until we reached 100 expansions; as the corresponding image expanded, the number of CCs increased.

@&#CONCLUSION@&#

In East Asia, ancient musical compositions have been written in GCN for more than 1,000 years. GCN carries a great deal of musical information, and its conservation is very important in the digital age. Musical information can greatly enrich people's lives. This work proposes a technique to transmit a GCN musical score image and its MIDI information synchronously. In this technique, the embedded MIDI information serves to aid in the understanding of the GCN musical information and avoid ambiguity for the reader. This enables the information from the musical score image with embedded MIDI information to be used in modern musical works.

Our algorithm enables efficient synchronous transmission of GCN scores and their associated MIDI information and will thus be instrumental in digitizing and preserving ancient Chinese and East Asian music. We selected 20 GCN musical score images and used OMR to confirm that our system does not damage the integrity of the score. We also examined the difference in the numbers of connected components in the original and watermarked scores for the image expansion algorithm. Our algorithm avoids information loss with minimal added time complexity and improved note extraction accuracy rates.

Our methodology is also suitable for other notations, including CMN and/or numbered musical notation (NMN). Our expansion algorithm can effectively avoid original musical information loss, thus CMN or NMN musical score images can be embedded with MIDI information using our methodology to produce synchronous communication sequence media and image media for musical works.

In our future work, we intend to study some other interesting problems, including the change in the number of CCs between two adjacent pixel by pixel expansions for an image. We will also try to apply our method for other notations such as CMN or NMN using the proposed algorithm, and develop practical software using our methodology.

@&#ACKNOWLEDGMENTS@&#

This work was supported by the Natural Science Foundation of Zhejiang Province (Grant #LY14F020037) in China, the National Social Science Foundation of China (Grant # 14FYS004), the National Science and Technology Support Program of China (Grant # 2015BAK04B00), the Special Project of Science and Technology Accredited Person of Hangzhou (Grant # 20151232I23), in China.

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.compeleceng.2015.11.003.


                     
                        
                           Application 1
                           Image, application 1
                           
                        
                     
                  

@&#REFERENCES@&#


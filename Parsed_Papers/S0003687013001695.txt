@&#MAIN-TITLE@&#Facilitating the comparison of multiple visual items on screen: The example of electronic architectural plan correction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The automatic recognition of technical documents involves a correction by an operator.


                        
                        
                           
                           We compared three displays formats for retroconversion errors detection with architectural plans.


                        
                        
                           
                           Superimposing the plans improves errors correction efficiency compared to separate plans.


                        
                        
                           
                           In addition, the sequential display of the plans improves the completeness of the correction.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Plan correction

Spatial integration

Attentional guidance

@&#ABSTRACT@&#


               
               
                  This paper describes two experiments designed to (1) ascertain whether the way in which architectural plans are displayed on a computer screen influences the quality of their correction by humans, and (2) identify the visual exploration strategies adopted in this type of task. Results of the first “spot the difference” experiment showed that superimposing the plans yielded better error correction performances than displaying them side by side. Furthermore, a sequential display mode, where the second plan only gradually appeared on the screen, improved error search effectiveness. In the second experiment, eye movement recordings revealed that superimposition increased plan comparison efficiency by making it easier to establish coreference between the two sources of information. The improvement in effectiveness in the sequential condition was shown to be linked to the attentional guidance afforded by this display mode, which helped users to make a more thorough exploration of the plans.
               
            

@&#INTRODUCTION@&#

Large volumes of technical documents are currently interpreted automatically not just for archiving purposes, but also so that they can be modified using computer-aided design (CAD) software. These documents include land registry maps (Boatto et al., 1992), architectural plans (Lu et al., 2005; Ahmed et al., 2011), electrical diagrams (Ouyang and Davis, 2009), road maps (Chiang and Knoblock, 2011) and even music scores (Bainbridge and Bell, 2001). The two experiments described in the present paper were part of a collaborative research project to develop retroconversion software capable of interpreting scanned plans and reconstructing them in a format compatible with all the main types of CAD software.
                        1
                     
                     
                        1
                        This software is under development as part of the “MobiSketch” French National Research Agency (ANR) project (ref. 09-CORD-015).
                      Although this research will be generalizable to all types of technical documents, we chose to restrict our experiments to architectural plans. The software under development currently has a 9% retroconversion error rate for simple plans of this nature (Ghorbel et al., 2013). It will therefore be important for users to be able to identify mistakes. In some design activities, such as the creation of architectural plans, professionals often start off by producing a hand-drawn paper sketch (Bilda and Gero, 2006; Manolopoulou, 2005), which is then reconstructed in software, either manually or by means of automatic recognition. Whether we are talking about the manual copying of paper diagrams into CAD software, document retroconversion, or systems intended to beautify hand-drawn sketches of industrial parts (Ku et al., 2006), product designs (Orbay and Kara, 2010) or architectural plans (Elsen et al., 2012), it is vital that users inspect the end product to ensure that the system has not made any errors of interpretation. He must compare the two plans: the scanned plan and the one interpreted by the system. This type of “spot the difference” task, involving the mental integration of two distinct visual sources, raises the question of which is the best display format for ensuring that as many errors as possible are spotted.

The cognitive processing of architects' drawings has been explored from several angles, including their 3D visualization (Yagmur-Kilimci, 2011), the different stages in their production (Bilda et al., 2006; Manolopoulou, 2005), and variations in design strategies according to expertise (Maycock et al., 2009). To the best of our knowledge, however, there has never been any research on the cognitive processes involved in comparing such drawings, the difficulties that may be encountered along the way and the best ways of minimizing them. There have, of course, been a great many studies of the parallel processing of visual information sources in the field of multimedia document comprehension (for a review, see Ginns, 2006). These studies have shown that when a document consists of an image and a text that refer to each other, presenting each chunk of text next to the corresponding area of the image, rather than simply displaying the two side by side, enhances learning performances (e.g., Erhel and Jamet, 2006, 2011; Johnson and Mayer, 2012; Mayer, 2009; Sweller and Chandler, 1994). It is generally assumed that the beneficial effect of this spatial contiguity stems mainly from a reduction in the number of times that the gaze has to travel back and forth between the two sources. This to-ing and fro-ing is widely assumed to hinder individuals by forcing them to hold information in memory (Ayres and Sweller, 2005; Cierniak et al., 2009; Chang et al., 2011). Some authors, however, have claimed that spatial contiguity actually works by making it easier to establish coreference between the visual sources (Erhel and Jamet, 2006, 2011; Holsanova et al., 2008). This claim was recently confirmed by Johnson and Mayer (2012), who used eyetracker measurements to demonstrate that spatial contiguity leads individuals to make more eye movements from the text to the corresponding area of the image (and vice versa) than a separated format does. The principle of spatial contiguity has been extended from learning of text and pictures documents to comparative visual search by Bauhoff et al. (2012).

The research conducted by Kroft and Wickens (2002) on map comparison shed additional light on this subject. In their study, student pilots were shown two maps. One of them indicated the characteristics of the terrain (relief, power lines, etc.), while the other provided information about air traffic and weather conditions. Participants had to answer multiple-choice questions. Some of these questions (e.g., “What is the altitude of plane X?”) only required them to process one of the maps, but others (e.g., “Will plane Y fly over a lake?”) forced them to integrate information across both of them (Kroft and Wickens, 2002). Performances on the latter were better when the maps were superimposed, rather than being displayed side by side. Here once more, the beneficial effect of spatial integration was explained in terms of cognitive cost. Answering a question that concerned both maps involved three processing stages: information searching, reading and mental integration. When the maps were superimposed, the mental integration stage no longer required any cognitive resources (Kroft and Wickens, 2002).

Correcting plans involves not just the comparison of multiple visual sources, but also their visual exploration. However, the nature of this exploration is determined by the image's characteristics and does not necessarily take the form of systematic scanning. When individuals view an image displayed on a screen, for instance, they tend to fixate the centre of that image (Bindemann, 2010) and, more generally, any salient areas (for a review, see Grant and Spivey, 2003; Schütz et al., 2011). There are several methods for guiding the visual exploration of a screen, such as using motion to trigger visual pursuit (Dorr et al., 2010). This type of guidance was used in a study by Nickles et al. (2003), who found that a cursor moving across the screen improved visual search proficiency. According to the authors, it was the guidance afforded by the cursor that led to this improvement, by encouraging a more exhaustive exploration of the image. Tracking down errors in plans relies on precisely this sort of exhaustive exploration. Given that retroconversion software interprets documents one element at a time, one solution would be to use the realtime display of this gradual process to guide attention. This on-screen retroconversion would constitute a form of sequential display. A great deal of research has shown that when a fresh item appears on the screen, it immediately captures the viewer's attention, triggering a saccade to that item and the allocation of processing resources (Abrams and Christ, 2003; Craig et al., 2002; Godijn and Theeuwes, 2002; Hillstrom and Chai, 2006; Ludwig et al., 2008). Furthermore, several studies have reported improved comprehension of a multimedia document when it is displayed sequentially (Bétrancourt et al., 2001; Jamet et al., 2008; Mayer and Chandler, 2001). One explanation for these results is that sequential presentation avoids perceptual and cognitive overload by ensuring that there is never too much information on the screen at any one time. Another is that it ensures that the document is explored in a more coherent order (Bétrancourt et al., 2003; Jamet et al., 2008).

We began by conducting a “spot the difference” pretest, where participants had to compare two plans displayed side by side. The results of the pretest highlighted the inherent difficulty of this task, in that only 33% of participants managed to detect every single error. Research on multimedia documents, albeit ones combining textual and pictorial information, suggests that spatially integrating the two plans would have improved performances (e.g. Ayres and Sweller, 2005; Erhel and Jamet, 2011; Mayer, 2009). Furthermore, as mentioned earlier, Kroft and Wickens (2002) concluded in their study that integration makes it easier to answer questions requiring the combined processing of two maps. These parallels with maps and multimedia documents led us to predict that plan integration would reduce the need to hold information in memory, thereby boosting task effectiveness.
                        2
                     
                     
                        2
                        In accordance with ISO usability standard 9241, efficiency referred to the time it took to complete the task and effectiveness to its successful completion (participants' ability to locate all the errors).
                      Our second prediction was that the attentional guidance effects observed for sequentially presented multimedia documents would also be observed when the second plan in our comparison task only gradually appeared on the screen. We postulated that the sequential display mode would facilitate plan comparison by minimizing the visual search process and proposing an order of exploration which, if the participants adhered to it, ensure that each and every feature of the plan was checked. By making the mistakes easier to spot, it would ultimately improve the effectiveness of the retroconversion software prototype.

This first experiment was administered to 54 participants (19 men and 35 women), students and young professionals, recruited from the basis of voluntary testers of the Observation Laboratory on the uses of information and communication technology (LOUSTIC). The youngest was aged 18 years and 9 months, and the oldest 31 years and 3 months. The participants' mean age was 23 years and 2 months (SD: 38 months).

Participants performed the spot the difference task on an Asus Eee Slate with a 12.1″ screen, examining three different plans interpreted by our retroconversion software prototype. This prototype is capable of recognizing all the different symbols used in hand-drawn plans, but for the purposes of our experiment, it only had to recognize walls, which it showed as black lines, doors (red boxes) and windows (blue boxes). The source document appeared on the screen at the beginning of each test, but participants were not allowed to start circling the errors until the retroconversion process was finished (30–60 s, depending on the plan's complexity). They had to compare three pairs of plans in succession and in one of three experimental conditions. In the separated condition, the hand-drawn plan was displayed on the screen and once the retroconversion process was finished, the retroconverted plan was displayed alongside it, at which point the participants were allowed to circle the errors (Fig. 1
                           ). The integrated condition was very similar to the separated one, in that the retroconverted plan only appeared once it was complete. However, instead of being displayed alongside the hand-drawn one, it appeared on top of it (i.e., superimposed). In the third and final sequential condition, the hand-drawn plan was once more visible from the very outset, but this time participants could watch the retroconversion process take place in realtime, as the retroconverted plan gradually appeared on top of the hand-drawn one. The three plans were the real plans of the three levels of the building wherein there is the LOUSTIC. They were composed respectively of 11, 11 and 33 symbols. The proportion of errors was kept constant relative to the number of symbols and deliberately high so that the difficulty of the task is adequate. They contained respectively 5, 5 and 15 errors.

@&#PROCEDURE@&#

An architectural drawing was displayed on the screen. This drawing was then interpreted by the prototype, and the participants had to circle the interpretation errors on the retroconverted plan with a digital pen. The experimenter emphasized to participants that the system represented the walls as black lines, the doors as red squares and the windows as blue squares. The different types of errors made by the prototype included mistaking a window for a door, a door for a window, and a window or door for a wall. Each participant checked three different plans in the same experimental condition. The order of presentation of these plans was counterbalanced within each of the three experimental groups. We measured plan comparison effectiveness and efficiency.

@&#RESULTS@&#

We only compared task completion times (i.e. efficiency) between the separated and integrated groups, for although participants in the sequential group had to wait for the end of the retroconversion process before they could start circling the errors (exactly like the other two groups), they could nonetheless make a mental note of them beforehand. Accordingly, comparing task durations between the sequential condition and the other two conditions would not have made much sense. We ran Levene's test for homogeneity of variance on the task completion times, showing that homoscedasticity was met, F(1, 32) = .44, p = .51. An analysis of variance (ANOVA) revealed that the task took significantly longer to complete in the separated condition than in the integrated one, F(1, 32) = 13.58, MSE = 2066.42, p = .001 (see Table 1
                        ).

We compared effectiveness in the different conditions by establishing a contingency table summarizing the participants' success or failure on the task. This indicator was chosen because in this type of task, the number of errors which are not identified is nearly always very low. Thus, the variance of the number of errors found is very low too. The likelihood ratio chi-square test showed that there was a statistically significant relationship between the frequency of task success and the display condition, LR(2, N = 52) = 7.127, p = .028. To explore this difference further, we ran a second likelihood ratio test to compare the separated and integrated groups on success frequency. This failed to reveal any significant difference, LR(1, N = 34) = .48, p = .48. A third likelihood ratio test compared the integrated and sequential groups. This revealed that task success was significantly more frequent in the sequential condition, LR(1, N = 35) = 6.66, p = .01 (see Table 2
                        ).

@&#DISCUSSION@&#

In Experiment 1, we predicted that superimposing the plans would help the participants. However, our hypothesis was that the superimposition would improve the effectiveness while the results showed that it improves the efficiency. It took the participants significantly less time to complete the task when the plans were superimposed than when they were displayed separately. Our spot the difference task required participants to establish links between the two plans. In the separated condition, this meant encoding visuospatial information about one of them and holding it in memory until the corresponding area could be located in the other one and the comparison made. It is surprising that the integration improves efficiency but not effectiveness. This result can be explained by the fact that in our study, the time to complete the task was free. Thus, the participants had the option to compensate for their difficulties by spending more time. In contrast, the time of consultation of the documents was limited in the experiments on the spatial contiguity like that of Erhel and Jamet (2011) or that of Mayer and Gallini (1990). Superimposing the plans did away with problems of distance and thus eliminated the stages of visual searching and active storage of visuospatial information, for when the participants in this condition looked at a given spot on the plan, they straightaway had all the information they needed to spot the potential error. This result was coherent both with Wickens' theory (Kroft and Wickens, 2002), whereby the physical integration of two visual sources of information enables individuals to dispense with the mental integration stage.

Our second prediction was that the sequential display of the interpreted plan would improve the participants' and thus the prototype's effectiveness. Once again, this prediction was validated by the results, as more errors were located in the sequential condition than in the integrated one. We assumed that this difference was an effect of attentional guidance, for if participants chose to explore the plan in the order in which it appeared, they could be sure of checking the whole plan, which was not necessarily the case in the two static conditions.

We based our interpretation of the results for this first experiment on the assumption that findings for multimedia documents could be extended to the comparison of complex visual sources. Plan comparison has much in common with the experiments conducted by Sweller and Chandler (1994), Erhel and Jamet (2011), and even Mayer and Chandler (2001), but it also differs in two important respects. First, these experiments focused on textual and pictorial content. Second, the aim of the participants in these studies was to learn the content of the documents. For both these reasons, we felt it was important to test our interpretations by conducting a rerun of same experiment, but this time with the addition of eye movement recordings.

The first experiment enabled us to demonstrate that both plan superimposition and sequential display make it easier to spot mistakes. The second experiment replicated the first one, but this time, an eyetracker was used to gain a more detailed understanding of the data. The shorter task duration we observed in the integrated condition, compared with the separated condition, had two possible explanations. The first (Hypothesis 1) was that the participants wasted time due to ineffectual coreferencing. In measurement terms, this hypothesis led us to predict that more time would be spent looking at error-free areas than at ones with potential errors in the separated condition, compared with the integrated one. The second (Hypothesis 2) was that participants in the separated condition had to hold information in memory while they were making the comparisons, which was more time-consuming. This hypothesis led us to predict that total error fixation times would greater in the separated condition than in the integrated one.

We attributed the more accurate pinpointing of errors in the sequential condition in Experiment 1 to attentional guidance (Hypothesis 3), postulating that the staggered display of items on the screen (Abrams and Christ, 2003; Craig et al., 2002; Godijn and Theeuwes, 2002; Hillstrom and Chai, 2006; Ludwig et al., 2008) encouraged participants to follow a set order of exploration that ensured that all the potential sources of error were checked. We therefore predicted that more errors would go unchecked in the integrated condition than in the sequential one.

A total of 54 volunteers (23 men and 31 women) took part in this second experiment. As in the first experiment, the participants were students and young professionals recruited from the basis of voluntary testers of the Observation Laboratory on the uses of information and communication technology. The youngest was aged 18 years and 6 months and the oldest 29 years and 8 months. The participants' mean age was 23 years and 5 months (SD: 31 months).

The experimental conditions were the same as in Experiment 1 (separated, integrated and sequential). The only difference was that we recorded eye movements during the task with a Tobii T60 eye-tracker (Stockholm, Sweden) integrated in a 17-inch TFT monitor with a maximum resolution of 1280 × 1024 pixels. This non-touch material means that instead of circling the errors with a digital pen, participants used a computer mouse.

@&#PROCEDURE@&#

As in Experiment 1, participants were asked to circle any retroconversion errors they spotted in the architectural plans. Each participant examined the same three plans as in Experiment 1, in one of the same three experimental conditions. The order of presentation of the three plans was counterbalanced within each experimental group. We measured task duration and task success. These plan comparison measures were supplemented by recordings of the participants' eye movements during the task.

@&#RESULTS@&#

We ran Levene's test for homogeneity of variance on the task completion times, showing that homoscedasticity was met, F(1, 32) = .040, p = .842. As in Experiment 1, an ANOVA on task duration by condition revealed a significant difference between the separated and integrated conditions, F(2, 48) = 11.68, MSE = 2847.40, p = .013 (see Table 3
                           ).

A likelihood ratio chi-square test highlighted a statistically significant relationship between task success frequency (see Table 4
                           ) and condition, LR(2, N = 51) = 10.55, p = .005. To explore this difference further, we ran a second likelihood ratio test to compare the separated and integrated groups on success frequency. This failed to reveal any significant difference, LR(1, N = 34) = .425, p = .515. A third likelihood ratio test comparing the integrated and sequential groups revealed that task success was significantly more frequent in the sequential condition, LR(1, N = 35) = 9.808, p = .002. Results for task duration and success were similar to those in Experiment 1.

As a Levene's test on error fixation times revealed that homoscedasticity was not met, F(1, 32) = 3.35, p = .076, we tested the effect of integration on total error fixation times by means of the nonparametric Mann–Whitney U test. This test failed to reveal any significant difference in total error fixation times between the separated and integrated conditions, U = 141.5, p = .931 (see Table 5
                           ). Levene's test on total fixation times on the error-free areas showed that homoscedasticity was met, F(1, 32) = .038, p = .847. We therefore ran an ANOVA to test the effect of integration on these total fixation times. This revealed that fixation times on error-free areas were significantly longer for the separated group than for the integrated one, F(1, 32) = 11.45, MSE = 1653.68, p = .002. As an indication, the mean number of times the participants' gaze travelled to and fro between the two plans in the separated condition was 63.9 (SD = 23.97), that is, one back-and-forth eye movement every 3.75 s on average. To briefly check if there was an attentional guidance in the sequential group, we considered that when a symbol was fixed within a second after it appeared, it was an attentional capture. With this indicator, we found that the guiding was very common (86% on average) for all participants in the sequential group (66.7% minimum and 100% maximum).

The eyetracker measurements enabled us to distinguish between those participants who visually checked all the potential sources of errors and those who skipped some of them. In order to compare the numbers of participants who checked all the error zones in each group, we calculated a likelihood ratio chi-square test, which revealed a statistically significant difference between the groups, LR(2, N = 51) = 6.37, p = .041 (see Table 6
                           ). To explore this difference in greater depth, we ran a second likelihood ratio test comparing total error-checking frequency between the separated and integrated groups. This test failed to reveal any significant difference, LR(1, N = 34) = .133, p = .715. A third likelihood ratio test comparing the integrated and sequential groups revealed that total error checking was significantly more frequent in the sequential condition, LR(1, N = 35) = 4.20, p = .040.

@&#DISCUSSION@&#

Experiment 2 replicated the first experiment described above, with the addition of eye movement recordings. Results confirmed those of Experiment 1, as once again spatial integration (superimposed plans) improved efficiency and sequential display improved effectiveness.

The first hypothesis tested in Experiment 2 was that coreference is harder to establish when plans are displayed side by side. Results confirmed this hypothesis, as mean total fixation times on error-free zones were longer in the separated condition than in the integrated one. This result showed that, on average, the reduction in task duration in the integrated condition stemmed from a reduction in the amount of time spent on coreferencing rather than in the time spent processing the errors. We can therefore conclude that the negative impact of spatial distance on coreferencing signalled by Johnson and Mayer (2012) can also be observed in the plan comparison situation. One explanation for this is that participants in both studies had to establish coreference between different items of information by looking back and forth. This visual to-ing and fro-ing necessarily resulted in unintentional fixations outside the potential error zones, thus wasting valuable time. We can assume that this problem is not inherent to architectural plans, but instead stems from a situation where two visual sources displayed side by side have to be compared area by area. Opting for a side-by-side display in a comparison task of this kind therefore implies that some of the participants' time will be taken up by the visual adjustments needed to perform the coreferencing between the subcomponents.

Hypothesis 2 was that error zones are fixated for longer when plans are displayed separately rather than being superimposed, as the need to hold comparison information in memory while looking back and forth slows processing down. However, as there was no significant difference in fixation duration between these two conditions, this second hypothesis was not validated. The reduced efficiency in the separated condition does not, therefore, appear to have stemmed from a slowdown in the comparison process, although as we did not measure participants' mental load during the task, we cannot totally rule this possibility out.

The third hypothesis of Experiment 2 was that effectiveness is greater with a sequential display, as the resulting attentional guidance gives individuals an opportunity to systematically check all the potential errors. This hypothesis was validated by results, as significantly more participants in the sequential group visually checked all the error zones. The static integrated format prevented participants from adopting an organized exploration strategy and thus exposed them to the risk of omitting some of the potential errors. In the sequential condition, the potential errors were displayed on the screen one by one. Each time, their appearance generated attentional capture (Hillstrom and Chai, 2006; Ludwig et al., 2008) and they were thus more likely to be checked than they would have been in the integrated condition.

The two experiments described here concerned the display of information on a computer screen by software developed to automatically recognize architectural plans. Nevertheless, the conclusions reached here are not specific to this type of content and apply to other software tools designed to recognize technical documents such as electrical diagrams (Lee, 1992) and even music scores (Bainbridge and Bell, 2001). The retroconversion of these types of documents is not a totally error-free process. For this reason, it is vital for humans to compare the automatic interpretation with the source. How efficient and effective this comparison is depends mainly on the way in which the information is displayed on the screen. This presentation should promote coreferencing and the exhaustive exploration of the documents. During this human inspection phase, we therefore recommend superimposing the interpretation and the initial document in order to promote more efficient correction. Furthermore, displaying the interpretation as it unfolds in realtime can improve inspection effectiveness. It should be noted that a sequential display does not impose any particular constraints on users who, for reasons of organization, find it more convenient to carry out a posteriori checks.

The main result of these two experiments is that it is easier to compare complex visual sources if these sources are superimposed and if one of them appears only gradually on the screen. According to Cierniak et al. (2009), the difficulty of learning from separate but mutually referring sources arises from the need to hold information in memory, which reduces the amount of cognitive resources available. However, the results of Experiment 2 do not allow us to conclude that this is why error processing took longer in the separated condition. This non-result may be related to the small amount of information that had to be retained. In the study conducted by Cierniak et al. (2009), the split-source format meant that textual information had to be retained while the picture was explored, whereas for the comparison of the two plans, participants could “get away with” retaining just one item of information at a time, corresponding to one type of feature (door, window or wall). The results reported by these authors may therefore have reflected the sheer volume and complexity of the textual information referring to each area of the picture. Nonetheless, our failure to measure cognitive load during the plan comparison task means that we are unable to reach any firm conclusions on this point.

In Experiment 2, participants spent longer fixating on error-free areas in the separated condition than they did in the integrated one, reflecting coreferencing difficulty. This difficulty, characterized by more visual searching, is not restricted to error-finding tasks, nor indeed to architectural plans, but rather to the processing of separate but mutually referring sources, and we would therefore expect to observe it in experiments exploring the effect of spatial contiguity on the learning of multimedia documents. The studies conducted by Johnson and Mayer (2012) and Holsanova et al. (2008), both of which were supplemented by eyetracking measurements, showed that bringing mutually referring items closer together increases the number of direct eye movements between these items. The authors explained these results in terms of easier coreferencing, insofar as participants more readily realize that a given pictorial item of information is linked to a textual item if the two are close together.

The results of Experiment 2 suggest that the positive effect of sequential display on error-finding effectiveness was due to a more exhaustive exploration of the plans, made possible by attentional guidance. We can postulate that in a sequential display, each new element that appears on the screen captures the participants' attention, thus prompting checking behaviour. A dot moving across a static plan, or salient (e.g., flashing) stimuli to highlight each item in turn would probably have yielded similar results. It should be noted that user interventions during the actual retroconversion process would provide the recognition system with feedback, thus resulting in fewer and fewer errors (Ghorbel et al., 2012). This more cooperative approach to plan correction would mean giving users the ability to halt the retroconversion process, which might in turn obviate the need for them to retain the errors they had identified until the end of the recognition process. Future research is needed to investigate this possibility.

The results of the two experiments described here have yielded several concrete recommendations for designing the interfaces of CAD, retroconversion and beautification software. The first clear result was that superimposing the plans reduced the time it took to compare them – a finding that has practical implications for software development. To deal with situations where professionals (e.g., architects) manually transfer hand-drawn sketches to computers, CAD software could include a function whereby the digitized document was superimposed on the transferred version. Similarly, in the case of software intended for the retroconversion of technical documents (telephone networks, architectural plans, land registry maps, etc.), the interpreted representation of the document and the digitized document could be superimposed in order to make it easier to spot and correct the system's errors. Even the beautification of hand-drawn documents (e.g., design of industrial parts) involves a risk of error and therefore requires the user to check for mistakes. Once again, corrections would be easier to make if the beautification software displayed the end result on top of the hand-drawn sketch. The second result of our two experiments was that gradually revealing the interpreted symbols, rather than displaying the entire representation all in one go, made it easier for the human correctors to pinpoint mistakes, by guiding their inspection. Given the increasing numbers of software tools on the market for retroconverting technical documents, it is important to ensure that they include a feature that enables the retroconversion process to be viewed as it unfolds in realtime, in order to pick up any errors as it goes along.

The present study had several limitations. First, the participants were all novices when it came to processing architectural plans. An expert population would doubtless have displayed greater correcting efficiency and might spontaneously have adopted more effective exploration strategies. Therefore, it is possible that some expert users do not benefit from the positive effects of sequentiality. However, the sequential presentation happens during a computer processing time that would exist anyway. It can be ignored by the users who would prefer directly verify the interpretation completed. Second, in the final version of the software, instead of just signalling the errors, users will directly correct them, meaning that they will also have to select the correct feature. As well as possibly increasing task difficulty, this extra stage involving specific cognitive processing will raise fresh questions about how the information is best displayed on the screen with more interactive systems.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A Time Flexible Kernel framework for video-based activity recognition

@&#HIGHLIGHTS@&#


               
                  
                     
                        
                           
                           TFK: a kernel framework between arbitrary length sequences.


                        
                        
                           
                           Some complex activities are defined by the order of sub-actions.


                        
                        
                           
                           The new kernel framework improves results in complex activities recognition.


                        
                        
                           
                           Combination of several levels of granularity in temporal divisions reduces clutter.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Activity recognition

Soft-assignment

Kernel methods

Support Vector Machine

@&#ABSTRACT@&#


               
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Significant research effort has been invested in video-based activity recognition during the last few years, supported by the widespread availability of video cameras, as it may benefit many applications such as video indexing, surveillance or entertainment.

A video is a sequence of frames that can be viewed as a 3-dimensional matrix of pixels, two dimensions provide the space localization and the third one is related to time. When displayed in a screen, as a sequence of images, humans are able to easily distinguish among activities, but the same task is extremely challenging for a computational method. The machine learning community has suggested several approaches with their advantages and disadvantages, but results in unconstrained recordings are still far from what humans may achieve.

The design of sophisticated low-level descriptors [1,2,3] has been central in recent advances for this research challenge. Specifically, space-time feature codification has been present in the state-of-the-art approaches where video sequences are represented by a Bag of Features (BoF) or a Fisher Vector (FV), encoding the extracted features. The recognition process is carried out afterwards by applying a multi-class Support Vector Machine (SVM) [4], which takes advantage of the kernel trick. Despite the promising performance of these approaches there are two drawbacks due to the characteristics of the descriptors: (i) using image or short-term descriptors, the lack of explicit temporal information withhold them from reliable recognition of activities [5], and (ii) mid-term descriptors may describe better the activities [6] but still lack of information of the whole temporal structure making them unreliable for complex activities where the order of sub-actions describes the activity.

On the other hand, some state space models such as Hidden Markov Models (HMM) [7] or more recent Conditional Random Fields [8], codify the long term temporal information of the sequences. Although they have provided satisfactory results in human activities they usually work in constrained scenarios such as ones implied by the datasets KTH, Weizmann or UT-Tower, where there is no camera motion and the point of view is fixed [9,10,11]. Thanks to these restrictions it is possible to train states encompassing common characteristics among the videos and thus to achieve high accuracy. However, new databases, such as HMDB51, UCF50, OlympicSports and Virat Release 2.0 have been produced aiming at challenging tasks, such as indexing events in unconstrained videos in the internet or surveillance in uncontrolled scenarios performing a scene-independent learning and recognition. These datasets were recorded in unconstrained environments with random viewpoints, camera movements and/or dynamic changes in the background.

Some of the best results in these challenging benchmark datasets have been obtained with variations of the mentioned SVM approach [12,4,6], which has been proven to be a convenient method in spite of the lack of long-term dynamic information. Nevertheless, the long-term temporal information is important in the description of complex activities and thus, we propose the recognition framework depicted in Fig. 1
                      where such information is maintained. Both BoF and FV create a codebook, the former using k-means clustering of the training descriptors and the latter using an EM-GMM algorithm. Following the application of sliding frame-windows, each video is modelled as a sequence of BoFs or FVs. The use of a window with few frames produces sparse data so we minimize its effect by using a soft-assignment approach when using BoFs. These sequences preserve the long-term dynamic information needed for the recognition of complex activities. However, as the sequences length and the pace of actions are variable, standard kernels obtained between vectors of the same length are not applicable and novel approaches, like Spatio-Temporal Pyramid Matching (STPM) [13], keep the long-term information, but they rely on perfect alignment of the sequences with regular pace of actions. Nevertheless, it is worth noting the improvement achieved using several encoding scales, proposed in STPM, that we also apply into our work. So, our contribution in this paper includes the design of a novel kernel formulation between arbitrary length sequences that allows the use of the long-term dynamic information in a SVM with matching flexibility, named Time Flexible Kernel (TFK). In order to validate our contribution we have carried out several experiments in four challenging datasets: HMDB51, UCF50, OlympicSports and Virat Release 2.0.

The rest of the paper is divided as follows. Section 2 reviews some related works. Section 3 explains the proposed framework, focusing on our two main technical contributions: a novel encoding scheme and the Time Flexible Kernel, as well as its application for activity recognition. Section 4 presents our experimental validation and Section 5 concludes the work.

@&#RELATED WORK@&#

Feature extraction is a key element in recognition systems thus a significant number of methods have been proposed. Descriptors can be divided into global and local or low-level features, however, the former group is sensitive to noise, occlusions and viewpoint variations that can be experienced in challenging datasets such as HMDB51, UCF50, OlympicSports and Virat Release 2.0. Therefore, researchers have mainly focused on local descriptors that can be roughly categorised as: (i) image descriptors like SIFT, HOG, Harris, which lack any kind of time information or (ii) space-time descriptors like their extensions 3D-SIFT [2], HOG3D [3] and spatio-temporal Harris interest points [1]. Some descriptors of the latter group are designed so to capture directly the video information as Motion Interchange Patterns (MIP) [5], HOG-HOF [14] or SCISA [15] do. Most of the approaches use holistic encoding based on BoF or FV to derive a vector for each video sequence. Then, SVM is used for multi-class classification, either using a one-against-one approach or a one-against-all approach for multi-class recognition. Until recently, BoF has been the standard approach in video encoding, quantizing the feature vectors into a predefined codebook. However, recent works [6,4] have adopted the strategy of encoding the feature information into a FV which keeps second-order information in relation to an estimated Gaussian Mixture Model (GMM). Alternatively to the above framework, Can and Manmatha [16] modify the SVM strategy to a ranking problem obtaining encouraging results. Finally, Dense Trajectories [17,18] and the actual state of the art in many benchmarks Improved Dense Trajectories (IDT) [6] are based on short trajectories of local descriptors within a sliding temporal window.

The activity encoding methods such as BoF and FV require a “visual word” dictionary. Usually, such a dictionary is created using clustering of the extracted features in the training examples. In the case of BoF every feature is roughly assigned to a word of the dictionary. However, quantization errors are caused, when only a small amount of samples are used, as in the case of the use of a narrow temporal window. Soft-assignment approaches have been proposed to deal with this problem [19,20,21]. Alternatively, FV models the codebook as a GMM and the encoding produces a vector of K(2d
                     +1) dimensions, K is the number of Gaussians and d is the dimension of descriptors, where second order information of the GMM is used [4,6]. However, the main drawback of both approaches is that the long-term temporal information is lost since the encodings are obtained from an unordered collection of local descriptors.

Many approaches have been designed to account complex temporal structures recognizing complex human activities defined as composite multimedia semantics (e.g., birthday party, wedding ceremony) where orderless sub-actions appear in the video. These approaches consider the order of sub-actions as a distracter (not a discriminant) and hence they perform an alignment of similar sub-scenes disregarding their order. For instance Xu et al. [22] divide the clips into sub-clips which later are matched with other sequence using the earth mover's distance (EMD). Cao et al. [23] have designed a kernel that makes a pooling of the frames into a fixed number of scenes called Scene Alignment Pooling (SAP). In [24] a detection of sub-scene categories and a global scene category are combined in a Multiple Kernel Latent SVM where several features are used. In the work of Li et al. [25] the proposed method identifies the most representative segments of the actions using a dynamic pooling with a latent variable.

As opposed to the previously explained works, the temporal order of the sub-actions performed in an activity is considered essential in this paper, as the objective is to distinguish between complex activities that can be composed of the same sub-actions but in different order, even opposite as for instance “Getting Out of Vehicle” and “Getting Into Vehicle” in Virat dataset, Fig. 2
                     .

Thanks to the kernel trick the SVM can classify in a dimensional space different from the original one where samples may be linear-separable. The standard kernel methods assume a fixed length D-dimensional vector per sample which is projected into a different space where the inner product is performed. However, this is not straightforward in activity recognition videos where the long-term activity dynamic information remains in the encoding because lengths of sequences may be arbitrary. Two solutions have been proposed in the literature: (i) obtaining some sort of inner product by aligning the sequences lengths of the patterns, as Dynamic Time-Alignment Kernel [26] or Fast Global Alignment Kernel [27] do and (ii) training a HMM with a single sequence and posterior obtaining a Probability Product Kernel (PPK) [28] like in [29]. Both solutions have been used in sequence clustering tasks [30,29,31]. Sequence alignment enforces a common start and end in the sequences which is not always the case. On the other hand, the PPK of HMMs implies that each HMM is trained with only one sequence which does not offer sufficient information to train properly the parameters of a complex model. Moreover, the optimization process in the HMM training is performed with the Baum-Welch algorithm which only assures a local optimum.

The long-term temporal information has been used in some other methods. A recent one is the extension of the work of Spatial Pyramid Matching (SPM) [32] called Spatio-Temporal Pyramid Matching (STPM) [13]. The method suggests dividing the videos into equal number of spatio-temporal volumes at several scales, called pyramids, computing in each volume a BoF, and finally obtaining a similarity between two video clips by comparing the corresponding volumes. Fixing the number of divisions and comparing volumes one-to-one constrain the method to regular paced actions losing flexibility. In [33] they encode each video into a 3D histogram with spatio-temporal information and design a specific kernel for the 3D histogram, but their pairwise feature comparison is not suitable for dense features extraction which recently has provide the state-of-the-art results. Using HMM, the authors of [34] propose to learn the temporal structure, including latent variables that determine the expected time to stay in a state. Todorovic [35] keeps the long-term information using graph models of the video foreground and with a Kronecker product constructs a Kronecker graph model per action class used in the classification. In [36] the sequences length is not constrained and the authors use a framework where appearance and temporal position of motion segments is included, however, due to high computational load, their learning process finds a local optimum.

As pace of actions is unknown and the alignment performed by the segmentation can introduce some errors, our approach improves the previous methods by introducing some flexibility in the kernel framework that compensates in some degree these errors. The framework allows arbitrary length vectors in the kernel, and as the SVM training is a convex optimization problem it finds a global optimum.


                     Fig. 3
                      summarises our proposed framework for activity recognition and compares it to the standard approach. Specifically, it assumes a pipeline of feature extraction and clustering, video encoding using BoF or FV, applying kernel and finally using multi-class SVM. The contribution of our framework is twofold: First, the video encoding method that produces multiple encodings that preserve temporal information, as described in Section 3.1. Second, the Time Flexible Kernel that allows comparison of vectors of different lengths, as described in Section 3.2. Section 3.3 discusses the application of the novel framework on activity recognition.

We have designed an encoding that maintains the temporal information of sequences. In Fig. 3 we can compare the standard approach (up) and our encoding method (down). There is a common stage of features extraction and codebook generation by clustering, but the video is represented differently. Our proposal keeps temporal information by computing the FV or BoF on sliding frame-windows on the video. The width of the window is w
                        
                           K
                         frames and it is displaced w
                        
                           D
                         frames each time.

A limitation may be introduced because of the width of the window, as the narrower the window the sparser the data used for encoding. In the case of BoF a descriptor is commonly assigned to the closest cluster which is a rough assignation because much of the spatial information in the descriptors space is lost. FV, on the other side, keeps information related to the mean and variance of each cluster which addresses this limitation. Soft-assignment has been proven a good improvement representing continuous data with a codebook model [19] and then in order to cope with the BoF limitation a soft-assignment is proposed. Specifically, first the relative distance between a descriptor S and a cluster centroid c
                        
                           i
                         in relation to the nearest cluster centroid is obtained. 
                           
                              (1)
                              
                                 
                                    
                                       d
                                    
                                    ˜
                                 
                                 
                                    
                                       S
                                       ,
                                       
                                          
                                             c
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       d
                                       
                                          
                                             S
                                             ,
                                             
                                                
                                                   c
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             min
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             d
                                             
                                                
                                                   S
                                                   ,
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

But, instead of performing a hard-assignment (one for the closest cluster and zero for the rest), a soft-assignment is applied as follows: 
                           
                              (2)
                              
                                 
                                    
                                       s
                                    
                                    ˜
                                 
                                 
                                    
                                       S
                                       ,
                                       
                                          
                                             c
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   
                                                      
                                                         d
                                                      
                                                      ˜
                                                   
                                                   
                                                      
                                                         S
                                                         ,
                                                         
                                                            
                                                               c
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       β
                                    
                                 
                                 .
                              
                           
                        
                     

We assure that maximum value of 
                           
                              
                                 s
                              
                              ˜
                           
                           
                              
                                 S
                                 ,
                                 
                                    
                                       c
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           =
                           1
                         is for the closest cluster while smaller values are assigned for more distant centroids. Also, high values of β approximate to the hard-assignment, which is achieved when β →∞.

Finally, we obtain a sequence 
                           x
                           =
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       N
                                    
                                 
                              
                           
                        , being 
                           
                              
                                 
                                    
                                       x
                                    
                                    ¯
                                 
                              
                              
                                 i
                              
                           
                         a D-dimensional vector. In the case of BoF D is the number of clusters in the codebook, while in the case of FV, where soft-assignment is not used, D
                        =
                        K(2d
                        +1), as discussed in Section 2.

In the standard approach we have a fixed size D-dimensional vector per video so only standard kernels (linear, polynomial, RBF, χ
                        2, ...) may be applied before using a multi-class SVM. In contrast, our encoding produces arbitrary length sequences of vectors and therefore our novel formulation of a kernel between sequences of different length is applied.

Having two sequences 
                           x
                           =
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       N
                                    
                                 
                              
                           
                         and 
                           y
                           =
                           
                              
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       M
                                    
                                 
                              
                           
                         we define the function space Γ : ℝ→ℝ
                           D
                         where F,G ∈ Γ:


                        
                           
                              (3)
                              
                                 F
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       f
                                    
                                    
                                       i
                                    
                                 
                                 (
                                 t
                                 )
                                 
                                    
                                       
                                          
                                             
                                                x
                                             
                                          
                                          ‾
                                       
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 G
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                       =
                                       1
                                    
                                    
                                       M
                                    
                                 
                                 
                                    
                                       g
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 
                                    
                                       
                                          
                                             
                                                y
                                             
                                          
                                          ‾
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                           
                        with 
                           
                              
                                 
                                    
                                       x
                                    
                                    ¯
                                 
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 
                                    
                                       y
                                    
                                    ¯
                                 
                              
                              
                                 j
                              
                           
                           ∈
                           
                              
                                 R
                              
                              
                                 D
                              
                           
                        . We link each vector element with a specific function f
                        
                           i
                        ,g
                        
                           j
                         : ℝ→ℝ used to introduce the temporal position of each element. These functions weigh each sequence element according to variable t.

The TFK is then defined as: 
                           
                              (5)
                              
                                 
                                    T
                                    F
                                    K
                                 
                                 (
                                 F
                                 ,
                                 G
                                 )
                                 =
                                 
                                    
                                       ∫
                                    
                                    
                                       t
                                    
                                 
                                 F
                                 
                                    
                                       
                                          
                                             t
                                          
                                       
                                    
                                    
                                       T
                                    
                                 
                                 G
                                 
                                    
                                       t
                                    
                                 
                                 d
                                 t
                                 .
                              
                           
                        
                     

With the aim of demonstrating that TFK is indeed a kernel we reorder the equation:


                        
                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             T
                                             F
                                             K
                                          
                                          (
                                          F
                                          ,
                                          G
                                          )
                                       
                                       
                                          =
                                          
                                             
                                                ∫
                                             
                                             
                                                t
                                             
                                          
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                t
                                                )
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                         
                                                         ‾
                                                      
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      T
                                                   
                                                
                                             
                                          
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                M
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      g
                                                   
                                                   
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                
                                                   
                                                      
                                                         
                                                            
                                                               y
                                                            
                                                         
                                                         ‾
                                                      
                                                   
                                                   
                                                      j
                                                   
                                                
                                             
                                          
                                          d
                                          t
                                       
                                    
                                    
                                       
                                       
                                          =
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                M
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∫
                                                   
                                                   
                                                      t
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            f
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      (
                                                      t
                                                      )
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            g
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      (
                                                      t
                                                      )
                                                   
                                                
                                                d
                                                t
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     x
                                                                  
                                                               
                                                               ‾
                                                            
                                                         
                                                         
                                                            i
                                                         
                                                         
                                                            T
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     y
                                                                  
                                                               
                                                               ‾
                                                            
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                M
                                             
                                          
                                          
                                             
                                                K
                                             
                                             
                                                S
                                                T
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      i
                                                   
                                                
                                                
                                                   
                                                      t
                                                   
                                                
                                                ,
                                                
                                                   
                                                      g
                                                   
                                                   
                                                      j
                                                   
                                                
                                                
                                                   
                                                      t
                                                   
                                                
                                             
                                          
                                          
                                             
                                                K
                                             
                                             
                                                L
                                                I
                                                N
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                         
                                                         ‾
                                                      
                                                   
                                                   
                                                      i
                                                   
                                                
                                                ,
                                                
                                                   
                                                      
                                                         
                                                            
                                                               y
                                                            
                                                         
                                                         ‾
                                                      
                                                   
                                                   
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

To prove that Eq. (6) represents a kernel, we follow several steps. First we check whether K
                        
                           ST
                         and K
                        
                           LIN
                         inside the summation are indeed kernels. The linear kernel, K
                        
                           LIN
                        , is well known. On the other hand, to assure that the structural kernel, K
                        
                           ST
                        , is a kernel we impose the following initial conditions on f
                        
                           i
                         and g
                        
                           j
                        : First, they should be square integrable, so 
                           
                              
                                 ∫
                              
                              
                                 t
                              
                           
                           
                              
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             i
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 
                              
                              
                                 2
                              
                           
                           d
                           t
                         and 
                           
                              
                                 ∫
                              
                              
                                 t
                              
                           
                           
                              
                                 
                                    
                                       
                                          
                                             g
                                          
                                          
                                             j
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 
                              
                              
                                 2
                              
                           
                           d
                           t
                         are well defined (not infinity). Second, f
                        
                           i
                        (t),g
                        
                           j
                        (t) ≥ 0,∀t. Thus, f
                        
                           i
                        (t) and g
                        
                           j
                        (t) belong to the Hilber-space L
                        2, hence the kernel is semi-positive definite [28].

We still need to prove that the summation of these kernels is a kernel. In this regard, we proceed with the following steps: First, we extend the vector representing the shortest sequence with zeros. Without loss of generality, let's assume that N > M, so we extend 
                           
                              
                                 
                                    
                                       y
                                    
                                    ¯
                                 
                              
                              
                                 j
                              
                           
                         in such a way that 
                           
                              
                                 
                                    
                                       y
                                    
                                    ¯
                                 
                              
                              
                                 j
                              
                           
                           =
                           
                              
                                 0
                              
                              ‾
                           
                         for j > M and we can use any function g
                        
                           j
                        (t) for j > M that fulfil the initial conditions. We also denote 
                           
                              
                                 x
                              
                              
                                 i
                              
                              
                                 p
                              
                           
                         the p-th component of the 
                           
                              
                                 
                                    
                                       x
                                    
                                    ¯
                                 
                              
                              
                                 i
                              
                           
                         vector, and the N-dimensional vector 
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                    
                                    ^
                                 
                              
                              
                                 p
                              
                           
                           =
                           (
                           
                              
                                 x
                              
                              
                                 i
                              
                              
                                 p
                              
                           
                           ,
                           i
                           =
                           1
                           ⋯
                           N
                           )
                        . Then, we develop the scalar product in Eq. (6) as: 
                           
                              (7)
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       p
                                    
                                 
                                 K
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             t
                                          
                                       
                                       ,
                                       
                                          
                                             g
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             t
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       p
                                    
                                 
                                 )
                                 (
                                 
                                    
                                       y
                                    
                                    
                                       j
                                    
                                    
                                       p
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       p
                                    
                                 
                                 
                                    
                                       (
                                       (
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                
                                                ^
                                             
                                          
                                          
                                             p
                                          
                                       
                                       )
                                       )
                                    
                                    
                                       T
                                    
                                 
                                 
                                    K
                                 
                                 (
                                 
                                    
                                       
                                          
                                             
                                                y
                                             
                                          
                                          ^
                                       
                                    
                                    
                                       p
                                    
                                 
                                 )
                              
                           
                        where K is a N
                        ×
                        N matrix K
                        
                           i,j
                        
                        =
                        K (f
                        
                           i
                        (t),g
                        
                           j
                        (t)). The matrix K is a positive semidefinite matrix, since it corresponds to a kernel in the space of functions. Thus, each of the addends in Eq. (7) is a kernel in a subspace, and the sum of kernels in all the subspaces is also a kernel in the global space [37].

As 
                           
                              
                                 
                                    
                                       x
                                    
                                    ¯
                                 
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 
                                    
                                       y
                                    
                                    ¯
                                 
                              
                              
                                 j
                              
                           
                         are vectors in an arbitrary ℝ
                           D
                         space, we can consider any projection of them in a different ℝ
                           S
                         space obtaining 
                           ϕ
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           ,
                           ϕ
                           
                              
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                           
                        . Then, we can consider any kernel 
                           K
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                           
                         as a linear kernel in the projected space 
                           
                              
                                 K
                              
                              
                                 L
                                 I
                                 N
                              
                           
                           
                              
                                 ϕ
                                 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                ¯
                                             
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 ,
                                 ϕ
                                 
                                    
                                       
                                          
                                             
                                                
                                                   y
                                                
                                                ¯
                                             
                                          
                                          
                                             j
                                          
                                       
                                    
                                 
                              
                           
                         so, in the previous proof, the linear kernel can be substituted by any arbitrary kernel.

In a real world application there are video sequences with variable lengths, and the recording or segmentation of the same event classes is not perfect and then they might start and end in different positions. This implies that when comparing two repetitions of the same activity class it is possible that only a portion of the sequence coincides. We can see this fact in Fig. 4
                         where two sequences of the same activity class (somersault), extracted from the HMDB51 benchmark, coincide only in the final portions of the sequences.

Thanks to TFK we are able to compare sequences of different lengths and by selecting the appropriate associated function we can deal with non-perfect alignment. In this regard we design the following framework.

Let 
                           x
                           =
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       N
                                    
                                 
                              
                           
                         and 
                           y
                           =
                           
                              
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       M
                                    
                                 
                              
                           
                         be two sequences of vectors representing two different activity executions (the same or different class). These sequences are obtained with the process explained in Section 3.1 so each vector of the sequence is a BoF or a FV. On the other hand, the proper alignment between two sequences is unknown and the computation of an algorithm seeking for this alignment can increase notably the computational cost. Moreover, a proper segmentation is assumed in advance so the core of the activity is most probably located in the middle of the sequences. Therefore, without an alignment process and simply ensuring that centres of both sequences coincide, the proposed method uses the structural kernel of TFK to provide the desired degree of flexibility in compression and stretching of the activity representation. As depicted in Fig. 5
                        , we centre both sequences and assign a Gaussian distribution to each element of the sequences constrained to fixed temporal positions, being f
                        
                           i
                        (t) and g
                        
                           j
                        (t) the probability density functions of 
                           
                              
                                 N
                              
                              
                                 i
                              
                           
                         and 
                           
                              
                                 N
                              
                              
                                 j
                              
                           
                         respectively, 
                           
                              
                                 f
                              
                              
                                 i
                              
                           
                           (
                           t
                           )
                           =
                           
                              
                                 1
                              
                              
                                 
                                    
                                       σ
                                    
                                    
                                       x
                                    
                                 
                                 
                                    
                                       2
                                       π
                                    
                                 
                              
                           
                           
                              
                                 e
                              
                              
                                 −
                                 
                                    
                                       
                                          
                                             
                                                
                                                   t
                                                   −
                                                   
                                                      
                                                         μ
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       2
                                       
                                          
                                             σ
                                          
                                          
                                             x
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 g
                              
                              
                                 j
                              
                           
                           (
                           t
                           )
                           =
                           
                              
                                 1
                              
                              
                                 
                                    
                                       σ
                                    
                                    
                                       y
                                    
                                 
                                 
                                    
                                       2
                                       π
                                    
                                 
                              
                           
                           
                              
                                 e
                              
                              
                                 −
                                 
                                    
                                       
                                          
                                             
                                                
                                                   t
                                                   −
                                                   
                                                      
                                                         μ
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       2
                                       
                                          
                                             σ
                                          
                                          
                                             y
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                         being 
                           
                              
                                 μ
                              
                              
                                 i
                              
                           
                           =
                           
                              
                                 i
                                 −
                                 
                                    
                                       N
                                       +
                                       1
                                    
                                    
                                       2
                                    
                                 
                              
                           
                           
                              
                                 Δ
                              
                              
                                 t
                              
                              
                                 x
                              
                           
                         and 
                           
                              
                                 μ
                              
                              
                                 j
                              
                           
                           =
                           
                              
                                 j
                                 −
                                 
                                    
                                       M
                                       +
                                       1
                                    
                                    
                                       2
                                    
                                 
                              
                           
                           
                              
                                 Δ
                              
                              
                                 t
                              
                              
                                 y
                              
                           
                        .

The associated Gaussians weigh the inner product between sequence elements in relation to their temporal position, obtaining a maximum when their time coincides. These functions provide flexibility in the temporal position of the elements, allowing an irregular expansion or narrowing of the sequences as well as a displacement. In order to define the functions f
                        
                           i
                        (t) and g
                        
                           j
                        (t) it is possible to fix the vector spacing Δ
                        
                           t
                         and then only the standard deviation of the Gaussian σ modifies the precision of the sequence position. The smaller is σ, the narrower are the Gaussians and then the lesser is the degree of temporal flexibility. Moreover, as the number of elements in a sequence is variable and each element has a Gaussian associated, it is possible to normalize the functions so that the length of the sequence does not influence the kernel value using the normalized Gaussians: 
                           
                              
                                 f
                              
                              
                                 i
                              
                              
                                 ′
                              
                           
                           (
                           t
                           )
                           =
                           
                              
                                 1
                              
                              
                                 N
                              
                           
                           
                              
                                 f
                              
                              
                                 i
                              
                           
                           (
                           t
                           )
                         and 
                           
                              
                                 g
                              
                              
                                 j
                              
                              
                                 ′
                              
                           
                           (
                           t
                           )
                           =
                           
                              
                                 1
                              
                              
                                 M
                              
                           
                           
                              
                                 g
                              
                              
                                 j
                              
                           
                           (
                           t
                           )
                        .

Taking into account all previous concerns, we use the following kernel: 
                           
                              (8)
                              
                                 
                                    T
                                    F
                                    K
                                 
                                 (
                                 F
                                 ,
                                 G
                                 )
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                       =
                                       1
                                    
                                    
                                       M
                                    
                                 
                                 
                                    
                                       K
                                    
                                    
                                       G
                                       A
                                       U
                                       S
                                       
                                          
                                             S
                                          
                                          
                                             ρ
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             i
                                          
                                          
                                             ′
                                          
                                       
                                       (
                                       t
                                       )
                                       ,
                                       
                                          
                                             g
                                          
                                          
                                             j
                                          
                                          
                                             ′
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 
                                 
                                    
                                       K
                                    
                                    
                                       L
                                       I
                                       N
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                
                                                ‾
                                             
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             
                                                
                                                   
                                                      y
                                                   
                                                
                                                ‾
                                             
                                          
                                          
                                             j
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

We use the kernel between Gaussians that was proposed in [28] as K
                        
                           ST
                         in Eq. (6), which in our one-dimensional case is simplified as: 
                           
                              (9)
                              
                                 
                                    
                                       K
                                    
                                    
                                       G
                                       A
                                       U
                                       S
                                       
                                          
                                             S
                                          
                                          
                                             ρ
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             i
                                          
                                          
                                             ′
                                          
                                       
                                       (
                                       t
                                       )
                                       ,
                                       
                                          
                                             g
                                          
                                          
                                             j
                                          
                                          
                                             ′
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   2
                                                   π
                                                   
                                                      
                                                         σ
                                                      
                                                      
                                                         x
                                                      
                                                   
                                                   
                                                      
                                                         σ
                                                      
                                                      
                                                         y
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             (
                                             1
                                             −
                                             2
                                             ρ
                                             )
                                             /
                                             2
                                          
                                       
                                    
                                    
                                       N
                                       M
                                       
                                          
                                             2
                                             ρ
                                          
                                       
                                    
                                 
                                 
                                    
                                       e
                                    
                                    
                                       
                                          
                                             −
                                             ∥
                                             
                                                
                                                   μ
                                                
                                                
                                                   i
                                                
                                             
                                             −
                                             
                                                
                                                   μ
                                                
                                                
                                                   j
                                                
                                             
                                             
                                                
                                                   ∥
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             4
                                             
                                                
                                                   σ
                                                
                                                
                                                   x
                                                
                                             
                                             
                                                
                                                   σ
                                                
                                                
                                                   y
                                                
                                             
                                             /
                                             ρ
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Selecting ρ
                        =1/2 we obtain the Bhattacharyya kernel.

Inspired by the idea exposed in STPM [13], we explore the addition of two levels of granularity in the sequence division. Therefore, using a simple linear combination of kernels, that keeps the kernel property [38], we combine the TFK previously explained with a linear kernel between the vectors obtained from the feature extraction of the whole video. In Fig. 3 this would mean to combine the two pipelines of the diagram in the following kernel. 
                           
                              (10)
                              
                                 C
                                 o
                                 m
                                 b
                                 K
                                 (
                                 
                                    
                                       v
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       v
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 =
                                 
                                    T
                                    F
                                    K
                                 
                                 (
                                 F
                                 ,
                                 G
                                 )
                                 +
                                 
                                    
                                       K
                                    
                                    
                                       L
                                       I
                                       N
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                x
                                             
                                          
                                          ‾
                                       
                                       ,
                                       
                                          
                                             
                                                y
                                             
                                          
                                          ‾
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

If the means and variances of the functions f
                        
                           i
                        (t) and g
                        
                           j
                        (t) are only dependant on the length of the sequences it is possible to precompute in advance the 
                           
                              
                                 K
                              
                              
                                 G
                                 A
                                 U
                                 S
                                 
                                    
                                       S
                                    
                                    
                                       ρ
                                    
                                 
                              
                           
                           
                              
                                 
                                    
                                       f
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                                 (
                                 t
                                 )
                                 ,
                                 
                                    
                                       g
                                    
                                    
                                       j
                                    
                                    
                                       ′
                                    
                                 
                                 (
                                 t
                                 )
                              
                           
                         values for most of the possible combinations of N and M, so the computational cost is only influenced by the kernel between the vectors. Considering the computational cost of 
                           K
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          ¯
                                       
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             y
                                          
                                          ¯
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                           
                         be 
                           O
                           (
                           D
                           )
                        , the increase is linear with the increase of one of the sequences length 
                           O
                           (
                           N
                           M
                           (
                           D
                           +
                           1
                           )
                           )
                        .

We test the performance of our framework in four challenging Activity-Recognition benchmarks (HMDB51, UCF50, OlympicSports, Virat Release 2.0), against other published methods.


                        HMDB51 
                        [39] is one of the most challenging datasets nowadays. It contains a collection of videos obtained from a variety of sources ranging from digitized movies to YouTube videos. The total of 6766 video clips contains 51 distinct activity categories each one represented by at least 101 examples. The dataset is divided by the authors into 3 splits, each one containing 70 training clips and 30 testing clips in order to display a representative variability of the recording sources. The dataset includes a stabilized version of the videos that is not used in our experiments. We follow the protocol proposed by the authors.


                        UCF50 
                        [40] is obtained from YouTube videos. It contains 6681 video clips of 50 different activities. Some of these videos are segmentations of a longer one, so it is important to follow the authors' protocol. The authors suggest a division into 25 groups in order to apply a leave-one-group-out cross-validation strategy that we follow.


                        OlympicSprots 
                        [36] contains 783 videos of athletes practising 16 different sports. All video sequences were obtained from YouTube and have been annotated with the help of Amazon Mechanical Turk. The authors suggest a split for training and testing the recognition system.


                        Virat Release 2.0 
                        [41] has been recorded in 11 different scenes of video surveillance, captured by stationary HD cameras (1080p or 720p). There are 11 different classes of activities annotated where persons and vehicles appear (Loading, Unloading, Opening Trunk, Closing Trunk, Getting Into Vehicle, Getting out of Vehicle, Entering Facility, Exiting Facility, Gesturing, Carrying and Running). We follow the scene-independent learning and recognition mode of evaluation suggested by the authors. In the experiments we specifically focus in the actions with “opposite” counterpart, all the actions except Gesturing, Carrying and Running.

The framework performance is tested using two different descriptors. First, as representative low-level descriptor with short-term information we have used the MIP descriptor [5], which performs better than other common short-term descriptors like SIFT or HOG-HOF. Second, as state-of-the-art descriptor, and with longer temporal information captured we have selected the IDT descriptor. In order to understand the utility of the proposed framework we have conducted more exhaustive experiments with this descriptor. In both cases a parameter analysis is explained in this subsection.

The MIP descriptor is extracted with the original specifications proposed by the authors. The video is encoded with a BoF approach creating a codebook of 5000 codewords per channel obtaining a (8×5000)-dimensional vector. Our proposed video encoding depends on three parameters: β (in Eq. (2)) controlling the softness of the assignment and w
                        
                           D
                         and w
                        
                           K
                         (in Fig. 3) modelling the sliding frame-windows. Fixing the temporal spacing Δ
                        
                           t
                        
                        =1 we let σ as the free parameter of the Gaussian functions.

We firstly perform experiments for multiple combinations of the parameter β, the window width w
                        
                           D
                        , the window displacement w
                        
                           K
                         and the standard deviation σ of the Gaussian function of the kernel, using the first split of the HMDB51 dataset.

From initial experiments we have found that a sliding frame-window without overlapping provides best results, therefore we fix w
                        
                           D
                        
                        =
                        w
                        
                           K
                         and then only 2 parameters of the video encoding are analysed: w
                        
                           K
                         and β. We show in Fig. 6
                         the results obtained by fixing two of the three analysed parameters to the values finally selected, so the graphs represent the performance of the remaining one.

We can observe the importance of using the soft-assignment approximation in Fig. 6 (a) where different values of β are evaluated. If we use a hard-assignment with a window of width w
                        
                           K
                        
                        =15 the system performance declines in relation to a proper soft-assignment, which can be explained by the lack of sufficient data in a window. On the other hand, any of the three analysed values of β (6, 8 and 10) gives better results than the hard-assignment, what implies that the use of a soft-assignment is an adequate optimization in a wide range of values.

The width of the window w
                        
                           K
                        , Fig. 6 (b), does not impose significant variations in the system performance either, although the value w
                        
                           K
                        
                        =15 seems to be optimal.


                        Fig. 6 (c), depicts the performance of the system while varying the standard deviation σ of the kernel Gaussian functions. The bigger it is the wider are the Gaussians which means that the sequences are more flexible to asymmetrically expand or shrink but also that the temporal position is less influential. Very small values of σ lead to low accuracy, but then the variation in performance is minor and we find the optimum between σ
                        =1 and σ
                        =2.

We extend the parameters influence experiments to the IDT descriptor. In this case the encoding is performed with FV using a mixture model of 256 Gaussians. Hence, the study is performed over w
                        
                           K
                         and w
                        
                           D
                         for the sliding frame-window and σ for the temporal structure. We perform the analysis using the training examples of the OlympicSports dataset, dividing it into two groups randomly selected: 70% for training and 30% for validation. In Fig. 7
                         we show three graphs fixing two of the parameters to the final value selected and varying the remaining one.


                        Fig. 7 (a) shows low variation in the performance of the system for varying w
                        
                           K
                         except with short windows close to the IDT length, once reached w
                        
                           K
                        
                        =25 the accuracy variation is produced only by two examples recognition, slightly tending to the maximum when increasing the size until reaching the whole video represented in the axes as w
                        
                           K
                         →∞. The case where w
                        
                           K
                         →∞ corresponds to the use of a single FV per video, which is the standard approach of IDT presented in [6]. Therefore, in order to compare our framework with the original approach we carry out the experiments using w
                        
                           K
                        
                        =30. The value of w
                        
                           D
                         has even a lower influence in the performance and although the optimal value is between w
                        
                           D
                        
                        =5 and w
                        
                           D
                        
                        =15, it makes little difference in the final result. The parameter σ has a similar behaviour to the one in the MIP analysis, although we can consider that the optimum value extends from σ
                        =1 to at least the maximum analysed σ
                        =3 because the accuracy decreases only in one incorrectly recognized example.

Our proposed framework is advantageous in two scenarios: (i) when using short time descriptors, as it allows including longer temporal information in the classifier and (ii) recognizing complex activities where the order of actions may be crucial for correct recognition. In the latter scenario, our framework can benefit even cases where longer time descriptors are used, as it encodes all the temporal information of the activity. However, when dividing the videos in small sub-clips the information can be scarce and produce unstable encoding that leads to bad classification in examples where the previous propositions are not fulfilled. This problem is overcome by combining the two granularities of the video division proposed in Eq. (10).

Our first experiment analysed the proposed framework performance using short-term descriptors. It is carried out using the MIP descriptor and the BoF encoding over the datasets HMDB51 and UCF50. In the previous section, we have seen that the performance of the framework is not significantly influenced when parameters are chosen within acceptable ranges. For the following experiments we select β
                        =8, in case of soft-assignment, the width w
                        
                           K
                        
                        =15 and the displacement of sliding frame-windows w
                        
                           D
                        
                        =15, so they are not overlapped, and the standard deviation of the Gaussian functions of the structural kernel σ
                        =1. We divided both datasets according to the authors' recommendations: 3 splits in HMDB51 and 25 groups in UCF50. We have used publicly available code for MIP
                           1
                        
                        
                           1
                           MIP descriptor code can be downloaded in http://www.openu.ac.il/home/hassner/projects/MIP/MIPcode.zip
                           
                         and SVM
                           2
                        
                        
                           2
                           SVM code can be downloaded in http://www.csie.ntu.edu.tw/<SPitie/>cjlin/libsvm/
                           
                         , using the default parameters. The randomness of initialisation of the k-means algorithm justifies why our results do not exactly coincide with those given in the MIP original paper. To ensure fair comparison between the standard method and our proposed framework, clustering and features extraction, as well as the one-against-all SVM classification, coincide in both pipelines. The difference lays in the middle stages. The standard method encodes the video with a single BoF obtained with a hard-assignment and applies a linear kernel between BoFs (BoF+LinK) as suggested by the authors for best results [5]. The proposed framework encodes each video in a sequence of BoFs (SeqBoF) using soft-assignment and applies the proposed TFK (SeqBoF+TFK). In Table 1
                         we can see how the inclusion of long-term temporal information using TFK clearly improves the results in both datasets which validates our first assumption regarding short-term descriptors. However, clearly better results have been obtained in the state-of-the-art using mid-term descriptors and specifically with IDT.

The second battery of experiments has been performed using the state-of-the-art descriptor, IDT
                           3
                        
                        
                           3
                           IDT descriptor code can be downloaded in http://lear.inrialpes.fr/people/wang/download/improved_trajectory_release.tar.gz
                           
                         , and comparing the novel framework against the original work in [6] and other related works in Activity Recognition. The sliding frame-windows vary from the MIP experiments as w
                        
                           K
                        
                        =30 and w
                        
                           D
                        
                        =15. We compute the experiments in all the evaluated datasets: OlympicSports, HMDB51, UCF50 and Virat Release 2. In all the experiments we follow the authors' recommendations: one division for training and testing in OlympicSports, 3 splits in HMDB51, leave-one-group-out from 25 groups in UCF50 and leave-one-scene-out with 11 scenes in Virat Release 2.0. As in the literature we find mainly results of Accuracy (acc) or Mean Average Precision (mAP), we compute both in the different approaches evaluated. Table 2
                         shows the results obtained with the original IDT as well as our proposed frameworks. To assure fair comparison we perform all the experiments using the same IDT extraction and GMM estimation. First, we obtain a unique FV per Video and apply a linear kernel for a SVM classification (IDT+FV+LinK), obtaining our own implementation of the approach in [6]. Following, we use the extracted IDT features to obtain a sequence of FV (SeqFV) that are used in our TFK approach (IDT+SeqFV+TFK). Finally, we combine both approaches in the CombK kernel (IDT+CombK).

The TFK approach is suitable in complex activities where the order of sub-actions determines the class. This can be confirmed with the results in Virat dataset where there are 4 activities with their respective “opposites”, depicted in the second row, two last columns of Table 2. However, TFK also has some drawbacks, as can be observed in the other three datasets where it performs similarly to the original IDT method. TFK relies in the extracted features in each window, and if they are scarce, the computed FV can be less robust to clutter. These datasets have complex activities, but not all of them depend on the order of sub-actions, therefore, although some activities are better classified with TFK, others are worse. The solution for this lack of robustness against clutter is the linear combination of both kernels. As we can see in the last row, this approach improves the results in all datasets but Virat where, even improving the original approach, the result is worse than the direct use of TFK because all the activities but 3 have “opposite” counterparts and the combination of kernels lowers the importance of order.

In Table 3
                         we observe a comparison of the proposed approach against some of the best results in the literature. It is worth to note that there are two rows representing the original approach with IDT [6], the third-to-last and the second-to-last. In the third-to-last row we show the results provided in the original paper, but a direct comparison between this results and our approach is not fair as several stages have some randomness and slightly alter the final results. On the other hand, the second-to-last row shows our own implementation of [6] which share the features extraction and the clustering with the TFK so the comparison is fair. We can see how our novel approach overtakes all the compared methods in the “fair” comparison. To our knowledge there is no method with better results for all the datasets.

The results on Virat Release 2.0 are further analysed using only the activities with “opposites”, (Loading, Unloading, Opening Trunk, Closing Trunk, Getting Into Vehicle, Getting out of Vehicle, Entering Facility and Exiting Facility). The Confusion Matrices of the (IDT+FV+LinK) and (IDT+SeqFV+TFK) methods are depicted in Fig. 8
                        . In addition to the improvement obtained with the proposed framework, these matrices confirm our premise that the TFK is suitable for better learning of complex activities defined with the sub-actions order. The improvement achieved by the proposed framework is clear as every element of the diagonal is greater or equal. But the improvement does not restrict to this as in addition of a general improvement, the wrong classified activities are now confused with activities with similar temporal structure. For instance, the two first activities (‘Loading’ and ‘Unloading’) are mainly confused with (‘Getting Into Vehicle’ and ‘Getting Out of Vehicle’). If we observe the Confusion Matrix of the (IDT + FV + LinK) method, the confusion is more or less random, but using TFK we can see how the structure is learned and then “loading“ is mainly confused with “getting into vehicle” and “unloading“ is mainly confused with “getting out of vehicle”. We achieve a clearer representation of this idea by gathering all the activities with similar temporal structure into one class so, activities (Loading, Opening Trunk, Getting Into Vehicle and Entering Facility) with structure (approaching and opening–closing) are grouped in class IN and activities (Unloading, Closing Trunk, Getting out of Vehicle and Exiting Facility) with structure (opening–closing and moving away) are grouped in class OUT. Fig. 9
                         depicts the Confusion Matrices of these two classes. Here it is clear how the TFK approach keeps better the temporal structure of the activities.

Finally, we introduce one more experiment in order to compare our framework with the STPM approach which also preserves the temporal structure of the activities. In [13], Choi et al. have designed an experiment called Quality of binary decision where one example is compared to other two, one with the same class and other with a different class. Whenever the example of the same class is more similar to the initial example than the other one, the binary decision is correct. With this experimentation the authors obtain a maximum of 95.3% of Precision. In order to get a similar process we select single-class SVM to provide binary decisions between two randomly selected examples (one from the same class and one from a different class). Whenever the example of the same class has a greater note than the other one, the binary decision is correct. Using this experimentation we obtain a 99.3% of Precision.

@&#CONCLUSION@&#

We have introduced a new framework that improves accuracy in human activity classification taking into account the long-term information. The framework can be used with a wide variety of low-level feature descriptors, such as MIP and IDT, and video encoding methods, such as BoF and FV. The specific technical novelties of our work are a video encoding method that preserves the temporal information and the Time Flexible Kernel that is able to compare sequences of different lengths and random alignment.

Our experiments demonstrated the value of the novel framework in two cases: First, low-level descriptors with short-term information lose the long-term temporal information of the sequences. Our framework is able to consider such temporal information and therefore can improve the performance in activity recognition. Second, although modern state-of-the-art descriptors like IDT include some temporal information for recognizing several activities in spite of the unordered encoding of BoF or FV, they fail in case of complex activities that are defined by the order of the same short events. Again, our framework is able to preserve such complex temporal structure and distinguish between activities that consist of similar events but in different order.

The novel formulation of TFK is not restricted to activity sequences but it can be applied in any comparison between two sets that their structure of information can be defined using the functions f
                     
                        i
                      and g
                     
                        j
                     . For instance, an interesting extension for future research will be its application in image-based recognition, where the spacial structure is an important source of information.

Finally, the TFK approach can introduce some noisy results if the number of low-level extracted features is small in some windows. Using several levels of granularity in window width reduces this effect.

@&#ACKNOWLEDGEMENTS@&#

This work was partially supported by Spanish Grant TIN2013-45312-R (MINECO), Gobierno de Aragon and the European Social Found. Mario Rodriguez was sponsored by Spanish FPI Grant BES-2011-043752 and EEBB-I-14-08410.

@&#REFERENCES@&#


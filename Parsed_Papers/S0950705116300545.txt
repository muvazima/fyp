@&#MAIN-TITLE@&#Multi-label learning with label-specific feature reduction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose two multi-label learning approaches with LIFT reduction.


                        
                        
                           
                           The idea of fuzzy rough set attribute reduction is adopted in our approaches.


                        
                        
                           
                           Sample selection improves the efficiency in feature dimension reduction.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Feature reduction

Fuzzy rough set

Label-specific feature

Multi-label learning

Sample selection

@&#ABSTRACT@&#


               
               
                  In multi-label learning, since different labels may have some distinct characteristics of their own, multi-label learning approach with label-specific features named LIFT has been proposed. However, the construction of label-specific features may encounter the increasing of feature dimensionalities and a large amount of redundant information exists in feature space. To alleviate this problem, a multi-label learning approach FRS-LIFT is proposed, which can implement label-specific feature reduction with fuzzy rough set. Furthermore, with the idea of sample selection, another multi-label learning approach FRS-SS-LIFT is also presented, which effectively reduces the computational complexity in label-specific feature reduction. Experimental results on 10 real-world multi-label data sets show that, our methods can not only reduce the dimensionality of label-specific features when compared with LIFT, but also achieve satisfactory performance among some popular multi-label learning approaches.
               
            

@&#INTRODUCTION@&#

Nowadays, multi-label learning problem has received an increased attention in real-world applications. For example, in semantic annotation of images [3,16,26,49], a picture can be annotated as camel, desert and landscape. In text categorization [5,11,17,29], a document may belong to several given topics, including economics, finance or GDP. In bioinformatics [6,13,50], each gene may be associated with a set of functional classes, such as metabolism, transcription and protein synthesis. In all cases above, each sample may be associated with more than one label simultaneously and predefined labels for different samples are not mutually exclusive but may overlap. This situation is distinct from the traditional single-label learning where predefined labels are mutually exclusive, each sample only belongs to a single label.

Over the last decade, many multi-label learning approaches have been witnessed [12,28,58]. Generally, the existing methods can be grouped into two main categories [43], i.e., algorithm adaptation methods and problem transformation methods. Algorithm adaptation methods extend specific single-label learning algorithms to directly handle multi-label data by modifying some constraint conditions, such as AdaBoost.MH [40], ML-kNN [59], MLNB [60], and RankSVM [9]. Problem transformation methods, transform the multi-label task into one or more corresponding single-label ones and then handle them one by one through traditional methods. The well-known problem transformation methods include binary relevance (BR), label power set (LP) and pruned problem transformation (PPT). BR [3] learns a binary classifier for each label independently and predicts each of the labels separately, so it cuts up the relationship among different labels. LP [44] considers each unique set of labels that exists in a multi-label training set as a new single-label multi-value class. Though this method considers the correlations among different labels, it easily leads to a higher time consumption since the number of new classes is increased exponentially with the increasing of labels. Meanwhile, some new classes created by a few samples may lead to class unbalance problem. PPT [34] abandons the new classes associated with extremely small number of samples or assigns these samples with new labels that can create accepted classes, while some abandoned classes will lead to the loss of multi-label information. Although above methods have achieved good performance in multi-label learning, they make use of the same features to achieve the learning purposes in different labels. Actually, different labels may have distinct characteristics of their own, and these characteristics are more inclined to judge whether labels belong to a specific sample. Fortunately, Zhang [61,62] has proposed the representative LIFT algorithm and validated the effectiveness of constructing label-specific features. For each label, LIFT employs clustering analysis in the positive and negative samples respectively, and then constructs label-specific features by checking the distances between the sample and all the clustering centers. (There is not any semanteme for constructed label-specific features, which can be regarded as a set of distances.) However, construction of label-specific features may encounter the increasing of feature dimensionalities, and a large amount of redundant information exists in feature space. As a result, the structure information between different samples will be disrupted, and even more be destroyed, which leads to the decreasing of the performance of multi-label learning approach. To alleviate this problem, an effective solution is to perform dimension reduction in label-specific features.

Rough set theory is a good mathematical tool for describing incomplete and uncertain data. With over 30 years of development, it has been widely applied in attribute reduction [18,30], feature selection [20,22,31,42,55], rule extraction [25,38] and uncertainty reasoning [46]. Numerous researchers [31,32] have used the various rough set models for dealing with single-label data analyses in real-world applications. Recently, some researchers [53,54,56,57] begin to attempt at carrying out multi-label classification via rough set approaches, however, all of them determine different labels in the same feature space, which contradicts the fact that different labels may have distinct characteristics of their own. In this paper, with the idea of attribute reduction based on fuzzy rough set, we will develop a multi-label learning approach with label-specific feature reduction (FRS-LIFT), which uses the approximation quality to evaluate the significance of specific dimension and takes the forward greedy search strategy. Furthermore, sample selection is an effective data compression technique, which can reduce the time and memory consumption in attribute reduction. On the basis of FRS-LIFT, another multi-label learning approach with label-specific feature reduction by sample selection (FRS-SS-LIFT) will be presented at the same time. To validate the effectiveness of FRS-LIFT and FRS-SS-LIFT, we conduct comprehensive experiments on 10 real-world multi-label data sets. Experimental study shows clear advantages of FRS-LIFT and FRS-SS-LIFT over various multi-label learning algorithms.

The rest of this paper is organized as following. Section 2 introduces the formal definition of multi-label learning’s framework and LIFT approach. Section 3 provides some background materials on fuzzy rough set and sample selection, and then the details of our FRS-LIFT and FRS-SS-LIFT are presented. Section 4 describes data sets, evaluation metrics, experimental settings, and then analyzes the results of comparative studies on 10 multi-label data sets. Finally, Section 5 summarizes and sets up several issues for future work.

Let 
                           
                              X
                              =
                              
                                 R
                                 d
                              
                           
                         be the d-dimensional sample space and 
                           
                              L
                              =
                              {
                              
                                 l
                                 1
                              
                              ,
                              
                                 l
                                 2
                              
                              ,
                              …
                              ,
                              
                                 l
                                 m
                              
                              }
                           
                         be the finite set of m possible labels. 
                           
                              T
                              =
                              {
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 ,
                                 
                                    Y
                                    i
                                 
                                 )
                              
                              |
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                              }
                           
                         denotes the multi-label training set with n labeled samples, where xi
                         ∈ X is a d-dimensional feature vector such that 
                           
                              
                                 x
                                 i
                              
                              =
                              
                                 [
                                 
                                    x
                                    
                                       i
                                    
                                    1
                                 
                                 ,
                                 
                                    x
                                    
                                       i
                                    
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 
                                    x
                                    
                                       i
                                    
                                    d
                                 
                                 ]
                              
                              ,
                           
                         
                        Yi
                        ⊆L is the set of labels associated with xi
                        .

The goal of multi-label learning is to produce a real-valued function 
                           
                              f
                              :
                              X
                              ×
                              P
                              (
                              L
                              )
                              →
                              R
                           
                        . In detail, for each xi
                         ∈ X, a prefect learning system will tend to output larger values for labels in Yi
                         than those not in Yi
                         
                        [59], i.e., for any l, l′ ∈ L, if l ∈ Yi
                         and l′ ∉ Yi, f(xi, l) > f(xi, l′) holds.

LIFT aims to improve the learning performance of multi-label learning system through generating distinguishing features which capture the specific characteristics of each label lk
                            ∈ L. To achieve this goal, LIFT takes into account intrinsic connection between different samples in all labels. Specifically, with respect to each label lk
                           , the training samples are divided into two categories, i.e., the set of positive training samples Pk
                            and the set of negative training samples Nk
                           , such that:

                              
                                 (1)
                                 
                                    
                                       
                                          
                                             
                                                P
                                                k
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   {
                                                   
                                                      x
                                                      i
                                                   
                                                   |
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         Y
                                                         i
                                                      
                                                      )
                                                   
                                                   ∈
                                                   T
                                                   ,
                                                   
                                                      l
                                                      k
                                                   
                                                   ∈
                                                   
                                                      Y
                                                      i
                                                   
                                                   }
                                                
                                                ;
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                N
                                                k
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   {
                                                   
                                                      x
                                                      i
                                                   
                                                   |
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         Y
                                                         i
                                                      
                                                      )
                                                   
                                                   ∈
                                                   T
                                                   ,
                                                   
                                                      l
                                                      k
                                                   
                                                   ∉
                                                   
                                                      Y
                                                      i
                                                   
                                                   }
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           In other words, the training sample xi
                            belongs to Pk
                            if xi
                            has label lk
                           ; otherwise, xi
                            is included in Nk
                           .

To consider intrinsic connection among different samples, LIFT employs clustering analysis on Pk
                            and Nk
                           , respectively. Following Zhang’s research [61,62], k-means algorithm [21] is adopted to partition Pk
                            into 
                              
                                 m
                                 k
                                 +
                              
                            disjoint clusters whose clustering centers are denoted by 
                              
                                 {
                                 
                                    p
                                    1
                                    k
                                 
                                 ,
                                 
                                    p
                                    2
                                    k
                                 
                                 ,
                                 …
                                 ,
                                 
                                    p
                                    
                                       m
                                       k
                                       +
                                    
                                    k
                                 
                                 }
                              
                           . Similarly, Nk
                            is also partitioned into 
                              
                                 m
                                 k
                                 −
                              
                            disjoint clusters whose clustering centers are 
                              
                                 {
                                 
                                    n
                                    1
                                    k
                                 
                                 ,
                                 
                                    n
                                    2
                                    k
                                 
                                 ,
                                 …
                                 ,
                                 
                                    n
                                    
                                       m
                                       k
                                       −
                                    
                                    k
                                 
                                 }
                              
                           . LIFT treats clustering information gained from Pk
                            and Nk
                            as equal importance, and then the numbers of clusters on Pk
                            and Nk
                            are set to be the same, i.e., 
                              
                                 
                                    m
                                    k
                                    +
                                 
                                 =
                                 
                                    m
                                    k
                                    −
                                 
                                 =
                                 
                                    m
                                    k
                                 
                              
                           . Specifically, the number of clusters for both positive samples and negative samples is:

                              
                                 (3)
                                 
                                    
                                       
                                          
                                             
                                                m
                                                k
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   ⌈
                                                   δ
                                                   ·
                                                   min
                                                   (
                                                   |
                                                   
                                                      P
                                                      k
                                                   
                                                   |
                                                   ,
                                                   |
                                                   
                                                      N
                                                      k
                                                   
                                                   |
                                                   )
                                                   ⌉
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where | · | represents the cardinality of a set, δ ∈ [0, 1] is the ratio parameter for controlling the number of clusters.

The above two groups of clustering centers describe inner structures of positive samples Pk
                            and negative samples Nk
                           , on this basis, label-specific features can be constructed in the form of:

                              
                                 (4)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   φ
                                                   k
                                                
                                                
                                                   (
                                                   
                                                      x
                                                      i
                                                   
                                                   )
                                                
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   [
                                                   d
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         p
                                                         1
                                                         k
                                                      
                                                      )
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   d
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         p
                                                         
                                                            m
                                                            k
                                                         
                                                         k
                                                      
                                                      )
                                                   
                                                   ,
                                                   d
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         n
                                                         1
                                                         k
                                                      
                                                      )
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   d
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         n
                                                         
                                                            m
                                                            k
                                                         
                                                         k
                                                      
                                                      )
                                                   
                                                   ]
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where d( ·, ·) represents the distance between two samples. In literatures [61,62], Euclidean metric is used to calculate sample distance. Actually, φ
                              k
                            is a mapping from the original d-dimensional sample space X to a new 2mk
                           -dimensional label-specific feature space LIFT
                           
                              k
                           , i.e., φ
                              k
                           : X → LIFT
                           
                              k
                           .

LIFT induces a family of m classification models 
                              
                                 {
                                 
                                    f
                                    1
                                 
                                 ,
                                 
                                    f
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 
                                    f
                                    m
                                 
                                 }
                              
                            in the constructed label-specific feature spaces LIFT
                           
                              k
                           (1 ≤ k ≤ m). Formally, for each lk
                            ∈ L, a binary training set 
                              
                                 T
                                 k
                                 *
                              
                            with n samples is created from the training set T according to the mapping φ
                              k
                           , such that:

                              
                                 (5)
                                 
                                    
                                       
                                          
                                             
                                                T
                                                k
                                                *
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   {
                                                   
                                                      (
                                                      
                                                         φ
                                                         k
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                            i
                                                         
                                                         )
                                                      
                                                      ,
                                                      ϕ
                                                      
                                                         (
                                                         
                                                            Y
                                                            i
                                                         
                                                         ,
                                                         
                                                            l
                                                            k
                                                         
                                                         )
                                                      
                                                      )
                                                   
                                                   |
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      ,
                                                      
                                                         Y
                                                         i
                                                      
                                                      )
                                                   
                                                   ∈
                                                   T
                                                   }
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 ϕ
                                 (
                                 
                                    Y
                                    i
                                 
                                 ,
                                 
                                    l
                                    k
                                 
                                 )
                                 =
                                 +
                                 1
                              
                            if lk
                            ∈ Yi
                           ; otherwise, 
                              
                                 ϕ
                                 (
                                 
                                    Y
                                    i
                                 
                                 ,
                                 
                                    l
                                    k
                                 
                                 )
                                 =
                                 −
                                 1
                              
                           . Based on the binary training set 
                              
                                 
                                    T
                                    k
                                    *
                                 
                                 ,
                              
                            any binary learner can be employed to induce a classification model fk: LIFT
                           
                              
                                 
                                    
                                    k
                                 
                                 →
                                 R
                              
                            for lk
                           .

Given an unseen sample x′ ∈ X, the predicted label set for x′ is 
                              
                                 
                                    Y
                                    ′
                                 
                                 =
                                 
                                    {
                                    
                                       l
                                       k
                                    
                                    |
                                    f
                                    
                                       (
                                       
                                          φ
                                          k
                                       
                                       
                                          (
                                          
                                             x
                                             ′
                                          
                                          )
                                       
                                       ,
                                       
                                          l
                                          k
                                       
                                       )
                                    
                                    >
                                    0
                                    ,
                                    1
                                    ≤
                                    k
                                    ≤
                                    m
                                    }
                                 
                              
                           .

To fuse rough set approaches into machine learning problems, we will introduce the classification learning task instead of the notion of information system. Formally, a classification learning task can also be considered as the 3-tuple < U, A, D >, in which 
                           
                              U
                              =
                              {
                              
                                 x
                                 1
                              
                              ,
                              
                                 x
                                 2
                              
                              ,
                              …
                              ,
                              
                                 x
                                 n
                              
                              }
                           
                         is the finite set of n samples called the universe of discourse, 
                           
                              A
                              =
                              {
                              
                                 a
                                 1
                              
                              ,
                              
                                 a
                                 2
                              
                              ,
                              …
                              ,
                              
                                 a
                                 c
                              
                              }
                           
                         is the set of condition features, D is the decision.

Let U ≠ ∅ be a universe of discourse. F: U → [0, 1] is a fuzzy set [8] on U, F(x) is the membership function of F, F(U) is the set of all fuzzy sets on U. A given fuzzy binary relation R can be a fuzzy equivalence relation if and only if R is reflexive, symmetric and transitive. Equivalently, ∀x, y, z ∈ U, 
                           
                              R
                              (
                              x
                              ,
                              x
                              )
                              =
                              1
                              ,
                           
                        
                        
                           
                              R
                              (
                              x
                              ,
                              y
                              )
                              =
                              R
                              (
                              y
                              ,
                              x
                              )
                           
                         and 
                           
                              
                                 ⋀
                                 y
                              
                              
                                 (
                                 R
                                 
                                    (
                                    x
                                    ,
                                    y
                                    )
                                 
                                 ,
                                 R
                                 
                                    (
                                    y
                                    ,
                                    z
                                    )
                                 
                                 )
                              
                              ≤
                              R
                              
                                 (
                                 x
                                 ,
                                 z
                                 )
                              
                           
                        .

                           Definition 1
                           
                              [8,18]
                           


                           Let U ≠ ∅ be a universe of discourse, R is a fuzzy equivalence relation on U, ∀F ∈ F(U), the fuzzy lower and upper approximations of F are denoted by 
                                 R
                               (F) and 
                                 
                                    
                                       R
                                       ¯
                                    
                                    
                                       (
                                       F
                                       )
                                    
                                    ,
                                 
                               respectively, ∀x ∈ U, the membership functions are defined as:

                                 
                                    (6)
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      R
                                                      ̲
                                                   
                                                   
                                                      (
                                                      F
                                                      )
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                
                                             
                                             
                                                =
                                             
                                             
                                                
                                                   
                                                      inf
                                                      
                                                         y
                                                         ∈
                                                         U
                                                      
                                                   
                                                   max
                                                   
                                                      (
                                                      1
                                                      −
                                                      R
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ,
                                                      F
                                                      (
                                                      y
                                                      )
                                                      )
                                                   
                                                   ;
                                                
                                             
                                          
                                       
                                    
                                 
                              
                              
                                 
                                    (7)
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      R
                                                      ¯
                                                   
                                                   
                                                      (
                                                      F
                                                      )
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                
                                             
                                             
                                                =
                                             
                                             
                                                
                                                   
                                                      sup
                                                      
                                                         y
                                                         ∈
                                                         U
                                                      
                                                   
                                                   min
                                                   
                                                      (
                                                      R
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ,
                                                      F
                                                      (
                                                      y
                                                      )
                                                      )
                                                   
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           

The pair 
                           
                              [
                              
                                 R
                                 ̲
                              
                              
                                 (
                                 F
                                 )
                              
                              ,
                              
                                 R
                                 ¯
                              
                              
                                 (
                                 F
                                 )
                              
                              ]
                           
                         is referred to as a fuzzy rough set of F.

                           Definition 2
                           Let < U, A, D > be a classification learning task, ∀B⊆A, RB
                               is the fuzzy equivalence relation on U in feature subset B, 
                                 
                                    U
                                    /
                                    I
                                    N
                                    D
                                    
                                       (
                                       D
                                       )
                                    
                                    =
                                    
                                       {
                                       
                                          d
                                          1
                                       
                                       ,
                                       
                                          d
                                          2
                                       
                                       ,
                                       …
                                       ,
                                       
                                          d
                                          p
                                       
                                       }
                                    
                                 
                               is the partition induced by the decision D, then approximate quality of U/IND(D) based on fuzzy rough set is represented in form of:

                                 
                                    (8)
                                    
                                       
                                          
                                             
                                                
                                                   γ
                                                   (
                                                   B
                                                   ,
                                                   D
                                                   )
                                                
                                             
                                             
                                                =
                                             
                                             
                                                
                                                   
                                                      
                                                         |
                                                         
                                                            ⋃
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            p
                                                         
                                                         
                                                            
                                                               R
                                                               B
                                                            
                                                            ̲
                                                         
                                                         
                                                            (
                                                            
                                                               d
                                                               i
                                                            
                                                            )
                                                         
                                                         |
                                                      
                                                      
                                                         |
                                                         U
                                                         |
                                                      
                                                   
                                                   =
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            
                                                               |
                                                               U
                                                               |
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               ⋁
                                                               
                                                                  i
                                                                  =
                                                                  1
                                                               
                                                               p
                                                            
                                                            
                                                               
                                                                  R
                                                                  B
                                                               
                                                               ̲
                                                            
                                                            
                                                               (
                                                               
                                                                  d
                                                                  i
                                                               
                                                               )
                                                            
                                                            
                                                               (
                                                               
                                                                  x
                                                                  j
                                                               
                                                               )
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         |
                                                         U
                                                         |
                                                      
                                                   
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              where | · | denotes the cardinality of a set, di
                               is a decision class.


                        γ(B, D) reflects the approximation abilities of the granulated space induced by feature subset B to characterize the decision D. Obviously, 0 ≤ γ(B, D) ≤ 1 holds. In literatures [18,19], it is proved that approximate quality is monotonic with the increasing or decreasing of condition features in a classification learning task, i.e, γ(B
                        1, D) ≤ γ(B
                        2, D) if B
                        1⊆B
                        2.

                           Definition 3
                           Let < U, A, D > be a classification learning task, ∀B⊆A, B is referred to as a reduct of A if and only if

                                 
                                    1.
                                    
                                       
                                          
                                             γ
                                             (
                                             B
                                             ,
                                             D
                                             )
                                             =
                                             γ
                                             (
                                             A
                                             ,
                                             D
                                             )
                                             ;
                                          
                                       
                                    

∀C ⊂ B, γ(C, D) ≠ γ(B, D).

By Definition 3, we can see that a reduct of A is a minimal subset of A, which preserves the approximate quality. However, in the majority of real-world applications, the above definition is much too strict. To expand the application scope of attribute reduction (dimension reduction, feature selection), Hu et al. [18,19] introduced the threshold ε to control the change of approximate quality for loosening the restrictions of reduct. In reality, we can also consider B as a reduct of A when satisfying the following conditions: (1) 
                           
                              γ
                              (
                              A
                              ,
                              D
                              )
                              −
                              γ
                              (
                              B
                              ,
                              D
                              )
                              ≤
                              
                                 ɛ
                              
                           
                        ; (2) ∀C ⊂ B, 
                           
                              γ
                              (
                              A
                              ,
                              D
                              )
                              −
                              γ
                              (
                              C
                              ,
                              D
                              )
                              >
                              
                                 ɛ
                              
                           
                        . Note that, ε is aimed at reducing redundant information as much as possible, while maintaining the change of approximate quality in a smaller range. In general, ε is recommended to be [0, 0.1].

In fuzzy rough set, with the number of features increasing, the fuzzy similarity between samples will decrease, and then the lower approximation of decision will increase, namely, the size of positive region will be enlarged. As is well known, the samples in positive region are usually regarded as to be certain, and then the degree of certainty in the classification learning task will be improved. It is consistent with our intuition that new features will bring new information about granulation and classification.

Let < U, A, D > be a classification learning task, ∀ai
                         ∈ B⊆A, we define a coefficient

                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             
                                                Sig
                                                
                                                   i
                                                   n
                                                
                                             
                                             
                                                (
                                                
                                                   a
                                                   i
                                                
                                                ,
                                                B
                                                ,
                                                D
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             γ
                                             
                                                (
                                                B
                                                ,
                                                D
                                                )
                                             
                                             −
                                             γ
                                             (
                                             B
                                             −
                                             
                                                {
                                                
                                                   a
                                                   i
                                                
                                                }
                                             
                                             ,
                                             D
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        as the significance of ai
                         in B relative to decision D. 
                           
                              
                                 Sig
                                 
                                    i
                                    n
                                 
                              
                              
                                 (
                                 
                                    a
                                    i
                                 
                                 ,
                                 B
                                 ,
                                 D
                                 )
                              
                           
                         reflects the change of approximate quality if ai
                         is eliminated from B. Accordingly, we can also define

                           
                              (10)
                              
                                 
                                    
                                       
                                          
                                             
                                                Sig
                                                
                                                   o
                                                   u
                                                   t
                                                
                                             
                                             
                                                (
                                                
                                                   a
                                                   i
                                                
                                                ,
                                                B
                                                ,
                                                D
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             γ
                                             
                                                (
                                                B
                                                +
                                                
                                                   {
                                                   
                                                      a
                                                      i
                                                   
                                                   }
                                                
                                                ,
                                                D
                                                )
                                             
                                             −
                                             γ
                                             
                                                (
                                                B
                                                ,
                                                D
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 a
                                 i
                              
                              ∈
                              A
                              −
                              B
                              ,
                           
                        
                        
                           
                              
                                 Sig
                                 
                                    o
                                    u
                                    t
                                 
                              
                              
                                 (
                                 
                                    a
                                    i
                                 
                                 ,
                                 B
                                 ,
                                 D
                                 )
                              
                           
                         measures the change of approximate quality if ai
                         is introduced into B. On the basis of above, large numbers of researchers [24,45,47,51,52,63] iteratively select the most significant features with forward greedy algorithm until no more deterministic rules generating with the increasing of features. Feature selection (dimension reduction) based on approximate quality can greatly reduce redundant and irrelevant information in feature space, while remaining the degree of certainty in the classification learning task.

In this subsection, we will propose a multi-label learning approach with label-specific feature reduction based on fuzzy rough set (FRS-LIFT). In the multi-label training set T, FRS-LIFT firstly constructs the label-specific feature space LIFT
                        
                           k
                         for each label lk
                         (Steps 2–4); then, dimension reduction in LIFT
                        
                           k
                         is implemented with fuzzy rough set (Steps 5–10); next, m classification models are built in the dimension-reduced label-specific feature space FRS-LIFT
                        
                           k
                         (Steps 13 and 14); finally, the unseen sample is predicted in the multi-label learned system (Step 16).

Formally, FRS-LIFT can be designed as following.

The time complexity of FRS-LIFT mainly comprises of three components: clustering on Pk
                         and Nk
                         in Step 3, forming the label-specific feature space in Step 4, and dimension reduction for the label-specific feature space in Steps 5–10. The cost of performing clustering on Pk
                         and Nk
                         using k-means is 
                           
                              
                                 O
                                 (
                              
                              
                                 m
                                 k
                              
                              
                                 (
                              
                              
                                 t
                                 1
                              
                              
                                 |
                              
                              
                                 P
                                 k
                              
                              
                                 |
                                 +
                              
                              
                                 t
                                 2
                              
                              
                                 |
                              
                              
                                 N
                                 k
                              
                              
                                 |
                                 )
                                 )
                                 ,
                              
                           
                         where t
                        1 and t
                        2 are the iterations of k-means on Pk
                         and Nk
                        , respectively. Forming the label-specific feature space requires O(2mk
                        |T|) time. Finally, the time complexity of dimension reduction is 
                           
                              O
                              (
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              |
                              T
                              
                                 |
                                 2
                              
                              )
                           
                        . Therefore, in general the time complexity of FRS-LIFT is 
                           
                              
                                 O
                                 (
                              
                              
                                 m
                                 k
                              
                              
                                 (
                              
                              
                                 t
                                 1
                              
                              
                                 |
                              
                              
                                 P
                                 k
                              
                              
                                 |
                                 +
                              
                              
                                 t
                                 2
                              
                              
                                 |
                              
                              
                                 N
                                 k
                              
                              
                                 |
                                 )
                              
                              +
                              2
                              
                                 m
                                 k
                              
                              
                                 |
                                 T
                                 |
                              
                              +
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              
                                 
                                    |
                                    T
                                    |
                                 
                                 2
                              
                              
                                 )
                              
                           
                        .

Although FRS-LIFT improves the performance of multi-label learning via reducting redundant label-specific feature dimensionalities, its computational complexity is high. To alleviate this problem, sample selection technique will be introduced in next subsection.

In the field of machine learning, sample selection is considered as a better data compression technique [23]. The ultimate goal of sample selection is to reduce the size of training samples without losing any extractable information, while simultaneously insisting that a learning approach built on the reduced training samples is good or nearly as good as a learning approach built on the original training samples [7]. It is obvious that removing some samples from the training set decreases the computational complexity of learning approach. Several methods of sample selection have been explored and studied, such as condensed nearest neighbor (CNN) algorithm [15], instance-based learning (IB) algorithm [1], selective nearest neighbor (SNN) algorithm [36], and edited nearest neighbor (ENN) algorithm [48].

According to many research [4,48], the uncertainty for samples in the boundary is larger than in other places, which means that the information provided by boundary samples will be more important. Accordingly, the majority of methods of sample selection tend to choose samples in boundary. Similarly, in dimension reduction, we compute a series of similarity matrices in the sample space constructed by boundary samples instead of the original sample space. The time and memory consumption of constructing fuzzy equivalence relations will be reduced greatly. For this purpose, some clustering algorithms, for example, k-means or fuzzy k-means [10,27] algorithm can be employed to seek the samples far away from the center of similar samples. Specifically, we suppose that Cj
                         is a cluster, 
                           
                              C
                              j
                              *
                           
                         is the clustering center of Cj
                        , 
                           
                              d
                              i
                              s
                              t
                              (
                              x
                              ,
                              
                                 C
                                 j
                                 *
                              
                              )
                           
                         denotes the distance between x ∈ Cj
                         and 
                           
                              
                                 C
                                 j
                                 *
                              
                              ,
                           
                         and the average distance between ∀x ∈ Cj
                         and 
                           
                              C
                              j
                              *
                           
                         is represented as following:

                           
                              (11)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   d
                                                   i
                                                   s
                                                   t
                                                
                                                ¯
                                             
                                             
                                                (
                                                
                                                   C
                                                   j
                                                   *
                                                
                                                )
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                1
                                                
                                                   〈
                                                   
                                                      C
                                                      j
                                                   
                                                   〉
                                                
                                             
                                             
                                                ∑
                                                
                                                   x
                                                   ∈
                                                   
                                                      C
                                                      j
                                                   
                                                
                                             
                                             d
                                             i
                                             s
                                             t
                                             
                                                (
                                                x
                                                ,
                                                
                                                   C
                                                   j
                                                   *
                                                
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where ⟨ · ⟩ represents the number of samples in a cluster.

The sample x ∈ Cj
                         whose 
                           
                              d
                              i
                              s
                              t
                              (
                              x
                              ,
                              
                                 C
                                 j
                                 *
                              
                              )
                           
                         is larger than 
                           
                              
                                 
                                    d
                                    i
                                    s
                                    t
                                 
                                 ¯
                              
                              
                                 (
                                 
                                    C
                                    j
                                    *
                                 
                                 )
                              
                           
                         is considered as a boundary sample. With all selected boundary samples, a new classification learning task can be constructed and its computational complexity is reduced in some extent.

In this subsection, we will propose a multi-label learning approach with label-specific feature reduction by sample selection (FRS-SS-LIFT). In the multi-label training set T, FRS-SS-LIFT firstly constructs the label-specific feature space LIFT
                        
                           k
                         for each label lk
                         (Steps 2–4); then, sample selection is adopted to reduce the number of samples in LIFT
                        
                           k
                         (Steps 5–8); next, dimension reduction in the sample-selected label-specific feature space SS-LIFT
                        
                           k
                         is implemented with fuzzy rough set (Steps 9–14); after that, m classification models are built in the dimension-reduced label-specific feature space FRS-SS-LIFT
                        
                           k
                         (Steps 17 and 18); finally, the unseen sample is predicted in the multi-label learned system (Step 20).

Note that k-means algorithm [21] is used to partition all samples into k clusters, where k represents the number of decision classes. In multi-label learning’s framework, for each label l ∈ L, the value of decision for any xi
                         ∈ X equals 
                           
                              +
                              1
                           
                         if xi
                         has l; otherwise, the value equals 
                           
                              −
                              1
                           
                        . Therefore, k is set to be 2 in k-means clustering. The samples far away from their own clustering centers are selected to form a new label-specific feature space.

Formally, FRS-SS-LIFT can be designed as following.

The time complexity of FRS-SS-LIFT mainly comprises of four components: clustering on Pk
                         and Nk
                         in Step 3, forming the label-specific feature space in Step 4, sample selection on the label-specific feature space in Steps 5–8, and dimension reduction for the sample-selected label-specific feature space in Steps 9–14. The cost of performing clustering on Pk
                         and Nk
                         using k-means is 
                           
                              
                                 O
                                 (
                              
                              
                                 m
                                 k
                              
                              
                                 (
                              
                              
                                 t
                                 1
                              
                              
                                 |
                              
                              
                                 P
                                 k
                              
                              
                                 |
                                 +
                              
                              
                                 t
                                 2
                              
                              
                                 |
                              
                              
                                 N
                                 k
                              
                              
                                 |
                                 )
                                 )
                                 ,
                              
                           
                         where t
                        1 and t
                        2 are the iterations of k-means on Pk
                         and Nk
                        , respectively. Forming the label-specific feature space requires O(2mk
                        |T|) time. Then, sample selection on the label-specific feature space needs O(2t
                        3|T|) time, where t
                        3 is the iterations of k-means on |T|. Finally, the time complexity of dimension reduction is 
                           
                              O
                              (
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              |
                              
                                 T
                                 s
                              
                              
                                 |
                                 2
                              
                              )
                              ,
                           
                         where |Ts
                        | is the number of selected samples (boundary samples). Therefore, in general the time complexity of FRS-SS-LIFT is 
                           
                              
                                 O
                                 (
                              
                              
                                 m
                                 k
                              
                              
                                 (
                              
                              
                                 t
                                 1
                              
                              
                                 |
                              
                              
                                 P
                                 k
                              
                              
                                 |
                                 +
                              
                              
                                 t
                                 2
                              
                              
                                 |
                              
                              
                                 N
                                 k
                              
                              
                                 |
                                 )
                              
                              +
                              2
                              
                                 m
                                 k
                              
                              
                                 |
                                 T
                                 |
                              
                              +
                              2
                              
                                 t
                                 3
                              
                              
                                 |
                                 T
                                 |
                              
                              +
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 
                                    |
                                    2
                                 
                                 )
                              
                           
                        .

In the majority of data sets, we have 
                           
                              
                                 |
                                 T
                                 |
                                 −
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 |
                                 >
                              
                              
                                 t
                                 3
                              
                              /
                              
                                 (
                                 2
                                 
                                    m
                                    
                                       k
                                    
                                    2
                                 
                                 )
                              
                              ,
                           
                         then 
                           
                              
                                 (
                                 1
                                 +
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 |
                                 /
                                 |
                                 T
                                 |
                                 )
                                 (
                                 |
                                 T
                                 |
                                 −
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 |
                                 )
                              
                              >
                              
                                 t
                                 3
                              
                              /
                              
                                 (
                                 2
                                 
                                    m
                                    
                                       k
                                    
                                    2
                                 
                                 )
                              
                           
                         ⇔ 
                           
                              2
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              
                                 (
                                 |
                                 T
                                 |
                                 +
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 |
                                 )
                                 (
                                 |
                                 T
                                 |
                                 −
                                 |
                              
                              
                                 T
                                 s
                              
                              
                                 |
                                 )
                                 >
                              
                              
                                 t
                                 3
                              
                              
                                 |
                                 T
                                 |
                              
                           
                         ⇔ 
                           
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              
                                 
                                    |
                                    T
                                    |
                                 
                                 2
                              
                              >
                              2
                              
                                 t
                                 3
                              
                              
                                 |
                                 T
                                 |
                              
                              +
                              4
                              
                                 m
                                 
                                    k
                                 
                                 2
                              
                              
                                 
                                    |
                                    
                                       T
                                       s
                                    
                                    |
                                 
                                 2
                              
                           
                         holds. Therefore, it is shown that the time complexity of FRS-SS-LIFT is lower than that of FRS-LIFT.

To evaluate the performances of our multi-label learning methods, 10 real-world multi-label data sets have been employed in this paper. For each multi-label data set 
                           
                              S
                              =
                              {
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 ,
                                 
                                    Y
                                    i
                                 
                                 )
                              
                              |
                              1
                              ≤
                              i
                              ≤
                              p
                              }
                              ,
                           
                         symbol |S|, dim(S), L(S) and F(S) represent the number of samples, number of features, number of possible labels, and feature type, respectively. Moreover, for better describing the characteristics of data sets, some other multi-label properties [33,58,61,62] also have been adopted such as:

                           
                              •
                              
                                 
                                    
                                       L
                                       C
                                       a
                                       r
                                       d
                                       
                                          (
                                          S
                                          )
                                       
                                       =
                                       
                                          1
                                          p
                                       
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          p
                                       
                                       
                                          |
                                          
                                             Y
                                             i
                                          
                                          |
                                       
                                       :
                                    
                                  measures the average number of labels in each sample;


                                 
                                    
                                       L
                                       D
                                       e
                                       n
                                       
                                          (
                                          S
                                          )
                                       
                                       =
                                       
                                          
                                             L
                                             C
                                             a
                                             r
                                             d
                                             (
                                             S
                                             )
                                          
                                          
                                             L
                                             (
                                             S
                                             )
                                          
                                       
                                       :
                                    
                                  normalizes LCard(S) with the number of possible labels;


                                 
                                    
                                       D
                                       L
                                       
                                          (
                                          S
                                          )
                                       
                                       =
                                       |
                                       {
                                       
                                          Y
                                          i
                                       
                                       |
                                       
                                          (
                                          
                                             x
                                             i
                                          
                                          ,
                                          
                                             Y
                                             i
                                          
                                          )
                                       
                                       ∈
                                       S
                                       }
                                       |
                                       :
                                    
                                  counts the number of distinct label combinations in S;


                                 
                                    
                                       P
                                       D
                                       L
                                       
                                          (
                                          S
                                          )
                                       
                                       =
                                       
                                          
                                             D
                                             L
                                             (
                                             S
                                             )
                                          
                                          
                                             |
                                             S
                                             |
                                          
                                       
                                       :
                                    
                                  normalizes DL(S) with the number of samples.


                        Table 1
                        
                         summarizes some detailed statistics of multi-label data sets used in our experiments. The 10 data sets are chosen from five distinct practical application domains, such as music, audio, biology, text and image. Therefore, the multi-label data sets used in our experiments are more comprehensive.

Since
                         each sample is simultaneously associated with several labels, the performance evaluation in multi-label learning is more complicated than traditional single-label learning. Some popular evaluation metrics in the single-label learning system, such as accuracy, precision, recall and F-measure [41], can’t well adapt to the multi-label learning system. In this paper, five widely used multi-label evaluation metrics proposed in [14,37,39,40] are employed, including average precision, coverage, hamming loss, one error and ranking loss.

Given a multi-label testing set 
                           
                              
                                 T
                                 ′
                              
                              =
                              
                                 {
                                 
                                    (
                                    
                                       x
                                       i
                                    
                                    ,
                                    
                                       Y
                                       i
                                    
                                    )
                                 
                                 |
                                 1
                                 ≤
                                 i
                                 ≤
                                 t
                                 }
                              
                              ,
                           
                         the real-valued function f( ·, ·) produced from the multi-label learning system can be transformed into a ranking function rankf
                        ( ·, ·) [59]. For each l ∈ L, rankf
                        (xi, l) maps f(xi, l) to the grades {1,2,...,m}, i.e., for f(xi, l) > f(xi, l′), rankf
                        (xi, l) < rankf
                        (xi, l′) holds. The detailed multi-label evaluation metrics are presented as following.

                           
                              •
                              Average Precision [37]: evaluates the average fraction of labels ranked above a particular label l ∈ Yi
                                  which actually are in Yi
                                 . The bigger the value of AveragePrecision(f), the better the performance. Specially, the performance is perfect when 
                                    
                                       A
                                       v
                                       e
                                       r
                                       a
                                       g
                                       e
                                       P
                                       r
                                       e
                                       c
                                       i
                                       s
                                       i
                                       o
                                       n
                                       (
                                       f
                                       )
                                       =
                                       1
                                    
                                 .

                                    
                                       (12)
                                       
                                          
                                             
                                                
                                                
                                                
                                                   
                                                      A
                                                      v
                                                      e
                                                      r
                                                      a
                                                      g
                                                      e
                                                      P
                                                      r
                                                      e
                                                      c
                                                      i
                                                      s
                                                      i
                                                      o
                                                      n
                                                      
                                                         (
                                                         f
                                                         )
                                                      
                                                      =
                                                      
                                                         1
                                                         t
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         t
                                                      
                                                      
                                                         1
                                                         
                                                            
                                                               |
                                                            
                                                            
                                                               Y
                                                               i
                                                            
                                                            
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                
                                                
                                                   
                                                      
                                                      ×
                                                      
                                                      
                                                         ∑
                                                         
                                                            l
                                                            ∈
                                                            
                                                               Y
                                                               i
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            |
                                                            
                                                               {
                                                               
                                                                  l
                                                                  ′
                                                               
                                                               |
                                                               r
                                                               a
                                                               n
                                                               
                                                                  k
                                                                  f
                                                               
                                                               
                                                                  (
                                                                  
                                                                     x
                                                                     i
                                                                  
                                                                  ,
                                                                  
                                                                     l
                                                                     ′
                                                                  
                                                                  )
                                                               
                                                               ≤
                                                               r
                                                               a
                                                               n
                                                               
                                                                  k
                                                                  f
                                                               
                                                               
                                                                  (
                                                                  
                                                                     x
                                                                     i
                                                                  
                                                                  ,
                                                                  l
                                                                  )
                                                               
                                                               ,
                                                               
                                                                  l
                                                                  ′
                                                               
                                                               ∈
                                                               
                                                                  Y
                                                                  i
                                                               
                                                               }
                                                            
                                                            |
                                                         
                                                         
                                                            r
                                                            a
                                                            n
                                                            
                                                               k
                                                               f
                                                            
                                                            
                                                               (
                                                               
                                                                  x
                                                                  i
                                                               
                                                               ,
                                                               l
                                                               )
                                                            
                                                         
                                                      
                                                      .
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Coverage [40]: evaluates the average depth of going down the list of labels for covering all the possible labels of sample. The smaller the value of Coverage(f), the better the performance. Specially, the performance is perfect when 
                                    
                                       C
                                       o
                                       v
                                       e
                                       r
                                       a
                                       g
                                       e
                                       (
                                       f
                                       )
                                       =
                                       0
                                    
                                 .

                                    
                                       (13)
                                       
                                          
                                             
                                                
                                                   
                                                      C
                                                      o
                                                      v
                                                      e
                                                      r
                                                      a
                                                      g
                                                      e
                                                      (
                                                      f
                                                      )
                                                   
                                                
                                                
                                                   =
                                                
                                                
                                                   
                                                      
                                                         1
                                                         t
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         t
                                                      
                                                      
                                                         max
                                                         
                                                            l
                                                            ∈
                                                            
                                                               Y
                                                               i
                                                            
                                                         
                                                      
                                                      r
                                                      a
                                                      n
                                                      
                                                         k
                                                         f
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                            i
                                                         
                                                         ,
                                                         l
                                                         )
                                                      
                                                      −
                                                      1
                                                      .
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Hamming Loss [14]: evaluates the average time of misclassification in each sample, i.e., a label not associated with the sample is predicted or a label associated with the sample is not predicted. The smaller the value of HammingLoss(h), the better the performance. Specially, the performance is perfect when 
                                    
                                       H
                                       a
                                       m
                                       m
                                       i
                                       n
                                       g
                                       L
                                       o
                                       s
                                       s
                                       (
                                       h
                                       )
                                       =
                                       0
                                    
                                 .

                                    
                                       (14)
                                       
                                          
                                             
                                                
                                                   
                                                      H
                                                      a
                                                      m
                                                      m
                                                      i
                                                      n
                                                      g
                                                      L
                                                      o
                                                      s
                                                      s
                                                      (
                                                      h
                                                      )
                                                   
                                                
                                                
                                                   =
                                                
                                                
                                                   
                                                      
                                                         1
                                                         t
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         t
                                                      
                                                      |
                                                      h
                                                      
                                                         (
                                                         
                                                            x
                                                            i
                                                         
                                                         )
                                                      
                                                      ⊗
                                                      
                                                         Y
                                                         i
                                                      
                                                      |
                                                      ,
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where h(xi
                                 ) is the predicted label set which is associated with xi
                                 , ⊗ represents symmetric difference between two sets.

One Error [39]: evaluates the average fraction of top-ranked label which is not in the set of possible labels associated with the sample. The smaller the value of OneError(f), the better the performance. Specially, the performance is perfect when 
                                    
                                       O
                                       n
                                       e
                                       E
                                       r
                                       r
                                       o
                                       r
                                       (
                                       f
                                       )
                                       =
                                       0
                                    
                                 .

                                    
                                       (15)
                                       
                                          
                                             
                                                
                                                   
                                                      O
                                                      n
                                                      e
                                                      E
                                                      r
                                                      r
                                                      o
                                                      r
                                                      (
                                                      f
                                                      )
                                                   
                                                
                                                
                                                   =
                                                
                                                
                                                   
                                                      
                                                         1
                                                         t
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         t
                                                      
                                                      Ψ
                                                      
                                                         (
                                                         
                                                            [
                                                            arg
                                                            
                                                               max
                                                               
                                                                  l
                                                                  ∈
                                                                  L
                                                               
                                                            
                                                            f
                                                            
                                                               (
                                                               
                                                                  x
                                                                  i
                                                               
                                                               ,
                                                               l
                                                               )
                                                            
                                                            ]
                                                         
                                                         ∉
                                                         
                                                            Y
                                                            i
                                                         
                                                         )
                                                      
                                                      ,
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where for any predicate τ, 
                                    
                                       Ψ
                                       (
                                       τ
                                       )
                                       =
                                       1
                                    
                                  if τ holds; otherwise, 
                                    
                                       Ψ
                                       (
                                       τ
                                       )
                                       =
                                       0
                                    
                                 .

Ranking Loss [59]: evaluates the average fraction of label pairs which are reversely ordered for the sample. The smaller the value of RankingLoss(f), the better the performance. Specially, the performance is perfect when 
                                    
                                       R
                                       a
                                       n
                                       k
                                       i
                                       n
                                       g
                                       L
                                       o
                                       s
                                       s
                                       (
                                       f
                                       )
                                       =
                                       0
                                    
                                 .

                                    
                                       (16)
                                       
                                          
                                             
                                                
                                                   
                                                      R
                                                      a
                                                      n
                                                      k
                                                      i
                                                      n
                                                      g
                                                      L
                                                      o
                                                      s
                                                      s
                                                      (
                                                      f
                                                      )
                                                   
                                                
                                                
                                                   =
                                                
                                                
                                                   
                                                      
                                                         1
                                                         t
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         t
                                                      
                                                      
                                                         1
                                                         
                                                            
                                                               |
                                                            
                                                            
                                                               Y
                                                               i
                                                            
                                                            
                                                               ∥
                                                               
                                                                  
                                                                     Y
                                                                     i
                                                                  
                                                                  ¯
                                                               
                                                               |
                                                            
                                                         
                                                      
                                                      |
                                                      {
                                                      
                                                         (
                                                         l
                                                         ,
                                                         
                                                            l
                                                            ′
                                                         
                                                         )
                                                      
                                                      |
                                                      f
                                                      
                                                         (
                                                         
                                                            x
                                                            i
                                                         
                                                         ,
                                                         l
                                                         )
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   ≤
                                                
                                                
                                                   
                                                      f
                                                      
                                                         (
                                                         
                                                            x
                                                            i
                                                         
                                                         ,
                                                         
                                                            l
                                                            ′
                                                         
                                                         )
                                                      
                                                      ,
                                                      
                                                         (
                                                         l
                                                         ,
                                                         
                                                            l
                                                            ′
                                                         
                                                         )
                                                      
                                                      ∈
                                                      
                                                         Y
                                                         i
                                                      
                                                      ×
                                                      
                                                         
                                                            Y
                                                            i
                                                         
                                                         ¯
                                                      
                                                      }
                                                      |
                                                      ,
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where 
                                    
                                       
                                          Y
                                          i
                                       
                                       ¯
                                    
                                  denotes the complementary set of Yi
                                 .

In this paper, our FRS-LIFT and FRS-SS-LIFT are compared with three well-established multi-label learning algorithms, including ML-kNN [59], MLNB [60] and LIFT [62]. According to Ref. [59], in ML-kNN, the number of nearest neighbors k and smoothing parameter s are set to be 10 and 1, respectively. For LIFT, FRS-LIFT and FRS-SS-LIFT, we adjust the parameter δ by increasing it from 0.1 to 1.0 (stepsize 0.1), and finally assign δ to 0.2. Note that, to our best knowledge, no theoretical bases have been reported to specify the threshold ε for controlling the change of approximate quality. The optimal value of threshold ε is dependent on the nature of a specific application. Therefore, we conduct a large number of experiments which help us determine an optimal change range of approximate quality. Consequently, our methods achieve better classification performance when ε is between 0.001 and 0.05. Furthermore, all experiments are run on a workstation equipped with a 3.10 Hz processor and a 8.00G memory.

@&#RESULTS@&#

10-fold cross-validation (10-CV) is used for evaluating the effectiveness of different methods in our experiments. 10-CV breaks all samples into 10 groups of the same size, the nine groups compose the multi-label training set and the one group composes the multi-label testing set. The classification process repeats 10 times in turn and the mean value and standard deviation of 10 experimental results are recorded.


                        Table 2–11
                        
                        
                         
                         
                         
                        
                        
                         demonstrate the performance comparisons of our methods with some other multi-label learning methods on above 10 data sets respectively. For each evaluation metric, ↑ indicates the larger the better while ↓ indicates the smaller the better. Meanwhile, the best performance among the five comparing algorithms is highlighted in boldface.

In all the 50 predictive performance results (10 data sets × 5 evaluation metrics), FRS-LIFT ranks in first place among the five comparing algorithms at 44% cases, in second place at 30% cases, in third place at 26% cases, and never ranks in fourth and fifth places. Meanwhile, FRS-SS-LIFT ranks in first place at 42% cases, in second place at 48% cases, in third place at 8% cases, and only 2% cases exist in fourth place. From the performance comparisons of proposed methods (FRS-LIFT and FRS-SS-LIFT) with the most popular multi-label learning methods (ML-kNN, MLNB and LIFT), it is found that the proposed methods achieve satisfactory predictive results on the large majority of multi-label data sets, which means that label-specific feature reduction can greatly improve the learning performance of multi-label learning system.


                        Table 12
                         lists the label-specific feature dimensionalities of three comparing algorithms, including LIFT, FRS-LIFT and FRS-SS-LIFT, which construct multi-label learning systems from the view of label-specific features. On all the 10 data sets, the label-specific feature dimensionalities of our FRS-LIFT and FRS-SS-LIFT are both smaller than LIFT. Taking Yeast as an example for detailed analysis, we can find that the label-specific feature dimensionality of LIFT is 225.00, however, the label-specific feature dimensionalities of FRS-LIFT and FRS-SS-LIFT fall to 180.90 and 179.90, respectively. The decreasing of label-specific feature dimensionalities means that fuzzy rough set based dimension reduction really is an effective approach to eliminate redundant information in label-specific feature space. So naturally, our methods speed up the training process in comparison to LIFT.


                        Table 13
                         and 14
                         list the detailed comparison of FRS-LIFT and FRS-SS-LIFT. From Table 13, it is clear that, via sample selection, the number of samples used for dimension reduction in FRS-SS-LIFT has been greatly reduced in comparison to FRS-LIFT. Although the maximum data compression ratio reaches 50.43% (minimum is 63.56%) in our experiments, as shown in Table 2–11, the predictive performance differences between FRS-SS-LIFT and FRS-LIFT is insignificant, and both of them are superior to some other popular multi-label learning methods. Table 14 shows that time consumption of FRS-SS-LIFT is much smaller than that of FRS-LIFT. For example, on Slashdot, the number of samples used in FRS-LIFT is 3782, suppose that we construct fuzzy equivalence relations for label-specific feature reduction in such an enormous sample space, the memory cost will be very huge. Fortunately, FRS-SS-LIFT chooses 1763 representative samples from the whole 3782 samples, and then the operating efficiency of learning approach has been extremely improved. From Table 14, we can see that time consumption of FRS-LIFT on Slashdot is 130,720 s while FRS-SS-LIFT is only 29,121 s. When the available multi-label datasets are large, such as multimedia databases, genome sequences and financial forecasting, the advantage of FRS-SS-LIFT is more obvious. In some ways, FRS-SS-LIFT can be considered as an evolution of FRS-LIFT.

@&#CONCLUSIONS@&#

Different labels may have distinct characteristics of their own, and then construction of label-specific features for each label is great necessary for multi-label learning. However, the construction of label-specific features may cause the increasing of feature dimensionalities with redundant information. In this paper, we have developed two approaches named FRS-LIFT and FRS-SS-LIFT for multi-label learning, which effectively remove some redundant information existing in label-specific feature space with the idea of fuzzy rough set based attribute reduction. In addition, FRS-SS-LIFT using sample selection comes with the equivalent predictive performance while achieving the low computational complexity in comparison to FRS-LIFT. In other words, FRS-SS-LIFT can be considered as an evolution of FRS-LIFT. The experimental study on 10 data sets from five different application domains demonstrates the superiorities of our proposed two approaches to other three typical multi-label learning approaches, including ML-kNN, MLNB and LIFT.

It is worth noting that FRS-LIFT and FRS-SS-LIFT do not take full account of the correlations between different labels. To further improve the performances of our multi-label learning approaches, we can attempt to fuse them into dimension-reduced label-specific features in the future study.

@&#ACKNOWLEDGMENTS@&#

This work is supported by the National Natural Science Foundation of China (Nos. 61572242, 61305058, 61373062, 61503160, 61502211), Key Program of National Natural Science Foundation of China (No. 61233011), Natural Science Foundation of Jiangsu Province of China (No. BK20130471), Open Project Foundation of Intelligent Information Processing Key Laboratory of Shanxi Province (No. 2014002), Key Laboratory of Oceanographic Big Data Mining & Application of Zhejiang Province (No. OBDMA201501), Postdoctoral Science Foundation of China (No. 2014M550293), Qing Lan Project of Jiangsu Province of China, Postgraduate Research Innovation Foundation of Jiangsu University of Science and Technology (No. YCX15S-10).

@&#REFERENCES@&#


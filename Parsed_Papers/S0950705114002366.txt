@&#MAIN-TITLE@&#A new method to determine basic probability assignment using core samples

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We proposed a method to determine basic probability assignment using core samples.


                        
                        
                           
                           We can generate basic probability assignment on single and compound hypothesis.


                        
                        
                           
                           Relevance ratios based on convex hulls are obtained in a data-driven manner.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Data fusion

Dempster–Shafer theory of evidence

Basic probability assignment

Core sample

Convex hull

@&#ABSTRACT@&#


               
               
                  The Dempster–Shafer theory of evidence (D–S theory) has been widely used in many information fusion systems. However, the determination of basic probability assignment (BPA) remains an open problem which can considerably influence final results. In this paper, a new method to determine BPA using core samples is proposed. Unlike most of existing methods that determining BPA in a heuristic way, the proposed method is data-driven. It uses training data to generate core samples for each attribute model. Then, helpful core samples in generating BPAs are selected. Calculation of the relevance ratio based on convex hulls is integrated into the core sample selection as a new feature of the proposed method. BPAs are assigned based on the distance between the test data and the selected core samples. Finally, BPAs are combined to get a final BPA using the Dempster’s combination rule. In this paper, compound hypotheses are taken into consideration. BPA generated by the proposed method can be combined with some other sources of information to reduce the uncertainty. Empirical trials on benchmark database shows the efficiency of the proposed method.
               
            

@&#INTRODUCTION@&#

Data fusion is an evolving technology used by human to integrate data from sensors continually and make inferences about the real world [1]. The information provided by single sensor may be lack of accuracy or limited. Thus, the use of multiple sensor is aimed to improve the accuracy and can provide the user with increased information about the environment [2]. Applications of data fusion ranges from environment analysis [3,4], clinical diagnosis [5,6], transportation management [7,8] and so on. In order to integrate information from multisensor efficiently, different strategies have been developed for data fusion. Classical Bayesian theory and Dempster–Shafer theory of evidence (D–S theory) [9,10] are two mainstream frameworks in data fusion. When comparing with the classical Bayesian theory, the merit of D–S theory is outweigh. As a useful tool to handle uncertainty, D–S theory has been a research hotspot in the field of data fusion [11–20].

Dempster–Shafer theory of evidence, introduced by Dempster [9] and then developed by Shafer [10] since the early 1980’s, has now developed into a mature stage. But at the same time, it also has some problems. Although Dempster–Shafer theory of evidence is widely used and has good performance in practical applications [21–24], some basic problems are still not clarified. Within the framework of D–S theory, the construction of basic probability assignment (BPA) remains an important problem which can considerably influence final results. However, the determination of BPA remains an open issue. Till now, there is no general method to determine BPA. Many authors have addressed this problem through different approaches [25–28], but most of the existing approaches determine BPA heuristically. Yager [26] associated the D–S belief structure with a whole class of fuzzy measures, and discussed the entropy of a fuzzy measure. Xu [28] put forward a method to obtain BPA based on the normal distribution of data in each attribute. Denoeux [25] proposed a neural network classifier based on D–S theory. In Denoeux’s work [25], the determination of BPA is implemented in a multilayer neural network with the architecture of one input layer and two hidden layers. The weight vector in the neural network is used to determine BPA based on the distance of pattern to its k-nearest neighbor (k-NN) prototypes. Prototype is considered as a representative pattern for each class. This method shows excellent performance as compared to existing statistical and neural network techniques. However, prototype in Denoeux’s work is generated on every single class. Although each prototype is assumed to possess a degree of membership to each class, Denoeux’s methods do not consider the BPA on compound hypotheses and do not exploit all the strengths of the theory. Compound hypotheses are useful and important to represent the uncertainty and imprecise situation and hypothesis on compound set is reallocated proportionally among singleton during the combination process.

Inspired by Denoeux’s work [29,30,25], a new method to determine BPA is proposed in this paper. The main contribution of this paper is the development of a new way to determine the BPA, in which compound hypotheses are taken into consideration. BPA generated by the proposed method can be combined with some other sources of information to reduce the uncertainty. In this method, the basic probability of a pattern to a class is assigned by calculating distance with core samples representing each classification. Since not every core sample is helpful to generate a BPA, whether and which core samples should be selected is quantified by relevance ratio based on convex hulls. For each attribute in the pattern, BPAs are generated and then combined using Dempster’s combination rule to get a final BPA.

The present work extends the use of the Denoeux’s model where BPA can be assigned not only on single hypothesis but also on compound hypotheses. When evidence is not adequate, unlike classical probability theory in which possibilities should be determined forcedly, D–S theory provides a flexible way to determine BPA on both single hypotheses and compound hypotheses. Therefore, when existing information is insufficient to make a convincing conclusion solely on single hypotheses, is it reasonable to introduce compound hypotheses to modeling the uncertainty. Also, we develop some new features into the proposed method that uncertainty of subjectivity is reduced by core sample selection.

The rest of this paper is organized as follows. Section 2 starts with some concepts on D–S theory and some necessary related concepts. The proposed method determining basic probability assignment using core samples and its detailed procedures are presented Section 3. In Section 4, experiments on pattern classification task are conducted using the proposed method. Conclusion is presented in Section 5.

In this section, the main concepts underlying the Dempster–Shafer theory of evidence are recalled. The Dempster–Shafer theory of evidence, as introduced by Dempster [9] and then developed by Shafer [10], has emerged from their works on statistical inference and uncertain reasoning. Compared with the Bayesian probability model, the merits of D–S theory have already been recognized in various fields. First, the D–S theory can handle more uncertainty in real world. In contrast to the Bayesian probability model in which probability masses can be only assigned to singleton subsets, in D–S theory probability masses can be assigned to both singletons and compound sets. Thus, more evidence will be provided to illustrate the hypotheses or the distribution between the singletons. Second, in D–S theory, no prior distribution is needed before the combination of evidence from individual information sources. Third, the D–S theory allows one to specify a degree of ignorance in some situations instead of being forced to be assigned for probabilities. Some notations in D–S theory are introduced.

In D–S theory, Let
                              
                                 (1)
                                 
                                    Θ
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   θ
                                                
                                                
                                                   1
                                                
                                             
                                             ,
                                             
                                                
                                                   θ
                                                
                                                
                                                   2
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   θ
                                                
                                                
                                                   n
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           be the finite set of mutually exclusive and exhaustive events. The set of every subset of Θ, which has the cardinality of 
                              
                                 
                                    
                                       2
                                    
                                    
                                       
                                          
                                             Θ
                                          
                                       
                                    
                                 
                              
                           , is called the frame of discernment, denotes as
                              
                                 (2)
                                 
                                    Ω
                                    =
                                    
                                       
                                          
                                             ∅
                                             ,
                                             
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                             
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                             
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      ,
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         
                                                            θ
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

When some pieces of evidence assigns probability masses to the subsets of Ω, the resulting function is called a basic probability assignment or a mass function. Mathematically, a basic probability assignment is a function m mapping from the power set of Θ to 
                              
                                 
                                    
                                       
                                          0
                                          ,
                                          1
                                       
                                    
                                 
                              
                           , satisfying
                              
                                 (3)
                                 
                                    m
                                    (
                                    ∅
                                    )
                                    =
                                    0
                                 
                              
                           
                           
                              
                                 (4)
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             A
                                             ⊆
                                             Θ
                                          
                                       
                                    
                                    m
                                    (
                                    A
                                    )
                                    =
                                    1
                                 
                              
                           where 
                              
                                 ∅
                              
                            is an empty set and A is any subsets of Θ and the mass function 
                              
                                 m
                                 (
                                 A
                                 )
                              
                            represents how strongly the evidence supports A.

The BPA obtained by two individual information sources are combined according to Dempster’s combination rule, defined as
                              
                                 (5)
                                 
                                    m
                                    (
                                    A
                                    )
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          1
                                          -
                                          K
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             B
                                             ∩
                                             C
                                             =
                                             A
                                          
                                       
                                    
                                    
                                       
                                          m
                                       
                                       
                                          1
                                       
                                    
                                    (
                                    B
                                    )
                                    
                                       
                                          m
                                       
                                       
                                          2
                                       
                                    
                                    (
                                    C
                                    )
                                 
                              
                           with
                              
                                 (6)
                                 
                                    K
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             B
                                             ∩
                                             C
                                             =
                                             ∅
                                          
                                       
                                    
                                    
                                       
                                          m
                                       
                                       
                                          1
                                       
                                    
                                    (
                                    B
                                    )
                                    
                                       
                                          m
                                       
                                       
                                          2
                                       
                                    
                                    (
                                    C
                                    )
                                 
                              
                           where 
                              
                                 A
                                 ,
                                 B
                              
                            and C are subsets of 
                              
                                 
                                    
                                       2
                                    
                                    
                                       
                                          
                                             Θ
                                          
                                       
                                    
                                 
                              
                           , and K is a normalization constant, called the conflict coefficient of two BPAs.

After combination, mass function can be transformed into pignistic probability [31] for decision making. Pignistic probability for A is denoted as:
                              
                                 (7)
                                 
                                    
                                       
                                          P
                                       
                                       
                                          pig
                                       
                                    
                                    (
                                    A
                                    )
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             B
                                             ⊆
                                             θ
                                          
                                       
                                    
                                    
                                       
                                          card
                                          (
                                          A
                                          ∩
                                          B
                                          )
                                          ×
                                          m
                                          (
                                          B
                                          )
                                       
                                       
                                          card
                                          (
                                          B
                                          )
                                          ×
                                          (
                                          1
                                          -
                                          m
                                          (
                                          ∅
                                          )
                                          )
                                       
                                    
                                 
                              
                           Since 
                              
                                 m
                                 (
                                 ∅
                                 )
                                 =
                                 0
                              
                           , this equation can be simplified as:
                              
                                 (8)
                                 
                                    
                                       
                                          P
                                       
                                       
                                          pig
                                       
                                    
                                    (
                                    A
                                    )
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             B
                                             ⊆
                                             θ
                                          
                                       
                                    
                                    
                                       
                                          card
                                          (
                                          A
                                          ∩
                                          B
                                          )
                                          ×
                                          m
                                          (
                                          B
                                          )
                                       
                                       
                                          card
                                          (
                                          B
                                          )
                                       
                                    
                                 
                              
                           where 
                              
                                 card
                                 (
                                 X
                                 )
                              
                            stands for the cardinality of set X.

In the field of computational geometry, convexity [32] is a widely studied problem. The determination of the convex hull [33] is useful in many analysis methods and has successfully been applied to many fields, such as pattern recognition and image processing. If not special specified, the following concepts are based on 2-dimensional space. However, convexity properties also can be seen in one dimension and higher dimensions. In this paper, convex hull is analogously used to describe the shape of a set of data points.

A subset S of the plane is called a convex set if and only if for every pair of points 
                              
                                 p
                                 ,
                                 q
                              
                            in S, the line segment 
                              
                                 
                                    
                                       pq
                                    
                                    
                                       ‾
                                    
                                 
                              
                            is completely contained in S.
                              
                                 
                                    S
                                    ⊆
                                    
                                       
                                          R
                                       
                                       
                                          d
                                       
                                    
                                    
                                    convex
                                    
                                    if
                                    
                                    for
                                    
                                    all
                                    
                                    p
                                    ,
                                    q
                                    ∈
                                    S
                                    ,
                                    
                                    
                                       
                                          pq
                                       
                                       
                                          ‾
                                       
                                    
                                    ∈
                                    S
                                 
                              
                           
                        

The convex hull 
                              
                                 CH
                                 (
                                 S
                                 )
                              
                            of a set S is the smallest convex set that contains S. In Fig. 1
                           , the convex hull of a set of points S is a convex polytope with vertices in S.

A large number of algorithms for determining the convex hull in different dimensional spaces have been proposed [33,35–38].

In 1-dimensional space, convex hull consists of data points with one attribute. The shape of convex hull in 1-dimensional space is described by interval length. The merging of two convex hulls is to find the intersection of two intervals. As for convex hull in 2-dimensional space, for example, given two finite sets of points 
                              
                                 P
                                 1
                              
                            and 
                              
                                 P
                                 2
                              
                           , if 
                              
                                 CH
                                 (
                                 
                                    
                                       P
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 ∩
                                 CH
                                 (
                                 
                                    
                                       P
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 =
                                 ∅
                              
                           , then objects 
                              
                                 P
                                 1
                              
                            and 
                              
                                 P
                                 2
                              
                            do not intersect. See Fig. 2
                           .

In 2-dimensional space, given two convex polygons, the polygon corresponding to the merged convex hulls is the smallest convex polygon containing their union. In efficient algorithms [36,39], convex hulls are merged by setting up bridges between each other. Fig. 3
                            illustrates this concept:

Two disjoint convex polygons are shown in Fig. 3. The merged hull consists of convex chains belonging to the polygons (shown in solid blue
                              1
                              For interpretation of color in Fig. 3, the reader is referred to the web version of this article.
                           
                           
                              1
                            lines), joined by bridges between the polygons (shown in dashed blue lines).

Let us consider an m-class problem where a pattern 
                        
                           
                              
                                 x
                              
                              
                                 s
                              
                           
                           ∈
                           
                              
                                 R
                              
                              
                                 P
                              
                           
                        
                      has to be classified in 
                        
                           M
                           =
                           {
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           m
                           }
                        
                      classes, denote as
                        
                           (9)
                           
                              Θ
                              =
                              {
                              
                                 
                                    ω
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    ω
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    ω
                                 
                                 
                                    m
                                 
                              
                              }
                           
                        
                     The training data with P attributes
                        
                           (10)
                           
                              X
                              =
                              {
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       =
                                       {
                                       
                                          
                                             x
                                          
                                          
                                             1
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             2
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             P
                                          
                                          
                                             i
                                          
                                       
                                       }
                                    
                                 
                              
                              i
                              =
                              1
                              ,
                              …
                              ,
                              T
                              }
                           
                        
                     is acquired by data points with known classification, where T stands for the number of instances.

Core sample is considered as a representative pattern to a set of data points. It represents the average features of a classification. For example, the P-dimensional core sample 
                           
                              
                                 
                                    C
                                 
                                 
                                    m
                                 
                              
                           
                         represents the average features of a set of data points with known classification 
                           
                              
                                 
                                    ω
                                 
                                 
                                    m
                                 
                              
                           
                        . Typically, in an m-class problem, one has to deal with m core samples, which yield m estimations of its classifications. For every single hypothesis, a core sample is generated. It is generated by applying k-means to data points which has the known classification 
                           
                              
                                 
                                    ω
                                 
                                 
                                    m
                                 
                              
                           
                        . For each dimension in a core sample, we would perform k-means once. In our method, since compound hypotheses are taken into consideration to reduce uncertainty, the proposed method need to deal with extra estimations on compound hypotheses. For core sample representing compound classifications, we perform k-mean for data points with their corresponding classifications. For example, a core sample representing the average features of two classifications 
                           
                              
                                 
                                    ω
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    ω
                                 
                                 
                                    b
                                 
                              
                           
                         is denote as
                           
                              (11)
                              
                                 
                                    
                                       C
                                    
                                    
                                       ab
                                    
                                 
                                 
                                 a
                                 ,
                                 b
                                 ∈
                                 M
                                 
                                 and
                                 
                                 a
                                 
                                 ≠
                                 
                                 b
                              
                           
                        It is obtained by performing k-means to all data points in X with the classification 
                           
                              
                                 
                                    ω
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    ω
                                 
                                 
                                    b
                                 
                              
                           
                        . No matter the hypothesis is simple or compound, there is a corresponding core sample representing its average features. That is to say, each core sample represents an estimation of the classification. If there are m classes in the training set, generally we need to deal with m core samples at least, 
                           
                              
                                 
                                    2
                                 
                                 
                                    m
                                 
                              
                              -
                              2
                           
                         core samples at most. From the vocabulary of D–S theory, all the 
                           
                              
                                 
                                    2
                                 
                                 
                                    m
                                 
                              
                              -
                              2
                           
                         core samples including 
                           
                              ∅
                           
                         and 
                           
                              {
                              Ω
                              }
                           
                         can be called the frame of discernment. It should be pointed out that the number of helpful core samples varies from 
                           
                              [
                              m
                              ,
                              
                                 
                                    2
                                 
                                 
                                    m
                                 
                              
                              -
                              2
                              ]
                           
                        , since not every core sample is helpful in generating BPAs. Only representative core samples are selected during the core sample selection. The strategy of core sample selection is discussed in Section 3.3.

We assume that the assign of a given pattern 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         to the estimations of its classification 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    n
                                 
                              
                           
                         (
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                              ⊆
                              M
                              ,
                              card
                              (
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                              )
                              ⩾
                              1
                           
                        ) can be formed by calculating its distance with the selected 
                           
                              card
                              (
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         core samples. If 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         is far from one core sample 
                           
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         representing the classification 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                           
                        , it is considered providing very little information that 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         belongs to classification 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                           
                        . On the contrary, if 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         is close to one core sample 
                           
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                        , it is considered providing much information that 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         belongs to classification 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                           
                        . If the pattern 
                           
                              
                                 
                                    x
                                 
                                 
                                    s
                                 
                              
                           
                         yields n estimations of its classification, BPA should be assigned on 
                           
                              n
                              +
                              1
                           
                         subsets of the frame of discernment, 
                           
                              {
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              }
                              ,
                              {
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              }
                              ,
                              …
                              ,
                              {
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                              }
                           
                         and 
                           
                              {
                              Ω
                              }
                           
                        . The basic probability assigned on 
                           
                              {
                              Ω
                              }
                           
                         stands for the most uncertain situation where it is unable to make estimations on any specific classifications. Thus the basic probability is assigned on 
                           
                              {
                              Ω
                              }
                           
                         to make sure the value of all mass functions sum up to 1. 
                           
                              {
                              Ω
                              }
                           
                         only acknowledges that the pattern do belongs to one of the known classifications. It seems reasonable to definite a decreasing function on the distance:
                           
                              (12)
                              
                                 
                                    
                                       m
                                    
                                    
                                       s
                                    
                                 
                                 
                                    
                                       
                                          {
                                          
                                             
                                                C
                                             
                                             
                                                
                                                   
                                                      N
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          }
                                       
                                    
                                 
                                 =
                                 
                                    
                                       α
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 φ
                                 
                                    
                                       
                                          
                                             
                                                d
                                             
                                             
                                                i
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (13)
                              
                                 
                                    
                                       m
                                    
                                    
                                       s
                                    
                                 
                                 
                                    
                                       
                                          {
                                          Ω
                                          }
                                       
                                    
                                 
                                 =
                                 1
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          n
                                       
                                    
                                 
                                 
                                    
                                       α
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 φ
                                 
                                    
                                       
                                          
                                             
                                                d
                                             
                                             
                                                i
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              0
                              <
                              
                                 
                                    α
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              ⩽
                              1
                           
                         is a constant number given weigh to a monotonically decreasing function φ where 
                           
                              φ
                              (
                              0
                              )
                              =
                              1
                           
                         and 
                           
                              
                                 
                                    lim
                                 
                                 
                                    
                                       
                                          d
                                       
                                       
                                          i
                                       
                                       
                                          s
                                       
                                    
                                    →
                                    ∞
                                 
                              
                              φ
                              (
                              
                                 
                                    d
                                 
                                 
                                    i
                                 
                                 
                                    s
                                 
                              
                              )
                              =
                              0
                           
                        . In [29], an exponential form was proposed for φ
                        
                           
                              (14)
                              
                                 φ
                                 
                                    
                                       
                                          
                                             
                                                d
                                             
                                             
                                                i
                                             
                                             
                                                s
                                             
                                          
                                       
                                    
                                 
                                 =
                                 exp
                                 (
                                 -
                                 
                                    
                                       γ
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 
                                    
                                       (
                                       
                                          
                                             d
                                          
                                          
                                             i
                                          
                                          
                                             s
                                          
                                       
                                       )
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                           
                        while 
                           
                              
                                 
                                    γ
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is a constant number corresponding with the core sample 
                           
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                        . The optimization for the constant number 
                           
                              
                                 
                                    α
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 
                                    γ
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is described in [30].

As mentioned above, not every core sample is helpful in generating BPAs. In this paper, for a set of data points, core sample representing single classification should be generated. They provide necessary information for fundamental hypotheses. On the other hand, whether and which core sample representing compound classifications should be generated are discussed in the following context.

With the help of convex hull, the core sample selection chooses helpful core samples. Intuitively, a rubber band spanned a set of data points is defined as a convex interval or a convex polygon containing all the data points. The length of the resulting convex interval or the shape of the resulting convex polygon can be called the convex hull of the data points. Based on the observations, robust estimation [40] shows the data points in the inner of a data set is generally more trustable than some extreme data points outside the data set. Thus, convex hull of a set of data points is calculated as a preprocessing step to show a common, relatively trustable boundary of the existing data points with known classifications. Convex hulls on data points with single classification 
                           
                              
                                 
                                    ω
                                 
                                 
                                    m
                                 
                              
                           
                         should be generated first, which is denoted as
                           
                              (15)
                              
                                 CH
                                 (
                                 
                                    
                                       C
                                    
                                    
                                       m
                                    
                                 
                                 )
                                 
                                 m
                                 ∈
                                 M
                              
                           
                        When generating core sample 
                           
                              
                                 
                                    C
                                 
                                 
                                    N
                                    ⊆
                                    M
                                 
                              
                           
                         with 
                           
                              card
                              (
                              N
                              )
                              ⩾
                              2
                           
                         representing compound classifications, the question transfer into the similarity between single convex hulls 
                           
                              CH
                              (
                              
                                 
                                    C
                                 
                                 
                                    m
                                 
                              
                              )
                           
                         where 
                           
                              m
                              ∈
                              N
                           
                        . For example, core sample
                           
                              (16)
                              
                                 
                                    
                                       C
                                    
                                    
                                       ab
                                    
                                 
                                 
                                 a
                                 ,
                                 b
                                 ∈
                                 M
                                 
                                 (
                                 a
                                 
                                 ≠
                                 
                                 b
                                 ,
                                 a
                                 
                                 ≠
                                 
                                 ∅
                                 ,
                                 b
                                 
                                 ≠
                                 
                                 ∅
                                 )
                              
                           
                        represents two classification 
                           
                              
                                 
                                    ω
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    ω
                                 
                                 
                                    b
                                 
                              
                           
                        . Whether 
                           
                              
                                 
                                    C
                                 
                                 
                                    ab
                                 
                              
                           
                         can be generated depends on the following rules:
                           
                              •
                              If 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  overlaps with 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                 , it illustrates that data points in the training data consider more similarity than confliction to each other. D–S theory can process information by re-allocating the masses assigned on the non-single hypotheses proportionally into the single hypotheses during the combination process. Thus, 
                                    
                                       
                                          
                                             C
                                          
                                          
                                             ab
                                          
                                       
                                    
                                  is supposed to be generated under this circumstance. We use the relevance ratio to quantify the degree of similarity. In this case, we set
                                    
                                       (17)
                                       
                                          
                                             
                                                R
                                             
                                             
                                                ab
                                             
                                          
                                          =
                                          1
                                       
                                    
                                 
                              

If 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  are not overlapping, the degree of similarity could be measure by calculating the proportion of 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  in merged convex hull 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       +
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                 . In this case, the relevance ratio is calculated according to the following equation:
                                    
                                       (18)
                                       
                                          
                                             
                                                R
                                             
                                             
                                                ab
                                             
                                          
                                          =
                                          
                                             
                                                CH
                                                (
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      a
                                                   
                                                
                                                )
                                                +
                                                CH
                                                (
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      b
                                                   
                                                
                                                )
                                             
                                             
                                                CH
                                                (
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      a
                                                   
                                                
                                                +
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      b
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 where 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  stands for the boundary of data with classification 
                                    
                                       
                                          
                                             ω
                                          
                                          
                                             a
                                          
                                       
                                       ,
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  stands for which with classification 
                                    
                                       
                                          
                                             ω
                                          
                                          
                                             b
                                          
                                       
                                    
                                 . 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       +
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  stands for the merging of 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                 . 
                                    
                                       
                                          
                                             R
                                          
                                          
                                             ab
                                          
                                       
                                    
                                  decreases as 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  are getting isolated to each other. In 1-dimensional space, 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  are the interval lengths of data with classification 
                                    
                                       
                                          
                                             ω
                                          
                                          
                                             a
                                          
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             ω
                                          
                                          
                                             b
                                          
                                       
                                    
                                  respectively. 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       +
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                  is the shortest continuous interval containing 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             a
                                          
                                       
                                       )
                                    
                                  and 
                                    
                                       CH
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             b
                                          
                                       
                                       )
                                    
                                 . A numeric experiment of calculating the relevance ratio using the Eq. (18) is presented in Section 4.

Relevance ratio in our method is introduced to portray the similarity between two convex hulls. When two convex hulls are overlapping, existing evidence shows that two sets of data points are intersect. Therefore, by the evidence we obtained so far, they cannot be easily distinguished from each other. Thus, the similarity is relatively high in this situation. When two convex hulls are not overlapping, more isolated two convex hulls are, the less we consider they have similarity to each other. Quantified the similarity by relevance ratio, compound hypothesis whose relevance ratio under a specific degree is not encouraged in generating BPAs.

For compound classification 
                           
                              N
                              ⊆
                              M
                           
                         where 
                           
                              card
                              (
                              N
                              )
                              ⩾
                              2
                           
                        , a threshold 
                           
                              
                                 
                                    R
                                 
                                 
                                    T
                                 
                              
                           
                         is denoted. If 
                           
                              
                                 
                                    R
                                 
                                 
                                    N
                                 
                              
                              >
                              
                                 
                                    R
                                 
                                 
                                    T
                                 
                              
                           
                        , we consider this hypothesis worth generating. Otherwise, the inner dissimilarity within compound hypothesis exceed some degree, therefore, this compound hypothesis should not be supported.

It should be pointed out that in 1-dimensional space, we use interval length to measure the approximate shape of convex hulls and their intersections, while in 2-dimensional and 3-dimensional space we use area and volume to measure respectively.

A flow chart of the main process of the proposed method is shown in Fig. 4
                        . The details of this procedure are described as follows.

Since multivariate data are common in practice, for a given multivariate data, every individual variate is considered as an attribute. Attribute can be multivariate if these multivariate are obtained from the same source. The proposed method can be used to obtain BPA for each attribute. We consider each attribute as a unique source of information. During the attribute division, test data with k attributes is divided and transformed into k attribute models.

Then, core samples are generated representing single and compound classifications. Next, by calculating relevance ratio based on convex hulls, core sample selection determined which core samples representing compound classifications are helpful in generating BPAs. After that, BPA is generated for each attribute model. Then, BPAs from every attribute model are combined to get a final BPA for the whole training data. Finally, the final BPA can be transformed into pignistic probability for decision making.

It should be pointed out that when evidence is highly conflicting, D–S rule may produce counter-intuitive results. In our approach, the way we generate BPA is aimed at avoiding highly conflicting BPAs. Unlike classical probability theory in which possibilities are forcedly assigned even the information is not adequate for decision making, in our approach, we assigned possibilities on single hypotheses as well as compound hypotheses. Especially, we can also assign possibilities on 
                           
                              {
                              Ω
                              }
                           
                        . By doing this, only convincing evidences are assigned to single hypotheses. In other situations where it is hard to distinguish single hypotheses with each other, we assign BPA in a much more flexible manner (to assign possibilities on compound hypotheses to reduce uncertainty). Thus, highly conflicting evidence can be avoided. Therefore, in our approach, D–S rule is enough to handle conflict evidence. However, if some extreme cases happened, other methods, such as average [41] and weighted average [42] can be taken into consideration.

@&#EXPERIMENTS@&#

The proposed method is illustrated with real data based examples of pattern classification task. First, a simple example is presented on Iris data to generate BPAs, in which a simple numerical example on calculating relevance ratio is presented. After that, the threshold 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                        
                      in selecting compound classification is presented. Its influence in the accuracy of classification tasks is then discussed. Finally, the proposed method is compared with the related work and other well-known classifiers on various real data sets to show the efficiency of the proposed method.

First, we conducted an experiment on the Iris data [43]. Iris data is a well-known benchmark dataset in pattern classification. It involves three classes of Iris flowers – Iris Setosa (a), Iris Versicolour (b) and Iris Virginica (c). Each class of Iris flowers is consist of 50 instances with four attributes: sepal length (SL) in cm, sepal width (SW) in cm, petal length (PL) in cm, and petal width (PW) in cm. All four attributes are considered as four unique information sources in this experiment.

In this experiment, 30 of 50 instances in each class are randomly selected as the training data, the remaining are served as test data. Core samples are generated and selected for every attribute in the training set. For instances in test data, BPAs are obtained using these core samples. After combination of BPAs, the final BPA is transformed into pignistic probability. The hypothesis on the classification with the maximum pignistic probability is chosen as the predicted class of the instance in the test data. Then confusion matrix is used to illustrate the accuracy of the pattern classification tasks, from the other side of view, shows the performance of the proposed method. The details of the experiment are as follows.

As the training data is consists of four attributes, it is divided into four attribute models. Table 1
                      shows core samples generated from each attribute model in the training data by applying k-means to data points.

All core samples representing single classification should be selected, while core samples representing compound classifications are selected based on the relevance ratio of each core sample. In order to obtain relevance ratios for each attribute model, convex hulls need to be calculated first. In this case, since each attribute model is in 1-dimensional space, we use interval length to measure the approximate shape of convex hulls. Table 2
                      shows convex hulls of each attribute model.

Then, relevance ratios are calculated using Eqs. (17) and (18). For example, in attribute model PL, since 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 b
                              
                           
                           )
                        
                      and 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 c
                              
                           
                           )
                        
                      are overlapping, according to Eq. (17), 
                        
                           
                              
                                 R
                              
                              
                                 bc
                              
                           
                           =
                           1
                        
                     . 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 a
                              
                           
                           )
                        
                      and 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 b
                              
                           
                           )
                        
                      are not overlapping, therefore 
                        
                           
                              
                                 R
                              
                              
                                 ab
                              
                           
                        
                      is calculated according to Eq. (18). Since 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 a
                              
                           
                           )
                           =
                           [
                           1.0
                           ,
                           1.9
                           ]
                        
                      and 
                        
                           CH
                           (
                           
                              
                                 C
                              
                              
                                 b
                              
                           
                           )
                           =
                           [
                           3.3
                           ,
                           5.0
                           ]
                        
                     , 
                        
                           (19)
                           
                              CH
                              (
                              
                                 
                                    C
                                 
                                 
                                    a
                                 
                              
                              )
                              +
                              CH
                              (
                              
                                 
                                    C
                                 
                                 
                                    b
                                 
                              
                              )
                              =
                              (
                              1.9
                              -
                              1.0
                              )
                              +
                              (
                              5.0
                              -
                              3.3
                              )
                              =
                              2.6
                           
                        
                     
                     
                        
                           (20)
                           
                              CH
                              (
                              
                                 
                                    C
                                 
                                 
                                    a
                                 
                              
                              +
                              
                                 
                                    C
                                 
                                 
                                    b
                                 
                              
                              )
                              =
                              5.0
                              -
                              1.0
                              =
                              4.0
                           
                        
                     Thus,
                        
                           (21)
                           
                              
                                 
                                    R
                                 
                                 
                                    ab
                                 
                              
                              =
                              
                                 
                                    CH
                                    (
                                    
                                       
                                          C
                                       
                                       
                                          a
                                       
                                    
                                    )
                                    +
                                    CH
                                    (
                                    
                                       
                                          C
                                       
                                       
                                          b
                                       
                                    
                                    )
                                 
                                 
                                    CH
                                    (
                                    
                                       
                                          C
                                       
                                       
                                          a
                                       
                                    
                                    +
                                    
                                       
                                          C
                                       
                                       
                                          b
                                       
                                    
                                    )
                                 
                              
                              =
                              
                                 
                                    2.6
                                 
                                 
                                    4.0
                                 
                              
                              =
                              0.65
                           
                        
                     In the same way,
                        
                           (22)
                           
                              
                                 
                                    R
                                 
                                 
                                    ac
                                 
                              
                              =
                              
                                 
                                    (
                                    1.9
                                    -
                                    1.0
                                    )
                                    +
                                    (
                                    6.9
                                    -
                                    4.5
                                    )
                                 
                                 
                                    6.9
                                    -
                                    1.0
                                 
                              
                              =
                              
                                 
                                    3.3
                                 
                                 
                                    5.9
                                 
                              
                              ≈
                              0.5593
                           
                        
                     
                  


                     Table 3
                      shows the relevance ratios of each attribute model.

In this paper, we set 
                        
                           
                              
                                 R
                              
                              
                                 T
                              
                           
                           =
                           0.9
                        
                     . Thus, 
                        
                           {
                           
                              
                                 ω
                              
                              
                                 a
                              
                           
                           ,
                           
                              
                                 ω
                              
                              
                                 b
                              
                           
                           }
                           ,
                           {
                           
                              
                                 ω
                              
                              
                                 a
                              
                           
                           ,
                           
                              
                                 ω
                              
                              
                                 c
                              
                           
                           }
                        
                      in attribute model PL and PW are not selected. Other core samples representing compound classification N are considered helpful in generating BPAs since 
                        
                           
                              
                                 R
                              
                              
                                 N
                              
                           
                           >
                           
                              
                                 R
                              
                              
                                 T
                              
                           
                        
                     .

For every instance in test data, four sets of BPAs are generated, each obtained from an attribute model. A sample instance from test data of Virginica, whose attributes are:
                        
                           
                              SL
                              =
                              6.9
                              
                              cm
                              
                              SW
                              =
                              3.1
                              
                              cm
                              
                              PL
                              =
                              5.4
                              
                              cm
                              
                              PW
                              =
                              2.1
                              
                              cm
                           
                        
                     is taken as an example. In Table 4
                     , BPAs for every attribute model of the sample instance are calculated using (12) and (13).

Using the Dempster’s combination rule (Eq. (5)) to combine these four BPAs, we obtain the final BPA:
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       a
                                       }
                                    
                                 
                              
                              =
                              0.0317
                              
                              m
                              
                                 
                                    
                                       {
                                       b
                                       }
                                    
                                 
                              
                              =
                              0.2862
                              
                              m
                              
                                 
                                    
                                       {
                                       c
                                       }
                                    
                                 
                              
                              =
                              0.6089
                           
                        
                     
                     
                        
                           
                              m
                              
                                 
                                    
                                       
                                          
                                             
                                                ab
                                             
                                          
                                       
                                    
                                 
                              
                              =
                              0.0057
                              
                              m
                              
                                 
                                    
                                       
                                          
                                             
                                                ac
                                             
                                          
                                       
                                    
                                 
                              
                              =
                              0.0067
                              
                              m
                              
                                 
                                    
                                       
                                          
                                             
                                                bc
                                             
                                          
                                       
                                    
                                 
                              
                              =
                              0.0300
                           
                        
                     
                     
                        
                           
                              m
                              
                                 
                                    
                                       
                                          
                                             
                                                Ω
                                             
                                          
                                       
                                    
                                 
                              
                              =
                              0.000017
                           
                        
                     
                  

The final BPA can be transformed into pignistic probability using Eq. (8). In this case, we obtained:
                        
                           
                              
                                 
                                    P
                                 
                                 
                                    pig
                                 
                              
                              
                                 
                                    
                                       {
                                       a
                                       }
                                    
                                 
                              
                              =
                              0.0379608
                              
                              
                                 
                                    P
                                 
                                 
                                    pig
                                 
                              
                              
                                 
                                    
                                       {
                                       b
                                       }
                                    
                                 
                              
                              =
                              0.3040812
                              
                              
                                 
                                    P
                                 
                                 
                                    pig
                                 
                              
                              
                                 
                                    
                                       {
                                       c
                                       }
                                    
                                 
                              
                              =
                              0.6273121
                           
                        
                     where 
                        
                           
                              
                                 P
                              
                              
                                 pig
                              
                           
                           
                              
                                 
                                    {
                                    c
                                    }
                                 
                              
                           
                        
                      has the maximum pignistic probability. So we predict this instance in test data belongs to Iris Virginica, which coincides with its actual class.

Relevance ratio in the proposed method is used to quantify the similarity between corresponding single hypotheses in a compound hypothesis. Fig. 5
                      shows how the determination 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                        
                      affects the classification accuracy in different real data sets. The determination of 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                        
                      reveals the tolerance to inner dissimilarity within compound hypothesis. In application, the higher we set 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                        
                     , the more we eliminate core samples representing compound hypotheses with relatively high degree of inner dissimilarity.

When we set 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           1
                        
                     , the proposed method refused to generate any core samples on compound hypotheses whose consisting single hypotheses are not overlapping. Only compound hypotheses consist of two overlapping single hypotheses are encouraged in generating BPAs.

When 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           0
                        
                     , the similarity within compound hypotheses is totally neglected, that is to say, every core sample representing compound hypotheses is encouraged in generating BPAs. Even a compound hypothesis consists of two highly isolated single hypotheses is supported, which may leads to counter-intuitive classification results.

According to Fig. 5, when 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           1
                        
                      the classification tasks may achieve the highest accuracy, but we cannot make sure compound hypothesis consists of two overlapping single hypotheses always exists in every attribute model. If corresponding single hypotheses inside every compound hypotheses are highly isolating and we set 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           1
                        
                     , then all compound hypotheses will not be taken into consideration. Thus, we set 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           0.9
                        
                      to make sure some compound hypotheses will be supported when compound hypotheses containing two overlapping single hypotheses are not available. Moreover, we set 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           =
                           0.9
                        
                      to make sure those compound hypotheses whose relevance ratio exceed 
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                        
                      are still useful enough to provide reasonable core samples.

Finally, a confusion matrix of the proposed method is generated for all instances in the test data. As can be seen in Table 5
                     , the pattern classification task achieves the correct prediction of 58/60 instances.

The confusion matrix of the related work [29],where focal elements possess fully membership on single hypotheses, is shown in Table 6
                     . The confusion matrix of an evidential neural network classifier [25] is shown in Table 7
                     .

In [29], a given pattern is classified using the evidence of its nearby sample observation. According to the k-nearest neighbor (k-NN) rule mentioned in [29], an unclassified sample is assigned to the class by calculating the distance with its k-nearest neighbors. As referenced by [29], although k-NN rule is widely used in the Pattern Recognition literature, the main drawback of this k-NN method is that it assumed that the k-nearest neighbors of a given data point can be obtained in a region of relatively small volume, so that estimations of its classifications can be easily made. However, in practice, the distance between the given data points and one of its nearest neighbors is not always negligible. Outside the high-density region, the distance can become very large. What is more, from the aspect of algorithm, the computational complexity of the search for the nearest neighbors in a training set is known to be another drawback of k-NN techniques[25]. In [25], the computational problem may be alleviated by synthesizing the learning set in the form of a limited number of representative patterns. Compared with [29,25], the proposed methods also alleviated the computational problem. Each time when a pattern is given, there is no need to search for its nearest neighbors. Core samples are only generated once during the whole processes. Then the distance of the given pattern with a specific number of core samples are calculated.

In [25], focal elements possess fully membership on single hypotheses. Compound hypotheses are not considered. While the proposed method took compound hypotheses into consideration. The basic probability assigned on compound hypotheses can be synthesized with other information sources to reduce uncertainty. Thus the proposed method provides a much flexible way to generate BPA as well as to reduce uncertainty.

In order to be better illustrated, some sets of BPAs generated by [29,25] and the proposed methods are shown in the following context. For example, as shown in Fig. 6
                     , we select a sample from the testing data:
                        
                           
                              SL
                              =
                              6.0
                              
                              cm
                              
                              SW
                              =
                              2.7
                              
                              cm
                              
                              PL
                              =
                              5.1
                              
                              cm
                              
                              PW
                              =
                              1.6
                              
                              cm
                              
                              Species
                              :
                              
                              Iris
                              
                              Versicolor
                              (
                              b
                              )
                           
                        
                     
                  

Using the method in [29], we obtained the BPAs in Table 8
                      and the final BPA:
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       a
                                       }
                                    
                                 
                              
                              =
                              0
                              
                              m
                              
                                 
                                    
                                       {
                                       b
                                       }
                                    
                                 
                              
                              =
                              0.0016
                              
                              m
                              
                                 
                                    
                                       {
                                       c
                                       }
                                    
                                 
                              
                              =
                              0.9980
                              
                              m
                              
                                 
                                    
                                       {
                                       Ω
                                       }
                                    
                                 
                              
                              =
                              0.004
                           
                        
                     According to the mass function 
                        
                           m
                           
                              
                                 
                                    {
                                    c
                                    }
                                 
                              
                           
                           =
                           0.9980
                        
                     , it is likely to say that this sample belongs to Iris Virginica (c). However, actually it is a sample of Iris Versicolour (b). The proposed method [29] tried to produce only one precise estimation of the classification. In some applications, just like the case we chose, the given pattern may have several different possible estimations, and the classification result of the given pattern (test sample) with different estimations can be very different. When in some attribute model (in this case SL, SW and PL), the features of different classifications cannot be easily distinguished from each other, but the k-NN rule in [29] does not have such strategy to handle uncertainty in this situation thus the BPA generated can be highly conflict. Therefore, due to insufficient information in training data, the k-NN rule is really hard to correctly classify the given pattern under uncertainty and to make a specific classification.

Using the method in [25], we obtained the BPAs in Table 9
                     . After combination, the final BPA is:
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       a
                                       }
                                    
                                 
                              
                              =
                              3.2554
                              ×
                              
                                 
                                    10
                                 
                                 
                                    -
                                    6
                                 
                              
                              
                              m
                              
                                 
                                    
                                       {
                                       b
                                       }
                                    
                                 
                              
                              =
                              0.2054
                              
                              m
                              
                                 
                                    
                                       {
                                       c
                                       }
                                    
                                 
                              
                              =
                              0.7919
                              
                              m
                              
                                 
                                    
                                       {
                                       Ω
                                       }
                                    
                                 
                              
                              =
                              0.0027
                           
                        
                     Since 
                        
                           m
                           
                              
                                 
                                    {
                                    c
                                    }
                                 
                              
                           
                           =
                           0.7919
                        
                     , even after the transformation into pignistic probability, the BPA generated using the method in [25] is not convincing enough for a correct classify decision.

While applied with the proposed method, we obtained BPAs in Table 10
                      and the final BPA:
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       a
                                       }
                                    
                                 
                              
                              =
                              0.0256
                              
                              m
                              
                                 
                                    
                                       {
                                       b
                                       }
                                    
                                 
                              
                              =
                              0.4552
                              
                              m
                              
                                 
                                    
                                       {
                                       c
                                       }
                                    
                                 
                              
                              =
                              0.4137
                           
                        
                     
                     
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       ab
                                       }
                                    
                                 
                              
                              =
                              0.0082
                              
                              m
                              
                                 
                                    
                                       {
                                       ac
                                       }
                                    
                                 
                              
                              =
                              0.0092
                              
                              m
                              
                                 
                                    
                                       {
                                       bc
                                       }
                                    
                                 
                              
                              =
                              0.0611
                              
                           
                        
                     
                     
                        
                           
                              m
                              
                                 
                                    
                                       {
                                       Ω
                                       }
                                    
                                 
                              
                              =
                              0.0037
                           
                        
                     In this case, after pignistic probability transformation, our method’s prediction coincides with its actual classification. In our method, all possible core samples representing compound hypotheses are taken into consideration since compound hypotheses are useful and important to represent the uncertainty and imprecise situation during the classification. Compound hypotheses will be conditionally kept for the uncertain patterns that are hard to correctly classify. Although on the whole, the classification accuracy of the proposed method is lower than [25] (but higher than [29]), it shows its advantage in handling uncertainty by introducing compound hypotheses into the method.

As a new way to determine BPA in a data classifier using belief functions, the proposed method will compare with other well-known classifiers in the following experiment. Other classifiers are considered including Naive Bayes [44], Bayes Net [45], Decision Tree Learner (REPTree) [46], Random Forest [47] and One Nearest Neighbor (IB1) [48]. Besides the Iris dataset, we also consider other real data sets in the experiments, which are from the UC Irvine Machine Learning Repository [49].

In all real data sets we use, 60% of the data are randomly selected to build the training data set, while the remaining is served as test data. Table 11
                      shows the general information about the real data sets. Within this, the Heart dataset (Statlog collection) is concerned with predicting the presence or absence of heart disease, which is based on some general information about a patient and some test results. The wine data set is the result of chemical analysis of three types of wines from different regions. The Haberman data set (Haberman’s Survival Data Set) consists of two categories, but all the attributes are numerical not categorical, which are better applied with our method. The Iris data set, as mentioned above, is perhaps the best known database to be found in pattern recognition literature. The Seeds data set is the measurements of geometrical properties of kernels belonging to three different varieties of wheat. The relationship between the determination of relevance ratio and the accuracy of classification tasks is best illustrated with the Seeds data set.


                     Table 12
                      presents the accuracy of the proposed method with various classifiers on different real data sets. The average accuracy in Table 12 provides evidence to support that the proposed method is reasonable and effective in generating BPAs. The accuracy of the proposed method is not obviously higher than other classifiers, but it introduces a new way to determine BPA using core samples, and it can be combined with some other sources of information to reduce the uncertainty.

@&#CONCLUSION@&#

In many pattern classification application systems based on D–S theory, how to determine basic probability assignment remains an open issue. Our study focuses on a new method to determine BPA using core samples. The proposed method uses training data to generate core samples for each attribute model. Then, core samples helpful in generating BPAs are selected. Core sample representing single classification should be generated since they provide necessary information for fundamental hypotheses. Whether and which core sample representing compound classifications should be generated is quantified by calculating relevance ratio based on convex hulls. Next, a set of BPAs are assigned based on the distance between the test data and the selected core samples. Finally, BPAs are combined using the Dempster’s combination rule.

The advantages of the proposed method are:
                        
                           1.
                           The method is data-driven and can reduce the uncertainty of subjectivity by core sample selection.

The method can generate BPAs on not only single hypothesis but also compound hypothesis, which gives more evidence to illustrate the hypotheses or the distribution between the singletons.

Since convex properties can be seen in one dimension and higher dimensions, the proposed method can be applied on both single-variate and multi-variate attribute models.

The proposed method can perform well without a large amount of training data.

Empirical trials on benchmark database shows that the proposed method performs well and can be easily used in many practical applications, such as possible applications in risk analysis and water quality modeling. Additional research is focusing on attribute model with multivariate data which takes convex hulls on multi-dimensional space into account.

@&#ACKNOWLEDGEMENT@&#

The authors greatly appreciate the reviews’ suggestions. The work is partially supported by National Natural Science Foundation of China (Grant Nos. 61174022 and 71271061), R&D Program of China (2012BAH07B01), National High Technology Research and Development Program of China (863 Program) (Grant No. 2013AA013801), Science and Technology Planning Project of Guangdong Province, China (Grant Nos. 2010B010600034 and 2012B091100192), Business Intelligence Key Team of Guangdong University of Foreign Studies (Grant No. TD1202), Doctor Funding of Southwest University (Grant No. SWU110021), China State Key Laboratory of Virtual Reality Technology and Systems.

@&#REFERENCES@&#


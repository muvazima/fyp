@&#MAIN-TITLE@&#Fast automated segmentation of wrist bones in magnetic resonance images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Magnetic resonance of wrist is used in the diagnosis of rheumatoid arthritis (RA).


                        
                        
                           
                           Segmentation of wrist bones is necessary for automated evaluation of RA lesions.


                        
                        
                           
                           A framework for automated segmentation of wrist bones was developed.


                        
                        
                           
                           An excellent agreement with gold truth data was reported.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image segmentation

Rheumatoid arthritis

Magnetic resonance imaging

Watershed from markers

Wrist

@&#ABSTRACT@&#


               
               
                  Purpose
                  According to current recommendations in diagnostics of rheumatoid arthritis (RA), Magnetic resonance (MR) images of wrist joints are used to evaluate three main signs of RA: synovitis, bone edema and bone erosions. In this paper we present an efficient method for segmentation of 15 bones present on MR images of the wrist which is inevitable for future computer-assisted diagnosis system for RA lesions.
               
               
                  Method
                  The segmentation procedure consists of two stages. The first stage is evaluation of markers (parts of bones working as seeds for the watershed algorithm) for bones in every joint: the distal parts of ulna and radius, the proximal parts of metacarpal bones and carpal bones. In the second stage the watershed from markers algorithm is applied based on the markers determined in the previous stage and the wrist bones are segmented. The markers were found using Multi Otsu algorithm along with custom method for filtering bones from other tissues.
               
               
                  Results
                  We analyzed 34 MR images. The automated segmentations were compared with manual segmentations using metrics: accuracy ACC derived from area under ROC curve AUC, Dice coefficient and mean absolute distance MAD. The mean (standard deviation) values of ACC, Dice and MAD were 0.99 (0.02), 0.98 (0.04) and 1.21 (0.39), respectively.
               
               
                  Conclusion
                  The results of this study prove that our method is efficient and gives satisfactory results for segmentation of bones on low-field MR images of the wrist
               
            

@&#INTRODUCTION@&#

The purpose of this study was to create a fully-automatic, reasonably fast tool for segmenting wrist bones present on 0.2T low-contrast MR images of the wrist that are used in diagnosis of rheumatoid arthritis (RA). RA is a chronic systemic inflammatory disease of unknown cause. The hallmark feature of RA is the progressive and irreversible destruction of articular and periarticular structures, that usually starts in the wrist [1]. The prevalence rate is approximately 1%, increasing with age (peak between the age of 35–50), depending also on gender, race/ethnicity, and calendar year. Extra-articular involvement of organs such as the skin, heart, lungs, and eyes can be significant. The risk of death of people with RA is therefore significantly higher compared with age- and sex-matched controls without RA due to increased risk from gastrointestinal, respiratory, cardiovascular, infectious, and hematologic diseases among RA patients [2]. An early diagnosis of RA is essential for delaying irreversible joint destruction resulting in functional disabilities. Sensitive diagnostic tools are necessary for efficient antiarthritic therapy and accurate monitoring of disease activity. RA starts with autoimmune reaction to some external trigger that causes inflammation of the synovium (synovitis) that further leads to destruction of various tissues: bone, cartilage, tendons, ligaments, and blood vessels. The earliest symptoms are therefore synovitis, bone edema and bone erosions. Currently, the most promising image-based diagnostic tool in RA is magnetic resonance imaging (MRI). In 2005 Outcome Measures in Rheumatology Clinical Trials MRI working group (OMERACT) developed an RA scoring system (RAMRIS) [3] for assessing the earliest symptoms on MRI images of the wrist. RAMRIS is reproducible and sensitive to changes due to therapy or disease progress that outperforms other common methods of assessing RA. However some of its limitations are also recognized. Firstly, RAMRIS scoring is time-consuming since it requires analyzing and quantifying multiple, frequently small details in three dimensions (e.g. erosions and bone edema in 15 bones). Secondly, RAMRIS is a semi-quantitative scoring system (e.g. the actual volumes of erosions or edema are not reported), and thus it may seem too rigid, especially for quantifying early changes or therapy monitoring. A limited set of RAMRIS scores can be also a source of a substantial inter-operator variability [4].

Recently there have been some efforts to develop quantitative methods of assessing RA-related changes and comparing them with RAMRIS outcomes [5–7]. These methods were however essentially based on manual outlining of wrist bones or joints borders in 3T MR images of wrist. Other recently published studies [8,9] used semi-automatic methods for quantifying lesions. Those methods [8,9] require however substantial manual work related to extraction of bone regions from a MR image (later we compare our results with one of them).

In immediately follows from the trends of the recent studies that the most important feature of the future CAD systems for supporting RA diagnosis would be segmentation of wrist bones that would enable subsequent detection of joints (i.e. inter-bone regions) for the quantification of synovitis and marrow space for the search and quantifying of bone edema. Comparison of the external surfaces of bones with anatomical models will enable detection and quantification of bone erosions.

Apart from our algorithm presented in [10] there is no comprehensive framework for automated segmentation of wrist bones in MR images designed for low resolution low-field MR images. There are a few studies focused on segmentation of eight carpal bones in CT [11,12] or high-field MR images [13], while RA diagnosis requires evaluating 15 wrist bones. Moreover, apart from our previous study [10], there is no wrist segmentation framework designed for low resolution low-field MR images. Low-field (0.2T) extremity scanners are more popular primarily because they are less expensive, more comfortable for patients, and better accessible than high-field scanners. They offer, however, lower image quality due to lower signal-to-noise ratio and worse resolution. For these reasons they are more demanding for automatic processing.

The algorithm presented in [10] was essentially based on registering atlas images to actual images. On the output of the algorithm described in [10] there were markers of all 15 wrist bones. The markers were then used by the watershed from markers algorithm to produce the final segmentation of bones. A substantial part of the processing was performed in 3D space, resulting in a long computation time. In the present paper we present improved and faster segmentation framework for low-field MR images as compared with [10]. The main effort of the present study was to improve the method of calculating markers used in watershed from markers algorithm.

The remaining part of this paper includes two sections. In Section 2 we describe details concerning the analyzed MR data and processing tools and the segmentation algorithm itself and, finally, the algorithm is evaluated and conclusions are drawn in Section 3.

@&#MATERIAL AND METHODS@&#

The wrist is a collection of 15 bones that stretch from the hand to the forearm. The bones comprising to the wrist include the distal ends of the radius and ulna, 8 carpal bones, and the proximal portions of the 5 metacarpal bones (
                        Fig. 1). Numerous ligaments provide flexibility and stability of the wrist bones and bound carpals to other carpals, to metacarpal bases, to radius or to ulna. The distal row of carpal bones articulates with the bases of metacarpal bones forming carpometacarpal joint. Other articulations within the wrist form radioulnar, radiocarpal and intercarpal joints.

We analyzed 34 study cases that were a result of diagnostic procedure of 32 patients of the Department of Rheumatology of the author׳s institution university hospital. All patients had symptomatic pain in at least one wrist and were examined with DCE-MRI (dynamic contrast-enhanced MRI) as a part of the diagnostic procedure. MRI of both wrists was taken in case of RA symptoms reported in both wrists. MRI examinations were performed using a 0.2T extremity E-scan (ESAOTE Ltd., Genova, Italy) with surface coil. The patients were examined in supine position in accordance with the recommendations of the manufacturer. No other special hand positioning procedures were applied prior to the examination. Basic MR equipment such as 0.2T extremity E-scan does not offer specialized MR sequences enhancing signal from structures of interest (bone in our case), for example fat saturated sequences. Due to this anatomical structures or tissues (e.g. skin) other than bones are imaged at similar intensity range to bones. This poses the main problem for an automated segmentation of wrist bones.

Among all MRI sequences, acquired for the diagnostic purposes in accordance with the recommendations of OMERACT/EULAR [3], only a pre-contrast coronal turbo 3D T1-weighted gradient echo (TR=35ms, TE=16ms, pixel spacing=0.75mm, slice thickness=0.7mm) was used in the present study. All captured sequences were exported to 16-bit per voxel unsigned integer raw data files and were an input to our segmentation procedure. 3 patients had no synovitis at all, 4 had synovitis in one joint, 8 in two and the rest in all 3 joints. 17 patients had no bone edema, 12 had edema in 1–5 bones and the rest in more than 5 bones. 8 patients had no erosions- 0 on RAMRIS scale (0% bone volume affected), 13 had small erosions in some bones of type 1 (1–10% bone volume affected), 9 had erosions in some bones of type 1 and sporadically 2, 3 or 4, the rest of the patients had erosions in some bones from 4 to 7.

We compared the segmentation results with the ground truth data acquired through manual segmentation accomplished by two trained individuals. Three similarity criteria between ground truth and an automated segmentation were used to evaluate the algorithm quality. We compared them with the results presented in our previous study [10]. We also measured average time required for computing one case and compared it with average time for the method described in [10]. We performed our calculations on Intel Core i3-2310, 4×2.10Ghz, 4 GB RAM, machine (single core was used in the computations).

To compute ACC – accuracy, the measurement derived from area under receiver operating characteristic curve (ROC), we calculated the number of true positive (TP – bone voxels in ground truth images correctly recognized as bone voxels in automated segmentation), false positive (FP - background voxels in ground truth images incorrectly recognized as bone voxels in automated segmentation), true negative (TN - background voxels in ground truth images correctly recognized as background voxels in automated segmentation), and false negative (FN - bone voxels in ground truth images incorrectly recognized as background voxels in automated segmentation) voxels. False and true positive rates were calculated:
                           
                              (1)
                              
                                 FPR
                                 =
                                 FP
                                 /
                                 
                                    (
                                    
                                       FP
                                       +
                                       TN
                                    
                                    )
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 TPR
                                 =
                                 TP
                                 /
                                 
                                    (
                                    
                                       TP
                                       +
                                       FN
                                    
                                    )
                                 
                              
                           
                        
                     

We calculated accuracy according to the following equation:
                           
                              (3)
                              
                                 ACC
                                 =
                                 
                                    
                                       
                                          FPR
                                          ⁎
                                       
                                       TPR
                                    
                                    2
                                 
                                 +
                                 (
                                 1
                                 −
                                 FPR
                                 )
                                 
                                    
                                       1
                                       +
                                       TPR
                                    
                                    2
                                 
                              
                           
                        
                     

ACC value equal to 1 characterized an ideal classifier while ACC that was equal to 0.5 was expected for a classifier which assigned cases with equal probabilities to positive and negative classes (similarly to AUC). The value of ACC is basically the area under a piece-wise linear function connecting points (0,0), (FPR, TPR) and (1,1) in the XY coordinate system and was used in the present study to enable comparison with the results of other studies [13]. Instead of mean similarity (MS) coefficient used in [10] to measure the region accuracy of segmentation result and ground truth we calculated Dice coefficient, according to the following formula:
                           
                              (4)
                              
                                 Dice
                                 =
                                 
                                    
                                       2
                                       
                                          |
                                          
                                             
                                                
                                                   Im
                                                
                                                
                                                   g
                                                
                                             
                                             ∩
                                             
                                                
                                                   Im
                                                
                                                
                                                   s
                                                
                                             
                                          
                                          |
                                       
                                    
                                    
                                       
                                          |
                                          
                                             
                                                
                                                   Im
                                                
                                                
                                                   g
                                                
                                             
                                          
                                          |
                                       
                                       +
                                       
                                          |
                                          
                                             
                                                
                                                   Im
                                                
                                                
                                                   s
                                                
                                             
                                          
                                          |
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          2
                                          ⁎
                                       
                                       TP
                                    
                                    
                                       
                                          2
                                          ⁎
                                       
                                       TP
                                       +
                                       FP
                                       +
                                       FN
                                    
                                 
                              
                           
                        where Img and Ims are ground truth and automatically segmented images, respectively and |Im| denotes the number of foreground (bone) voxels in image Im. The closer the value to 1 the better agreement existed between two images. The change was made to compare our method with one of the semi-automated tools.

The mean absolute distance (MAD) was calculated to evaluate the difference between the ground truth boundary and the segmented boundary. For this purpose an XORi (exclusive or) image was calculated for each image pair (Img,i, Ims,i):
                           
                              (5)
                              
                                 
                                    
                                       XOR
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    (
                                    
                                       
                                          
                                             Im
                                          
                                          
                                             g
                                             ,
                                             i
                                          
                                       
                                       ∩
                                       
                                          
                                             
                                                
                                                   Im
                                                
                                                
                                                   s
                                                   ,
                                                   i
                                                
                                             
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    )
                                 
                                 ∪
                                 
                                    (
                                    
                                       
                                          
                                             Im
                                          
                                          
                                             s
                                             ,
                                             i
                                          
                                       
                                       ∩
                                       
                                          
                                             
                                                
                                                   Im
                                                
                                                
                                                   g
                                                   ,
                                                   i
                                                
                                             
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    )
                                 
                              
                           
                        where Img,i and Ims,i were ground-truth and segmented i-th image, and denoted negative of Im.,i. Then, an Euclidean distance transform was calculated for XORi image. To calculate the Euclidean distance transform [14], we assume that the background in an XORi image is composed of all voxels which have zero value (i.e. voxels that are classified identically in an automated and manual segmentations) and the foreground is composed of all non-zero voxels in an XORi image (i.e. voxels that are classified differently in a manual and an automated segmentations). Then, the Euclidean distance transform computes for each foreground voxel its distance to the nearest background voxel [14]. Clearly, if there is only a small shift between the automated and the manual segmentations, the values of the Euclidean distance transform would be small on avrage. In some sense the Euclidean distance transform measures thickness of regions misclassified in an automated segmentation. In the present study MAD was defined as an average over Euclidean distance transform values in foreground voxels. With lower values of MAD the segmentation became more accurate, compared to the ground truth.

As an image processing tool as well as the source of implementation of the algorithms utilized in the presented method, particularly Multi Otsu, morphological operations and watershed from markers, we used ITK (www.itk.org).

Our algorithm consists of two main stages: calculating of the markers for bones in each of the three bone regions separately (distal parts of radius and ulna, carpals and proximal metacarpal bases) and running watershed from markers algorithm on a magnitude of gradient of the input MR image and a bone markers image. To compute the magnitude of image gradient we estimated gradient components with a simple two-point formula. The gradient components were calculated for an original MR image blurred with a Gaussian filter with fixed half-size equal to 1 voxel. We performed watershed from markers twice: once for the distal parts of ulna and radius and metacarpal bases and the second for carpals. The reason for this was that we needed segmented radius, ulna and metacarpal bases to properly select region of interest for the carpals only which lay between the previously segmented bones. Moreover the calculations for the carpals due to their position as well as the voxel intensities which was often below the range for the other bones deserved special treatment and separate stage of the algorithm, slightly different than for other bones. The markers of radius, ulna and metacarpal bases were simpler to find because these bones lay at the bottom and the top of an image accordingly and they had similar shape within their groups.

The presented method for calculating markers was about four times faster and more efficient when it comes to time complexity than the previous one presented in [10].

The main contribution of the present paper is the development of an automated marker selection procedure, working in a timely manner and enabling robust watershed-based segmentation of the wrist bones. We achieved this by skipping registration and replacing it with a method based on filtering bones based on their geometric properties and knowledge about wrist anatomy.

To denoise the image we applied curvature driven algorithm, where iso-brightness contours in the grayscale input image are viewed as a level set [15]. The advantage of this approach is that the boundaries are preserved with smoothing occurring only within regions next to the boundaries. This was particularly important regarding the low-contrast of low-field MR images being analyzed.

To proceed to the next stages of the MR data processing we extracted from the original data the region corresponding to an examined hand. The computation of the hand mask was essentially based on the Multi Otsu segmentation method [16] that classifies voxels of an image into classes by maximizing the between-class variance of intensity values. We ran Multi Otsu algorithm with the number of classes equal to three.

Intensity variations coming from inhomogeneous B0 and B1 fields did not apply to our images because they are more visible in high-extremity images and because the analyzed area was relatively small compared to the workspace of the MR scanner. For the mask calculation we chose the class with the lowest intensities as this choice corresponded to the low-intensity background. Bone regions were included within the class characterized by the highest intensities while all other soft tissues were within the class with intermediate intensities.

After Multi Otsu segmentation the hand boundaries were sharply marked but contained a number of cavities, as shown on a sample coronal slice in 
                           Fig. 2a, so morphological was essential to obtain smooth hand surface. The result of the morphological closing is shown in Fig. 2b.

The computation of markers of ulna and radius consisted of the following steps:
                              
                                 1.
                                 Applying Multi Otsu algorithm to the smoothed image.

We ran Multi Otsu algorithm with the number of classes set to three. For the extraction of the markers of radius, ulna and metacarpal bases we selected the class with the brightest mean intensity for further processing (
                                    Fig. 3a). Due to the risk of merging bones with other tissues characterized by high signal intensities (as seen in Fig. 3a) we applied morphological erosion to the segmented image (ball structuring element with radius equal to 2 voxels—Fig. 3b).

Automated selection of a region of interest (ROI) containing ulna and radius based on the results of Multi Otsu segmentation.

We analyzed the profiles of the mean MR signal intensity within axial cross sections of the original MR image, limiting calculations to the hand mask only. We presumed high mean intensity value for an axial slice with the highest ratio of the number of ulna and radius voxels to the number of the mask voxels. Moving in the distal direction from that slice one finally gets into a minimum of the mean intensity profile corresponding to the radioulnar joint region (Fig. 3a, horizontal line). The region from the slice corresponding to the minimum of intensity profile to the bottom of the image was selected as the ROI containing the radius and ulna.

Applying morphological erosion and leaving 10 largest connected components in the ROI.

Objects filtering based on their geometrical characteristics and anatomical knowledge.

First we removed non-bone tissues that were close to the hand mask boundaries, like skin and tendons. As a connected component rejecting criterion we chose the distance to mask boundaries lower than 5 voxels. After that we selected from the remaining objects those two that were closest to the center of the mask.


                           
                           Fig. 4 shows a sample 3D image of radius and ulna markers.

The computation of the markers of the metacarpal bases was analogous to the method used for segmenting radius and ulna. Having previously calculated the ROI containing radius and ulna, we selected the bottom of the metacarpal bases ROI at the axial slice at the label equal to 0.6 times the label of the slice at the top of the radius and ulna ROI. This selection worked well in all cases because the positioning of the wrist during MR image acquisition is standardized with the wrist occupying the center of coronal slices. Sample coronal slices from the image window are shown in 
                           Fig. 5.

To proceed with filtering redundant objects we applied additional erosion to the image (ball structuring element with radius equal to 2 voxels) because after initial erosion there were still cases of bones regions merged with other tissues regions. However we performed this additional erosion only for objects which were sufficiently large (i.e. the percentage of voxels of these objects was bigger than 13% of the total number of all object voxels). After that, to remove small objects׳ remainders, we left 15 largest connected components. Next we removed the objects close to the hand mask boundaries within a distance of 10 pixels. We started from objects closest to the mask checking the number of remaining objects after each removal. Finally, we left the 5 largest connected components. Example marker images for metacarpal bases are depicted in 
                           Fig. 6.

The marker images for the radius and ulna as well as the proximal metacarpal bases together with the magnitude of the gradient of the input MR image are input images for the watershed from markers algorithm. An example result of this algorithm is presented in 
                           Fig. 7.

In this stage we used similar algorithms as in the previous two stages however in different sequence and using the result of previous calculations itself. The reason of special treatment of carpals was twofold:
                              
                                 1.
                                 The location of carpals, between the metacarpals and radius and ulna, with two rows of bones cannot be easily presumed – because of that we needed the results of previous calculations to mark out the carpal region.

The range of voxel intensities in the region of carpals was often different than for group of bones considered in earlier stages – for this reason we needed separate run of Multi Otsu algorithm only for the carpal ROI.

The segmentation of carpals consisted of the following steps:
                              
                                 1.
                                 Computing ROI for carpals based on the segmentation of radius, ulna and metacarpal bases.

We determined the top envelope of ulna and radius and the bottom envelope of metacarpal bases (
                                    Fig. 8a). Then, two planes were found which bounded carpal regions from the right and from the left, one tangential to the ulna and the base of the fifth metacarpal, and the other one tangential to the radius and to the first metacarpal base (Fig. 8b).

Applying Multi Otsu algorithm within the carpal ROI.

Applying morphological erosion and leaving 15 largest objects in the ROI (Fig. 8c).

Applying erosion to the objects volume larger than 13% of the total volume of all objects and removing small objects.

After erosion carpal bones were in all cases well separated from components related to other tissues.

Removing objects closest to the mask boundaries at a distance to the hand mask boundary smaller than 10 pixels.

Removing objects with holes.

We observed that remainders of the skin and other non-bone tissues have holes and cavities or are often formed from a set of homogeneous objects connected by strips of 1–5 voxels whereas bones were cohesive and compact with no or a small amount of holes in their internal structure. We calculated the amount of holes voxels within an object slice by slice on coronal images. We removed connected components if the total number of connected components left in the image was bigger than 8 and the percentage of holes within a component was greater than 4%

Leaving 8 largest connected components from all objects remained in the image (Fig. 8d).

Applying watershed from markers to the selected carpal ROI.

We added the result of the watershed from markers segmentation to the segmentation of radius, ulna and metacarpal bases and this was the final result of the procedure. Two typical examples of segmentation of all wrist bones together with sample slices from manual segmentation are shown in 
                                    Fig. 9.

@&#RESULTS AND DISCUSSION@&#

The approach to the segmentation of bones in magnetic resonance images of the wrist proposed in this paper can be rated on the basis of test quality, computational cost and its limitations.

To test the quality of the proposed segmentation algorithm we conducted manual segmentation of all thirty-four cases. The results of the manual outlining were treated as the ground truth. 
                     Table 1 summarizes the average and standard deviation values of the accuracy, Dice coefficient and mean absolute distance (MAD) between manual and automated segmentation in three groups: distal parts of radius and ulna, metacarpal bases and carpal bones. The average and standard deviation values ACC, Dice coefficient and MAD between the manual and automated segmentation images are shown in 
                     Table 2. The results prove the correctness of the proposed method as compared to the manual segmentation. The object borders, as detected by watersheds from markers, are localized at object boundaries. The values of MAD (which are very close to one) indicate that the distance between the contours of automated and manual segmentations is approximately equal to 1 pixel. In Fig. 9c and d we show example slices of segmented image overlapped on original image and In Fig. 9e and f we show manually segmented images. Some slight differences are visible when it comes to bone marrow (we miss some pixels) and darker parts of the bone. For comparison, in the study of Koch et al. [13] (which was based on MR images with two times higher resolution than in the present study) the segmentation accuracy was equal to 0.48mm, compared to 0.365mm voxel size. For the same study the values of ACC do not exceeded 0.91. In comparison with our older method our results for ACC and MAD were similar or slightly better, as we improved recognition of bone edema by including darker pixels on bone border. Dice coefficient equal to 0.98 shown in Table 2 is slightly better than those calculated for SmartBrush semi-automated tool described in [9] where it was close to 0.95.

We shortened significantly the computation time as compared to our previous method described in [10]. We were able to decrease the time demand for each case from average 63min to 5.9min which definitely makes the algorithm more comprehensive. Detailed comparison of computation time is shown in 
                     Table 3. The computation time for the proposed method and the method described in [10] is plotted against the number of image voxels in 
                     
                     Fig. 11. For the proposed method the computation time grows approximately linearly with the number of voxels. For the method described in [10] the plot is much more scattered mainly because of the optimization-based nature of the algorithm described in [10] in which case the computation time depends not only on the size of an image but also on details present within the image.

The main limitation of our algorithm is that it is sensitive to medium and large bone erosions. In the case of small erosion algorithm behaves correctly; all 15 bones are detected; eroded parts are not seen on the segmented image sometimes few additional pixels are missing (Fig. 10c and d). Because small erosions are typical for early stages of RA our algorithm may be used for early diagnostics without any changes. In the case of large erosions and bones edema we can distinguish two types of flaws: missing segments or a cloud of unrelated points or distorted segments (Fig. 10a and b). To overcome this limitation we plan to use multi-atlas segmentation to model the erosion and estimate its stage. We were taking also into account deformable models however we abandoned this approach because when there are weak signals from bones edges then this method will not work properly. It should be also noted that for better segmentation of eroded bones the algorithm using registration described in [10] can be used, because registration-based methods used in the approach described in [10] usually place markers in proper anatomical locations. The main problem with large erosion cases is however not with the markers but with the boundaries of eroded bones which are largely diluted in MR images. This makes the problem of segmentation of strongly eroded bones not very well defined.

The second limitation of the presented method might be its sensitivity to the parameters used in filtering stages; primarily the distance to the mask used or holes percentage. These parameters were optimally selected for the dataset in hand. Further test cases must be acquired to test the sensitivity of the segmentation procedure with the respect to the parameter selection. However, it should be noted that the selection of the values of these parameters is dictated by the anatomical knowledge, e.g., given typical thickness of skin and the half-size of the eroding element used during the preprocessing step, the connected components related to bones cannot be located at distances to the mask boundaries closer than the selected values.

The results of the present study demonstrate that automated segmentation of wrist bones is feasible even in the case of as low image quality as in the case of 0.2T images. Further improvements of the segmentation may include testing the other segmentation algorithms that start from markers (region growing, geodesic contours, etc.) and finding more robust gradient algorithm. To shorten computation time parallel versions of the algorithms may be used (ITK framework provides multithreaded implementations). The results of the segmentation can be used for joint localization and further for creating an automated diagnostic system for quantification of synovitis. Our results can be also used to investigate bone edema and bone erosions algorithms. On STIR images used for evaluating bone edema bones appear darker than on T1-weighted images. This statement is valid also for T2 images. Therefore our algorithm cannot be used with those types of images as an input. However image registration from bones segmented in T1 to STIR can be used to locate bones there.

Justyna Włodarczyk, Kamila Czaplicka, Zbisław Tabor, Wadim Wojciechowski and Andrzej Urbanik declare that they have no conflict of interest related to the study described in the article.

Informed consent was obtained from all patients for being included in the study.

@&#REFERENCES@&#


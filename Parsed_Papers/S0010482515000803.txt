@&#MAIN-TITLE@&#Automatic identification of oculomotor behavior using pattern recognition techniques

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Classification of three types of eye movements: saccades, blinks and fixations.


                        
                        
                           
                           Statistical features distinguish the three types of eye movements.


                        
                        
                           
                           Classification by a cascade of three classifiers with overall accuracy 95.9%.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Saccades

Microsaccades

Blinks

Fixation

Classification

Neural network

Velocity threshold algorithm

@&#ABSTRACT@&#


               
               
                  In this paper, a methodological scheme for identifying distinct patterns of oculomotor behavior such as saccades, microsaccades, blinks and fixations from time series of eye׳s angular displacement is presented. The first step of the proposed methodology involves signal detrending for artifacts removal and estimation of eye׳s angular velocity. Then, feature vectors from fourteen first-order statistical features are formed from each angular displacement and velocity signal using sliding, fixed-length time windows. The obtained feature vectors are used for training and testing three artificial neural network classifiers, connected in cascade. The three classifiers discriminate between blinks and non-blinks, fixations and non-fixations and saccades and microsaccades, respectively. The proposed methodology was tested on a dataset from 1392 subjects, each performing three oculomotor fixation conditions.
                  The average overall accuracy of the three classifiers, with respect to the manual identification of eye movements by experts, was 95.9%. The proposed methodological scheme provided better results than the well-known Velocity Threshold algorithm, which was used for comparison. The findings of the present study indicate that the utilization of pattern recognition techniques in the task of identifying the various eye movements may provide accurate and robust results.
               
            

@&#INTRODUCTION@&#

Gesture, speech and eye movements are frequently analyzed by experts in order to explain human behavior. As a result, eye movements have enjoyed burgeoning attention in recent years as a tool for studying human behavior [1]. Perhaps the most important reason for their usefulness is that eye movements indicate the focus of visual attention although covert attention can be focused away from the point of visual fixation [2]. The eyes do not remain still when viewing a visual scene; they have to move constantly to build up a mental “map” from interesting parts of the scene [3]. The main reason for this is that only a small central region of the retina, the fovea, is able to perceive with high acuity.

According to Leigh and Zee [4], four basic types of eye movements can be identified: (1) Saccades, that are fast voluntary movements, which bring the fovea in the region of interest within the visual field, (2) smooth eye pursuit, that involves a slow continuous movement of both eyes in order to follow a moving visual stimulus in the visual field, (3) vergence, that is the disconjugate slow movements of the eyes that converge or diverge in order to foveate an object in three-dimensional space, and (4) fixation, that is the inhibition of all eye movements which keeps the eyes locked on a particular location in the orbit. When fixing the gaze, there exist microscopic and unnoticed motions of the eye, called fixational eye movements. Furthermore, saccades can be divided into two distinct groups: major saccades, that are easily observed even with naked eye and minor saccades that are virtually unobservable without special instrumentation [5]. The smallest saccades, called ‘microsaccades’, are involuntary eye movements produced during attempted visual fixation. They are the largest and fastest of the fixation eye movements [6].

Saccades have been extensively examined in normal vision towards the understanding of human behavior [7]. Apart from the study of normal vision, saccadic deviations have been also measured in special groups, such as patients with psychiatric disorders (such as attention deficit hyperactivity disorder (ADHD) and schizophrenia), young children and elderly people in an attempt to differentiate saccadic characteristics between those conditions and normal controls [8].

Although eye movements have become increasingly popular as a tool for investigating behavior, the analysis of movements can be often extremely difficult and tedious [9]. A major objective for eye movement analysis could be the identification of the main eye movement types with no or minimal user intervention. Towards to this direction, eye movement characteristics have been analyzed in many studies and the visual behavior during specific tasks has been successfully modeled in an automatic manner. In [10], an analysis of eye movement using tracing methods in three conditions (equation solving, reading and gaze-based interfaces) from seven participants has been conducted. In order to identify fixation points and saccades, methods based on sequence-matching and Hidden Markov Models were used, resulting in identification of eye movements as accurately as human experts, but in significantly less time with an overall accuracy ranging between 87.5% and 93.7%. In another study, machine learning methods were used to improve the accuracy of detecting Mild Cognitive Impairment (MCI) in 60 participants, by modeling eye movement types such as fixations, saccades, and re-fixations during the Visual Paired Comparison task [11]. The features used were the fixation duration, re-fixations, saccade orientation and the pupil diameter which were fed as inputs to a Support Vector Machine (SVM) classifier. Using this classification algorithm, age-matched normal control subjects were distinguished from MCI subjects with an overall accuracy of 87.0%.

In a recent study, a set of 90 features, that describe the eye movement data, were collected from 10 participants under five activities: copying a text, reading a printed paper, taking hand-written notes, watching a video, and browsing the web [12]. The features included, among other, the mean and the variance of the saccade signal amplitude, the maximum electro-oculographic (EOG) signal amplitudes, the rate of small or large saccades, and the positive and the negative saccades in horizontal or vertical direction. These features were ranked and evaluated using the minimum redundancy maximum relevance feature selection method along with an SVM classifier in order to automatically discriminate these five activities resulting in 80.2% overall accuracy. In [13] a new velocity-based algorithm that makes the saccade detection less sensitive to variations in noise level was suggested. The algorithm includes a data driven threshold for peak and saccade onset/offset detection, an adaptive threshold adjustment based on local noise levels, physical constraints on eye-movements to exclude noise and new recommendations for minimum allowed fixation and saccade duration. The algorithm detects saccades and postsaccadic oscillations in the presence of smooth pursuit movements with 92.0–96.0% specificity and 80.0–90.0% sensitivity. In another study, a method for the detection of saccades, blinks, postsaccadic oscillations and fixations in the acceleration domain was presented [14]. The method was a two-step procedure that involved the identification of approximate saccadic intervals and saccadic onset and offset detection. The method was applied on eye-tracking signals from 33 subjects that performed three different tasks and provided sensitivity between 66.7% and 97.8% and specificity between 82.8% and 99.9%. In another study, the development of robust and accurate microsaccade detection techniques was presented, based on unsupervised clustering techniques [15]. The new clustering method validated using an eye-movement database included recordings from 20 adult subjects (12 men, 8 women) with normal or corrected-to normal vision that maintained fixation on a centrally presented target, and simulated eye-movement data. The clustering method compared other microsaccade-detection techniques conclude to higher performance both for binocular and monocular data. The median error rate in the method proposed in [16] was 0.25 errors per second, while the median error rate in the clustering method was 0.1 errors per second. The sensitivity of detecting microsaccades for both methods is more than 75%, using manual labeling as the gold standard. Also, in [17], participants were asked to fixate a small dot on a computer display and microsaccades were detected in two dimensional velocity space by using thresholds for peak velocity and a minimum duration, implemented as an improved version of an algorithm proposed earlier [16].

The purpose of the proposed study was to develop a methodology for the automatic classification of eye movements of healthy individuals into four categories: saccades, microsaccades, blinks and fixation. Towards this direction, 2335 oculomotor signals from 1392 individuals have been processed, in order to automatically identify specific characteristics of the saccadic eye movements [18]. The proposed methodology involves an array of three neural network classifiers: the first classifier discriminate blinks from non-blinks, the second one separates fixation from all types of saccades and finally the third one which differentiates microsaccades from major saccades. To our knowledge, it is the first attempt towards the automatic identification of different types of eye movement characteristics, including saccades and microsaccades, from a very large database of oculomotor signals.

This study used the oculomotor dataset from the ASPIS sample (Athens Study for Psychosis Proneness and Incidence of Schizophrenia) according to Smyrnis et al. and Evdokimidis et al. [18,19]. A sample of 1778 young male subjects aged 18–24 years were recruited from the Greek Air Force. These agreed to participate in the study after giving written informed consent. These individuals performed a battery of eye movement tasks (smooth eye pursuit, saccade, antisaccade, visual fixation) and cognitive tasks and they also completed questionnaires for a detailed psychometric analysis. Each subject from the ASPIS sample has been codified with a unique number code. The correlation between the subjects and the codes has been destroyed. The subject׳s horizontal eye movements (angular displacement) were recorded from the right eye only using the IRIS SCALAR infrared device (spatial resolution: 2min of arc) [19]. A chin rest was used to stabilize the head. A 12-bit A/D converter was used for data acquisition (Advantech PC-lab Card 818L). The data were sampled at 600Hz, providing 30,000 samples for time duration of 50s.

The participants performed three fixation conditions [19]. In the first fixation condition, the participants were instructed to simply fixate a visual target on the center of the computer monitor (white cross 
                           0.3
                           °
                           ×
                           0.3
                           °
                        ) for 50s. In the second fixation condition, the participants were asked to fixate again a central target and ignore targets that might appear to the right or the left. For each trial four distracting targets were used; two small, 
                           0.3
                           °
                           ×
                           0.3
                           °
                         white crosses and two large, 
                           0.1
                           °
                           ×
                           0.1
                           °
                         crosses, each presented for 500ms at random intervals during the 50-s fixation period. The distracting targets could appear at a random distance of 
                           2
                           °
                           −
                           9
                           °
                         and a random direction at left or at right from the center. Finally, in the third fixation condition, the participants were asked to keep their eyes fixating in the primary position (straight ahead) in front of a black screen and avoid making eye movements.

Before each active fixation condition, a calibration procedure was performed that consisted of saccadic movements at targets located 
                           10
                           °
                         to the right and left of a central fixation target (see 
                        Fig. 1a). In some cases, due to the motion of the individual and/or the instability of the device that was placed on the participant׳s head, the calibration signal was corrupted by noise (see Fig. 1b). The signals from these participants were excluded from the study. Furthermore, there were cases that the calibration signals were not corrupted by noise but the recorded signals presented a strong noise component (Fig. 1c). These noisy signals were smoothed using a bandpass filter as it is presented in Fig. 1d.

A total set of 2335 oculomotor signals from 1392 individuals were finally selected for further analysis. Two experts of Eginition Hospital in Athens (Smyrnis and Evdokimidis) identified the types of the eye movements in a set of signals by visual examination. The experts marked the “center” point of each type of eye movement (blinks, saccades and microsaccades). Then, a window of proper size was centered at each marked point (see 
                        Fig. 2) and the corresponding signal segment was extracted for subsequent analysis.

Thus, for the blinks or (micro)saccades the positions of the time windows were not overlapped. Two time windows W1 and W2 are used for the detection of blinks and saccades/fixations, respectively. Furthermore, for each saccade identified by the experts, the segments of the signal of length W2 that lie just before and after the saccade were selected as fixations. Since the duration of blinks is usually larger (100–400ms) [20], than the duration of saccades (6–300ms) [6], the length of the windows W1 and W2 is set to 400ms (corresponding to 240 data samples) and 13ms (corresponding to 8 data samples), respectively. In total, from the 2335 available signals, 16,012 time intervals (200ms before the center point and 200ms after were selected) containing blinks and 316,612 time intervals (6.5ms before the center point and 6.5ms after were selected) containing saccades and microsaccades were identified from the experts.

The proposed methodological scheme for the classification of three types of eye movements, consists of three main processes (see 
                     Fig. 3):
                        
                           a)
                           Preprocessing.

Feature Extraction.

Classification using Artificial Neural Networks.

This module aims to (a) to remove linear trends (detrending) from the recorded signals, and (b) calculate the angular velocity of the detrended signals. A linear trend typically indicates a systematic increase or decrease in the data. A systematic shift can result, for example, from sensor drift. Analysis focusing on short-term fluctuations of the data requires removal of trends in order to improve the results, as is the case in the present study. The most common detrending process, which was adopted in the present study, usually consists of removing the linear trends (see 
                        Fig. 4).

It has been observed that the distribution of the velocity of eye׳s movement, namely the time derivative of the angular deviation, is characterized by two distinctive peaks: one peak for low velocities (less than 100°/s) that corresponds to fixations and one peak for high velocities (larger than 300°/s) that corresponds to saccades [10]. This fact provides a sufficient discrimination of saccadic eye movements from other types of eye movements based on velocity. The velocity is computed as the (angular) distance between the current point and the next (or previous) point, divided by the time difference between samples [21]. Analytically, since the recorded data measure the angular deviation of eye, a(t), the angular velocity of the eye movement, ω(t), at a given time t, is given by the first derivative of the angular deviation:
                           
                              (1)
                              
                                 ω
                                 
                                    (
                                    t
                                    )
                                 
                                 =
                                 
                                    
                                       d
                                       a
                                       
                                          (
                                          t
                                          )
                                       
                                    
                                    
                                       d
                                       t
                                    
                                 
                              
                           
                        
                     

The first derivative must be estimated robustly, taking into account that eye-movement data often include much smaller eye movements (tremor, drifts and flicker) than those related to the phenomena that are to be investigated in the present study. These small eye movements will introduce fluctuations in ω(t) that will severely hamper the subsequent analysis, thus these fluctuations have to be discarded. Therefore, the signal a(t) was firstly smoothed by means of the convolution with a smoothing kernel, h(t) and then the derivative of the smoothed version was computed:
                           
                              (2)
                              
                                 ω
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       d
                                       (
                                       α
                                       ⁎
                                       h
                                       )
                                       (
                                       t
                                       )
                                    
                                    
                                       dt
                                    
                                 
                                 =
                                 
                                    (
                                    
                                       α
                                       ⁎
                                       
                                          
                                             dh
                                          
                                          
                                             dt
                                          
                                       
                                    
                                    )
                                 
                                 (
                                 t
                                 )
                              
                           
                        where ⁎ denotes convolution.

In this study, the Gaussian kernel was used:
                           
                              (3)
                              
                                 h
                                 (
                                 t
                                 )
                                 =
                                 
                                    1
                                    
                                       
                                          
                                             2
                                             π
                                             σ
                                          
                                       
                                    
                                 
                                 
                                    
                                       e
                                    
                                    
                                       −
                                       (
                                       
                                          
                                             t
                                          
                                          2
                                       
                                       /
                                       2
                                       
                                          
                                             σ
                                          
                                          2
                                       
                                       )
                                    
                                 
                              
                           
                        where the parameter σ determines the level of the smoothing. After experimentation, σ=1 was selected as the most appropriate value of the parameter. The velocity signal for different values of σ is presented in 
                        Fig. 5. As can be seen in Fig. 5a and b, low values of the parameter σ result to noisy signals, which is a drawback in identification of onset/offset of saccades. On the other hand, high values of the parameter σ result in excessively smoothed signals, as it is shown in Fig. 5d, so microsaccades are misinterpreted as fixation. In Fig. 5c, the velocity signal is calculated using the parameter value σ=1, resulting in a smoothed signal with more transparent differences between the types of eye movement.

The angular velocity of the detrended signal is shown in 
                        Fig. 6, where the experts have identified different types of eye movements such as blinks (labeled with numbers 1, 2 and 3) as well as saccades (labeled with number 4). As can be observed from Fig. 6, blinks are clearly visible both in the detrended angular deviation and the angular velocity. A typical characteristic of a blink is the short coherence of two large peaks in the recorded signal: one positive and one negative. However, the discrimination between saccades and blinks is not often too obvious. For example, in the signal presented in Fig. 6, in spite of the high angular deviation of the eye (number 4 in Fig. 6a), the duration of this movement exceeds the average length of a blink that is 100–400ms [20]. Such parts of the signal are considered as a sequence of saccades (number 4 in Fig. 6b).

Finally, in 
                        Fig. 7, the angular deviations (a–c) and the corresponding angular velocity signals (d–f) are given for three different types of eye movements such as blinks, saccades and fixation points, as identified by the experts.

The first step towards the accurate discrimination of the different types of eye movements is the computation of relevant features from the angular deviation and velocity signals. Initially, two time windows, W1 and W2 that slide over each signal (deviation or velocity) are used. Then, for each signal and for each position of these windows over a signal, seven (7) features are computed:
                           
                              1)
                              
                                 Max value, referred to the maximum value of the angular deviation signal and the maximum value of the angular velocity signal.


                                 Mean value, which is the average value of each signal according to:
                                    
                                       (4)
                                       
                                          
                                             x
                                             
                                                ¯
                                             
                                          
                                          =
                                          
                                             1
                                             n
                                          
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 where 
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    n
                                  are the sample values of the signal (angular deviation or velocity) and n is the number of the signal values.


                                 Standard deviation, which is a measure of the dispersion of a set of data 
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                  from its mean 
                                    
                                       x
                                       ¯
                                    
                                  according to:
                                    
                                       (5)
                                       
                                          
                                             σ
                                             ^
                                          
                                          =
                                          
                                             
                                                
                                                   
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         n
                                                      
                                                      
                                                         
                                                            
                                                               (
                                                               
                                                                  
                                                                     x
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               −
                                                               
                                                                  x
                                                                  ¯
                                                               
                                                               )
                                                            
                                                            2
                                                         
                                                      
                                                   
                                                   
                                                      n
                                                      −
                                                      1
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              


                                 Kurtosis, which measures the relative peakedness or flatness of the distribution of signal values. It is defined as the fourth statistic moment of the distribution of the data, according to the following equation:
                                    
                                       (6)
                                       
                                          K
                                          =
                                          
                                             1
                                             n
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   n
                                                
                                                
                                                   (
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  x
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                            −
                                                            
                                                               x
                                                               ¯
                                                            
                                                         
                                                         
                                                            σ
                                                            ^
                                                         
                                                      
                                                   
                                                   )
                                                
                                             
                                             4
                                          
                                       
                                    
                                 
                              


                                 Skewness, which is a measure of the asymmetry of distribution of the signal values around the sample mean. If the skewness is negative (positive), the data are spread out more to the left (right) of the mean than to the right (left). The skewness of the normal distribution (or any perfectly symmetric distribution) is zero. The skewness of a distribution is defined as follows:
                                    
                                       (7)
                                       
                                          S
                                          =
                                          
                                             
                                                
                                                   
                                                      1
                                                      n
                                                   
                                                
                                                
                                                   
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         n
                                                      
                                                      
                                                         (
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         −
                                                         
                                                            x
                                                            ¯
                                                         
                                                         )
                                                      
                                                   
                                                   3
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         σ
                                                         ^
                                                      
                                                   
                                                   3
                                                
                                             
                                          
                                       
                                    
                                 
                              


                                 The energy of the signal, which is defined as follows:
                                    
                                       (8)
                                       
                                          
                                             
                                                E
                                             
                                             
                                                s
                                             
                                          
                                          =
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   n
                                                
                                                
                                                   (
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   )
                                                
                                             
                                             2
                                          
                                       
                                    
                                 
                              


                                 The entropy, which is a measure of uniformity of the distribution of the values of the signal:
                                    
                                       (9)
                                       
                                          H
                                          
                                             (
                                             x
                                             )
                                          
                                          =
                                          −
                                          
                                             ∑
                                             
                                                k
                                                =
                                                0
                                             
                                             
                                                M
                                                −
                                                1
                                             
                                          
                                          
                                             
                                                
                                                   p
                                                
                                                
                                                   k
                                                
                                             
                                             
                                             
                                                
                                                   log
                                                
                                                
                                                   2
                                                
                                             
                                             
                                             
                                                
                                                   p
                                                
                                                
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                              

For the Gaussian kernel, it can be shown [23] that the optimal choice for 
                           h
                         is:
                           
                              (12)
                              
                                 h
                                 =
                                 
                                    
                                       (
                                       
                                          
                                             
                                                4
                                                
                                                   
                                                      
                                                         σ
                                                         ^
                                                      
                                                   
                                                   5
                                                
                                             
                                             
                                                3
                                                M
                                             
                                          
                                       
                                       )
                                    
                                    
                                       
                                          
                                             1
                                             5
                                          
                                       
                                    
                                 
                                 ≈
                                 1.06
                                 
                                    σ
                                    ^
                                 
                                 
                                    
                                       M
                                    
                                    
                                       −
                                       1
                                       /
                                       5
                                    
                                 
                              
                           
                        where 
                           
                              σ
                              ^
                           
                         is the standard deviation of the samples.

The features estimated using the time windows W1 and W2 are used for the detection of blinks (saccades and fixation intervals).

The classification of eye movements is achieved using an array of three Artificial Neural Networks (ANN) classifiers. An ANN is an information processing system, which contains a large number of highly interconnected processing units called neurons. These neurons work together in a distributed matter to learn from the input information, to coordinate internal processing and to optimize their final output [24]. The four eye movements of interest are blinks, saccades, micro-saccades and fixation (no movement), where microsaccades are saccades with amplitude less than 
                           0.5
                           °
                         
                        [25]. Since there are four movements of interest, a hierarchical structure containing three binary classification levels is used, as shown in 
                        Fig. 8.

The first classifier discriminates between non-blinks (class C1,1) and blinks (class C1,2). The non-blinks dataset contains saccades or fixations. The feature vectors for the blink and non-blink datasets are computed using the window W1. If a non-blink is detected, the second classifier is activated, which discriminates between non-fixation (class C2,1) and fixation (class C2,2). The non-fixation dataset contains saccades and microsaccades. The feature vectors for the fixation and non-fixation datasets are computed using the window W2. Finally, if a non-fixation is detected, the third classifier is applied in order to discriminate between saccades (class C3,1) and microsaccades (class C3,2).

Each classifier is implemented as a feed-forward neural network with one hidden layer and one output (see 
                        Fig. 9). After experimentation, the optimal number of neurons in the hidden layer was considered to be 10 and the maximum number of training epochs was equal to 1000. Trials were conducted for the choice of the optimal number of neurons in the hidden layer. Each classifier consists of one hidden layer with 5, 10, 15 and 20 neurons. A subset of the dataset is used as input to each classifier and the variations of the performance were observed. Specifically, the performance of each classifier presents lower values when the number of the neurons was 5, while the performance presents small variations when the number of neurons was 10, 15 or 20. In order to eliminate the complex, 10 neurons were used in this study. The output layer consists of one neuron, encoding the two classes. The output values are between 0 and 1, values below 0.5 classified in class1 and values below 0.5 are classified into class 1 and values above 0.5 are classified into class 2. In order to avoid overtraining, each classifier is implemented as a feed-forward neural network with one hidden layer and one output and achieves an accepted generalization in the classification, three data sets were selected: training set, validation set, and testing set. Each ANN was trained using the training set and the weights corresponded to the epoch that the best performance was achieved on the validation set were saved.

Each classifier was trained 10 times, using the scaled conjugate gradient backpropagation algorithm, with different, randomly selected training, validation and testing sets [26]. The training sets comprised feature vectors from 60% of the available signals, namely 1401 signals. The feature vectors from the rest 20% of the signals (467 signals) were used for validation purposes during the training and the feature vectors from the final 20% of the signals (467 signals) were used for testing each neural network. Since each signal contained different number of blinks and saccades, the size of the training, validation and testing sets varied between runs. For the first classifier (blinks vs. nonblinks), 649,236 feature vectors were totally, extracted using window W1. In particular, the average number of the training feature vectors were 405,738 for blinks and non-blinks, the average number of the testing feature vectors for the class C1,1 (non-blinks) was 118,791 and for the class C1,2 (blinks) was 2958. For the second classifier (fixation vs. non fixation), 633,224 feature vectors, extracted by means of window W2, from the time intervals that did not contain blinks. The average number of the training feature vectors was 413,122 feature vectors, whereas the average number of the testing feature vectors for the class C2,1 (non-fixation) was 21,456 and for the class C2,2 (fixation) was 88,595. Finally, for the third classifier (saccades vs. microsaccades) 127,750 feature vectors, using window W2, from the time intervals that did not contain blink or fixation, were used. The average number of the training feature vectors was 76,650 feature vectors, the average number of the testing feature vectors for the class C3,1 (non-microsaccades) was 12,267 and for the class C3,2 (microsaccades) was 13,283.

The sensitivity and specificity of each type of eye movement are calculated as:
                           
                              
                                 Sensitivity
                                 =
                                 
                                    
                                       Number
                                       
                                       of
                                       
                                       feature
                                       
                                       vectors
                                       
                                       of
                                       
                                       eye
                                       
                                       movement
                                       
                                       classified
                                       
                                       correctly
                                    
                                    
                                       Total
                                       
                                       number
                                       
                                       of
                                       
                                       feature
                                       
                                       vectors
                                       
                                       of
                                       
                                       eye
                                       
                                       movement
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 Specificity
                                 =
                                 
                                    
                                       Number
                                       
                                       of
                                       
                                       feature
                                       
                                       vectors
                                       
                                       of
                                       
                                       other
                                       
                                       eye
                                       
                                       movements
                                       
                                       classified
                                       
                                       correctly
                                    
                                    
                                       Total
                                       
                                       number
                                       
                                       of
                                       
                                       feature
                                       
                                       vectors
                                       
                                       of
                                       
                                       other
                                       
                                       eye
                                       
                                       movements
                                    
                                 
                              
                           
                        
                     

Specifically, the performance of each classifier was assessed by means of the following measures:
                           
                              •
                              Specificity for classifier i, SPEC
                                    i
                                 =100×M
                                 
                                    i,1/N
                                 
                                    i,1
                              

Sensitivity for classifier i, SENS
                                    i
                                 =100×M
                                 
                                    i,2/N
                                 
                                    i,2
                              

Overall Accuracy for classifier i, ACC
                                    i
                                 =100×(M
                                 
                                    i,1+M
                                 
                                    i,2
                                 )/(N
                                 
                                    i,1+N
                                 
                                    i,2)

@&#EXPERIMENTAL RESULTS@&#

The confusion matrix and the Receiver Operating Curve (ROC) for the testing set of each classification level are obtained. The confusion matrix was calculated averaging the results for the 10 individual runs for each classification level. The corresponding average sensitivity, specificity and overall accuracy were calculated. For each classifier, the rate of the corrected classified patterns versus the rate of incorrectly classified patterns for various threshold values of its output was plotted, resulting in a ROC curve for the specific classifier.

The average sensitivity, specificity and overall accuracy were 99.9%, 97.1% and 99.8%, respectively. 
                        Table 1 shows the “average” confusion matrix for the testing set, together with the performance evaluation metrics. 
                        Fig. 10a) illustrate the Receiver Operating Curve (ROC) of the classifier, where it can be seen that the overall accuracy remains high for each class, for various threshold values.

The average sensitivity, specificity and overall accuracy were 95.5%, 98.0% and 97.5%, respectively. 
                        Table 2 shows the “average” confusion matrix for the testing set, together with the performance evaluation metrics. Fig. 10b) illustrate the Receiver Operating Curve (ROC) of the classifier, where it can be seen that the overall accuracy remains high for each class, for various threshold values.

The average sensitivity, specificity and overall accuracy were 95.9%, 96.0% and 95.9%, respectively. 
                        Table 3 shows the “average” confusion matrix for the testing set, together with the performance evaluation metrics. Fig. 10c) illustrate the Receiver Operating Curve (ROC) of the classifier, where it can be seen that the overall accuracy remains high for each class, for various threshold values.

The classifier with the best accuracy is used for comparison with others algorithm (Velocity Threshold and Clustering Method). The performance of the proposed methodological scheme from the combination of the three classifiers is presented in 
                        Table 4. As it can be seen, the accuracy from the identification of saccades and microsaccades presents lower values of the average accuracy of each classifier.

The performance of the proposed methodological scheme from the combination of the three classifiers is also examined for each fixation condition. The performance of the proposed methodological scheme from the combination of the three classifiers per fixation condition is shown in 
                        Table 5. As can be seen, the fixation condition does not affect the performance of the proposed methodology.


                        
                           
                              a)
                              Velocity Threshold

The proposed methodological scheme was compared against the Velocity Threshold algorithm, presented in [13], for the classification of fixation from non-fixation and microsaccades from non-microsaccades, in signals after blinks removal. The details of the algorithm are as follows: an initial velocity threshold, 
                                    P
                                    
                                       
                                          T
                                       
                                       
                                          0
                                       
                                    
                                 , which is usually in the range 
                                    100
                                    °
                                    /
                                    s
                                    −
                                    300
                                    °
                                    /
                                    s
                                 , is selected. For all velocity values lower than 
                                    P
                                    
                                       
                                          T
                                       
                                       
                                          0
                                       
                                    
                                 , the average, 
                                    
                                       
                                          μ
                                       
                                       
                                          0
                                       
                                    
                                 , and standard deviation, 
                                    
                                       
                                          σ
                                       
                                       
                                          0
                                       
                                    
                                 , are calculated. The threshold is updated as 
                                    P
                                    
                                       
                                          T
                                       
                                       
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          μ
                                       
                                       
                                          0
                                       
                                    
                                    +
                                    6
                                    
                                       
                                          σ
                                       
                                       
                                          0
                                       
                                    
                                 , the safety margin 
                                    6
                                    
                                       
                                          σ
                                       
                                       
                                          0
                                       
                                    
                                 is used in microsaccade detection algorithm [16]. The above procedure is iterated until the difference of the thresholds between two successive iterations becomes smaller than 
                                    1
                                    °
                                    /
                                    s
                                 . After the last iteration, the algorithm detects the saccade peaks that have velocity above the threshold. Then, the algorithm searches backward and forward in time for the saccade onset and offset, respectively. Saccade onset and offset is simple to detect due to its well-behaved velocity profile and are defined from the first sample that goes zero. This algorithm was chosen because it is one of few algorithms that are able to detect saccades. The overall accuracy of the velocity algorithm was estimated based on the identification of saccades from experts. Results are shown in Table 5. Comparing these results, it is evident that the proposed classification scheme provides superior results with the respect to the Velocity Threshold algorithm for each discrimination task and fixation condition.

Clustering Method

The proposed methodology was also compared with the algorithm presented in [15], which used clustering tecniques in order to determine the boundary between microsaccades and non-microsaccades, concluding to higher performance comparing to other tecniques both for binocular and monocular data.

The training, validation and testing sets are the same that were used in the third classifier of the proposed method. The true positives of the clustering method is 100%, whereas the accuracy for each discrimination task is presented in Table 5. The Clustering Method presents higher performance than the Velocity Threshold algorithm for each fixation condition. The proposed methodological scheme presents the accuracy.

The proposed classification scheme was also tested without retraining the classifiers in a second eye movement recording set. The experiment and results are described in detail in a recent report [27]. Briefly, horizontal and vertical eye movements were recorded from 30 participants while they watched two videos of videotaped performances of the Greek National Team in Rhythmic Gymnastics lasting 2′29″ and 2′30″ with a resting period of a few minutes in between. There was no sound attached to the videos. The participants refrained from moving their head with the use of a chinrest. The participants were instructed to evaluate the gymnasts׳ routine, according to an official scoring sheet, in order to simulate the evaluation procedure that takes place during official competition events. Movements of the right eye of each participant were recorded, using the ISCAN ETL-200 camera (sampling rate: 240Hz). The display dimensions were specified to correspond to
                           
                              
                                 20
                              
                              ∘
                           
                        of maximum horizontal deviation and 
                           15
                           °
                         of maximum vertical deviation from the center of the projection. The spatial resolution of eye movement measurements was at 
                           0.07
                           °
                         and 
                           0.12
                           °
                         at the horizontal and vertical axis respectively. Each participant also performed a calibration procedure using a nine-point grid, and a moving white circular dot (the initial scene of each video clip was used as background). The calibration procedure was repeated performed before and after each video presentation in order to reevaluate the measurement precision. The duration of the window W2 is 13ms. Thus, for the sampling rate 240 samples/s provided by the ISCAN ETL-200 camera the window W2 corresponds to 
                           240
                           (
                           
                              
                                 13
                              
                              /
                              
                                 1000
                              
                           
                           )
                           ≅
                           3
                         samples, which is not an adequate number for the calculation of the 14 features. Therefore, the signals from the camera were resampled at 600Hz. In general, signals acquired with relative low sampling rates (below 600Hz) will require resampling in order to get meaningful and accurate results. Then, the eye movement recording data were processed with the proposed methodology using the three classification level without retraining the classifiers. The team of experts of Eginition Hospital in Athens identified (by visual examination) the various types of the eye movements in a subset of signals (702 signals in total), which were used as ground truth for evaluating the performance of the proposed method. In total, 11,188 feature vectors for the class C1,1 (non-blink) and 845 feature vectors for the class C1,2 (blink). Also, 3724 feature vectors for the class C2,1 (non-fixation) and 7464 for the class C2,2 (fixation) were used for the evaluation. The number of the feature vectors for the class C3,1 (non-microsaccades) was 2547 and for the class C3,2 (microsaccades) was 1029. The results of the three classifiers presented in 
                        Table 6.

The overall accuracy was 98.2%, the sensitivity and the specificity for saccades were 96.9% and 98.5%, respectively. The sensitivity and the specificity for blinks were 97.7% and 98.2%, respectively. The sensitivity and the specificity for microsaccades were 91.3% and 98.8%, respectively. Also, the sensitivity and the specificity for fixation were 99.6% and 95.7%, respectively. The proposed methodology is capable to identify saccades with maximum angular deviation of 
                           20
                           °
                        .

@&#DISCUSSION@&#

There are several factors that may affect the performance of the proposed classification methodology. Firstly, the determination of the length of the two sliding windows W1 and W2 for the estimation of the features is important since small window lengths will fail to include the eye movement under study, e.g. blinks or saccades, whereas large window lengths, especially for W2, it will result in merging movements with fixations. The effect of the size of the sliding window W1 on the accuracy of the first classifier is also shown in 
                     Fig. 11. As can be seen in this figure the maximum accuracy is obtained for window size for the W1 of 400ms.


                     
                     Fig. 12 shows the dependence of the accuracy of the second classifier on determining the size of the window W2. It is evident that the maximum accuracy is achieved when the size of the window W2 is set to 13ms.

Furthermore, 
                     Fig. 13 shows an example of the effect of the length of the window W2 on the identification of saccades. As can be seen, when the length of the sliding window W2 is increased from 13ms to 16ms, four saccades are not identified.

An advantage of the proposed system is its ability to identify microsaccades, in the range between 
                        0.1
                        °
                      and 
                        0.5
                        °
                      of angular displacement of the eye, which is not the case for the Velocity Threshold algorithm. As was mentioned, the proposed classification methodology provides higher classification accuracy, with respect to the Velocity Threshold algorithm, for all discrimination tasks and fixation conditions. This is especially true for the task of discriminating between saccades and microsaccades. The weakness of the Velocity Threshold algorithm to discriminate saccades from fixation was also shown in [14]. Also, the Clustering Method presents higher performance than the Velocity Threshold algorithm especially for the task of discriminating between saccades and microsaccades, the proposed methodological scheme overcomes the two methods.

The performance of the proposed methodology was also evaluated using alternative classification architectures. The alternatives included: (a) a single four-class classifier, and (b) a different arrangement of the three classifiers. Concerning the case with one ANN classifier with four output classes (fixation, saccades, microsaccades and blinks), an overall accuracy of 49.2% was observed, that is clearly inferior to the performance of the proposed system. This was expected, taking into account the difficulty for the discrimination of the various types of eye movements that were studied, especially microsaccades from fixation points as well as saccades from blinks. This approach was one of the main motivations in using a three-level approach for classification. As far as the different arrangement of the three discrimination steps into two classes is concerned, a variation of the proposed architecture was tested as it is shown in 
                     Fig. 14. The 1st level discriminates fixations from non-fixations (including blinks, saccades and microsaccades) with an overall accuracy 95.8%. The 2nd level separates the previously detected non-fixations into microsaccades and non-microsaccades (including blinks and saccades) with an overall accuracy 94.1%. Finally, the 3rd level differentiates the previously detected non-microsaccades into saccades and blinks with an overall accuracy 98.0%. Consequently, it can be concluded that the rearrangement of the classifiers has minimal effect on the performance of the proposed methodology.

There are several alternative classification algorithms that could be used for the task of discriminating eye movements, including k-NN, SVM, and decision trees. The most widely used alternative to the ANN is the SVM algorithm. In some studies, ANN has shown equal or better classification performance than SVM in various tasks [28,29], although their comparative performance is affected by many parameters, such as noise in the data, and depends on the specifics of each application. On the level of algorithm characteristics, although SVM and feed-forward ANN are structurally similar, the models differ in the way the solutions are obtained. The number of support vectors is usually a result of the optimization problem posed, and the support vectors are always a subset of the data in the SVM algorithm. On the other hand, the number of hidden nodes in an ANN is a free parameter which is usually fixed previously. Therefore, in contrast to ANN, the SVM algorithm has a desired property of automatically selecting their model size, by selecting the support vectors as a fraction of the training data. However, it is important to note that a large set of support vectors might be needed to form the output function, making SVM computationally slow in running time of the test phase and, therefore, computationally expensive for real-time applications. Although the definition of an appropriate number of hidden nodes in designing an ANN is not a trivial task, the model complexity is usually controlled by keeping the number of hidden nodes small and performing initial exploratory tests for defining the number of nodes, that are subsequently kept fixed. This approach was followed in the present study and resulted in average execution time of 50s for each signal of the testing set, using a PC with Intel i7 processor at 3.4GHz and 8GB RAM. The Velocity Threshold algorithm resulted in average execution time of 3min for each signal, while the Clustering Method resulted in average execution time of 10s for each signal.

The proposed method is nearly fully automated, requiring a logical amount of user intervention. In particular, the data should be manually pre-classified by experts in saccades and blinks segments in order to train the classifiers. However, when the training phase is completed the applied methodology can be applied to new, unknown signals without any user intervention. Furthermore, in order to calculate feature vectors that will be used for the classification, two time windows W1, W2 with duration 400ms and 13ms, respectively should be defined. The proposed values correspond to 240 samples (W1) and 8 samples (W2) for sampling rate 600Hz. If signals with lower sampling rates are to be used, then the signals should be properly resampled at 600Hz (or higher rates) in order to obtain meaningful and accurate results.

The proposed methodology detects fixation intervals, saccades, microsaccades and blinks, but it does not incorporate an explicit procedure for merging consecutive fixation intervals (or broken saccades) into larger ones. This will be one of the first tasks to be performed during future improvements of the methodology.

@&#CONCLUSIONS@&#

In this study, an automatic classification methodology for identifying various types of eye movements was presented. The accuracy of the proposed methodology for the various discriminations tasks and fixation conditions was above 87.2%, indicating that it could be used for supporting the evaluation of oculomotor signals. Due to the simplicity of the automatic proposed methodology and the fast execution time, it could be used easily used in clinical practice, making feasible its future integration in clinical routine in real-time implementations.

None declared.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank Prof. Dr. Periklis Ktonas for his constructive comments and contributions to the initial stages of the research.

@&#REFERENCES@&#


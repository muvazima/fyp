@&#MAIN-TITLE@&#Mining categorical sequences from data using a hybrid clustering method

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose an innovative hybrid method for clustering categorical sequential data.


                        
                        
                           
                           The algorithm combines model-based and hierarchical clustering approach.


                        
                        
                           
                           We are able to cluster sequences without losing information about their dynamics.


                        
                        
                           
                           In the first application the method detects 2 distinct web users search patterns.


                        
                        
                           
                           In the second application the method recovers 5 clusters with diverse job careers.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Data mining

Sequential data

Hidden Markov models

Clustering

Categorical data

@&#ABSTRACT@&#


               
               
                  The identification of different dynamics in sequential data has become an every day need in scientific fields such as marketing, bioinformatics, finance, or social sciences. Contrary to cross-sectional or static data, this type of observations (also known as stream data, temporal data, longitudinal data or repeated measures) are more challenging as one has to incorporate data dependency in the clustering process. In this research we focus on clustering categorical sequences. The method proposed here combines model-based and heuristic clustering. In the first step, the categorical sequences are transformed by an extension of the hidden Markov model into a probabilistic space, where a symmetric Kullback–Leibler distance can operate. Then, in the second step, using hierarchical clustering on the matrix of distances, the sequences can be clustered. This paper illustrates the enormous potential of this type of hybrid approach using a synthetic data set as well as the well-known Microsoft dataset with website users search patterns and a survey on job career dynamics.
               
            

@&#INTRODUCTION@&#

The identification of different dynamics in sequential data has become a fundamental step in many research fields. For instance, the analysis of the gene expression dynamics represents a relevant task in the bioinformatics framework (Ramoni, Sebastiani, & Cohen, 2002; Ramoni, Sebastiani, & Kohane, 2002; Tucker, Hoen, Vinciotti, & Liu, 2006), whereas the approximation of the spread of infectious diseases in large populations helps generate efficient dynamic optimization techniques to assist real-time modification of public health interventions (Yaesoubi & Cohen, 2005). In information science, the issue of text categorization which is originally handled using Support Vector Machines can also be tackled evaluating word sequential patterns and thus taking into account the temporal relationships between words and sentences as well (Jaillet, Laurent, & Teisseire, 2006). Other examples can be found in marketing where analyses aim to investigate the consumers’ brand choice behavior (Poulsen, 1990), as well as financial studies, where the purpose of researchers is to recognize similar fluctuations among stock markets (Basalto et al., 2007; Ramos, Vermunt, & Dias, 2011), and in modeling manpower systems where both observable and latent sources of dynamic heterogeneity should be accounted for (Guerry, 2011). Furthermore, in social sciences such as economics (Frühwirth-Schnatter & Kaufmann, 2008) and demography (Dias & Willekens, 2005), mining temporal or longitudinal data is essential for obtaining an accurate analysis of phenomena. Examples can also be found in engineering sciences such as reliability analysis (Zhou, Hua, Xu, Chen, & Zhou, 2010), equipment’s health status assessment (Dong & He, 2007) and in air traffic flow management where time series data clustering facilitates the mitigation of airport congestion effects (Inniss, 2006).

The challenging task of clustering this type of observations is that one has to incorporate data dependency in the clustering process (Kakizawa, Shumway, & Taniguchi, 1998). Therefore, methods for clustering time series data have recently received a growing attention in both data mining and statistics literature. However, most of the proposals developed so far merely try to modify the existing algorithms for clustering static data in such a way that time series data can be handled (Liao, 2005).

Furthermore, existing literature mainly focus on the analysis of real-valued and discrete-valued data series: the investigation and clustering of the temporal dynamics of sequences of quantitative variables is a preferred topic in time series analysis literature, but procedures for clustering categorical sequential data have only been addressed marginally (Raftery, 1985).

The search for data mining methods for dealing with large data sets has recently increased the interest in sequential data clustering (Ananthanarayana, Murty, & Subramanian, 2001; Keogh & Kasetty, 2003). For instance, the discovery of similar web navigation patterns has become a popular topic in web mining (Vakali, Pokorny, & Dalamagas, 2004). In this context, Spiliopoulou and Pohle (2001) show that traditional data mining approaches may not be appropriate for detecting different website users search patterns. Thus, many algorithms for clustering web usage patterns have been proposed. For example, approaches which extend the traditional K-means algorithm using the Kullback–Leibler distance as an alternative to the Euclidean distance (Dias & Cortinhal, 2008; Petridou, Koutsonikola, Vakali, & Papadimitriou, 2006); hierarchical pattern-based algorithms adopted for clustering web transactions (Yang & Padmanabhan, 2011); and model-based approaches based on Markov models (Anderson, Domingos, & Weld, 2002; Cadez, Heckerman, Meek, Smyth, & White, 2003; Dias & Vermunt, 2007; Dongshan & Junyi, 2002; Sen & Hansen, 2003) and self-organizing maps (Smith & Ng, 2003).


                     Ramoni et al. (2002) propose a Bayesian method – BCD algorithm – which models dynamic processes as Markov chains and then hierarchically groups time series according to the Bayes rule by applying an agglomerative clustering procedure. They deal with observed frequencies to compute the transition matrices assuming Markov chains in the first step of their algorithm. In the second step, they compute the average symmetrized Kullback–Leibler distances between (observed) transition matrices and (agglomerative hierarchically) group time series according to the Bayes rule, i.e., evaluating the posterior probabilities of a partition given the data.

We provide a toy example to show the limitations of using observed transitions between categories in the clustering task. Table 1
                      contains two categorical sequences – A and B – with observed state-space 
                        
                           {
                           1
                           ,
                           2
                           }
                        
                      of length 16. Fig. 1
                      depicts these sequences. Despite the same original state – both sequences start in category 1 – sequences are remarkably different. Moreover, from a Markov chain point of view both sequences are identical as its sufficient statistics are the same. Indeed, initial states and the matrix of observed transitions between states are identical (Table 2
                     ). Thus, based on these input data, any measure of distance between A and B will be null, and sequences are assumed as identical and will belong always to the same cluster.


                     Liao (2007) deals with continuous multivariate data and he converts them into a discrete-valued univariate time series. Then, he uses the same identical procedure introduced by Ramoni et al. (2002). Bicego, Murino, and Figueiredo (2004) train each sequence by different hidden Markov models. However, this procedure fails in scaling all sequences on the same set of parameter and retrieve comparable parameter estimates.

In this paper, we aim to provide a contribution to the methodology of categorical time series clustering which represents an innovative and challenging task. In particular, we propose a hybrid method, which combines the model-based clustering approach provided by an extension of the hidden Markov model (HMM) and a hierarchical clustering procedure. More specifically, we develop a clustering process that incorporates the data dependency observed in the time series and transforms the categorical data set into a probabilistic space, where a symmetric Kullback–Leibler distance can operate. Then, we resort to hierarchical clustering on the matrix of distances in order to cluster the data sequences into homogenous groups according to both their characteristics and dynamics. Moreover, our hybrid method does not require that all sequences have the same length.

The two-step procedure of our novel hybrid method for clustering categorical sequential data and discovering groups characterized by similar trajectories and dynamics allows us to handle two issues which affect many of the aforementioned proposals. The first step of our approach represented by the estimation of the Panel HMM enables us to assume that, conditional on cluster membership, the observations are dependent and, thus, analyzing the sequential structure of the data not only at individual level. On the other hand, the second step, which is derived from a distance-based clustering procedure, addresses the evidence that sequential data dynamics, such as web navigation data, may be non-Markovian in nature (Huberman, Piroli, Pitkow, & Lukose, 1997). Thus, our approach differs from that of Ramoni et al. (2002) in two important ways. In the first step of the clustering procedure, both the BCD algorithm by Ramoni et al. (2002) and our hybrid approach transform the original time series using Markov chains. However, BCD algorithm replaces the categorical sequential series by Markov chains represented by transition probability matrices obtained by computing the observed switching between adjacent observations of the time series. On the contrary, our hybrid approach uses a Panel HMM to obtain latent transition matrices of the unobserved Markov chain underlying the series.
                        1
                        The differences between the BCD algorithm and the HMM are outlined in Section 4 of Ramoni et al. (2002) and in Section 5 of Liao (2007).
                     
                     
                        1
                      Consequently, the BCD algorithm clusters time series according to the distances between the (observed) transition matrices, whereas our clustering procedure is based on the distances between (latent) posterior probabilities achieved by the (estimation of the) learned Panel HMM. Secondly, by estimating a Panel HMM we fix the same latent part to all time series allowing that posterior probabilities of each sequence are comparable.

Section 2 of the paper introduces the proposed hybrid clustering method and details its two steps. Section 3 provides a full synthetic example that compares our hybrid approach with competing techniques, highlighting the advantages of this new hybrid method. Section 4 illustrates the enormous potential of our hybrid approach in web mining applications using the well-known Microsoft msnbc dataset for clustering and interpreting website users search patterns. Section 5 provides a second application of the algorithm to a longitudinal survey data set on job career dynamics. Finally, Section 6 concludes the paper proving a summary of main findings and avenues for further research.

This section introduces a flexible method for clustering categorical time series, which combines model-based and hierarchical clustering procedures.

In the following, we consider a sample of n objects denoted by 
                           
                              y
                              =
                              (
                              
                                 
                                    y
                                 
                                 
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    y
                                 
                                 
                                    n
                                 
                              
                              )
                           
                        . The generic object of the sample, denoted by i (
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                        ), is characterized by a sequence of categories 
                           
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              :
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              =
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    y
                                 
                                 
                                    
                                       
                                          iT
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              )
                           
                        . Let 
                           
                              
                                 
                                    y
                                 
                                 
                                    it
                                 
                              
                              ∈
                              {
                              A
                              ,
                              B
                              ,
                              C
                              ,
                              …
                              }
                           
                         denote the category of object i at time t.

We assume discrete time from 1 to 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                           
                         (
                           
                              t
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                           
                        ) and, therefore, the length of the sequence may differ between objects. Thus, each object denotes a sequence of categories of a certain length 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                        .

Let 
                           
                              φ
                           
                         denotes the set of parameters whereas 
                           
                              f
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              ;
                              φ
                              )
                           
                         denotes the probability density function for object i with respect to the parameter set. The logarithm of the likelihood function of the data for the set of parameters is denoted by 
                           
                              ℓ
                              (
                              φ
                              ;
                              y
                              )
                           
                        .

The definition of clusters of time series characterized by similar dynamics is achieved using a two-step procedure provided by the proposed hybrid clustering method. The purpose of the first step is to transform the original categorical data set into a probabilistic space using the model-based clustering approach provided by the Panel HMM. Then, in the second step, we resort to hierarchical clustering for obtaining the dendrogram which defines the partition of the data set, using the similarity matrix defined by computing the distances between the transformed data achieved in step 1.

The first step of our clustering method consists in exploiting the model-based approach provided by an extension of the hidden Markov model (Smyth, 1997). This model has been extensively adopted for investigating the dynamic pattern of categorical and metric variables. For instance, Rees and Koehler (2006) show its application in retrieving genetic algorithm (GA) parameters.

In particular, the HMM assumes that the observed time series 
                           
                              
                                 
                                    Y
                                 
                                 
                                    t
                                 
                              
                           
                         depends on an underlying latent stochastic process 
                           
                              
                                 
                                    Z
                                 
                                 
                                    t
                                 
                              
                           
                         characterized by K latent states. The relationship between the observed data series and the latent process for object i, is depicted in Fig. 2
                        . This graph shows that the serial dependence among the observations is completely accounted for by the latent process 
                           
                              
                                 
                                    Z
                                 
                                 
                                    it
                                 
                              
                           
                        , thus the HMM estimates one latent variable characterized by K states for each time observation for a total of 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                           
                         latent variables.

With respect to the traditional HMM (Baum, Petrie, Soules, & Weiss, 1970; Zucchini & MacDonald, 2009), the Panel HMM is a multiple sequence model able to account for serial dependencies of categorical time series of different length. For the set of parameters 
                           
                              φ
                           
                        , the Panel HMM for object i is specified as:
                           
                              (1)
                              
                                 f
                                 (
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 ;
                                 φ
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                i
                                                1
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                i
                                                2
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 …
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                
                                                   
                                                      iT
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 f
                                 (
                                 
                                    
                                       z
                                    
                                    
                                       i
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       z
                                    
                                    
                                       
                                          
                                             iT
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 f
                                 (
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 
                                    
                                       z
                                    
                                    
                                       i
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       z
                                    
                                    
                                       
                                          
                                             iT
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                              
                           
                        The density function in Eq. (1) is thus defined by two parts:
                           
                              1.
                              The probability function for the latent process, 
                                    
                                       f
                                       (
                                       
                                          
                                             z
                                          
                                          
                                             i
                                             1
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             z
                                          
                                          
                                             
                                                
                                                   iT
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       )
                                       =
                                       f
                                       (
                                       
                                          
                                             z
                                          
                                          
                                             i
                                             1
                                          
                                       
                                       )
                                       ×
                                       
                                          
                                             ∏
                                          
                                          
                                             t
                                             =
                                             2
                                          
                                          
                                             
                                                
                                                   T
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       f
                                       (
                                       
                                          
                                             z
                                          
                                          
                                             it
                                          
                                       
                                       |
                                       
                                          
                                             z
                                          
                                          
                                             i
                                             ,
                                             t
                                             -
                                             1
                                          
                                       
                                       )
                                    
                                 , characterized by a first-order Markov chain, which assumes that the latent state occupied at time t depends only on the state occupied at time 
                                    
                                       t
                                       -
                                       1
                                    
                                 , and an initial-state probability for the latent variable at time 1.

The measurement model, 
                                    
                                       f
                                       (
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       |
                                       
                                          
                                             z
                                          
                                          
                                             i
                                             1
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             z
                                          
                                          
                                             
                                                
                                                   iT
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       )
                                       =
                                       
                                          
                                             ∏
                                          
                                          
                                             t
                                             =
                                             1
                                          
                                          
                                             
                                                
                                                   T
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       f
                                       (
                                       
                                          
                                             y
                                          
                                          
                                             it
                                          
                                       
                                       |
                                       
                                          
                                             z
                                          
                                          
                                             it
                                          
                                       
                                       )
                                    
                                 , assumes that the observation at time t depends only on the state occupied at time t, i.e., conditional on the latent state 
                                    
                                       
                                          
                                             z
                                          
                                          
                                             it
                                          
                                       
                                    
                                 , the observation 
                                    
                                       
                                          
                                             y
                                          
                                          
                                             it
                                          
                                       
                                    
                                  is independent of observations at other time points and also independent of the states occupied at other time points.

The density function for time series i is then specified as:
                           
                              (2)
                              
                                 f
                                 (
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 ;
                                 φ
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                i
                                                1
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                i
                                                2
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 …
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                z
                                             
                                             
                                                
                                                   
                                                      iT
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 f
                                 (
                                 
                                    
                                       z
                                    
                                    
                                       i
                                       1
                                    
                                 
                                 )
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          t
                                          =
                                          2
                                       
                                       
                                          
                                             
                                                T
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 f
                                 (
                                 
                                    
                                       z
                                    
                                    
                                       it
                                    
                                 
                                 |
                                 
                                    
                                       z
                                    
                                    
                                       i
                                       ,
                                       t
                                       -
                                       1
                                    
                                 
                                 )
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          t
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                T
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 f
                                 (
                                 
                                    
                                       y
                                    
                                    
                                       it
                                    
                                 
                                 |
                                 
                                    
                                       z
                                    
                                    
                                       it
                                    
                                 
                                 )
                              
                           
                        where 
                           
                              f
                              (
                              
                                 
                                    z
                                 
                                 
                                    i
                                    1
                                 
                              
                              )
                           
                         denotes the initial distribution, that is 
                           
                              
                                 
                                    λ
                                 
                                 
                                    k
                                 
                              
                              =
                              f
                              (
                              
                                 
                                    z
                                 
                                 
                                    i
                                    1
                                 
                              
                              =
                              k
                              )
                           
                         is the probability of starting in latent state 
                           
                              k
                              ;
                              f
                              (
                              
                                 
                                    z
                                 
                                 
                                    it
                                 
                              
                              |
                              
                                 
                                    z
                                 
                                 
                                    i
                                    ,
                                    t
                                    -
                                    1
                                 
                              
                              )
                           
                         indicates the latent transition distribution which denotes the probabilities of switching from one state to another: 
                           
                              
                                 
                                    π
                                 
                                 
                                    wk
                                 
                              
                              =
                              f
                              (
                              
                                 
                                    z
                                 
                                 
                                    it
                                 
                              
                              =
                              k
                              |
                              
                                 
                                    z
                                 
                                 
                                    i
                                    ,
                                    t
                                    -
                                    1
                                 
                              
                              =
                              w
                              )
                           
                         represents the probability of being in state k at time t conditional on being in state w at time 
                           
                              t
                              -
                              1
                           
                        ; and 
                           
                              f
                              (
                              
                                 
                                    y
                                 
                                 
                                    it
                                 
                              
                              |
                              
                                 
                                    z
                                 
                                 
                                    it
                                 
                              
                              )
                           
                         is the confusion matrix, which is assumed to be distributed as a multinomial. Since objects 
                           
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                           
                         are independent, the log-likelihood function for 
                           
                              φ
                           
                         is given by the expression 
                           
                              ℓ
                              (
                              φ
                              ;
                              y
                              )
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    n
                                 
                              
                              log
                              f
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              ;
                              φ
                              )
                           
                         and the maximum likelihood estimator is 
                           
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              =
                              
                                 
                                    argmax
                                 
                                 
                                    φ
                                 
                              
                              ℓ
                              (
                              φ
                              ;
                              y
                              )
                           
                        . Parameters estimation is achieved using a special variant of the EM procedure (Dempster, Laird, & Rubin, 1977) known as the forward-backward or Baum–Welch algorithm (Baum et al., 1970; Welch, 2003). This algorithm exploits the conditional independence assumptions implied by the model in order to circumvent the computational issue which affects the traditional EM procedure when the number of time points is high. A detailed description of the algorithm is provided in Appendix A.

Therefore, the same set of parameter estimates 
                           
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                           
                         is obtained for all n time series, which means that we are able to keep the same scaling for all sequences and to avoid problems related to label-switching (Dias & Wedel, 2004). If we would estimate each sequence separately (provided each model is identified), because parameter estimates would be different, posterior probabilities would not be scaled. Moreover, it would be hard to make a good correspondence between the different latent states for different sequences.

Model estimation allows us to compute posterior probabilities, 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    ik
                                 
                              
                              (
                              t
                              )
                              =
                              f
                              (
                              i
                              ∈
                              k
                           
                         
                        at time t 
                        
                           
                              |
                              y
                              ,
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              )
                           
                        , which define the probabilities of an observation to belong to a certain latent state at time t conditional on the observed time series and the estimated parameters (see Eq. (A.3)). In our work, we propose to transform the original data set into posterior probabilities 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    ik
                                 
                              
                              (
                              t
                              )
                           
                        . This data transformation allows us to achieve a threefold goal: (a) posterior probabilities contain the unique information from each time series and this information can be easily exploited for clustering purposes; (b) they are scaled, i.e., each time series at each time point has different degrees of the same set of clusters since 
                           
                              
                                 
                                    ∑
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 
                                    K
                                 
                              
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    ik
                                 
                              
                              (
                              t
                              )
                              =
                              1
                           
                        , for 
                           
                              k
                              =
                              1
                              ,
                              …
                              ,
                              K
                           
                         and 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                        ; and (c) they take into account serial dependency observed in the data via the estimated (latent) Markov chain.

An important step of our analysis is represented by the definition of the number of time periods characterized by similar observed dynamic pattern, i.e., the value of K representing the number of latent states of the underlying Markov process. The selection between different nested models, such as HMMs with different states, is usually performed using the likelihood ratio test. However, in the framework of HMM the required regularity condition of Cramer on the asymptotic properties of the maximum likelihood estimator does not hold and, as consequence, the likelihood ratio test statistic is not asymptotically distributed as a chi-square distribution (Gassiat & Kérebin, 2000). In order to overcome this issue, the number of latent states is usually defined using information criteria. In general, an information criterion considers the log-likelihood, 
                           
                              ℓ
                              (
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              ;
                              y
                              )
                           
                        , and a penalty term which depends on the number of free model parameters (Npar) and on a constant 
                           
                              d
                              :
                              C
                              =
                              -
                              2
                              ℓ
                              (
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              ;
                              y
                              )
                              +
                              d
                              ×
                              Npar
                           
                        . For different values of d, we obtain different criteria. The two most widespread and used criteria are the Akaike information criterion (AIC; 
                           
                              d
                              =
                              2
                           
                        ) (Akaike, 1974) and the Bayesian information criterion (BIC; 
                           
                              d
                              =
                              log
                              n
                           
                        ) (Schwarz, 1978). However, different criteria may lead to different model identifications posing some doubts about the reliability and accuracy of these indicators. In this work, we select the number of latent states according to the BIC which is a consistent estimator of the Markov chain order as demonstrated by Csiszár and Shields (2000).

The second step of our hybrid clustering method exploits the information provided by the probabilistic space obtained in the first step in order to define the clusters of sequences characterized by similar dynamic patterns. In particular, if two time series have similar posterior probabilities 
                           
                              
                                 
                                    u
                                 
                                 
                                    ˆ
                                 
                              
                           
                         of being allocated to the same latent states over time then they should be classified into the same cluster. A natural choice for computing the distance between two probability distributions is the Kullback–Leibler (KL) distance (Kullback & Leibler, 1951):
                           
                              (3)
                              
                                 KL
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       p
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 log
                                 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             1
                                          
                                       
                                       )
                                    
                                    
                                       
                                          
                                             p
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             2
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    X
                                 
                                 
                                    1
                                 
                              
                           
                         and 
                           
                              
                                 
                                    X
                                 
                                 
                                    2
                                 
                              
                           
                         are random variables, whereas 
                           
                              
                                 
                                    p
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    1
                                 
                              
                              )
                           
                         and 
                           
                              
                                 
                                    p
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    2
                                 
                              
                              )
                           
                         are probability distributions. Notice that the points are defined on the convex hull, the Euclidean distance is not appropriated. However, since the KL divergence is not symmetric, i.e., 
                           
                              KL
                              (
                              
                                 
                                    X
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    X
                                 
                                 
                                    2
                                 
                              
                              )
                              ≠
                              KL
                              (
                              
                                 
                                    X
                                 
                                 
                                    2
                                 
                              
                              ,
                              
                                 
                                    X
                                 
                                 
                                    1
                                 
                              
                              )
                           
                        , we propose to evaluate distances according to the Symmetric KL (SKL) distance:
                           
                              (4)
                              
                                 SKL
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       KL
                                       (
                                       
                                          
                                             X
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             X
                                          
                                          
                                             2
                                          
                                       
                                       )
                                       +
                                       KL
                                       (
                                       
                                          
                                             X
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       
                                          
                                             X
                                          
                                          
                                             1
                                          
                                       
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        Using the posterior probabilities estimated in step 1, the SKL distance between time series i and j is given by:
                           
                              (5)
                              
                                 
                                    
                                       d
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 SKL
                                 (
                                 
                                    
                                       
                                          
                                             u
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             u
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          t
                                          =
                                          1
                                       
                                       
                                          min
                                          {
                                          
                                             
                                                T
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                T
                                             
                                             
                                                j
                                             
                                          
                                          }
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      u
                                                   
                                                   
                                                      ˆ
                                                   
                                                
                                             
                                             
                                                ik
                                             
                                          
                                          (
                                          t
                                          )
                                          log
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      ik
                                                   
                                                
                                                (
                                                t
                                                )
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      jk
                                                   
                                                
                                                (
                                                t
                                                )
                                             
                                          
                                          +
                                          
                                             
                                                
                                                   
                                                      u
                                                   
                                                   
                                                      ˆ
                                                   
                                                
                                             
                                             
                                                jk
                                             
                                          
                                          (
                                          t
                                          )
                                          log
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      jk
                                                   
                                                
                                                (
                                                t
                                                )
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      ik
                                                   
                                                
                                                (
                                                t
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Distances 
                           
                              
                                 
                                    d
                                 
                                 
                                    ij
                                 
                              
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                         and 
                           
                              j
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                        , define the dissimilarity (distance) matrix which is used for grouping time series into a tree of clusters through the hierarchical clustering procedure: the dendrogram is achieved starting from n clusters, one for each time series 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                        , and iteratively aggregating pairs of clusters until 1 single cluster is obtained. This agglomerative strategy is defined using complete linkage, i.e., dissimilarity between clusters is measured on the basis of the distance between the two farthest data points in two clusters. The hierarchical clustering allows us to easily obtain an informative data structure without having to specify a priori the number of clusters.

This section explores a synthetic data set that illustrates the key features of our method. First, we describe the data generating process. Second, we cluster the time series using the hybrid method. Then, our approach is compared with competing methods.

In our example we assume four different patterns (
                           
                              S
                              =
                              4
                           
                        ), all given by the sinusoid expression:
                           
                              (6)
                              
                                 
                                    
                                       x
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       α
                                    
                                    
                                       s
                                    
                                 
                                 sin
                                 (
                                 
                                    
                                       β
                                    
                                    
                                       s
                                    
                                 
                                 +
                                 
                                    
                                       γ
                                    
                                    
                                       s
                                    
                                 
                                 t
                                 )
                                 .
                              
                           
                        
                     


                        Table 3
                         defines the values used in the data generating process.

Variable t takes values from 1 to 10 with increments of 0.1. This means that the length of each sequence is 
                           
                              T
                              =
                              91
                           
                        . From this population of four clusters (pure types), sample units were generated by adding a certain amount of noise. Thus, an object generated from cluster s is given by
                           
                              (7)
                              
                                 
                                    
                                       x
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 t
                                 )
                                 +
                                 N
                                 (
                                 0
                                 ,
                                 
                                    
                                       σ
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 ,
                              
                           
                        where 
                           
                              N
                              (
                              0
                              ,
                              
                                 
                                    σ
                                 
                                 
                                    2
                                 
                              
                              )
                           
                         is the normal distribution with mean 0 and variance 
                           
                              
                                 
                                    σ
                                 
                                 
                                    2
                                 
                              
                           
                        . In our simulation, we take 
                           
                              σ
                              =
                              0.5
                           
                        . Panels A and B of Fig. 3
                         show the true model in each cluster and one sample unit from each cluster, respectively.

Finally, given the continuous outcome from this data generating process, the sequence (or discrete time series) is obtained by rounding the value to the closer integer. As there is a natural order in the states, we add a constant in such a way that the first state is one, i.e.,
                           
                              (8)
                              
                                 
                                    
                                       y
                                    
                                    
                                       it
                                    
                                 
                                 =
                                 a
                                 +
                                 1
                                 +
                                 [
                                 
                                    
                                       x
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 t
                                 )
                                 +
                                 N
                                 (
                                 0
                                 ,
                                 
                                    
                                       σ
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 ]
                                 ,
                              
                           
                        where a is the minimum value of all rounded values over all sequences, and 
                           
                              [
                              ·
                              ]
                           
                         denotes the rounding function to the closest integer. Fig. 4
                         depicts the final sequences shown in Fig. 3.

Based on this data generating process, our sample size is 2000 with four clusters of same size (25% of the sample). Thus, our input to the model is the matrix 
                           
                              y
                           
                         containing elements 
                           
                              
                                 
                                    y
                                 
                                 
                                    it
                                 
                              
                           
                        , with 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              2000
                           
                         and 
                           
                              t
                              =
                              1
                              ,
                              …
                              ,
                              91
                           
                        . The synthetic data set contains 
                           
                              K
                              =
                              9
                           
                         states.

In this application as we know the true data generating process, we set 
                           
                              S
                              =
                              4
                           
                         and 
                           
                              K
                              =
                              9
                           
                        . Then, we can compare performance of the proposed method with competing approaches removing potential model selection biases.

In the first step of the proposed hybrid clustering method, the estimation of the Panel HMM provides the definition of the 
                           
                              K
                              =
                              9
                           
                         latent states for the unobserved Markov process which explains the dynamics of the generated time series. The results of the Panel HMM estimation are reported in Tables 4 and 5
                        
                        . Specifically, Table 4 provides the confusion matrix 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              z
                              )
                           
                         which collects the probabilities of the 9 categories of the observed variable 
                           
                              
                                 
                                    y
                                 
                                 
                                    it
                                 
                              
                              =
                              c
                           
                        , for 
                           
                              c
                              =
                              1
                              ,
                              …
                              ,
                              9
                           
                        , conditional on the 9 latent states 
                           
                              
                                 
                                    z
                                 
                                 
                                    it
                                 
                              
                              =
                              k
                           
                        , for 
                           
                              k
                              =
                              1
                              ,
                              …
                              ,
                              9
                           
                        . As we may expect, the nine latent states are quite well defined by few categories: e.g., the first state (
                           
                              k
                              =
                              1
                           
                        ) mainly collects the observed categories 3 and 4, and, to a lesser extent, also categories 5 and 2; state 5 basically clusters only category 4; and so on. Table 4 also provides the estimated marginal distribution 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              )
                           
                         and the proportions 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              z
                              )
                           
                        . We invite the reader to consider the empirical applications in Sections 4 and 5 for a comprehensive description of these results. In Table 5, we report the estimated transition probabilities 
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    wk
                                 
                              
                           
                        , that is the probabilities of switching from state w at time 
                           
                              t
                              -
                              1
                           
                         to state k at time t for the synthetic data set. The latent states are quite persistent since the transition probabilities 
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    wk
                                 
                              
                           
                         for 
                           
                              w
                              =
                              k
                           
                         are quite large for all the 9 states. However, the unobserved Markov chain is also allowed to switch between states over time: for instance, the switching from state 5 at time 
                           
                              t
                              -
                              1
                           
                         to state 9 at time t happens with an estimated probability of 0.365.

The estimated Panel HMM allows the transformation of the original sequences into the posterior probabilities 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    k
                                 
                              
                              (
                              t
                              )
                           
                        , for 
                           
                              k
                              =
                              1
                              ,
                              …
                              ,
                              9
                           
                        . The sequences 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    ik
                                 
                              
                              (
                              t
                              )
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              2000
                           
                        , are then used in the second step of the proposed hybrid clustering method. In particular, the second step consists in performing a hierarchical clustering to group the generated time series according to their posterior probabilities, using the SKL distances in Eq. (5) and an agglomerative clustering method based on complete linkage. The dendrogram depicted in Fig. 5
                         clearly shows that the (true) four-cluster solution can be easily obtained using the proposed hybrid method. Analyzing the true cluster against the allocation values provided by this four-cluster solution, 100% of the observations are correctly classified, thus highlighting the reliability of the proposed hybrid method.

We compare the performance of the hybrid method with traditional methods based on the observed sequences. Based on the observed transition probabilities between states, we set up two different types of clustering approaches: a K-means like method and a hierarchical method.

The sequential K-means (SKM) by Dias and Cortinhal (2008) can be applied to this type of categorical time series. The SKM is an iterative method, starting from a random set of centroids, i.e., a transition probability matrix representing each cluster. As any K-means algorithm, it contains two main steps: first, it allocates each object to the closest centroid based on the minimum symmetric Kullback–Leibler distance; second, it recomputes centroids based on the average transition probabilities of the objects in each clusters. The algorithm stops when no further changes in allocation happened. For more details we refer to Dias and Cortinhal (2008). The application of the SKM method to the synthetic data set, shows that without a filtering process provided by the first step (Panel HMM) it is impossible to recover the true structure. All runs out of 1000 did not converge to a solution, as at some iteration one of the clusters became empty and the algorithm failed.

As an alternative approach, we apply a traditional hierarchical approach without previous application of the Panel HMM. Thus, we compute directly the distance between two objects by the symmetric Kullback–Leibler distance between the respective observed transition probabilities. Then, we apply the complete linkage on the distance matrix as in the proposed method. From Fig. 6
                         we cannot identify a clear four-cluster solution.


                        Table 6
                         provides the tabulation of the 2000 observations by the traditional hierarchical method. We conclude that a solution of four clusters merges the first two original clusters into a single cluster and splits clusters three and four into three clusters.

In terms of agreement between the true partition of the data set and the proposed partition by both methods, we conclude that 100% of the observations are correctly classified by the proposed method. For the traditional hierarchical method, the corrected rand index (Hubert & Arabie, 1985) between these two partitions is 0.405, i.e., only 40.5% of agreement. Note this index takes into account the label-switching problem that affects HMM and broadly speaking finite mixture models (Dias & Wedel, 2004).

In this section, we resort to the hybrid clustering method introduced in Section 2 for analyzing the msnbc.com anonymous web data set (available on kdd.ics.uci.edu). In this application we aim to analyze the sequences of pages requested by web users visiting a website and to define clusters characterized by distinct web search patterns and dynamics in order to better understand users’ behavior. This data set has been used by other authors (Cadez et al., 2003; Dias & Vermunt, 2007).

The analyzed data set contains information on the search sequences of visitors on msnbc website, describing the page visits on msnbc.com on the entire day of September 28, 1999. Each sequence in the data set corresponds to page views of a user during that 24-h period. The original data set consists in 989 818 users and each event in the sequence is classified into the following categories: (1) frontpage, (2) news, (3) tech, (4) local, (5) opinion, (6) on-air, (7) misc, (8) weather, (9) health, (10) living, (11) business, (12) sports, (13) summary, (14) bbs (bulletin board service), (15) travel, (16) msn-news, and (17) msn-sports. In our analysis, we consider a random sample of 1% of the users with a sequence of length at least 2, i.e., each users’ sequence has at least one transition. The sample size is 
                           
                              n
                              =
                              6244
                           
                        .

In order to analyze heterogeneity in web users’ search patterns, we allow different trajectories, i.e., each time observation will have a certain (posterior) probability of belonging to each one of the K states. In the first step of our analysis, we thus estimate Panel HMMs with 1–15 latent states using 300 different starting values in order to avoid local maxima. According to the BIC, the best model is the Panel HMM with 
                           
                              K
                              =
                              12
                           
                         latent states (
                           
                              l
                              (
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              ;
                              y
                              )
                              =
                              -
                              63004.1
                              ,
                              Npar
                              =
                              335
                           
                        , BIC=128,936) which identifies 12 different groups of contents.

The meanings of the 12 latent states can be interpreted using the proportions, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              z
                              )
                           
                        , and the confusion matrix, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              z
                              )
                           
                        , estimated by the model and summarized in Table 7
                        . In this table, states are ordered according to the proportion which indicates the size of state occupancy and are interpreted considering the probabilities included in the confusion matrix 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              z
                              )
                           
                        . From the results reported in Table 7, we can observe that the different states cluster periods characterized by homogenous users’ web search preferences. For instance, latent state 1, which represents the largest group (21.3% of the time individuals stay in that state), is characterized by web users who visit mainly the frontpage (80.2%). State 2 (12.3% of the time series) clusters periods where users are mostly interested in news (66.7%) and living (19.2%). Latent states 3 and 4, which correspond to 9.9% and 9.6% of the time sample, represent observations where web users are very specific in their tastes and have a strong preference for weather (97.1%) and BBS (94.9%), respectively. The remaining states are characterized by sizes ranging from 8.3% to 2.3% of the time series and can be interpreted using a similar approach: state 5 clusters periods in which web users are interested in local and misc, observations classified into state 6 are characterized by users specially concerned with on-air and travel, and so on.

Furthermore, the marginal distribution, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              )
                           
                        , reported in Table 7 indicates the degree of occurrence of each category. Thus, frontpage is the most visited page (19.6%), followed by weather (9.8%), BBS (9.8%), and news (9.7%) pages. On the other hand, travel (1.5%), msn-sports (0.4%), and msn-news (0.1%) are rarely visited by website users.


                        Table 8
                         reports the estimated initial probabilities, 
                           
                              
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    k
                                 
                              
                           
                        , and latent transition probabilities, 
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    wk
                                 
                              
                           
                        , for 
                           
                              k
                              ,
                              w
                              =
                              1
                              ,
                              …
                              ,
                              12
                           
                        . These results enable us to determine both the initial-state of the latent process and the probabilities of switching from one state to another at adjacent time points. According to the initial probabilities reported in first row of Table 8, 34.9% of the time the latent process starts from state 1, which is closely related to the Frontpage (see Table 7).

According to the high values of the transition probabilities reported on the main diagonal of Table 8, the model identifies high state-persistence, i.e., there is a strong tendency to remain in the same state over time (all the probabilities 
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    kk
                                 
                              
                           
                         are greater than 0.73). However, state-switching may occur, e.g., from state 6 to state 11 
                           
                              (
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    6
                                    ,
                                    11
                                 
                              
                              =
                              0.108
                              )
                           
                         and also the opposite switch is somewhat likely (
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    11
                                    ,
                                    6
                                 
                              
                              =
                              0.071
                           
                        ). It can be also noted that even though it is quite unlikely to start from latent state 2 (
                           
                              
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    2
                                 
                              
                              =
                              0.073
                           
                        ), this state is visited rather more often than others, e.g., from state 1 with a probability of 0.059, from state 8 (
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    8
                                    ,
                                    2
                                 
                              
                              =
                              0.050
                           
                        ), or from state 6 (
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    6
                                    ,
                                    2
                                 
                              
                              =
                              0.046
                           
                        ), but also from states such as 10, 7, and 5 with transition probabilities greater than 0.02. Thus, latent state 2, closely related to news and living pages, seems to be a sort of “attractor” for web users.

For defining the clusters of time series characterized by similar dynamic patterns, we use the vectors of posterior probabilities 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              6244
                           
                        , estimated by the Panel HMM. The hierarchical clustering is performed computing the dissimilarity (distance) matrix using Eq. (5) and allows the definition of the dendrogram depicted in Fig. 7
                        .

The two clusters shown in Fig. 7 define the cut of the cluster tree that corresponds to the maximum split between clusters. In this representation, we are able to provide a sounding interpretation of the two groups. Cluster 1, which corresponds to 63.71% of the sample, collects web users who prefer short sessions characterized by a small number of clicks and search for specific topics, such as news, weather, and sports. Therefore, we can label the first group as “Specialists”. On the other hand, cluster 2, which collects the remaining 36.29% of the sample, represents “Generalists”, since web users classified into this group like longer sessions characterized by longer sequences of clicks and prefer surfing through different topics on the website. Furthermore, if we allow six clusters, then the first cluster is split into two clusters, whereas the second cluster originates four clusters. Within “Specialists”, 14.07% of the users go directly to the topic they want to search, whereas the second subgroup with 49.64% starts from the frontpage, moves to the specific topic, and then finishes the session. The “Generalists” cluster contains four subgroups of users: subgroup 1 (5.35% of the total sample) moves between topics connected to sports, news, and health; subgroups 2 (7.08%) is connected to BBS, summary, and misc; subgroup 3 (6.89%) switches between opinion, on-air, and news; and finally subgroup 4 (16.97%) does not show a specific pattern of switching, moving between pages without a specific purpose.

In this section, we provide a second application using the hybrid clustering method introduced in Section 2. In particular, we analyze the dynamics of job career of the Italian household heads using longitudinal survey data. The purpose of this application is to define clusters characterized by distinct job carrier dynamics.

The data set of the second analysis is drawn from the Survey on Households Income and Wealth (SHIW) provided by the Bank of Italy which collects information about income and wealth of Italian households over time (Brandolini & Cannari, 1994). Among the different variables contained in the survey, we analyze the employment status of the household heads over the period 1998–2008, which corresponds to 
                           
                              T
                              =
                              6
                           
                         waves of the panel (here, 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                              =
                              T
                           
                         for all individuals 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              n
                           
                        ). The sample used in the most recent survey comprises about 8000 households. In our analysis, we consider all the households who have participated in all of the last 6 waves of the survey which corresponds to a sub-sample of size 
                           
                              n
                              =
                              1183
                           
                         individuals. Each sequence in the data set identifies the job carrier of a household head over a period of 10 years and each observation in the sequence belongs to one of the following categories: (1) worker, (2) manager, (3) self-employed, (4) retired, and (5) unemployed.

The first step of our analysis consists in estimating Panel HMMs with 1–10 latent states using 300 different starting values in order to avoid local maxima. The BIC suggests as best model the Panel HMM with 
                           
                              K
                              =
                              5
                           
                         latent states (
                           
                              l
                              (
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              ;
                              y
                              )
                              =
                              -
                              4728.8
                              ,
                              Npar
                              =
                              44
                           
                        , BIC=9769), which identifies five different states of the job carrier for the Italian household heads.

In Table 9
                        , the estimated latent states are ordered according to the proportions, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              z
                              )
                           
                        , which indicate the state occupancy sizes. The interpretation of the 5 states, achieved using the confusion matrix, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              z
                              )
                           
                        , is quite straightforward: each state represents one particular employment status. For instance, latent state 1, which represents more than half of the time sample (50.5%), is mainly characterized by retired individuals (97.8%). State 2 (30.6% of the observations) clusters workers (93.8%), whereas state 3, which corresponds to 8.6% of the time series, primarily collects unemployed household heads (91.6%). Individuals classified into latent state 4 (7.9% of the time sample) are mostly self-employed (92%). Finally, state 5 (2.4% of the observations) is characterized by managers (82.9%) and workers (11.9%).

According to the marginal distribution, 
                           
                              
                                 
                                    f
                                 
                                 
                                    ˆ
                                 
                              
                              (
                              y
                              |
                              
                                 
                                    φ
                                 
                                 
                                    ˆ
                                 
                              
                              )
                           
                        , reported in Table 9 the modal employment status for the sampled Italian household heads is retired (50.2%), followed by worker (29.8%), unemployed (9%), self-employed (7.9%) and manager (3.2%). In this case, it is not surprising that the marginal distribution values are similar to the proportions of the latent states: since each state is strongly characterized by one particular employment status, these two estimated quantities almost coincide.

The estimated initial probabilities, 
                           
                              
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    k
                                 
                              
                           
                        , and latent transition probabilities, 
                           
                              
                                 
                                    
                                       
                                          π
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    wk
                                 
                              
                           
                        , for 
                           
                              k
                              ,
                              w
                              =
                              1
                              ,
                              …
                              ,
                              5
                           
                        , are reported in Table 10
                        . According to the initial probabilities, 41.9% of the time the hidden Markov process starts from state 1 which represents retired individuals, whereas 39.4% of the time from state 2 which mostly collects workers. The high values on the main diagonal of the transition probability matrix in Table 10 identify high state-persistence for the employment status. In particular, the probability of staying in state 1 is close to 1: 
                           
                              
                                 
                                    π
                                 
                                 
                                    1
                                    ,
                                    1
                                 
                              
                              =
                              0.979
                           
                        . This result is what we expected since latent state 1 is an absorbing state, i.e., once an individual retires, she/he quits working and remains retired for the rest of the life. However, quite surprisingly there is still a small probability of switching to state 3 (
                           
                              
                                 
                                    π
                                 
                                 
                                    1
                                    ,
                                    3
                                 
                              
                              =
                              0.015
                           
                        ), that is to move from retirement to unemployment. This could be a result of measurement error which may affect longitudinal survey data. However, it must be noted that this issue can be handled quite easily by our clustering procedure (see Section 4.3). The probability for an individual of remaining in latent state 2, which represents the worker status, is 
                           
                              
                                 
                                    π
                                 
                                 
                                    2
                                    ,
                                    2
                                 
                              
                              =
                              0.862
                           
                        . Moreover, the probability of switching from worker to retired is 
                           
                              
                                 
                                    π
                                 
                                 
                                    2
                                    ,
                                    1
                                 
                              
                              =
                              0.077
                           
                        , whereas the probability of losing the job is 
                           
                              
                                 
                                    π
                                 
                                 
                                    2
                                    ,
                                    3
                                 
                              
                              =
                              0.038
                           
                        . On the other hand, the probability of remaining in state 3, which represents the unemployed status, is 
                           
                              
                                 
                                    π
                                 
                                 
                                    3
                                    ,
                                    3
                                 
                              
                              =
                              0.796
                           
                        . Furthermore, according to the estimated values in Table 10, it is more likely to switch directly from unemployment to retirement (
                           
                              
                                 
                                    π
                                 
                                 
                                    3
                                    ,
                                    1
                                 
                              
                              =
                              0.134
                           
                        ) than to leave unemployment and become a worker (
                           
                              
                                 
                                    π
                                 
                                 
                                    3
                                    ,
                                    2
                                 
                              
                              =
                              0.062
                           
                        ). An individual classified into state 4, which represents self-employed status, stays in the same state with probability 
                           
                              
                                 
                                    π
                                 
                                 
                                    4
                                    ,
                                    4
                                 
                              
                              =
                              0.859
                           
                        , or may switch to retired, worker, or unemployed with similar probabilities: 0.059, 0.045, and 0.036, respectively. Finally, the probability of remaining in latent state 5, which is closely related to the manager status, is 0.85, whereas the switching to states 1 and 2 occurs with probabilities 0.059, and 0.045, respectively. From the results in Table 10, it can also be noted that switching to latent state 5 (manager) is only possible from state 2 (worker) but this event is quite unlikely (
                           
                              
                                 
                                    π
                                 
                                 
                                    2
                                    ,
                                    5
                                 
                              
                              =
                              0.011
                           
                        ). Furthermore, it is largely unlikely that an individual classified into state 5 moves directly to state 3 (unemployed) since 
                           
                              
                                 
                                    π
                                 
                                 
                                    5
                                    ,
                                    3
                                 
                              
                              =
                              0.001
                           
                        .

In the second step of our hybrid approach, we define the clusters of job carriers characterized by similar patterns performing hierarchical clustering on the dissimilarity matrix computed using the vectors of posterior probabilities 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              1183
                           
                        , estimated by the Panel HMM at step 1.

In this example, all sequences have the same length, that is 
                           
                              T
                              =
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    T
                                 
                                 
                                    j
                                 
                              
                              =
                              min
                              {
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    T
                                 
                                 
                                    j
                                 
                              
                              }
                           
                        . Based on the vectors of posterior probabilities 
                           
                              
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                        , for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              1183
                           
                        , estimated by the Panel HMM, and using the SKL distance, an agglomerative clustering approach (complete linkage) was performed. Fig. 8
                         summarizes the result supporting a solution with 5 clusters which allows us to obtain some relevant insights on the dynamics of Italian household heads’ job carriers. This representation can be summarized in the following way:
                           
                              •
                              cluster 1 (15.6% of the sample) contains sequences with transitions to retired, the most common being from worker to retired;

cluster 2 (10.2%) contains individuals recently retired with an unstable job career before retirement such as work –> unemployed –> retirement;

cluster 3 (5.3%), interestingly, identifies sequences that are the result of measurement error as they are inconsistent, specially due to the fact that retired tends to be an absorbing state. For example, sequences with the transition retired –> unemployed belongs to this cluster;

cluster 4 (5.0%) contains sequences with transitions between unemployed –> worker and worker –> unemployed, and being specific to individual that are active but movers between these two states;

finally, cluster 5 is the largest one with 63.9% of the sample of the stayers, the ones that mostly keep staying in the same state in the sampled period. Mostly, it has respondents always in the state worker and retired.

@&#CONCLUSIONS@&#

In this paper we propose an innovative method for clustering categorical sequential data. Using a hybrid algorithm, we develop a two-step procedure which allows us to discover groups of data series characterized by similar trajectories and dynamics. In the first step, we resort to the model-based clustering approach provided by the Panel hidden Markov model in order to transform the categorical data into a probabilistic space defined by the estimated posterior probabilities without losing information related to the dynamics and dependency in the data. Then, in the second step, we compute the distances between the sequences using a symmetric Kullback–Leibler distance and we perform an agglomerative clustering approach in order to cluster the data sequences into homogenous groups. Our method contributes to the growing literature on sequential data clustering providing a specific focus on dealing with categorical variables and sequences characterized by different lengths. We illustrate the enormous potential of our hybrid clustering method by means of a synthetic example and two applications. Using the msnbc.com web data set, we define two distinct website users search patterns which can be exploited, e.g., for marketing purposes (Dias & Vermunt, 2007) or for improving the structure and the design of a website. The second application deals with investigating the job career dynamics using a survey provided by the Bank of Italy where we detect five clusters characterized by different employment status patterns. The information provided by this classification is helpful in guiding work and social security policies.

This paper opens an important stream of research on data mining similarities between categorical time series. Several extensions of the method can be investigated, namely, the impact of the probability measure used to compute the distance between two sequences. Thus, one can compare the performance of the KL distance with other measures as well as explore other clustering algorithms. These extensions and comparisons can explore categorical data sets from other fields of research.

@&#ACKNOWLEDGEMENTS@&#

The authors would like to thank the editor and two anonymous reviewers for their constructive comments, which helped us to improve the manuscript. The first author thanks the Italian Ministry of Education, University and Research for financial support through the PRIN project “Multivariate statistical models for risk assessment”. The second author thanks the Fundação para a Ciência e Tecnologia (Portugal) for its financial support (PTDC/EGE-GES/103223/2008).

The estimation of the vector of parameters 
                        
                           φ
                        
                      for the Panel HMM proposed in Section 2 is achieved by the well-known EM algorithm (Dempster et al., 1977) which, in the context of HMMs, is also known as the Baum–Welch algorithm.

For object i, the likelihood function of the observed sequence of categories 
                        
                           
                              
                                 y
                              
                              
                                 i
                              
                           
                        
                      of length 
                        
                           
                              
                                 T
                              
                              
                                 i
                              
                           
                        
                      for 
                        
                           φ
                        
                      can be written in matrix form:
                        
                           (A.1)
                           
                              L
                              (
                              φ
                              ;
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              Λ
                              P
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                    1
                                 
                              
                              )
                              Π
                              P
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                    2
                                 
                              
                              )
                              Π
                              P
                              (
                              
                                 
                                    y
                                 
                                 
                                    i
                                    3
                                 
                              
                              )
                              …
                              Π
                              P
                              (
                              
                                 
                                    y
                                 
                                 
                                    
                                       
                                          iT
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              )
                              
                                 
                                    1
                                 
                                 
                                    ′
                                 
                              
                           
                        
                     where 
                        
                           Λ
                           =
                           
                              
                                 (
                                 
                                    
                                       λ
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 
                                    
                                       λ
                                    
                                    
                                       K
                                    
                                 
                                 )
                              
                              
                                 ′
                              
                           
                        
                      is the initial distribution vector, 
                        
                           Π
                        
                      is the 
                        
                           K
                           ×
                           K
                        
                      latent transition matrix which collects the switching probabilities 
                        
                           
                              
                                 π
                              
                              
                                 wk
                              
                           
                           ,
                           1
                        
                      is a K-dimensional vector of ones, and 
                        
                           P
                        
                     
                     
                        
                           (
                           
                              
                                 y
                              
                              
                                 it
                              
                           
                           )
                        
                     , for 
                        
                           t
                           =
                           1
                           ,
                           …
                           
                              
                                 T
                              
                              
                                 i
                              
                           
                        
                     , is a 
                        
                           K
                           ×
                           K
                        
                      diagonal matrix with kth diagonal element 
                        
                           
                              
                                 p
                              
                              
                                 k
                              
                           
                           (
                           
                              
                                 y
                              
                              
                                 it
                              
                           
                           )
                           =
                           f
                           (
                           
                              
                                 y
                              
                              
                                 it
                              
                           
                           |
                           
                              
                                 z
                              
                              
                                 it
                              
                           
                           =
                           k
                           )
                        
                     , for 
                        
                           k
                           =
                           1
                           ,
                           …
                           ,
                           K
                        
                     .

The likelihood function in Eq. (A.1) can be written as 
                        
                           L
                           (
                           φ
                           ;
                           
                              
                                 y
                              
                              
                                 i
                              
                           
                           )
                           =
                           
                              
                                 α
                              
                              
                                 it
                              
                           
                           
                              
                                 β
                              
                              
                                 it
                              
                              
                                 ′
                              
                           
                        
                     , where the row vector 
                        
                           
                              
                                 α
                              
                              
                                 it
                              
                           
                           =
                        
                      
                     
                        
                           Λ
                           P
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 1
                              
                           
                           )
                           Π
                           P
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 2
                              
                           
                           )
                           …
                           Π
                           P
                           (
                           
                              
                                 y
                              
                              
                                 it
                              
                           
                           )
                        
                      collects the forward probabilities 
                        
                           
                              
                                 α
                              
                              
                                 it
                              
                           
                           (
                           k
                           )
                           =
                        
                      
                     
                        
                           f
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 y
                              
                              
                                 it
                              
                           
                           ,
                           
                              
                                 z
                              
                              
                                 it
                              
                           
                           =
                           k
                           )
                        
                      and the vector of backward probabilities 
                        
                           
                              
                                 β
                              
                              
                                 it
                              
                              
                                 ′
                              
                           
                           =
                           Π
                           P
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 ,
                                 t
                                 +
                                 1
                              
                           
                           )
                           Π
                           P
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 ,
                                 t
                                 +
                                 2
                              
                           
                           )
                           …
                           Π
                           P
                           (
                           
                              
                                 y
                              
                              
                                 
                                    
                                       iT
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           )
                           
                              
                                 1
                              
                              
                                 ′
                              
                           
                        
                      contains the conditional probabilities 
                        
                           
                              
                                 β
                              
                              
                                 it
                              
                           
                           (
                           k
                           )
                           =
                           f
                           (
                           
                              
                                 y
                              
                              
                                 i
                                 ,
                                 t
                                 +
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 y
                              
                              
                                 
                                    
                                       iT
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           |
                           
                              
                                 z
                              
                              
                                 it
                              
                           
                           =
                           k
                           )
                        
                     , for 
                        
                           k
                           =
                           1
                           ,
                           …
                           ,
                           K
                        
                      (Zucchini & MacDonald, 2009).

The complete-data log-likelihood of a Panel HMM is given by 
                        
                           
                              
                                 ℓ
                              
                              
                                 c
                              
                           
                           (
                           φ
                           ;
                           y
                           )
                           =
                           log
                           
                              
                                 L
                              
                              
                                 c
                              
                           
                           (
                           φ
                           ;
                           y
                           )
                           =
                           
                              
                                 ∑
                              
                              
                                 i
                                 =
                                 1
                              
                              
                                 n
                              
                           
                           log
                           
                              
                                 L
                              
                              
                                 c
                              
                           
                           (
                           φ
                           ;
                           
                              
                                 y
                              
                              
                                 i
                              
                           
                           )
                        
                     , where
                        
                           (A.2)
                           
                              log
                              
                                 
                                    L
                                 
                                 
                                    c
                                 
                              
                              (
                              φ
                              ;
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    u
                                 
                                 
                                    ik
                                 
                              
                              (
                              1
                              )
                              log
                              
                                 
                                    λ
                                 
                                 
                                    k
                                 
                              
                              +
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       w
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                t
                                                =
                                                2
                                             
                                             
                                                
                                                   
                                                      T
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             v
                                          
                                          
                                             iwk
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 
                              
                              log
                              
                                 
                                    π
                                 
                                 
                                    wk
                                 
                              
                              +
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       t
                                       =
                                       1
                                    
                                    
                                       
                                          
                                             T
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                              
                                 
                                    u
                                 
                                 
                                    ik
                                 
                              
                              (
                              t
                              )
                              log
                              
                                 
                                    p
                                 
                                 
                                    k
                                 
                              
                              (
                              
                                 
                                    y
                                 
                                 
                                    it
                                 
                              
                              )
                           
                        
                     where 
                        
                           
                              
                                 u
                              
                              
                                 ik
                              
                           
                           (
                           t
                           )
                           =
                           1
                        
                      iff 
                        
                           
                              
                                 z
                              
                              
                                 it
                              
                           
                           =
                           k
                        
                      and 
                        
                           
                              
                                 v
                              
                              
                                 iwk
                              
                           
                           (
                           t
                           )
                           =
                           1
                        
                      iff 
                        
                           
                              
                                 z
                              
                              
                                 it
                              
                           
                           =
                           k
                        
                      and 
                        
                           
                              
                                 z
                              
                              
                                 i
                                 ,
                                 t
                                 -
                                 1
                              
                           
                           =
                           w
                        
                     .

The EM algorithm proceeds as follows:
                        
                           •
                           In the E step the quantities 
                                 
                                    
                                       
                                          u
                                       
                                       
                                          ik
                                       
                                    
                                    (
                                    t
                                    )
                                 
                               and 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          iwk
                                       
                                    
                                    (
                                    t
                                    )
                                 
                               in Eq. (A.2) are replaced by their conditional expectations given the observations 
                                 
                                    
                                       
                                          y
                                       
                                       
                                          i
                                       
                                    
                                 
                               and the current parameter estimates 
                                 
                                    
                                       
                                          φ
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                              :
                                 
                                    (A.3)
                                    
                                       
                                          
                                             
                                                
                                                   u
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ik
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       f
                                       (
                                       
                                          
                                             z
                                          
                                          
                                             it
                                          
                                       
                                       =
                                       k
                                       |
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             φ
                                          
                                          
                                             ˆ
                                          
                                       
                                       )
                                       =
                                       
                                          
                                             α
                                          
                                          
                                             it
                                          
                                       
                                       (
                                       k
                                       )
                                       
                                          
                                             β
                                          
                                          
                                             it
                                          
                                       
                                       (
                                       k
                                       )
                                       /
                                       L
                                       (
                                       
                                          
                                             φ
                                          
                                          
                                             ˆ
                                          
                                       
                                       ;
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                 
                              and
                                 
                                    
                                       
                                          
                                             
                                                
                                                   v
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             iwk
                                          
                                       
                                       (
                                       t
                                       )
                                       =
                                       f
                                       (
                                       
                                          
                                             z
                                          
                                          
                                             it
                                          
                                       
                                       =
                                       k
                                       ,
                                       
                                          
                                             z
                                          
                                          
                                             i
                                             ,
                                             t
                                             -
                                             1
                                          
                                       
                                       =
                                       w
                                       |
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       )
                                       =
                                       
                                          
                                             α
                                          
                                          
                                             i
                                             ,
                                             t
                                             -
                                             1
                                          
                                       
                                       (
                                       k
                                       )
                                       
                                          
                                             π
                                          
                                          
                                             wk
                                          
                                       
                                       
                                          
                                             p
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       
                                          
                                             y
                                          
                                          
                                             it
                                          
                                       
                                       )
                                       
                                          
                                             β
                                          
                                          
                                             it
                                          
                                       
                                       (
                                       k
                                       )
                                       /
                                       L
                                       (
                                       
                                          
                                             φ
                                          
                                          
                                             ˆ
                                          
                                       
                                       ;
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                 
                              
                           

In the M step the three terms of the function in Eq. (A.2) are maximized with respect to the corresponding three set of parameters: 
                                 
                                    Λ
                                 
                               for the first term, 
                                 
                                    Π
                                 
                               for the second term, and, for the third term, the parameters of the state-dependent (categorical) multinomial distributions: 
                                 
                                    ϖ
                                    =
                                    (
                                    
                                       
                                          ϖ
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          ϖ
                                       
                                       
                                          s
                                       
                                    
                                    )
                                 
                              , where s denotes the number of different categories and 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          h
                                          =
                                          1
                                       
                                       
                                          s
                                       
                                    
                                    
                                       
                                          ϖ
                                       
                                       
                                          h
                                       
                                    
                                    =
                                    1
                                 
                              .

The EM procedure consists in repeating these two steps until some convergence criterion has been reached.

The Panel HMM is an extension of the HMM. Removing index i from expressions above (i.e., a single time series, 
                        
                           n
                           =
                           1
                        
                     ), Panel HMM reduces to the traditional HMM.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#User identification for enhancing IP-TV recommendation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           In contrast with group recommendation which recommends items for groups of people, this approach provides recommendations for members.


                        
                        
                           
                           The user identification problem is studied as clustering periodical temporal habits and combination of similar activities in each account.


                        
                        
                           
                           Experimental results show that the proposed algorithm gives substantially better results than previous approaches.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

User identification

Shared account

IP-TV recommendation

@&#ABSTRACT@&#


               
               
                  Internet Protocol Television (IP-TV) recommendation systems are designed to provide programs for groups of people, such as a family or a dormitory. Previous methods mainly generate recommendations to a group of people via clustering the common interests of this group. However, these methods often ignore the diversity of a group’s interests, and recommendations to a group of people may not match the interests of any of the group members. In this paper, we propose an algorithm that first identifies users in accounts, then provides recommendations for each user. In the identification process, time slots in each account are determined by clustering the factorized time subspace, and similar activities among these slots are combined to represent members. Experimental results show that the proposed algorithm gives substantially better results than previous approaches.
               
            

@&#INTRODUCTION@&#

In recent years, due to the rapid growth and increasing popularity of Internet Protocol Television (IP-TV) services, IP-TV services have been widely consumed in our daily life, and it has been a common phenomenon that families or roommates share programs after they get back home or dormitory from work. To help users (viewers) benefit from the abundant resources, such as channels, programs and videos, and easily find what they are actually interested in, recommender systems [1] are integrated into the services.

However, the main challenge in developing a IP-TV recommendation system is user identification [2]. Intuitively, the recommendations provided to a shared account, comprising the ratings of two dissimilar users, may not match the interests of either of both users [3]. The use of a single account shared by multiple users poses more personalized requirements in providing programs to this account.

Our goal is to improve the recommendation performance by alleviating the problem of user identification in IP-TV services. However, none of the individual user information [4] can be directly used for the identification, since the interaction between a user and a set-top-box (STB) is very weak. Typically, users do not have easy access to the keyboard, mouse or touch screen. Moreover, the services are indistinctly shared by the users in a shared account. The history logs recorded by STBs contain the following data fields: AccountId, ProgramId, StartTime, EndTime and Genre. In reality, a log recalls that an account starts and ends a program, and marks a program to a genre.

The assumption is that users within a shared account not only have distinct temporal habits, such as after dinner or at weekends, but also have different preferences for television programs (or genres). There are two questions: (1) how to accurately detect temporal habits over accounts? (2) how to accurately obtain preferences based on the detected temporal habits for a user?

To address these questions, we propose a novel algorithm that consists of a partition process and a consolidation process. In the partition process, the time is divided into several nonoverlapping time slots to present temporal habits of users. More specifically, we use the consumption logs to construct an account-item-time play count tensor. We decompose this tensor into the multiplication of a few (low-rank) latent matrices of accounts, items, time intervals, and a core tensor. And then, time slots are obtained via clustering the latent matrix of time intervals. In the consolidation process, we introduce virtual user to represent preferences of an account in a clustered time slot, and similar virtual users are combined to extract users.

A simple overview of our proposed algorithm is drawn in Fig. 1
                     .

The contributions of this paper are summarized as follows:

                        
                           1.
                           We study the problem of user identification in IP-TV services as mining groups of time slots and preferences within accounts.

We propose an algorithm to fulfill the identification task. In this algorithm, we try a tensor factorization based subspace clustering method to discover groups of time slots. And then similar preferences over these time slots are combined to present users.

Finally, we demonstrate how this algorithm above can be applied to improve recommendation. Experimental results on a real IP-TV dataset show that our algorithm outperforms comparable methods.

A preliminary result was reported previously [5]. This paper substantially extends this work.

The rest of this paper is organized as follows. Section 2 provides a brief review of related work on IP-TV recommendation. Section 3 gives the problem definition and notations. Section 4 describes our proposed approach to carry out identification task. Section 5 shows the settings in our experiments. Section 6 presents the experimental results and analysis. Finally, Section 7 concludes the paper.

@&#RELATED WORK@&#

The work in this paper closely relates to the research areas: collaborative filtering and context-aware recommendation. We present the most relevant previous work in each of them.

Collaborative filtering (CF) has been the most popular technique for recommender systems [6,7]. Typically, collaborative filtering approaches can be divided into two types: memory-based methods as well as model-based approaches. Memory-based methods focus on using predefined similarity calculation functions to find similar users or items for generating predictions [8]. Memory-based methods can be further classified as user-based [9–11] and item-based [12–14] approaches based on whether similar users or similar items are used. In contrast, the model-based approaches use the observed ratings to train a predefined learning model, and the unobserved ratings are then predicted via the trained model. Algorithms in this category include but not limited to clustering model [15], the aspect models [16], the Bayesian hierarchical model [17], the ranking model [18], etc.

Recently, a particular group of methods, referred to as matrix factorization methods, have become dominant in the field [19]. The performance of the group of methods for the rating prediction problem has been tested in Netflix Prize Contest [20,21] and the KDD CUP 2011 [22]. Matrix factorization methods normally seek to factorize the user-item rating matrix into two low rank latent matrices of users and items, and then utilize the factorized matrices to make further predictions. The factorized latent matrix of user is also employed to cluster groups of users with similar tastes. Zhang et al. [3] believed that users within a household have similar interests, and applied several clustering algorithms to identify groups of users as households. Matrix factorization methods have been further extended to incorporate content metadata information [23], so that the rich side information of users and items beyond the user-item relations can be exploited for improving recommendation. In addition, the matrix factorization framework has also been developed for the top-K recommendation problem in domains with implicit feedback data [24,25], and the binary rating technique is employed to represent users’ implicit preferences.

However, these methods cannot be directly used to alleviate our problem, since a television is indistinctly shared by multiple users. In this paper, we consider users within a shared account do not have common interests and temporal habits in IP-TV services.

The context-aware recommender systems (CARS) have received lots of attentions. Early work in CARS utilized contextual information (e.g., demography, location and time) for pre-processing, where the context drives data selection, or post-processing, where the context is used to filter recommendations [26]. Said et al. [27] used time to split an user into two contextual user profiles, and recommendations are provided to each contextual user profiles. A significant portion of recent work has focused on incorporating context variables into the matrix factorization methods [28–30]. Due to the success of matrix factorization for modeling the user-item relations, one major group of approaches exploited the tensor factorization techniques [31] for modeling the 3-way user-item-context relations [32–34]. A tensor in this case is a generalization of matrix from 2-dimension to n-dimension. Another contribution for modeling the contextual information is factorization machines [35,36], which models the interactions between each pair of entities in terms of their latent factors, such as user–user, user-item, user-context interactions.

The work in this paper also builds upon tensor factorization models. The latent matrix of the context (time) is factorized and clustered to detect temporal habits.


                     Table 1
                      gives the main notations used in this paper.

To start with, let us consider a common scene that multiple users share a common account in IP-TV services. As Fig. 2
                      shows, an account corresponding to a STB shared by 3 kinds of family members: senior, younger and kids. The senior get used to demanding history series in the morning or afternoon, kids would like to play the sort of cartoon programs after school or dinner, and younger might prefer films after kids go to the bed.

From the common scene above we can find: (1) the consuming behaviors are periodic; (2) different users get used to consuming the services in different part(s) of a period; (3) different users often have different preferences for programs (genres) provided by the services. Based on this common phenomenon, the problem of identifying users sharing a common STB can be regarded as distinguishing user preferences over time.

We introduce period P to describe periodic behavior. The period is defined as

                        
                           (1)
                           
                              
                                 
                                    
                                    
                                       
                                          P
                                          :
                                          =
                                          
                                             ⋃
                                             
                                                k
                                                =
                                                1
                                             
                                             
                                                |
                                                P
                                                |
                                             
                                          
                                          
                                             p
                                             k
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                          
                                          
                                             ⋂
                                             
                                                k
                                                =
                                                1
                                             
                                             
                                                |
                                                P
                                                |
                                             
                                          
                                          
                                             p
                                             k
                                          
                                          =
                                          ∅
                                          .
                                       
                                    
                                 
                              
                           
                        
                     This definition means that the continuous period P (e.g., day) consists of several, non-overlapping sub-period pk
                      (e.g., hour of day). A user may consume television services in more than one sub-period, and is defined as

                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             u
                                             
                                                a
                                                h
                                             
                                          
                                          :
                                          =
                                          
                                             {
                                             
                                                (
                                                a
                                                ,
                                                
                                                   s
                                                   
                                                      a
                                                      h
                                                   
                                                
                                                )
                                             
                                             |
                                             a
                                             ∈
                                             A
                                             ,
                                             
                                                s
                                                
                                                   a
                                                   h
                                                
                                             
                                             ⊆
                                             P
                                             ,
                                             
                                                s
                                                
                                                   a
                                                   h
                                                
                                             
                                             ≠
                                             ∅
                                             }
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where uah
                      is the hth user within account a who consumes services in sah, sah
                      denotes several sub-period within P (e.g., Morning and Afternoon), and A denotes all accounts in the system. As Fig. 2 provides, the senior consume services in the Morning and Afternoon, the younger consume services in the Morning, and kids in the Evening. Hence, all users U in system can be defined as

                        
                           (3)
                           
                              
                                 
                                    
                                       
                                          U
                                          :
                                          =
                                          
                                             ⋃
                                             
                                                a
                                                ∈
                                                A
                                             
                                          
                                          
                                             ⋃
                                             
                                                
                                                   s
                                                   
                                                      a
                                                      h
                                                   
                                                
                                                ⊆
                                                P
                                             
                                          
                                          
                                             u
                                             
                                                a
                                                h
                                             
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     Our goal is to identify U, and provide accurate recommendations for U. We are trying to reach the goal by addressing the two questions: (1) how to capture the preferences of user uah
                      (hth user within account a)? (2) how to determine the consuming time sah
                      of hth user within account a?

In order to capture the preferences of user uah
                     , we introduce virtual user vak
                      to present activities of an account in a sub-period pk
                     . The virtual user is defined as

                        
                           (4)
                           
                              
                                 
                                    
                                       
                                          
                                             v
                                             
                                                a
                                                k
                                             
                                          
                                          :
                                          =
                                          
                                             {
                                             
                                                (
                                                a
                                                ,
                                                
                                                   p
                                                   k
                                                
                                                )
                                             
                                             |
                                             a
                                             ∈
                                             A
                                             ,
                                             
                                                p
                                                k
                                             
                                             ∈
                                             P
                                             ,
                                             
                                                p
                                                k
                                             
                                             ≠
                                             ∅
                                             }
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where vak
                      is the activities of account a in sub-period pk
                     , and an identified user is a composite of virtual user(s). Therefore, the preferences of a real user can be composed by the preferences of corresponding virtual users.

We suppose that users in reality have different preferences for both programs (or genres) and different periodic behaviors. Hence, the users in an account can be identified by consolidation of virtual users. We introduce the similarity graph G, which uses vertexes to denote virtual users, and uses edges to denote the similarity between virtual users. The preference similarity graph G is defined as

                        
                           (5)
                           
                              
                                 
                                    
                                       
                                          G
                                          :
                                          =
                                          G
                                          (
                                          v
                                          (
                                          a
                                          )
                                          ,
                                          s
                                          (
                                          a
                                          )
                                          )
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where v(a) is the set of virtual users within account a, and s(a) presents pairs of similar virtual users within account a. The benefits of using graph G are that the process of combining virtual users can be easily controlled and the complexity of this process can be reduced.

In this section, we propose an algorithm, namely Tensor factorization based subspace clustering and preferences consolidation (TCC), to identify users within shared accounts. The algorithm mainly consists of the partition process for determining time slots, and the consolidation process for fusing similar preferences in different time slots.

Detailed steps of the proposed TCC algorithm are given in Algorithm 1.
                  

We try three different methods to carry out the partition task: (1) empirical split method. The time slots are assigned according to experiments; (2) average split method. In this method, the period is equally divided into a given number of time slots. We use VUI to present this method as well as [5]; (3) while previous methods are greatly affected by manual setup and cannot fit the dataset well. In this paper, we use latent time space to cluster the time slots via factorizing the account-item-time play count tensor.

As Fig. 3
                         shows, we use symbol 
                           C
                         to present the play count tensor, use cait
                         to denote a given entry in 
                           
                              C
                              ,
                           
                         and use T to denote time dimension of 
                           C
                        . More realistically, cait
                         means the play count of item i consumed by account a in time interval t ∈ T. The time dimension T in 
                           C
                         is equally divided into several intervals, and each interval in 
                           C
                         must be smaller than any sub-period pk
                        . Therefore, the sub-period can be obtained by clustering the factorized sub-spaces.

A common approach to obtaining the sub-space is to decompose 
                           C
                         into the multiplication of a few (low-rank) matrices and a core tensor (or just a few vectors), based on 
                           C
                        ’s non-zero entries. For example, as illustrated in the right part of Fig. 3, we can decompose 
                           C
                         into the multiplication of a core tensor 
                           
                              M
                              ∈
                              
                                 R
                                 
                                    
                                       d
                                       X
                                    
                                    ×
                                    
                                       d
                                       Y
                                    
                                    ×
                                    
                                       d
                                       Z
                                    
                                 
                              
                              ,
                           
                         and three matrices, 
                           
                              X
                              ∈
                              
                                 R
                                 
                                    
                                       |
                                       A
                                       |
                                    
                                    ×
                                    
                                       d
                                       X
                                    
                                 
                              
                              ,
                              Y
                              ∈
                              
                                 R
                                 
                                    
                                       |
                                       I
                                       |
                                    
                                    ×
                                    
                                       d
                                       Y
                                    
                                 
                              
                              ,
                              Z
                              ∈
                              
                                 R
                                 
                                    
                                       |
                                       T
                                       |
                                    
                                    ×
                                    
                                       d
                                       Z
                                    
                                 
                              
                              ,
                           
                         using a tucker decomposition model [37]. The objective function to control the error of the decomposition is usually defined as

                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             L
                                             (
                                             M
                                             ,
                                             X
                                             ,
                                             Y
                                             ,
                                             Z
                                             )
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                1
                                                2
                                             
                                             
                                                
                                                   ∥
                                                   C
                                                   −
                                                   M
                                                   
                                                      ×
                                                      X
                                                   
                                                   X
                                                   
                                                      ×
                                                      Y
                                                   
                                                   Y
                                                   
                                                      ×
                                                      Z
                                                   
                                                   Z
                                                   ∥
                                                
                                                2
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                             
                                                λ
                                                2
                                             
                                             
                                                (
                                                
                                                   
                                                      ∥
                                                      M
                                                      ∥
                                                   
                                                   2
                                                
                                                +
                                                
                                                   
                                                      ∥
                                                      X
                                                      ∥
                                                   
                                                   2
                                                
                                                +
                                                
                                                   
                                                      ∥
                                                      Y
                                                      ∥
                                                   
                                                   2
                                                
                                                +
                                                
                                                   
                                                      ∥
                                                      Z
                                                      ∥
                                                   
                                                   2
                                                
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where ‖·‖2 denotes the Frobenius norm, the first part is to control the decomposition error and 
                           
                              
                                 λ
                                 2
                              
                              
                                 (
                                 
                                    
                                       ∥
                                       M
                                       ∥
                                    
                                    2
                                 
                                 +
                                 
                                    
                                       ∥
                                       X
                                       ∥
                                    
                                    2
                                 
                                 +
                                 
                                    
                                       ∥
                                       Y
                                       ∥
                                    
                                    2
                                 
                                 +
                                 
                                    
                                       ∥
                                       Z
                                       ∥
                                    
                                    2
                                 
                                 )
                              
                           
                         is a regularization term to avoid over-fitting, dX, dY
                         and dZ
                         are usually very small, denoting the number of latent factors, λ is a parameter controlling the contribution of the regularization term. The symbol “×” denotes the matrix multiplication; “×
                           X
                        ” stands for the tensor-matrix multiplication, where the subscript “X” stands for the mode a tensor, e.g., 
                           
                              W
                              =
                              M
                              
                                 ×
                                 X
                              
                              X
                           
                         is 
                           
                              
                                 W
                                 
                                    i
                                    j
                                    k
                                 
                              
                              =
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    d
                                    X
                                 
                              
                              
                                 
                                    M
                                    
                                       i
                                       j
                                       k
                                    
                                 
                                 ×
                                 
                                    X
                                    
                                       i
                                       j
                                    
                                 
                              
                           
                        .

As the partition procedure in Lines 6–15, Algorithm 1 shows, we exploit stochastic gradient descent (SGD)
                           1
                        
                        
                           1
                           The SGD [31] is chosen due to its speed and ease of implementation. An alternative strategy is alternating least square (ALS) [38]. While ALS can be parallelized, these advantages are irrelevant in our case.
                         to learn the tensor, where X
                        
                           a*, Y
                        
                           i*, Z
                        
                           t* denote the ath, ith, tth columns of X, Y, Z respectively, 
                           
                              M
                              
                                 ×
                                 Y
                              
                              
                                 Y
                                 
                                    i
                                    *
                                 
                              
                              
                                 ×
                                 Z
                              
                              
                                 Z
                                 
                                    t
                                    *
                                 
                              
                           
                         is the gradient of X
                        
                           a*, and γ is the learning rate. We choose k-Means to cluster the latent time space Z 
                        [39], and the similarity between two time intervals is measured by Squared Euclidean Distance.

As presented in Consolidation procedure in Lines 16–26, Algorithm 1, members in a shared account are represented via consolidating the similar preferences among the parted time slots. The duration from an account to an item is used to calculate the preferences. The implicit rating of an account over a time slot is formulated as

                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             
                                                r
                                                
                                                   a
                                                   i
                                                   k
                                                
                                             
                                             =
                                             
                                                
                                                   exp
                                                   (
                                                   
                                                      d
                                                      
                                                         a
                                                         i
                                                         k
                                                      
                                                   
                                                   )
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      
                                                         |
                                                         P
                                                         |
                                                      
                                                   
                                                   exp
                                                   
                                                      (
                                                      
                                                         d
                                                         
                                                            a
                                                            i
                                                            k
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where daik
                         is the duration of item i consumed by account a in sub-period pk
                        , and exp () stands for the exponential function [40]. The exp () is adopted to smooth daik
                        , since daik
                         varies as item changes. For example, the length of a played movie can easily exceed one hour, but the length of a cartoon is usually limited within half of an hour. Note that, an account may demand an item more than one time, therefore, we do not choose the binary rating techniques or percentage of a program watched to the length of it [7]. For convenience, the virtual user (Eq. (4)) is introduced to represent an account’s activities in a given time slot, and the implicit rating of a given virtual user is captured by using Eq. (7).

In order to consolidate the similar virtual users within an account, we use Cosine function to measure the similarity between two virtual users, then a similarity threshold ρ ∈ [0, 1] is adopted to determine the consolidation. Given account a, the preference similarity between virtual user v and v′ within a is defined as

                           
                              (8)
                              
                                 
                                    
                                       
                                          
                                             S
                                             
                                                v
                                                
                                                   v
                                                   ′
                                                
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             cos
                                             
                                                (
                                                v
                                                ,
                                                
                                                   v
                                                   ′
                                                
                                                )
                                             
                                             =
                                             cos
                                             
                                                (
                                                
                                                   v
                                                   
                                                      a
                                                      k
                                                   
                                                
                                                ,
                                                
                                                   v
                                                   
                                                      a
                                                      
                                                         k
                                                         ′
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         ∈
                                                         I
                                                         
                                                            (
                                                            
                                                               v
                                                               
                                                                  a
                                                                  k
                                                               
                                                            
                                                            )
                                                         
                                                         ∩
                                                         I
                                                         
                                                            (
                                                            
                                                               v
                                                               
                                                                  a
                                                                  
                                                                     k
                                                                     ′
                                                                  
                                                               
                                                            
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      r
                                                      
                                                         a
                                                         i
                                                         k
                                                      
                                                   
                                                   ·
                                                   
                                                      r
                                                      
                                                         a
                                                         i
                                                         
                                                            k
                                                            ′
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         ∑
                                                         
                                                            i
                                                            ∈
                                                            I
                                                            (
                                                            
                                                               v
                                                               
                                                                  a
                                                                  k
                                                               
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         r
                                                         
                                                            a
                                                            i
                                                            k
                                                         
                                                      
                                                      ·
                                                      
                                                         ∑
                                                         
                                                            i
                                                            ∈
                                                            I
                                                            (
                                                            
                                                               v
                                                               
                                                                  a
                                                                  
                                                                     k
                                                                     ′
                                                                  
                                                               
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         r
                                                         
                                                            a
                                                            i
                                                            
                                                               k
                                                               ′
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where raik
                         denotes implicit rating of account a to item i in pk
                        , and I(vak
                        ) denotes set of items consumed by virtual user vak
                        . We introduce 
                           
                              
                                 s
                                 
                                    v
                                    
                                       v
                                       ′
                                    
                                 
                                 ′
                              
                              ∈
                              
                                 {
                                 0
                                 ,
                                 1
                                 }
                              
                           
                         to denote binary similarity. The binary similarity 
                           
                              s
                              
                                 v
                                 
                                    v
                                    ′
                                 
                              
                              ′
                           
                         is defined as

                           
                              (9)
                              
                                 
                                    
                                       s
                                       
                                          v
                                          
                                             v
                                             ′
                                          
                                       
                                       ′
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   1
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      S
                                                      
                                                         v
                                                         
                                                            v
                                                            ′
                                                         
                                                      
                                                   
                                                   ⩾
                                                   ρ
                                                
                                             
                                          
                                          
                                             
                                                
                                                   0
                                                   ,
                                                
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where ρ denotes the threshold of preference similarity. This means if the similarity of two virtual users is greater than ρ, the virtual users are regarded as similar, otherwise dissimilar. The advantage of ρ is that the effects on recommendation performance of the consolidation process can be explicitly observed.

To combine the similar virtual users throughout an account, we regard a virtual user as a node in a graph and the similarity between virtual users as edges of this graph. Therefore, the consolidation process is a problem of graph traverse. The consolidation operation is described in Lines 18–27 in Algorithm 1 using deep-first-search (DFS). An alternative way to carry out the task is bread-first-search (BFS) algorithm.

The complexity of the proposed algorithm TCC is 
                           
                              
                                 O
                                 (
                              
                              
                                 t
                                 p
                              
                              
                                 |
                                 C
                                 |
                              
                              
                                 d
                                 X
                              
                              
                                 d
                                 Y
                              
                              
                                 d
                                 Z
                              
                              +
                              
                                 t
                                 c
                              
                              
                                 |
                                 P
                                 ∥
                                 T
                                 |
                              
                              
                                 d
                                 Z
                              
                              +
                              
                                 
                                    |
                                    A
                                    |
                                    (
                                    |
                                    P
                                    |
                                 
                                 2
                              
                              /
                              2
                              +
                              
                                 2
                                 |
                                 P
                                 |
                              
                              +
                              
                                 |
                                 S
                                 |
                                 )
                                 )
                                 ,
                              
                           
                         and we summarize it as follows. Given the max epoch of tensor factorization tp
                         and the max epoch of k-Means tc
                        , the tensor factorization scales linearly to the number of non-zero entries 
                           
                              |
                              C
                              |
                           
                         and the dimensionality of the factors dX, dY, dZ
                        , the complexity of tensor factorization is 
                           
                              O
                              (
                              |
                              C
                              |
                              
                                 d
                                 X
                              
                              
                                 d
                                 Y
                              
                              
                                 d
                                 Z
                              
                              )
                           
                        . The complexity of k-Means is 
                           
                              O
                              (
                              
                                 t
                                 c
                              
                              |
                              P
                              ∥
                              T
                              |
                              
                                 d
                                 Z
                              
                              )
                              ,
                           
                         |T| denotes the number of time intervals of time dimension in 
                           C
                        . In the consolidation process, given the number of pairs of similar virtual users (i.e., edges) |S|, the complexity of implicit rating is 
                           
                              O
                              (
                              |
                              P
                              |
                              )
                              ,
                           
                         and it takes 
                           
                              O
                              (
                              |
                              P
                              
                                 |
                                 2
                              
                              +
                              |
                              P
                              |
                              +
                              |
                              S
                              |
                              )
                           
                         to generate and traverse the graph. From these complexity analysis, we can see that the TCC complexity mainly depends on the number of split sub-period |P|.

In this section, we illustrate dataset collection, evaluation metrics and algorithms for recommendation. We evaluate algorithm TCC on the dataset collected from the content provider SMG
                        2
                     
                     
                        2
                        
                           http://www.smg.cn/.
                      in Shanghai, China. It should be noted that we focus on the evaluation of recommender performance by means of identified users, rather than the accuracy evaluation of algorithm TCC.

The logs in the services from SMG are during the period between March 1, 2011 till March 31, 2011. We filter out logs of play time (calculated by start time and end time) less than 10 min. It contains 376,038 records, 5933 videos categorized into 66 genres consumed by 14,856 accounts after being filtered. The records before March 25, 2011 are used for training, and the rest are as test set. The fields of this dataset are shown in Table 2
                        .

In order to avoid problems related to cold start, for both accounts and items, we decide that accounts in the evaluation sets have to consume at least 50 programs. Three subsets of 100, 200, and 500 accounts are randomly selected to carry out the experiments.

We use precision and recall metrics to measure the performance of all the mentioned algorithm, since they often attract lots of attention in a running system and are well known. The precision metric is defined as

                           
                              (10)
                              
                                 
                                    
                                       
                                          
                                             P
                                             r
                                             e
                                             c
                                             i
                                             s
                                             i
                                             o
                                             n
                                             @
                                             N
                                             =
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         u
                                                         ∈
                                                         U
                                                      
                                                   
                                                   
                                                      |
                                                      R
                                                      
                                                         (
                                                         u
                                                         ,
                                                         N
                                                         )
                                                      
                                                      ∩
                                                      T
                                                      
                                                         (
                                                         u
                                                         )
                                                      
                                                      |
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         u
                                                         ∈
                                                         U
                                                      
                                                   
                                                   
                                                      |
                                                      T
                                                      
                                                         (
                                                         u
                                                         )
                                                      
                                                      |
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where N denotes the length of a recommendation list, R(u, N) denotes the recommendation list to user u with length N, T(u) means items has been consumed by identified user u in test set. The recall metric is defined as

                           
                              (11)
                              
                                 
                                    
                                       
                                          
                                             R
                                             e
                                             c
                                             a
                                             l
                                             l
                                             @
                                             N
                                             =
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         u
                                                         ∈
                                                         U
                                                      
                                                   
                                                   
                                                      |
                                                      R
                                                      
                                                         (
                                                         u
                                                         ,
                                                         N
                                                         )
                                                      
                                                      ∩
                                                      T
                                                      
                                                         (
                                                         u
                                                         )
                                                      
                                                      |
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         u
                                                         ∈
                                                         U
                                                      
                                                   
                                                   
                                                      |
                                                      R
                                                      
                                                         (
                                                         u
                                                         ,
                                                         N
                                                         )
                                                      
                                                      |
                                                   
                                                
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        From these definitions, we can see that a larger Precision@N or Recall@N indicates a better performance.

We use the cross-validation technique to study the parameter period P, similarity threshold ρ, and the number of clustered time slots in Algorithm 1 as well. According to validated experiments, we first hold 
                           
                              |
                              P
                              |
                              =
                              4
                              ,
                           
                         and observe the evaluation metrics by changing ρ from 0 to 1 with step size 0.1, then the performance are measured by ranging |P| in {1, 2, 3, 4, 5, 6, 8, 12} while holding 
                           
                              ρ
                              =
                              0.8
                           
                        . For the number of clusters k in TCC, we set 
                           
                              k
                              =
                              4
                           
                         to compare with average split method with 
                           
                              |
                              P
                              |
                              =
                              4
                           
                         and fix 
                           
                              ρ
                              =
                              0.8
                           
                         while changing the recommendation list N.

We adopt, one of the most famous collaborative filtering methods, K-Nearest Neighbor (KNN) method to provide recommendations, since it performs very well in practice (e.g., [41–43]), and we can also learn the benefit from identified users by comparing with recommendations without identification. The Cosine method is used to measure the similarity among accounts/users in algorithm KNN. Hereafter, for easy presentation of figures, we name the recommendations for users identified by Algorithm 1 as TCC, and the recommendations for users identified by the average split method in [5] is named as VUI, respectively.

To study the improvement of TCC (or VUI), we choose the following comparable methods.

                           
                              1.
                              
                                 AccountKNN: this method is the account-based collaborative filtering. The unknown ratings are predicted by considering the ratings given by similar accounts. Account similarity is computed by cosine similarity of ratings.


                                 CUPs 
                                 [27]: this method regards that an account consists of two contextual user profiles (CUPs), and these users are determined by the time of a film started (or ended).


                                 TF 
                                 [44]: this method incorporates time as an independent dimension, and the preferences of missing values in the account-item-time tensor are recovered via factorization techniques. The top-N predicted preferred items within time intervals are provided to accounts.

In this section, we conduct several experiments to compare different parameters of VUI and different methods. Our experiments are intended to address the following questions:

                        
                           1.
                           How the parameters (P and ρ) affect recommendations? In other words, how the partition of a period and consolidation of virtual users affect recommendations?

How the split methods affect recommendations? Can the time consuming behavior be obtained by clustering the factorized subspace?

Can TCC outperform other comparable methods?

Finally, what is the connection between the number of identified users and the recommendation performance?

To study how partition process and consolidation process affect user identification and recommendations, we measure the performance in terms of precision and recall as P or ρ change while holding other parameter. Note that, when 
                           
                              |
                              P
                              |
                              =
                              1
                           
                         or 
                           
                              ρ
                              =
                              0
                              ,
                           
                         the TCC regards an account as a user, and items are directly recommend to an account. In reality, users tend to consume items in specific hours of a day. Here, we use average split method to equally assign the time slots.

The results are presented in Fig. 4
                        . As Fig. 4(a) and (b) state, we hold 
                           
                              |
                              P
                              |
                              =
                              4
                           
                         and change ρ from 0 to 1 with step size 0.1, (1) the precision and recall values are still increasing as ρ increases, (2) the optimal values are found when ρ is set to 0.8, and (3) the Precision@10, Precision@20 value are both higher than the Precision@1, Precision@5 value when no users are identified (
                           
                              ρ
                              =
                              0
                           
                        ), a possible reason is that less recommendations to an account have a higher chance of mismatch of members’ interest.

To study effects on the split of period P, we fix ρ at 0.8 and change |P| to measure Precision@N and Recall@N when making N genre(s) recommendation with 
                           
                              N
                              =
                              {
                              1
                              ,
                              5
                              ,
                              10
                              ,
                              20
                              }
                           
                        . Here, we set 
                           
                              ρ
                              =
                              0.8
                           
                         since the optimal precision and recall values are found at 
                           
                              (
                              |
                              P
                              |
                              =
                              4
                              ,
                              ρ
                              =
                              0.8
                              )
                           
                         according to results in Fig. 4(a) and (b). As revealed in Fig. 4(c) and (d), (1) the precision and recall values are significantly improved, when compared with AccountKNN (
                           
                              |
                              P
                              |
                              =
                              1
                              ,
                           
                         Precision: 1%, Recall: < 1%); (2) the two optimal values are obtained at 
                           
                              |
                              P
                              |
                              =
                              4
                           
                         and 
                           
                              |
                              P
                              |
                              =
                              5
                              ,
                           
                         and the precision value is slight over 17%; (3) the performance starts degrading when |P| > 5, and (4) the Precision@1 value is smaller than Precision@5 when 
                           
                              |
                              P
                              |
                              =
                              8
                              ,
                           
                         which reveals miss match of interests for shared accounts.

According to the conducted experiments above, we learn the effects on the parameters (P and ρ) with respect to average split methods, and the two optimal values can be found at 
                           
                              |
                              P
                              |
                              =
                              4
                           
                         and 
                           
                              |
                              P
                              |
                              =
                              5
                           
                         (a slight better). In this section, we compare Algorithm 1 with empirical and average split methods at [5].

We set 
                           
                              |
                              P
                              |
                              =
                              4
                           
                         to compare the split methods, since it’s more easier to empirically split up four sub-period than five sub-period. Another reason we choose four sub-period to compare is that four sub-period are more close to our daily life. The split up sub-period are shown in Table 3
                        , and the differences are in bold type.

We use the partition procedure in TCC (see Algorithm 1) to cluster 4 time slots. The play count tensor are learned until convergency by the configurations as follows: 
                           
                              
                                 d
                                 x
                              
                              =
                              
                                 d
                                 y
                              
                              =
                              
                                 d
                                 z
                              
                              =
                              5
                              ,
                           
                        
                        
                           
                              γ
                              =
                              λ
                              =
                              0.01
                           
                         
                        [34]. Table 4
                         shows the results via clustering factorized time space ZT
                        . According to the status of a television, a possible status of televisions in intervals of cluster4 in Table 4 is under suspension. In contrast, the empirical method and the average split method both regard televisions work all the day, which may lead to a slip on user identification.

We compare the results of 3 partition mentioned methods on top-N recommendation as the length of recommendation list N changes. For these 3 methods, ρ is set to 0.8. As Fig. 5
                         states, (1) the empirical split method gains a slight improvement when compared with the average split method, but the improvement is not stable. A possible reason for the improvement is that users are off work after 18:00, and they need to spend time on the way and cannot receive programs immediately; (2) the TCC (blue line with diamond sign) outperforms other two split methods with respect to Precision@N and Recall@N when N > 3. The benefit of VUI is its simpleness, meanwhile VUI greatly depends on manual setup. The TCC avoids this problem, and it can automatically cluster the sub-period.

The predictive accuracy with respect to Precision@N and Recall@N (N ranges from 1 to 20) is measured and plotted in Fig. 6
                        .

Firstly, the predictive accuracy is greatly enhanced when an account is decomposed into several users, and the best recommendation performance is achieved by TCC. We compare TF and TCC (
                           
                              ρ
                              =
                              0.8
                           
                        ). It can be observed that the recommendation performances of both two methods tend to be close as N increases. However, the precision values of TF are still smaller than TCC’s.

Secondly, the predictive accuracy of AccountKNN (black line with cross sign) is instable and worse than any other comparable methods. This provides an evidence for the essential of user identification. A possible reason is that the recommendations provided to an account do not match the interests of either of its members, and the preferences of an account consisting of several members.

We try to discover the relationship between the number of identified users and the recommender performance. The numbers of identified users are plotted in Fig. 7
                        , and the performance in terms of Precision@N and Recall@N is measured in Fig. 4.

According to the comparison of Figs. 4(a), (b) and 7(a), we can see that (1) the Precision@N and Recall@N values are increasing when users are identified; (2) the two optimal performances are found at 
                           
                              (
                              |
                              U
                              |
                              =
                              209
                              ,
                              ρ
                              =
                              0.8
                              ,
                              |
                              P
                              |
                              =
                              4
                              )
                           
                         and 
                           
                              (
                              |
                              U
                              |
                              =
                              256
                              ,
                              ρ
                              =
                              0.9
                              ,
                              |
                              P
                              |
                              =
                              4
                              )
                           
                        ; (3) the precision starts decreasing when |U| > 256. The comparison among Figs. 4(c), (d) and 7(b), states, (1) the optimal performance is found at 
                           
                              (
                              |
                              U
                              |
                              =
                              255
                              ,
                              |
                              P
                              |
                              =
                              5
                              ,
                              ρ
                              =
                              0.8
                              )
                              ,
                           
                         and (2) the recommendation performance degrades when |P| > 5, 
                           
                              ρ
                              =
                              0.8
                           
                        .

The following summarizes the key conclusions we observe from the results: (1) the recommender performance is improved when users within accounts are identified for personalized recommendations. A reason for the improvement is that recommendations based on identified users alleviate the problem of recommending given items to wrong users within a shared account; (2) too many or too few identified users (|U| is too small or too large) will degrade the performance. The possible reasons are as follows:

                           
                              1.
                              Too few users identified: when P is split into few sub-period and ρ is set very close to 1, which may regard two (or more than two) real users as one. Hence, a possible reason for the low performance is that items are recommended to users who dislike them.

Too many users identified: when P is split into too many sub-period and ρ is set very close to 0, which may regard a real user as two (or more than two) identified users, and the preferences of the real user are divided into several parts by the identified users. Hence, the opportunity of recommending right items to the real user may decrease since the KNN recommends items other users also preferred.

(3) the optimal precision and recall values are found when 2.5 users per account are identified, and it reflects the rate of real user number to account number.

To study the scalability of the average split method and the proposed algorithm TCC, we randomly select 3 subsets of 100, 200, and 500 accounts. As shown in Fig. 8
                        (a), given Recall@N > 0.05, the TCC (solid lines) outperforms average split method (dash lines) as the data scale increases. For both algorithms, the performance degrades as the data scale increases, however the performance is instable when 
                           
                              N
                              =
                              1
                           
                         (i.e., Recall@N < 0.05), which shows that less recommended items get a higher probability of interests mismatch.

Although TCC has a better recommendation accuracy, the runtime of TCC is still longer than VUI’s. Fig. 8(b) reports the runtime comparison of TCC and VUI on SMG dataset. We can see that TCC spends much time in clustering the time slots. The rate of TCC runtime to VUI runtime tends to be smaller as the data scale increases. The TCC scales linearly to the number of accounts by benefiting from SGD.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this paper, we study the problem that multiple users share a common account in IP-TV services. To enhance recommendation performance for each user, we propose the algorithm TCC to decompose an account into several users. This algorithm consists of two processes: the partition process is designed for detecting time slots, and the consolidation process is used for combining similar preferences to extract real users.

Experimental results on a commercial dataset show that about 2.5 users per account are identified in average, and the recommendation performance is significantly enhanced with respect to precision and recall. The advantage of the proposed TCC is that the temporal habits (i.e., time slots) can be automatically learned from the provided dataset. Moreover, the proposed VUI and TCC have been officially adopted by the provider SMG. The algorithm VUI has been applied as an option of recommendation strategy in the television system with excellent user satisfaction since 2013, and TCC is deploying.

In the future, we plan on extending our work on the study of factorization methods for partition process, cross-validation techniques in terms of the number of clusters and ρ and try different recommendation algorithms.

@&#ACKNOWLEDGMENTS@&#

This research has been supported in part by the Shanghai Science and Technology Commission Foundation (nos. 12dz1500205 and 13430710100), and the National High Technology Research and Development Program (“863” Program no. 2015AA015801). The authors are grateful to the editor and anonymous reviewers for their helpful comments in improving the quality of the paper.

@&#REFERENCES@&#


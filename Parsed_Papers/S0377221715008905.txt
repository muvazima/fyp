@&#MAIN-TITLE@&#Critical Learning Incidents in system dynamics modelling engagements

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Identifies clients’ Critical Learning Incidents by system dynamics engagement activity.


                        
                        
                           
                           In-depth analyses of interviews from client–consultant dyads.


                        
                        
                           
                           Maps learning incidents to prescriptive or predictive model-based engagement phases.


                        
                        
                           
                           Ten system dynamics consulting case studies.


                        
                        
                           
                           Applies constructivist learning theory to complex consulting environments.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Systems dynamics

Practice of OR

Critical Learning Incidents

Behavioural OR

Constructivism

@&#ABSTRACT@&#


               
               
                  This paper reports in-depth behavioural operational research to explore how individual clients learned to resolve dynamically complex problems in system dynamics model-based engagements. Consultant-client dyads involved in ten system dynamics consulting engagements were interviewed to identify individual clients' Critical Learning Incidents—defined as the moment of surprise caused after one's mental model produces unexpected failure and a change in one's mental model produces the desired result. The cases, which are reprised from interviews, include assessments of the nature of the engagement problem, the form of system dynamics model, and the methods employed by consultants during each phase of the engagement. Reported Critical Learning Incidents are noted by engagement phase and consulting method and constructivist learning theory is used to describe a pattern of learning. Research outcomes include descriptions of: the role of different methods applied in engagement phases (for example, the role of concept models to commence problem identification and to introduce iconography and jargon to the engagement participants); how model form associates with the timing of Critical Learning Incidents; and the role of social mediation and negotiation in the learning process.
               
            

@&#BACKGROUND@&#

A conceptual framework is essential to discovery. No matter what the field of interest, all questions and responses arise from a conceptual framework – a way of thinking about things. System dynamics is such a conceptual framework, one that integrates observation and theory from multiple perspectives to improve understanding of how the structure of the transmission and return of information – feedback – determines outcomes. The system dynamics conceptual framework is supported by a mature methodology comprising a variety of methods. (For a more complete description of methodology, see Forrester (1975a) and Ränders (1980).) After conceptualising a problem with causal connections, dynamic hypotheses are tested and analysed in computer models that facilitate comparison between simulated and measured observations to build confidence in new theory (Forrester & Senge, 1980). Adding or removing causal connections changes system performance. Strengthening or weakening the flows of information changes system performance. When the model does not simulate observations, there is an opportunity to learn more about model formulation or more about the world. When a system dynamics model “gets it right”, it is evidence in support of the hypothesis.

The use of feedback dynamics for analysing the behaviour of social systems has by now gained wide acceptance as perhaps the most fruitful method for improving our understanding of the complex interdependencies underlying most social, economic and ecological behaviour (Simon, 1996). While not unique in its use of dynamic concepts or of feedback structures, system dynamics differs substantively from other methodologies in management science in three fundamentals: (1) a resolutely systemic perspective rather than isolated attention to bits-and-pieces, (2) explanation in deterministic mechanisms, and (3) open hypothesising as a method of forming new theory rather than correlation of measured data (Richardson, 1991).

Because system dynamics, and other OR methods, facilitate clients in thinking about and solving problems, individual behavioural issues are key to understanding the outcomes of the process. Indeed, Hämäläinen, Luoma, and Saarinen (2013) identified understanding how certain OR methods produce outcomes, including how individual decision-makers learn, as a fruitful area for behavioural operational research (BOR).

To date, such studies primarily focused on students or a group dealing with a hypothetical problem (see for example, Hämäläinen et al., 2013, Moxnes, 1998; Shields, 1999; Sterman, 1986
                     , 1996; Sterman & Sweeney, 2002; Vennix, 1996). Group model building in system dynamics consulting engagements has been studied on numerous occasions (Rouwette, Vennix, & Mullekom, 2002), and questions of various operational research approaches in facilitated environments have been studied from the perspective of client learning (Franco & Montibeller, 2010). This study (a) considers the experiences of consultants and their clients in consulting engagements based in system dynamics methodology and (b) seeks to provide insights into learning in this context, complementing the findings of studies conducted in a more experimental context.

In practice, system dynamics methodology is often applied by a consultant who works with one or more clients (Wolstenholme & Coyle, 1983). The consultant and clients are frequently confronted with an ill-defined, recurrent and confounding problem. The consultant guides clients through the methodology: problem identification and conceptualisation; formulation of a computer model that simulates the observed system behaviour; dynamic hypothesis testing and analysis; and problem resolution (Ränders, 1980; Lane, 1994). Covering ten cases, the study identifies individual clients’ Critical Learning Incidents – defined as the ‘moment of surprise’ caused after one's mental model produces unexpected failure and a change in one's mental model produces the desired result – and clarifies contributions and limitations of facilitated feedback model building processes to client problem solving and learning.

The research strategy gives voice to individual clients to identify, in their own words, how they construct solutions with help from system dynamics techniques. Consultant–client dyads were selected to be interviewed. Each client and consultant was interviewed separately, and the dyads were analysed to determine how clients made sense of dynamically complex systems and resolved problematic issues. The case analyses include assessments of the nature of the engagement problem and the form of system dynamics model and employ constructivist learning theory to determine how simulation models affect client's Critical Learning Incidents.

Study of the literature on learning, in general and specific to system dynamics, in conjunction with one of the author's (Thompson) reflections on personal experiences as a system dynamics consultant, led to the identification of three principal questions that guided exploration of these issues:

                        
                           (1)
                           Does the application of system dynamics methods change the engagement problem in the mind of the client?

Which consulting methods applied in each phase of an engagement produced a Critical Learning Incident?

Is there a pattern of Critical Learning Incidents in the consulting engagement that is common to all system dynamics consulting engagements?

The section that follows introduces learning theory and considers the role of mental models within this work. Mental models are of interest to this work as they are referred to throughout the system dynamics literature (Groesser & Schaffernicht, 2012) as means used to process experience and thus evidence learning. Following the description of mental models, the paper describes system dynamics methodology and the case method used to gather data to consider the research questions. Background information is provided for each of the cases before presenting a discussion of the results of the research. The richness of the data also enabled analysis of what clients reported as having changed in their mental models and if their changed understanding of the engagement problem affected engagement outcomes. The paper concludes with implications drawn from the research and suggested future research.

The concept of mental model is pervasive in system dynamics literature. Beginning with its earliest mentions in the work of Forrester (1975a), researchers have treated system dynamics methodology as a means for individuals – whether on their own (Schaffernicht & Groesser, 2011) or in groups (Scott, Cavana, & Cameron, 2014) – to better understand interesting experiences by considering cause and effect differently. System dynamics methods explicitly assume that people have one or more mental models through which their experience is processed to make sense of it and that a change in how one makes sense of experience is evidence of learning (Kim, 2009; Morecroft, 2004; Richardson, Andersen, Maxwell, & Stewart, 1980; Senge, 1990).

In the broader field of management science, researchers have followed a similar thread: that in order for a person to resolve a persistent problem, a different way of thinking about that problem is often necessary (for example, Belton & Elder, 1994; Howick & Eden, 2007; Mingers & White, 2010; Mitchell, 1993; Rosenhead & Mingers, 2001; Simon, 1991).

To carry out the research described in this article, a theory of learning was sought that applies widely to adults, embraces the concept of mental model, and has demonstrated useful insight. It was noted that constructivist learning theory is extensively applied in adult learning situations and broadly describes learning as a change in one's mental model. Constructivist researchers such as Glasersfeld (1983), Steffe and Gale (1995), Fox (2001), and Doolittle (2001) use the image of ‘structure’ to describe mental model construction and differentiate between the acquisition of knowledge and a change in mental model structure to explain phenomena such as personal insight (see Appendix B: Survey of adult learning theories).

The constructivist threads build on a theory of learning developed with elements that describe how learning occurs:

                        
                           •
                           Assimilation: The mental process of treating new experience as an instance of something known; experience fitted into one's conceptual structure.

Accommodation: The mental process of treating new experience as an instance of something unknown and modifying one's conceptual structure to make sense of new experience.

Equilibration: A mental process of reflection, of learning to learn, and expanding one's capacity for dealing with the unknown Glasersfeld (1995).

Thus, constructivist learning takes place when an experience, instead of producing the expected result, leads to perturbation, and the perturbation leads to new construction in one's mental model – an accommodation – that maintains or re-establishes one's conceptual equilibrium. The constructivist position is that to learn means to draw conclusions from experience: “Once experiential elements can be re-presented and combined to form hypothetical situations that have not actually been experienced, it becomes possible to generate thought experiments of all kinds. They may start with simple questions, such as: what would happen if I did this or that? And they may regard the most sophisticated abstract problems of physics and mathematics. Insofar as their results can be applied and lead to viable outcomes in practice, thought experiments constitute what is perhaps the most powerful learning procedure in the cognitive domain,” (Glasersfeld, 1995, p. 69, emphasis supplied).


                     Seel (2001) reviews constructivist theories and notes that mental models guide and regulate one's perceptions of physical and social reality. He finds that one's mental model projects an order on to reality, but one's mental model is not a reproduction of reality. Rather it provides a structure used to comprehend one's experiences (p. 408).


                     Fig. 1
                      illustrates one route to learning. In the figure an actual result is different to an expected result, and the difference drives reflection which changes the Perceived Situation and the Action taken as a consequence of the Perceived Situation. This is the hoped-for learning when applying a different methodology to a persistent problem.

As described in constructivist literature, learning is a lifelong process (Merriam & Caffarella, 1999). People continually add to, and understand their experience with, their mental models. When an experience does not fit the structure of their mental model, they may choose to ignore the ill-fitting experience or pursue a better understanding. That pursuit of a better understanding may lead to a change in the mental model structure – a moment of personal insight when a previously unresolved problem is solved (Doolittle & Camp, 1999; Goodell, 2006; Seel, 2001).


                     Senge (1990) observed that participants in system dynamics consulting engagements may experience a much broader change in thinking, from seeing parts to seeing wholes (p. 69) and seeing relationships rather than linear cause-effect chains (p. 73). When carried beyond an immediate problem and applied more generally in one's life, Senge characterises the change as a fundamental shift of mind (p. 68) that leads to mastering a different paradigm. This pattern of change parallels with transformative learning theory (Mezirow, 1990). A framework to identify transformative learning behaviours has emerged from constructivist learning research in the works of Mezirow (1991) and Cranton (2006) which includes experiencing a disorienting dilemma leading to a critical assessment of internalised assumptions and leading to exploration of options for new ways of acting and ways of processing these. The initial social alienation, relation to similar experiences of others and reintegration into society with a new perspective that characterises transformative learning has parallels with the transition from individual to group learning in the context of learning from models.

Based in these traditions of constructivist learning theory, management science and system dynamics literature, this article considers that

                           
                              •
                              an individual's mental model is a construct of thought used to make sense of one's experiences;

learning is the acquisition of knowledge or skill through study or reflection that changes the structure of one's mental model; and,

a Critical Learning Incident is the moment of surprise caused when one's mental model produces unexpected failure to understand an experience and a change in one's mental model produces the desired understanding.

The next section describes the system dynamics methodology used in the consulting engagements reviewed for this study.

System dynamics consulting engagements generally follow a series of steps enumerated in Table 1. The system dynamics methodology described in Table 1 is implemented with a number of methods – tools, processes and techniques – that emerged over years of practice.

Regardless of how steps are carried off, Homer (1996) observes that the phases do not occur in neat sequence. Simulation model-building in a system dynamics consulting engagement is an iterative process of elaboration and simplification, and there are opportunities for learning by the client and consultant in all engagement phases.

The next section describes the research methods used in this study.

Case study methods have been successfully applied to analyse events and outcomes from complicated system dynamics consulting engagements (Eskinasi & Fokkema, 2006). The principal methods used here to develop case materials are researcher reflection (Section 4.1) described by Moon (1999) and semi-structured, open-ended interviews (Section 4.2) described by Yin (2003) to develop ten case studies that combine the recollections of consultant–client dyads.

Episodic memories of interview subjects are generally reliable and durable (see, for example, Bartlett, 1932; Tulving, 1984, 
                     2001). Thus, interviews and personal reflections made after an event can be reliable. In addition, for this work clients were interviewed separately from their consultants to allow for corroboration of events and outcomes.

The interview selection criteria included system dynamics practitioners who have significant career achievements accumulated over five or more years and clients of those consultants. The membership list of the System Dynamics Society was searched to identify suitable consultants and includes independent consultants and educators who do external consulting work. Fifteen consultants were contacted and agreed to participate, but six withdrew their consent before participating. The nine consultants are identified by case name in Table 2
                     . Consultants were asked to nominate an individual client with whom they worked on a system dynamics consulting engagement, without regard to the results of the engagements, which included all of the phases noted in Table 1. A further factor in choosing a client was also their availability and willingness to participate in the interviews. This restricted the clients that could be nominated, and, rather than finding clients from successful engagements, a likely bias was in finding clients interested in reflecting on learning. The individual clients in each case were members of an organisational team assembled to solve a dynamically complex problem or learn to solve a dynamically problem confronting their organisation.

Conversations with five interviewees were held in person (2 consultants and 3 clients); the remaining 13 (6 consultant and 7 client interviews) were held by telephone. Initial interviews lasted about two and one-half hours; one interview spanned six hours. For nearly all interviews, follow-up telephone conversations, lasting one-half to one hour, were needed to clarify points made by the interviewee. Each interview was digitally recorded (voice data recording) with the prior knowledge and permission of the interviewee.

The audio recordings were transcribed. The transcriptions were coded using QSR NVivo version 2.0, and dyadic results juxtaposed and compared. In the event that client and consultant disagreed on the facts, each was interviewed in more depth at least once to find and reconcile the source of disagreement.

The research for this study began with a detailed review of one of the authors’ (Thompson) consulting fieldwork. Consulting case materials including system dynamics models, client and consultant presentations and case notes were reviewed and summaries were prepared that included reports of what was done in the engagement.

To be selected for reflection, the engagement certain characteristics were required:

                           
                              •
                              A complete application of system dynamics methodology, i.e. problem identification, conceptualisation, formulation of computer simulation model with feedback, comparison of simulation to observed results, and implementation in the form of action taken based in the engagement findings.

A principal client, i.e. an individual with ongoing responsibility for the engagement.

The author led the consulting engagement and worked directly with the principal client.

Two preliminary cases, not included in this study, were selected with a question in mind: how did client's thinking change over the course of the engagement? Finally, those reviews led to more detailed questions:

                           
                              (1)
                              Does the application of system dynamics methods change the engagement problem in the mind of the client?

                                    
                                       (a)
                                       In what phase of the consulting engagement do clients report the engagement problem as having changed in their minds?

Which consulting methods applied in each phase of an engagement affect client learning?

                                    
                                       (a)
                                       Do the clients experience Critical Learning Incidents from each method used in each phase?

Is there a pattern of Critical Learning Incidents that is common to all system dynamics consulting engagement?

                                    
                                       (a)
                                       Do system dynamics consulting engagements produce Critical Learning Incidents reliably by engagement phase?

These reviews produced more detailed questions for case interviews described in the next section (see also Appendix A: Client and consultant interview questions).

To investigate the research questions, each client and consultant was interviewed separately. As described in detail in Section 5, client organisations were engaged in manufacturing, governmental agency, engineering services, shipbuilding, U.S. managed healthcare, pharmaceuticals, and global development financing. Of eight consultants interviewed, seven were engaged in professional consulting practices, and one was a fulltime graduate school faculty member in the field of system dynamics.

Appendix C lists the primary research questions, a first level of coding for themes expressed in those questions and a keyword for grouping like expressions by the interviewees. Of particular importance, clients asked to recount Critical Learning Incidents from the system dynamics consultation.

Next, the cases are summarised to provide context for the results and discussion that follow in Sections 6 and 7.

In the cases reprised here, Critical Learning Incidents follow a constructivist path that begins with the client becoming aware of an experience that cannot be explained with the client's current mental model (Glasersfeld, 1983). Application of the system dynamics methodology generates a subjective re-presentation of experiences usually linked in ways that the client had not made previously. The client socialises the new understanding to test and gain acceptance of his new perspective. Although client learning traces out a familiar pattern over time, each client's approach to the engagement problem reflects the uniqueness of engagement issues, consulting techniques, intervention conditions, and the individuality of clients.

In 1993 senior management of a large pharmaceuticals company were concerned about the long-term profitability of the organisation. Because lead times for discovering and developing new drugs span more than ten years, senior managers wanted more information about the potential value of compounds in the research and development pipeline. One compound that was in the final phases of its pre-market trials was selected by management as a prototype case, and a consulting firm was engaged to develop a model to predict its value to the company. The consultants planned to adapt the prototype model to other compounds in the R&D pipeline. As the model formulation progressed, simulation produced an undesired forecast: the market for the drug under development was likely to be much smaller than originally planned. The focus of the engagement was changed to use the simulation model to help the line managers to revise strategic marketing plans.

The client interviewed was the senior product marketing manager for the drug in question, and reported that initially she was overwhelmed by the conceptualisation process in which the list of variables indicated the engagement would encompass estimating the number of people infected with HIV in the country, the drug approval process, and manufacturing and marketing endeavours.

The consultants reviewed the simulation model in detail with the client, her colleagues on the engagement team and then with a large number of scientists, physicians and marketing executives employed by the company. It became clear to all participants that the estimates of “available market” prepared by the marketing department were substantially greater than the estimates produced in the system dynamics model that the client and her colleagues had helped to define. This process of building confidence in the system dynamics model gradually produced a Critical Learning Incident for the client. The Pharma client reported that she became convinced the system dynamics-based forecasts were closer to what the organisation would experience on product launch and that the improved forecast was due to the system dynamics perspective.

In 1996, a new president was named at Development Bank who challenged the organisation's administrative officers to develop annual budgets to conform to the Bank's strategic vision. The consultant was engaged to work with the administrative officers to develop an algorithm to allocate annual budgets. In his first meeting with the administrative officers, the consultant noted that there was a strong disagreement within the administrative officers on how to allocate funds fairly. The client explained that she and her colleagues in the engagement group had come to think of budgets as ‘spending authorisations’ rather than resources allocated to achieve a set of results.

As meetings with the engagement team progressed, the consultant asked the engagement participants about the Bank – its purpose, mission, and goals. After listing engagement team complaints about the budgeting process, the consultant asked if an innovative spirit in the Bank's loan development officers had diminished over the same period. All agreed that the ‘old days’ were more exciting, even fun.

The consultant built several small system dynamics models that simulated reference mode behaviours,
                           1
                        
                        
                           1
                           The term ‘reference mode behaviour’ means time series data used to illustrate problematic or interesting results that are the initial focus of the engagement. Such modes of behaviour over time can include growth, decay, oscillation and steady state.
                         but only output of the models was shown to the participants. A dynamic hypothesis built slowly that suggested that the budgeting process controlled the Bank's behaviour, innovative projects declined as a consequence of tying current ‘spending authorisations’ to past successes, and the budget process had grown largely as a consequence of tying resource allocations to past projects. The client reported that she developed the insight under the pressure of the moment. As a consequence, the engagement participants developed a new work process that began with the senior managers of the Bank settling on a multi-year strategy that they refined annually. After the strategic goals were set, the administrative officers and senior managers would negotiate how resources would be allocated in accordance with their needs to meet strategic goals. To complete the change, the administrative officers adopted a new accounting and reporting system to tie intentions to action and results. In short, the engagement participants changed the way the Bank was run.

When asked to summarise the Critical Learning Incident, the client reported, “I always remember … how neat it was to have an Aha moment where something complex can be made so simple. It was [a trusted colleague] who liked metaphors, so he would always force us to try and find metaphors – and I started trying to do that afterward …. There are metaphors, and this [engagement] taught me that one of the ways to do it is a neat little graphic that says it all.”

A new medical care provider organisation proposed to render services to members of Managed Care's insurance plans with nurses replacing physicians for a limited number of conditions. The Managed Care chief medical officer arranged with the consultant to work with a management group he assembled to consider the policy change: “We set out a little approach … a plan to resolve the issues. We even tentatively agreed to build a [system dynamics] model and, if that model indicated that coverage would be inflationary and we all understood the model and its output, we would recommend against coverage.” The model development team included the chief medical officer, healthcare economists, provider network managers, underwriters and insurance product managers. The focus was on “PMPM” – the cost per member per month. The team's initial hypothesis was that treatment costs would be lower with a nurse providing treatment than with a physician providing treatment, which would lower PMPM.

As the team developed the model, they discovered that most of the services covered by the new provider sector were for minor ailments. Ailments that previously went untreated without further complication would now be treated. The results indicated that medical care costs would tend to increase because of the addition of the new provider, and as agreed, coverage was denied for member expenditures at the new vendor. Six months later, the policy was reversed.

The client reported two Critical Learning Incidents: “The Aha for the product organisation was that it was inflationary. Then the other Aha was, ‘But it's small!’ It was kind of fascinating. People weren't looking at the number, the absolute actual value of the number, and weighing it. So there were maybe two Ahas …. I was the one who put it on the table, but I had to step back out of my role of trying to convince everyone it was inflationary and then say, ‘Ok, so now let's see, step back.’ I convinced everyone of that, and now I've got to step back and say, ‘Ok, so what do we do now?’ And then, when I stepped out of that, a rational organisation could end up going there, so that was probably an Aha for me, because I was so into the battle around trying to get everyone to understand it was inflationary.”

Interviews with the Memory Devices client and consultant provided two cases. In the early 1990s, middle managers of Memory Devices assembled an informal group to discuss readings from Senge (1990), The Fifth Discipline. The client remembers, “I was intrigued by the systems thinking piece, but I was really bothered by the idea that, with some practice, anybody can draw these loops. How do you know the loops – the hypotheses – are real?”

The client viewed their first engagement as a test of the value of system dynamics methodology to the organisation. The calibrated forecasting model yielded an insight that surprised the client: a secondary market came to dominate the global market, an effect that all previous analysis had not detected.

During Memory Devices – 2, the engagement team met with the consultant and in their first meeting, three environmental affairs experts used the term pollution as a model variable. Each had a different time delay in mind for when the pollution would abate, and it was during this process step that each learned of the others’ thinking. When one expert participant used the term “pollution”, he was referring to contaminants that decayed in a relatively short period–say, ten to twenty years–whilst the others referred to contaminants that broke down in hundreds of years and even millennia. The client remembers that laying out the stock and flow diagram with explicit time delays provided a powerful insight for him and the other team members: the most obvious contaminants were biodegradable and less toxic than less obvious but more harmful contaminants.

The Critical Learning Incidents reported by the client in the two Memory Devices engagements occurred at very different engagement phases. In the first engagement, the client reports crucial learning from model confidence-building. In the second engagement, the client reports the most significant learning occurring during conceptualisation. The client recalled these two Critical Learning Incidents because the moment of insight was confirmed by further research and, in the client's words, the predictions “came true”.

Community Hospital serves a small semi-urban community. The hospital's Medical Director said, “We invited about 35 patients with congestive heart failure and diabetes to ‘redesign American health care’.” The Medical Director chose to apply system dynamics methodology in a group setting that included system dynamics consultants, patients, representatives of some medical expense paying organisations, physicians and concerned citizens.

The client convened members of the community for ‘solving a problem’ – how to reduce community-level expenditures for treating diabetes and related disorders. The consultants led the group in problem definition, model conceptualisation, policy confidence-building, and development of a plan for community action. The client attended most of the community group sessions and participated directly in several. As the model took shape and the consultants presented structure to the group, the client reified it: “The model actually shows that as soon as the clinical care specialist's role gets saturated, the costs are going up and healthcare quality starts going down. That's kind of interesting because I ended up ‘retrospective sense making’.” This Critical Learning Incident led to an even deeper acceptance of engagement insight: “Well, the thing that always sticks in your mind is the graphs. These are twenty-year graphs, and it seemed like magic at the time … [The consultants asked questions] that were cogent and that are answered in graphs …. That is what none of us could have possibly done. Their experience helped them to know which questions and graphs produced useful information, and the graphs are quite compelling to me.”

The client joined Ministry of Health to guide their role in medical education and was appointed to administer the consulting engagement. The consultant had constructed a first model, loosely parameterised and without reference mode data, to demonstrate what the final product might look like. He used the first model for development, and added the details to simulate the reference modes proposed by the group participants.

The client reported a Critical Learning Incident that stayed with her for years. The model-building process provided her with an orderly view of how medical schools fed physician capacity and staffed hospitals, clinics and private practices, and how physician retirements and outbound migration drained away capacity: “I think what was helpful to me in that exercise was kind of seeing on paper, or visualising stuff I knew fit together somehow. I appreciated the relationships and the causal relationships and ‘if you do this, that's going to happen’. You kind of knew it intuitively or from your experience, but it was all rolled into one big picture and you could really see how complex the issues are.”

Engineering & Technology Group experienced contract overruns, mix-ups, and delayed deliveries punctuated by acceptable achievements. The client wished to improve organisational performance and through reading became acquainted with system dynamics methodology as a problem-solving tool.

The client reported that the engagement had run for a year before he and the consultant were able to identify a system-based explanation for the program management problems, and the consultant then built a small model to illustrate the system dynamics. In the interview for this study, the client was asked, “Is there a moment in time that sticks in your mind when things came together?” He paused and answered, “Certainly when the consultant came out with the ‘aha’ and here's a model ….”

The problem on which the Shipyard client focused had confounded all members of the senior management group for years. When new construction activity peaked, “Shipyard couldn't make any money on commercial ships. We were tapped with trying to understand why we couldn't solve production costs and schedule problems on our commercial line in a very up market. That was the most immediate objective.”

In the months before the system dynamics consulting engagement, the client developed an elaborate wall chart that depicted how “lateness in the supply chain caused by late customer requirements, late engineering, and lateness in supply deliveries led to part shortages, which made it hard to put ships together … and caused high costs.” The chart supplied a dynamic hypothesis, and the client asked the consultants to build and calibrate a model to simulate system performance. As the engagement progressed, the engagement participants discovered that parts shortages did not “align with the operating losses” as had been assumed. The calibrated model strongly suggested that certain labour issues were at the root. When asked what he learned from the engagement, the client reported a Critical Learning Incident as a result of Confidence-building: “Data matters. Attention to calibration – detailed calibration – matters in sorting out causal relationships. It is a very, very fundamental belief that I have as a result of that engagement.”

Boules
                         de Pétanque fabricates steel balls (“boules”) used in the sport of pétanque. Annual sales had grown with the popularity of the game, but profits failed to keep pace. Moreover, margins were eroding and consumer complaints were growing. Senior management was considering a proposal to expand and modernise their customer call centre to help handle the increasing burden of responding to consumer complaints about late-arriving shipments, multiple deliveries to the same customer sites, mislabelled boules and shortages of the most popular boules. The client was given the task of developing a strategy to improve profitability and stanch the loss of customers.

In the first meeting with the problem-solving group, the consultant proposed a concept model – a small ‘sketch’ simulation of a dynamic problem that the group might be facing. The consultant recalled, “It was a particular moment where something happened … I still think about it … the moment of insight. It came very early on … . The project went on to do a lot of empirical work that tied a lot of things together … which probably contributed to their collective understanding in different ways – more routine ways … .”

The client agreed it was a Critical Learning Incident: “Once we arrived at the Aha, we wanted to get going on it. We didn't want to wait to meet once every quarter with the [division managers]. Frankly, we thought they'd slow us down.” The client continued, “I'm not sure this is the case, but I think that it's the first time … maybe I'd been secretly thinking it or suspecting it … but it was the first time where a group of thoughtful people even talked about the possibility that maybe we could [change the system].”

@&#RESULTS AND DISCUSSION@&#

The data collected from the interviews and reflections were considered with respect to the three research questions detailed in Section 1. A discussion of the key results is presented in this section in response to those three questions.

One step toward learning in constructivist theory is re-presentation, looking at a problem through a different lens (Glasersfeld, 1983). In these cases, the development of a dynamic hypothesis during the conceptualisation phase and the formulation and testing of the simulation model provide opportunities to present the engagement problem differently to how it had been framed previously.

The nature of the engagement problem suggests a solution path: determining the impact of system changes or forecasting how things will go. Simon (1989) names these two principal purposes for making a simulation model prescription and prediction (p. 6). The prescriptive model described by Simon is comparable to the concept of policy model in system dynamics.
                           2
                        
                        
                           2
                           For discussion of policy design, see Forrester (1975c), pp. 167 ff; Forrester (1994), pp. 58–59; and Sterman (2000a), p. 84 ff.
                         As used here, a policy model is a simulation constructed to produce a steady state in which stock inflows equal stock outflows or a smoothly changing state (positive or negative) so that effects of a policy change can be identified apart from noisy data. Simon's predictive model is comparable to the terms forecast or point prediction in system dynamics literature. In addition, the interview questions were designed to determine whether the engagement was designed to solve a problem or to learn to solve a problem.

The learning-oriented engagements developed only policy models, and the problem solving-oriented engagements developed both policy and predictive models (Table 3).

Respondents were also asked whether the initial problem statement presented to the consultants or developed early in the conceptualisation phase was the same problem the consultant and client reported to have resolved.

If, in the face of the same variables, the re-presented problem changes in the mind of the client, it is evidence of learning (Glasersfeld, 1989). In eight of ten cases, the initial engagement problem changed and, in half of those cases, the problem changed as the client and other members of the organisation were defining the problem and conceptualising causes and possible actions to be taken (Table 4).

There were two cases in which the problem remained unchanged in the mind of the client. In both Memory Devices – 1 and Ministry of Health, the client led the engagement team that selected and defined the problem and did not change the problem throughout the engagement.

For example, the Pharma case engagement problem changed when the epidemiology sector of the system dynamics model simulated a dramatically smaller market for the organisation's product than the market forecast by the organisation's market research group. It was then, whilst the engagement participants were building confidence in the predictions made with the system dynamics model, that the engagement focus changed from ‘how to best introduce a new medicine’ to ‘how to salvage their investment in the research compound’. As the Pharma client reported, “Initially, some of the details of that model were surprising to me. Just the [forecast] data that came out of it … just as [the consultant modeller] explained the model … ‘A + B = C’ and whatever C became and the number that it represented … . It became 10,000 instead of 2 million or whatever … it was because of X, Y, Z. And the results were surprising because they were so remarkably different.”

Three engagements were about learning to solve a problem with system dynamics methodology and seven engagements were focused on solving a problem. In those engagements designed to learn to solve a problem, the clients remarked that they were curious about the methodology, felt system dynamics methodology could proliferate in their organisations, and engaged the practitioner to help the subject client to learn how to apply system dynamics. In those engagements in which the practitioner was engaged to help solve a problem, methodology was an important factor in making the decision to engage the consultant.

As defined in Section 2, a Critical Learning Incident is the moment of surprise caused when one's mental model produces unexpected failure to understand an experience and a change in one's mental model produces the desired understanding. Interview questions (Appendix A) were designed to identify moments in the consulting engagement when the client experienced such an event.

In each case, subject clients participated in group problem-solving as part of the subject engagement; this research focuses on how one individual, the person interviewed, learned in the group environment. The reflections and interviews asked what means were used by the consultant to elicit, define, and frame issues and to provide an initial model design.

Preparation is defined as first client meetings and agreement on the consultative approach. In the case of system dynamics consulting engagements, it is the opportunity for the consultant to determine the level and quantity of introductory instruction for the engagement team based on their familiarity with systems thinking, mathematical modelling techniques and the like. The interviews disclosed that there were no Critical Learning Incidents experienced by clients during engagement preparation.

Consultants and clients agreed on the techniques used in the Conceptualisation phase, and Critical Learning Incidents occurred during the conceptualisation process shown in Table 5.
                        

Given the importance of ‘solving the right problem’, the system dynamics literature is rich with discussion of the challenge of forming a testable hypothesis. As Vennix, Andersen, Richardson, and Rohrbaugh (1994) describe, system dynamics consulting engagements include an early step in which the participants invest time to describe issues or problems of interest: “The terms ‘brainstorming’ or ‘divergent thinking’ have often been applied to some conceptual behaviour of this sort. In the system dynamics model-building process, this type of thinking is often most necessary in the problem definition or model conceptualisation phases where an individual or a group is attempting to determine what factors or variables to include or exclude from a system's boundary...,” (pp. 31–32).

Most frequently the clients developed lists of variables,
                              3
                           
                           
                              3
                              When a variable is selected to consider for simulation, the behavior of its time series are the reference mode or reference modes.
                            stock-and-flow diagrams, and causal loop diagrams or maps. Morecroft (1982), Richardson, Andersen, Rohrbaugh, and Steinhurst (1992), Wolstenholme (1994), Vennix (1996), and Andersen and Richardson (1997) describe these techniques in exquisite detail. Richardson (1986,
                           1995) discusses weaknesses in causal loop diagramming and other techniques for mapping system dynamics simulation models for the purpose of explication.

Four clients and consultants mentioned the use of a concept model, a simple simulation model during the conceptualisation phase for familiarising the group with rudimentary concepts employed in the development of a feedback simulation model. In one interview, a consultant used the specific term concept model in the context of defining a problem of interest with his client. Andersen and Richardson (1997) describe a concept model as “visually very simple”, “typically rather bad first cuts at system dynamics models”, and “mostly open loop and constructed to hide as much diagrammatic complexity as possible”. Their purpose is “to lead the group [of clients] in the direction of robust and appropriate formulations for the problem at hand,” (p. 117).

Conceptualisation is the phase of the engagement during which problems are identified for investigation. No pattern emerges to suggest that one conceptualisation technique provided more Critical Learning Incidents than another, with the exception that all engagements employed a form of variables list during the conceptualisation process. The absence of a Critical Learning
                            Incident does not imply that nothing was learnt by the client. To the contrary, the conceptualisation phase is reported in each case as a source of learning about the nature and complexity of the issues. The cases with Critical Learning Incidents in the conceptualisation phase are noteworthy because the client and consultant identified that phase as providing an important insight for solving the problem. The insight retained its significance throughout the engagement and was not invalidated by later experiences.

Clients and consultants in all cases agreed that the clients were not directly engaged in writing equations for the simulation models, and Table 6 indicates that model formulation did not yield a Critical Learning Incident for the clients. Clients assimilated new data and, in all but Case 2, observed the model construction process.

Although clients did not write equations, three clients reported reviewing equations written by the consultant. In half of all cases, the client asked for details to be added to the subject model. Adding detail to a model signals understanding and involvement in the sensemaking process. Nevertheless, none reported a Critical Learning Incident as a result of activities in model formulation.

Consultants reported reviewing simulation output with each client. Each client agreed, and each reported reviewing how the model was structured with the consultant. All clients reported reviewing graphs of time-series data and, with the exception of the client in Case 8, all made comparisons to reference mode behaviour. That is, simulated output was compared to the reference mode behaviours defined by the engagement teams, and clients built their confidence in the simulation model by understanding how the simulated output compared to the reference data.

Both policy and predictive model-based engagements used graphs and spreadsheets to communicate simulation results as remembered by clients. The confidence-building steps taken are compared with reported Critical Learning Incidents in Table 7.
                        

As used in Table 6, reference mode behaviour is the time series data that is the initial focus of the engagement, e.g. declining sales, rising costs, unstable inventories, or a growing shortage of key personnel. In system dynamics literature (e.g. Forrester & Senge, 1980; Ränders, 1980; Sterman, 2000b), statistical testing of simulation model results play a key role in developing confidence in the problem statement and simulation model used to test hypotheses. These statistical tests are run against the reference modes in time series data.

In all of the cases involving predictive models, Critical Learning Incidents occurred in testing, analysis and confidence-building, which may reflect that clients remained sceptical of system dynamics simulation results that differed from other methods until results could be tested and analysed. However, some clients relied less on statistical tests and more on socialising results of the engagement with colleagues. In Case 1, the client met with a colleague to discuss the implications of engagement findings for the patient group who would be most directly affected. The initial findings did not accord with the client's understanding of the epidemiology of the disease, and the colleague was able to provide experienced context. The consultant was unaware of those meetings.

In Case 2 the client reported meeting with a respected colleague who “wasn't the listening board type” to air engagement findings – especially those that she found confusing or that involved multiple constituencies. The client and colleague would discuss implications of findings for the Case 2 organisation and imagine “what if” scenarios beyond the boundaries of the engagement.

The challengers in Case 3 were “built in”; they were engagement participants who continually questioned assumptions in the model and conclusions drawn from the engagement. However, this ‘loyal opposition’ did not have the organisational authority to challenge the chief medical officer. It was more a function of prodding and questioning until they got to the heart of the matter and achieved the desired result.

In both Cases 4 and 5, the client sought out members of the operations research and economics staffs to support the engagement. The client was asked to develop economic analyses outside the system dynamics engagement that were presented to sceptical senior managers to build understanding of the engagement results and to maintain their commitment to support the engagement. One in-house economist in particular played an important role in the first case; he challenged several tentative conclusions. The client used these ‘sparring sessions’ to understand how to communicate engagement findings to the rest of the organisation.

The client in Case 6 relied on a sceptical assistant to challenge engagement results. His assistant observed flaws in the engagement model and asked the client to have the model amended by the consultants. This process of sensemaking helped to build the client's confidence in model output.

In Case 7 the client aired engagement-generated insights with her immediate superiors who supported her efforts to keep the project going to conclusion. The consultant was keenly aware that the client reviewed engagement developments with her organisational superiors to both make sense of those developments and to continue funding the project.

The client in Case 9 presented tentative engagement results to the organisation's econometrics staff. The insight taken by the client from the engagement contradicted conclusions drawn by the econometricians, and they reacted accordingly. The engagement methodology was attacked and the consultants defended their reasoning in open management meetings with data produced in the econometrics department.

In Case 10, the client met with a colleague, a “PhD in economics”, who was openly hostile to the system dynamics methodology. The client treated the colleague as “loyal opposition” and tried to meet his objections and arguments with reasoned responses. Again, the consultant was unaware of the meetings between client and colleagues not involved in the engagement.

In the confidence-building phase, the role of sceptics, challengers and sounding boards in preventing such a cutting-off should not be underestimated. Dissentient colleagues helped the clients to remain in touch with the main organisation and its values. Their sensemaking processes prevented clients from drifting away from their organisation values and pushed clients to translate engagement findings into terms the rest of the organisation could understand. In those cases, engagements tended to be judged as ‘successes’, and the clients’ regret, if any, was that they did not do more earlier in the engagement to report tentative insights.


                           Ränders (1980) defines implementation as including:

                              
                                 •
                                 identification of potential users;

translation of study insights to an accessible form; and,

diffusion of study insights (p. 119).

This definition of implementation was echoed in interviews when the clients reported using results of the subject engagement in ways that were not necessarily the goal of the engagement at the outset. Results flowed directly from the consulting engagement in all but Case 7 and Case 9, both of which employed predictive models.

The Case 7 Ministry of Health engagement objectives were met and implemented, but only after another, more effective system dynamics consulting engagement by a competing firm. The insights generated in Case 9 were diffused throughout the organisation but were not fully appreciated in time to avoid a corporate change in ownership. The Shipyard client noted: “Ultimately, the organisation did adopt the recommendation … after continuing arguments. But there was really a lag for us as a project team to be able to articulate this sufficiently clearly that the organisation could easily assimilate the message.”

In Case 3, which employed a policy model, implementation of the case results was reversed. It was during the implementation phase that the chief medical director had his second Critical Learning Incident: that proposed change was likely to be inflationary but the amount was likely to be immaterial. In this case, the client had so reified the simulation results that that he referred to “the absolute actual value of the number”, although the result was from a policy model initialised in a steady state.

When asked to recount moments of insight (“Aha!”) from the system dynamics consultation, each client identified one or more Critical Learning Incidents. Such episodic memories are generally reliable and durable (see, for example, Bartlett, 1932; Tulving, 1984
                        , 2001). However, as Cannon (1999), writing on making sense of a perceived failure, observes, “The continuing debate regarding the accuracy of recollections is not particularly relevant when one assumes a learning point of view, because inaccurate accounts of the past are typically accepted as accurate data by those remembering them” [emphasis supplied]. Stated another way, what one remembers is what one learned. Reflection – re-presenting what is remembered – is the activity that changes one's mental model (Glasersfeld, 1983). When those episodic memories become a part of one's mental model, they are accessible to recall as Critical Learning Incidents (Table 8
                        
                        ).

Five of the seven policy-based cases report Critical Learning Incidents in the Conceptualisation phase – earlier phases than those involving a predictive model. The three engagements employing predictive models show Critical Learning Incidents only in the Confidence-building phase. The two policy-based cases with later-phase Critical Learning Incidents can be distinguished from the five cases with early-phase Critical Learning Incidents. In Case 3, the client reported two Critical learning Incidents: one in an early phase and one in a later-phase. In Case 4, the engagement participants required that the policy model simulate reference modes with a tight fit to measured data. In essence, the policy model confidence-building in Case 4 was more like that encountered in a predictive model case. In Case 6, the client did not participate fully in engagement activities until the confidence-building phase.

All the client interviews revealed significant post-engagement reflection. Each client attributed significance to some incident as being a touchstone or seminal occasion. However, the circumstances surrounding reported Critical Learning Incidents reflected daily events in the client's working world: a business meeting, review of a report, or even diagramming a complex problem.

Thus far, the focus has been on Critical Learning Incidents and when those occurred in the course of a system dynamics consulting engagement. In the next section, the focus shifts to the content – what clients reported as having changed in their mental models.

In this research, learning is a process for constructing one's mental model. Critical Learning Incidents build up from experience and reflection, and the acquisition of information or data with reflection and fitting of the information or data to one's mental model completes the learning experience. This section reports what changed in clients’ mental models that contributed to Critical Learning Incidents and allowed the clients to make sense of a perturbing experience.


                     Glasersfeld (1995) describes learning as a construction process that begins with one becoming aware of some experience that does not fit one's mental model. The non-fitting experience, a perturbation, can cause one to reflect on the experience and to change one's mental model to accommodate the perturbation (p. 68). Glasersfeld goes on to say that one's thinking about similar experiences is so changed that those similar experiences only make sense when interpreted in the changed mental model (pp. 67–69). This section reports what changed in clients’ mental models that allowed them to make sense of a perturbing experience.


                     Richardson, Vennix, Andersen, and Rohrbaugh (1994), Senge (1990), Sterman (1989), and Sterman and Sweeney (2000) catalogue numerous shortcomings in mental models where the subject attempts to resolve a dynamically complex issue without the benefit of system dynamics methodology. As Sterman (1989) notes, a feedback loop exists when a change in a variable eventually comes back to cause further change in that variable, with the emphasis on the word eventually. When a client reports learning of a delay between an action and the intended result, it is labelled feedback with time delays.

From his earliest research, Forrester (1975b) noted that, without knowledge of complex systems, people will not understand the full systemic implications of decisions. When clients report discovering unplanned side effects arising from action within the system, the discoveries are labelled unintended consequences (see, for example, Kleinmuntz, 1993; Moxnes, 1998; Sterman, 1996).


                     Senge (1990) popularised the term “fundamental shift of mind” to describe how individuals change paradigms that structure their mental models. Lichtenstein (2000) and Chiva, Grandío, and Alegre (2010) report learning that includes a broad rethinking of problematic behaviours, which they label generative learning. When newly learned approach is applied by a client to understanding events beyond the scope of the system dynamics consulting engagement, the change is labelled a change in worldview.


                     Table 9 summarises these three types of mental model change: (a) feedback time delays, (b) unintended consequences, and (c) worldview.

Clients in six of the engagements noted that learning about feedback with time delays changed their mental models. They reported in the interview that the concept of a feedback loop had not influenced their thinking before the consulting engagement and that it became important to their understanding of the engagement problem. When they learned how time delays in a feedback loop affect the loops performance, the explanation helped them to understand system performance and how system structure contributed to the engagement problem. Three were clients in policy model engagements (Cases 2, 4 and 10), and three were in predictive model engagements (Cases 1, 7 and 9).

Nine of ten clients reported learning how actions or decisions can cause unintended consequences and that unintended consequences can be identified in a system dynamics simulation model. The tenth client, Case 3 Managed Care, was already aware of such unintended consequences arising from the engagement problem and reported that it was precisely because of these that he ordered the engagement.

Nine of ten clients reported a change in their worldview as a result of the consulting engagement. The tenth client, Case 3 Managed Care, reported that he took a systemic view of the engagement problem, and the consultant agreed with his report. However, the results of a simulation model convinced him that he had not understood the strength of the proposed change on the system.

Last, there are suggestions of transformative-like learning – Senge's “fundamental shift of mind” – throughout client interviews. However, care was taken to avoid analysing the motivation of individual client learners in system dynamics consulting engagements. The organisational goal of the interventions discussed here is to solve a problem or learn to solve a problem, not transform the thinking of one or a handful of managers. Within those limitations, it was noted that two clients reported that they pursued additional learning in system dynamics or systems thinking as a consequence of their consulting engagement experiences.

The Pharma client said in her interview, “[After the engagement] I did read a book on system dynamics because I was very intrigued … . So then it made sense to me … that was the most intriguing part of the Aha experience, because I try to apply it … to validate something as an intellectual premise. In my mind I look to the outside world to see if I can apply it and if it works … in my mind.”

When asked what she took from the engagement experience, the Development Bank client disclosed, “Something I learned later... I thought that we made good contribution, much more than you might expect insiders who were trying to reform themselves to make.” The client went on to say that, since retiring from the Bank, she enrolled in a university course on systems thinking which she believed would help in her roles a member of not-for-profit agency boards.

This research began with three questions to explore reports of ten consulting interventions by system dynamics consultants and their clients for Critical Learning Incidents: a moment of surprise caused after one's mental model produces unexpected failure and a change in one's mental model produces the desired result. Reported Critical Learning Incidents were noted by engagement phase and intervention activities to answer three research questions.

In this study, the engagement purpose is described as solving a problem or learning to solve a problem. In three cases, the engagement purpose was learning to solve a problem, and the consultant chose to use a policy (prescriptive) model. It can be inferred that the policy model form was chosen because it can be used easily to highlight the effect of changes to system structure or parameter values.

In the engagements designed to solve a problem, the model choice varied. Four used policy models and three used predictive models. In all four of the engagements designed to solve a problem that employed policy models, the engagement issue was one of organisational policy. In the three cases designed to solve a problem that employed predictive models, the engagement issue centred on a crucial external variable over which the organisation had no direct control and thus wished to determine its impact on the organisation.

The nature of the problem addressed in the engagement was characterised as predictive or prescriptive. In those engagements focusing on predictions, Critical Learning Incidents came late in the engagement when the client and consultant were building confidence in the simulation model results. When the predictive system dynamics model produced results deemed more accurate than other modelling efforts, the clients reified the system dynamics model. In policy-oriented, prescriptive engagements, Critical Learning Incidents clustered in the Conceptualisation phase of the engagement. That is, the client more quickly accepted a different approach to explaining problematic system behaviour.

The consulting method applied at each phase of the engagement affected Critical Learning Incidents. In policy-oriented engagements, the use of concept models to illustrate how problematic behaviours arise in a system produced strong client responses. System mapping of variables considered important to the clients produced Critical Learning Incidents leading to a change in the engagement problem. On the other hand, none of the clients interviewed engaged directly in simulation model formulation and reported no Critical Learning Incidents. Confidence-building – comparing simulation model results to observed system results – produced Critical Learning Incidents in predictive engagements and were affirming in policy-oriented engagements. As noted in the discussion, confidence in the clients’ changed mental model grew from their socialising results.

Confronted with unexplained or inadequately explained problematic system behaviours, application of system dynamics methodology led to improved understanding after the clients’ mental models changed. In these cases, system dynamics methodology provided a conceptual framework and means for making sense of experience.

The observations in this study hinge on the validity of data collected from a small self-selected group of clients and consultants, and the results of case studies may not be typical of all system dynamics consulting engagements. In particular, the cases considered clients who were selected by consultants, and there may be bias in the selections, e.g. respondents most interested in learning and reflection. A sample drawn from a wider range of clients from more than one culture would help to confirm or disconfirm these observations. Because the analyses here relied on the memories of clients and their consultants, future study may include direct observation or action research.

This work focused on Critical Learning Incidents that occurred for clients in interventions that used system dynamics methodology. The generalizability of the results beyond this situation is unknown but would be an interesting area for further study. Although interviews focused on single clients, these clients were part of organisational teams created for the consulting engagement, and future research considering learning gained by single members through interactions and influences within the group would be of wide interest.

The generalizability of the results to other model-based consulting approaches would be an interesting area for investigation, e.g. whether similar results are found with other simulation approaches such as discrete-event or agent based simulation, particularly due to the differences in approaches by system dynamics and discrete-event simulation modellers (see, for example, Tako & Robinson, 2009, 2010). It would therefore be interesting to investigate whether different methodologies and consultant approaches have an impact on clients’ Critical Learning Incidents.

In addition, this study viewed learning through a constructivist lens because of that theory's emphasis on individualistic learning and its use of changes in mental models to investigate learning. Application of competing learning theories has the potential to add a different perspective. While there is evidence of strong changes in client mental models suggestive of transformative learning, the question of whether system dynamics consulting engagements trigger such changes is also in need of further research.

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.ejor.2015.09.048.


                     
                        
                           Image, application 1
                           
                        
                     
                     
                        
                           Image, application 2
                           
                        
                     
                     
                        
                           Image, application 3
                           
                        
                     
                  

@&#REFERENCES@&#


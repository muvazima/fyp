@&#MAIN-TITLE@&#Product contamination in a multi-stage food supply chain

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Presents a simplified supply chain model to study a food contamination event.


                        
                        
                           
                           Analyzes the impact of sampling strategies, product, and supply chain attributes.


                        
                        
                           
                           Retailer sampling detects contamination later than reports of food borne illness.


                        
                        
                           
                           Few(many) suppliers and long(short) lead times create less(more) dispersion.


                        
                        
                           
                           Few(many) suppliers and long(short) lead times shift contamination up(downstream).


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Supply chain management

Contamination

Food supply network

@&#ABSTRACT@&#


               
               
                  Food product contamination has potentially devastating effects on companies and supply chains. However, the impact of contamination has still not been thoroughly studied from a supply chain planning perspective. This paper models a contamination event in a generic food supply chain consisting of suppliers, processing centers, and retailers. Contamination is detected through either company or government agency sampling tests or through reports of a food borne illness. In this research, we analyze the impact of origin and choice of sampling strategies, and product and supply chain attributes on a contamination event. We also simulate a real-world tomato contamination case to gain further insights.
               
            

@&#INTRODUCTION@&#

The past decade has seen an increase in the size, severity, and number of food products recalled in the United States (Dyckman and Lansburgh, 2004). Additionally, in 2003 most recall cases were “Class I” recalls, i.e., for foods that pose the greatest risk of illness or death (Ollinger and Ballenger, 2003). The Center for Disease Control and Prevention (CDC) estimates that about 76 million people contract a food borne illness and about 5000 die annually in the United States. The United States Department of Agriculture’s (USDA) Economic Research Service (ERS) estimates the annual economic cost of five major food borne illnesses at $6.9 billion (Golan et al., 2004b).

The risk of life-threatening symptoms from food borne illnesses is higher for older adults, young children, pregnant women, and immune compromised individuals. An increasing proportion of the population will be at risk due to the ongoing shifts in U.S. demographics. Additionally, more consumers are eating raw foods or foods with minimal processing, thus increasing their risk of contracting food borne illnesses, as these foods are often associated with contamination. For example, the average consumption of spinach, one the foods most likely to be associated with a food borne illness, has risen by 180 percent from 1992 to 2005 (Shames, 2007).

Furthermore, cost-reduction pressures, has resulted in relocation of production to countries with cheaper labor (Buckley, 2007; Roth, Tsay, Pullman, and Gray, 2008). The Food and Drug Administration (FDA) estimates that 80 percent of seafood, 50 percent of fresh fruits and 20 percent of fresh vegetables consumed in the U.S. are imported (Roth et al., 2008). These products are vulnerable to contamination risks as there is no emphasis on product safety (Lyles, Flynn, and Frohlich, 2008).

There have been several recent severe food borne illness outbreaks and recalls, including the 2006 E. coli outbreak from spinach and the 2008 Salmonella outbreak from tomatoes (FDA, 2008). Food contamination is generally detected through sampling or testing conducted by companies and regulatory agencies or reports of food borne illness. Detection is followed by a public announcement of the recall accompanied by efforts to isolate the origin of contamination and trace and retrieve the contaminated product in the supply chain (FDA, 2014; Piramuthu, Farahani, and Grunow, 2013).

Contamination and subsequent recall can have devastating effects on companies and supply chains. Frequently, an entire supply chain network shuts down until the source of contamination is identified. For example, a meat recall can affect the entire meat industry, including downstream entities such as retailers, and upstream suppliers such as farms (Golan et al., 2004a). An additional side effect of this is an unnecessary disruption of parts of the supply chain network unaffected by contamination (Piramuthu et al., 2013).

These recalls have created a growing acceptance by companies and regulators that recalls are an inevitable part of conducting business. There has, however, been an increased operational focus on the factors impacting: (1) the time to detect a contaminated product, and (2) the effectiveness and efficiency of a recall process (Hora, Bapuji, and Roth, 2011; Johnson-Hall, 2012; Roth et al., 2008).

The time to detection of contamination and the amount of contaminated stock have a major influence on the effectiveness and efficiency of the recall, as well as the cost of contamination (Hora et al., 2011; Lippincott, 2008). Regulatory agencies consider the successful tracing and retrieval of the contaminated product along the supply chain post-detection as a key element of effective and efficient recall processes (National Response Framework Doctrine, 2008).

In this paper, we develop a simplified but insightful model of food product contamination in a supply chain to assist decision makers in planning their operations while retaining a high level of food safety. The analytical model’s basic outputs are the expected time to detection of contamination and the expected amount of contaminated stock existing in the channel at the time of detection.

Our analysis of this model identifies how different sampling strategies and product attributes impact a supply chain’s ability to shorten the time to detection. Furthermore, for a particular contamination case, our analysis determines how supply chain attributes such as demand, lead times, and the number of processing centers impact the quantity and geographic dispersion of a contaminated product. In particular, we hope that our model can help in:

                        
                           (1)
                           analyzing the impact of different product attributes and modes of detection on the time it takes to detect a contamination,

comparing the impact of different sampling strategies that can preempt a food borne illness report, and

studying the effect of various supply chain attributes on the quantity, spread, and dispersion of the contaminated product along the supply chain post-detection.

The remainder of this paper is organized as follows: In Section 2, we give an overview of the related literature and the position of our paper relative to it. In Section 3, we present our analytical model, and in Section 4, we describe our research setting and implement a simulation study. In Section 5, we report the results of our work. Finally, Section 6 concludes the paper with a discussion of insights and future research directions.

Research into food contamination has dealt with a range of issues from trace back/trace forward models to investigations of the effectiveness of recall operations and predictive models for bio-terror attacks, and the implementation of traceability systems. Here, we provide a broad overview of related research and then discuss the position of our work relative to the existing literature.

There are several studies that attempt to understand food contamination events by using an “event study” approach to analyze consumer perceptions, stock market reactions, and loss of brand equity post-recall. For example, De Jonge, Van Trijp, Renes, and Frewer (2007) attempt to understand the determinants influencing consumer perceptions of food safety incidents. Marsh, Schroeder, and Minert (2004) empirically test the shift in consumption patterns and changes in consumer demands after a food contamination event (Marsh et al., 2004).


                     Thomsen, Shiptsova, and Hamm (2006) study recalled frankfurter brands to conclude that brand equity provides a sign to the customers about food safety and can insulate firms from industry-wide recall problems (Thomsen et al., 2006). Other studies analyze the impact of a food contamination event on shareholders, stock markets, and company valuations (Salin, 1998).

Various systems and standards have also been developed to identify, manage, and reduce food safety risks. The best-known are the hazard analysis critical control point (HACCP) system and the ISO 22000 standard (ISO 2005) (Akkerman, Farahani, and Grunow, 2010). Some papers discuss specific software based procedures to implement these safety systems (Bertolini, Rizzi, and Bevilacqua, 2007; Tuominen, Hielm, Aarnisalo, Raaska, and Maijala, 2003), and still others take a public health perspective, for example Cruz, Katz, and Suarez (2001) evaluate the usefulness of restaurant inspections in predicting food borne illness outbreaks in Miami-Dade county (Cruz et al., 2001).

There has also been a growing interest in the incentives associated with traceability systems such as RFID-based systems to track and trace products in a supply chain in case of contamination (Aung and Chang, 2014a; 2014b; Piramuthu et al., 2013). Pouliot and Sumner (2008) show how exogenous increases in food traceability incentivize farms and marketing firms to supply safer food by increasing liability costs.

Besides food, research into product safety and recalls using these methodologies has also been conducted for products such as automotives, drugs, and consumer products (Barber and Darrough, 1996; Chen, Ganesan, and Liu, 2009; Davidson and Worrell, 1992; Hora et al., 2011; Jarrell and Peltzman, 1985).

However, research on product contamination, recall, and food safety, from a supply chain planning and operations research perspective, has been somewhat limited. In a recent survey, Akkerman et al. (2010) review quantitative operations management approaches to food safety and stress the need for more research in this area. Piramuthu et al. (2013) state that in spite of recent work in this area, studies focusing on strategic, tactical, and operational planning to improve food safety are still limited and that it is imperative to address this gap (Akkerman et al., 2010; Piramuthu et al., 2013).

Thus far, research on product contamination in the supply chain context has broadly taken two approaches. The first uses mathematical modeling and simulation for a specific case of food contamination. For example, Weiser et al. (2013) use network graphs to trace back E. coli outbreak in Germany along the supply chain. van der Gaag et al. (2004b) and van der Gaag, Saatkamp, Backus, van Beek, and Huirne (2004a) use a state simulation model to study the spread of Salmonella in a Dutch Pork supply chain and evaluate the cost effectiveness of different intervention strategies. Wein and Liu (2005) mathematically model a supply chain associated with a single cow milk processing facility and analyze the impact of a deliberate release of botulinum toxin in milk (Wein and Liu, 2005). Tromp, Franz, Rijgersberg, Van Asselt, and Van Der Fels-Klerx (2010) use historic data to model the transmission of Salmonella through a broiler supply chain.

A second approach empirically studies the effectiveness of a recall process and the key supply chain factors associated with it through extensive data analysis and statistical regression techniques (Hora et al., 2011). For example, Johnson-Hall (2012) studies the influence of supply chain factors on food recalls conducted by the FDA through an econometric analysis of recall data.

The approach we follow in our work of analytical modeling and simulation is in line with the first set of studies. However, we aim to present an overarching, simplified supply chain model to study a food contamination event. Unlike previous studies, we attempt to move beyond the single case study approach of modeling a particular event, and instead build a generalizable supply chain model. We then model real cases of food contamination to analyze the impact of sampling strategies, product, and supply chain attributes on the scope of the event, prevent customer illness, and understand the quantity and geographic dispersion of a contaminated product.

Our retail food supply chain model closely follows similar supply chain networks studied in the food recall literature. We consider a generic, multi-stage supply chain (Fig. 1
                        ) consisting of a supplier, processing center, retailers, and customers. As illustrated, the general structure flows from the supplier toward the end customer such that raw material from the supplier is processed at the processing center to generate the final product which is then sold at the retailer level (Johnson-Hall, 2012; Kumar and Budin, 2006; Piramuthu et al., 2013).

For example, the supplier could be a spinach farm, the processing center could clean, rinse, dry, batch, and package the spinach into products which are then transported to the retailer, who sells these to customers (California Foundation for Agriculture in the Classroom, 2011; Golan et al., 2004a). While upstream supply chain entities can directly reach the customer (e.g., a farm can reach the customer through a farmer’s market), direct sales to customers are small, accounting for only 2 percent of final fresh food consumption in the United States, while 86 percent of the food products produced in the United States are processed (Golan et al., 2004a; Johnson-Hall, 2012).

The model focuses on the retail supply chain as restaurant operations are inherently complex and diverse, and the majority of consumption for the products we consider, such as tomatoes, is at home (USDA, 2012).

In the remainder of Section 3, we describe the different supply chain entities included in our model.

The customer purchases the final product from the retailer and may contract a food borne illness if it is contaminated. The time at which a customer purchases a product will be determined by the customer demand and the retailer’s service level. We assume that the customer consumes the product before the end of its shelf life and that the time of consumption is uniformly distributed between the time of purchase and the end of the product’s shelf life, though this will depend on the product type, as fresh products will be consumed sooner than frozen products, which have a longer shelf life. H denotes the product shelf life and starts from the time the finished product enters the finished goods inventory (FGI) at the processing center, following industry conventions (Kilcast and Subramaniam, 2000).

The food borne illness will manifest itself after a specific incubation time, which is the interval between ingestion of a contaminated food to cause illness and the appearance of the initial symptoms (FDA, 2014). Further, we assume that there is an exogenous probability, p, that a customer who consumes the contaminated product shows symptoms, which in reality depend on the product type and customer demographics, among other factors.

We also assume no time lag between a customer showing symptoms and reporting the illness. While there is typically a delay, and not all cases are reported, we ignore this as it is difficult to quantify. We also suppose that every illness due to contamination is reported.

We consider a supply chain with a total number of r retailers. We assume that customer demand per period at each is independent, stationary over time, and can be expressed as a normal random variable Di
                        , with known mean μi
                         and standard deviation σ[Di
                        ] with i = 1, …, r. We assume the coefficient of the variation of demand such that there is a negligible probability of non-positive demand. The total demand over multiple retailers is 
                           
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 r
                              
                              
                                 D
                                 i
                              
                           
                        .

An order-up to policy is in place at each retailer, meaning that the retailer sets a target inventory level, and every review period (e.g., daily) the retailer orders product to replenish stock according to the target level. We assume that the probability of encountering no demand during the review period is zero, so the retailer places an order every review period. The lead-time for receiving a shipment from the processing center is li
                        . The lead-time demand 
                           
                              D
                              
                                 L
                                 
                                    T
                                    i
                                 
                              
                           
                         also follows a normal distribution with mean 
                           
                              
                                 μ
                                 
                                    D
                                    
                                       L
                                       
                                          T
                                          i
                                       
                                    
                                 
                              
                              ,
                           
                         and standard deviation 
                           
                              σ
                              
                                 [
                                 
                                    D
                                    
                                       L
                                       
                                          T
                                          i
                                       
                                    
                                 
                                 ]
                              
                           
                        . Let the target service level for the retailer be 
                           
                              
                                 β
                                 
                                    R
                                    i
                                 
                              
                              ,
                           
                         then the retailer’s order-up to level 
                           
                              
                                 R
                                 
                                    R
                                    i
                                 
                              
                              ,
                           
                         is given by 
                           
                              F
                              
                                 (
                                 
                                    R
                                    
                                       R
                                       i
                                    
                                 
                                 )
                              
                              =
                              
                                 β
                                 
                                    R
                                    i
                                 
                              
                              ,
                           
                         where F represents the normal cumulative density function (CDF) of the lead time demand 
                           
                              D
                              
                                 L
                                 
                                    T
                                    i
                                 
                              
                           
                        .

The processing center satisfies the combined demand from all retailers, 
                           
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 r
                              
                              
                                 D
                                 i
                              
                           
                        . For mathematical tractability of the model, we assume that the processing center will see a demand stream equal to the aggregate retailer demand streams, and every period an order will be shipped to each retailer. Raw material arrives from the supplier in batches of fixed size k and enters the processing facility’s queue. During processing, the batches are broken apart and the individual items are served by a single server, and each item in the raw material batches is processed into m number of final products and reaches the FGI. For example, cartons of fruits may be processed to produce m packages of fruit.

The inter-arrival time of batches is denoted by the random variable AB
                        . The service time of an individual item in the batch is denoted by the random variable S, AB
                        , and S are assumed to be known characteristics of the queue with known distributions. This batch processing system is similar to that in Curry and Deuermeyer (2002). We model this system by formulating a G/G/1 queue (Allen, 1978; Buzacott and Shanthikumar, 1993; Curry and Deuermeyer, 2002), as shown in Fig. 2
                        .

From our macro view of the basic supply chain, it follows that this single server does not represent a particular machine, but rather the abstraction of all processing steps. The appropriate FGI level at the processing center takes into account demand variability and the variability of FGI replenishment through the queuing process. We derive the amount of safety stock at the processing center in Lemmas 1 and 2, available in the Supplementary material online.

We assume that the supplier has ample raw material and instantaneous production. We do not model separate inventory holding facilities because the supplier usually has few, if any, production steps. Hence, the supplier operates a push system, sending batches of raw material directly to the processing center. The processing center acts as a pull system, receiving batches based on the expected rate of demand. According to the production center’s needs, the supplier ships a batch of size k every 
                           
                              
                                 k
                                 m
                              
                              
                                 E
                                 
                                    [
                                    D
                                    ]
                                 
                              
                           
                         periods, where 
                           
                              D
                              =
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    r
                                 
                                 
                                    D
                                    i
                                 
                              
                           
                        . The lead time from the supplier to the processing center is denoted by L.

In our model, we consider an event where contamination in the supply chain has already led to a food borne illness. The model explicitly considers the stage at which the contamination originates in supply chain.

Contaminated products are detected and subsequently recalled in one of the following ways (Dyckman and Lansburgh, 2004; Teratanavat, Salin, and Hooker, 2005):

                           
                              (1)
                              Through sampling conducted along the supply chain (e.g. at the supplier, processing center, or retailer) by companies and regulatory agencies,

Through reports of food borne illness.

According to Teratanavat et al. (2005), 44.6 percent of contamination is discovered through sampling by the Food Safety and Inspection Services (FSIS), and 23.7 percent is discovered by companies in the supply chain; 17 percent of food borne illness incidents are discovered by regulatory agencies, and 14.7 percent are discovered through customer reports. For simplicity, we assume that sampling happens in zero time, is non-destructive, does not affect any other processes, and that it reliably detects contamination if it is present. The term “detection” here does not mean detection of the source, but detection of contamination in the product.

We are interested in the following performance metrics for contamination originating at a supply chain node i and detected through mode j;

                           
                              •
                              
                                 
                                    
                                       
                                          τ
                                          
                                             j
                                          
                                          i
                                       
                                       ,
                                    
                                  time to detection of a contamination event


                                 
                                    
                                       
                                          Ω
                                          
                                             j
                                          
                                          i
                                       
                                       ,
                                    
                                  the quantity of contaminated stock.

Contamination may be eliminated through a quality control process, such as cleaning the equipment or changing the water supply. However, we assume that contamination continues until it is detected, implying that after a contamination is introduced in a particular location, all subsequent products from that location are also contaminated. This allows us to quantify the complete impact of contamination until its detection in the absence of requisite quality control.

We now model the timeline from the start of the contamination incident to detection and food recall. Further, for different origins and modes of detection, we evaluate the time to detection and the quantity of contaminated stock (refer to Propositions 3 and 4 in the Supplementary Material).

At start time t = 0, the first batch of contaminated raw material is shipped from the supplier to the processing center, arriving after the constant shipping lead time L. The item’s cycle time at the processing center CT
                              P
                            is the sum of the queue time, individual service time, and the process time delay, which occurs because each item within a batch waits for the item(s) ahead to be processed (Fig. 3
                           ).

When the contamination originates at the processing center, the first batch is processed at time t = 0 after the contamination is introduced. The expected service time for each product is E[S]. For simplicity, we assume that the contamination lasts for the entire service time, a reasonable assumption given that the service time is much lower than the other time periods in our model, such as the lead time, li
                           , and incubation time TIn
                            (Fig. 4
                           ).

The sampling strategy is a policy decision defined by the frequency a sample is tested, N, which is defined as the number of batches between successive samples. Thus, a high value of N corresponds to infrequent sampling, and a low value corresponds to frequent sampling. Sampling may be done at any of the nodes in the supply chain. Sampling strategies are derived from industry standards such as ISO 22000. However, we do not consider specific food safety management systems to maintain a general model that can be adapted to different product types and food borne illnesses.

We assume that the supplier samples a single item belonging to one batch every N batches; the processing center samples one in every Nkm finished items; the retailer samples one in every Nk items prior to reaching the shelf.

As a consequence of this sampling strategy, the sampling times at the supplier are uniformly distributed between the start of the contamination until the Nth contaminated batch is assembled and shipped. Similarly, the sampling times at the processing center are uniformly distributed between the time the first contaminated batch arrives until the (Nkm)th product leaves the FGI when the contamination originates at the supplier. When the contamination originates at the processing center, the sampling times are uniformly distributed between the time the first contaminated product enters the FGI until the (Nkm)th product leaves the FGI. At any of r retailers, sampling is uniformly distributed between the time the first contaminated product arrives until the (Nkm)th product is sold. Proposition 3 in the Supplementary material derives the expected time to detection and the expected contaminated stock to detect through sampling at the supplier, processing center, and retailer.

A recall is publicly announced by regulatory agencies when food borne illness incidents are reported and linked to a certain food product. Hence, we assume that there exists a certain threshold, T, T ≥ 1, which represents the number of reported illnesses when the regulatory agency issues a public warning. This threshold may vary by type of contamination event. Proposition 4 in the Supplementary material derives the expected time to detection and the expected contaminated stock when contamination is detected through food borne illnesses.

This section uses the model described in Section 3 to model a recent high profile case of tomato contamination, using its inventory calculations to conduct a simulation study. The aim is to validate our work by comparing the results from the simulation study with the results generated from the analytical model, in particular the expected times to detection and the expected contaminated stocks when contamination is detected through either sampling or reports of food borne illness (refer to Propositions 3 and 4 in the Supplementary material). Simulation can be a useful technique for tracking and estimating the contaminated stock in more complex supply chains with multiple processing centers, (see Section 5.3, for example) which are not amenable to closed-form analytic solutions. Fig. 5
                      illustrates the model’s logic.

The tomato contamination case occurred in North America in April 2008, in which 1442 persons infected with Salmonella were identified in 43 states. At least 286 of those infected were hospitalized, and there were two associated deaths (Cuite et al., 2009).

Investigations revealed tomatoes to be the source of contamination, the contamination was traced back to a processing center in the U.S. and the processing center received produce grown in Mexico. The outbreak strain was isolated from samples collected at the U.S. processing center, a patient’s home, and from samples of produce and water collected on the farm in Mexico (CDC, 2009). Wal-Mart, Kroger, and Winn-Dixie were among the supermarket chains impacted by this recall (Johnson, 2008). Flanders (2008) estimated the economic impact of this outbreak on the state of Georgia at $13.9 million.

We generate data and results based on the tomato recall case. Input data are taken from various public sources and databases, including the USDA’s ERS, U.S. Bureau of Labor Statistics, and FDA, among others.


                        Table 1
                         lists the exogenous input parameters for the model, as well as their estimated base values, which represent our best estimate of reasonable values based on public sources. We later (see Section 4.3) perform a sensitivity analysis on these parameters to determine their relative impact on the model’s results. The demand is estimated based on USDA-provided annual production and supply data for commodities, which has been used as a proxy for demand estimation in earlier research (see, for example, Blisard, Blayney, Chandran, and Allshouse, 1999; Outlaw, Knutson, and Hamm, 1994). These data include the residual of a commodity’s total annual available supply after subtracting measurable uses, such as farm inputs (feed and seed) and exports. The USDA also states that 70 percent of tomatoes are consumed at home, and 30 percent at commercial establishments, so we modify the demand estimate to align with our retail supply chain model (USDA, 2012).

We consider the total supply data for tomatoes between 1992 and 2008, and subtract 30 percent (USDA, 2014). We then average this approximate retail supply over the total number of retailers. The total number of food retailers, consisting of supermarkets, grocery stores, and fruit and vegetable markets is estimated from census reports (US Census Bureau). As is common practice, we model demand by fitting the adjusted multi-year data (after controlling for restaurant use of tomatoes) to a normal distribution (Nauta, Litman, Barker, and Carlin, 2003; Phillips, Hoenigman, Higbee, and Reed, 2013) using statistical fitting software to estimate the distribution parameters, check for goodness of fit (Kolmogorov–Smirnov and Chi-Squared tests), finding acceptable results.

Retailer service levels are estimated using data on retail stock outs from the Commodity and Services Survey and U.S. Bureau of Labor Statistics. Matsa (2011) reports that the stock out rate for tomatoes is approximately 3.6 percent. We therefore set the base value for retailer service level at 96 percent.

Food science studies indicate that tomatoes held in a climate-controlled environment have a shelf life ranging from 2 to 3 weeks (Vieira, 1999). We take an average to estimate the shelf life of tomatoes at 17.5 days.


                        Table 2
                         lists the average incubation time ranges for common food borne illnesses, T
                        In, based on medical research data (Strohbehn and Beattie, 2010). The base value estimate for expected incubation time is the midpoint of the range for Salmonellosis.

The FDA’s first public announcement of recall was in early June 2008, by which time approximately 104 people reported an illness (FDA, 2008). Therefore, we set the base value of T to 100. Illnesses were recorded prior to the announcement, but the FDA announcement was the first public notification of contamination linked to a specific product.

We approximate lead times based on sustainability studies that estimate the average distance that produce in the U.S. travels from farm to market, which is mainly transported along the supply chain in trucks on roadways. Tomatoes travel an average of about 1570 miles (Pirog and Benjamin, 2003). We therefore assume that the total transportation lead time (including both transportation from supplier to processing center, and from processing center to retailer) in our study is approximately 29 hours (covering 1570 miles at an average speed of 55 miles per hour). Since produce typically travels a greater distance between the supplier and processing center than between the processing center to the retailer, we divide the 29-hour transportation lead time by a 3:2 ratio. Therefore, L = 17.4 hours and l = 11.6 hours.

Data from a produce supplier in California indicate that tomatoes are shipped in batches of 20 cases (Earthbound Farm Organic Foodservice Products, 2014) with each case of tomatoes processed into 1 layer of tomatoes weighing 1 pound.

Food processing manuals issued by the USDA estimate the time it takes to process tomatoes (such as packing them in their juice) using various processing equipment ranges from 10 to 40 minutes (USDA, 2009). We therefore assume an average processing time of 25 minutes. We also hold the coefficient of variation for the inter-arrival time and processing time at 0.1 to estimate standard deviations.

@&#METHOD@&#

Supply chain operations are simulated using the ARENA software package (Rockwell Automation Inc. ARENA simulation software). The key endogenous information evaluated are the cycle time at the processing center, the batches’ waiting time at the processing center, the time for the sale of safety stock, product purchase time, product consumption time, and the time the customer contracts the illness. The model terminates and provides the simulated time to detection through food borne illness when the specified T number of food borne illnesses are reported, signaling the external discovery of contamination. One of the model’s outputs is the total quantity of contaminated stock (rounded to the nearest decimal) at the time of detection.


                        Table 3
                         presents the analytical results (from the mathematical model described in Section 3) and the simulation results for T = 100, 500, 750 for 50 replications. The time to detection and the quantity of contaminated stock from the analytical study and the simulation model coincide reasonably well for different values of T, thus we can consider the simulation valid.

Sensitivity analysis was performed by varying each parameter by ± 50 percent from its base value when possible, while holding all other parameters constant and observing the corresponding variation in the output measure (time to detection). We then classified a parameter as “Low” impact if the output measure varied less than 10 percent relative to the output measure from the base value, and as a “High” impact parameter if the output varied by more than 10 percent (Table 1).


                        Table 1 shows that customer demand, number of customers reporting an illness, and shelf life have the highest impact on the model’s outputs. However, these high impact input parameters have been modeled based on published data sources (such as CDC, Census, USDA studies etc.), whereas the estimated parameters (e.g. coefficient of variation of the processing time) have a minimal impact on the model results.

Our attempt to develop a generalizable model involves an abstraction of processes, particularly at the supplier and the processing center to facilitate an estimation of the total time to recall. However, we believe that the base parameter value assumptions in Table 1 reflect reality well, because perishable nature of the products means that the time spent in these locations is much shorter compared to other parameters such as shelf life, incubation time, and as a proportion of the total time to recall. In addition, our insights based on the relative comparison of the performance metrics for various scenarios (such as different sampling strategies) will minimize the impact of any error in estimating the base quantities.

@&#RESULTS@&#

We first evaluate the impact of a particular sampling strategy on the time to detection and the quantity of contaminated stock, assuming that food borne illnesses occur in the absence of sampling, representing a scenario that supply chain entities would want to prevent. We aim to determine the sampling strategy that will preempt this situation. Figs. 6
                         and 7
                         depict the results, and show that a sampling strategy implemented closest to the node with the highest probability of contamination is most effective. This observation confirms a widely used principle in the food sector wherein controls for high-risk processes should be placed at the stage with a high failure probability (Bertolini et al., 2007).

We further quantify the benefit of sampling at a particular node in terms of performance metrics. When contamination originates at the supplier, there is a difference of one order of magnitude between the quantity of contaminated stock for sampling at the supplier or at the retailer. If the contamination originates at the processing center, the difference between the quantity of contaminated stock for sampling at the processing center or at the retailer is almost one order of magnitude. This implies that the sampling location has a very high impact on the performance metrics and, in turn, the severity of the contamination event.

We observe that sampling at the retailer can only detect contamination prior to a food borne illness announcement if sampling is done at least every N ≤ 31 batches (or every 620 pounds). This implies that for a moderate to less frequent sampling strategy, retailer sampling is redundant because detection through food borne illness occurs much earlier than a successful sampling event at that retailer.

In addition, sampling at the processing center may even be redundant or barely worth the investment in some cases. Figs. 6 and 7 show that a sampling strategy at the processing center is only successful if N ≤ 78 (sampling every 1560 pounds of tomatoes) for both origin at the processing center and at the supplier. If a company cannot afford to sample at this frequency, then sampling is unprofitable because sampling less frequently will not yield any benefits in terms of the detection timeline.

On the other hand, there are positive benefits to less frequent sampling when done at the supplier. In our example, a sampling strategy of N ≤ 94 (or every 1880 pounds) results in detection prior to a food borne illness announcement. These observations underline the importance of matching resources and choice of location to establish a useful sampling strategy.

This result is particularly significant, as in the U.S., the legal rule in the event of food contamination is “strict liability,” where the seller involved in the most stages of food handling is held responsible. The seller cannot claim lack of prior knowledge or that the incident was not foreseeable (Pouliot and Sumner, 2008). Specifically, in our model, the processing center will be responsible even when the contamination originates at the supplier. Therefore, it is critical for a processing center to use a particular sampling strategy to preempt detection through a food borne illness.

We now investigate whether intrinsic product attributes (expected incubation time, retailer service level, and shelf life) impact the outcome of a contamination event. In particular, we are interested in the influence of product attributes on the use of a particular sampling strategy.

To examine these product attributes, we contrast pork products, such as hams and roasts, with fresh produce, such as tomatoes.

Processed pork products typically have a lower service level, approximately 87 percent, at the retailer (Matsa, 2011); have a shelf life of about 30 days (Vieira, 1999); and can cause food borne illnesses from the Campylobacter jejuni bacteria, which has an average incubation time of 4 days (Strohbehn and Beattie, 2010). Products such as tomatoes have a comparatively higher service level of about 96 percent, have a shelf life of 17.5 days, and can cause Salmonellosis, which has an average incubation time of 18 hours (Strohbehn and Beattie, 2010). We vary these product attributes for tomato and pork products accordingly and hold all other parameters in the model constant.


                        Fig. 8
                         shows the time to detection for tomato and pork product contamination through a foodborne illness. It also shows the time to detection of contamination for different sampling strategies (N values). The results show that pork products, which have higher incubation times and shelf life, and typically lower retailer service levels, receive greater benefit from a relatively less frequent sampling strategy, which can detect contamination prior to an illness report. Comparatively, products like tomatoes, which have relatively higher service levels, and lower shelf lives and incubation times, receive fewer benefits from a similar sampling strategy.

Products such as tomatoes require a more frequent sampling strategy to receive benefits on par with a given sampling strategy for pork products. However, this will lead to a higher sampling cost. As it is easier and less expensive to implement a useful sampling strategy for pork products as compared to tomatoes, we would expect to see a higher incidence of food borne illnesses from tomatoes and similar products, given a limiting budget constraint.

To analyze the impact of the supply chain properties on the magnitude of the contamination event and spread of contaminated stock along the supply chain, we simulate an extensive supply chain consisting of multiple suppliers, processing centers, and retailers. We analyze the impact of changes in the demand fulfilled by a particular node in the supply chain, lead times, and the number of processing centers on the contamination event.

We extend the supply chain described above to include four suppliers S
                           1, S
                           2, S
                           3, S
                           4, two processing centers P
                           1, P
                           2, and a cluster of retailers R, as shown in Fig. 9
                           .

We assume that all suppliers supply both processing centers, and both the processing centers supply all retailers. As before, the raw material is shipped from the suppliers to the processing centers in batches. The batches from different suppliers are queued on arrival, broken down, and processed into finished products. Therefore, the queue at processing center P
                           1 will comprise of batches from all suppliers S
                           1, S
                           2, S
                           3, S
                           4, which are then processed into finished products.

We assume that a Salmonella contamination occurs at supplier S
                           1 leading to a food borne illness. Initially, both processing centers fulfill equal proportions of the retailers’ demand, i.e. 50 percent of the retailers’ total demand.

The four suppliers also equally fulfill the processing centers’ demand, i.e. 25 percent of the total demand. All other attributes of the suppliers, processing centers, and retailers such as the lead time from the supplier to the processing center and batch size remain the same. This will create an equitable case for comparison against other cases with varying attributes. Therefore, this model is termed the “base case,” and various scenarios for comparison will be created by modifying this case.

The simulation ends when the number of customers contracting a food borne illness T = 100 for the base case and the time to detection corresponds to the length of the simulation. Through the simulation, we record as outputs the origin and distribution of the contaminated stock in the supply chain as either raw material or finished products. Table 4
                            provides the simulation outputs for the base case for 50 replications. In Table 5
                           , we list the sample mean, half-width of a 95 percent confidence interval, and both the minimum and maximum of the summary output values across the replications. These measures demonstrate that the outputs show minor variation, and are acceptable for further analysis.

Initially, the demand fulfilled by supplier S
                        1 is varied to study the impact of low and high demand fulfillment values on the magnitude and spread of contamination. In this scenario, the demand fulfilled by S
                        1 is decreased to 13 percent of the total demand for the low demand fulfillment case, and increased to 52 percent of the total demand for the high demand fulfillment case.


                        Table 6
                         summarizes the simulation’s outputs. All the other model parameters and the length of the simulation are the same as in the base case. Fig. 10
                         depicts the breakdown of contaminated stock at different stages of the supply chain for the base case, low demand fulfillment, and high demand fulfillment. The total contaminated stock in the supply chain can be either raw material or finished products.

A change in demand fulfillment has a direct proportional impact on the total quantity of contaminated stock. For example, in the high demand case, when the demand fulfilled by S
                        1 nearly doubles, the quantity of contaminated stock increases more than doubles (480–1000 pounds). When the demand decreases, the total contaminated stock also decreases by half (480–240 pounds).

Of further interest is the proportion of raw material and finished products in the total contaminated stock for all cases. In the base case, the raw material accounts for about 20 percent of the total contaminated stock, and finished products form the remaining 80 percent. In the case of high demand fulfillment, the proportions change to 25 percent and 75 percent, respectively. However, in the low demand fulfillment case the raw material forms just 16 percent of the total contaminated stock, with finished products accounting for the remaining 84 percent.

This implies that when each supplier fulfills a smaller proportion of the total demand, and the total demand fulfilled is held constant, the number of suppliers will have to increase. In such a scenario, product contamination at a particular supplier will shift downstream as finished products. In contrast, for a supply chain where each supplier fulfills a greater proportion of the total demand, the number of suppliers will decrease, and the contaminated stock will shift upstream as raw material.

In absolute numbers (e.g. pounds of contaminated stock) the low-demand, many-supplier scenario produces less contaminated stock as expected. However, the breakdown of contaminated stock into contaminated raw material versus contaminated finished products provides additional insight: in the low-demand case, processing centers are responsible for most of the contaminated stock because it is in the form of finished product rather than raw material. On the other hand, in the high-demand, few-suppliers scenario, suppliers are responsible for a relatively greater quantity of contaminated stock.

We vary the lead time from suppliers S
                        1 to processing centers to study the impact of changing lead times on the magnitude and spread of contamination to assess the effect of the location of S
                        1 on a contamination event. The lead time from the supplier to the processing center is both halved (0.365 day) and doubled (1.46 days), compared to the base case. The other input parameters remain the same. Table 7
                         reports the corresponding simulation results.


                        Fig. 11
                         depicts the amount of contaminated stock at different stages in the supply chain for the base case, and low and high lead times. There is an insignificant change in the quantity of contaminated stock when the lead time from S
                        1 to the processing centers increases or decreases.

The proportions of raw material and finished products in the total contaminated stock are significant. In the low-lead time case, raw material forms just 10 percent of the total contaminated stock, whereas finished products the remaining 90 percent. For high-lead times, raw material forms 23 percent of the total contaminated stock, while finished products form 77 percent.

Therefore, while the total amount of contaminated stocks is not significantly different for changing lead times, the distribution as raw material upstream or finished products downstream differs significantly. Additionally, varying the lead times does not significantly alter the quantity of contaminated stock is not as significant changes in demand fulfillment.

We next analyze the impact of a change in the supply chain structure on contaminated stock. The number of processing centers is decreased to one center P
                        1 which fulfills retailers’ total demand, and increased to four by incorporating two additional processing centers, P
                        3 and P
                        4. The processing centers P
                        3 and P
                        4 are modeled similar to the processing centers P
                        1 and P
                        2.

All other parameters are the same as in the base case. Table 8
                         summarizes the simulation results. Additionally, Fig. 12
                         depicts the quantity of contaminated stock at different stages of the supply chain for the base case, one processing center, and four processing centers.

As the number of processing centers increases (2–4) or decreases (2–1), there is an insignificant change in the amount of contaminated stock. However, of greater significance is the fact that the dispersion of the contaminated stock in the supply chain varies as the number of processing centers change. As the number of processing centers in the supply chain increase, the contaminated stock will be dispersed more widely among them.

Product dispersion is an important factor in determining the scale and complexity of retrieval operations in a recall event and the value of traceability systems (Buhr, 2003). When the source of contamination is unknown, the contaminated stock must be tracked and traced at all processing centers as both raw material and finished products, that is, the raw material arriving from S
                        1 to the processing centers, and the finished products departing from all processing centers. This dispersion represents the location and type of contaminated stock to track and trace in a recall event. Fig. 12 shows the corresponding dispersion of stock in the supply chain.

@&#DISCUSSION@&#

In this study, we model the performance of a generic food supply chain consisting of suppliers, processing centers, and retailers in a contamination event. We assume that contamination can occur at the supplier or processing center. The mode of detection is through sampling at the supplier, processing center, retailer, or through reports of food borne illness.

Through the analysis, we show that for a real-world tomato contamination case, the choice of sampling location has a very significant impact on the overall severity of contamination. For example, when contamination originates at the supplier, there is a difference of one order of magnitude between the quantity of contaminated stock for sampling at the supplier or at the retailer.

The legal costs associated with a recall, concerns about liability, and impact on the brand value of a company, apart from ethical considerations, advocate detection through sampling over detection through customer illness. However, company budgets will limit sampling strategies. Retailer sampling detects contamination much later than reports of food borne illness, except when using an extremely stringent sampling strategy, implying that retailer sampling may be redundant, as the announcement of a food borne illness occurs much earlier than a successful sampling event.

Though supplier sampling is the best option to detect contamination and minimize losses, in cases where the supplier/farm is located abroad (as in the tomato case study), it may be difficult to implement and monitor safety procedures such as the HACCP. In this case, efforts must be concentrated on sampling at the processing center (presumably located within the U.S. as in the tomato case). However, sampling at the processing center detects contamination faster than food borne illness reports only when using a moderate sampling strategy. If it is possible to monitor the supplier, then there is more flexibility and sampling can be done with lower frequency.

A product’s intrinsic attributes also impact the success of different sampling strategies. We show that for a given sampling strategy, sampling to preempt detection through a food borne illness report is higher for products that have higher illness incubation times, a longer shelf life, and low retailer service levels. As pork products have these characteristics, they can be sampled less frequently than tomatoes, which have a shorter shelf life, lower illness incubation times, and typically higher retail service levels. The latter product types require far more frequent sampling to meet the success rates of the former product types.

We also study different supply chain scenarios to estimate the amount and dispersion of contaminated stock in each case because an indicator of an effective response to a food contamination incident is the identification and disposal of the contaminated stock (National Response Framework Doctrine, 2008). This in turn can facilitate the planning of recovery operations post-detection.

When there is a high number of suppliers fulfilling a smaller proportion of the total demand, there is a shift of contaminated stock downstream as finished goods at the FGI, in transit to the retailer, and on the retailer’s shelf. In contrast, a supply chain with fewer suppliers fulfilling a larger proportion of the total demand shifts the contaminated stock upstream as raw material at the supplier and in transit to the processing center. Similarly, shorter(longer) lead times shift the contaminated stock downstream(upstream). Additionally, a supply chain with a greater number of processing centers shows a larger dispersion of stock among different stages of the supply chain, thereby increasing the spread of contamination.

It may initially appear beneficial for the post-detection retrieval and recovery operations to shift contaminated stock upstream away from the customer as less-dispersed pre-processed raw material. This occurs in supply chains with few suppliers and longer lead times, creating less dispersion. However, as in the tomato case study, if the suppliers are located globally (as indicated by the longer lead times), then recovery and retrieval operations may be difficult to conduct and control at the supplier. In this case, a shift of contaminated stock downstream may be preferable, which occurs in supply chains with more suppliers and shorter lead times, however, this leads to wider dispersion. Therefore, the results provide insights into the trade-offs in these different supply chain scenarios that in turn impact post-contamination recovery operations.

While product contamination in supply chain networks has grown in importance, analytical research in this area is still limited. Our research contributes a quantitative model of the impact of contamination in a generic supply chain. However, this work could be improved and extended by incorporating a cost analysis into the model. Additionally, the model would benefit from adaptive sampling strategies that make use of new information to design more effective sampling strategies. Further analytical modeling of the information flow processes present another area for future research.

Supplementary data associated with this article can be found, in the online version, at 10.1016/j.ejor.2015.01.016.


                     
                        
                           
                        
                     
                  

@&#REFERENCES@&#


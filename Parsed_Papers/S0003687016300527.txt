@&#MAIN-TITLE@&#Why we love or hate our cars: A qualitative approach to the development of a quantitative user experience survey

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We present a novel way of developing questionnaires for measuring user experience.


                        
                        
                           
                           Items were generated using users' natural and domain-specific language.


                        
                        
                           
                           The survey is sensitive to real-life experiences.


                        
                        
                           
                           Results were highly reliable to measure drivers' appraisals of their cars.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

User experience

Design and emotion

Survey development

Appraisal theory

Car industry

@&#ABSTRACT@&#


               
               
                  This paper presents a more ecologically valid way of developing theory-based item questionnaires for measuring user experience. In this novel approach, items were generated using natural and domain-specific language of the research population, what seems to have made the survey much more sensitive to real experiences than theory-based ones. The approach was applied in a survey that measured car experience. Ten in-depth interviews were conducted with drivers inside their cars. The resulting transcripts were analysed with the aim of capturing their natural utterances for expressing their car experience. This analysis resulted in 71 categories of answers. For each category, one sentence was selected to serve as a survey-item. In an online platform, 538 respondents answered the survey. Data reliability, tested with Cronbach alpha index, was 0.94, suggesting a survey with highly reliable results to measure drivers' appraisals of their cars.
               
            

@&#INTRODUCTION@&#

Interest in measuring user experience has progressively increased along with a growing interest in experience-driven design. Initially, design researchers borrowed instruments developed in the social sciences (for reviews, see Laurans et al., 2009; Poels and Dewitte, 2006; Desmet et al., 2016) to undertake these measurements. Later, domain-dedicated instruments were developed. These instruments, such as scales that measure subtle and mixed user emotions (Desmet, 2003), affective responses to interactive products (Hassenzahl et al., 2010), or user experience over time (Karapanos et al., 2009), proved to be much more sensitive to the particular characteristics of the user experience itself. As a result, over the last decade, an overwhelming amount and diversity of user experience measurement instruments have become available. In response to this proliferation, several inventories have been organized and frameworks proposed with the aim of providing a comprehensive overview (e.g., Obrist et al., 2009; Vermeeren et al., 2010; ENGAGE, 2006; Höök, 2008).

Besides the attempt to provide an overview, various authors have also made an effort to increase awareness regarding the added value of applying experience measures in design processes (Väänänen-Vainio-Mattila et al., 2008; Law et al., 2014). These studies have revealed some pertinent theoretical, methodological, and practical issues for the measurement of user experience in the context of design processes. One recurrent issue is related to whether user experience is best measured with qualitative or quantitative methods. This question seems to refer back to the classical distinction between reductionism and holism at the same time that it appears to divide the user experience research community in two (Law, 2011). One of the main advantages of qualitative data, which tends to be rich and detailed, is that it can inform about the causes of certain experiences and offer relevant insights for both envisioning design opportunities and formulating design requirements. In contrast, one of the main advantages of quantitative data, which tends to be simple and precise, is that it can provide an objective basis for critical decisions on design and developmental issues. Such objectivity may come in handy when trying to attract investments and convince stakeholders about the effectiveness of design decisions. In addition, quantitative data can be helpful in testing and improving user experience theories, which, in their turn, may provide universal principles applicable to a multitude of design contexts. In practice, many researchers choose to combine qualitative and quantitative approaches as, for instance, when using emotion measurement in combination with open interviews (see Desmet and Schifferstein, 2012).

Within the wide variety of approaches to assess user experience, the traditional questionnaire is still currently the most often used in the context of design and design research, both for obtaining quantitative and qualitative data (Bargas-Avila and Hornbæk, 2011). Surveys are easy to develop and administer; they do not require sophisticated instruments or software; and they can be easily tailored to the research challenge at hand. Item generation is typically theory-based, requiring researchers to translate theoretical factors or variables into survey items. Two often reported concerns about using such theory-based questionnaires relate to their face and ecological validity, which again seem to refer back to the reductionism versus holism debate (Law et al., 2014). Design researchers tend to be sceptical about the degree to which surveys are able to uncover actual ‘real’ feelings and responses. In addition, they tend to question if theory-based surveys are sufficiently sensitive to the richness and variety of people's responses to stimuli in real-life settings. Acknowledging these two issues, we propose a novel way of developing theory-based item questionnaires for measuring user experience. The key difference from traditional questionnaires is that natural and domain-specific language of the research population is actually used in the generation of the items. Our proposition, therefore, is that both face and ecological validity may be increased with the use of questionnaires that are, not only based on underlying theoretical factors, but also formulated in a natural language sensitive to real experiences of real people in real usage contexts.

In the specific case of this paper, the attempt of applying a natural-language approach to item-development takes place within the context of a car experience survey. The reason for choosing car design is that vehicles usually evoke strong emotions and rich user experiences (Desmet et al., 2000; Kamp, 2012; Hiemstra-van Mastrigt et al., 2015; Franz et al., 2012). Moreover, stakeholders in the automotive industry typically require quantitative measures to justify and evaluate experience-driven design initiatives (Saucken et al., 2014). In the paper, we first briefly introduce the theoretical basis for the experience survey. Then, we present the three steps undertaken for developing the natural-language based questionnaire. Next, we report on the application of the survey and its results. Finally, in the Discussion Section, we bring the paper to an end, exploring some challenges and future research possibilities.

The theoretical basis for our approach to survey development is appraisal theory, one of the most commonly used theories (either implicitly or explicitly) for understanding emotional responses both in standard emotion research (Frijda, 1993) and in design research (Desmet and Hekkert, 2002). An appraisal is a sense-evaluation of the ‘relational meaning’ of a stimulus event, which determines the perceived relevance of the event to one's well-being (Frijda, 1986; Lazarus, 1991). Events that are appraised as contributing to one's well-being evoke pleasant emotions, and those that are appraised as threatening or harming one's well-being evoke unpleasant emotions. Because appraisals mediate events, user goals, and emotions, they may trigger insights regarding the relationships among these variables (Desmet and Hekkert, 2002). Experience questionnaires are usually developed on the basis of sets of distinct appraisal components, where each one relates to a particular ‘relational issue’ of a stimulus event (Roseman, 2001; Scherer, 2001). Reviewing a series of appraisal theories, Demir et al. (2009) selected seven main appraisal components that are relevant for user experience in human–product interactions. These components are presented in Table 1
                      along with their respective key relational issue.


                     Demir et al. (2009) argued that these seven appraisal components (Table 1) facilitate a systematic and fine-grained analysis of emotions. At the same time, the authors acknowledged that these components are too abstract to be useful for design purposes and, thus, advised that they should be operationalized according to the particular design domain of interest. In our natural-language approach to developing experience questionnaires, this operationalisation was mediated by domain-relevant interviews with real users rather than directly done by the researchers themselves (as it is the common practice). The next section reports on the three steps involved in this procedure in more details.

The first step was to conduct in-depth interviews to operationalize the appraisal components presented in Table 1 within the context of car experience, using natural and domain-relevant language. Respondents were recruited by e-mail. In this mail, they were asked to indicate to what extent they agreed with the sentences “I love my car” and “I hate my car”, using a five-point Likert scale (ranging from completely agree to completely disagree).

Ten respondents were selected from 50 e-mails sent: 5 females and 5 males; 18–54 years old; 3 undergraduates, 4 professionals, and 3 graduate students; all Brazilians. Five completely agreed that they loved their cars, and five completely agreed that they hated their cars. Even though the makeup of the two groups was different, as seen in Table 2
                        , these respondents were selected to ensure that the subsequent interviews would generate emotional exclamations, that is, evoke naturalistic sentences from the drivers when expressing appraisals in relation to their cars.

An interview-guiding list based on the seven appraisal components was developed to be discussed with the selected respondents. The interviews were conducted individually and took between 45 and 75 min. Time and place were determined by the respondents. For reasons of ecological validity, the interviews were conducted in the respondents' car; first while they just sat in the driver's seat and, after, while they were driving. The interviews were conducted while the car was parked. During the driving, the interviewers refrained from speaking and only registered spontaneous verbalizations. Interviews were recorded in video and transcribed afterwards.

All transcribed material was analysed according to content analysis (see Neuendorf, 2002). In line with general practice in this field, interviews were analysed until data saturation was reached, indicating that the ten respondents from the qualitative stage of this research were able to provide clear reasons to their appraisals. Categories of answers were identified, mainly by means of similarity. That is, similar sentences mentioned by different respondents were grouped together. Content analysis was initially developed separately by two researchers with more than ten years of experience with the technique. All transcriptions were read and generated a first draft of the categories, which was discussed on a meeting between them. In a collaborative process, the two researchers developed the final outline of categories.

This procedure resulted in 71 categories of answers, each related to at least one of the seven appraisal components. From each category, one sentence was selected to serve as the basis for the questionnaire items. In this selection, the following five basic guidelines for formulating survey items were taken into consideration (see Hinkin, 1998): (1) the language used is simple, short and familiar to the group of respondents (e.g., “It's a dream car.” Sentences were selected from the interviews, using everyday language.); (2) each item assesses a single issue, avoiding combinations of issues (e.g., “It makes unbearable noises.”); (3) items do not represent more than one theoretical construct (e.g., “Its engine is quiet” is representative of the appraisal component intrinsic pleasantness.); (4) leading formulations (questions phrased in a way that suggest expected responses) are avoided (e.g., we have refrained from using sentences such as “It is the best model I could pay for”); (5) items that are expected to generate little variance are avoided (e.g., sentences revealing ideas with which users obviously totally agree were not included, such as “a great car should never fail”.).

The second step was to prepare the 71 sentences collected for serving as survey items. The sentences were kept in the original language (Brazilian Portuguese) and were adapted as little as possible to preserve the drivers' genuine way of expressing themselves. Nevertheless, some small changes were made. Firstly, slang was eliminated. Secondly, some sentences were adapted to make sure that they were understandable when taken out of the original context of the conversation. Thirdly, emotional words (e.g., afraid and happy) were eliminated as much as possible since the focus of the questionnaire was not on particular emotions but on appraisals that evoke emotions. Regarding this last change, however, it is important to highlight that, whenever the omission of emotional words compromised the meaning of the sentences, they were kept in the original form. This kind of exception can be illustrated, for instance, by contrasting two connotatively different sentences included in the item pool: “It has already given me so many problems that I'm afraid of it” and “This car has just given me problems”. These two sentences would end up having very similar meanings, if the clause “that I'm afraid of it” had been omitted from the first sentence.

The questionnaire was built in an online platform. It started with general questions about the respondents' demographics and cars. Next, respondents indicated their level of agreement with each one of the 71 sentences, using 5-point Likert-type scales (1 = “completely disagree”; 5 = “completely agree”). Sentences were randomized among respondents to control for order and tiredness effects.

The third step was to authenticate both the content and the face validity of the questionnaire. For this survey, content validity referred to the extent to which it sufficiently represented all seven appraisal dimensions (Table 1). Content validity is typically judged by experienced (and recognized) subject matter experts. Here, the judge was a leading expert in experience design research (board member of the International Design and Emotion Society, editor of peer reviewed design research journals, and professor of design aesthetics). In a meeting with the authors, the judge discussed the relevance and form of all items, suggesting several minor modifications. While content validity refers to what the survey actually measures, face validity refers to what the survey appears to measure in the eyes of the respondent population, and the adequacy of the language and item presentation. Face validity was determined with 61 undergraduate students from a southern Brazilian university. They first answered the survey in a media lab, and then reflected on each item. This step resulted in some other additional minor modifications of some items; the final set of items is presented in Table 4
                        
                        .

The final version of the natural-language questionnaire was tested in a study with 710 Brazilian respondents. Respondents were recruited by e-mail. The data of 538 respondents (75.8%) who completed the whole survey were included in the data analysis. Briefly, information about the respondents and their vehicles may be summarized as follows:
                           
                              •
                              mean age: 31.2 (SD = 10.94);

gender: 56.7% female and 43.3% male;

level of education: 30.1% undergraduate students, 22.7% professionals holding a bachelor degree or equivalent, and 38.5% holders of a master degree;

car brands: 16.2% Chevrolet, 15.8% Volkswagen; 14.9% Fiat, and 14.3% Ford;

car condition at purchase: 65.2% new and 34.8% used;

car use frequency: 76.9% on a daily basis;

car users: 51.7% single users and 24.5% main users, but not the only ones.

Respondents filled out the questionnaire individually, online, at a place and time of their convenience.

@&#RESULTS@&#

Data reliability was tested with Cronbach's alpha. The result was 0.94, indicating an excellent internal consistency. The KMO measure of sampling adequacy was calculated to determine if the data was suitable for factor analysis. The result was 0.93, which is exceptionally high and suggested that the data was very suitable for factor analysis (Kaiser, 1974). In addition, we used Bartlett's test of sphericity that probes whether the correlation matrix is an identity matrix, in which case it would reveal that the factor model was inappropriate. The result, 16664.81 – p < 0.01, however, indicated that the factorial model was adequate (Norusis, 1994). The communalities also presented a mean of 0.59, implying that each variable shared a good amount of variance in the analysis with the other measured variables. All items in the scale had communality equal or above 0.46.

While the scale items were developed according to the seven theoretical factors, the factorial extraction suggested 15 factors, with the lowest one explaining 1.72 of the total variance. When results suggest more than ten factors, the eigenvalues are usually below 1.0, which would indicate that we should not accept this number of factors. This was not the case in this survey, since all eigenvalues were above 1.0. It was found that the 15 factors explained 58.989% of the total variance from the group of variables that were part of the instrument. Even though the variance explained by each factor was relatively balanced among them, the distance between the first (23.32) and the second (7.19) factors was higher. The Varimax orthogonal rotation showed a better distribution of the variance among factors. All these results can be seen in Table 3.

Item distribution in factors, considering their factorial extraction observed after the Varimax rotation and the Kaiser normalisation, is shown in Table 4.

Even though factors from 11 to 15 are composed by one item each, we decided to keep them in the survey, due to their communality scores. Observing their contents, it is not surprising that they did not charge in any other factor, since they do not seem to share a lot in meaning with any other general factor. Some of these last 5 factors even had some of the highest communality scores in the 71-item survey.

Each one of the 15 factors was named according to its item contents. A brief description of each factor's content can be found in Table 5
                        .

Motive consistency seems to be related to almost all of the 15 factors in Table 5. This finding is compatible with appraisal theory, which proposes that motive consistency is the ‘primary appraisal’ that determines if an emotion is experienced and if this emotion is positive or negative. The other appraisal components are secondary and determine what particular emotion is experienced (Roseman, 1991). Nonetheless, the other six appraisals are also represented by one or more factors: intrinsic pleasantness (factor 3); expectation confirmation (factor 13); agency (factor 14); standards conformance (factor 10); coping potential (factors 1 and 14); certainty (factor 11).

Convergent validity, in this case, is the degree to which a factor converges on the global scale results. It shows that assessment is related to what it should be related to. To test for convergent validity, a multiple linear regression analysis was conducted, with the item's global mean score as a dependent variable and the mean score for all items in each factor as an independent variable. This analysis revealed a significant Adjusted R Square (0.998), indicating that most of the variance of the global results is explained by the 15 factors that are part of the scale. Table 6
                         shows how much each factor predicts the global scale results.

It can be observed that the highest results are 0.404 (factor 2) and 0.338 (factor 1), both of them considerably distant from all the others, which means that the first two factors themselves can predict most of the global results of this research.

@&#DISCUSSION AND CONCLUSION@&#

In an inventory of user experience research, Bargas-Avila and Hornbæk (2011) found that half of the publications that used questionnaires employed self-developed instruments without providing readers with information about which items were used or on what basis these items were formulated. These authors claimed that using self-made items without such relevant information is unscientific, preventing readers from understanding and assessing the quality of the research approach and its outcomes. Their observation highlights an issue that is usually undervalued in the debate about the usefulness of questionnaires in experience-driven design: how survey items should be developed to maximise their contribution. Most of the attention seems to be placed on the contribution of quantitative research only.

The research reported in this paper aimed at taking a step towards exploring this issue, putting forward a novel way of developing user experience surveys. More specifically, it argued that the way in which items are generated could influence the internal consistency and the ecological validity of this kind of instrument. Although it is common practice to formulate survey items in a simple and direct language, appraisals towards products do not seem to be expressed in such straightforward terms in real life.

In the development of the car experience survey, it was observed that, when drivers verbally reported their experiences, they often connected attributes that are not usually combined in traditional survey items. By respecting these natural combinations in the survey development, the research seemed to have gained in ecological validity. For example, the sentence “I have confidence in it, because it has never caused any problems” states a causality relation. According to item-development guidelines, it should have been split into two items. However, respondents understood confidence only in relation to this particular cause. Thus, working with combined statements represents a much more real-life appraisal in relation to this particular product.

Therefore, the main contribution of this research was to demonstrate that, when using a natural and domain-specific approach to develop user experience surveys, researchers are more likely to end up with consistent research instruments. To integrate this naturalistic – qualitative dimension to a survey, researchers need to be flexible regarding the traditional ways of developing survey items. On balance, we believe that this research may represent an advance in the design and emotion field. It not only moves towards holism in evaluating real-life experiences, as advocated by Law (2011), but it also provides a strong basis to measure experience, which is still a key issue in contemporary user research.

It is also worth pointing out a secondary contribution, on a theoretical level: a better understanding of the role of appraisal theory in design studies. As discussed before, there was not a complete convergence between theoretical factors (appraisal components) and those extracted from the research data. For example, motive consistency was an appraisal component that seemed to be related to most of the 15 extracted factors. This outcome seems to indicate that a one-to-one correspondence between real-life appraisals to products and specific theoretical appraisal components or single questions about them is unreal. Theoretical constructs have consistently been useful in psychological research, among other functions, to inspire the design of data collection instruments. They may not reveal what happens in real life, but still be a source of input to collect and analyze data. Thus, it is normal and expected, e.g., that users buy cars that are more aesthetically appealing and pleasant to their senses. In Appraisal Theory, it would be both interpreted as motive consistency and intrinsic pleasantness.

The survey investigates appraisals that tend to evoke positive experiences, which can be useful to the industry. Some of these appraisals can be very factual, providing a lower level of insights to design better cars (e.g., “Its engine is quiet”). On the other hand, several other appraisals are less objective and allow researchers to foresee ways in which car design may be able to evoke better experiences than the current ones (e.g., “It seems like it's a part of me” and “It gives me a feeling of freedom, more than other cars”). Therefore, practical and subjective appraisals merge and determine the overall quality of user experience. Ignoring the non-factual appraisals is not recommended. As regression analysis indicates, factor 2 (personal identification), which is a very subjective factor, explains most of the variance of the global results of the survey.

Even though the results seem to support the idea that our approach allows for a consistent survey development, some challenges and limitations must be pointed out. One challenge is the amount of time spent in the elaboration of the survey. A traditional questionnaire can be developed in a few hours, while developing a survey in the lines of the proposed approach can take several weeks, since it requires interviewing users, analysing the content of their verbalizations, and generating the survey items based on qualitative analysis. Thus, general theory-based surveys continue to be more convenient when researchers have limited time.

In relation to the specificity and the depth of the analysis, a primary limitation is that this kind of research instrument is specific to evaluate user experience with a single product (category), which means that all survey items will be strictly related to one category. This limited scope, however, seems to be a trend in psychometrics: the development of specific surveys, instead of general ones. Although questionnaires gain in specificity, data reliability and validity, they lose in terms of development agility and availability, as well as in terms of the “purity” of traditional academic procedures.

Another limitation is that the approach is not suitable to develop a single survey version to be used with extremely distinct research populations. Considering that the actual products evaluated differ from culture to culture, it is clear that appraisals to them may also change, as well as the emotional outcomes from user–car interaction due to these appraisals. In addition, assuming that people in different cultures express appraisals in different ways, it also seems inadequate to develop research instruments to be used in cross-cultural studies. On the other hand, the industry is certainly more benefited from the use of a highly consistent instrument that reveals real-life appraisals than a general one, since the specificity of the product-related contents and the adequacy of the appraisals can deliver results to designers that allow for safe decision-making.

The type of relationship established between users and cars may also be different. In Brazil, where the data collection was developed, recently the government lowered taxes to stimulate citizens to purchase new cars. In addition, the public transportation system is known by being chaotic in most major cities, which can also stimulate people to have closer relationships with their cars due to intense use. Extremely different user-car relationships may be observed in distinct cultures, such as Denmark and The Netherlands, where citizens are stimulated to use other types of transport.

An important limitation of this study is that participants were not asked how recently they have been in their cars. It is known that the experience of use may change through time, and this variable should be addressed in further studies.

While this research is an initial effort in shaping a more naturalistic way of developing user experience questionnaires, based on respondents' natural and domain-specific language, further studies are required to make it even more solid. A research agenda on the topic could include the development of car experience surveys with the same approach but in different cultures, as well as translations of the current survey to other languages in order to compare results with the original findings in this paper. It is also important to develop further research instruments to evaluate users' appraisals of other categories of products, using the same approach, to access whether their results would also be highly consistent or not. Lastly, considering both the needs of the industry, to test products worldwide, and those of the academia, to have proper instruments and to accumulate knowledge based on similar scientific criteria, some effort could be done to try to develop reality-driven instruments suitable to cross-cultural studies.

@&#ACKNOWLEDGEMENTS@&#

We express our gratitude to copyeditor Sidnea Nunes Ferreira and to Paul Hekkert for his expert feedback in the survey development process. This research was supported by the MAGW VIDI grant number 452-10-011 of The Netherlands Organization for Scientific Research (N.W.O.) awarded to P.M.A. Desmet. Also, the first author would like to thank the Department of Industrial Design at Delft University of Technology for hosting him as a post-doctoral visiting scholar to develop this research.

@&#REFERENCES@&#


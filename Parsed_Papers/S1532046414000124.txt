@&#MAIN-TITLE@&#Computer-aided detection of breast cancer on mammograms: A swarm intelligence optimized wavelet neural network approach

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a CAD system for detecting breast cancer in mammograms.


                        
                        
                           
                           Swarm intelligence optimized wavelet neural network detects the cancers.


                        
                        
                           
                           We focus on optimized wavelet neural network to enhance the detection accuracy.


                        
                        
                           
                           Experiments are carried out on real clinical database collected from screening centers.


                        
                        
                           
                           Our method yielded better performance than other existing approaches.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Mammograms

Breast cancer

Computer aided diagnosis

Receiver operating characteristic

Laws

Particle swarm optimization

@&#ABSTRACT@&#


               
               
                  Breast cancer is the second leading cause of cancer death in women. Accurate early detection can effectively reduce the mortality rate caused by breast cancer. Masses and microcalcification clusters are an important early signs of breast cancer. However, it is often difficult to distinguish abnormalities from normal breast tissues because of their subtle appearance and ambiguous margins. Computer aided diagnosis (CAD) helps the radiologist in detecting the abnormalities in an efficient way. This paper investigates a new classification approach for detection of breast abnormalities in digital mammograms using Particle Swarm Optimized Wavelet Neural Network (PSOWNN). The proposed abnormality detection algorithm is based on extracting Laws Texture Energy Measures from the mammograms and classifying the suspicious regions by applying a pattern classifier. The method is applied to real clinical database of 216 mammograms collected from mammogram screening centers. The detection performance of the CAD system is analyzed using Receiver Operating Characteristic (ROC) curve. This curve indicates the trade-offs between sensitivity and specificity that is available from a diagnostic system, and thus describes the inherent discrimination capacity of the proposed system. The result shows that the area under the ROC curve of the proposed algorithm is 0.96853 with a sensitivity 94.167% of and specificity of 92.105%.
               
            

@&#INTRODUCTION@&#

Breast cancer is the most frequently diagnosed cancer in women worldwide and the leading cause of cancer death among females. Breast cancer accounts for 23% of the total cancer cases and 14% of the cancer death in both developed and developing countries. It is estimated that more than 1.6million new cases of breast cancer occurred among women worldwide in 2010 [1,2]. In 2011, nearly 1.7 million people were told to have breast cancer; statistics says that in USA 527 new cases of breast cancer were diagnosed per day and 110 people die of it per day. Early diagnosis remains important for survival, particularly in low and middle income countries where the diseases is diagnosed in late stages and resources are very limited. One proven way of reducing mortality from breast cancer is the screening of asymptotic women by mammography.

Mammography is the best screening tool that uses low dose X-rays to create an image of the breast to find breast cancer. Mammography has been proved to be effective in screening asymptomatic women to reduce mortality by as much as 30%. The American Cancer Society recommends that all women aged above 40 undergo screening mammography once in a year. Dense breast tissue can look white or light gray on a mammogram. This can make mammograms harder to interpret in younger women, who tend to have denser breasts. Many breast conditions mimic the symptoms of cancer and need tests and sometimes a biopsy for diagnosis. False positive results occur when mammogram finds something that looks like cancer, but turns out to be benign (not cancer). Depending on the density of the breasts radiologists may miss up to 30% of breast cancers [3]. Even qualified radiologists find it difficult to interpret screening mammograms in large numbers.

Two powerful indicators of cancer that are commonly used in evaluating mammograms are known as masses and microcalcifications. It is generally accepted that mass detection is a more challenging problem than the detection of micro-calcifications, not only for the large variation in size and shape in which masses can appear in a mammogram but also because masses often exhibit poor image contrast [4]. A true abnormality can usually be distinguished based on careful analysis on two different view of a mammogram namely Carniocaudal (CC) view and MedioLateral Obligue (MLO) view [5]. But, additional methods or imaging is need if the suspected region is not viewed on the complementary view of the mammogram or if there is a dense tissue present that could obscure an underlying abnormality.

Computer-aided detection and diagnosis (CAD) can be used on the digital images to help the radiologists analyse the overall images, and highlights potential areas of concern that needs closer study. CAD can find tumours that a radiologist might not spot. Once a CAD analysis has been done, a radiologist will do a visual check of those areas, and based on training and experience, decide how serious the lumps may actually be [6]. CAD will assist the radiologists by serving them as a “second reader”. The proposed CAD system will automatically identify the areas of abnormal contrast, calling the radiologist’s attention to suspicious regions. Combining mammography with CAD will improve the ability to find cancer [7]. In many cases, the microcalcifications and the cancer masses are hidden in the intense breast tissues especially in younger women, making both the diagnosis and detection more complex and intricate [8]. While mammography has been proven to be a powerful tool in the fight against breast cancer, the accurate reading of mammograms can sometimes be difficult [9]. Even the most trained radiologist can miss subtle variations in tissue that might be of concern.

A lot of researches in the area of CAD systems for breast cancer and developing intelligent techniques for improving classification accuracy have been conducted in last few decades [10–12]. Different studies have demonstrated that Computer Aided Detection (CAD) of breast cancer can improve the detection rate from 4.7% to 19.5% compared to radiologists. Regarding classification of abnormalities in mammogram, a number of techniques have been presented using machine learning approaches to classify samples as normal and abnormal.

Karahaliou et al. [13] investigated multi-scale texture properties of the tissue surrounding microcalcifications (MCs) for breast cancer diagnosis using probabilistic neural network. Kupinski and Giger [14] presented a radial gradient index based algorithm and a probabilistic algorithm for detecting lesions in digital mammograms. Sahiner et al. [15] used a Convolution Neural Network (CNN) classifier to classify the masses and the normal breast tissue. Eltonsy et al. [16] presented a method based on the presence of concentric layers surrounding a focal area with suspicious morphological characteristics and low relative incidence in the breast region. Zheng et al. [17] presented a mixed feature based neural network for detection of microcalcification clusters in digital mammograms. Features are computed in both the spatial and spectral domain and uses spectral entropy as a decision parameter. Backpropagation with Kalman filtering (KF) is employed to allow more computationally efficient training as required for evaluation of different features and input images.

Among existing CAD techniques, the main problem of developing an acceptable CAD system is inconsistent and low classification accuracy. In order to improve the training process and accuracy, in this paper a novel intelligent classifiers that use texture information as input to classify the normal and abnormal tissues in mammograms is investigated. Moreover, the intelligent machine learning classifiers are optimized using heuristic algorithms for finding appropriate hidden neurons, learning rate and momentum constant during the training process.

This paper concentrates on developing a CAD system as an artificial second radiologist. Texture helps to understand image content based on textural properties in images. Texture is the most important visual cue in identifying different types of homogeneous regions and gives information about the surface property, depth and orientation [18–22]. This texture information helps to extract specific characteristics from a data. Mammographic images possess textural information that could bear discriminant features. The Laws texture features were extracted from the mammogram to differentiate between abnormal and normal pixels. New artificial intelligent techniques such as neural network have been used in medical applications for discriminating the normal and abnormal tissues in mammograms. The thriving of artificial intelligence which utilizes the human experience in a more relaxed form than the conventional mathematical approach has recently attracted more attention.

Designing optimal neural network architecture is made by a human expert and it requires a tedious trial and error process. Especially automatic determination of artificial neural network parameters is the most critical task. This paper focuses mainly on designing a CAD system based on the optimized wavelet neural network evaluated using Particle Swarm Optimization approach (PSOWNN). Optimization of WNN is carried out to improve the classification accuracy in breast cancer detection thereby reducing the misclassification rate.

The proposed CAD system is based on a pattern recognition system which intelligently identifies the abnormal regions. CAD schemes using digital image processing techniques have the goal of improving the detection performance. Typically CAD systems are designed to provide a “second opinion” to aid rather than replacing the radiologist. Fig. 1
                      shows the proposed approach for detection of abnormality in mammograms.

Clinical mammogram database consisting of 216 images of 54 patients were taken from mammogram screening centers. The real time database includes a wide spectrum of cases that are difficult to classify by radiologists. All clinical mammograms that were collected from screening clinics were positive for presence of abnormalities. Mammograms were collected from 54 patients and all these patients have agreed to have their mammograms to be used in research studies. For each patient 4 mammograms were taken in two different views, one is the Craniocaudal (CC) and the other is the Mediolateral Oblique (MLO) view. The two projections of each breast (right and left) were taken for every case. The suspicious regions were identified by the automated system based on various machine learning algorithms and was reviewed by experienced radiologists. For this study a total of 216 mammograms were taken, all the mammograms were digitized to a resolution of 290×290Dots per Inch (DPI) which produces 24bits/pixel. Each digitized mammograms was incorporated into a 2020×2708pixel image (5.47Mpixels). Screening mammography is taken on asymptotic women to detect clinically occult cancers. Table 1
                         shows the summary of the different types of abnormalities in the database. The mammograms obtained are from women with an age group of 20–69years old.

The goal of pre-processing the image is to simplify recognition of cancers (abnormalities) without throwing away any important information. Mammograms has breast region and is superimposed over background structures to which analysis is not necessary. One way would be to restrict the analysis to Region of Interest (ROI) that does not contain any background. The initial preprocessing is done in the digital mammogram to separate the region of interest (breast) and the dark background. The separation of ROI from the dark background is done using a global thresholding technique. Consider an input mammogram image f(x,
                        y), having light breast area on a dark background. The objects from the background are separated using a threshold value T and is defined as in Eq. (1). Then any point (x,
                        y) for which f(x,
                        y)>
                        T is called the breast area; otherwise, the point is called the background region. The threshold is chosen by visual inspection of the image histogram [23].
                           
                              (1)
                              
                                 I
                                 (
                                 x
                                 ,
                                 y
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   f
                                                   ,
                                                
                                                
                                                   f
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                   >
                                                   T
                                                
                                             
                                             
                                                
                                                   0
                                                   ,
                                                
                                                
                                                   f
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                   ⩽
                                                   T
                                                
                                             
                                             
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

An intensity histogram is constructed and the local threshold value is chosen by statically examining the intensity values of the local neighborhood of each pixel. The mean of the local intensity distribution is calculated and used as a threshold value. The breast area in the mammogram only covers about 30%, on average, of each mammogram. Based on this observation, the breast area is first segmented out in order to save processing and then further processing is restricted to the breast area.

The texture energy measures developed by Kenneth Ivan Laws at the University of Southern California have been used for many diverse applications [24]. These texture features are used to extract Laws Texture Energy Measures (LTEM) from the ROI containing abnormality and normal tissue patterns. These measures are computed by first applying small convolution kernels to the ROI and then performing a windowing operation. The 2-D convolution kernels for texture discrimination are generated from the following set of 1-D convolution kernels of length five. Here textures are considered as a quantitative measure of arrangement of intensities in a region. The kernels are chosen in a way that they have to average to zero. The kernels are chosen so that they are sensitive to edge points, spots, lines and a combination of these. These kernels are chosen for finding the level, edge, spot, wave and ripple [24].
                           
                              
                                 
                                    
                                       
                                          L5
                                          =
                                          [
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   4
                                                
                                                
                                                   6
                                                
                                                
                                                   4
                                                
                                                
                                                   1
                                                
                                             
                                             
                                                
                                             
                                          
                                          ]
                                       
                                    
                                    
                                       
                                          E5
                                          =
                                          [
                                          
                                             
                                                
                                                   -
                                                   1
                                                
                                                
                                                   -
                                                   2
                                                
                                                
                                                   0
                                                
                                                
                                                   2
                                                
                                                
                                                   1
                                                
                                             
                                          
                                          ]
                                       
                                    
                                    
                                       
                                          S5
                                          =
                                          [
                                          
                                             
                                                
                                                   -
                                                   1
                                                
                                                
                                                   0
                                                
                                                
                                                   2
                                                
                                                
                                                   0
                                                
                                                
                                                   -
                                                   1
                                                
                                             
                                          
                                          ]
                                       
                                    
                                    
                                       
                                          W5
                                          =
                                          [
                                          
                                             
                                                
                                                   -
                                                   1
                                                
                                                
                                                   2
                                                
                                                
                                                   0
                                                
                                                
                                                   -
                                                   2
                                                
                                                
                                                   1
                                                
                                             
                                          
                                          ]
                                       
                                    
                                    
                                       
                                          R5
                                          =
                                          [
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   -
                                                   4
                                                
                                                
                                                   6
                                                
                                                
                                                   -
                                                   4
                                                
                                                
                                                   1
                                                
                                             
                                          
                                          ]
                                       
                                    
                                 
                              
                           
                        
                     

From this above 1-D convolution kernels 25 different two dimensional convolution kernels are generated by convoluting a vertical 1-D kernel with a horizontal 1-D kernel. Similarly, 25 different two dimensional masks can be formed.
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   -
                                                   1
                                                
                                             
                                             
                                                
                                                   -
                                                   2
                                                
                                             
                                             
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   2
                                                
                                             
                                             
                                                
                                                   1
                                                
                                             
                                          
                                       
                                    
                                 
                                 ×
                                 [
                                 
                                    
                                       
                                          1
                                       
                                       
                                          4
                                       
                                       
                                          6
                                       
                                       
                                          4
                                       
                                       
                                          1
                                       
                                    
                                 
                                 ]
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   -
                                                   1
                                                
                                                
                                                   -
                                                   4
                                                
                                                
                                                   -
                                                   6
                                                
                                                
                                                   -
                                                   4
                                                
                                                
                                                   -
                                                   1
                                                
                                             
                                             
                                                
                                                   -
                                                   2
                                                
                                                
                                                   -
                                                   8
                                                
                                                
                                                   -
                                                   12
                                                
                                                
                                                   -
                                                   8
                                                
                                                
                                                   -
                                                   1
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   2
                                                
                                                
                                                   8
                                                
                                                
                                                   12
                                                
                                                
                                                   8
                                                
                                                
                                                   2
                                                
                                             
                                             
                                                
                                                   1
                                                
                                                
                                                   4
                                                
                                                
                                                   6
                                                
                                                
                                                   4
                                                
                                                
                                                   1
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                    
                                 
                                 
                                    
                                       
                                          L5L5
                                       
                                       
                                          E5L5
                                       
                                       
                                          S5L5
                                       
                                       
                                          W5L5
                                       
                                       
                                          R5L5
                                       
                                    
                                    
                                       
                                          L5E5
                                       
                                       
                                          E5E5
                                       
                                       
                                          S5E5
                                       
                                       
                                          W5E5
                                       
                                       
                                          R5E5
                                       
                                    
                                    
                                       
                                          L5S5
                                       
                                       
                                          E5S5
                                       
                                       
                                          S5S5
                                       
                                       
                                          W5S5
                                       
                                       
                                          R5S5
                                       
                                    
                                    
                                       
                                          L5W5
                                       
                                       
                                          E5W5
                                       
                                       
                                          S5W5
                                       
                                       
                                          W5W5
                                       
                                       
                                          R5W5
                                       
                                    
                                    
                                       
                                          L5R5
                                       
                                       
                                          E5R5
                                       
                                       
                                          S5R5
                                       
                                       
                                          W5R5
                                       
                                       
                                          R5R5
                                       
                                    
                                 
                              
                           
                        The following steps will describe how texture energy measures are identified for each pixel in the ROI of a mammogram image.


                        
                           
                              
                                 Step 1: Apply the two dimensional mask to the preprocessed image i.e. the ROI to get F(i,
                                 j), where F(i,
                                 j) is a set of 25 N
                                 ×
                                 M features.


                                 Step 2: To generate the LTEM at the pixel, a non-linear filter is applied to F(i,
                                 j). The local neighborhood of each pixel is taken and the absolute values of the neighborhood pixels are summed together. A 15×15 square matrix is taken for doing this operation to smooth over the gaps between the texture edges and other micro-features. The non-linear filter applied is,

By applying Eq. (2), to the ROI image 25 texture energy measures for each pixel is obtained.
                           
                              
                                 Step 3: The texture features obtained from step 2 is normalized for zero-mean.

The goal of texture classification then is to produce a classification map of the input image where each uniform textured region is identified with the texture class it belongs to.

Classification has been examined in diverse fields like image processing, pattern recognition, medical imaging, etc. Pattern classification is assigning an object to one of a set of classes based upon the features of that object. The classification process mainly depends on how well the discriminant features performs and the classifier chosen. Intelligent algorithms have the ability to reason and learn in an environment of uncertainty and imprecision, soft computing, an innovative approach in constructing computationally intelligent systems. Soft computing consists of several computing paradigms including feedforward neural network which has its strength in learning from examples and adapting to changing environment [25], radial basis function [26], support vector machine [27] and wavelet neural network [28].

Wavelet Neural Networks (WNN) is an efficient model for non-linear pattern recognition [29,30]. The wavelet transformation technique is used for obtaining information from signals that are aperiodic, noisy, intermittent or transient. Wavelets have the properties of both spatial and frequency domain characteristics and hence it works well in detecting the abnormalities in mammograms. Among many artificial intelligent methods, the feedforward ANN is the widely used statistical tool designed to diagnose pathological images especially of cancers and precancers. Thus, the study will strengthen the foundation of ANN in CAD application by combining the wavelet multiscale theory and neural network and obtain a novel high performance network – wavelet neural networks. These networks are a new powerful tool for approximation and deals effectively with the problems of high dimensional model [31].

A wavelet neural network was first introduced by Zhang and Benvniste [28] as a class of feedforward networks composed of wavelets. The discrete wavelet transform is used for analyzing and synthesising feedforward neural network. The wavelet network uses wavelet activation function and preserves the universal approximation property. WNN is a feedforward neural network with an input layer, hidden layer and an output layer. The hidden layer is comprised normally of wavelets as activation function and the output layer is comprised of linear activation function. The output layer of WNN represents the weighted sum of the hidden layer units i.e. wavelet basis function. The backpropagation learning algorithm is used to update the network weights and to further minimize the standard Mean Square Error (MSE) of the networks approximation after network construction. Tuning a WNN is more important because of the following reasons,


                     Learning rate parameter, which, if not set properly, can either lead to oscillation or an indefinitely long training time.


                     Momentum constant parameter is to accelerate the convergence of error propagation algorithm. The BP is just a gradient descent algorithm on the error space, which can be complex and contain many deceiving local minima. Therefore, the BPs are most likely gets trapped into a local minimum, making it entirely dependent on initial settings.


                     Number of hidden layers and hidden neurons, determination of the optimal number of hidden layers and hidden neurons is the most critical task. An ANN will not be capable of classifying a complex set of problems with no or few hidden neurons. In contrast, if the ANN has too many neurons/layers, it eventually leads to more complex networks and can also be highly time-consuming. The optimum number of hidden nodes/layers might depend on input/output vector sizes, training and test data sizes and more importantly the characteristics of the problem.

In an attempt to improve the classification accuracy of the WNN classifier PSO is used to tune the initial network parameters. Particle Swarm Optimization (PSO) was introduced by Kennedy and Eberhart [32] as a population based stochastic search and optimization process. PSO simulates the behavior of bird flocking or fish schooling and used it to solve the optimization problems. In the basic PSO algorithm the system is initialized with a population of random solutions and searches for optima by updating positions and velocity. The potential solutions called particles fly through the problem space by following the current optimum particles. All of the particles have fitness values which are evaluated by the fitness function to be optimized, and have velocities which direct the flying of the particles. Each particle is updated after every iteration using two values pbest and gbest. pbest is the personal best value, which indicates the best solution achieved so far (i.e. lowest fitness value) and the global best solution achieved so far by any particle in the population. In a n-dimensional search space, 
                        
                           
                              
                                 
                                    
                                       X
                                    
                                    
                                       →
                                    
                                 
                              
                              
                                 i
                              
                           
                           =
                           (
                           
                              
                                 X
                              
                              
                                 i
                                 1
                              
                           
                           ,
                           
                              
                                 X
                              
                              
                                 i
                                 2
                              
                           
                           ,
                           .
                           .
                           .
                           .
                           .
                           .
                           ,
                           
                              
                                 X
                              
                              
                                 in
                              
                           
                           )
                           
                           and
                           
                           
                              
                                 
                                    
                                       V
                                    
                                    
                                       →
                                    
                                 
                              
                              
                                 i
                              
                           
                           =
                           (
                           
                              
                                 V
                              
                              
                                 i
                                 1
                              
                           
                           ,
                           
                              
                                 V
                              
                              
                                 i
                                 2
                              
                           
                           ,
                           .
                           .
                           .
                           .
                           .
                           .
                           ,
                           
                              
                                 V
                              
                              
                                 in
                              
                           
                           )
                        
                      are the positions and velocities respectively and they are updated for the dth dimension of the ith particle and is given by,
                        
                           (3)
                           
                              
                                 
                                    V
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              +
                              1
                              )
                              =
                              
                                 
                                    V
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              )
                              +
                              
                                 
                                    c
                                 
                                 
                                    1
                                 
                              
                              ·
                              
                                 
                                    rand
                                 
                                 
                                    1
                                 
                              
                              ·
                              (
                              
                                 
                                    pbest
                                 
                                 
                                    id
                                 
                              
                              -
                              
                                 
                                    X
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              )
                              )
                              +
                              
                                 
                                    c
                                 
                                 
                                    2
                                 
                              
                              ·
                              
                                 
                                    rand
                                 
                                 
                                    2
                                 
                              
                              ·
                              (
                              
                                 
                                    gbest
                                 
                                 
                                    d
                                 
                              
                              -
                              
                                 
                                    X
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              )
                              )
                           
                        
                     
                     
                        
                           (4)
                           
                              
                                 
                                    X
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              +
                              1
                              )
                              =
                              
                                 
                                    X
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              )
                              +
                              
                                 
                                    V
                                 
                                 
                                    id
                                 
                              
                              (
                              t
                              +
                              1
                              )
                           
                        
                     
                     c
                     1 and c
                     2 are the acceleration constants, rand
                     1 and rand
                     2 are the random numbers, pbestid
                      is the individual’s personal best i.e. the local best solution found so far. gbestd
                      is the neighborhood’s best solution found in the entire global community or in some neighborhood of the current particle. Vid
                     (t): Velocity of individual at iteration t, Xid
                     (t): Position of individual at iteration t, pbestid
                     : Best position of individual until iteration t, gbestd
                     : Best position of the group until iteration t.

Back propagation training is a gradient descent algorithm and is susceptible to getting trapped to the nearest local minimum. In order to find optimal network architecture for the problem under study, exhaustive back propagation training is done over every network configuration in the architecture space defined. Performing the training for larger number of times with randomized initial parameters increases the chances of converging to the global minimum of the fitness function. Even if the configuration is made to train large number of times still there is no guarantee of converging to the global optimum with the backpropagation. However a best performance configuration can be achieved in the architecture space defined by the optimality of the network evolved using a Particle Swarm Optimized Wavelet Neural Network (PSOWNN). The pseudo code for PSOWNN algorithm is as follows
                        
                           
                              
                              
                                 
                                    
                                       randomly generate initial population
                                    
                                 
                                 
                                    
                                       do
                                    
                                 
                                 
                                    
                                       for 
                                       i
                                       =1 to population_size
                                    
                                 
                                 
                                    
                                       Calculate fitness value using Eq. (6)
                                    
                                 
                                 
                                    
                                       
                                       
                                       if (F(Xi
                                       )<
                                       F(pbestt
                                       
                                       −1)) then
                                    
                                 
                                 
                                    
                                       
                                       
                                       
                                       pbestt
                                       
                                       =
                                       Xi
                                       
                                    
                                 
                                 
                                    
                                       
                                       
                                       else
                                    
                                 
                                 
                                    
                                       
                                       
                                       
                                       pbestt
                                       
                                       =
                                       pbestt
                                       
                                       −1
                                    
                                 
                                 
                                    
                                       
                                       gbestt
                                       
                                       =min(gbestneighbors
                                       )
                                 
                                 
                                    
                                       
                                       for 
                                       d
                                       =1 to dimensions
                                    
                                 
                                 
                                    
                                       
                                       Velocity update using Eq. (3)
                                    
                                 
                                 
                                    
                                       
                                       Position update using Eq. (4)
                                    
                                 
                                 
                                    
                                       
                                       end
                                    
                                 
                                 
                                    
                                       end
                                    
                                 
                                 
                                    
                                       while 
                                       maximum iterations (t) is reached
                                 
                              
                           
                        
                     
                  

In the proposed method, PSOWNN is applied for evolving fully connected wavelet neural network and is optimized with best network architecture by optimizing the number of neurons in the hidden layer, the learning rate and the momentum factor. Finding an optimal learning rate avoids major disruption of the direction of learning when very unusual pair of training patterns is presented. The main advantage of using optimal momentum factor is to accelerate the convergence of error propagation algorithm. The number of neurons in the input layer and output layer is fixed based on the problem defined.

Let NI
                      represents the number of the neurons in the input layer and NO
                      represents the number of the neurons in the output layer. The number of neurons in the input and output layer are fixed and they are same for the entire configuration in the architecture space. The number of hidden layers in this problem is restricted and made as one. The range of the optimization process is defined by two range arrays R
                     min
                     ={Nh
                     min,
                     Lr
                     min,
                     Mc
                     min} and R
                     max
                     ={Nh
                     max,
                     Lr
                     max,
                     Mc
                     max} where Nh is the number of neurons in the hidden layer, Lr is the learning rate and Mc is the momentum factor. Let f be the activation function and is given as,
                        
                           (5)
                           
                              
                                 
                                    y
                                 
                                 
                                    k
                                 
                                 
                                    p
                                 
                              
                              =
                              f
                              
                                 
                                    
                                       
                                          
                                             s
                                          
                                          
                                             k
                                          
                                          
                                             p
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           
                              
                                 s
                              
                              
                                 k
                              
                              
                                 p
                              
                           
                           =
                           
                              
                                 ∑
                              
                              
                                 j
                              
                           
                           
                              
                                 w
                              
                              
                                 j
                                 ,
                                 k
                              
                           
                           
                              
                                 y
                              
                              
                                 j
                              
                              
                                 p
                              
                           
                           +
                           
                              
                                 θ
                              
                              
                                 k
                              
                           
                           ,
                           
                           
                              
                                 y
                              
                              
                                 k
                              
                              
                                 p
                              
                           
                        
                      is the output of the kth neuron when a pattern p is fed, wj
                     
                     ,
                     
                        k
                      is the weight from the jth neuron and θk
                      is the bias value of the kth neuron in the hidden layer. The hidden layer uses a wavelet activation function and the output layer uses linear activation function. The fitness function sought for optimal training is the Mean Square Error (MSE) formulated as,
                        
                           (6)
                           
                              MSE
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       p
                                       ∈
                                       T
                                    
                                 
                              
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             o
                                          
                                       
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                t
                                             
                                             
                                                k
                                             
                                             
                                                P
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                k
                                             
                                             
                                                p
                                                ,
                                                o
                                             
                                          
                                       
                                    
                                 
                                 
                                    2
                                 
                              
                           
                        
                     where 
                        
                           
                              
                                 t
                              
                              
                                 k
                              
                              
                                 p
                              
                           
                        
                      is the target (desired) output, 
                        
                           
                              
                                 y
                              
                              
                                 k
                              
                              
                                 p
                                 ,
                                 o
                              
                           
                        
                      is the actual output from the kth neuron in the output layer o, for the pattern p in the training set. With the framed fitness function the PSOWNN algorithm automatically evolve a best solution. The optimally designed WNN has three-layer architecture: an input layer, hidden layer and an output layer. The number of neurons that structures the input layer is equal to the number of feature vectors extracted (25 LTEM). The hidden layer neurons are optimally added to the WNN and are defined by the wavelet activation function. The output layer contains one neuron which discriminates presence of abnormal and normal tissues. The neural network architecture space is defined over a multilayer perceptron with the parameters range set as R
                     min and R
                     max.

@&#EXPERIMENTAL RESULTS@&#

Clinical mammograms collected from 54 patients were used for evaluating the proposed PSOWNN classifier. The proposed system has been designed in a framework of MATLAB 7.10, which aims at developing a CAD system for breast cancer detection. After preprocessing the clinical mammograms, 25 LTEM features are extracted from each pixel of the ROI image. The data is taken from 15×15pixels from the ROI and is subjected to further analysis. The training dataset contains 1064 pairs of input–output training patterns from the mammograms of real clinical database. Table 2
                      shows the classification performance of Feedforward Neural Network (FFNN) and WNN classifiers by varying the hidden layer neurons with learning rate and momentum constant set as 0.01 and 0.9 respectively (values taken for FFNN and WNN design) using Laws texture features.

When the number of hidden layer neurons is increased there is an increase in the classification accuracy but at 140 hidden layer neurons the performance starts to degrade. This shows the importance of choosing optimal network parameters to increase the classification performance. The optimization of classifiers was performed with the learning rate and the momentum factor varied from 0 to 1 and the hidden neurons varied from 31 to 200. For this training a maximum of 100 generations are performed with a population size N
                     =50 and with 500 training epochs. These patterns contain normal, benign and malignant tissues. An optimized WNN is achieved with Nh
                     =116, Lr
                     =0.00127 and Mc
                     =0.9283. Testing is done for all the 216 real time clinical images. Masses are characterized by the margin of the mass. The mammographic border between the mass and the normal tissue is useful for predicting benign and malignant masses. Margins of a mass is described a circumscribed, obscured, ill defined and spiculated. The circumscribed masses have a well defined. Fig. 2
                      shows detection of a abnormalities in mammograms using PSOWNN classifier.

The real time mammograms are taken in varying intensities and hence detecting abnormalities in mammograms is a difficult task. Fig. 2(a) shows the original image of the breast mammogram and (b) shows the result after segmentation of ROI. Fig. 2(c) shows the detected abnormality. The most difficult to diagnose mass in mammograms are ill defined and spiculated masses. The shape of these masses are irregular and have ill defines and spiculated margins. The margins of a mass are difficult to evaluate on screening mammograms and this shows the importance of texture features in mass detection. The result shows the detection of a spiculated mass in a mammogram of a 28year old woman using the proposed classifier. Microcalcification clusters are tiny calcium deposits and these clusters that fail to demonstrate features characteristic of benignity have to be evaluated to determine for malignancy and their exact location in the breast. A mammographically significant cluster is usually considered to be 3–10 calcific particles within a volume of 1cm2. The result shows the detection result of microcalcification clusters in real clinical mammograms by considering the Laws texture features.

The results also show the detected masses in a denser mammogram. In the actual interpretation of mammographic abnormality detection, the texture features play a major role in defining microcalcification and masses. The irregular shaped clusters of masses and microcalcifications without well-defined boundaries of abnormalities are difficult to diagnose. Masses and microcalcification represent the most challenging signs characterizing the early breast cancer. Masses can become visible as dense region of unstable size varying from 3 to 30mm and properties can be characterized as circumscribed, spiculated and ill defined. The great variability of their appearance represents the main difficulty of developing a mass classification method. The mammogram images are irregular textures with subtle differences between benign and malignant tissues. Similarly, microcalcifications are tiny calcium deposits which range from 0.2 to 0.5mm. These clusters are also difficult to identify as these malignant clusters get camouflaged in the normal breast tissues and make the detection intricate. Masses are more difficult to detect than MCs because the features of a mass may be obscured by or be similar to those of normal breast parenchyma. The detection results illustrates that most of the abnormality clusters in the mammograms are correctly detected.

This section describes about the various performance measures used to analyse the potential of various classification approaches used for breast cancer detection [33]. For evaluation of detection performance, the number of True Positives (TP), False Positives (FP), True negatives (TN) and False Negatives (FN) should be taken into consideration. A true positive is considered as detected if at least one finding is located in the associated truth marking by the radiologists. All findings outside the truth marking by the radiologists are considered as false detections. In this way the true positive rate can be plotted against the false positive rate. Each decision threshold results in a corresponding operating point on the curve. Such a curve is referred as Receiver Operating Characteristic (ROC) curve. The ROC is the appropriate measure for the proposed detection system because there will be a trade-off between the true positive rate (TPR) and the false positive rate (FPR). TP, TN, FP and FN are the four different possible outcomes of a single prediction for a two-class case with classes “1” (for abnormal/malignant cases) and “0” (“for normal cases”).

Sensitivity and specificity are statistical measures of the performance of a binary classification test. Sensitivity measures the proportion of actual positives which are correctly identified when the mammogram contains cancers tissues in it. Specificity measures the proportion of negatives which are correctly identified when cancer is not present in the mammogram [34,35]. The sensitivity and specificity is given in Eqs. (7) and (8) respectively.
                        
                           (7)
                           
                              sensitivity
                              =
                              
                                 
                                    TP
                                 
                                 
                                    (
                                    TP
                                    +
                                    FN
                                    )
                                 
                              
                           
                        
                     
                     
                        
                           (8)
                           
                              specificity
                              =
                              
                                 
                                    TN
                                 
                                 
                                    (
                                    TN
                                    +
                                    FP
                                    )
                                 
                              
                           
                        
                     
                  

The area under the ROC curve (AUC or AZ
                     ) is a measure of how well a parameter can distinguish between two diagnostic groups (abnormal/normal tissues). AUC can be interpreted as the probability that the test results from a randomly chosen diseased individual is more indicative of disease than that from a randomly chosen non-diseased individual. The overall performance of diagnostic systems has been measured and reported in terms of classification accuracy which is the percentage of diagnostic decisions that proved to be correct. Youden’s index (J) [36] is a single statistic that captures the performance of a diagnostic test and is calculated as, sensitivity
                     +
                     specificity
                     −1.

There are possibilities for an automated classifier to miss certain abnormalities and may miss predict the normal cases as abnormalities, this is known as the misclassification rate. In order to investigate the usefulness of the texture features used, analysis was made for Laws texture features to determine the suitable discriminant features.

A comparative performance analysis based on ROC curve of various classifiers is shown in Fig. 3
                     . The result emphasizes the potential of the PSOWNN learning algorithm to be used as a breast cancer classifier. The classifier focuses the experimentation on trying to improve the classification rate by focussing on initial neural-network settings. Consequently, by using optimized parameter settings for wavelet neural networks the classification accuracy is improved drastically. A very high classification rate was achieved for the optimally tuned wavelet neural networks.

The performance evaluation demonstrates that the result of the optimized wavelet neural network classifier is generally better than that of other well known classifiers. This is consistent with the fact that optimization is useful in initial parameter setting of the network. The result shows that the best area under the ROC curve is found to be 0.96853 for real clinical Database. The PSOWNN approach generates a sensitivity of 94.167% with a specificity of 92.105%. The misclassification rate is found to be 0.063291 which is less when compared with the classification done by other classifiers. When optimized learning is introduced, there is an improvement in classification accuracy which is 93.671%. Therefore, PSOWNN have a great potential to be applied in automatic detection of abnormalities in mammograms by reducing the misclassification rate.

The performance measures of the optimally tuned wavelet neural network classifier in comparison with the other classifiers are presented in Table 3
                     . Summarizing the results for real clinical mammogram the classification accuracy of PSOWNN is higher than that of the other well known classifier models. This is because of the fact that the PSOWNN incorporates the wavelet neural network and optimally designs the neural network using swarm intelligence algorithm. This superior performance makes PSOWNN suitable for efficiently detecting abnormalities in mammograms.

@&#CONCLUSION@&#

The novel approach presented in this paper demonstrated that the PSOWNN classifier produces an improvement in classification accuracy to the problem of computer-aided analysis of digital mammograms for breast cancer detection. The algorithm developed here classifies mammograms into normal & abnormal. First, the ROI of the image is chosen then laws texture features are extracted and classified using PSOWNN. The optimized WNN based classifiers using the properties of both wavelet and neural network provide good classification accuracy by reducing the false positives and false negatives. The PSOWNN classifier designed using PSO algorithm applied to WNN is investigated for detecting breast cancer in mammograms. The results give better classification accuracy than the traditional classifiers. The optimized wavelet neural network accelerates the convergence of the error back propagation algorithm and also it avoids major disruptions in the direction of learning.

@&#REFERENCES@&#


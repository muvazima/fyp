@&#MAIN-TITLE@&#Object tracking via collaborative multi-task learning and appearance model updating 

@&#HIGHLIGHTS@&#

@&#KEYPHRASES@&#

Visual tracking

Particle filter

Sparse representation

Appearance modeling

Multi-task learning

@&#ABSTRACT@&#


               Abstract
               
                  In this paper, we propose a novel visual tracking algorithm using the collaboration of generative and discriminative trackers under the particle filter framework. Each particle denotes a single task, and we encode all the tasks simultaneously in a structured multi-task learning manner. Then, we implement generative and discriminative trackers, respectively. The discriminative tracker considers the overall information of object to represent the object appearance; while the generative tracker takes the local information of object into account for handling partial occlusions. Therefore, two models are complementary during the tracking. Furthermore, we design an effective dictionary updating mechanism. The dictionary is composed of fixed and variational parts. The variational parts are progressively updated using Metropolisâ€“Hastings strategy. Experiments on different challenging video sequences demonstrate that the proposed tracker performs favorably against several state-of-the-art trackers.
               
            


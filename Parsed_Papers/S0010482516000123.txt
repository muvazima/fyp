@&#MAIN-TITLE@&#Parallel scheme for real-time detection of photosensitive seizures

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Healthy viewing.


                        
                        
                           
                           Real-time detection of hazardous video content for photosensitive seizures.


                        
                        
                           
                           Multicore parallel computation.


                        
                        
                           
                           Seizure pattern inducer testing benchmark.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Health safety

Multicore parallel processing

Pattern recognition

Photosensitivity

Photosensitive epilepsy

Real-time video streaming

@&#ABSTRACT@&#


               
               
                  The production and distribution of videos and animations on gaming and self-authoring websites are booming. However, given this rise in self-authoring, there is increased concern for the health and safety of people who suffer from a neurological disorder called photosensitivity or photosensitive epilepsy. These people can suffer seizures from viewing video with hazardous content. This paper presents a spatiotemporal pattern detection algorithm that can detect hazardous content in streaming video in real time. A tool is developed for producing test videos with hazardous content, and then those test videos are used to evaluate the proposed algorithm, as well as an existing post-processing tool that is currently being used for detecting such patterns. To perform the detection in real time, the proposed algorithm was implemented on a dual core processor, using a pipelined/parallel software architecture. Results indicate that the proposed method provides better detection performance, allowing for the masking of seizure inducing patterns in real time.
               
            

@&#INTRODUCTION@&#

More than 50 million people worldwide suffer from epilepsy, making it the second most prevalent neurological disorder [1]. About 3–5% of those people have a particular form of epilepsy (called photosensitivity or photosensitive epilepsy) in which seizures can be evoked visually by high temporal contrast, high spatial contrast, or even particular colors. For these people, common stimuli, such as flashing emergency lights, flickering fluorescent lights, or lights seen through the blades of a moving ceiling fan can be hazardous. Another possible source of high-contrast spatiotemporal stimuli is viewed video [32].

With the dramatic advances in digital information technology over the last two decades, video has become an increasingly dominant type of content transported across the worldwide web (For example, see YouTube [2]). Video streaming now accounts for about 68% of the downstream data traffic during peak periods, and it is expected to continue rising in the coming years [3].

In addition, more and more of the video content being streamed over the web is being self-published, and is not always scrutinized, before being published, for compliance with video safety standards using video post-processing tools such as the Photosensitive Epilepsy Analysis Tool 
                     (PEAT) 
                     [4].

While photosensitivity has gained a lot of attention in neurology, as well as in multimedia research fields, there has not been adequate research done toward the development of real-time hazardous pattern detection, for use on video that is streamed from Internet video servers. This is important for both PC and game consoles users, to assure that the observed videos/games do not induce harmful seizures.

Game consoles such as Xbox, Play Station, and Steam box encourage freelancers and indie game developers to develop and publish their own content through webstores. In addition, several games, such as Minecraft and Little Big Planet, allow users to develop their own game stages and environments, and then share them with other game users. Many active gaming communities develop customized modifications to games (known as mods) that extend and augment the features provided by the original games [5].

All of these unprecedented abilities to self-publish both videos and videogames increase the possibility of distributing malicious or unintended hazardous video content that might induce seizures in people with photosensitivity. Since there is no mechanism for the enforcement of any governing restrictions on such multimedia content, there is little, if any, enforcement at all [6]. This leads to health and safety concerns for those who suffer from photosensitivity. One famous example was an episode of the cartoon Pokémon, which was broadcast in 1997, which induced seizures and affected thousands of Japanese children [7].

One of the main challenges in working with photosensitivity is that most people are not aware that they are vulnerable to this type of seizure until they either experience it, or they undergo a specialized epilepsy test involving an electroencephalogram (EEG) test, under the supervision of a neurologist [8].

These factors have motivated not just scientists and media specialists, but even law makers in recent years have taken actions (a) to increase public awareness of the problem, (b) to suggest research to better understand the types of content that evoke seizures, and (c) to institute regulations to reduce the risk of seizures while playing video games [29].

Most of the published research conducted to identify the types of content that evoke seizure in those with photosensitivity has been done by neurologists, who have employed one of two different methodologies. The first methodology surveys patients with photosensitivity, in an attempt to discover what types of spatiotemporal patterns tend to evoke seizures [9–13]. The second methodology employs EEGs that are recorded during intermittent photic stimulation (IPS), to identify photoparoxysmal responses (PPR) [8,14–17]. Some of the research done using these two methods has suggested some practical solutions to photosensitivity, such as the use of optical filters or colored glasses [18,19].

Additional published research has been conducted by multimedia researchers, who tend to focus on identification of spatiotemporal video characteristics that might evoke seizures in people with photosensitivity [6,20–25]. Based on video characteristics identified by this methodology, guidelines and standards have been developed. However, not enough research has been done toward the development of software tools to identify such characteristics in recorded videos [4]. What is needed are tools that can analyze streaming video in real time, to filter out any content that might trigger seizures.

This paper proposes a pipelined/parallel scheme for identifying seizure inducing patterns during real-time video streaming. The paper compares the performance of the proposed method with the PEAT post-processing tool [4] which is used for detecting such patterns in recorded videos. The experimental results show that the proposed method is able to provide accurate identifications of the seizure inducing patterns in real time. This paper includes the following contributions:
                        
                           •
                           
                              Real-Time Detection: The proposed method detects seizure inducing patterns in streaming video in real time.


                              Multicore Parallel Computation: The proposed method harnesses parallelism in multicore hardware, to meet real time requirements, and to achieve better performance.


                              Pattern Inducer: To evaluate the proposed method, a set of testing benchmarks is developed, in the form of video clips with spatiotemporal patterns that have the potential to induce seizures. These benchmarks can be used to provide a ground truth for this type of work.

This paper is organized as follows: Section 2 surveys the existing work done in Photosensitivity. Section 3 describes the system architecture and its main components. Section 4 describes the implementation details of the system. Section 5 conducts the evaluation experiments, and provides comparisons of the results. Section 6 proposes a parallel scheme for real-time detection of the seizure inducing patterns. The paper is concluded in Section 7.

@&#LITERATURE REVIEW@&#

There has been a considerable amount of published research on photosensitivity, by both neurologists and multimedia researchers. However, research has not yet focused on the problem of preventing seizures caused during real-time video streaming of untested video. This section reviews the existing research on photosensitivity in neurology, as well as in the multimedia field.

Ishiguro et al. [9] used a questionnaire to conduct follow-up surveys 1 and 3 years after the incident in which epileptic patients had seizures while watching an animated cartoon TV program “Pocket Monster” in 1997. The study showed that more than two thirds of those who had seizures during the incident had no seizures during the subsequent 3 years. Ishida et al. [10] also studied the incident of watching the animated cartoon TV program “Pocket Monster”. That study investigated the clinical symptoms of 4 patients who experienced seizures while watching the program. Shiraishi et al. [11] examined the distribution of epilepsy patients for (a) different ages, (b) different types of epilepsies and epileptic syndromes, and (c) different ethnic and geographical groups. The study found that the rate of photoparoxysmal responses (PPR) in eastern Asia was relatively low, compared to the studies performed in European countries. Further, it showed that there is a measureable relationship between the subject’s age and positive PPR.

Prasad et al. [12] discussed the effects of 3D television and cinema in triggering seizures in patients with photosensitivity, and contrasted it with 2D movie risks. In general, that study did not find anything new to 3D television, compared to conventional 2D television. The paper׳s discussion section includes some suggestions for minimizing the risk of seizures, which could be used by neurologists when advising their patients.

Wilkins et al. [13] summarized the different methods used to study the physiology of human visual sensitivity, including (a) the study of the physical characteristics of the trigger, (b) the study of the topographic distribution and probability of the PPR to elementary visual stimuli, and (c) the use of Visual Evoked Potentials (VEPs) to characterize the mechanisms of control of cortical excitability below the critical levels that trigger paroxysmal activity.

Guerrini and Genton [14] reviewed the clinical characteristics of the different types of photosensitivity, and the main epileptic syndromes. While this study identified the various seizure types triggered by visual sensitivity, it did not characterize the causes of such sensitivity. The study stated that rapid changes in color are believed to be responsible for the photosensitive seizures. In a later study, Trenite identified various variables that contribute to the photosensitivity. he called for defining a standardized methodologies that take into consideration these variables [33].

Lopes da Silva and Harding [15] investigated whether changes in neuronal activity preceding the transition to an epileptic PPR can be detected. Significantly, this work defined an index of the pre-ictal transition to seizures in photosensitivity. The index, called the relative Phase Clustering Index (rPCI), is computed from human EEG signals.

Smith [8] discussed the areas in which interictal and ictal EEG are useful in epilepsy diagnosis and management. Kasteleijn-Nolst Trenité et al. [16,17] developed a new algorithm for visual stimulation in the EEG laboratory, with the aim of standardizing the intermittent photic stimulation (IPS) procedure used to identify seizures. Their proposed algorithm consists of several steps.

Takahashi et al. [18] suggested compound filters composed of two different types of optical filters that can inhibit two identified mechanisms for the PPR. The first filter reflects the long-wavelength red light that can evoke a wavelength-dependent seizure response, and the other filter absorbs light across the visible spectrum evenly, which can evoke a quantity-of-light–dependent seizure response. The study found that both filters individually inhibited PPR insufficiently.

Wilkins et al. [19] designed an open trial to ascertain whether colorimetry assessment is safe for the investigation of photosensitive patients in optometry clinics, and what portion of patients with photosensitivity is likely to benefit to the extent already described in individual cases. The trial showed that colored glasses may provide relief from seizures in some patients with photosensitivity. They might also have other beneficial effects, such as a reduction of symptoms of discomfort.

Harding and Harding [20] investigated in the laboratory 2 sources of seizure stimuli: Flash stimuli and Pattern stimuli. For the Flash stimuli experiment, they found that most patients were sensitive when the flash rate was between 13 and 21 per second. The authors cited other studies by Harding et al. [21] that show light luminance is more important than its color. However, in yet another study by Takahashi and Tsukahara [22], long wavelength red light was shown to be more provocative – even at low luminance. For the pattern stimuli, the authors cited a previous study by Wilkins [23] in which the spatial and temporal characteristics of patterns that induce PPRs have been studied. It has been shown that, when square wave patterns consist of light and dark bars of equal width, visual sensitivity is greatest.

Fisher et al. [24] listed many factors (and their specifications) that increase the likelihood of seizures, including: flash frequency, brightness, contrast, distance between the viewer and the light source (which determines the total area of the retina receiving stimulation), location of the stimulation within the visual field, wavelength of the light, and the viewer׳s open or closed eyes. The paper also emphasized the sensitivity of some patients to particular spatial patterns, even when there is no flicker.

Wilkins et al. [6] characterized the triggering factors in screen images, and used these details to develop broadcast standards for the UK and Japan, which are now used to reduce the risk of seizures. Wilkins et al. [25] demonstrated that existing LED lighting technologies might provide flicker at frequencies that may induce biological effects, and discussed a few methods to mitigate such unintentional effects of LED lighting.

As a result of these researches, there are downloadable software tools that can be used for estimation of the seizure potential in videos during the post-processing stages. For example, the Photosensitive Epilepsy Analysis Tool (PEAT) [4] can be used to identify seizure risks in videos or animations, and the commercial Harding Flash and Pattern Analyser (FPA) [30] that can be used for more sophisticated post-processing tests of any audio–visual material.

Nomura et al. proposed a post-processing method, called Adaptive Temporal Filtering (ATF) [31], in which the authors recorded problematic Pokemon scenes, and used their ATF to filter the hazardous content of the recorded scene. Both the original, problematic scenes and the filtered scenes were presented to 11 patients on a display to monitor their EEG responses. The results showed that their method was able to remove the hazardous content from the problematic scenes.


                        
                        Table 1 summarizes the techniques proposed to deal with photosensitivity, and divides these techniques into optical and digital solutions. Optical techniques are physical solutions, while Digital techniques are software solutions. Digital solutions have the advantage of being applicable to a wider range of consumer electronics, and faster distribution of possible future improvements through software updates. For example, Shin et al. [26] developed a real-time user rating of the streaming TV content. Real time digital systems are stricter in terms of processing constraints, but provide just-in-time filtering solutions for video streamed from the Internet.

This section describes the basic modules used to construct the proposed system, and the overall system’s functionality. 
                     Fig. 1 shows the overall system architecture. The system is comprised of three basic modules: the Frames Capture module that intercepts the video frames to be displayed on the screen, a 3-part Computation module that processes the video frames and detects a hazardous flashing sequence, and an Alert System module that notifies the user when a hazardous flashing sequence is detected.

The proposed system intercepts the video frames that are to be displayed on a monitor. Upon capturing the video frames, the system performs two checks: a Luminance Flash check and a Saturated Red check. These two checks (as discussed later) determine whether the screen is showing one or more flashing patterns that might cause a seizure for the viewer. If the total area of all flashing patterns is ≥1/4 of the viewing area, the alert system is triggered.

The modularity of the system allows the function of its three basic modules to be customized, depending on the operating system and the intended application. For instance, the Alert System might be used to simply display an alert message, or blank a portion of the screen, or do something more comprehensive, such as system logging, parental notification, or even a full system shut down.

With the advent of advanced gaming systems such as Xbox and Play Station consoles, and the advent of smart TVs and other advanced TV-related gadgets such as Chromecast [27], the feasibility of implementing the proposed digital system increases, as these digital devices can be connected with other software and hardware modules, using standard I/O ports.

As a proof of concept, the proposed 3-module architecture was implemented as an embedded system device that accepts (and delivers) a video stream through an HDMI port. This permits the system to intercept HDMI video output from PCs, TV receivers, DVD/BluRay players, and game consoles. The system design (shown in 
                     Fig. 2) consists of the embedded device that intercepts the HDMI video stream from the originating device, and outputs a processed version of that stream to another HDMI port for display. The intercepted video stream frames are analyzed in real time, to determine whether a specific seizure inducing sequence is present. If such a sequence is present, the outputted video frames are replaced with a warning message for the duration of the sequence. Otherwise, the video frames are passed to the output without modification.

According to the W3C standard [4], there are two main types of features (i.e. visual stimuli) that might induce seizures in people with photosensitivity: flashing/flickering and repeating patterns. However, since sensitivity to flashing is more prevalent than sensitivity to repeating patterns, this paper tackles the types of seizures that are only triggered by flashing.

Flashing occurs when a light switches between dark and light values, with respect to its luminance. Restrictions are placed on some flashing characteristics that might precipitate seizures, such as the frequency of flash, dramatic changes in luminance, the spatial area of flashes, and color (saturated red, or alternating red and blue background).

This section describes these restrictions, and provide an algorithmic description (in the form of pseudo-code) for the detection techniques that the proposed system implements.

A Luminance Flash is a sequence of two transitions between two different colors that have a significant luminance difference. Presenting Luminance Flashes at a frequency greater than three flashes per second is prohibited, as it might cause seizures. To protect viewers from such seizure inducing sequences, there is a need to ensure that no substantial region within the video content flashes more than three times in any one-second period. Some examples of inducing sequences during a period of one second might be:
                           
                              
                                 
                                    D
                                    →
                                    L
                                    →
                                    D
                                    →
                                    L
                                    →
                                    D
                                    →
                                    L
                                    →
                                    D
                                    →
                                    L
                                 
                              
                           
                        
                     

or
                           
                              
                                 
                                    L
                                    →
                                    D
                                    →
                                    L
                                    →
                                    D
                                    →
                                    L
                                    →
                                    D
                                    →
                                    L
                                    →
                                    D
                                 
                              
                           
                        where D stands for Dark and L stands for Light. This pattern has seven transitions, causing 3.5 flashes per second.

The standard formally defines a Luminance Flash in terms of Relative Luminance. A Luminance Flash is a temporal transition with a change in Relative Luminance of 10% of their maximum value, where the Relative Luminance of the minimum (darker color) is below 0.8 on a full scale of 1.0. The luminance calculation is based on the relative color values of three color components. The 3-dimensional color space used for this purpose is referred to as sRGB, where the main color components are referred to as Rs, Gs, and Bs and are defined in (1), (2), and (3), respectively,
                           
                              (1)
                              
                                 
                                    R
                                    s
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  R
                                                               
                                                               
                                                                  ¯
                                                               
                                                            
                                                         
                                                         
                                                            12.92
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                         h
                                                         e
                                                         n
                                                      
                                                      
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      ≤
                                                      0.03928
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               
                                                                  
                                                                     (
                                                                     
                                                                        
                                                                           R
                                                                        
                                                                        
                                                                           ¯
                                                                        
                                                                     
                                                                     +
                                                                     0.055
                                                                     )
                                                                  
                                                                  
                                                                     1.055
                                                                  
                                                               
                                                            
                                                            )
                                                         
                                                         
                                                            2.4
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      o
                                                      t
                                                      h
                                                      e
                                                      r
                                                      w
                                                      i
                                                      s
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    G
                                    s
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  G
                                                               
                                                               
                                                                  ¯
                                                               
                                                            
                                                         
                                                         
                                                            12.92
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                         h
                                                         e
                                                         n
                                                      
                                                      
                                                      
                                                         
                                                            G
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      ≤
                                                      0.03928
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               
                                                                  
                                                                     (
                                                                     
                                                                        
                                                                           G
                                                                        
                                                                        
                                                                           ¯
                                                                        
                                                                     
                                                                     +
                                                                     0.055
                                                                     )
                                                                  
                                                                  
                                                                     1.055
                                                                  
                                                               
                                                            
                                                            )
                                                         
                                                         
                                                            2.4
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      o
                                                      t
                                                      h
                                                      e
                                                      r
                                                      w
                                                      i
                                                      s
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    B
                                    s
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  B
                                                               
                                                               
                                                                  ¯
                                                               
                                                            
                                                         
                                                         
                                                            12.92
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                         h
                                                         e
                                                         n
                                                      
                                                      
                                                      
                                                         
                                                            B
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      ≤
                                                      0.03928
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               
                                                                  
                                                                     (
                                                                     
                                                                        
                                                                           B
                                                                        
                                                                        
                                                                           ¯
                                                                        
                                                                     
                                                                     +
                                                                     0.055
                                                                     )
                                                                  
                                                                  
                                                                     1.055
                                                                  
                                                               
                                                            
                                                            )
                                                         
                                                         
                                                            2.4
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      o
                                                      t
                                                      h
                                                      e
                                                      r
                                                      w
                                                      i
                                                      s
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              R
                              
                                 ¯
                              
                           
                        = R/255, 
                           
                              G
                              
                                 ¯
                              
                           
                        = G/255, and 
                           
                              B
                              
                                 ¯
                              
                           
                        = B/255.

The Relative Luminance (Ls) for a color is then computed according to (4).
                           
                              (4)
                              
                                 
                                    L
                                    s
                                    =
                                    (
                                    0.2126
                                    ×
                                    R
                                    s
                                    )
                                    +
                                    (
                                    0.7152
                                    ×
                                    G
                                    s
                                    )
                                    +
                                    (
                                    0.0722
                                    ×
                                    B
                                    s
                                    )
                                 
                              
                           
                        
                     

A temporal pattern having more than three Saturated Red Flashes per second is prohibited. A Saturated Red Flash is defined as two transitions, where each transition switches between two states of colors, such that the following two conditions are satisfied: (a) for either or both states in each transition the RedRatio is greater than or equal to 0.8 and (b) the change in PureRed values of the two states in both transitions is greater than 20, where RedRatio and PureRed are defined in (5) and (6) respectively.
                           
                              (5)
                              
                                 
                                    
                                       
                                          Red
                                       
                                       
                                          Ratio
                                       
                                    
                                    =
                                    
                                       
                                          R
                                          s
                                       
                                       
                                          R
                                          s
                                          +
                                          G
                                          s
                                          +
                                          B
                                          s
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       PureRed
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      (
                                                      R
                                                      s
                                                      −
                                                      G
                                                      s
                                                      −
                                                      B
                                                      s
                                                      )
                                                      ×
                                                      320
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                         h
                                                         e
                                                         n
                                                      
                                                      
                                                      R
                                                      s
                                                      >
                                                      (
                                                      G
                                                      s
                                                      +
                                                      B
                                                      s
                                                      )
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      o
                                                      t
                                                      h
                                                      e
                                                      r
                                                      w
                                                      i
                                                      s
                                                      e
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Having flashes (both Luminance Flashes and Saturated Red Flashes) with an area more than 1/4 of the viewed screen area is prohibited. However, the viewed area depends upon the distance from which the screen is viewed. To ensure compliance over a range of viewing distances, there was a need to ensure that no region of the video frame that might fill ≥10° of the viewer׳s visual field contains more than 25% flashing pixels.

Viewing distances typically range from 22 to 26in. A typical 15-in. display (12w×9h) with a pixel count of 1024×768 has a pixel density of about 85 pixels/inch. A 10° viewing angle at a distance of 24in. from the screen spans about 4.23in. or about 361 pixels. In this example, to detect any flashes that span a visual angle ≥10°, there is a need to make sure that the total number of flashing pixels within any (361×361)= 130,321 pixel region of the screen is not greater than 32,581.

The pseudo-code of the detection algorithm described above is presented in 
                        Fig. 3, and the corresponding block diagram is shown in 
                        Fig. 4. In short, once the number of frames captured is sufficient to detect a seizure triggering temporal pattern (which requires at least 8 frames) a FrameSlidingWindow, or F, of eight frames that slides one frame at a time is established. Within each frame a 2D window, S, of size 10° visual field is established, which slides one pixel at a time over the face of each frame. For each pixel location of S, PixelLocationArray is formed and the required computations are done on it to check for Luminance Flashes and Saturated Red Flashes. If the number of flashing pixels, i.e. the flashing area, does not exceed 1/4 of the S area, the algorithm exits, indicating that no seizure danger is detected. Otherwise, if the flashing areas in any of the S windows exceed 1/4 of the window area, a seizure danger is detected in the current F, and an alert is triggered.

Of course, the 10° visual field area depends on the viewing distance, which might vary. If a viewing distance of 24in. is chosen to compute S, the algorithm shown in Fig. 3 detects all flashing epilepsy seizure hazards that would be present if the viewer is ≤24in. from the screen. If the viewer is more than 24in. from the screen, the 10° would include a larger portion of the screen. If the viewer is far enough away, it might even encompass the entire screen. However, there will never be over 1/4 of the pixels flashing on the entire screen, unless there is also at least one smaller S region containing over 1/4 flashing pixels. Of course, having a single S region with over 1/4 flashing pixels does not guarantee that 1/4 of all screen pixels are flashing. So, the algorithm might produce an occasional false alarm. However, that is preferable to missing a potential hazard.

This section develops a testing methodology to evaluate the performance of the implemented method, in comparison with an academic standard tool, namely PEAT [4], developed by the Trace Research and Development Center at the University of Wisconsin-Madison. First, a set of videos is generated using a range of characteristics that might cause seizures. Then these videos are tested using the PEAT tool and the proposed real-time method. For each method, a confusion matrix that describes the performance of that method is generated. Using the generated confusion matrices, different performance metrics such as Accuracy, Recall, Precision, F-measure, and miss-rate can be calculated.

The experiment was run on an Intel core i3 windows machine with two physical cores, and employs the Intel Hyper-Threading Technology (HTT) in which each core offers two hardware threads or logical cores. This architecture improves performance for multithreaded code, because the threads can take advantage of Simultaneous Multithreading (SMT). Each physical core runs at 3.0GHz, and the total RAM installed on the system is 4.0 GB.

There are video materials, which have been known to cause seizures, available on the internet (basically form Youtube). Preliminary test to the proposed methods is done against these videos. Nevertheless, one of the problems in the area of photosensitivity research is the lack of a standard database of videos that can be used to compare different proposed detection algorithms. To solve this problem, this work developed, as part of the contribution in this article, a video generation tool, which is called the Pattern Inducer. It generates videos with content that might induce seizures, according to the features discussed in Section 4. Those features are: (a) flashing rate, (b) flashing area vs viewed area, (c) location of the flashing area within the viewed area, and (d) flashing duration.

The Pattern Inducer can set these features to various values, and generate sets of test videos accordingly. It will be made freely available to all researchers, to facilitate the generation of test videos for their proposed algorithms. (Access to the tool and the test videos will be granted upon request.)


                        
                        Table 2 shows the feature values that were used in designing the test videos. Three flashing frequency rates (5, 4, and 3Hz) were chosen. These values were chosen because only flashing rates ≥3.5Hz tend to cause seizures. For the flashing area, 4 sizes were chosen, ranging from 1/8 screen to a full screen – doubling each size. As for the flashing area location, the tool was run 4 times to generate 4 random flashing area locations. (Note that full size areas were generated for only one location.) The flashing area duration was set to 15s. This results in 39 video scenarios. These scenarios were used to generate Luminance Flash videos as well as Saturated Red Flash videos, resulting in 2 sets of 39 test videos.

For the Luminance Flash, alternating black (RGB values of 0, 0, 0) and white (RGB values of 255, 255, 255) colors were used. These RGB values result in Relative Luminance values of Ls
                        1=0 and Ls
                        2=1. Since Ls
                        1<0.8, 10% of max (Ls
                        1, Ls
                        2)=0.1, and Ls
                        1−Ls
                        2<10% of the max, these color values satisfy the Luminance Flash requirements.

Saturated Red Flash colors that satisfy the Saturated Red Flash requirements, but do not satisfy the Luminance Flash requirements, were chosen. For this purpose two alternating red colors (RGB
                        1=255, 0, 0 and RGB
                        2=245, 0, 0) were used. Applying the Luminance Flash requirements to these values found that the Relative Luminance values are Ls
                        1=0.2126 and Ls
                        2=0.1941. Since Ls
                        2<0.8, 10% of max (Ls
                        1, Ls
                        2)=0.02126, and Ls
                        2−Ls
                        1 is not less than 10% of the max, these color values do not satisfy the Luminance Flash requirements. However, applying the Saturated Red Flash requirements to these values found that the (Rs, Gs, Bs) values for RGB
                        1 are (1, 0, 0) and for RGB
                        2 are (0.9131, 0, 0), the RedRatio value for RGB
                        1 is 1 and for RGB
                        2 is 1, and the PureRed value for RGB
                        1 is 320 and for RGB
                        2 is 292.19. Since RedRatio is ≥0.8 and the change in PureRed (27.81) is greater than 20, these color values do satisfy the Saturated Red Flash requirements. After generating these videos, they were tested using the PEAT tool and the proposed method.

The PEAT tool as well as the proposed method was run on the two sets of 39 testing videos, and the result of each method on each video was recorded as one of the following:
                           
                              1.
                              True Positive (TP): This means that the method classified the test video as having a seizure hazard, and that classification was correct.

True Negative (TN): This means that the method classified the test video as having no seizure hazard, and that classification was correct.

False Positive (FP): This means that the method classified the test video as having a seizure hazard, but that classification was incorrect.

False Negative (FN): This means that the method classified the test video as having no seizure hazard, but that classification was incorrect.

The experimental results are shown in 
                        Table 3. It shows the results for the (a) PEAT, (b) Serial, and (c) Pipelined/Parallel methods, alongside the Pattern Inducer Ground Truth. Wherever a result was not in agreement with the ground truth, it is shown in bold. (Notes: (1) The experiments showed the same results for both the Luminance Flashes and Saturated Red Flashes, so they were combined into one table. (2) At this point, the focus is on the Serial method results. In the Serial method the processing of each frame window is done sequentially. The Pipelined/Parallel method and the distinction between the two are presented later in Section 6. However, for comparison, the results of the parallel method is presented together with the serial method in Table 3, 
                        Fig. 5, and 
                        Table 4)

The classification results (TP, TN, FP, FN) are presented in the form of a confusion matrix for each method. The confusion matrices for the PEAT tool and for both of the proposed methods are shown in Fig. 5.

Using these confusion matrices, the following performance metrics were computed:
                           
                              1.
                              Accuracy=(TP+TN)/(TP+TN+FP+FN)

Recall or Sensitivity or True Positive Rate (TPR)=TP / (TP+FN)

Precision or Positive Predictive Value (PPV)=TP / (TP+FP)

F-measure=2*Precision*Recall/(Precision+Recall)

Miss-rate or False Negative Rate (FNR)=FN/(TP+FN)

According to the first equation, the true negatives (TNs) raise the Accuracy. However, in this application the True Negatives are less important than the True Positives (TPs). Therefore, this paper uses the Precision and Recall measures, which are both independent of the True Negatives. The F-measure is a measure of performance that takes into account both Precision and Recall, and its value is one indicator of the ability of the method to correctly detect hazardous video content.

However, a seizure might still result if the method falsely classifies hazardous content as safe (i.e. it generates a False Negative (FN)). For this reason, the miss-rate (or False Negative rate) is also computed. While high values for the Accuracy, Recall, Precision, and F-measure are desirable, it is also vital to have a low miss-rate. A summary of the performance metrics is shown in Table 4.

The results presented in Table 4 show that the PEAT method has a low F-measure, when compared to its Accuracy. This is due to the low Recall value. The results also show that the PEAT method has a 50% chance to miss a hazardous pattern that might cause a seizure. In summary, the PEAT method flagged substantially more hazardous frames than normal ones, but still failed to detect many hazardous frames. This result suggests that the proposed Pattern Inducer provides a good testing platform that is able to objectively measure the performance of existing methods (such as the PEAT method) and to show where there is a room for improvement in these methods.

The results also showed that the performance of the serial method is bad, as it missed all hazardous frames in all videos. Moreover, the serial method was also tested on the video materials known to cause seizures, and showed bad performance as well. A closer examination showed that processing each frame window sequentially took too much time (around 53ms compared to the frame rate of 1/30 or 33.33ms), causing the serial detection algorithm to miss seizure inducers. Obviously, there was a need to speed up the processing time of frame windows. This was done by employing pipelined and parallel processing. The next section describes this method.

This section presents a pipelined/parallel implementation of the detection algorithm, which employs the Task Parallel Library (TPL) of the C# programming language [28]. In the block diagram of the developed algorithm, shown in Fig. 4, there are two main blocks that can run in parallel: FrameSlidingWindow and PixelLocationArray.

The FrameSlidingWindow block can be parallelized, allowing multiple 8-frame sliding windows to be formed and computed concurrently. Inside each sliding window, the PixelLocationArray block can also be parallelized, allowing 8 pixel location arrays (one from each frame) to be formed and computed concurrently.

This type of parallelism is considered a data-level parallelism, where different types of data processing (sliding windows or pixel arrays) are done in parallel. 
                     Fig. 6 depicts the two levels of parallelization. Note that the processing of various pixel arrays also includes processing tasks such as computing PureRed, RedRatio, and Ls values – also in parallel, but this is considered a task-level parallelism.

While several parallelization opportunities are shown in Fig. 6, implementing the parallelism as shown with the limited number of logical cores did not achieve adequate speedup. In fact, the reprocessing of each 8-frame sliding window (as it moves forward one frame at a time) is very inefficient. In fact, 7 of the 8 frames in sequential sliding windows include redundant pixel computations, as each window slides by only one frame. Using pipelined processing to eliminate such redundant computations provides an additional performance improvement.

Thus, this implementation limits the parallelization to the PixelLocationArray level, and uses pipelined processing on the sliding windows to eliminate the redundant computation. 
                     Fig. 7 shows the proposed pipelined/parallel implementation of the detection algorithm, where the processing of sequential sliding windows is pipelined, but the processing of the different pixel location arrays within each single sliding window is parallelized. This scheme includes both data-level and task-level parallelism.

This work implemented the proposed pipelined/parallel scheme (shown in Fig. 7) which was initially tested on the video materials known to cause seizures and showed notable improvement over the serial method. The pipelined/parallel method was then employed on the 39 test videos. The results presented in Table 4 showed that the pipelined/parallel version of the proposed method outperforms both the PEAT and the serial methods. This is because the pipelined/parallel computation is able to better take advantage of the multiple logical cores provided by the microprocessors, thus speeding up the frame processing time.

@&#CONCLUSIONS@&#

This paper proposed a pipelined/parallel method for detecting video content that might induce seizures in people with photosensitivity during real-time video streaming. It also developed a testing platform called the Pattern Inducer, which automatically generates test videos that include video content that could potentially induce seizures. These test videos were then be used to evaluate and compare methods for detection, and showed that the proposed pipelined/parallel method outperformed PEAT in detecting seizure inducing patterns, even when done in real time.

@&#REFERENCES@&#


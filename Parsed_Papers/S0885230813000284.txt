@&#MAIN-TITLE@&#Ranked WordNet graph for Sentiment Polarity Classification in Twitter

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           The purpose of this article is to present a novel approach to Sentiment Polarity Detection in Twitter posts.


                        
                        
                           
                           We propose a non-supervised and domain-independent solution to Sentiment Analysis in Twitter.


                        
                        
                           
                           The method combines SentiWordNet scores with a random walk analysis of the concepts found in the text over the WordNet graph.


                        
                        
                           
                           Several experiments have been performed in order to compare them with other approaches like machine learning solutions.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Sentiment Analysis

Opinion Mining

Unsupervised method

Twitter

PageRank

SentiWordNet

Polarity classification

@&#ABSTRACT@&#


               
               
                  This paper presents a novel approach to Sentiment Polarity Classification in Twitter posts, by extracting a vector of weighted nodes from the graph of WordNet. These weights are used in SentiWordNet to compute a final estimation of the polarity. Therefore, the method proposes a non-supervised solution that is domain-independent. The evaluation of a generated corpus of tweets shows that this technique is promising.
               
            

@&#INTRODUCTION@&#

The birth of Web 2.0 supposed a breaking down of the barrier between the consumers and producers of information, i.e. the Web has changed from a static container of information into a live environment in which any user, in a very simple manner, can publish any type of information. This simplified means of publication has led to the rise of several different websites specializing in the publication of users opinions. Some of the most well-known sites include Epinions,
                        1
                     
                     
                        1
                        
                           http://epinions.com.
                      RottenTomatoes
                        2
                     
                     
                        2
                        
                           http://rottentomatoes.com.
                      and Muchocine,
                        3
                     
                     
                        3
                        
                           http://muchocine.net.
                      where users express their opinions or criticisms on a wide range of topics. Opinions published on the Internet are not limited to certain sites, but rather can be found in a blog, forum, commercial website or any other site allowing posts from visitors.

One of the most representative tools of the Web 2.0 are social networks, which allow millions of users to publish any information in a simple way and to share it with their network of contacts or “friends”. These social networks have also evolved and become a continuous flow of information. A clear example is the microblogging platform Twitter.
                        4
                     
                     
                        4
                        
                           http://twitter.com.
                      Twitter publishes all kinds of information, disseminating views on many different topics: politics, business, economics and so on. Twitter users regularly publish their comments on a particular news item, a recently purchased product or service, and ultimately on everything that happens around them. This has aroused the interest of the Natural Language Processing (NLP) community, which has begun to study the texts posted on Twitter, and more specifically related to Sentiment Analysis (SA) challenges.

In this manuscript we present a new approach to the scoring of posts according to the positive or negative degree of the opinions expressed in the text. This polarity classification problem is resolved by combining SentiWordNet scores with a random walk analysis of the concepts found in the text over the WordNet graph. In order to validate our non-supervised approach, several experiments have been performed in order to analyze major issues in our method and to compare it with other approaches like plain SentiWordNet scoring or machine learning solutions such as Support Vector Machines in a supervised approach. The paper is structured as follows: First, an introduction to the polarity classification problem is provided, followed by the description of our approach. Then the experimental method is described with a description of the generated corpus and the results obtained. Finally, conclusions and further work are discussed.

@&#RELATED WORK@&#

The interest among the research community in the analysis of opinions begins in 2002 with the publication of two reference studies which represent the two main approaches to tackling the problem of SA. These two strategies are the one based on the application of linguistic analysis and represented by the work of Turney (2002), and that based on the use of machine learning techniques and epitomized by Pang et al. (2002). Other authors prefer to refer to these two approaches as unsupervised learning and supervised learning. The current body of work attempts to exploit the advantages of both approaches and hybrid systems are proposed, these being represented by the work of Prabowo and Thelwall (2009). In the literature related to SA in long texts a distinction is made between studies of texts where we assume that the text is an opinion and therefore solely need to calculate its polarity, and those in which before measuring polarity it is necessary to determine whether the text is subjective or objective. A wide study on SA can be found in Pang and Lee (2008), Liu (2010) and Tsytsarau and Palpanas (2011).

Concerning the study of polarity in Twitter, most experiments assume that tweets are subjective. One of the first studies on the classification of polarity in tweets was (Go et al., 2009). The authors conducted a supervised classification study on tweets in English. If anything characterizes Twitter it is the vast amount of information published and the wide variety of topics on which users write. This makes very difficult and expensive the construction and manual tagging of a corpus for the supervised classification of polarity. Thus the authors use the emoticons that usually appear in tweets to differentiate between positive and negative tweets. The validity of this technique was demonstrated in Read (2005). Through Twitter Search APIs, authors generated a corpus of positive tweets, with positive emoticons “:)”, and negative tweets with negative emoticons “:(”. The corpus is used to study which features and which classification algorithm are best for the classification of polarity in Twitter. The algorithms analyzed are the same ones used in Pang et al. (2002), i.e. SVM, Naïve Bayes and Maximum Entropy. The authors obtained good results with the three algorithms and the different features they tested. In their study, they reach some interesting conclusions, such as that the use of POS-TAGS does not provide valuable information for the classification of polarity in Twitter, that the simple use of unigrams to represent tweets provides very good results, comparable to those obtained in the classification of polarity in long texts, and finally, that the results obtained with unigrams can be slightly improved by the combination of unigrams and bigrams.

Following the work of Go et al. (2009), Pak and Paroubek (2010) performed a study on the validity of Twitter for SA. They generated a corpus of positive tweets with positive emoticons, negative tweets with negative emoticons, and neutral tweets that corresponded to user accounts published by newspapers and magazines in North America. Firstly, a study of the frequency distribution of words in the tweets was performed on the corpus of 300,000 tweets generated, as well as an analysis of the frequencies of the different syntactic categories to which the words of the tweets of each of the three classes belong. Finally, the authors applied a machine learning process to classify the polarity of the tweets. In this process the performance of three algorithms was assessed: SVM, Naïve Bayes and CRF. The article concludes that the best configuration for the analysis of opinions on Twitter is to use the Naïve Bayes algorithm, and use n-grams and Post-tags as characteristics of the tweets.

A very interesting study is the one performed by Zhang et al. (2011), in which a hybrid method for the classification of polarity is applied to Twitter. As is well described by the authors, in SA there exist two paradigms, one based on the use of lexical resources such as lexicons, and another based on the use of machine learning techniques. Those based on lexical resources often have the problem of obtaining low recall values because they depend on the presence of the words comprising the lexicon in the message in order to determine the orientation of opinion. Machine learning-based methods meanwhile depend on the availability of labeled data sets. As regards SA in Twitter, the first strategy has the problem of the varied and changing nature of the language used in Twitter, and the second implies the difficulty of obtaining a large corpus of labeled tweets. In order to overcome these problems, the authors propose a hybrid system for the analysis of sentence-level opinions in Twitter. For their experiments the authors used a corpus of English tweets on five separate entities (Obama, Harry Potter, Tangled, iPad, Packers), to which a pre-processing was applied which consisted of: removing of retweets, translating of abbreviations into original terms and deleting of links, a tokenization process, and morphosyntactic labeling(POS). Once the corpus was cleaned, a lexicon-based method for classifying tweets according to their polarity was applied. The authors selected a set of subjective words from all those available in English and added hashtags with a subjective meaning. Note that special rules apply for the treatment of comparative judgments, the treatment of negation, and the treatment of expressions that can change the orientation of a phrase. In order to solve the problem of recall often inherent in these methods, the authors attempted to identify a greater number of words indicative of subjective content. Thus they applied the Chi-square test, with the idea that if a term is more likely to appear in a positive or negative judgment it is more likely to be a subjective content identifier. In this way, and automatically, the authors were able to increase the number of labeled tweets. The next step was to apply a machine learning method for the classification of new tweets, in this case using the SVM algorithm.

Although there are some controversial studies of the use of emoticons as a valid corpus of Twitter, recently Davidov et al. (2010) used 50 hashtags and 15 emoticons as sentiment labels in order to train a supervised sentiment classifier using KNN algorithm. The experiments were validated by human judges and the results obtained are very promising. On the other hand, many of the studies of Twitter use raw word representation (n-gram) as features for building a model for sentiment detection. However, the inclusion of some meta-information (like for example POS tags) and the use of syntactic features of the tweets (like for example hashtags, retweets, links, etc.) can improve the result obtained, as in Barbosa and Feng (2010). Based on this previous work, Jiang et al. (2011) study the target-dependent sentiment classification of tweets by using SVM and General Inquirer. They classify the sentiments of the tweets as positive, negative or neutral according to a given query. Thus, the query serves as the target of the sentiments. In addition, they also apply a context-aware approach in order to incorporate the context of tweets into the classification. In Agarwal et al. (2011) a study was performed on the different features to be taken into account in SA in Twitter. The study was conducted on a reduced corpus of tweets labeled manually. The experiment tests different methods of polarity classification and starts with a base case consisting of the simple use of unigram, then a tree-based model, specifically Partial Tree Kernels, a third model consisting of the use of various linguistic features and finally a combination of the different models proposed. A common feature used both in the tree-based model and in the third feature-based model is the polarity of the words appearing in each tweet. In order to calculate this polarity the authors use DAL dictionary (Whissell, 1989). Also noteworthy is the extensive set of features they use and the study they perform on which one gives more information. After extensive experimentation, the authors conclude that both the tree-based model and the feature-based one enhance the base case results, and that the features most relevant to SA in Twitter are those which define the polarity of a term numerically. The last conclusion the authors reach contradicts the research carried out up to this time, since most authors tend to indicate that the characteristics specific of Twitter imply the use of other techniques or a special adaptation of the techniques of OM on long texts. However, there is a strong indication in this case that SA in Twitter is no different from the analysis of long texts.


                        Hernández and Sallis (2011) propose an unsupervised method of reducing features for SA. Their method is based on the Latent Dirichlet Allocation (LDA) methodology, which is summarized in the article. The method is evaluated with a corpus of 10,000 tweets in English on the iPad tablet, which were downloaded during the months of March and April 2011. After cleaning the corpus the tweets are represented following the vector space model and using the TF-IDF metric to weight the terms. Once all the tweets are represented the authors apply their proposal for the reduction of features.

A Random Walk is a mathematical formalization of a trajectory that consists of taking successive random steps. The use of Random Walks algorithms in SA is based on the idea that if the process starts at a given word it is more likely to hit another word with the same semantic orientation before hitting a word with a different polarity. To follow this approach is needed a lexical knowledge base, which in NLP and specially in SA is used to be WordNet.

WordNet is a lexical database where English terms are grouped into synsets (Fellbaum, 1998). A synset is an abstract representation of a concept. When several terms are found in a synset, then those terms are labeled synonyms. When a term is related to several synsets, then that indicates that the term is polysemic. Furthermore, synsets are inter-related with a variety of connections according to their syntactic role:
                           
                              •
                              
                                 Nouns: hypernyms, holonyms, hyponyms, coordination, and meronyms.


                                 Verbs: hypernyms, troponyms, coordination and entailment.


                                 Adjectives: related nouns, similar to and participle of verb.


                                 Adverbs: They are defined in terms of the adjectives they are derived from, and thus inherit their structure from that of the adjectives.

From this configuration, a rich graph is constructed. Fig. 1
                         shows part of the WordNet subgraph for the term solid. We can see that multiple nodes are related. Some hypernyms, hyponyms and synonyms have been used to construct this graph.
                           5
                        
                        
                           5
                           Generated with wnbroser: 
                                 http://homepages.inf.ed.ac.uk/adubey
                              .
                         The graph nature of WordNet makes this resource a perfect candidate for graph analysis algorithms, like PageRank and others.

Several authors have been taken advantage of the graph nature of WordNet. For example, Hassan and Radev (2010) apply a Markov random walk model to WordNet (Fellbaum, 1998), producing a polarity estimate for any given word. Google PageRank (Page et al., 1999) is another Random Walk algorithm that could be used to measure the positive or negative grade of words. In Esuli and Sebastiani (2007) the objective of the authors is to obtain a semantic ranking version of WordNet, so they use a modified version of the original formula of PageRank to bias the random walk to positive and negative terms. They run the algorithm twice, once for positive and again for negative terms, and the results is the ranking of WordNet synsets in terms of how strongly they possess a given semantic property.

SentiWordNet (Baccianella et al., 2010) is a lexical resource based on the well known WordNet. It provides additional information on synsets related to sentiment orientation. A synset is the basic item of information in WordNet and it represents a “concept” that is unambiguous. Most of the relations over the lexical graph use synsets as nodes (hyperonymy, synonymy, homonymy and more). SentiWordNet returns from every synset a set of three scores representing the notions of “positivity”, “negativity” and “objectivity” (the latter being computed from the two previous ones). Therefore, every concept in the graph is weighted according to its subjectivity and polarity. The latest version of SentiWordNet (3.0) has been constructed starting from manual annotations of previous versions, populating the whole graph by applying a random walk algorithm. This resource has been used by the opinion mining community, as it provides a domain-independent resource for obtaining certain information about the degree of emotional charge of its concepts (Denecke, 2008; Ogawa et al., 2011).

In Table 1
                         an excerpt of SentiWordNet entries is shown. As can be seen, a given term may have different polarity weights according to the sense (for instance, fish). Also, some terms that may be considered in certain contexts as holders of polar orientation receive a neutral weight within the resource. As an example, solidness is, in our opinion, a positive term but for SentiWordNet it is fully neutral.

SentiWordNet has been also used in Twitter Sentiment Analysis (Chamlertwat et al., 2012), being a recent example. In this study the authors develop a system (MSAS, Micro-blog Sentiment Analysis System) to discover consumers opinions. Firstly the system performs a subjective classification to distinguish subjective and objective tweets. The second step is to measure the polarity of the tweets, which is obtained by an aggregation process of the polarity values of each term of the tweet. In order to obtain the semantic value the authors use SentiWordNet, so if the tweet has more positive words the tweet is positive, and if it has more negative, the tweet is negative.

Most of the proposed systems for polarity classification compute a value of negativeness or positiveness. Some of them even produce a neutrality value. We will consider the following measurement of polarity (which is very common): a real value in the interval [−1, 1] would be sufficient. Values over zero would reflect a positive emotion expressed in the tweet, while values below zero would instead correspond to negative opinions. The closer to the zero value a post is, the more neutral it would be. Therefore, a polarity classification system could be represented as a function p on a text t such as:


                     
                        
                           (1)
                           
                              p
                              :
                              t
                              →
                              
                                 
                                    ℝ
                                 
                              
                           
                        
                     so that p(t)∈[−1, 1]. We will define how to compute this function, but beforehand an explanation of the techniques implied in such a computation is provided.

One of the handicaps of the texts published in Twitter is their short length, so that in most cases there are few elements of information to decide whether the texts are positive or negative. This obstacle is more evident when it is followed an unsupervised approach because it depends largely on the terms presented in the text and the context. Therefore, the method proposed intends to expand the few concepts that are in tweets in order to calculate the global polarity of the tweet.

Personalized Page Rank vectors (PPVs) consists of a ranked sequence of WordNet synsets weighted according to a random walk algorithm, in this case PageRank. Taking the graph of WordNet, where nodes are synsets and axes are the different semantic relations between them, and the terms contained in a tweet, we can select those synsets that correspond to the closest sense for each term. Then, an iterative process begins and so more nodes are selected if they are not far from these “seeds”. After a number of iterations or a convergence of the weights, a final list of valued nodes can be retrieved.

More formally, let G be the WordNet graph, with N vertices 
                           
                              v
                              1
                           
                           ,
                           …
                           ,
                           
                              v
                              N
                           
                         representing all synsets and M a N
                        ×
                        N probability matrix representing all possible inter-synsets relations so that M
                        
                           ji
                        
                        =0 when there is no connection from 
                           
                              v
                              i
                           
                         to 
                           
                              v
                              j
                           
                         and M
                        
                           ji
                        
                        =1/d
                        
                           i
                         when a relation from 
                           
                              v
                              i
                           
                         to 
                           
                              v
                              j
                           
                         exists, being d
                        
                           i
                         the outdegree of 
                           
                              v
                              i
                           
                         (number of connections going from node i), then computing the PageRank of the nodes (that is, the scores of the synsets) is equivalent to resolve values for vector P in the recursive equation:


                        
                           
                              (2)
                              
                                 
                                    
                                       P
                                    
                                 
                                 =
                                 α
                                 M
                                 
                                    
                                       P
                                    
                                 
                                 +
                                 (
                                 1
                                 −
                                 α
                                 )
                                 
                                    
                                       v
                                    
                                 
                              
                           
                        
                     

In the above expression, the first term of the sum describes the propagation of values across the graph, while the second term specifies how new nodes can be reached, randomly, without propagation. Usually, the vector v contains N elements, with a value of 1/N, so any node is reachable according to the α factor. The value of this factor is set manually, and tends to be close to 1.0 (between 0.85 and 0.95), so a tiny weight is given to any node. The implementation of a solution for the given equation normally considers a maximum number of iterations or a convergence criteria.

For Personalized PageRank, context words act as nodes, with output connections to related synsets. In other words, if we have four valid terms in a tweet (correctly identified nouns, adjectives or verbs), the term nodes get an uniform initial weight of 1/4. It is important to note that terms are connected to synsets and are also part of the whole graph. The 3.0 version of WordNet has been used in this work.

A similar approach has been used recently by Ramage et al. (2009) to compute semantic text similarity in recognizing textual entailment, and also as a solution for word sense disambiguation by Agirre and Soroa (2009). We have used the UKB software from this last study to generate the PPVs used in our system. The idea behind this is to represent each tweet as a vector of weighted synsets that are semantically close to the terms included in the post. In some way, we are expanding these sort texts through a set of disambiguated concepts related to the terms included in the text.

As a combination of SentiWordNet scores with random walk weights is wanted, it is important that the final equation leads to comparable values. To this end, the weights associated to synsets after the random walk process are L
                        1 normalized so vectors of “concepts” sum up the unit as maximum value. The final polarity score is obtained by the product of this vector with associated SentiWordNet vector of scores, as expressed in Eq. (3).


                        
                           
                              (3)
                              
                                 p
                                 =
                                 
                                    
                                       
                                          
                                             
                                                r
                                             
                                          
                                          ·
                                          
                                             
                                                s
                                             
                                          
                                       
                                       
                                          |
                                          t
                                          |
                                       
                                    
                                 
                              
                           
                        where p is the final score, r is the vector of weighted synsets computed by the random walk algorithm of the tweet text over WordNet, s is the vector of polarity scores from SentiWordNet, and t is the set of concepts derived from the tweet.

In the first implementation of our method, the final polarity score is computed as described in Eq. (3). More precisely, it is the average of the product between the difference of positive and negative SentiWordNet scores, and the weight obtained with the random walk algorithm, as unveiled in Eq. (4).


                        
                           
                              (4)
                              
                                 p
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                             
                                                ∀
                                                s
                                                ∈
                                                t
                                             
                                          
                                          
                                             rw
                                             s
                                          
                                          ·
                                          (
                                          
                                             swn
                                             s
                                             +
                                          
                                          −
                                          
                                             swn
                                             s
                                             −
                                          
                                          )
                                       
                                       
                                          |
                                          t
                                          |
                                       
                                    
                                 
                              
                           
                        where s is a synset in the tweet t, rw
                        
                           s
                         is the weight of the synset s after the random walk process over WordNet, 
                           
                              swn
                              s
                              +
                           
                         and 
                           
                              swn
                              s
                              −
                           
                         are positive and negative scores for the synset s retrieved from SentiWordNet.

@&#EXPERIMENTS AND RESULTS@&#

Our experiments focused on testing the validity of applying this unsupervised approach compared to a classical supervised one based on Support Vector Machines Joachims (1998). To this end, the corpus was processed obtaining lemmas, as this is the preferred input for the UKB software. The algorithm takes the whole WordNet graph and performs a disambiguation process of the terms as a natural consequence of applying random walk over the graph. In this way, the synsets that are associated to these terms are initialized. Then, the iterative process of the algorithm (similar to PageRank but optimized according to an stochastic solution) will change these initial values and propagate weights to closer synsets. An interesting effect of this process is that we can actually obtain more concepts that those contained in the tweet, as all the related ones will also finalize with a certain value due to the propagation of weights across the graph. We believe that our approach benefits from this effect, as texts in tweets are usually of sort length, allowing us to expand short posts.

Another concern is therefore the final size of the PPV vector. If too many concepts are taken into account we may introduce noise in the understanding of the latent semantic of the text. In order to study this fact, different vector sizes have been explored and evaluated.

Polarity analysis on microblogging is a very recent task, so there are very few free resources. One of the most useful resources for SA are the corpus because over them the researchers can test their methods. For that purpose, the corpus must be labeled, i.e. must be known which documents express a positive opinion and which of them a negative one. In Twitter is published a great amount of text every minute, so the development of a representative manual labeled corpus is hard, time-consuming and not affordable for a reduce group of people. Nonetheless, in Saša et al. (2010) is presented a good and representative Twitter corpus for SA experiments, but the authors did not share it due to the restrictions of the terms of services of Twitter. Go et al. (2009) made available a hand labeled corpus of English tweets which is formed by 359 tweets (177 positive and 182 negative). Although, that is a very referenced corpus, we considered that it is a small corpus to the first validation of our method. Thus, we decided to generate a big and representative English corpus of tweets in order to accomplish the experiments for validating the method proposed.

The work of downloading tweets is not really difficult due to the fact that Twitter offers two kinds of API for this purpose. We have used the Search API of Twitter
                           6
                        
                        
                           6
                           
                              https://dev.twitter.com/docs/api/1/get/search.
                         for automatically accessing tweets through a query. For a supervised polarity study and in order to evaluate our approach, we need to generate a labeled corpus. We have built a corpus of tweets written in English following the procedure described in Read (2005) and Go et al. (2009).

According to Read (2005), when authors of an electronic communication use an emoticon, they are effectively marking up their own text with an emotional state. The main feature of Twitter is that the length of the messages must be 140 characters, so the users have to express their opinions, thoughts, and emotional states with few words. Therefore, users frequently write “smileys” in their tweets. Thus, we have used positive emoticons to label positive tweets and negative emoticons to tag negative tweets. The full list of emoticons that we have considered for labeling the retrieved tweets can be found in Table 2
                        . So, following Go et al. (2009), the presumption in the construction of the corpus is that the query “:)” returns tweets with positive smileys, and the query “:(” retrieves negative emotions. We have collected a set of 376,296 tweets (181,492 labeled as positive tweets and 194,804 labeled as negative tweets), which were published on Twitter's public message board from September 14th 2010 to March 19th 2011. Table 3
                         lists other characteristics of the corpus.

On the other hand, the language used in Twitter has some unique attributes, which have been removed because we have decided not to use them for this first approach. These specific features are:
                           
                              1.
                              
                                 Retweets: A retweet is the way to repeat a message that users consider interesting. Retweets can be performed through the web interface using the Retweet option, or as the old way by writing RT, the user name and the post to retweet. The first way is not a problem because is the same tweet, so the API only returns it once, but in the old way retweets are different tweets but with the same content, so we removed them to avoid putting extra weight on any particular tweet.


                                 Mentions: Another feature of Twitter is the so called Mentions. When a user wants to refer to another one, he or she introduces a Mention. A Mention is easily recognizable because all of them start with the symbol “@” followed by the user name. We consider that this feature does not provide any relevant information, so we have removed the mentions in all the tweets.


                                 Links: It is very common that tweets include web directions. In our approach we do not analyze the documents that links those urls, so we have eliminated them from all tweets.


                                 Hashtags: A hashtag is the name of a topic in Twitter. Anybody can begin a new topic by typing the name of the topic preceded by the symbol “#”. For this study we do not classify topics so we have neglected all the hashtags.

Due to the fact that users usually write tweets with a very casual language, it is necessary to pre-process the raw tweets before feeding the sentiment analyzer. For that purpose we have applied the following filters:
                           
                              1.
                              
                                 Remove new lines: Some users write tweets in two or three different lines, so all newlines symbols were removed.


                                 Opposite emoticons: Twitter sometimes considers positive or negative a tweet with smileys that have opposite senses. For example:


                                 
                                    
                                       
                                          
                                             
                                                @Harry_Styles I have all day to try get a tweet off you:) when are you coming back to dublin i missed you last time, I was in spain:(
                                             

The tweet has two parts one positive and the other one negative, so the post cannot be considered as positive, but the search API returns as a positive tweet because it has the positive smiley “:)”. We have removed this kind of tweets in order to avoid ambiguity.


                                 Emoticons with no clear sentiment: The Twitter Search API considers some emoticons like “:P” or “:PP” as negative. However, some users do not type them to express a negative sentiment. Thus, we have eliminated all tweets with these kinds of smileys (see Table 4
                                 ).


                                 Repeated letters: Users frequently repeat the letters of some words several times to emphasize their messages. For example:


                                 
                                    
                                       
                                          
                                             
                                                Blood drive todayyyy!!!!!:) Everyone donateeeee!!
                                             

This can be a problem for the classification process, because the same word with different repetitions of the same letter would be considered as a different word. To avoid this problem we have reduced the number of repetitions of any letter occurring more than two times to only two occurrences. The example above would be converted into:


                                 
                                    
                                       
                                          
                                             
                                                blood drive todayy:) everyone donatee!!
                                             

Although the correct spelling is not proposed, many expressions may encounter the same form (like “aaahhhhh” and “aaaaaahhhhhhhhhhhhhhh”, for instance).


                                 Laugh: There is no single manner to express laugh. Therefore, we have normalized the way to write laugh. Some examples are: hahahaha→haha; hehehehe→hehe; Lol→haha.

Finally, although the emoticons have been used to tag the positive and negative samples, the final corpora does not include these emoticons. In addition, all the punctuation characters have been neglected in order to reduce noise in the data. Fig. 2
                         shows the process followed in order to generate our Twitter corpus.

Our first experiment consisted of evaluating a supervised approach, like Support Vector Machines, using the well known vector space model to build the vector of features. Each feature corresponds to the TF-IDF weight of a lemma. Stop words have not been removed and the minimal document frequency required was two, that is, if the lemma is not present in two o more tweets, then it is discarded as an attribute of the final vector. The SVM-Light
                           7
                        
                        
                           7
                           
                              http://svmlight.joachims.org/.
                         software with the default configuration parameters (linear kernel) was used to compute support vectors and to evaluate them using a random leave-one-out strategy. From a total of 376,284 valid samples, 85,423 leave-one-out evaluations were computed, reporting a value of 0.6429, 0.6147 and 0.6285 for precision, recall and F1 respectively.

The results obtained by the method proposed (RW-SWN) are graphically shown in Figs. 3–5
                        
                        
                         for precision, recall and F1 values respectively. As can be noticed from the shapes of the graphs, the size of the PPV vectors affects the performance. Sizes above 10 present stable behavior, that is, considering a large number of synsets does not improves the performance of the system, but neither does it get worse. The WordNet graph considered for the random walk algorithm includes antonyms relations, so we wanted to check whether discarding these connections would affect the system. From these graphs we can extract the conclusion that antonyms relations are worth keeping.

Comparing our best configuration to the SVM approach, the results are not better, but quite close (Table 5
                        ). Therefore, this unsupervised solution is an interesting alternative to the supervised one.

With the aim of facilitating the comprehension of the method an example is shown below. The tweet to be processed is:


                        
                           
                              
                                 
                                    
                                       Using Linux and loving it - so much nicer than windows... Looking forward to using the wysiwyg latex editor!:)
                                    

After cleaning the tweet the text to apply in the following step was:


                        
                           
                              
                                 
                                    
                                       using Linux and loving it so much nicer than windows Looking forward to using the wysiwyg latex editor
                                    

Before making up the PPVs and getting the polarity scores from SentiWordNet a disambiguation process was applied with the aim of discovering the correct synset of each term. The synsets associated with the words present in the tweet are (synset terms in WordNet are also given in parentheses):


                        
                           
                              
                                 
                                    
                                       using → 01158872-v (utilize#1 utilise#1 use#1 employ#1 apply#1)
                                    


                                       loving → 01463965-a (loving#1)
                                    


                                       nicer → 00984333-a (squeamish#1 prissy#2 overnice#1 nice#4 dainty#4)
                                    


                                       windows → 04587648-n (window#1)
                                    


                                       Looking → 02133435-v (seem#1 look#2 appear#1)
                                    


                                       forward → 00075442-r (forward#3 ahead#2)
                                    


                                       using → 01158872-v (utilize#1 utilise#1 use#1 employ#1 apply#1)
                                    


                                       latex → 15006118-n (latex#1)
                                    


                                       editor → 10044879-n (editor_in_chief#1 editor#1)
                                    

After the disambiguation of the terms of the tweet the following step is the building of PPVs. The PPV vector of the above tweet is:


                        
                           
                              
                                 
                                    
                                       01158872-v:0.003819 01463965-a:0.004263 00984333-a:0.004060
                                    


                                       04587648-n:0.005603 02133435-v:0.002388 00075442-r:0.013473
                                    


                                       01158872-v:0.003819 15006118-n:0.007688 10044879-n:0.011033
                                    

The number next to the identification number of the synset (01158872-v) is the PageRank score (0.003819).

The final step is weighting the SentiWordNet polarity score of each synset with its PageRank value. The polarity score is obtained as result of the difference between positive and negative scores. The corresponding calculation for the above PPV is:


                        
                           
                              
                                 
                                    
                                       [01158872-v] (0.000 - 0.000) * 0.003819 → use#1...
                                    


                                       [01463965-a] (0.750 - 0.000) * 0.004263 → loving#1...
                                    


                                       [00984333-a] (0.000 - 0.375) * 0.004060 → nice#4...
                                    


                                       [04587648-n] (0.000 - 0.000) * 0.005603 → window#1...
                                    


                                       [02133435-v] (0.000 - 0.000) * 0.002388 → look#2...
                                    


                                       [00075442-r] (0.000 - 0.000) * 0.013473 → forward#3...
                                    


                                       [01158872-v] (0.000 - 0.000) * 0.003819 → use#1...
                                    


                                       [15006118-n] (0.000 - 0.000) * 0.007688 → latex#1...
                                    


                                       [10044879-n] (0.000 - 0.000) * 0.011033 → editor#1...
                                    

And the final polarity score is 0.000186 i.e. the system assigns the tweet to the positive class.

A new unsupervised approach to the problem of polarity classification in Twitter posts has been proposed. By combining a random walk algorithm that weights synsets from the text with polarity scores provided by SentiWordNet, it is possible to build a system comparable to a SVM based supervised approach in terms of performance. Our solution is a general approach that does not suffer from the disadvantages associated with supervised ones: the need for a training corpus and dependence on the domain where the model was obtained.

Many issues remain open, and these will drive our future work. How to deal with negation is a major concern, as the score from SentiWordNet should be considered in a different way in the final computation if the original term comes from a negated phrase. Our “golden rules” must be taken carefully, because emoticons are a rough way to classify the polarity of tweets. We are currently working on the generation of a new corpus in the political domain that is now under a manual labeling process. Another step is to correct certain flaws in the computation of the final score. So far, all WordNet relations are taken into account in building the graph, but a more carefully selection of connections could be of interest. We also plan to study the context of a specific tweet among the time line of tweets from that particular user in order to identify the publisher's mood and adjust final scores. As an additional task, the processing of original texts is important. The numerous grammatical and spelling errors found in this fast method of publication demand a better cleaning of the incoming data. An automatic spell checker is under development.

The proposed solution needs of two main resources: a graph to connect terms and polarity weights for individual terms. Any possible variation on the choice of these two resources could be worth exploring. For instance, if the tweets are concerned within a controlled domain, could a specific graph be constructed for such a domain? We believe that it is possible, as mutual information values above a given threshold between any pair of terms could reflect a relation between those terms. Besides, this would allow for analysis beyond unigrams analysis, as graphs with bigrams and unigrams as vertices could be generated. Regarding polarity values, further resources are available and could be evaluated within our approach.

One major experimentation being undertaken is the evaluation of our system as a multilingual solution for non-supervised polarity classification, by means of word nets in other languages, like the Spanish WordNet found in the Multilingual Central Repository (Gonzalez-Agirre et al., 2012). Although our proposal is mainly concerned with the unsupervised nature of the solution, we believe that including the values obtained from the random walk algorithm in a supervised algorithm may improve its performance.

As a final conclusion, we believe that this first attempt is very promising and that it has raised many relevant questions on the subject of sentiment analysis. More extensive research and experimentation is being undertaken from the starting point introduced in this paper.

@&#ACKNOWLEDGEMENTS@&#

This work has been partially supported by a grant from the Fondo Europeo de Desarrollo Regional (FEDER), TEXT-COOL 2.0 project (TIN2009-13391-C04-02) from the Spanish Government. Also, this paper is partially funded by the European Commission under the Seventh (FP7 – 2007–2013) Framework Programme for Research and Technological Development through the FIRST project (FP7-287607). This publication reflects the views only of the authors, and the Commission cannot be held responsible for any use which may be made of the information contained therein.

@&#REFERENCES@&#


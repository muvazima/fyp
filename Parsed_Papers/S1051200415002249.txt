@&#MAIN-TITLE@&#Full body movements recognition – unsupervised learning approach with heuristic R-GDL method

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We have used Gesture Description Language (GDL) for user actions recognition.


                        
                        
                           
                           A method for generation of knowledge base for GDL classifier has been proposed.


                        
                        
                           
                           The method analyzes unsegmented data recordings of gestures.


                        
                        
                           
                           The evaluation has been made on 770 samples of gym exercises.


                        
                        
                           
                           We obtained recognition rate at the level of 100% to 91%.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gesture recognition

Full body movements recognition

Unsupervised learning

Syntactic classification

Gesture Description Language

Reverse-Gesture Description Language

@&#ABSTRACT@&#


               
               
                  In computer systems that are used for actions recognition the human movements are often represented by three-dimensional coordinates of body joints that are tracked by motion capture hardware. The motivation of our research was to propose a novel method for automatic generation of knowledge base for syntactic Gesture Description Language (GDL) classifier by analyzing unsegmented data recordings of gestures. We have proposed novel unsupervised learning approach to deal with this task. Because this process seems to be reverse engineering to GDL approach, the learning algorithm we introduce in this paper, is called Revers-GDL (R-GDL). The R-GDL machine-learning approach for full-body movements recognition is a novel method of time-varying multidimensional signals classification. The description of R-GDL and its validation is our original and never before published achievement. The evaluation of R-GDL was performed with k-fold cross validation on large dataset that contains 770 complete movements samples of 9 gym exercises performed by 14 persons and compared with results from multivariate normally continuous density hidden Markov model classifier. Depending on exercise type GDL obtained recognition rate at the level of 100% to 91%.
               
            

@&#INTRODUCTION@&#

Human movements or gesture recognition systems have been presented in literature and implemented for many years. In this scope, many scientific papers and commercial systems aim at the sign language analysis. This problem is especially important because efficient gesture recognition system of this type aids to interact with the deaf and deaf-mutes because very few people know how to communicate with person with disabled senses. From the other hand full body movements recognition (in this article we will use term full body gestures analysis as the synonym) was not so much examined. That was due to the fact that for many years systems (mostly hardware solutions) that enabled acquisition of gestural data (like motion capture technology) were relatively expensive and could not be easily set up in undedicated environment. In the last few years we can observe a boom on gesture recognition systems that is mostly caused by introduction to market new multimedia devices that uses infra-red projector and camera to generate depth maps (the most popular from this family is Kinect). The close look on methodologies of gestures recognition reveals that even though the problem of movements classification is well known and investigated for many years it is very difficult or nearly impossible to indicate the one leading methodology that deals with this problem and is reliable and in the same time applicable in commercial practice. The aim of this paper is to propose and present evaluation of a novel heuristic method that satisfies both of those needs.

Although hand gesture recognition and full body movements classification seems to be different classes of problems both of them have much in common. Both of them deals will real-time analysis of human behavior and due to this fact often the similar approaches are used. Due to this fact the state-of-the-art knowledge about those approaches are crucial for every researcher.

The first very important stage that has to be done before gesture analysis is extraction of features from input recording. In [1] the main objective behind using 15 Gabor filter responses is to reduce the complexity with better accuracy. In [2] hands postures are detected and hand gestures are recognized based on features of hand which are extracted using the Haar-Like features. The variety of object skeletons extraction methods from 2D [3] and 3D point cloud has been proposed [4–6]. Many researches choose formalisms that are invariant to localization of a data capturing sensor. For example work [7] introduces a new representation for Motion Capture data (MoCap) that is invariant under rigid transformation and robust for classification and annotation of MoCap data. This representation relies on distance matrices that fully characterize the class of identical postures up to the body position or orientation. In [8] each pose is described using an angular representation of the skeleton joints.

The intrinsic dimensionality of human motion data is rather small compared to the typical dimensionality of the raw motion capture data. Therefore, motion modeling often begins with a dimensionality reduction step to enable generalization to novel motion from small amounts of data. It is very often done with PCA [9] (principal component analysis) or other approaches [7].

After features selection and data transformation from original space into space determined by selected features there are large variety of computational intelligence methods that are used in process of gestures recognition. Among most popular are hidden Markov models (HMMs) [10,11], support vector machines (SVM) [1,8,12], decision forests [8,13], Gaussian process dynamical models [14], k-means clustering [2] or dynamic Bayesian networks [15].

Some approaches use syntactic pattern recognition methods. Those classifiers requires special syntax for representing human gestures and sometimes rule sets that correspond to the basic spatial and temporal components of an action [16–19]. Creating domain-specific gesture recognizers of this type is not a simple task. It requires significant amounts of experimentation and training with large gesture corpora to determine a suitable set of features and rules set [2,20].

The behavior analysis and modeling with computer-vision methods is novel and very interesting scientific problem. Some authors propose methods that can be applied to this task. For example in paper [9] authors used radial basis functions (RBF) and linear kernels associated with a nonlinear auto-regression model to learn a computer system interactions between a couple of actors and then replace one actor by the motion capture data of a human user during real time interaction. In [21] authors present a new approach for the learning of structured dynamical models for the synthesis of interactive body movements that is based on hierarchical Gaussian process latent variable models. The latent spaces of this model encode postural manifolds and the dependency between the postures of the interacting characters. In addition, this model includes dimensions representing emotional style variations (for neutral, happy, angry, and sad) and individually-specific motion style. Paper [22] combines an approach to the generation of culture-specific behaviors with full body avatar control based on the Kinect sensor. A study revealed that users are able to easily control an avatar through their body movements and immediately adapt its behavior to the cultural background of the agents they interact with.

Besides issues we already mentioned there are also those that are crucial to make a gesture recognition method applicable in practice (for example in commercial products). At first many problems in vision involve the prediction of a class label for each frame in an unsegmented sequence [23]. In practice, the user is expecting from the system capability of recognition of his natural gesticulation. What is more lack of necessity of pre-segmentation (that is often manual or governed by a user) of training data highly reduces time that has to be spent to train classifier. Another important aspect is if interactive, action-based interface has low latency [24]. High latency causes the system's feedback to lag behind user actions and thus significantly degrades the interactivity of the user experience. In practice, the implementation of classifier should operate in real time (at least with the same speed as new data arrives from data acquisition hardware).

As can be noticed from previous section there are several very important aspects that should be considered while choosing proper gesture classification approach. An optimal choice is a method that provides high recognition rate and in the same time operates on features that are invariant to rigid transform of observed object, has a stable training algorithm and operates in real-time on unsegmented (real-live) data. No less important are easily readable parameters and training results of the algorithm what make it possible to interpret what are decision borders between classes and to apply results to deep analysis of nature of some physical activity. In our previous researches we have introduced and evaluated Gesture Description Language (GDL) that is syntactic classifier that uses rule-based expert system approach for gesture description and recognition. The GDL showed to be efficient and effective classifier in multiple full body gestures recognition tasks like common – live gestures [16], natural user interface [25] and initially in karate techniques [18,19]. GDL incorporates all those aspects that are so important for gesture recognition system hover our solution lacked so far automatic training of its knowledge base (rules had to be tailored during implementation phase manually).

The motivation of our research was to propose a novel unsupervised learning method for automatic generation of GDL knowledge base (that is written in context-free GDL script (GDLs) formal grammar) by analyzing unsegmented data recordings of gestures to be recognized. Because this process seems to be reverse engineering to GDL approach the learning algorithm we introduce in this paper will be called Revers-GDL (R-GDL). What is crucial the GDLs that is generated after this analysis preserves all most important features of manually – defined GDLs:
                           
                              –
                              The GDLs generated by R-GDL can be very easily interpreted by a user and corrected/expanded/attached to any other GDLs file.

The training of classifier is based on reliable unsupervised clustering method on unsegmented data recordings of gestures.

The effectiveness of classifier is function of generated rules precision.

The classifier runs in real time, which enable recognition with the same speed as data arrives from video capturing hardware.

The GDLs description might be invariant to user position towards the data acquisition sensor.

GDLs enables to define features set derived from raw skeleton tracking data.

The GDL/R-GDL machine-learning approach for full-body movements recognition we propose is a novel method of time-varying multidimensional signals classification. In computer systems that are used for actions recognition the human movements are often represented by three-dimensional coordinates of body joints that are tracked by MoCap hardware. In our experiment we use Microsoft Kinect however we can utilize any type of device that is capable of body joints tracking. In case of cheap, multimedia MoCap devices the low sampling frequency (30 Hz or less) causes that the single action is registered on only several or several dozens of samples which makes frequency-based analysis very difficult or even impossible. The low-frequency MoCap data processing is still open and actual subject of researches and our methodology presented in this paper is one of the possible solution of this problem. Besides already mentioned features our methodology is additionally innovative because GDL methodology together with R-GDL training creates an unified solution in which features calculation, key-frames detection, signal identification and classifiers training are among single framework which common part are descriptions made with context-free GDLs grammar.

The description of R-GDL approach is our original and never before published achievement. Together with evaluation and discussion of validation results of this methodology on large dataset that contains 770 complete movements samples of 9 gym exercises performed by 14 persons it is a content of the following sections of this paper. We have also compared classification results obtained with R-GDL/GDL approach with state of the art multivariate normally continuous density hidden Markov model classifier.

The methodology that is utilized for solving signal identification problem is dependent on many factors. Those are inter alia the dimensionality of problem, features that are used to describe the phenomena or spectra characteristic of discrete samples. In this paragraph we will describe the characteristic of our dataset and we will introduce the methodology we propose to deal with full body gesture classification problem.

Our classifier is trained and validated on so called skeleton recordings (SKL-files) that are initially processed data from depth camera of data acquisition sensor. In our case we store detection results of third-party image processing library (Microsoft Kinect SDK) that automatically detects 20 points on human body (so called body joints) and track them with the approximated 30 Hz frequency – see Fig. 1
                         on right. The tracking frequency might be lower than 30 Hz if Kinect SDK image processing is delayed by other background threads of operating systems. Those fluctuations of tracking speed did not appear in our dataset. Each SKL recording frame stores three-dimensional position of each one of 20 body joints. The detection and tracking procedure is marker-less. Our dataset satisfies the following assumption:
                           
                              1.
                              It contains recordings of each gesture to be recognized.

The same gesture is performed by multiple people both man and woman.

Each person preforms a single body movement periodically (five or more times).

Recording of a person performing periodically single gesture is stored in separate SKL file. Because of that each SKL file can be assigned to particular person and particular body movement.

There is no need to partition a single recording SKL to smaller samples. For instance if SKL file contains 10 repetitions of body weight squads we do not have to segment beginning and end frame of each exercise. This assumption is very important because it highly reduces the time of test and validation set preparation especially where there are several hundred or thousands of body movements samples. However, for reasons that we will revel later we segment not more than 5% exemplars of each type of movement for additional evaluation.

All gestures are correctly performed that means each gesture in dataset can be assigned to single or multiple classes.

While tailoring gesture recognition classifier we must be aware the number of aberrations that might appear in SKL recordings. Those aberrations might be partitioned into two groups: individual features of filmed participants and imperfection of data capturing hardware and processing software. Among first group most important factors are suppleness and physical condition of a user. After several repetitions of exhaustive physical exercise the speed and precision of body movements differs in comparison to beginning of the training session. Among second group most difficult to overcome are inaccuracies in body joint segmentation especially noticeable when a body part to be segmented is covered by another body part. That is quite frequent while performing natural physical activates. This is mainly the problem of segmentation algorithm rather than accuracy of the depth map, which is sufficient for this task [26,27]. Of course those two types of phenomena are present in all real-world (not artificially created) datasets and should be considered both in training and validation dataset.

The user data gathered by Kinect and tracked by Microsoft Kinect SDK library already contains quite heavy tracking noises. According to research [28] in a more controlled body posture (e.g. standing and exercising arms), the accuracy of the joint estimation is comparable to motion capture. However, in general postures, the variability of the current implementation of the pose estimation is about 10 cm which is large value comparing to the size not only particular limb by the whole user's body. The measurements could be used to assess general trends in the movement, but for quantitative estimation an improved skeletonization with an anthropometric model is needed. Due to this fact the further classification is already made under noise and we did not find necessary to introduce additional signal disturbances to our dataset for the methodology evaluation purposes.

The GDL classifier was described in details in our paper [16]. In this section we will only summarize the basic assumptions under this approach.

The very heart of our approach is an automated reasoning module. It performs forward chaining reasoning (like a classic expert system) with its inference engine every time new portion of data arrives from the feature extraction library. All rules of the knowledge base are organized in GDL scripts (GDLs) having the form of text files that are parsed with a context-free grammar. The input set of body joints and all conclusions obtained from knowledge base are put on the top of the memory stack. In addition, each level of the stack has its own timestamp which allows checking how much time has passed from one data acquisition to another. Because the conclusion of one rule might form the premise of another one, the satisfaction of a conclusion does not necessarily mean recognizing a particular gesture. The interpretation of a conclusion appearance depends on the GDL script code.

Let us assume that we have time varying 
                           3
                           ⋅
                           d
                        -dimensional MoCap signal 
                           
                              
                                 P
                              
                              
                                 [
                                 
                                    
                                       t
                                    
                                    
                                       i
                                    
                                 
                                 .
                                 .
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 ]
                              
                           
                         sampled in discrete time moments 
                           
                              
                                 t
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 t
                              
                              
                                 i
                                 +
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 t
                              
                              
                                 j
                              
                           
                         (
                           i
                           <
                           j
                        ).
                           
                              (1)
                              
                                 
                                    
                                       P
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                                 =
                                 [
                                 
                                    
                                       
                                          p
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          p
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ]
                              
                           
                         where:
                           
                              (2)
                              
                                 
                                    
                                       
                                          p
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                a
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       3
                                       ⋅
                                       d
                                    
                                 
                              
                           
                         
                        d is number of body joints, 3 is number of dimensions in Cartesian frame per joint, 
                           a
                           ∈
                           [
                           i
                           ,
                           j
                           ]
                        .

As we already mentioned in Section 1.2 we have to recalculate each signal sample 
                           
                              
                                 
                                    p
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          a
                                       
                                    
                                 
                              
                              ‾
                           
                         to make it invariant to relative position to camera. We call that step features calculation. Features are numeric values derived from MoCap data with function 
                           F
                        .
                           
                              (3)
                              
                                 
                                    
                                       P
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                                 
                                    →
                                    F
                                 
                                 
                                    
                                       
                                          f
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    ‾
                                 
                              
                           
                         where 
                           
                              
                                 
                                    f
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          a
                                       
                                    
                                 
                              
                              ‾
                           
                           ∈
                           
                              
                                 R
                              
                              
                                 m
                              
                           
                        , 
                           a
                           ∈
                           [
                           i
                           ,
                           j
                           ]
                        .

Function 
                           F
                         is defined by a set of GDLs Features expressions (see Appendix A).

After applying (3) to (1) in each moment of time we get:
                           
                              (4)
                              
                                 
                                    
                                       F
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                                 =
                                 [
                                 
                                    
                                       
                                          f
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          f
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ]
                              
                           
                         The next step is calculation of rules' conclusions. Each of r-rules that are defined in GDLs might be either satisfied or not:
                           
                              (5)
                              
                                 
                                    
                                       
                                          r
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                a
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ∈
                                 
                                    
                                       {
                                       
                                          true
                                       
                                       ,
                                       
                                          false
                                       
                                       }
                                    
                                    
                                       r
                                    
                                 
                              
                           
                         where 
                           
                              
                                 
                                    r
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          a
                                       
                                    
                                 
                              
                              ‾
                           
                         is a feature vector that contains all conclusions of rules. It is possible that conclusion of one rule is present as a premise of another one (see GDL MoCap data processing algorithm – b).

We define:
                           
                              (6)
                              
                                 
                                    
                                       R
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                                 =
                                 [
                                 
                                    
                                       
                                          r
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          r
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ]
                              
                           
                         And:
                           
                              (7)
                              
                                 
                                    {
                                    
                                       
                                          F
                                       
                                       
                                          [
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                          .
                                          .
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                          ]
                                       
                                    
                                    ,
                                    
                                       
                                          R
                                       
                                       
                                          [
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                          .
                                          .
                                          
                                             
                                                t
                                             
                                             
                                                j
                                                −
                                                1
                                             
                                          
                                          ]
                                       
                                    
                                    }
                                 
                                 
                                    →
                                    ℜ
                                 
                                 
                                    
                                       R
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                              
                           
                         where ℜ is a function defined by a set of GDLs Rules expressions (see Appendix A).

The top of GDL memory stack in time 
                           
                              
                                 t
                              
                              
                                 a
                              
                           
                         is defined as:
                           
                              (8)
                              
                                 
                                    
                                       
                                          s
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                a
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             p
                                          
                                          
                                             
                                                
                                                   t
                                                
                                                
                                                   a
                                                
                                             
                                          
                                       
                                       ‾
                                    
                                    ,
                                    
                                       
                                          
                                             f
                                          
                                          
                                             
                                                
                                                   t
                                                
                                                
                                                   a
                                                
                                             
                                          
                                       
                                       ‾
                                    
                                    ,
                                    
                                       
                                          
                                             r
                                          
                                          
                                             
                                                
                                                   t
                                                
                                                
                                                   a
                                                
                                             
                                          
                                          
                                             ′
                                          
                                       
                                       ‾
                                    
                                    }
                                 
                              
                           
                         where 
                           
                              
                                 
                                    r
                                 
                                 
                                    
                                       
                                          t
                                       
                                       
                                          a
                                       
                                    
                                 
                                 
                                    ′
                                 
                              
                              ‾
                           
                         is a vector that contains only those rule's conclusions that are satisfied (true) at a moment of time 
                           
                              
                                 t
                              
                              
                                 a
                              
                           
                        .

Eventually GDL stack S is defined as:
                           
                              (9)
                              
                                 
                                    
                                       S
                                    
                                    
                                       [
                                       
                                          
                                             t
                                          
                                          
                                             i
                                          
                                       
                                       .
                                       .
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       ]
                                    
                                 
                                 =
                                 [
                                 
                                    
                                       
                                          s
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       
                                          s
                                       
                                       
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    ‾
                                 
                                 ]
                              
                           
                        
                     


                        Fig. 2
                         presents a flowchart of GDL. Symbol 
                           <
                           <
                           
                              trigger
                           
                           >
                           >
                         means that data flow activates a given processing block, but data for the operation in a block is taken from GDL stack.

The GDL performs according to the following algorithm (see also Fig. 1 and Fig. 2):


                        GDL MoCap data processing algorithm
                        
                           
                              1)
                              Parse the input GDL script that consists of set of rules and feature, generate a parsed tree.

Begin data capturing.

Repeat the above instructions until the application is stopped:
                                    
                                       a.
                                       If a new skeleton arrives from the data capture algorithm, store it on the top of the memory stack with the current timestamp. Calculate values of all features defined in GDLs and store their values on the same level of memory stack as skeleton. Each level of the memory stack contains three types of data: a set of body joints, a set of features values and a set of rules names that was satisfied for the current/previously captured skeletons and features and the current/previously satisfied rules. Skeleton, features values and names of rules satisfied in previous iterations lie on memory stack layers corresponding to a particular previous iteration. The size of the memory stack in our implementation is 256 layers (about 8.5 seconds of data capture at the frequency of 30 Hz). We did not find a “deeper” stack useful, but because data stored in the stack is not memory consuming, the stack might be implemented as “virtually unlimited in depth”.

Repeat until no new rules are satisfied
                                             
                                                •
                                                Check if body joints and features values satisfy any one rule in the memory stack whose name is not present in the top level of the memory stack. The GDLs may also consider joints from previous captures; for example Spine.x[0] is the actual x-coordinate of the torso joint while Spine.x[2] is the x-coordinate of the same joint but captured two iterations before – two levels below from the top position of the memory stack. Rule truth might also depend on the current and previously satisfied rules.

If any rule is satisfied, add its name to the top of the memory stack at the same layer at which the last captured skeleton points were stored (top level of stack). As each level of the stack has its timestamp, it is possible to check if some rule was satisfied no earlier than a given period of time ago. Thanks to this mechanism, it is possible to check if the particular sequence of body joint positions (represented by rule names) appeared in the given time period. The sequence of body positions defines the gesture that we want to recognize.
                                                

The biggest challenge in using GDL approach is preparation of GDLs description. While the description of gestures requires 3 to 4 features one can very easily handle it manually. However when the gestures are some sophisticated full-body activities with many constraints on body joints relative positions the problem becomes more difficult. Knowing that we tailored a new method for automatic generation of GDLs files that analyzed set of SKL recordings with unsupervised learning methods (R-GDL). To make R-GDL consistent to GDL approach we have to make some extension to GDLs 1.0 language from [16] and we introduce GDLs 1.1 specification, that is described in the following section.

The GDLs 1.0 specification was complete and well-designed. However during usage several suggestions appear about possible extension of its syntactic potential. The most common request was possibility of defining numeric variables which will have similar form of GDLs rules. The second common postulate was to include possibility of checking persistence of rule conclusion on memory stack (how long given rule is present in different levels memory stack). In Appendix A we have presented formal definition of GDL 1.1, but only those elements that are extension of GDL 1.0. What is important those new syntactic elements suits very well with the needs of extension of GDLs to keep it compact with new paradigm of R-GDL, which will be presented in next section.

In GDL approach we have the assumption, that a movement can be represented as a sequence of key frames. If those key frames play some crucial role for gesture identification they should also be “remarkably visible” in a future space. That means if a user is capable to find out what other person is doing by detection of some important phases of movement computer should also be capable to do so if we indicate proper features to be analyze. If those key-frames appear for all persons performing some movement they should be detected as centers of clusters in feature space where data to be clustered is set of SKL frames. The next issue is to choose the clustering algorithm that is sufficient for this type of analysis. We will discuss this in the following section.

We are interested in detection of central points of clusters (Gaussian distribution model is reported to be applied in human movements analysis [23]) which will create the root of key frames. Because we want to classify human movements we can more or less estimate how many important key-frames are present in each movement activity. We have a large spectrum of clustering methods however many of them can be excluded from consideration because they requires a prior hard to determine (or varying between datasets) knowledge about SKL recordings. The hierarchical based clustering might not be a good choice because we are looking for centers of clusters and each cluster might have different distribution of elements which make proper definition of linking/splitting criterion very difficult. Also density-based clustering methods like DBSCAN requires prior knowledge about threshold values of considered densities. We have assumed that the data has a Normal distribution (Gaussian mixture model) however all parameters (mean vectors, covariance matrix and prior probabilities for each class) are unknown. Provided that we can estimate the probable number of key-poses (clusters) we can use k-means clustering approach to solve this problem. k-Means clustering is a very popular approximate method that is often use to deal with maximum-likelihood estimates of means [29]. This method often allows fast convergence and does not require additional assumptions on data model.

The GDL classifier trained with R-GDL method works as follows. Let us assume that we have time varying m-dimensional signal 
                              
                                 
                                    F
                                 
                                 
                                    [
                                    
                                       
                                          t
                                       
                                       
                                          i
                                       
                                    
                                    .
                                    .
                                    
                                       
                                          t
                                       
                                       
                                          j
                                       
                                    
                                    ]
                                 
                              
                            
                           (4).

A signal sample belongs to cluster 
                              
                                 
                                    C
                                 
                                 
                                    b
                                 
                              
                              (
                              
                                 
                                    
                                       μ
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                              ,
                              
                                 
                                    
                                       σ
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                              ,
                              
                                 
                                    
                                       ε
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                              )
                            when:
                              
                                 (10)
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             
                                                
                                                   t
                                                
                                                
                                                   a
                                                
                                             
                                          
                                       
                                       ‾
                                    
                                    ⊂
                                    
                                       
                                          C
                                       
                                       
                                          b
                                       
                                    
                                    
                                    ⇔
                                    
                                    |
                                    
                                       
                                          
                                             f
                                          
                                          
                                             
                                                
                                                   t
                                                
                                                
                                                   a
                                                
                                             
                                          
                                       
                                       ‾
                                    
                                    −
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             b
                                          
                                       
                                       ‾
                                    
                                    |
                                    
                                       <
                                       ‾
                                    
                                    
                                    
                                       
                                          
                                             μ
                                          
                                          
                                             b
                                          
                                       
                                       ‾
                                    
                                    +
                                    
                                       
                                          
                                             ε
                                          
                                          
                                             b
                                          
                                       
                                       ‾
                                    
                                 
                              
                            where 
                              
                                 
                                    
                                       μ
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                            is a mean vector (center of cluster), 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                            is a standard deviation of cluster's elements and 
                              
                                 
                                    
                                       ε
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                            together with 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       b
                                    
                                 
                                 ‾
                              
                            determines size of a cluster. 
                              
                                 <
                                 ‾
                              
                            means that all coordinates of vector in the left side have lower value than corresponding to them coordinates in the right side (both vectors have the same dimension).

GDL classifies signal 
                              
                                 
                                    F
                                 
                                 
                                    [
                                    
                                       
                                          t
                                       
                                       
                                          i
                                       
                                    
                                    .
                                    .
                                    
                                       
                                          t
                                       
                                       
                                          j
                                       
                                    
                                    ]
                                 
                              
                            to class 
                              
                                 
                                    C
                                 
                                 
                                    c
                                 
                              
                            when:
                              
                                 (11)
                                 
                                    
                                       GDL
                                    
                                    (
                                    
                                       
                                          F
                                       
                                       
                                          [
                                          
                                             
                                                t
                                             
                                             
                                                i
                                             
                                          
                                          .
                                          .
                                          
                                             
                                                t
                                             
                                             
                                                j
                                             
                                          
                                          ]
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          C
                                       
                                       
                                          c
                                       
                                    
                                    
                                    ⇔
                                    
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         
                                                            
                                                               t
                                                            
                                                            
                                                               
                                                                  
                                                                     l
                                                                  
                                                                  
                                                                     1
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   ‾
                                                
                                                ⊂
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                                ∧
                                                ⋯
                                                ∧
                                                
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         
                                                            
                                                               t
                                                            
                                                            
                                                               
                                                                  
                                                                     l
                                                                  
                                                                  
                                                                     n
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   ‾
                                                
                                                ⊂
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                                ,
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            l
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                                <
                                                ⋯
                                                <
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            l
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      j
                                                   
                                                
                                                −
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            l
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                                <
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                   
                                                
                                                ∧
                                                ⋯
                                                ∧
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            l
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                                −
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            l
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                                <
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                            where 
                              [
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                              ]
                            are n-element set of clusters (key frames) of an action, 
                              [
                              
                                 
                                    t
                                 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    t
                                 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                              ]
                            are time constraints assigned to each key frame and 
                              [
                              
                                 
                                    t
                                 
                                 
                                    
                                       
                                          l
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    t
                                 
                                 
                                    
                                       
                                          l
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                              ]
                            are moments of time when particular samples belongs to a given cluster. We can simply prevent the situation that GDL classifier detects particular action multiple times in neighboring frames by adding constraint that next action of a same type cannot appear in time shorter than 
                              
                                 
                                    t
                                 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          n
                                       
                                    
                                 
                              
                           .

In R-GDL the initial configuration for k-means clustering is:
                              
                                 –
                                 SKL file with movements exemplar on which classifier is trained.

Input GDLs file with definitions of features. The clustering algorithm will be running in m-dimensional space where m is a number of features defined in this file. Those features are computed for all body joints in each SKL file frame. Clustering does not take into account time order of frames.

Number of clusters (k) – this number has to be estimated by the user basing on his expectation about the optimal number of key frames.

“Epsilon values” that widen the margin of cluster borders estimation.

Initial features definition.

Features generated by R-GDL that is:
                                       
                                          ∘
                                          epsilon values for all features,

centers of clusters computed as average value of all elements assigned to them (all features have the same weight),

spatial dimensionality of clusters computed as standard deviation value of all elements assigned to them (all features have the same weight).

Key frames definition: each key frame corresponds to the single cluster. Single key frame has the following pattern of rule definition (compare with (10)):


                                    
                                       RULE abs(feature 1 value – average value of feature 1 in given cluster) <= standard deviation of feature 1 in a given cluster + epsilon value for feature 1
                                 


                                    AND (...)


                                    AND abs(feature m value – average value of feature L in given cluster) <= standard deviation of feature K in a given cluster + epsilon value for feature L
                                 


                                    
                                       THEN Key frame for a given cluster
                                 

Key frames are order into sequences in the following form (compare with (11)):


                                    
                                       RULE key frame C
                                 


                                    & sequenceexists(”[key frame B, time of persistence of key frame B]
                                 

(...)


                                    [key frame A,Time of persistence of key frame A]”)
                                 


                                    
                                       THEN Conclusion
                                 

The previous rule will be satisfied as long as “key frame C” rule is satisfied and the sequence satisfies the time constraints. However if we would like to force GDL classifier to return the conclusions of gesture appearance only once per gesture that might be done with the following construction:


                           
                              RULE Conclusion & sequenceexists(”[!Conclusion,1]”)
                        


                           
                              THEN Detected gesture name
                        

This is especially useful when we want to use generated script not only to check if the particular gesture exists in given SKL recordings but also to count how many time it appeared. An example complete GDLs description of a gesture generated by R-GDL approach is presented in Appendix C.

The computational complexity of R-GDL is the same as k-means algorithm: 
                              O
                              (
                              
                                 tmni
                              
                              )
                            
                           [29] where t is number of training patterns, m is number of features, n number of clusters, i is number of iterations. The “precision” of final solutions (the difference between estimated parameters of normal distributions and “real-world” parameters) depends on motion-capture tracking quality of training samples. The more tracking inaccuracies samples contains the worse results (further from “real-world” value) we get. Also the recognition rate of GDL that operates on GDLs generated with R-GDL depends directly on k-means approximation results. That is because GDLs rules utilize derived parameters of normal distributions.

The computational complexity of GDL that operates on rules generated with R-GDL is: 
                              O
                              (
                              s
                              n
                              +
                              
                                 nmr
                              
                              )
                            where s is a size of a GDL stack, n is number of classes (clusters), m is number of features and r is number of rules per class. The first part sn expresses complexity of calculation of sequenceexists functions that appears in n rules (there are the same number of rules with sequenceexists as classes). The second term nmr expresses a complexity of calculation of all rules.

The next step after detection key frames of movements is ordering them in into sequences. The problem is challenging because unsupervised learning supply only information that particular key frame is situated statistically in the center of a cluster. The k-means algorithm with random initialization does not also guarantee that results of the data partitioning will return results accordant to our intuition. Of course it is possible to visualize several SKL frames that belongs to detected clusters or to determinate the order of key frames by checking it with dedicated application [30], however we will still not know what are the maximal time spans that passes between one key frame to another. The information of those time spans is crucial for creation of gesture sequences that are basis of GDLs descriptions.

Let us assume for simplicity that the SKL recording was portioned into three clusters. We represent those partitioning by three key frames: key frame A, key frame B and key frame C. We can now expect that the movement can be described by those key frames and each one of them appears at least once in the description in some order for example 
                              C
                              →
                              A
                              →
                              B
                           . However it is possible that the sequence might also contains more than one key frame on single type for example 
                              C
                              →
                              A
                              →
                              B
                              →
                              C
                            
                           or 
                           
                              C
                              →
                              A
                              →
                              B
                              →
                              A
                              →
                              C
                           . Knowing that we can consider the sequences of key frames that appears in the recording as series of n-grams which probability (estimated by a frequency of appearance in training set) should indicate the “real” order in movements to be classified. According to this definition probability of n-gram of gesture NG equals quantity of NG n-gram in considered dataset divided by quantity of all n-grams in this set.
                              
                                 (12)
                                 
                                    P
                                    (
                                    
                                       NG
                                    
                                    )
                                    =
                                    
                                       
                                          #
                                          
                                             NG
                                          
                                       
                                       
                                          #
                                          
                                             all
                                          
                                          
                                          n
                                          -
                                          
                                             grams
                                          
                                       
                                    
                                 
                              
                           
                        

Of course in practice the output sequences we obtain from GDL reasoning module looks for example like this:
                              
                                 (13)
                                 
                                    S
                                    =
                                    [
                                    …
                                    ,
                                    C
                                    ,
                                    C
                                    ,
                                    C
                                    ,
                                    X
                                    ,
                                    X
                                    ,
                                    A
                                    ,
                                    A
                                    ,
                                    A
                                    ,
                                    X
                                    ,
                                    X
                                    ,
                                    B
                                    ,
                                    B
                                    ,
                                    …
                                    ]
                                 
                              
                            where X means that particular SKL frame is not assigned to any cluster. That is because quite often a number of neighboring SKL frames are assigned to the same cluster because body joints positions between them do not differ much. Together with sequence S we also have sequence T that holds the information how much time has passed since last SKL frame:
                              
                                 (14)
                                 
                                    T
                                    =
                                    [
                                    
                                       
                                          t
                                       
                                       
                                          0
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          t
                                       
                                       
                                          k
                                       
                                    
                                    ,
                                    
                                       
                                          t
                                       
                                       
                                          k
                                          +
                                          1
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          t
                                       
                                       
                                          n
                                       
                                    
                                    ]
                                 
                              
                            where 
                              
                                 
                                    t
                                 
                                 
                                    0
                                 
                              
                              =
                              0
                           , 
                              
                                 
                                    t
                                 
                                 
                                    k
                                 
                              
                            = time that passed between SKL frame 
                              
                                 
                                    t
                                 
                                 
                                    k
                                    −
                                    1
                                 
                              
                            and 
                              
                                 
                                    t
                                 
                                 
                                    k
                                 
                              
                           , 
                              
                                 
                                    t
                                 
                                 
                                    n
                                 
                              
                            – time that passed between frame 
                              
                                 
                                    t
                                 
                                 
                                    n
                                    −
                                    1
                                 
                              
                            and 
                              
                                 
                                    t
                                 
                                 
                                    n
                                 
                              
                           .

For us the most important information is an event of transition of SKL frame between one cluster to another and time that passed from one transition to another. The transformation of (13) to the form that we can process can be done with the following algorithm:


                           n
                           -gram generation algorithm
                        


                           
                              
                                 
                                    Time:=0
                                    
                                    NS:=EMPTY
                                    
                                    NT:=EMPTY
                                    
                                    J:=0
                                    
                                    ActualCluster:=X
                                    
                                    FORallelementsSiinS
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       IF(ActualCluster==X)
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       IF(Si!=X)
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       NSj:=Si
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       NTj:=Time
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ActualCluster=Si
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ELSE
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       Time:=Time+Ti
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ENDIF
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       ELSE
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       IF(ActualCluster!=Si)
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       IF(Si!=X)
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       j:=j+1
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       NSj:=Si
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       NTj:=0
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ActualCluster=Si
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ENDIF
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       ENDIF
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       
                                       NTj:=NTj+Ti
                                    
                                    
                                       
                                       
                                       
                                       
                                       
                                       ENDIF
                                    
                                    ENDFOR
                                 

Now NT contains sequence of clusters that can be easily used to compute (12).

The comparison of probability of particular diagram type (for example 3-gram, 4-gram or 5-gram) might be not sufficient to correctly identify the proper order of key frames. That is because often the less numerous n-gram is more probable than the one with more elements. For example in the case of key frames sequence:
                              
                                 
                                    
                                       ABCABABCAB
                                    
                                 
                              
                           
                           
                              
                                 
                                    P
                                    (
                                    A
                                    B
                                    )
                                    =
                                    
                                       4
                                       9
                                    
                                    
                                    while 
                                    
                                    P
                                    (
                                    A
                                    B
                                    C
                                    A
                                    B
                                    )
                                    =
                                    
                                       2
                                       6
                                    
                                    .
                                 
                              
                            Of course without partitioning training dataset into one-gesture samples it is impossible to determine if AB or 
                              A
                              B
                              C
                              A
                              B
                            (or any other n-gram that is present here) is a correct answer. We assumed in Sections 2.1–5, that we do not want to do this type of partitioning to whole dataset. To check the correct order of frames we can however utilize some small part of training dataset (for example 5% of samples) and take longest n-grams that appear in most of the samples. The n-gram analysis on whole training dataset might not be much in use for finding appropriate order of frames and quantity of “n”, however it supplies us with information about time spans that passes between each key frame in sequence (NT). We can make “safe” estimation that time 
                              
                                 
                                    t
                                 
                                 
                                    A
                                    →
                                    B
                                 
                              
                            which passes between key frames A and B is:
                              
                                 (15)
                                 
                                    
                                       
                                          t
                                       
                                       
                                          A
                                          →
                                          B
                                       
                                    
                                    =
                                    
                                       max
                                       
                                          i
                                          ∈
                                          N
                                       
                                    
                                    ⁡
                                    (
                                    
                                       
                                          t
                                       
                                       
                                          i
                                          A
                                          →
                                          B
                                       
                                    
                                    )
                                 
                              
                            where 
                              
                                 
                                    t
                                 
                                 
                                    i
                                    A
                                    →
                                    B
                                 
                              
                            is time that passes between i-th transitions from class A to B in sequence NS for a considered n-gram.

The 
                              
                                 
                                    t
                                 
                                 
                                    A
                                    →
                                    B
                                 
                              
                            is also quantized to satisfy the condition:
                              
                                 (16)
                                 
                                    
                                       m
                                       o
                                       d
                                    
                                    (
                                    
                                       
                                          t
                                       
                                       
                                          A
                                          →
                                          B
                                       
                                    
                                    ,
                                    
                                       
                                          t
                                       
                                       
                                          q
                                       
                                    
                                    )
                                    =
                                    0
                                 
                              
                            where 
                              
                                 
                                    t
                                 
                                 
                                    q
                                 
                              
                            is quantization time. The quantization simplifies the manual analysis of obtained results.

In this section we describe the setup and results of validation procedure of our R-GDL methodology. We also compare classification results obtained with R-GDL/GDL approach with state of the art multivariate normally continuous density HMM classifier.

R-GDL was validated on SKL files dataset that contains a group of adult people with age 25+ both men and women that performed gym worm-up and fitness exercises. The dataset consists of SKL recordings for 14 participants, 4 women (W1–W4) and 10 men (M1–M10) – W means a woman, M – man, numbers defines id of a participant. The exercises that were performed were: body weight lunge left (bwll), body weight lunge right (bwlr), body weight squat (bws), dumbbell bicep curl (dbc), jumping jacks (jj), side lunges left (sll), side lunges right (slr), standing dumbbell upright row (sdur), tricep dumbbell kickback (tdk). In Table 1
                         we have presented quantities of gestures of a given type that was performed on a given SKL recording by each person. As can be seen not every person have performed each gesture, also the numbers of gestures are not equal. That is because that recordings were made in a certain period of time and not all users were asked to perform all gestures (for example in four recordings bws was skipped). Those lacks were then completed by recordings from other four persons in order to complete the dataset. Each person was asked to perform those exercises how many times he is capable to, but not more than 10 (in order not to get too tired for next exercises). There were some people who made those exercises more than 10 times (for example M1). For the other hand many participants, were getting tired more quickly and it was decided to reduce number of repetitions to 5 of each type. The participant M4 after perfuming slr was not capable to perform sll correctly. The test set was portioned into 10 groups of recordings (the indexing number of test set is presented in second column of Table 1). We have used 14 SKL recordings (datasets) coming both from men and woman (W and M respectively). This partitioning is shown in first column. Those dataset was used to crate 10 test datasets for k-fold cross validation. The division on test datasets is shown in second column. Each test dataset besides one (the fourth) contains each type of examined gestures. The other columns contain quantities of gestures (exercises) of a given type that was performed in a given SKL recording. The criterion of division was that each set consists of SKL recordings from a single person. The movement samples of this person are not present in other sets. In case of users who were not performing particular gesture (bws in M3, M4, M5 and M8) those sets were complement with W3, W4, M6 and M9.

In Fig. 3
                         we have presented digitalized pictures that demonstrate important phases of each activity (they are not a GDLs key frames). We did not show body weight lunge left and side lunge left, because they are analogous to right ones.

In order to generate GDLs we used R-GDL methodology presented in Section 2.4. The k-fold cross validation was used to evaluate the results, where 
                           k
                           =
                           10
                        . Each gesture was trained separately and the results from all clustering of the single dataset were integrated into one GDLs that contained definitions of all nine gestures. The final validation was performed on these integrated GDLs. We arbitrary set epsilon parameter to 10 in considered cases. Because all features we used were based on angles (angles in GDL are calculated in degrees from range 
                           [
                           0
                           ,
                           180
                           ]
                        ) this value is about 10% of overall possible range of angle values. We must remember that the data capturing hardware we used for data acquisition is a multimedia device that might be highly inaccurate. The quantization time (16) is set to 
                           
                              
                                 t
                              
                              
                                 q
                              
                           
                           =
                           0.5
                            
                           sec
                        .

The number of clusters in all cases was set to three. In our case the choice of three clusters is arbitrary however it was forced by the low quality of tracking data we are dealing with (we already discussed this in Section 2.1). It is a quite an obvious observation that the more clusters are used to govern the movement there will be smaller number of movements incorrectly classified to a given class. We have to remember however when there are too much classes the whole method is more sensitive to noises and might lose its generalization ability. As we already mentioned the variability of pose estimation is about 10 cm for each joint. Due to this fact we decided to choose the smallest number of clusters that are sufficient to describe dynamic of movement. If we have chosen 2 clusters most probably we would detect only the initial and middle part of movement where are the largest number of samples in SKL recordings. It can be illustrated in side lunge exercises (see Fig. 3) where user spends most of time in stretching position with one knee joint bent and the other is stretched. The choice of three clusters allows us to detect the middle position of the movement with low risk of finding outliners instead. The good recognition rate obtained in further experiment assures us that our initial assumptions were correct. In order to use larger number of cluster we would have to gather dataset with better tracking quality (for example from professional motion capture hardware) which would be very interesting goal for future research.

To initialize the k-means method we used random partition method (all elements are randomly assigns to a cluster). Because of that we have repeated our training procedure three times and choose the results from which recognition count on training (not a validation) dataset was the highest. In rest of this evaluation we present only results of this chosen dataset.

The features we used for training are presented in Appendix B. We intentionally have chosen the relatively small subset of all possible (and reasonable) features that in our opinion might be suitable to obtain high accuracy of classification and to avoid “curse of dimensionality” during clustering. All of those features are invariant to rotation (they are angles defined between vectors determined by body joints). The only exception is “Bowing” features, that checks angle between “spine” and arbitrary chosen vertical axis and “SideDirection” computes angle between pelvis and horizontal axis in tdk activity that are not invariant to rotation.

The example clustering results (for one of the test sets) with assignment to GDLs key frames symbolized by different colors (yellow, cyan and dark red) is presented in Fig. 4
                         – key frame definition is presented in Section 2.4.1. Blue elements are not assigned to any key frame. The dimensionality is reduced to three dimensions with PCA. The visualization represent from left to right: first row – bwll, bwlr, bws exercise; second row – dbc, jj, sdur; third row – sll, slr, tdk. Those visualizations clearly show that some movements where based on limited number of “most important” muscles – joints (or group of muscles), that were bending and expanding in all possible range (like in case of bws that was knees, in case of dbc, tdk and sdur elbows) and the projected samples are mostly extended along single dimension. Other cases were more complicated. Especially difficult was sll and slr which additionally introduced noises caused by imperfection of methodology of data capturing and body tracking. The extreme tracking inaccuracies are clearly visible in bwlr and blwr as outlier elements.

In Fig. 5
                        . we present the example frames that were assigned to each of the cluster from Fig. 4. As can be seen agreeable to our expectations those results corresponds to our “intuitive guesses” from Fig. 3. The skeleton visualizations are based on SKL recordings of test set. We did not show body weight lunge left and side lunge left, because they are analogous to right ones.

After key frames detection we determined order of key frames by analyzing 3 exemplars of movements samples that we additionally segmented for each class of gestures. Of course all of those samples were taken from training (not validation) dataset. The time periods between key frames were computed using n-gram generation algorithm on whole training dataset (see Section 2.4.2).

In Table 2
                         we have presented validation results of our 10-fold cross evaluation. The evaluation was performed on unsegmented sequence of samples, where a person was performing the movement periodically. The class names in first column is an actual condition, columns 2–9 presents obtained results by GDL classifier (for example 
                           98
                           %
                           ±
                           6
                           %
                         of bwll exemplars were correctly classified while 
                           2
                           %
                           ±
                           6
                           %
                         where misclassified as bwlr). The rows in table do not sum up to 100%. Sums might either exceed or not this value. That is because GDL classifier is capable to detect multiple classes in the same recording sample (it is not a binary classifier); due to this fact we cannot measure its performance with precision-recall factors. This is very important feature of GDL, however in the case of our dataset we take an assumption that none of the movement should be treated as part of another one. Because of it two sll movements might be interpreted by single slr and vice versa (it will be explained in Section 3.3). We can see this kind of error (slr found in the sequence of sll) in 
                           13
                           %
                           ±
                           14
                           %
                         cases. This type of error (or “unwanted behavior”) can be easily minimized by introducing GDLs heuristic that will be described in the following section.

We have compared our results with multivariate normally continuous density HMM classifier. HMM classifier was composed of 3-state forward-only HMM and was trained to recognize the same set of classes as previously presented GDL method (each HMM in classifier was trained to recognize single body gesture). We have used the same features set as in GDL classifier. We have utilized Baum–Welch learning method. The evaluation was done with 10-fold cross evaluation however the data in validation set has been previously sampled that each data sample consisted only one gesture (so data has been previously segmented in contrary to unsegmented validation of R-GDL approach). The choice of forward-only 3-states HMM architecture was based on similar assumptions as we made we in Section 3.2 about clusters count and because forward-only architecture already proved its usefulness in gestures classification [11]. In Table 3
                         we have presented validation results of our 10-fold cross evaluation of HMM classifier. The rows in table sum up to 100% because our HMM classifier assigns one and only one label to each data sample.

Results in Table 2 showed that in 
                           13
                           %
                           ±
                           14
                           %
                         cases the sll class was confused with slr. This problem can be solved by three possible approaches:
                           
                              1)
                              If we want to exclude the possibility that one class of movement is a subset of another one we can simply clear the GDL stack any time the gesture of a given type is classified (this can be simply done with software API we have implemented).

The second possibility is to introduce heuristics that are based on our knowledge on nature of movement.

We can redo the features selection for the classifier for example by adding features that represents movements of body parts that will most probably help with distinguish gestures.

The first approach would solve slr/sll confusion problem however that approach might disturb the recognition process of a gestures that might be also attached to our GDLs and which is a part of other gestures. Of course it is possible to run many instances of GDL classifier and separate the rules to those that are exclusive or not. We decided however to show that second and third approach, that uses only GDLs 1.1 instructions and does not require knowledge about implementation of classifier.

The confusion of sll with slr is caused by the fact, that R-GDL rules do not investigate the direction of movement, but only appearance of particular key frames. In case of sll in initial phase the person is putting the weight on the left leg by moving body to the left side (in case of slr movement is in opposite direction). The final extreme body position are governed by angle values computed by R-GDL, however, during the phase of movement where body is returning from the extreme right or left positions the considered angles in knees and hips might be similar to those that are in key frames of slr in case of sll and slr in case of sll. Due to this fact during periodic repetition of sll and slr the additional incorrect recognition of the other movement might appear. In order to eliminate these phenomena, we can supply the GDLs with additional information about direction of movement by including the following rules:


                        
                           RULE Spine.x[0] - Spine.x[1] > 10
                     


                        
                           THEN MovementsRightPart
                     


                        
                           RULE Spine.x[0] - Spine.x[1] < -10
                     


                        
                           THEN MovementsLeftPart
                     


                        
                           RULE rulepersists(MovementsLeftPart,0.25,0.5)
                     


                        
                           THEN MovementsLeft
                     


                        
                           RULE rulepersists(MovementsRightPart,0.25,0.5)
                     


                        
                           THEN MovementsRight
                     

Rulepersits function governs the direction of movement and check if it is performed to the left or the right side (for detailed information about this function check Appendix A). Now the conclusion of appropriate rule have to be added to key frame definition (MovementsLeft for sll and MovementsRight for slr). Our GDLs implementation can be found in Appendix C. After introducing the above heuristic we have found that error classification of sll to slr was reduced by 11% to the level of 
                           2
                           %
                           ±
                           5
                           %
                        .

The third case is typical tuning procedure of features set. By adding more features we add more constraints on data that might help in distinction between gestures classes. However we must remember that adding more constraints on data might cause lowering the ability of classifier's generalization. We have re-trained our GDL classifier for slr and sll classes using extended features set for sll/slr from Appendix B. After this we have found that error classification of sll to slr was reduced by 7% to the level of 
                           6
                           %
                           ±
                           10
                           %
                        . Neither second nor third approach however did cause increase in recognition rate of sll and slr.

@&#DISCUSSION@&#

The results of validation presented in Table 2 showed high recognition rate of our methodology. Depending of gesture type it was 91% to even 100%. These results are very promising especially that the gym exercises dataset is difficult to classify. That is because simultaneous processing of multiple features is necessary for correct identification and some gestures are very similar to other (for example dbc to sdur).

The outcomes of k-fold cross validation procedure proved that R-GDL-generated GDLs rules have ability of generalization. Also the visual evaluation of clustering results (Fig. 4) and visualization of example key frames (Fig. 5) showed, that in this case k-means clustering algorithm generates intuitive results (we have already discussed this in Section 3). This fact is very important, because it shows that R-GDL preserves one of the basic assumptions of GDL that is intuitiveness of approach and simplicity of rules interpretation. Thanks to that it is also very easy to introduce some heuristic GDLs construction to increase recognition rate of automatically trained classifier even more. Also key frames order and between-frames time spans determination algorithm correctly predicted those values.

Basing on the results we can state that epsilon that was used to compensate inaccuracies of body tracking does not deteriorate the overall recognition rate. We can conclude about this because very seldom one class was confused with another by the classifier. In case of hardware with better precision of capturing (for example motion capture systems) we believe that epsilon might be set to zero.

Our experiment also showed that if the features are properly selected the R-GDL rules are capable to distinguish between different classes even though the training of each set of rules was made separately for each type of gestures. The most difficult to recognize were bws, slr, sll and tdk. That is because during performing those physical activities when a person is facing Kinect (bws, slr and sll) particular body parts that are important to recognize the gesture are covered by another and data tracking software cannot estimate those body joints positions correctly. In slr and sll the hands are additionally very close to corpus which highly disturbs the body segmentation. In case of tdk user is positioned sideways to camera because in this position data capturing sensor can observe all most important joints to classify this exercise. However left part of the body is nearly covered by the right one which results in deteriorating overall classification results. All of this introduces inevitable tracking inaccuracies that were already enumerated in Section 2.1. We believe that application of more precise tracking hardware will cause in reducing those errors to minimum.

The biggest difference of recognition rate between R-GDL and state-of-the art HMM classifier equals 10% and is present between slr classes. The high value of standard deviation indicates that recognition error of HMM was present in few test datasets (mainly in 2 of 10 where recognition rate was 40% and 15%). That indicates worse generalization potential of HMM model in comparison to GDL. The recognition rate for all considered classes in case of GDL classifier never dropped below 91% (in case of HMM it was 81%). We have also to remember that classification task of HMM was much easier than those of GDL because our HMM operated on pre-segmented data and for HMM it was not necessary to detect a gesture in continues recordings. Continues recordings always contains some irrelevant for classification task perspective movements. It is of course possible to create HMM capable to continues data classification and to distinguish between exemplars of classes and unknown signals (for example with thresholding approach [31]) however in our case it was not necessary for the comparision with GDL. We can observe that GDL has a bit worse recognition rates for five classes (namely from 2% to 7%). The errors each classifier made confusing one class with another are not same distributed which is quite obvious because both methods uses different mathematical models. Both classifiers had similar problem confusing sll and slr classes. The biggest advantage of GDL over HMM is that straightforward architecture of R-GDL/GDL approach is capable not only to classify various movements from samples but also to do it straightforward from real-time continues recording without additional thresholding schemas. Also it is very easy to interpreted the results given as an output of R-GDL training and to expand it with manually designed heuristics. In case of HMM the manual modification of trained classifier in order its improvement is rather impossible and HMM framework was not design to provide this functionality. Due to this fact R-GDL/GDL is very powerful and easy to learn tool that can be used in practice both in academic tasks and in industry. Also our syntactic approach allows straightforward possibility of manual rule-based definition of basic but usable movements patters (like from example those presented in [16]) for which classifier that need to be trained (like HMM) generates additional costs of collecting proper database of movements' recordings.

@&#CONCLUSION@&#

The R-GDL unsupervised learning method complemented our syntactic GDL approach with possibility of automatic generation of GDLs descriptions basing on set of SKL recordings. The ability to generate syntactic descriptions of full body gesture comprehensible to user is among most important features of our new method. The other are short time required to prepare the data for training (it is not necessary to segment whole data into samples that consists only single movement activity) and intuitiveness of training parameters. Together with high recognition rate and ability to process unsegmented data they make our approach especially useful both to scientific and commercial applications.

GDL together with R-GDL is a novel combination that has huge potential in many fields. The most obvious is generation of GDLs for GDL classifier and utilizing them in scientific and commercial projects. Scientists and computer programmers choose GDL because its attractive features like real time performance and many other that were already mentioned. R-GDL highly speed up the process of rules definition and validation (which was most time demanding) and we anticipate that it will quickly become one of the most common approach for this kind of computational problem.

The other interesting application is utilizing this method for computer analysis of various human movements activities. The GDLs generated with R-GDL might be a source of knowledge about nature of movements. The visualizations of both SKL datasets clusters and key-frames of GDLs might give valuable information both during analyzing human population and case-study. This however requires utilizing more precise hardware/software tracking solution.

In the future we would like to introduce to R-GDL/GDL possibility of quantitative evaluation of performed gestures. By quantitative evaluation we mean possibility of scoring similarity of recognized gesture to a pattern that was established during R-GDL training of classifier. In case when we are dealing with a low-quality data from multimedia Kinect controller this kind of evaluation will not give much valuable information because of tracking inaccuracies however after introducing professional motion capture hardware this quantitative evaluation will have many potentially interesting applications. For example it could be used in computer-aided sport training applications to indicate the flaws of user techniques or for example during medical evaluation of body movements and rehabilitation. This future goal might be realized by appropriate definition of features set for R-GDL training and by adding additional quantitative evaluation functions that will be accessible from GDLs syntax and application programming interface.

@&#ACKNOWLEDGEMENTS@&#

We kindly thank company NatuMed Sp. z o.o (Targowa 17a, 42-244 Wancerzow, Poland) for supplying us with SKL dataset that together with our own SKL recordings was used as training and validation dataset in this research.

The formal definition of GDLs 1.0 is given in paper [16]. GDL 1.0 is a context-free grammar:
                        
                           
                              
                                 GDLs
                              
                              =
                              {
                              
                                 
                                    V
                                 
                                 
                                    N
                                 
                              
                              ,
                              
                                 
                                    V
                                 
                                 
                                    T
                                 
                              
                              ,
                              
                                 SP
                              
                              ,
                              
                                 STS
                              
                              }
                           
                        
                      GDLs 1.1 is extension of GDLs 1.0 and it is also a context-free grammar.
                        
                           
                              
                                 
                                    GDLs
                                 
                                 
                                    1.1
                                 
                              
                              =
                              {
                              
                                 
                                    V
                                 
                                 
                                    N1.1
                                 
                              
                              ,
                              
                                 
                                    V
                                 
                                 
                                    T1.1
                                 
                              
                              ,
                              
                                 
                                    SP
                                 
                                 
                                    1.1
                                 
                              
                              ,
                              
                                 STS
                              
                              }
                           
                        
                      where 
                        
                           
                              V
                           
                           
                              N1.1
                           
                        
                      is a set of nonterminal symbols, 
                        
                           
                              V
                           
                           
                              T1.1
                           
                        
                      is a set of terminal symbols, 
                        
                           
                              SP
                           
                           
                              1.1
                           
                        
                      is a set of productions and STS is the start symbol of the grammar.


                     
                        
                           VN1.1 = VN + {FeatureNumeric}
                        
                     
                  


                     
                        
                           VT1.1 = VT + {RulePersistsFunction, FeatureNumericName, FeatureNumeric3DName, FeatureSymbol, AsSymbol}
                        
                     
                  

SP1.1 = SP + New productions (see below)
                        
                           
                              
                                 
                                    STS
                                 
                                 
                                    1.1
                                 
                              
                              =
                              
                                 STS
                              
                           
                        
                      Body joint sets supplied by the third-party tracking library are mapped to NumericRule and Numeric3DRule terminal symbols. For Kinect SDK 1.7/1.8 tracking library the set becomes:


                     
                        BodyParts = {HipCenter, Spine, ShoulderCenter, Head, ShoulderLeft, ElbowLeft, WristLeft, HandLeft, ShoulderRight, ElbowRight, WristRight, HandRight, HipLeft, KneeLeft, AnkleLeft, FootLeft, HipRight, KneeRight, AnkleRight, FootRight} + {.x|.y|.z} + {[}
                     
                  


                     
                        BodyParts3D={HipCenter, Spine, ShoulderCenter, Head, ShoulderLeft, ElbowLeft, WristLeft, HandLeft, ShoulderRight, ElbowRight, WristRight, HandRight, HipLeft, KneeLeft, AnkleLeft, FootLeft, HipRight, KneeRight, AnkleRight, FootRight} + {.xyz[}
                     
                  


                     
                        
                           RulePersistsFunction = {rulepersists(}
                        
                      – this function returns true if a given conclusion is present in the last x seconds in at least y percent of memory stack levels. This function returns false in other cases.

For example:


                     rulepersists(gesture, 4.5, 0.92) – returns true if the conclusion “gesture” is present in at least 92% of memory stack levels over the last 4.5 seconds.


                     The new productions are:
                  

Rule → FeatureNumeric

FeatureNumeric → FeatureSumbol NumericRule AsSymbol FeatureNumericName

NumericRule → FeatureNumericName

LogicalRule → RulePersistsFunction Conclusion Comma NumericRule Comma Numeri-cRule ClosedBracket


                     
                        
                           FeatureNumericName
                        
                      – Any string after the AsSymbol is a FeatureName. Any unrecognized string is hypothetically this one. Because rules and features can appear in any order, at the end of the parsing, the parser checks if all unrecognized strings appear after the AsSymbol and if it forms a part of a FeatureNumeric production. If not, the GDL script contains an error. Features are parsed before rules.

For example:


                     
                        FEATURE 24 – 15.5 AS MyFeature
                  

In this case MyFeature equals 8.5.

Conclusion, FeatureNumericName should consist of alphanumeric characters ([a–z], [A–Z], [0–9]) and can also contain “_” or “–“ or “!” but the exclamation cannot constitute the first letter.

In this section we present feature definitions we used to initialize R-GDL training.

Below features were used for the following movements: body weight lunge (left and right), body weight squat, dumbbell bicep curl, standing dumbbell upright row


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     WristRight.xyz[0] - ElbowRight.xyz[0]) AS RightElbow
                  


                     
                        FEATURE angle(ShoulderLeft.xyz[0] - ElbowLeft.xyz[0],
                  


                     WristLeft.xyz[0] - ElbowLeft.xyz[0]) AS LeftElbow
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderRight.xyz[0],
                  


                     ElbowRight.xyz[0] - ShoulderRight.xyz[0]) AS RightShoulder
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderLeft.xyz[0],
                  


                     ElbowLeft.xyz[0] - ShoulderLeft.xyz[0]) AS LeftShoulder
                  


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     ShoulderLeft.xyz[0] - ElbowLeft.xyz[0]) AS BetweenWrists
                  


                     
                        FEATURE angle(HipRight.xyz[0] - KneeRight.xyz[0],
                  


                     AnkleRight.xyz[0] - KneeRight.xyz[0]) AS RightKnee
                  


                     
                        FEATURE angle(HipLeft.xyz[0] - KneeLeft.xyz[0],
                  


                     AnkleLeft.xyz[0] - KneeLeft.xyz[0]) AS LeftKnee
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - HipCenter.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS RightHip
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - HipCenter.xyz[0],
                  


                     KneeLeft.xyz[0] - HipLeft.xyz[0]) AS LeftHip
                  

Below features were used for jumping jacks


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     WristRight.xyz[0] - ElbowRight.xyz[0]) AS RightElbow
                  


                     
                        FEATURE angle(ShoulderLeft.xyz[0] - ElbowLeft.xyz[0],
                  


                     WristLeft.xyz[0] - ElbowLeft.xyz[0]) AS LeftElbow
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderRight.xyz[0],
                  


                     ElbowRight.xyz[0] - ShoulderRight.xyz[0]) AS RightShoulder
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderLeft.xyz[0],
                  


                     ElbowLeft.xyz[0] - ShoulderLeft.xyz[0]) AS LeftShoulder
                  


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     ShoulderLeft.xyz[0] - ElbowLeft.xyz[0]) AS BetweenWrists
                  


                     
                        FEATURE angle(KneeLeft.xyz[0] - HipLeft.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS BetweenLegs
                  

Below features were used for side lunges (left and right)


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     WristRight.xyz[0] - ElbowRight.xyz[0]) AS RightElbow
                  


                     
                        FEATURE angle(ShoulderLeft.xyz[0] - ElbowLeft.xyz[0],
                  


                     WristLeft.xyz[0] - ElbowLeft.xyz[0]) AS LeftElbow
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderRight.xyz[0],
                  


                     ElbowRight.xyz[0] - ShoulderRight.xyz[0]) AS RightShoulder
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderLeft.xyz[0],
                  


                     ElbowLeft.xyz[0] - ShoulderLeft.xyz[0]) AS LeftShoulder
                  


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     ShoulderLeft.xyz[0] - ElbowLeft.xyz[0]) AS BetweenWrists
                  


                     
                        FEATURE angle(HipRight.xyz[0] - KneeRight.xyz[0],
                  


                     AnkleRight.xyz[0] - KneeRight.xyz[0]) AS RightKnee
                  


                     
                        FEATURE angle(HipLeft.xyz[0] - KneeLeft.xyz[0],
                  


                     AnkleLeft.xyz[0] - KneeLeft.xyz[0]) AS LeftKnee
                  


                     
                        FEATURE angle(KneeLeft.xyz[0] - HipLeft.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS BetweenLegs
                  

Below features were used for tricep dumbbell kickback:


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     WristRight.xyz[0] - ElbowRight.xyz[0]) AS RightElbow
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderRight.xyz[0],
                  


                     ElbowRight.xyz[0] - ShoulderRight.xyz[0]) AS RightShoulder
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - HipCenter.xyz[0], [0,1,0]) AS Bowing
                  


                     
                        FEATURE angle(HipRight.xyz[0] - HipLeft.xyz[0], [1,0,0]) AS SideDirection
                  


                     
                        FEATURE angle(KneeLeft.xyz[0] - HipLeft.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS BetweenLegs
                  

The extended features set for sll/slr are the same as those used for body weight lunge and additionally:


                     
                        FEATURE angle(KneeLeft.xyz[0] - HipLeft.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS BetweenLegs
                  

This appendix presents an example GDLs that describes side lunge left movement. It was generated with R-GDL for test set number 7. The underlined fonts show rules that were added later as a heuristic by a user. Those additional rules eliminate the recognition errors that were described in Section 3.3.


                     //-------------Original FEATURES---------------------------
                  


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     WristRight.xyz[0] - ElbowRight.xyz[0]) AS RightElbow
                  


                     
                        FEATURE angle(ShoulderLeft.xyz[0] - ElbowLeft.xyz[0],
                  


                     WristLeft.xyz[0] - ElbowLeft.xyz[0]) AS LeftElbow
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderRight.xyz[0],
                  


                     ElbowRight.xyz[0] - ShoulderRight.xyz[0]) AS RightShoulder
                  


                     
                        FEATURE angle(ShoulderCenter.xyz[0] - ShoulderLeft.xyz[0],
                  


                     ElbowLeft.xyz[0] - ShoulderLeft.xyz[0]) AS LeftShoulder
                  


                     
                        FEATURE angle(HipRight.xyz[0] - KneeRight.xyz[0],
                  


                     AnkleRight.xyz[0] - KneeRight.xyz[0]) AS RightKnee
                  


                     
                        FEATURE angle(HipLeft.xyz[0] - KneeLeft.xyz[0],
                  


                     AnkleLeft.xyz[0] - KneeLeft.xyz[0]) AS LeftKnee
                  


                     
                        FEATURE angle(ShoulderRight.xyz[0] - ElbowRight.xyz[0],
                  


                     ShoulderLeft.xyz[0] - ElbowLeft.xyz[0]) AS BetweenWrists
                  


                     
                        FEATURE angle(KneeLeft.xyz[0] - HipLeft.xyz[0],
                  


                     KneeRight.xyz[0] - HipRight.xyz[0]) AS BetweenLegs
                  


                     //-------------R-GDLv1.0 FEATURES------------------------------------
                  


                     
                        FEATURE 10 AS rightelbow_EPS
                  


                     
                        FEATURE 10 AS leftelbow_EPS
                  


                     
                        FEATURE 10 AS rightshoulder_EPS
                  


                     
                        FEATURE 10 AS leftshoulder_EPS
                  


                     
                        FEATURE 10 AS betweenwrists_EPS
                  


                     
                        FEATURE 10 AS rightknee_EPS
                  


                     
                        FEATURE 10 AS leftknee_EPS
                  


                     
                        FEATURE 10 AS betweenlegs_EPS
                  


                     
                        
                           
                              
                              
                              
                                 
                                    
                                       
                                          FEATURE 83 AS rightelbow_MEAN_0
                                    
                                    
                                       
                                          FEATURE 26 AS rightelbow_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 83 AS leftelbow_MEAN_0
                                    
                                    
                                       
                                          FEATURE 28 AS leftelbow_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 132 AS rightshoulder_MEAN_0
                                    
                                    
                                       
                                          FEATURE 20 AS rightshoulder_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 138 AS leftshoulder_MEAN_0
                                    
                                    
                                       
                                          FEATURE 16 AS leftshoulder_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 40 AS betweenwrists_MEAN_0
                                    
                                    
                                       
                                          FEATURE 21 AS betweenwrists_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 166 AS rightknee_MEAN_0
                                    
                                    
                                       
                                          FEATURE 9 AS rightknee_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 159 AS leftknee_MEAN_0
                                    
                                    
                                       
                                          FEATURE 14 AS leftknee_DEV_0
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 53 AS betweenlegs_MEAN_0
                                    
                                    
                                       
                                          FEATURE 18 AS betweenlegs_DEV_0
                                    
                                 
                              
                           
                        
                     
                  


                     
                        
                           
                              
                              
                              
                                 
                                    
                                       
                                          FEATURE 63 AS rightelbow_MEAN_1
                                    
                                    
                                       
                                          FEATURE 29 AS rightelbow_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 90 AS leftelbow_MEAN_1
                                    
                                    
                                       
                                          FEATURE 34 AS leftelbow_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 112 AS rightshoulder_MEAN_1
                                    
                                    
                                       
                                          FEATURE 22 AS rightshoulder_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 109 AS leftshoulder_MEAN_1
                                    
                                    
                                       
                                          FEATURE 24 AS leftshoulder_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 33 AS betweenwrists_MEAN_1
                                    
                                    
                                       
                                          FEATURE 19 AS betweenwrists_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 143 AS rightknee_MEAN_1
                                    
                                    
                                       
                                          FEATURE 18 AS rightknee_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 110 AS leftknee_MEAN_1
                                    
                                    
                                       
                                          FEATURE 27 AS leftknee_DEV_1
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 96 AS betweenlegs_MEAN_1
                                    
                                    
                                       
                                          FEATURE 22 AS betweenlegs_DEV_1
                                    
                                 
                              
                           
                        
                     
                  


                     
                        
                           
                              
                              
                              
                                 
                                    
                                       
                                          FEATURE 152 AS rightelbow_MEAN_2
                                    
                                    
                                       
                                          FEATURE 15 AS rightelbow_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 148 AS leftelbow_MEAN_2
                                    
                                    
                                       
                                          FEATURE 15 AS leftelbow_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 140 AS rightshoulder_MEAN_2
                                    
                                    
                                       
                                          FEATURE 10 AS rightshoulder_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 139 AS leftshoulder_MEAN_2
                                    
                                    
                                       
                                          FEATURE 9 AS leftshoulder_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 32 AS betweenwrists_MEAN_2
                                    
                                    
                                       
                                          FEATURE 11 AS betweenwrists_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 171 AS rightknee_MEAN_2
                                    
                                    
                                       
                                          FEATURE 5 AS rightknee_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 170 AS leftknee_MEAN_2
                                    
                                    
                                       
                                          FEATURE 7 AS leftknee_DEV_2
                                    
                                 
                                 
                                    
                                       
                                          FEATURE 15 AS betweenlegs_MEAN_2
                                    
                                    
                                       
                                          FEATURE 16 AS betweenlegs_DEV_2
                                    
                                 
                              
                           
                        
                     
                  


                     //-------------R-GDLv1.0 RULES---------------------------------------
                  


                     
                        
                           RULE Spine.x[0] - Spine.x[1] > 10 THEN MovementsRightPart
                     
                  


                     
                        
                           RULE Spine.x[0] - Spine.x[1] < -10 THEN MovementsLeftPart
                     
                  


                     
                        
                           RULE rulepersists(MovementsLeftPart,0.25,0.5) THEN MovementsLeft
                     
                  


                     
                        
                           RULE rulepersists(MovementsRightPart,0.25,0.5) THEN MovementsRight
                     
                  


                     
                        RULE 
                        MovementsLeft & abs(rightelbow -rightelbow_MEAN_0) <= rightelbow_DEV_0 + rightelbow_EPS
                  


                     & abs(leftelbow -leftelbow_MEAN_0) <= leftelbow_DEV_0 + leftelbow_EPS
                  


                     & abs(rightshoulder -rightshoulder_MEAN_0) <= rightshoulder_DEV_0 + rightshoulder_EPS
                  


                     & abs(leftshoulder -leftshoulder_MEAN_0) <= leftshoulder_DEV_0 + leftshoulder_EPS
                  


                     & abs(betweenwrists -betweenwrists_MEAN_0) <= betweenwrists_DEV_0 + betweenwrists_EPS
                  


                     & abs(rightknee -rightknee_MEAN_0) <= rightknee_DEV_0 + rightknee_EPS
                  


                     & abs(leftknee -leftknee_MEAN_0) <= leftknee_DEV_0 + leftknee_EPS
                  


                     & abs(betweenlegs -betweenlegs_MEAN_0) <= betweenlegs_DEV_0 + betweenlegs_EPS
                  


                     
                        THEN SideLungesLeft0
                  


                     
                        RULE abs(rightelbow -rightelbow_MEAN_1) <= rightelbow_DEV_1 + rightelbow_EPS
                  


                     & abs(leftelbow -leftelbow_MEAN_1) <= leftelbow_DEV_1 + leftelbow_EPS
                  


                     & abs(rightshoulder -rightshoulder_MEAN_1) <= rightshoulder_DEV_1 + rightshoulder_EPS
                  


                     & abs(leftshoulder -leftshoulder_MEAN_1) <= leftshoulder_DEV_1 + leftshoulder_EPS
                  


                     & abs(betweenwrists -betweenwrists_MEAN_1) <= betweenwrists_DEV_1 + betweenwrists_EPS
                  


                     & abs(rightknee -rightknee_MEAN_1) <= rightknee_DEV_1 + rightknee_EPS
                  


                     & abs(leftknee -leftknee_MEAN_1) <= leftknee_DEV_1 + leftknee_EPS
                  


                     & abs(betweenlegs -betweenlegs_MEAN_1) <= betweenlegs_DEV_1 + betweenlegs_EPS
                  


                     
                        THEN SideLungesLeft1
                  


                     
                        RULE abs(rightelbow -rightelbow_MEAN_2) <= rightelbow_DEV_2 + rightelbow_EPS
                  


                     & abs(leftelbow -leftelbow_MEAN_2) <= leftelbow_DEV_2 + leftelbow_EPS
                  


                     & abs(rightshoulder -rightshoulder_MEAN_2) <= rightshoulder_DEV_2 + rightshoulder_EPS
                  


                     & abs(leftshoulder -leftshoulder_MEAN_2) <= leftshoulder_DEV_2 + leftshoulder_EPS
                  


                     & abs(betweenwrists -betweenwrists_MEAN_2) <= betweenwrists_DEV_2 + betweenwrists_EPS
                  


                     & abs(rightknee -rightknee_MEAN_2) <= rightknee_DEV_2 + rightknee_EPS
                  


                     & abs(leftknee -leftknee_MEAN_2) <= leftknee_DEV_2 + leftknee_EPS
                  


                     & abs(betweenlegs -betweenlegs_MEAN_2) <= betweenlegs_DEV_2 + betweenlegs_EPS
                  


                     
                        THEN SideLungesLeft2
                  


                     
                        RULE SideLungesLeft2 & sequenceexists("[SideLungesLeft1,3][SideLungesLeft0,2][SideLungesLeft2,2]")
                  


                     
                        THEN SideLungesLeft
                  


                     
                        RULE SideLungesLeft & sequenceexists("[!SideLungesLeft,1]")
                  


                     
                        THEN SideLungesLeft!
                  

@&#REFERENCES@&#


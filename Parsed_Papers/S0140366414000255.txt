@&#MAIN-TITLE@&#A study of user behavior in online VoD services

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We discover a quite consistent user early departure pattern for different sets of view records, over different time periods, for videos of different popularity.


                        
                        
                           
                           We show the distribution of the number of videos a user transition through. This understanding helps construct a more realistic user behavior model.


                        
                        
                           
                           We show seeks can be considered as part of video browsing, and explain what users are doing using seek: either emulating fast-forwarding or looking for some specific content.


                        
                        
                           
                           We measure a user-level video switching and early departure behavior.


                        
                        
                           
                           We explore the online video popularity, and users’ seek behavior.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

User behavior

VoD service

Measurement

@&#ABSTRACT@&#


               
               
                  A big portion of Internet traffic nowadays is video. A good understanding of user behavior in online Video-on-Demand (VoD) systems can help us design, configure and manage video content distribution. With the help of a major VoD service provider, we conducted a detailed study of user behavior watching streamed videos over the Internet. We engineered the video player at the client side to collect user behavior reports for over 540 million sessions. In order to isolate the possible effect of session quality of experience (QoE) on user behavior, we use only the sessions with perfect QoE, and leave out those sessions with QoE impairments (such as freezes). Our main finding is that users spend a lot of time browsing: viewing part of one video after another, and only occasionally (around 20% of the time) watching a video to its completion. We consider seek (jump to a new position of the video) as a special form of browsing – repeating partial viewing of the same video. Our analysis leads to a user behavior model in which a user transitions through a random number of short views before a longer view, and repeats the process a random number of times. This model can be considered an extension, and a more detailed alternative to the closed queueing network formulation introduced by Wu et al. (2009) [1]. As an application of our user behavior model, we use it to measure video popularity. We study the similarity of our approach to subjective evaluation and simple view count based metric, and conclude our approach gives results closer to subjective evaluation.
               
            

@&#INTRODUCTION@&#

Significant traffic on the Internet today can be attributed to video content distribution [2]. Increasingly people choose some online service such as Netflix and Hulu for watching movie and TV (in US), and use YouTube to share video clips. On-line video services are also very popular in China. Tencent Video [3], Youku and Tudou are some of the most popular service providers.

Understanding user behaviors in watching Internet video is helpful for improving system design and configuration. For example, a recent paper used user engagement to identify the quality of experience (QoE) factors that affect the users most [4], thus identifying which QoE factors should be addressed first in system design, and even attached a dollar value to the consequences. Our work focuses on studying user’s natural behavior during online videos viewing, by excluding those session reports with QoE impairments in the collected dataset. Using this approach, we can initially disassociate the effect of QoE on user behavior, and add it later on.

Our purpose of studying user behavior is to build a user behavior model to help study system performance and design issues. To this end, our main finding is that the user demand on a VoD streaming service is mainly video browsing; namely, sampling videos partially before selecting a video to view to completion. Based on a detailed model of this behavior, we can improve system design and configuration in various ways. For example, we can design progressive downloading algorithms that will minimize wastage, the amount of downloaded video that is never viewed; we can also optimize what content we replicate at different servers; and design new features to help users search for the content that interest them more effectively.

Sometimes it is convenient to use an abstract user behavior model, especially in analytical studies. The closed-queueing-network model (WLR) proposed in [1] to study multi-channel live streaming is a good example. In this model, users pick (next) videos to watch based on a transition matrix, and watch each video for an exponential amount of time. While WLR is elegant and analytically convenient, it is not detailed and accurate enough for studying some performance problems. In this paper, our measurement-based exploration of user behavior will also let us build a load model, but with more details, and based on what is observed in a practical system.

For our study, the dataset comes from our collaborator Tencent Video, one of the largest video streaming service providers in China. They have more than 45 million active users on a daily basis, and more than 1.5 million users online concurrently during busy hours. Their video content includes movie, TV episodes, music/entertainment video, as well as many short clips of news and sports. The online VoD service is delivered via HTTP/TCP. We collected a large set of user viewing records over one month period from their large-scale real-world VoD system. The total size of data records are 490GB. We use a Hadoop system to process this big data and perform our analysis of various video browsing behavior.

The main results can be summarized as follows: (1) We discover a quite consistent user early departure pattern for different sets of view records, over different time periods, for videos of different popularity. We propose a generic model for user departures (that is different than simple exponential departures in [1]). (2) We show the distribution of the number of videos a user transition through. This understanding helps construct a more realistic user behavior model as an open-loop queueing system. (3) We show seeks can be considered as part of video browsing, and explain what users are doing using seek: either emulating fast-forwarding or looking for some specific content. (4) Based on the above, we build a user-level model for the video browsing behavior. We discuss how such a user-behavior model can be used as a load model in system performance studies. (5) We apply the observation of user behavior to explore the online video popularity.

The paper is organized as follows. In Section 2, we describe the system we measured, and how we did the measurement. In Section 3, the meat of this paper, we summarize all the measurement results. Also, we discuss the video popularity based on user behavior study in Section 4. Section 5 gives a brief discussion of related works, and we conclude and briefly discuss directions for future works in the last section.

We begin by fixing some terminology. We have users and videos. A user watches one or multiple videos. A view (record) is the information associated with the viewing by a user of a single video. The information includes things like whether the user viewed a portion or the full video, and how often/long the events of pause, freeze and seek occurred. Videos are categorized into types according to their content. They are also partitioned into two groups – popular and unpopular – according to view counts. The basic format of a view record is shown as follows:
                           
                              
                                 date
                                 ‖
                                 user id
                                 ‖
                                 video
                                 ‖
                                 play timestamp
                                 ‖
                                 stop timestamp
                                 ‖
                                 pause
                                 ‖
                                 freeze
                                 ‖
                                 seek.
                              
                           
                        
                     

We study user behavior by collecting a large set of views. A user’s actions during a viewing session include various events: arrival, play, pause, seek, and departure. A view with impaired QoE (indicated by freezes) during playback is discarded in our analysis.
                           1
                           We note that the QoE for VoD streaming usually consist of video quality, initial buffering time, seek-induced delay, freeze frequency and freeze durations. We take the freeze as a major factor of the impaired QoE.
                        
                        
                           1
                         A common user behavior is merely represented by a large set of views with similar pattern of events.

To collect view records, the VoD service platform is instrumented with the following capabilities: (1) the video player at the client side embeds a module to report the user behavior information in each view; (2) a distributed data collection system is set up to receive huge amount of the view records for later processing. Also, a distributed data processing system is built to analyze the collected data.

Since Tencent’s video service covers a large geographical region (mostly within China), the data collection involves many edge servers running in parallel in different places. All reported data will be aggregated into a datacenter, and stored in an unstructured database. To implement bigdata analysis, we introduce a distributed data processing system and analyze collected data in different time scale and quantity scale dimensions.

We collected over 540 million viewing records with perfect QoE over one month. These viewing records are generated and reported by around 48.9 million different users. The users come from all geographical regions in China according to commercial precise IP-geolocation mapping database. The videos sampled are of different genre and length.

In this study, we focus on four types of videos: (1) Movie (60∼180mins); (2) TV episode (30∼60mins); (3) Music video (3∼10mins); (4) Sport video clips (30s∼10mins). The number of viewing sessions for Movie and TV videos is more than the short ones in our collected reports. We believe this combination of video types is typical for video watched over the Internet. The proportion of these four types of views in our dataset is 
                           
                              6
                              :
                              9
                              :
                              1
                              :
                              2
                           
                        .

To study the video browsing behavior, we need to group the views by individual users. The IP address cannot reliably identify a single user since IP addresses may be dynamically assigned to users, or multiple users may share a common IP due to traversing NAT. Cookies are used to identify requests from the same user, but it can be cleared or disabled. In the system we study, we are able to identify each user by their social network identity. This important feature allows us to identify all views by the same user to study user behavior on a per-user basis.

@&#OVERVIEW@&#

Given the size of the dataset, there are a lot of different user behavior patterns we can mine, and report. To focus our efforts on things more useful, we actually started with some specific questions in mind, mostly related to how to improve system design and user experience (QoE). For example:
                           
                              •
                              How often and when do users quit viewing a video in the middle? Is this behavior predictable enough so that we can control progressive downloading policies to minimize wasted pre-buffering?

How many videos does a typical user go through? How much time does a typical user spend on a video before moving onto the next one? And does it depend on the number of videos already visited and time spent in the system?

Is there any regularity for user’s seek behavior, and does it depend on the content, or QoE? Can we engineer some other features that are more efficient and still satisfy users’ needs?

What we found is, there are a lot of early departures and seeks. Overall, around 80% of the sessions resulted in early departure, i.e. user quitting before completing the whole video. Also, around 62.5% of the viewing sessions had seeks. The best way to characterize or summarize the situation is that most users are engaging in what we call video browsing. This is not surprising if we think about it – a user is presented with a rather large collection of videos she may spend time watching, so it is natural for her to try out different ones until something really interesting is found. So our workload is a video browsing workload, and a smart VoD system should be designed to efficiently support this video browsing behavior.

It is well-known that QoE does affect user behavior. Several recent papers (e.g. [4]) studied this relationship and propose to use the observed user behavior to estimate/predict QoE. Therefore, the study of QoE and its effect of user behavior is not the main purpose of this paper. In fact, for the rest of the paper (beyond this subsection), our study is based on removing all the views with QoE impairments.
                           2
                           The QoE impairment refers to the playback freeze. Though, the QoE impairment is not unique, we believe, also consistent with recent studies, playback freeze is the most significant QoE impairment.
                        
                        
                           2
                         More specifically, our record is daily based thus a user’s daily record will be removed if there is any freeze.

However, to better understand our dataset, we include some QoE statistics below. Table 1
                         shows the distribution of the number of freezes for all the views we collected. In this case, only freezes before seeks, or without seeks are counted.

From the table, we observe that the overall performance of this VoD service is reasonably good in terms of freeze frequency, since around 
                           
                              80.5
                              %
                           
                         of the views ended without freezes. This summary gives us a rough calibration of the system under study.

The QoE and content related factors are always intertwined in the study of user behavior for watching online videos. To untangle them in our analysis, we choose to remove all the viewing reports with at least one freeze event. This way, we focus on the views under perfect QoE performance (the 80.5% of the reports in our dataset). Similarly, when we consider user-level behavior, we choose to remove any user who had at least one view that has freezes in it in each day. We refer to this as the user’s natural behavior, as opposed to user behavior induced by QoE.

Another factor that affect QoE is start-up delay. It occurs at two places: (1) at the start of video viewing, and (2) immediately after a seek, unless the seek destination is content already pre-fetched. Event (1) occurs for all views. For the VoD service we study, a fixed-length advertisement typically longer than the start-up delay is played, so the initial start-up delay is replaced by something users expect. So we do not count (1) as a QoE factor for filtering views. In order to study seeks, we do not remove seek-induced start-up delays either. Instead, we treat seeks in two ways: (a) treat seeks as part of a view; (b) treat seeks as separate views. By reporting our results for both (a) and (b), it helps us to isolate possible influence (at the view level) by QoE.

It is very common for users to quit viewing a video in the middle. Roughly, 56.4% videos are watched for less than half of their duration. After excluding the effect of QoE, the possible factors to cause early departure vary from the lack of interest in the video content, to other reasons such as the arrival time of video requests. To study early departure quantitatively, we define a metric called viewing ratio x to measure normalized amount of time a video is watched. Normally, for a particular video, viewing time T depends on the length of the video denoted by L. That means, for view i the viewing ratio is
                           
                              
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             T
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             
                                                
                                                   v
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    T
                                 
                                 
                                    i
                                 
                              
                           
                         is the total playtime (deducting possible rewinds already), 
                           
                              
                                 
                                    v
                                 
                                 
                                    i
                                 
                              
                           
                         is the video in the ith view and 
                           
                              
                                 
                                    L
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is the length of the video in the ith view. Note, 
                           
                              0
                              <
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ⩽
                              1
                           
                        . When a user finishes viewing a video completely or partially, the video player at the client side will record how long the video is played by this view. Viewing ratios for all views are calculated based on these records.

A view with larger viewing ratio means the view complete a larger portion video view, which can reflect the early departure behavior. Viewing ratio equaling 1 indicates a user quits after completion, called complete view. In practice, if the viewing ratio is greater than a threshold, such as 0.95, we consider the user completes viewing the entire video, since the last few percents video content usually contains only meta information (e.g. the cast list and credits etc.).

After calculating the viewing ratios for all views, we can plot the Cumulative Distribution Function (CDF) for viewing ratio, as shown in Fig. 1
                        . The horizontal axis is the viewing ratio, ranging from 0 to 1. The vertical axis is the proportion of all views whose viewing ratios are less than or equal to a given viewing ratio value. Fig. 1 has total four curves. These four curves correspond to the cases of (a) all views; (b) views of popular videos; (c) views of videos of medium popularity; and (d) views of unpopular videos. Popularity is defined as follows. We group the top 10% videos in term of view counts as popular ones; the middle-popular and unpopular videos are those videos with view counts ranking 11%∼30% and 31%∼100% respectively. There are numerous ways to group videos based on view counts. However, so far there is no standard way to group them. We heuristically split videos into three groups based on our view count distribution to show how video popularity affects viewing ratio and early departure behavior. Intuitively users quit unpopular videos more quickly resulting in smaller viewing ratios, which is consistent with the observation in Fig. 1. The viewing ratios of medium popular and popular videos are comparable. Viewing ratio of overall system is dominated by those views from more popular videos such that the curve of all videos is very close to the curve of popular videos. For all curves, there is a sharp jump when viewing ratio is around 90%. That means a fraction of users will view videos completely. Based on our measured results, the fraction of complete views is about 20% of total views.

In Fig. 2
                        , we split a view with k seeks into 
                           
                              k
                              +
                              1
                           
                         views, each starting from the destination of the seek (the first of these 
                           
                              k
                              +
                              1
                           
                         views starts from position 0). This, of course, drastically increases the proportion of views with small viewing ratios, and decreases the fraction of complete views (by a factor of average number of seeks). In this case, more than 60% views have a viewing ratio less than or equal to 
                           
                              0.2
                           
                        . This gives a worse case perspective because of early departure, though a seek may not incur as much overhead as starting a new video view.

Finally, we found that the early departure behavior is sensitive to video length or video content. To demonstrate this, we group videos into four types: (a) Movies; (b) TV episodes; (c) MV (Music videos); and (d) Sports. Among them, (c) and (d) tend to be short compared to (a) or (b).

The comparison of viewing ratios of different video groups is shown in Fig. 3
                        , from which we can conclude that shorter videos tend to result in larger viewing ratios. Sport videos have the largest fraction of complete views. The early departure probability is highest for viewing movies. In summary, user’s engagement seems to be inversely correlated to the length of videos, which is consistent with conventional wisdom. Another observation is that there is a jump in cumulative probability for TV episodes viewing ratio at around 90%. This is because the VoD service provider implements a feature that allows users to easily skip the repeated beginning and ending of a TV episode.

The reason for our interest in early departure behavior is to help us understand how much pre-fetching to do during video streaming. Any pre-fetching left in the buffer when a user departs early is considered wasted. From the results in Fig. 3, amount different types of videos Movies have more early departures. In the following, we use curve fitting to create a model for early departure for Movies.

To further analyze the distribution of viewing ratio, we plot the viewing ratio (for Movies)
                           3
                           We are interested in the early departure behavior of users viewing long videos due to its heavy bandwidth consumption.
                        
                        
                           3
                         histogram on log–log scales as shown in Fig. 4
                        , and find that it is a straight line for viewing ratio less than 80% on the logarithmic scale. In this region of viewing ratios (0% to 80%), the departure behavior follows the Power Law distribution. We can capture the distribution of these viewing ratios by fitting a curve 
                           
                              ln
                              P
                              (
                              x
                              )
                              =
                              -
                              a
                              ln
                              x
                              +
                              c
                           
                        , where a and c are constants. Equivalently,
                           
                              (1)
                              
                                 P
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       cx
                                    
                                    
                                       -
                                       a
                                    
                                 
                              
                           
                        The least square linear fitting of curve in Fig. 4 is 
                           
                              P
                              (
                              x
                              )
                              =
                              0.063
                              
                                 
                                    x
                                 
                                 
                                    -
                                    0.48
                                 
                              
                           
                        . The coefficient of determination is 
                           
                              
                                 
                                    R
                                 
                                 
                                    2
                                 
                              
                              =
                              0.75
                           
                        . We also try to fit curves using other distributions such as Exponential. The fit with the Power Law distribution has the least residual error. Thus we conclude that the pure (non-QoE-induced) early departure behavior follows a Power Law decay for viewing ratios up to 80%.

Besides the early departures, a significant fraction of the views are complete views. We assume these complete views end within a short span (in terms of viewing ratio), denoted by 
                           
                              ∊
                           
                        . Further, we assume these views are uniformly distributed within this short span of 
                           
                              ∊
                           
                        . Combining the two cases, we can express the viewing ratio distribution as:
                           
                              
                                 P
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         cx
                                                      
                                                      
                                                         -
                                                         a
                                                      
                                                   
                                                   ,
                                                
                                                
                                                   0
                                                   <
                                                   x
                                                   ⩽
                                                   1
                                                   -
                                                   ∊
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         1
                                                         -
                                                         
                                                            ∫
                                                            
                                                               t
                                                               =
                                                               0
                                                            
                                                            
                                                               1
                                                               -
                                                               ∊
                                                            
                                                         
                                                         
                                                            
                                                               ct
                                                            
                                                            
                                                               -
                                                               a
                                                            
                                                         
                                                         dt
                                                      
                                                      
                                                         ∊
                                                      
                                                   
                                                
                                                
                                                   1
                                                   -
                                                   ∊
                                                   <
                                                   x
                                                   ⩽
                                                   1
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Here, 
                           
                              α
                              =
                              
                                 ∫
                                 
                                    t
                                    =
                                    0
                                 
                                 
                                    1
                                    -
                                    ∊
                                 
                              
                              
                                 
                                    ct
                                 
                                 
                                    -
                                    a
                                 
                              
                              dt
                           
                        . Clearly, users quit viewing more frequently at the beginning part of playback. As a user completes viewing a video more, the chances of her completing the video increases.

The key parameters of our model, 
                           
                              ∊
                              ,
                              c
                              ,
                              a
                           
                        , and 
                           
                              α
                           
                         are summarized in Table 2
                        . The dataset includes all views for all videos.

A unique id is associated with each user in the viewing report, allowing us to group views on a per-user basis. In particular, we are interested in what video a user selects to view first, and what videos she switch to later. We introduce some new terms: the video selected first by a user upon arrival is called first view; those views with viewing ratio 
                           
                              x
                              >
                              0.5
                           
                         are called long views and the remaining views are called short views. Our user model assumes that a user goes through a random number of browsing cycles. In each browsing cycle, she goes through a random number of short views before visiting a long view.

We first study what videos are picked by users as the first view. In the log–log plot of Fig. 5
                        , the solid line represents video popularity. We count the total number of views for each video and sort them to generate the popularity plot. Using the same ordering of videos, we then count the number of times they are selected as first view, and plot the result as a scatted plot. It is interesting to observe that the popular videos are often selected for first view even more frequently than their popularity. This may be due to the success of the recommendation system provided by the VoD service.

In Fig. 6
                        , we plot the proportion of long views against the sequence of views in a user’s browsing history. There is a clear increasing trend, indicating a user is more likely to be in the browsing mode earlier than later. This confirms the basic assumption about video browsing in our model is valid.

Next, we turn to the number of views a typical user browse through. We first consider the number of views per day by a user, as plotted in Fig. 7
                         as a CDF. Around a quarter of users had only one view per day. The rest three quarters of users watch more than one video, and their views account for the major part of our view dataset. The number of views per day has a long tail, with a few percent of the users with more than twenty views. The dotted line curve corresponds to the case when seeks are considered additional views. In this case, each user goes through more views, as expected.

The next question is how many long views (viewing ratio larger than 50%) a user goes through. This is also plotted as a CDF, in Fig. 8
                        . The figure shows that 90% of the users had no more than seven long views per day, and around 28% users did not have any long views. This time, if we split seeks as separate views, the number of long views per user tend to reduce, as shown by the dotted curve. This is because the splitted views tend to be shorter than the original views.

Finally, we are interested to know how many short views a user goes through before landing in a long view. This is plotted in Fig. 9
                        . From this figure, we observe that around 80% long views are preceded by one to five short views, and around 15% long views were not preceded by any short views. By further examination of the video type, we find that most successive long views are TV episodes. Here, if we split seeks as separate views, we tend to increase the number of short views per user, since most views due to seek are short views.

Our characterization of user video browsing behavior can be used for more realistic load generation when studying the performance of VoD system under different levels of loads. For example, it can be assumed that user arrive according to some distribution (Poisson arrival at certain rate, or based on a trace). Then each user will go through a random number of long views, each preceded by a random number of short views. The number of long and short views can be generated based on the distribution shown in Figs. 8 and 9.

Seeks are a form of video browsing. From personal experience, we know some of the main reasons for seeks: (a) We look for some specific content in the video; (b) We try to finish the video at a fast speed than the playback rate. Most VoD streaming services do not support fast-forwarding. Through analyzing the seek related reports, we hope to confirm our beliefs and systematically characterize any regular patterns.

A seek is triggered by a user dragging the current play position along the playback progress bar to a new position. If there is no pre-fetched content corresponding to the new position, the seek action will induce a freeze to allow some amount of content to be buffered before resuming play. This is similar to the start-up delay when viewing of a video first starts. A small difference between the start-up delay for the whole video versus a seek is that during the former usually an advertisement is played, whereas during the latter, it happens like a regular freeze, hence a QoE event. For this reason, it is impossible to study seek completely independently from QoE impairments, as we study early departure and video switching above.

For seek behavior, the client side reports the time for the current play position and the next play position that the seek jumps to. The reports also include the number of seeks and freezes and their occurrence times in the same view reports. After aggregating and analyzing these data, we can summarize our observations as follows: (1) Seek tends to lead to more seeks – it seems users are inclined to seek back and forth once a seek occurred; (2) Seeks within a small range of the video happens is more often than in large range – this seems to confirm possibly manual fast-forwarding; (3) Besides content induced seeks, degraded QoE tends to induce seek behavior; (4) Seeks occur more frequently for long videos than for short ones – the average seek rate for long videos is 2∼3 times that for short videos, where seek rate is defined as the number of seeks per unit of video length.

We illustrate (1) with the following Table 3
                        . It shows the conditional probability that a seek occurs more than once is 76.1%, which means the repeated seek phenomenon is relatively common.

By counting the frequency of different range of seeks, we notice that seeks that jump forward within 5min account for around 80% of the cases, while seeks to beyond 30min away is relatively rare. This means most seeks are concentrated around the neighborhood of the current play position, as summarized in the following table (see Table 4
                        ).

We analyzed the relationship between seek frequency and viewing ratio for the four different types of videos we categorized, and for popular and unpopular videos (where popularity is defined by high view counts). Table 5
                         shows that longer videos tend to induce more seeks than shorter ones. On the other hand, we did not notice a significant disparity of seek rate between popular and unpopular videos. For special type of content, such as TV episodes, seek frequent is also relatively lower (in comparison to movies).

We select one movie video to study the destination position for seeks, for all views. This is depicted in Fig. 10
                        . It indicates that users seek more frequently around the 20th minute and 110th minute positions than other positions. In this case, we can see that these two positions do contain interesting material for the given movie. For other videos, we can also find such clustering pattern. This confirms our believe that some seeks are related to specific contents. To help user find such interesting content more easily, some VoD services already provide the “trickplay” [5] feature, which displays a thumbnail of snapshots of the video as the play position is changed on the sliding bar.

There are many potential applications for our use behavior analysis. For example, it can be used for resource allocation strategies for pre-fetching during video streaming, or for video replication decisions in CDN and P2P networks. In the following, we discuss how to apply user behavior to estimating video popularity.

Given the large number of choices of online videos, it is necessary for content providers to provide some form of video recommendation. The simplest form of recommendation is based on video popularity. Almost all video services use view count as an indication of video popularity. This seems consistent with the movie industry reporting the box-office sales of films shown in cinemas as an indication of the movie’s popularity. There is, however, a subtle and important difference. For online videos, as our study showed, viewers often do not view a video to its completion.

There is another serious problem besides not every click results in a complete view. Because of the use of view count as indication for popularity, and popularity tends to attract more views, there is incentive for video owners or their promoters to manipulate the view count. From the data we have access to, this phenomenon appears quite prevalent. There are two common ways to inflate the view count: (a) use a (software) robot, or even a botnet, to simulate a large number of view sessions by human (we call these fake views); (b) give the video a misleading title that is likely to attract viewers. Fake views can be identified (offline) to a high degree of accuracy, if we can track the views from the same user. The main challenge is the ability to aggregate views from the same user. We have studied how to systematically and automatically do that, to be published separately. Misleading title is a little harder to detect automatically. Fortunately, this technique usually has less harm (only a nuisance factor), since users can quickly determine something is wrong and abandon that video.

YouTube is the largest VoD service provider for user generated content (UGC) in the world. It has a massive collection of UGC videos and serves a huge number of viewers everyday. YouTube used view count as a primary indicator for video popularity in its ranking and recommendation system till October 2012. After YouTube noticed increased level of view count manipulation, they designed two strategies to deal with this problem: i) freezing the view count briefly (some times for a day or two) when it reaches 300, to check for anomalies (our guess is that they need this break mainly to check for misleading titles which may need to be done manually); ii) adding the “watch-time” metric in YouTube Analytics [6] as a supplementary indicator.

Youku, Tudou and Tencent Video are the popular Internet video content providers in China. All these VoD systems use view count as an important indicator for video popularity, calculated on a daily basis. Supplementing that, these content providers also allow users to rate videos on their webpage. These user ratings are then taken into account in video ranking and recommendation. Our collaborator has indicated to us that they would like to compute video popularity on a continuing basis, with capability of removing fake views, and using a metric that is resistent to the effects of misleading titles.

Before we consider and discuss solutions to these problems, we briefly review and discuss another avenue for users to get video recommendations – via some popular video recommendation sites.

We describe two popular video recommendation sites: (a) Internet Movie Database (IMDb), and (b) Douban.

Internet Movie Database (IMDb) is one of the most popular websites providing information for movies. One type of information is the movies’ rating. IMDb allows (registered) users to rate movies on a scale of one to ten. Not every user’s vote carries the same weight (the exact way the weighting is assigned is kept as a secret, to prevent abuse). The IMDb “Top 250” contains the list of the top rated 250 movies. IMDb uses the following formula to derive a rating that factors in the number of votes a movie received as well [7]:
                           
                              
                                 W
                                 =
                                 
                                    
                                       Rv
                                       +
                                       Cm
                                    
                                    
                                       v
                                       +
                                       m
                                    
                                 
                                 .
                              
                           
                        
                     


                        R is the (weighted) average rating of a movie, a number from 0 to 10, based on v votes in total. C is the mean vote (currently 7.1) across all movies and m equals to minimum number of votes required to be listed in the Top 250 (currently 25,000). Essentially, this gives a Bayesian posterior mean for the weighted rating W. Given this formulation, the greater the number of separate votes, the more credible the rating is. IMDb’s video ratings are widely considered as the de facto popularity evaluations for movies online.

Although IMDb appears a reliable source for subjective video rating, we encounter a practical problem in using it for validating our methods. The set of movies we collected for our study is from three-months of viewing records for around two thousand movie videos, after removing those records that include QoE impairments, and movies that had only a small number of total views. Many of the movies in this dataset are Chinese movies that are either not in IMDb, or are given a “default” rating based on the Bayesian average formula by IMDb. Due to this reason, we considered another movie rating web site – Douban.

Douban is a local video rating website in China, whose users and voters are mostly Chinese. Since Douban also has a large user base, it can be considered the “Chinese IMDb”. Douban allows registered users to give scores and comments for any movies on its website. Its style is similar to IMDb but mostly focusing on Chinese movies. Douban’s mechanism appears less sophisticated – it simply takes the average of collected votes for a video and presents the mean value. Additionally, Douban provides a bar chat to show the distribution of users’ ratings as supplementary information. As expected, we found Douban to have more user ratings of the movies we are interested in evaluating.

After we propose our behavior-based video rating, we will compare it to the subjective ratings from IMDb and Douban, as well as to the simple view counts. For calibration, let us first take a look at the similarity between ratings from Douban and IMDb using the intersection set of movies found on these two web sites, and the movies found in our user view records. The results are shown in Table 6
                         for the two thousand movies we crawled. We used all three of the popular methods to study similarity between two popularity rankings – Pearson, Spearman and Kendall [8]. The correlation of Douban and IMDb is only around 0.4 according to Pearson, which is only a weak correlation. Given the reasons we gave earlier (the fact that the movies in our set may not be popular in IMDb, hence often get default ratings), and the fact that these are subjective ratings, we feel that this weak level of correlation is still an acceptable indication that these ratings can be used for our study.

For a on-line VoD service, as we have shown from our user behavior analysis, the typical behavior is video browsing. Given this fact, our question is how to calculate a good video popularity index; more specifically, how to calculate a movie video popularity index (as supposed to MV video index, or UGC video index). In view of the fact that browsing is a pre-dominating behavior, arguably users’ interest in videos should be reflected by how much time they spend viewing in those videos.
                           4
                           Note, all our discussion is built on the premise that our user-behavior analysis is based on user records without QoE-impairment; hence any early departure is not caused by QoE reasons.
                        
                        
                           4
                        
                     

The most straightforward way to apply viewing ratio to video popularity is simply to replace a single view count by a viewing ratio. The total view count then becomes the sum of viewing ratio of all views of a video. We call this the linear view-time-based index. To compare this linear view-time-based index with total view count as an index, we used the two thousand odd movies that are found in both our VoD system and Douban to compare the correlations between each method with Douban. The results are shown in Table 7
                        . Although the correlation for both methods to Douban are not that high, it is clear that the correlation between the linear viewing-time-based index with Douban is definitely higher, using all three methods to measure correlation.

Although the use of viewing ratio instead of view count appears to improve video popularity estimation according to Douban’s subjective index, the correlation is rather weak. The question is, will a non-linear mapping from viewing ratio to a user’s rating for a video produce better results?

There are reasons for using a non-linear mapping. Intuitively, when the viewing ratio of a particular video by a user is lower than a certain point, it can be almost surely concluded that the user felt this video is not what he or she expected and quitted the session. Therefore, almost no credit should be given to such a video – even the linear mapping is over-crediting such a video. On the other hand, when a user has completely a sufficiently large portion of a video, it can be concluded that the user intended to watch that video. There can be a variety of reasons for early departure after watching a large portion already. For example, many people do not bother watching the trailer of a movie, which can be several minutes long; watching a movie at home tend to get interrupted for many reasons, such as when dinner is ready, or a friend calls, and so on.

To summarize, our intuition tell us that when viewing ratio is small, the linear mapping is likely over-crediting a user’s rating, and when viewing ratio is large, the linear mapping is likely under-crediting a user’s rating. This lead us to choose a Sigmoidal function to represent the mapping from viewing ratio to user’s rating. This is the sigmoid function we choose:
                           
                              
                                 sig
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       1
                                       +
                                       
                                          
                                             e
                                          
                                          
                                             -
                                             a
                                             ·
                                             (
                                             x
                                             -
                                             c
                                             )
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        To illustrate the behavior of a sigmoidal function, we plot 
                           
                              sig
                              (
                              x
                              )
                           
                         in Fig. 11
                        , for five set of values of (
                           
                              a
                              ,
                              c
                           
                        ): (1) a=20, c=0.5; (2) a=20, c=0.2; (3) a=20, c=0.7; (4) a=60, c=0.5; (5) a=10, c=0.5 respectively. As we can see, it is always an S-curve, with the turning point situated at the point when the viewing ratio (x) equal to c. The parameter a determines how sharply the curve turns from low rating to high rating.
                           5
                           Strictly speaking, we would like to use a sigmoidal function that also satisfies 
                                 
                                    sig
                                    (
                                    0
                                    )
                                    =
                                    0
                                 
                               and 
                                 
                                    sig
                                    (
                                    1
                                    )
                                    =
                                    1
                                 
                              ; which is not exactly satisfied by the function we chose. But as we can see in Fig. 11, for all intents and purposes, 
                                 
                                    sig
                                    (
                                    x
                                    )
                                 
                               satisfies our needs, and is simple enough to use.
                        
                        
                           5
                        
                     

Actually, the linear viewing-time-based rating function and the total view count function are also special cases of the set of functions we explore. The linear mapping corresponds to the case when the turning point is at 
                           
                              0.5
                           
                         and the sharpness is minimum; whereas the total view count corresponds to the case when the turning point is 0 and the sharpness is maximum.

The way we apply the sigmoid function to calculate a video’s rating is as follows. For each view, we calculate the viewing ratio and map it into a viewing-time-based rating using 
                           
                              sig
                              (
                              x
                              )
                           
                         with the given parameter. For example, if video j had n views in total, its viewing-time-based rating is then calculated as:
                           
                              
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             f
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                    
                                       n
                                    
                                 
                                 ,
                                 
                                 k
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 3
                                 ,
                                 4
                                 ,
                                 5
                                 ,
                              
                           
                        where the function 
                           
                              f
                              (
                              ·
                              )
                           
                         could be one of the sigmoid functions or the linear function, and 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         is the viewing ratio of i-th view, and k is used to index the five sigmoid functions derived from the five groups of parameters (see Fig. 12
                        ).

The sigmoid function based ratings and Douban rating is compared using the standard correlation functions in Table 8
                        . Overall, there exists a weak correlation between the sigmoid function based ratings and Douban rating. Despite the weak correlation level, we observe (a) the correlation pattern is consistent across different methods of comparison; (b) Sigmoid 1 showed stronger correlation than the other sets of parameters; and (c) Sigmoidal viewing-time-based rating has higher correlation than linear viewing-time-based rating and view count based rating. These observations all agree with our intuition.

The correlation between the Sigmoidal viewing-time-based ratings and IMDb rating are shown in Table 9
                        . It is similar to the previous result, but with much weaker correlation. As we explained earlier, in IMDb, the movies in our dataset (mostly Chinese) do not get a high number of votes and hence tend to get ratings close to the default value, and are not as accurate as we expect. Nonetheless, the conclusions tend to agree with the Douban case.

To visually compare the similarity of viewing-time-based rating and Douban rating, we sampled the top two hundred popular movies (10% of all which got enough number of views) and normalized the viewing-time-based rating into 0∼10 range using the Bayesian average approach. We use a scatter plot to visualize these two ratings in Fig. 13
                        . The x and y axis correspond to the viewing-time-based rating and Douban rating for each video respectively. The results show that in a good percentage of the cases, the viewing-time-based ratings strongly agreeing with the Douban ratings.

We believe both the subjective video rating systems (such as IMDb and Douban) and the objective video ratings (such as view count or viewing-time-based ratings) have their roles in helping users evaluate video popularity. For a variety of reasons, for example the subjective ratings are accumulated over a long time but the objective ratings are computed over a shorter time span over a different set of videos, these ratings may not correlate strongly. Based on this weak correlation, however, we can already demonstrate some evidence that viewing time information can be used to improve video rating based on view count only. We further show that the use of a sigmoid-like mapping from viewing time to video rating can improve over a linear mapping. A more large scale and comprehensive study with real-world data can help further confirm this conclusion.

@&#RELATED WORK@&#

Some previous works studied user behavior and its correlation to QoE [4], with the objective of using user engagements to estimate actual QoE (which is hard to encertain). This is orthogonal to our work. In this paper, we do confirm that QoE can affect user behavior. But the main part of our work is to study user behavior when it is unaffected by QoE. We do this by removing all viewing sessions with QoE impairments.

The early departure user behavior has been identified previously by other studies. It was studied as a preview activity for users to shop for videos they like [9]. That study is a smaller scale study (based on data collected on a campus network) compared to ours, and the user activity is much different than ours (VoD streaming service) as well. Another study [10] reported statistics of video playback aborts – 60% of videos watched for no more than 20% of their duration. Our study to a large extent agrees with these previous results. Our contribution is a more comprehensive user behavior study based on a much larger trace with different types of videos and from a real-world service provider. Our other contributions are to try to build a user behavior model, and to apply the results to video rating.

Besides the above recent studies more closely related to ours, there are a large number of user behavior studies with different objectives and observations in the past. For example, user arrival patterns were analyzed and modeled in [11]. In [12], the K-means technique was used to cluster user behaviors using a Markovian model based on a movie trailer database. Another work [13] probed the relationship between several types of user behavior and found that the behavior of a user in a video streaming session had strong correlation with the user’s behaviors in previous streaming sessions. The paper [14] modeled the behavioral states a user transitioned while browsing to be the hidden states of a hidden Markov model. In the paper [15], the authors performed subjective experiments to analyze user viewing activities and correlate them with network path performance and QoE. The paper [16] investigates user behavior in a social network created by video interactions among users on YouTube. All these studies, while interesting, are not directly related to our study.

Watching video over the Internet has become a part of daily life for many people. As more and more videos with rich content appear on the Internet, the scale of video streaming systems will expand. The service providers are eager to understand how to improve the quality of experience for users, and make best use of system resources. The study of user behavior provides a good foundation to study how to improve system design and optimize resource allocation.

Our data collection is still on-going, and we expect to further develop and validate our user departure model. We have already formulated a multi-flow rate adaptation optimization problem taking into account of user behavior, to study the performance of current practices in HTTP streaming, and suggest improvements. We will also investigate whether different algorithms should be applied to users performing seeks versus those who do not seek.

We have discussed how to apply our user behavior models to system performance improvement, and video popularity rating. Both of these applications are important to the operation of a video content provider.

@&#ACKNOWLEDGEMENT@&#

We thank the anonymous reviewers for their feedback that helped improve this paper, and Youwei Hua, Feng Liang, Suibin Yao from Tencent Video for providing a great support. We also thank Yue Wang in Department of Information Management, School of Information, Central University of Finance and Economics, for his discussion. This work is supported by the National Natural Science Foundation of China (No. 61309030).

@&#REFERENCES@&#


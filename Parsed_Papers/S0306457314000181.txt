@&#MAIN-TITLE@&#Personalized and object-centered tag recommendation methods for Web 2.0 applications

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose new heuristics for object-centered and personalized tag recommendation.


                        
                        
                           
                           We also propose new learning-to-rank (L2R) based strategies for the same tasks.


                        
                        
                           
                           They exploit tag co-occurrences, textual features, relevance metrics and user history.


                        
                        
                           
                           Our solutions greatly outperform state-of-the-art methods on real datasets.


                        
                        
                           
                           Tag personalization produces better descriptions of the objects.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Tag recommendation

Relevance metrics

Personalization

@&#ABSTRACT@&#


               
               
                  Several Web 2.0 applications allow users to assign keywords (or tags) to provide better organization and description of the shared content. Tag recommendation methods may assist users in this task, improving the quality of the available information and, thus, the effectiveness of various tag-based information retrieval services, such as searching, content recommendation and classification. This work addresses the tag recommendation problem from two perspectives. The first perspective, centered at the object, aims at suggesting relevant tags to a target object, jointly exploiting the following three dimensions: (i) tag co-occurrences, (ii) terms extracted from multiple textual features (e.g., title, description), and (iii) various metrics to estimate tag relevance. The second perspective, centered at both object and user, aims at performing personalized tag recommendation to a target object-user pair, exploiting, in addition to the three aforementioned dimensions, a metric that captures user interests.
                  In particular, we propose new heuristic methods that extend state-of-the-art strategies by including new metrics that estimate how accurately a candidate tag describes the target object. We also exploit three learning-to-rank (L2R) based techniques, namely, RankSVM, Genetic Programming (GP) and Random Forest (RF), for generating ranking functions that exploit multiple metrics as attributes to estimate the relevance of a tag to a given object or object-user pair. We evaluate the proposed methods using data from four popular Web 2.0 applications, namely, Bibsonomy, LastFM, YouTube and YahooVideo. Our new heuristics for object-centered tag recommendation provide improvements in precision over the best state-of-the-art alternative of 12% on average (up to 20% in any single dataset), while our new heuristics for personalized tag recommendation produce average gains in precision of 121% over the baseline. Similar performance gains are also achieved in terms of other metrics, notably recall, Normalized Discounted Cumulative Gain (NDCG) and Mean-Reciprocal Rank (MRR). Further improvements, for both object-centered (up to 23% in precision) and personalized tag recommendation (up to 13% in precision), can also be achieved with our new L2R-based strategies, which are flexible and can be easily extended to exploit other aspects of the tag recommendation problem. Finally, we also quantify the benefits of personalized tag recommendation to provide better descriptions of the target object when compared to object-centered recommendation by focusing only on the relevance of the suggested tags to the object. We find that our best personalized method outperforms the best object-centered strategy, with average gains in precision of 10%.
               
            

@&#INTRODUCTION@&#

Several Web 2.0 applications have reached unprecedented popularity mainly due to the strong stimuli and easiness for users to create their own content and share it with others, establishing online communities and social networks. Each page in a Web 2.0 application is composed by a main object, which can be stored in different media types (e.g., text, audio, image, video) as well as several other sources of information associated with the object, here referred to as its features. For instance, content features are sources of information that can be extracted from the object itself, such as the color histogram of an image. Textual features, on the other hand, are blocks of text typically assigned by users to the object, such as title, description, tags and several comments posted by users. Finally, there are also features related to the users, here referred to as user profile features, such as the user’s age, sex and tags frequently assigned by her.

Among all textual features, tags have become one of the main textual features in Web 2.0 applications, as they are often exploited to provide better organization and description of the content. Moreover, recent studies have shown that tags are one of the best textual features to be exploited by various tasks related to Information Retrieval (IR), such as automatic object classification (Figueiredo et al., 2013; Ramage, Heymann, Manning, & Garcia-Molina, 2009), searching (Li, Guo, & Zhao, 2008), and content recommendation (Guy, Zwerdling, Ronen, Carmel, & Uziel, 2010).

In this context, tag recommendation services aim at assisting users in the task of assigning tags to a target object by suggesting keywords that are related to its content, thus improving the quality of the available information and ultimately the effectiveness of various IR services that rely on tags as main data source. The tag recommendation problem can be tackled from two perspectives. The first perspective, object-centered, aims at suggesting relevant tags to a target object, that is, suggesting tags that are related to the object’s content.

The second perspective, centered at both object and user, aims at performing personalized tag recommendation to a target object-user pair. Personalization is motivated by the fact that users typically have different interests, levels of expertise, or vocabulary biases, and may also have different purposes when choosing tags for a target object (e.g., content organization or content description). Moreover, even users with similar purposes may perceive the object’s content differently, particularly in case of multimedia objects (an effect known as the semantic gap). All these factors ultimately impact the user’s tag choices. Thus, personalized tag recommendation aims at suggesting tags that not only are related to the object’s content but also captures the user interests, profile and background, and thus might help services such as content organization. Moreover, as illustrated and further discussed in Sections 3 and 6.5.3, personalized tag recommendations may also provide, either in isolation or collectively (i.e., all personalized recommendations provided to all users who tagged an object) better and more complete descriptions of the object’s content, compared to object-centered recommendations, which, in turn, help improve services, such as search and content recommendation.

Many existing object-centered strategies exploit tag co-occurrence patterns in previous tag assignments in the collection, expanding an initial tag set 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      of the target object o with other tags that frequently co-occur together with the tags in 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      (Garg & Weber, 2008; Heymann, Ramage, & Garcia-Molina, 2008; Menezes et al., 2010; Sigurbjörnsson & van Zwol, 2008). Other methods do not assume the existence of such tags in the target object, using, instead, terms extracted from other textual features (Lipczak, Hu, Kollet, & Milios, 2009; Wang, Hong, & Davison, 2009; Zhang, Zhang, & Tang, 2009). However, various textual features, including tags, are created by the end users, and thus, may contain a lot of noise (e.g., misspellings or unrelated terms) (Figueiredo et al., 2013; Koutrika, Effendi, Gyöngyi, Heymann, & Garcia-Molina, 2008). Thus, it is important to filter such terms out of the list of recommendations or reduce their importance, favouring terms that are more “relevant” for the target object. By relevant, we mean terms that are good descriptors of the object’s content and/or that help discriminate it from others, for supporting services such as searching and classification, which typically use tags as data sources. With that in mind, some previous methods (Belém, Martins, Almeida, Gonçalves, & Pappa, 2010; Lipczak et al., 2009; Sigurbjörnsson & van Zwol, 2008; Wang et al., 2009) exploit metrics of relevance, such as Term Frequency (TF), either to filter out irrelevant candidates or to boost candidates with more potential. Thus, most existing object-centered methods exploit a subset of the following dimensions
                        1
                        Other dimensions, such as content features (Wu, Yang, Yu, & Hua, 2009) and the similarity among objects (Pedro, Siersdorfer, & Sanderson, 2011; Siersdorfer, San Pedro, & Sanderson, 2009; Song et al., 2008; Song, Zhang, & Giles, 2011) can also be exploited. Extending our methods to include them is left for the future.
                     
                     
                        1
                     : (i) tag co-occurrences with tags previously assigned to the target object, (ii) terms extracted from multiple textual features, and (iii) metrics of relevance. However, to our knowledge, they exploit at most two of these three dimensions.

In the context of personalized tag recommendation, most previous work exploits user profile features, specifically the history of tag assignments of all users of the application, known as folksonomy, or of a particular (target) user, known as her personomy. Collaborative filtering and FolkRank (Jäschke, Marinho, Hotho, Lars, & Gerd, 2007), as well as PITF – Pairwise Interactions Tensor Factorization (Rendle & Lars, 2010) – fall into this category. A few other efforts exploit multiple textual features along with the history of tag assignments (Lipczak et al., 2009) and tag co-occurrence patterns (Garg & Weber, 2008; Rae, Sigurbjörnsson, & van Zwol, 2010). However, to our knowledge, existing methods do not jointly exploit tag assignment history along with the three aforementioned dimensions, which may also be important for personalized recommendations.

Accordingly, we here address the tag recommendation from both object-centered and personalized perspectives, modeling it as a multiple candidate tag ranking problem. In other words, we develop functions that estimate the relevance of a candidate tag as a tag recommendation to a given object or to a given object-user pair, thus enabling us to rank the candidate tags according to such estimates, and recommend the most relevant ones as tags to the target object (for object-centered recommendation) or object-user pair (for personalized recommendation).

Unlike previous solutions, we here address the object-centered tag recommendation problem by jointly exploiting all three aforementioned dimensions.
                        2
                        Although the three dimensions may have some overlap, we argue that they are distinct. For example, some metrics (dimension (iii)) are based on tag co-occurrences (dimension (i)). However, while dimensions (i) and (ii) represent different sources used to produce candidate tags, dimension (iii) consists of metrics computed for the already generated candidates to estimate their relevance. In particular, some of these metrics are not directly related to any of the other two dimensions.
                     
                     
                        2
                      In other words, we extend traditional tag co-occurrence based approaches to include not only tags that have been previously assigned to the objects (including the target object), but also terms contained in other textual features, such as title and description. The contents of these textual features are used to extract candidate tags. We also exploit several heuristic metrics to try to capture the relevance of each such candidate as a recommendation for the target object. Specifically, we propose eight heuristic strategies for object-centered tag recommendation. Our heuristics extend two state-of-the-art techniques that exploit tag co-occurrences and some metrics of relevance (Menezes et al., 2010; Sigurbjörnsson & van Zwol, 2008) by including new metrics that try to capture how accurately a candidate tag describes the object’s content and by exploiting multiple textual features. They are simple, easy to compute, and quite efficient.

In order to address the personalized tag recommendation problem, we first analyze different strategies to extract tag co-occurrence patterns. Some of these strategies have never been proposed in previous work. More specifically, we define the tag sets exploited to compute co-occurrence patterns in two different ways: (1) all tags assigned to an object by different users and (2) all tags assigned to an object by the same user. While the first strategy benefits from a larger amount of tag relationships, the second one may be less susceptible to noise. In fact, we find that the two strategies produce quite different results, and the best strategy depends on the employed co-occurrence-based method. We then propose two new heuristics that extend our two best object-centered tag recommendation heuristics to include a metric that estimates the relevance of a candidate tag to the target user, named User Frequency (UF). UF is based on the history of tag assignments of the target user.

We note that, for both object-centered and personalized tag recommendation, a number of heuristics can be devised to combine multiple metrics of relevance into a final tag recommendation function. Finding the “best” heuristic is not an easy task due to the potential large size of the search space, which, in our case, consists of all possible tag recommendation functions that can be built using the suggested metrics. Thus, we also investigate the benefits of applying learning-to-rank (L2R) techniques for tag recommendation. We propose three L2R-based object-centered strategies: one exploits the traditional RankSVM method (Joachims, 2006), whereas the other two are based on Genetic Programming (GP) (Banzhaf, Nordin, Keller, & Francone, 1998) and Random Forest (RF) (Breiman, 2001). RankSVM, GP and RF are here treated as meta-heuristics to generate ranking functions that exploit all given metrics as attributes to accurately estimate the relevance of each given candidate tag. Our motivation to use L2R methods are threefold: (1) they can effectively exploit many attributes in the generation of ranking functions, (2) they can be easily extended to include more attributes, and (3) there is a strong theoretical background on learning methods, which has been recently extended for ranking problems (Qin, Liu, & Li, 2010). We also extend our three L2R-based strategies to perform personalized recommendation by including the aforementioned UF metric as an attribute.

We evaluate our object-centered and personalized tag recommendation strategies with real datasets collected from four popular Web 2.0 applications, namely, YouTube and YahooVideo, two video sharing sites, LastFM, an online radio station, and Bibsonomy, a bookmark and publication sharing system.
                        3
                        
                           http://www.youtube.com, http://www.yahoo.com/video, http://www.last.fm, and http://www.bibsonomy.org, respectively.
                     
                     
                        3
                     
                  

In particular, we evaluate our object-centered tag recommendation strategies, comparing them against three state-of-the-art techniques, namely, 
                        
                           
                              
                                 Sum
                              
                              
                                 +
                              
                           
                        
                     , the best function proposed in Sigurbjörnsson and van Zwol (2008), LATRE (Menezes et al., 2010), and the winner of the ECML Discovery Challenge 2009 (Lipczak et al., 2009; Lipczak & Milios, 2011), here referred to as Co-occurrence and Text-based Tag Recommender – CTTR. 
                        
                           
                              
                                 Sum
                              
                              
                                 +
                              
                           
                        
                      exploits co-occurrence of pre-assigned tags along with some tag frequency statistics. LATRE, in turn, is a more recent, efficient and effective method that exploits solely tag co-occurrence patterns. Our heuristics are extensions of these two methods. CTTR exploits the contents of textual features associated with the target object along with one metric of tag relevance, but does not consider the tags previously assigned to the target object.

Our results indicate that our object-centered heuristics produce improvements over the original techniques on which they are based of 36% in precision and 40% in recall on average across all datasets and heuristics, with gains on a single dataset reaching as much as 105% and 116%, respectively. Moreover, our best heuristic outperforms the best baseline, with average gains of 12% (up to 20%) in precision and 13% (up to 25%) in recall. This heuristic extends the LATRE baseline by incorporating a new metric that tries to capture the descriptive power of each candidate tag and by exploiting multiple textual features.

Further improvements over our best heuristics can also be achieved with our L2R-based strategies, with gains in precision and recall of up to 23% and 14% on average. In particular, our results show that Random Forest is the best of the three L2R techniques, with average gains in precision over the best of GP and RankSVM in each dataset of 7% (and reaching up to 10%). Similar performance gains are also achieved in terms of others metrics, notably Normalized Discounted Cumulative Gain (NDCG) and Mean-Reciprocal Rank (MRR) (Sigurbjörnsson & van Zwol, 2008).

We also evaluate our personalized tag recommendation strategies, comparing them against the state-of-the-art PITF personalized strategy (Rendle & Lars, 2010). We find that our best heuristic outperforms PITF by 121% in precision and 122% in recall, on average. Moreover, like for object-centered strategies, our L2R-based personalized tag recommendation methods also yield further improvements: the best L2R strategy – the RF-based method – provides gains of 10% on average (and up to 13%) in precision over our best heuristic. Once again, similar improvements in recall, NDCG and MRR were also achieved. In general, for both object-centered and personalized recommendation, we note that the L2R-based strategies provide a flexible framework that can be easily extended to include other attributes (i.e., tag relevance metrics) or to address other aspects of the tag recommendation problem. As a final result, we also quantify the benefits of personalized tag recommendations to produce better descriptions of the target object when compared to object-centered recommendations, by measuring the relevance of the suggested tags to the object only (i.e., disregarding their relevance to the target user). Comparing our best personalized and object-centered tag recommenders, both based on the RF technique, we find that the former outperforms the latter, with average gains in precision of 10%.

In sum, we here greatly extend our previous effort (Belém, Martins, Pontes, Almeida, & Gonçalves, 2011), by bringing the following main contributions: (1) the proposal of seven personalized tag recommendation solutions (four heuristics and three L2R-based approaches); (2) the analysis of new tag co-occurrence patterns not exploited in previous work; (3) an extended experimental evaluation, for both object-centered and personalized strategies, including data obtained from Bibsonomy, a standard dataset to evaluate tag recommendation (Benz et al., 2010; Lipczak & Milios, 2011), and new evaluation metrics; (4) the inclusion of new tag relevance metrics used as attributes in our L2R-based strategies, namely, Predictability (Pred) and, for personalized strategies, User Frequency (UF); (5) the application of the Random Forest technique to the tag recommendation problem, particularly in the context of personalized recommendation, producing results that are significantly superior to the results of previously evaluated L2R-based techniques; and (6) a quantitative assessment of the benefits of personalized tag recommendation to provide better descriptions of the target object.

The rest of this article is organized as follows. Section 2 discusses related work, whereas Section 3 describes how we model the tag recommendation problem. The main metrics used to estimate the relevance of a candidate tag are defined in Section 4, while our new tag recommendation techniques are introduced in Section 5. Section 6 presents our experimental evaluation and discusses the most representative results. Section 7 concludes the article and points out some directions for future work.

@&#RELATED WORK@&#

In this section, we review related efforts, starting by presenting existing tag recommendation methods in Section 2.1. We then discuss previous studies of Learning-to-Rank techniques in general and in the tag recommendation domain, specifically, in Section 2.2. Finally, in Section 2.3, we briefly review previous characterizations of tagging systems.

Many tag recommendation strategies exploit co-occurrence patterns computed over a history of tag assignments. In particular, some of them exploit tag co-occurrences to expand an initial set of tags 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                         associated with an object o (Garg & Weber, 2008; Heymann et al., 2008; Krestel, Fankhauser, & Wolfgang, 2009; Menezes et al., 2010; Sigurbjörnsson & van Zwol, 2008; Wu et al., 2009). For this purpose, Heymann et al. (2008) use association rules, i.e., implications of the form 
                           
                              X
                              →
                              y
                           
                        , where the antecedent X is a set of tags, and the consequent y is a candidate tag for recommendation, restricting the rules by a confidence threshold. However, the authors do not provide a ranking of the recommended tags. Sigurbjörnsson and van Zwol (2008), on the contrary, exploit simple global metrics of tag co-occurrence (e.g., confidence), applying them over all tags in the initial set to produce a final ranking of candidate tags. Some of the considered metrics, related to tag frequency, try to capture the “relevance” of each candidate. In comparison, we here consider a much richer set of metrics, including new metrics based on multiple textual features, which, as we shall see, are responsible for our largest improvements.

Due to efficiency issues, most of these strategies usually compute co-occurrences between only two tags (i.e., X contains only one tag), thus possibly missing important co-occurrence relationships. To address this problem, Menezes et al. (2010) propose LATRE – Lazy Associative Tag Recommendation, which computes association rules in an on-demand manner, allowing an efficient generation of more complex and potentially better rules, and producing superior results in comparison with the best method in Sigurbjörnsson and van Zwol (2008).

A few other efforts do not exploit tags previously assigned to the target object, focusing, rather, on other textual features (Katakis, Tsoumakas, & Vlahavas, 2008; Lipczak et al., 2009; Lipczak & Milios, 2011; Lu, Yu, Chang, & Hsu, 2009; Wang et al., 2009; Zhang et al., 2009). Lipczak et al. (2009) and Lipczak and Milios (2011) extract terms from other textual features (e.g., title) of the target object, expanding them by association rules, and sorting the extracted terms by their usage as tags in a training set. Wang et al. (2009) use the traditional TF
                        ×
                        IDF metric to extract and rank the most important terms from the object’s textual content. Lu et al. (2009) as well as Zhang et al. (2009) propagate tags between objects with similar textual content. Others adopt multilabel text classification techniques in which each tag represents a possible label to be assigned to an object, and terms extracted from textual features are used directly as attributes for the classifier (Katakis et al., 2008).

These previous methods address the object-centered tag recommendation problem by exploiting a combination of (i) co-occurrence patterns among previously assigned tags, (ii) multiple textual features, and (iii) metrics of relevance. However, to our knowledge, none of them jointly exploits all three dimensions of the problem. In contrast, in Belém et al. (2011), we investigate the benefits of combining these three dimensions to perform tag recommendation by designing new heuristics and L2R-based methods for object-centered recommendation. Our evaluation, comparing the proposed strategies against various state-of-the-art baselines in three different datasets, showed that our solutions outperform the previous techniques. These findings motivated the present study, which greatly extends our prior work (Belém et al., 2011) by also: (1) addressing the problem of personalized tag recommendation, (2) using one more dataset to evaluate our methods (the Bibsonomy dataset) as well as two new metrics (NDCG and MRR), (3) comparing different tag co-occurrence patterns for personalized recommendation, (4) introducing another L2R-based method (Random Forest), (5) extending the set of attributes exploited by the L2R-based methods, and (6) quantifying the benefits of personalized tag recommendations to provide better descriptions of the target object, when compared to object-centered recommendations.

In addition to co-occurrence and text based strategies, other approaches have also been exploited for object-centered tag recommendation. For example, Wu et al. (2009) add image content information to rank tags. Lin, Ding, Hu, Wang, and Sun (2012) perform a random search process over the graph of images with similar visual content. Siersdorfer et al. (2009) and Pedro et al. (2011) create a graph of videos based on content similarity, and make recommendations by propagating Song et al. (2008), Song et al. (2011) exploit clustering in a bipartite graph containing tags, documents and words to recommend tags to a document. The documents are first associated to multiple clusters, and the most representative tags of each cluster are recommended to the target document. Yin et al. (2013) address not only the problem of predicting tags, but also of predicting different kinds of relationships (such as relations between users, comments and items, and social links between users), exploiting a generalized latent factor model and Bayesian inference. The authors find that connecting comments and tags within the same model allows mutual reinforcement and improves prediction accuracy. However, it is not possible to compare this method with our strategies because comments are absent in our datasets, while they are also noisy and absent in a large fraction of the objects (Almeida, Gonçalves, Figueiredo, Belém, & Pinto, 2010; Figueiredo et al., 2013). In a different direction, we address not only relevance, but also other important aspects in tag recommendation systems, namely novelty and diversity, in some other previous work (Belém, Martins, Almeida, & Gonçalves, 2013; Belém, Santos, Gonçalves, & Almeida, 2013).

Other studies address the problem of personalized tag recommendation, often exploiting the history of tag assignments of all users of the application, or of a specific (target) user. Collaborative filtering and FolkRank (Jäschke et al., 2007), as well as PITF – Pairwise Interactions Tensor Factorization (Rendle & Lars, 2010) – and the graph-based ranking proposed in Guan, Bu, Mei, Chen, and Wang (2009) fall into this category. Some studies focus on exploiting tag co-occurrences in these histories of tag assignments (Rae et al., 2010; Garg & Weber, 2008). For example, Rae et al. (2010) extend the strategy proposed in Sigurbjörnsson and van Zwol (2008) to include personalization, exploiting tag co-occurrences in different contexts: (1) the whole data collection, (2) the objects of a specific user, (3) the social contacts of the user, and (4) the groups in which the target user is included. Lipczak et al. (2009) include a metric related to the target user’s history to provide personalized recommendations. Feng and Wang (2012) model the folksonomy as a heterogeneous graph containing tags, users and objects as nodes, and employ an optimization strategy, OptRank, to learn the weights of the edges that connect these nodes. Finally, Yin, Hong, Xue, and Davison (2011) consider the temporal aspect of tagging systems, i.e., the variation of user interests over time. However, these two more recent studies (Feng & Wang, 2012; Yin et al., 2011) still focus only on the folksonomy, disregarding the use of textual features. More broadly, none of these previously proposed personalized tag recommendation methods jointly exploits all three dimensions of the problem identified and exploited by us, that is, tag co-occurrences, multiple textual features and metrics of tag relevance (including the user-related UF metric for personalization). Moreover, our experimental results indicate that our extension of object-centered recommendation strategies to include personalization can significantly outperform state-of-the-art personalized tag recommendation methods as well as the original object-centered strategies in providing better descriptions for the objects.

Learning-to-rank (L2R) for Information Retrieval (IR) is the task of automatically constructing a ranking model using training data, such that the model can sort new objects according to their degrees of relevance, preference, or importance (Liu, 2009). Liu (2009) review existing L2R algorithms, categorizing them into three approaches: pointwise, pairwise and listwise. The pointwise approach assumes that each query-document pair in the training data has a numerical score, and thus the L2R problem can be approximated by a regression problem. Pairwise approaches are approximated by binary classification – given a pair of documents, it is necessary to predict which one is the best, while the listwise approach tries to directly optimize a given evaluation measure. The advantages and disadvantages of each approach are analyzed, and the relationships between the loss functions used in these approaches and IR evaluation measures are discussed. Moreover, experiments using the datasets of the LETOR benchmark indicate that the listwise approach is the most effective among the three approaches.

The effectiveness of L2R has been studied in various specific domains, particularly document and image retrieval (Faria et al., 2010; Gomes, Oliveira, de Almeida, & Gonçalves, 2013). For example, Gomes et al. (2013) compare thirteen L2R techniques for document ranking using various datasets of the LETOR benchmark. They find that: (i) in most datasets the results of all analyzed methods are statistically tied with each other and with an unsupervised strategy that uses the best individual attribute in isolation and (ii) for the other datasets, there is not a clear winner method. In contrast, in the context of image ranking, Faria et al. (2010) show that all studied L2R methods outperform the unsupervised ranking by attribute values in isolation, and that two L2R methods, one based on association rules and the other based on Genetic Programming (GP), are clear winners.

In a recent work, Niu, Guo, Lan, and Cheng (2012) propose a novel top-k L2R framework, in which pairwise preference judgements with multiple levels of relevance are performed to partially sort search results, generating a top-k ranking of documents, in contrast to the traditional ordering of all documents in the result list. This strategy reduces time complexity of generating the ground-truth from O (
                           
                              n
                              log
                              
                              n
                           
                        ) to O (
                           
                              n
                              log
                              
                              k
                           
                        ), where n is the number of documents in the ranking. The framework also includes a new L2R strategy, FocusedRank, which fully captures the characteristics of the top-k ground-truth. One of the best variations of FocusedRank, called FocusedSVM, combines characteristics of RankSVM and 
                           
                              
                                 
                                    SVM
                                 
                                 
                                    MAP
                                 
                              
                           
                         (a listwise approach that directly optimizes mean average precision).

Other recent work on L2R tackles the problems of selecting documents for L2R datasets and the impact of these choices on the efficiency and effectiveness of L2R algorithms (Aslam, Kanoulas, Pavlu, Savev, & Yilmaz, 2009), and filtering the steady stream of social media information users receive (Hong, Bekkerman, Adler, & Davison, 2012). Particularly, Hong et al. (2012) discuss how to build effective systems for ranking social updates from a unique perspective of LinkedIn – the largest professional network in the world. They address this problem as an intersection of L2R, collaborative filtering, and click-through modeling, while leveraging ideas from information retrieval and recommender systems. On a complementary direction, Chen et al. analyze the relationship between ranking measures and loss functions in several L2R methods, such as RankSVM, RankBoost and ListNet, showing that the loss functions of these methods are upper bounds of the measure-based ranking errors. Thus, the minimization of these loss functions leads to the maximization of the ranking measures. Modeling ranking as a sequence of classification tasks, the authors prove that the essential loss (defined as the weighted sum of the classification errors of individual tasks in the sequence) is both an upper bound of the measure-based ranking errors and a lower bound of the loss functions in the aforementioned methods. With that in mind, they propose modified loss functions that are tighter bounds of the measure-based ranking errors, obtaining better ranking performances.

Regarding the application of L2R techniques to the tag recommendation problem, we are aware of only a few prior efforts. One such effort is our prior investigation (Belém et al., 2011), where both RankSVM and Genetic Programming were applied to the tag recommendation problem. Two other related studies are those by Cao et al. (2009) and Wu et al. (2009), which exploit RankSVM and RankBoost as L2R techniques, respectively. However, all these previous studies focus only on object-centered tag recommendation. Instead, we here address both personalized and object-centered recommendations, and compare three L2R techniques, namely, RankSVM, GP and Random Forest. Moreover, unlike our current effort, Wu et al. (2009) consider only metrics related to tag co-occurrences and image content, and do not exploit textual features, whereas Cao et al. Cao et al. (2009) consider only metrics related to tag frequency, disregarding tag co-occurrence metrics.

A related body of previous work focuses on characterizing tagging systems, thus producing useful knowledge for the design of tag recommendation systems (Almeida et al., 2010; Figueiredo et al., 2013; Li et al., 2008; Lipczak & Milios, 2010; Rader & Wash, 2008). For example, Lipczak and Milios (2010) find that the title and the personal tagging history of a user are the main factors that impact tagging decisions, whereas Rader and Wash (2008) show that personal organization has a stronger impact on tagging decisions than social influences. In another direction, Almeida et al. (2010) and Figueiredo et al. (2013) propose several metrics to assess the quality of different textual features commonly associated with objects in Web 2.0 applications. They find that the title is the textual feature with the best capacity of describing the object’s content, followed by tags. Similarly, Li et al. (2008) find that user-generated tags are consistent with the web textual content with which they are associated, and that they capture the user’s interests. In a more recent work, Zhang, Korayem, You, and Crandall (2012) study geo-spatial and temporal relationships between tags, but only apply them to cluster and visualize tags, and not to recommend tags.

A Web 2.0 object is a media instance (e.g., a text, an audio, a video, an image) in a given Web 2.0 application. There are various sources of information related to an object, here referred to as its features. In particular, textual features, one of our main sources of information, comprise the self-contained textual blocks that are associated with an object, usually with a well defined functionality (Figueiredo et al., 2013). The textual features here exploited are tags, title and description associated with each object.

Let 
                        
                           U
                           ,
                           O
                        
                      and T be the sets of users, objects and tags of a Web 2.0 application, respectively. The tag recommendation strategies proposed here are based on the following sources of information:
                        
                           (1)
                           the set of tag assignments 
                                 
                                    P
                                    ⊆
                                    U
                                    ×
                                    O
                                    ×
                                    T
                                 
                              , represented by a set of triples defined as:
                                 
                                    
                                       P
                                       =
                                       {
                                       〈
                                       u
                                       ,
                                       o
                                       ,
                                       t
                                       〉
                                       |
                                       
                                       user
                                       
                                       u
                                       
                                       assigned
                                       
                                       tag
                                       
                                       t
                                       
                                       to
                                       
                                       object
                                       
                                       o
                                       }
                                       ,
                                    
                                 
                              and

for each object 
                                 
                                    o
                                    ∈
                                    O
                                 
                              , a set of textual features (other than tags) 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                    
                                    =
                                    {
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                       
                                          2
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                       
                                          n
                                       
                                    
                                    }
                                 
                              , where each element 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                       
                                          i
                                       
                                    
                                 
                               is the set of terms in textual feature i associated with object o.

Let 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      be the set of tags previously assigned to the target object o, and 
                        
                           
                              
                                 I
                              
                              
                                 o
                                 ,
                                 u
                              
                           
                        
                      the set of tags assigned to the target object o by the target user u, that is,
                        
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                              =
                              {
                              t
                              |
                              ∃
                              u
                              ∈
                              U
                              
                              such
                              
                              that
                              
                              〈
                              u
                              ,
                              o
                              ,
                              t
                              〉
                              ∈
                              P
                              }
                              ,
                           
                        
                     
                     
                        
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                    ,
                                    u
                                 
                              
                              =
                              {
                              t
                              |
                              〈
                              u
                              ,
                              o
                              ,
                              t
                              〉
                              ∈
                              P
                              }
                              .
                           
                        
                     
                  

Thus, we define two tag recommendation tasks:
                        
                           
                              Object-Centered Tag Recommendation.
                              Given a set of input tags 
                                 
                                    
                                       
                                          I
                                       
                                       
                                          o
                                       
                                    
                                 
                               and a set of textual features 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                    
                                 
                              , associated with the target object o, generate a set of candidates 
                                 
                                    
                                       
                                          C
                                       
                                       
                                          o
                                       
                                    
                                 
                               (
                                 
                                    
                                       
                                          C
                                       
                                       
                                          o
                                       
                                    
                                    ∩
                                    
                                       
                                          I
                                       
                                       
                                          o
                                       
                                    
                                    =
                                    ∅
                                 
                              ), sorted according to their relevance to o.
                                 4
                                 Note that we here refer to the task of recommending tags for an object aiming at improving the quality of its tags (but not necessarily matching the interests of any particular user) as object-centered tag recommendation, even though some of the attributes exploited by the methods (see the description of all metrics in Section 4), such as the tag co-occurrence metrics, are related to other tags of the object, and, in a sense, could be considered tag related attributes.
                              
                              
                                 4
                              
                           


                              Personalized Tag Recommendation.
                              Given a set of input tags 
                                 
                                    
                                       
                                          I
                                       
                                       
                                          o
                                       
                                    
                                 
                               and a set of textual features 
                                 
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                    
                                 
                              , associated with the target object o, generate a set of candidates 
                                 
                                    
                                       
                                          C
                                       
                                       
                                          o
                                          ,
                                          u
                                       
                                    
                                 
                               (
                                 
                                    
                                       
                                          C
                                       
                                       
                                          o
                                          ,
                                          u
                                       
                                    
                                    ∩
                                    
                                       
                                          I
                                       
                                       
                                          o
                                          ,
                                          u
                                       
                                    
                                    =
                                    ∅
                                 
                              ) sorted according to their relevance to both user u and object o.

We note that, when the recommendation task is centered at the object, the same tags are provided regardless of the target user. The primary goal of this kind of recommendation is improving the quality of the tags in these objects, thus, improving the effectiveness of services, such as searching, indexing and classification, that use them as data source. On the other hand, the personalized tag recommendation takes the target user into account: the goal is to suggest relevant tags for the object that match the interests, profile and background of the target user. Personalized tag recommenders might provide different answers to different users (or users with different profiles). One important service that can benefit from personalized tag recommendations is personal content organization. However, we argue that other services that rely on good descriptions of the object’s content, such as content recommendation and search, might also benefit from personalized tag recommendations.

One observation that supports our argument is that different users may use very different tags to describe the same object, depending on their backgrounds and interests, and how they perceive the object’s content. Moreover, objects shared on Web 2.0 applications are often multifaceted, being related to various topics, and different users may relate to such topics differently. Thus, in applications where multiple users can assign tags to the same object, such as the popular Last.FM, a personalized tag recommender is not only useful for the individual user (e.g., for content organization) but also in a collective sense, as jointly the tags recommended to different users may provide a more complete description of the object, which indirectly helps search and recommendation services. In other words, a set of personalized tags for the same object produced to different users, with different backgrounds and interests, helps covering multiple facets or interpretations of the same object, thus helping with the semantic gap. Moreover, personalized tag recommendations might provide better descriptions of the object, compared to object-centered recommendations, even if considering a single user. Take, for instance, the user who created and uploaded the object. Personalized tag recommendations tailored to her interests might better capture the object’s content.

In order to support our argument, we present three real-world examples extracted from one of our datasets (Last.FM) where personalization produced qualitatively better results than a non-personalized method. Table 1
                      shows the top-5 tags recommended by our best object-centered recommender (4th column) and by our best personalized tag recommender (5th column) to two artists: Taylor Swift and Nina Simone. For the latter, Table 1 includes the recommendations produced to two different users.

While the object-centered strategy recommended general tags such as “seen” and “live” for Taylor Swift (example 1), the tags recommended by the personalized strategy to one user represent well the artist’s main music genres (“pop” and “country”) and initial decade of success (2000s). These tags might be considered a better description of the artist.

In examples 2 and 3, the object-centered strategy suggested the tag “rock” to Nina Simone, probably due to a large number of co-occurrences of this tag with the previously available tags of the object. Again, the personalized recommendations provided more related genres for the singer (“jazz” and “soul”, in example 2) among the top recommendations. Moreover, the personalized method recommended tags that might be more important to the target user (and thus to users of similar interests and backgrounds), such as “instrumental” and “piano”, which are two of the most emphasized tags on the tag cloud of the page of this user on Last.FM. To another user (example 3), the method correctly recommended the nationality of the singer (“American”), one of her decades of most success (“60s”), and the tag “female”, which is important in the tag cloud of this user, who appreciates female vocalists in general (according to her user profile). Moreover, note that, if taken collectively, the set of tags suggested to both users by our personalized recommender provides a much better and more complete description of the singer than the object-centered recommendations, which would be the same to all users.

These examples illustrate our argument that personalized tag recommendation may provide better descriptions of the target object, covering multiple facets or interpretations of it. We provide further evidence to support this claim in Section 6.5.3, where we empirically compare the effectiveness of object-centered and personalized tag recommendation strategies.

Having motivated the tag recommendation tasks addressed here, we now formally define our target scenarios. For both recommendation tasks, we focus on cases in which there are some available tags in the target object (i.e., 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                           
                           ≠
                           
                           ∅
                        
                     ), and we want to recommend new (different) tags to it. We note, however, that our methods are also able to recommend relevant tags to an object with no initial set of tags by exploiting other textual features and metrics of relevance. We leave this for future work.

Many tag recommendation strategies, and in particular the ones proposed here, exploit co-occurrence patterns by mining relations among tags assigned to the same object (or additionally by the same user) in an object collection. The process of learning such patterns is defined as follows.

For object-centered tag recommendation, we define a training set 
                        
                           D
                           =
                           {
                           〈
                           
                              
                                 I
                              
                              
                                 d
                              
                           
                           ,
                           
                              
                                 F
                              
                              
                                 d
                              
                           
                           〉
                           }
                        
                     , where 
                        
                           
                              
                                 I
                              
                              
                                 d
                              
                           
                        
                      (
                        
                           
                              
                                 I
                              
                              
                                 d
                              
                           
                           
                           ≠
                           
                           ∅
                        
                     ) contains all tags assigned to object d, and 
                        
                           
                              
                                 F
                              
                              
                                 d
                              
                           
                        
                      contains the term sets of the other textual features associated with d. There is also a test set 
                        
                           O
                        
                     , which is a collection of tuples 
                        
                           {
                           〈
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                           ,
                           
                              
                                 F
                              
                              
                                 o
                              
                           
                           ,
                           
                              
                                 Y
                              
                              
                                 o
                              
                           
                           〉
                           }
                        
                     , where both 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      and 
                        
                           
                              
                                 Y
                              
                              
                                 o
                              
                           
                        
                      are sets of tags associated with object o. However, while tags in 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      are known (and given as input to the recommender), tags in 
                        
                           
                              
                                 Y
                              
                              
                                 o
                              
                           
                        
                      are assumed to be unknown and are taken as the relevant recommendations to the target object o (i.e., the expected answer). Splitting the tags of each test object into these two subsets facilitates an automatic assessment of the recommendations, as performed in Garg and Weber (2008), Menezes et al. (2010), Heymann et al. (2008), Lipczak and Milios (2011), Rendle and Lars (2010), and Guan et al. (2009) and further discussed in Section 6.2. Similarly, there might also be a validation set 
                        
                           V
                        
                      used for tuning parameters and “learning” recommendation functions (see Section 6.2). Thus, each object v in 
                        
                           V
                        
                      also has its tag set split into input tags (
                        
                           
                              
                                 I
                              
                              
                                 v
                              
                           
                        
                     ) and expected answer (
                        
                           
                              
                                 Y
                              
                              
                                 v
                              
                           
                        
                     ).

For personalized tag recommendation, we exploit two different kinds of tag co-occurrences: (1) between tags assigned to the same object by various users (as we do in the object-centered recommendation task) and (2) between tags assigned by the same user to the same object. Thus, there are two variants of the training set for personalized recommendation: (1) 
                        
                           D
                           =
                           {
                           〈
                           
                              
                                 I
                              
                              
                                 d
                              
                           
                           ,
                           
                              
                                 F
                              
                              
                                 d
                              
                           
                           〉
                           }
                        
                     , where 
                        
                           
                              
                                 I
                              
                              
                                 d
                              
                           
                        
                      contains all tags assigned to object d (by any user) and (2) 
                        
                           D
                           ′
                           =
                           {
                           〈
                           
                              
                                 I
                              
                              
                                 d
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       d
                                    
                                 
                              
                           
                           ,
                           
                              
                                 F
                              
                              
                                 d
                              
                           
                           〉
                           }
                        
                     , where 
                        
                           
                              
                                 I
                              
                              
                                 d
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       d
                                    
                                 
                              
                           
                        
                      contains all tags assigned to an object d by each user 
                        
                           
                              
                                 u
                              
                              
                                 d
                              
                           
                           ∈
                           
                              
                                 U
                              
                              
                                 d
                              
                           
                        
                     , where 
                        
                           
                              
                                 U
                              
                              
                                 d
                              
                           
                        
                      is the set of users who assigned at least one tag to object d. In both cases, 
                        
                           
                              
                                 F
                              
                              
                                 d
                              
                           
                        
                      contains the term sets of the other textual features associated with d, as defined above. The elements of the test object collection 
                        
                           O
                        
                      are tuples 
                        
                           〈
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                           ,
                           
                              
                                 F
                              
                              
                                 o
                              
                           
                           ,
                           
                              
                                 Y
                              
                              
                                 o
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       o
                                    
                                 
                              
                           
                           〉
                        
                     , where 
                        
                           
                              
                                 I
                              
                              
                                 o
                              
                           
                        
                      is a set of input tags, assigned by any user, including the target user, and 
                        
                           
                              
                                 Y
                              
                              
                                 o
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       o
                                    
                                 
                              
                           
                        
                      (expected answer) is a set of tags assigned by each user 
                        
                           
                              
                                 u
                              
                              
                                 o
                              
                           
                        
                      who assigned tags to object o. Similarly, each element of validation set 
                        
                           V
                        
                      also has its tag set split into input tags (
                        
                           
                              
                                 I
                              
                              
                                 v
                              
                           
                        
                     ) and expected answer (
                        
                           
                              
                                 Y
                              
                              
                                 v
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       v
                                    
                                 
                              
                           
                        
                     ).

Thus, we define associative and text based tag recommendation methods as algorithms that estimate the relevance of tag candidates relying on the elements described above. We model tag recommendation as a multiple term candidate ranking problem. That is, we develop functions to estimate the relevance of a candidate term as a tag recommendation to a given object (or object-user pair, for personalized tag recommendation), thus enabling us to rank the candidates according to such estimates and recommend the most relevant ones.

In this section, we present several metrics that can be used to estimate the relevance of a candidate for tag recommendation. They are used as attributes by our tag recommendation methods, particularly the L2R-based strategies. Some metrics, like 
                        
                           Sum
                           ,
                           Stability
                           ,
                           TF
                        
                      and Entropy, have been previously applied to recommend tags (Heymann et al., 2008; Menezes et al., 2010; Sigurbjörnsson & van Zwol, 2008). Others, such as IFF and AFS, were proposed in our previous work (Belém et al., 2011) and are here applied to both object-centered and personalized tag recommendation tasks. We note that the use of these metrics in the second task is a novel contribution of this work.

Each metric falls into one of these categories:
                        
                           •
                           
                              Tag co-occurrence metrics (Section 4.1): a key aspect in tag recommendation systems that estimates how relevant a candidate tag c is given a set of input tags that often co-occur with c in the dataset.


                              Descriptive power metrics (Section 4.2): estimate how accurately a candidate describes the object’s content, which is important for information services that exploit object’s semantics.


                              Discriminative power metrics (Section 4.3): estimate the capability of a candidate to distinguish the target object from others, which is important for tasks such as separating the objects into semantic classes or into levels of relevance regarding a query.


                              Term predictability (Section 4.4): indicates the likelihood that a candidate will be predicted as a tag.


                              User related metrics (Section 4.5): used for personalization, these metrics estimate the interest of a target user in certain tags.

Co-occurrence based tag recommendation approaches usually exploit association rules, that is, implications of type 
                           
                              X
                              →
                              y
                           
                        , where the antecedent X is a set of tags and the consequent y is a candidate tag for recommendation. The importance of an association rule is estimated based on support (
                           
                              σ
                           
                        ), which is the number of co-occurrences of X and y in the training set, and confidence (
                           
                              θ
                           
                        ), which is the conditional probability that y is assigned as a tag to an element 
                           
                              d
                              ∈
                              D
                           
                         given that all tags in X are also associated with d. As the number of rules mined from the training set 
                           
                              D
                           
                         can be very large and some of them may not be useful for recommendation, minimum support and confidence thresholds (
                           
                              
                                 
                                    σ
                                 
                                 
                                    min
                                 
                              
                           
                         and 
                           
                              
                                 
                                    θ
                                 
                                 
                                    min
                                 
                              
                           
                        , respectively) are used as lower bounds to select only the most frequent and/or reliable rules. This selection can improve both effectiveness and efficiency of the recommender.

At recommendation time, we select the rules whose antecedents are included in the previously assigned set of tags 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                        . For each term c appearing as consequent of any of the selected rules, we estimate its relevance as a tag for the object (and for the user in the personalized case), given the initial tag set 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                        , as the sum of the confidences of all rules containing c, i.e.:
                           
                              (1)
                              
                                 Sum
                                 (
                                 c
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 ℓ
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          X
                                          ⊆
                                          
                                             
                                                I
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 θ
                                 (
                                 X
                                 →
                                 c
                                 )
                                 ,
                                 
                                 (
                                 X
                                 →
                                 c
                                 )
                                 ∈
                                 R
                                 ,
                                 
                                 |
                                 X
                                 |
                                 ⩽
                                 ℓ
                                 ,
                              
                           
                        where 
                           
                              R
                           
                         is a set of association rules computed offline over the training set 
                           
                              D
                           
                        , given thresholds 
                           
                              
                                 
                                    σ
                                 
                                 
                                    min
                                 
                              
                           
                         and 
                           
                              
                                 
                                    θ
                                 
                                 
                                    min
                                 
                              
                           
                        , and 
                           
                              ℓ
                           
                         is the size limit for the association rules’ antecedents. Sum was proposed in Sigurbjörnsson and van Zwol (2008), which also proposed several other metrics related to tag co-occurrences, including Vote and 
                           
                              
                                 
                                    Vote
                                 
                                 
                                    +
                                 
                              
                           
                        , which are also considered here. The metric Vote estimates the relevance of a candidate tag c by the number of association rules whose antecedents are tags in 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                         and whose consequent is the candidate c. That is:
                           
                              (2)
                              
                                 Vote
                                 (
                                 c
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ∈
                                          
                                             
                                                I
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 j
                                 ,
                                 
                                 where
                                 
                                 j
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   x
                                                   →
                                                   c
                                                   )
                                                   ∈
                                                   R
                                                   ,
                                                
                                             
                                             
                                                
                                                   0
                                                   ,
                                                
                                                
                                                   otherwise,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     


                        
                           
                              
                                 
                                    Vote
                                 
                                 
                                    +
                                 
                              
                           
                         is built from Vote as follows:
                           
                              (3)
                              
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   Vote
                                                
                                                
                                                   +
                                                
                                             
                                             (
                                             c
                                             ,
                                             
                                                
                                                   I
                                                
                                                
                                                   o
                                                
                                             
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   x
                                                
                                             
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   c
                                                
                                             
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   r
                                                
                                             
                                             )
                                             =
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      x
                                                      ∈
                                                      
                                                         
                                                            I
                                                         
                                                         
                                                            o
                                                         
                                                      
                                                   
                                                
                                             
                                             j
                                             ×
                                             Stab
                                             (
                                             x
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   x
                                                
                                             
                                             )
                                             ×
                                             Stab
                                             (
                                             c
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   c
                                                
                                             
                                             )
                                             ×
                                             Rank
                                             (
                                             c
                                             ,
                                             x
                                             ,
                                             
                                                
                                                   k
                                                
                                                
                                                   r
                                                
                                             
                                             )
                                             ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             where
                                             
                                             j
                                             =
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               1
                                                               ,
                                                            
                                                            
                                                               if
                                                               
                                                               x
                                                               →
                                                               c
                                                               ∈
                                                               R
                                                               ,
                                                            
                                                         
                                                         
                                                            
                                                               0
                                                               ,
                                                            
                                                            
                                                               otherwise,
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        and 
                           
                              
                                 
                                    k
                                 
                                 
                                    x
                                 
                              
                              ,
                              
                                 
                                    k
                                 
                                 
                                    c
                                 
                              
                           
                         and 
                           
                              
                                 
                                    k
                                 
                                 
                                    r
                                 
                              
                           
                         are tuning parameters. 
                           
                              Rank
                              (
                              c
                              ,
                              x
                              ,
                              
                                 
                                    k
                                 
                                 
                                    r
                                 
                              
                              )
                           
                         is equal to 
                           
                              
                                 
                                    k
                                 
                                 
                                    r
                                 
                              
                              /
                              (
                              
                                 
                                    k
                                 
                                 
                                    r
                                 
                              
                              +
                              p
                              (
                              c
                              ,
                              x
                              )
                              )
                           
                        , where 
                           
                              p
                              (
                              c
                              ,
                              x
                              )
                           
                         is the position of c in the ranking of candidates according to the confidence of the corresponding association rule (whose antecedent is x). This factor is employed to make confidence values decay smoother. Stab is a metric used to reduce the relative importance of terms that occur either too often or very rarely in the training set, and thus may represent poor recommendations. This metric, defined in Section 4.3, is used, as part of 
                           
                              
                                 
                                    Vote
                                 
                                 
                                    +
                                 
                              
                           
                        , to weight the confidence values of the tags in the antecedent and in the consequent of the association rules. A similar extension of Sum, called 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                        , is also presented in Sigurbjörnsson and van Zwol (2008), being reported as the metric that produces the best tag recommendations out of all metrics proposed in that study. Thus, we here apply 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                         as a baseline method for object-centered recommendation (see Section 5.1).

For personalized tag recommendation, we here distinguish two types of co-occurrence patterns: (1) between all tags assigned to an object by different users, which have been previously exploited in the literature (Garg & Weber, 2008; Lipczak et al., 2009; Sigurbjörnsson & van Zwol, 2008) and is here adopted for object-centered recommendation as well and (2) between all tags assigned by the same user to an object, which we propose here. While the first strategy benefits from a larger amount of data, the second strategy may generate less noise. As we will show in Section 6, these two strategies provide quite different results, and the best strategy depends on the complexity of the exploited association rules, given by parameter 
                           
                              ℓ
                           
                        . For all metrics of tag co-occurrence, we use a subscript u to indicate that the second type of co-occurrence is used. When there is no such subscript, we refer to the first strategy to generate co-occurrence patterns. For example, 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    u
                                 
                              
                              (
                              c
                              ,
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                              ,
                              ℓ
                              )
                           
                         indicates that the set of rules 
                           
                              R
                           
                         exploited to compute metric Sum was generated from sets of tags assigned by the same user to an object (that is, training set 
                           
                              D
                              ′
                           
                        , defined in Section 3). 
                           
                              Sum
                              (
                              c
                              ,
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                              ,
                              ℓ
                              )
                           
                         refers to the original metric, which exploits co-occurrences between all tags assigned to an object by different users.

We here exploit four heuristic metrics that try to capture, to some extent, the descriptive power of a candidate c. In Belém et al. (2011), we exploited them for object-centered tag recommendation, while here we also apply them to the personalized tag recommendation task. This is a novel aspect of this work.

We start by defining the Term Spread of a candidate c in an object 
                           
                              o
                              ,
                              TS
                              (
                              c
                              ,
                              o
                              )
                           
                        , as the number of textual features (except tags, in the present context)
                           5
                           We do not include tags to compute any of the descriptive power metrics, as it does not make sense to use tags previously assigned to the target object as candidates for recommendation.
                        
                        
                           5
                         of o that contain c (Figueiredo et al., 2013):
                           
                              (4)
                              
                                 TS
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 j
                                 ,
                                 
                                 where
                                 
                                 j
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   c
                                                   ∈
                                                   
                                                      
                                                         F
                                                      
                                                      
                                                         o
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The assumption behind 
                           
                              TS
                              (
                              c
                              ,
                              o
                              )
                           
                         is that the larger the number of features of o containing c, the more related c is to o’s content. For example, if the term “Sting” appears in all features of a video, there is a high chance that the video is related to the famous singer. The maximum TS is given by the number of textual features, other than tags, considered. As we here consider title and description, 
                           
                              TS
                              ⩽
                              2
                           
                        .

The Term Frequency of c in object 
                           
                              o
                              ,
                              TF
                              (
                              c
                              ,
                              o
                              )
                           
                        , is:
                           
                              (5)
                              
                                 TF
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 tf
                                 (
                                 c
                                 ,
                                 
                                    
                                       F
                                    
                                    
                                       o
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                              
                           
                        where 
                           
                              tf
                              (
                              c
                              ,
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         is the number of occurrences of c in feature 
                           
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                           
                         of object o. Thus, TF considers all textual features of o as a single bag of words, counting all occurrences of c in it. In contrast, TS considers the structure of an object, composed by textual features, which are well-defined blocks of text, counting the number of blocks containing c.

Although both TS and TF try to capture how accurately a term describes an object’s content, neither of them considers that different features may present, in general, different descriptive capacities. For example, the title may describe an object’s content more accurately than other textual features (Figueiredo et al., 2013). Thus, we proposed in Belém et al. (2011) two other metrics, built on TF and TS, that weight a term based on the average descriptive powers of the textual features in which it appears.

The average descriptive power of a textual feature 
                           
                              
                                 
                                    F
                                 
                                 
                                    i
                                 
                              
                           
                         is assessed by the Average Feature Spread (AFS) heuristic (Figueiredo et al., 2013). Let the Feature Instance Spread of a feature 
                           
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                           
                         associated with object 
                           
                              o
                              ,
                              FIS
                              (
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                              )
                           
                        , be the average TS over all terms in 
                           
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                           
                        . We define 
                           
                              AFS
                              (
                              
                                 
                                    F
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         as the average 
                           
                              FIS
                              (
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         over all instances of 
                           
                              
                                 
                                    F
                                 
                                 
                                    i
                                 
                              
                           
                         associated with objects in the training set 
                           
                              D
                           
                        . We then define weighted TS and TF metrics as:
                           
                              (6)
                              
                                 wTS
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 j
                                 ,
                                 
                                 where
                                 
                                 j
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   AFS
                                                   (
                                                   
                                                      
                                                         F
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   )
                                                
                                                
                                                   if
                                                   
                                                   c
                                                   ∈
                                                   
                                                      
                                                         F
                                                      
                                                      
                                                         o
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 wTF
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          
                                             
                                                F
                                             
                                             
                                                o
                                             
                                          
                                       
                                    
                                 
                                 tf
                                 (
                                 c
                                 ,
                                 
                                    
                                       F
                                    
                                    
                                       o
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ×
                                 AFS
                                 (
                                 
                                    
                                       F
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 .
                              
                           
                        
                     

One may argue that recommending more infrequent terms (provided that they are not too rare) may be desirable, since they may better discriminate objects into different categories, topics, or levels of relevance, particularly considering that several services (e.g., classification, searching) often perform IR on multimedia content by using the associated tags as data sources. This aspect can be heuristically captured by the Inverse Feature Frequency (IFF) metric (Figueiredo et al., 2013), an adaptation of the traditional Inverse Document Frequency (IDF) that considers the term frequency in a specific textual feature (in our case, tags). Given the number of elements in the training set 
                           
                              |
                              D
                              |
                           
                        , the IFF of a candidate c is defined as:
                           
                              (8)
                              
                                 IFF
                                 (
                                 c
                                 )
                                 =
                                 log
                                 
                                    
                                       |
                                       D
                                       |
                                       +
                                       1
                                    
                                    
                                       
                                          
                                             f
                                          
                                          
                                             c
                                          
                                          
                                             tag
                                          
                                       
                                       +
                                       1
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    f
                                 
                                 
                                    c
                                 
                                 
                                    tag
                                 
                              
                           
                         is the number of elements (objects for object-centered recommendation, or object-user pairs for personalized recommendation) in 
                           
                              D
                           
                         that are tagged with c. Note that c may be extracted from other textual features. The value 1 is added to both numerator and denominator to deal with new terms that do not appear as tags in the training data. We note that this metric may privilege terms from other textual features that do not appear as tags in the training data. Nevertheless, this metric will be combined with the other metrics into a function, using learning-to-rank algorithms. Thus, its relative weight can be adjusted.

Along the same lines, one may consider that terms that are very common, such as “video” in a YouTube object collection, are too general and broad, whereas very rare terms may be too specific or may represent noise (e.g., misspellings, neologisms and unknown words). In either case, such terms represent poor recommendations as they have very poor discriminative power. Sigurbjörnsson and van Zwol (2008) propose the Stability (Stab) metric, which gives more importance to terms with intermediate frequency values:
                           
                              (9)
                              
                                 Stab
                                 (
                                 c
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             k
                                          
                                          
                                             s
                                          
                                       
                                    
                                    
                                       
                                          
                                             k
                                          
                                          
                                             s
                                          
                                       
                                       +
                                       |
                                       
                                          
                                             k
                                          
                                          
                                             s
                                          
                                       
                                       -
                                       log
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             c
                                          
                                          
                                             tag
                                          
                                       
                                       )
                                       |
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    k
                                 
                                 
                                    s
                                 
                              
                           
                         represents the “ideal frequency” of a term and must be adjusted to the data collection. We here also use Stab to assess the relevance of a candidate tag, but, unlike (Sigurbjörnsson & van Zwol, 2008), we apply it not only to tags but also to terms extracted from all textual features 
                           
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                              
                           
                         associated with target object o.

Another important aspect for tag recommendation is term predictability. Heymann et al. (2008) measure this characteristic through the term’s entropy. The entropy of a candidate c in the tags feature, 
                           
                              
                                 
                                    H
                                 
                                 
                                    tags
                                 
                              
                              (
                              c
                              )
                           
                        , is defined as:
                           
                              (10)
                              
                                 
                                    
                                       H
                                    
                                    
                                       tags
                                    
                                 
                                 (
                                 c
                                 )
                                 =
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          (
                                          c
                                          →
                                          i
                                          )
                                          ∈
                                          R
                                       
                                    
                                 
                                 θ
                                 (
                                 c
                                 →
                                 i
                                 )
                                 log
                                 
                                 θ
                                 (
                                 c
                                 →
                                 i
                                 )
                                 .
                              
                           
                        
                     

If a term occurs consistently with certain tags, it is more predictable, thus having lower entropy. Terms that occur indiscriminately with many other tags are less predictable, thus having higher entropy. In other words, 
                           
                              
                                 
                                    H
                                 
                                 
                                    tags
                                 
                              
                              (
                              c
                              )
                           
                         measures the concentration of confidence values of all association rules whose antecedent is c. If a term is absent in the training set, it receives an arbitrarily high entropy, as, in this case, the result is not a real number. Term entropy can be useful particularly for breaking ties, as it is better to recommend more “consistent” or less “confusing” terms. Whereas term entropy was used in Heymann et al. (2008) only to evaluate recommendations, we here apply it as an input to the recommendation functions.

Inspired by the method proposed in Lipczak et al. (2009), described in Section 5.1, we here propose a metric called Predictability (Pred), which measures the probability that a term is used as a tag in an object given that it was used in another textual feature of the same object. Unlike the metric proposed in Lipczak et al. (2009), which computes such co-occurrences separately for each textual feature, Pred is computed by aggregating all textual features of the object. In other words, the Predictability of a candidate tag 
                           
                              c
                              ,
                              Pred
                              (
                              c
                              )
                           
                        , is defined as:
                           
                              (11)
                              
                                 Pred
                                 (
                                 c
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             c
                                          
                                          
                                             tag
                                             ,
                                             F
                                          
                                       
                                    
                                    
                                       
                                          
                                             f
                                          
                                          
                                             c
                                          
                                          
                                             F
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    f
                                 
                                 
                                    c
                                 
                                 
                                    tag
                                    ,
                                    F
                                 
                              
                           
                         is the number of objects in the training set in which c appears both as a tag and as a term in any other textual feature, and 
                           
                              
                                 
                                    f
                                 
                                 
                                    c
                                 
                                 
                                    F
                                 
                              
                           
                         is the number of objects in which c is a term associated with any of its textual features (except tags).

In order to estimate the relevance of a candidate for a target user and thus provide personalized recommendations, we propose here a metric called User Frequency,
                           6
                           This metric is similar to one proposed in Lipczak et al. (2009). However, the authors in Lipczak et al. (2009) make use of the timestamp of the tagging event. As this information is not available in our datasets, we adapted this metric to consider all tag assignments of user u in the training set.
                        
                        
                           6
                         or UF, which is the frequency at which the target user assigns a candidate tag to an object. In other words, given a candidate c and a target user 
                           
                              u
                              ,
                              UF
                              (
                              c
                              ,
                              u
                              )
                           
                         is defined as:
                           
                              (12)
                              
                                 UF
                                 (
                                 c
                                 ,
                                 u
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             N
                                          
                                          
                                             c
                                             ,
                                             u
                                          
                                       
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             u
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    N
                                 
                                 
                                    c
                                    ,
                                    u
                                 
                              
                           
                         is the number of times that user u tagged an object with c in the training set 
                           
                              D
                           
                        , and 
                           
                              
                                 
                                    N
                                 
                                 
                                    u
                                 
                              
                           
                         is the total number of times user u submitted a tag. Thus, the rationale behind UF is: the more frequently a user u assigns a candidate tag c to other objects in the application, the more relevant c is for u. This metric is computed for all tags used by the target user u in the training set.

In this section, we present the tag recommendation strategies analyzed in this work. First, in Section 5.1, we describe state-of-the-art methods used here as baselines for object-centered and personalized tag recommendation. The object-centered baseline methods exploit a combination of at most two of the following dimensions: term co-occurrence with pre-assigned tags, multiple textual features and relevance metrics. The personalized baseline method is a matrix factorization approach that exploits the folksonomy.

We then present our new proposed solutions, which exploit all aforementioned dimensions as well as new relevance metrics. In Section 5.2, we introduce our new object-centered and personalized heuristics, while we describe the learning-to-rank based strategies in Section 5.3.

The following sections briefly describe the baseline methods used for evaluating our new object-centered and personalized tag recommendation methods.

Our first baseline is 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                           , the best function proposed in Sigurbjörnsson and van Zwol (2008), which exploits both tag co-occurrences and metrics of tag relevance. 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            extends the Sum metric (Eq. (1)) similarly to how 
                              
                                 
                                    
                                       Vote
                                    
                                    
                                       +
                                    
                                 
                              
                            extends Vote (see Section 4.1), that is, by weighting the confidence values by the Stability of the terms in the antecedent and consequent of the corresponding association rules. We here use the Apriori algorithm (Agrawal & Srikant, 1994) to generate the association rules. In other words, given a candidate c for an object o associated with a set of previously assigned tags 
                              
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            is defined as:
                              
                                 (13)
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    (
                                    c
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          o
                                       
                                    
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          x
                                       
                                    
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          c
                                       
                                    
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          r
                                       
                                    
                                    ,
                                    ℓ
                                    )
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             x
                                             ∈
                                             
                                                
                                                   I
                                                
                                                
                                                   o
                                                
                                             
                                          
                                       
                                    
                                    θ
                                    (
                                    x
                                    →
                                    c
                                    )
                                    ×
                                    Stab
                                    (
                                    x
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          x
                                       
                                    
                                    )
                                    ×
                                    Stab
                                    (
                                    c
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          c
                                       
                                    
                                    )
                                    ×
                                    Rank
                                    (
                                    c
                                    ,
                                    x
                                    ,
                                    
                                       
                                          k
                                       
                                       
                                          r
                                       
                                    
                                    )
                                    ,
                                    
                                    |
                                    X
                                    |
                                    ⩽
                                    ℓ
                                    ,
                                 
                              
                           where 
                              
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                              
                            are tuning parameters.


                           
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                           , as most co-occurrence based strategies (Garg & Weber, 2008; Sigurbjörnsson & van Zwol, 2008), restricts the size of the association rules to only one tag in the antecedent (i.e., 
                              
                                 ℓ
                              
                           =1) due to efficiency issues. In contrast, LATRE – Lazy Associative Tag Recommender (Menezes et al., 2010), our second baseline, is able to efficiently generate larger association rules by doing it on demand. This is in contrast to other strategies (e.g., Apriori), which compute all rules from the training set beforehand (i.e., offline), possibly including rules that might not be useful when recommending for objects in the test set. LATRE ranks each candidate c by the sum of the confidences of all rules containing c. That is, it uses the Sum metric (Eq. (1)) with 
                              
                                 ℓ
                                 ⩾
                                 1
                              
                           , thus exploiting solely co-occurrence patterns. We note that two variations of LATRE, with and without calibration, are presented in Menezes et al. (2010). We here consider the LATRE without calibration since it has lower complexity and, according to Menezes et al. (2010), produces very similar results to those obtained with calibration, with no significant differences in most cases.

Our third baseline is called here Co-occurrence and Text based Tag Recommender (CTTR). It exploits terms extracted from other textual features and a metric of relevance, but does not consider tags previously assigned to the target object. CTTR is an adaptation of the winner of the ECML Discovery Challenge 2009 (Lipczak et al., 2009), which, in addition to the two aforementioned aspects, also takes the user’s tag assignment history into account. We here do not include such user statistics in CTTR, because they include the time instants when the tag assignments were done by each user, and this information is not available in our datasets. Thus, we here use CTTR as a baseline for object-centered recommendation only.
                              7
                              The lack of the user historical information required by the method prevented us from using it as baseline for personalized tag recommendation.
                           
                           
                              7
                            Like our methods, CTTR also exploits multiple textual features. Thus, the comparison of our methods against this baseline allows us to assess the benefits of applying our metrics of relevance to such terms and to exploit co-occurrence of previously assigned tags.

The basic structure of CTTR is depicted in Fig. 1
                           . As described below, CTTR distinguishes two types of co-occurrences: (1) between tags, in which the antecedents are tags in the objects of the training set and (2) between terms in the title of an object and its tags, in which the antecedents are terms in the titles of such objects. At recommendation time, the sets of rules related to the extracted terms are combined using corresponding scores. As a final step, the scores obtained from the association rules and from the title and description of the target objects are rescored once again, and merged, resulting in the final ranking.

The first step is the extraction of potential candidates from other textual features associated with the target object, namely its title and description. Each term extracted from the title (or description) is scored according to its usage in previous tagging posts (training set). The score 
                              
                                 
                                    
                                       p
                                    
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                              
                            is the ratio of the number of times the term x was used simultaneously in 
                              
                                 
                                    
                                       F
                                    
                                    
                                       d
                                    
                                    
                                       i
                                    
                                 
                              
                            and as a tag to the total number of objects in which x is associated with the textual feature 
                              
                                 
                                    
                                       F
                                    
                                    
                                       d
                                    
                                    
                                       i
                                    
                                 
                              
                           , where 
                              
                                 i
                                 ∈
                                 {
                                 title
                                 ,
                                 description
                                 }
                              
                           .
                              8
                              The score 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                    
                                  inspired us to build the Pred metric, defined in Section 4.4.
                           
                           
                              8
                           
                        

Next, the candidate sets generated by title and description are merged. As observed in Lipczak et al. (2009), titles tend to provide more precise recommendations than other textual features, which should be reflected in the merging step. Towards that goal, the authors propose to use a leading precision rescorer for weighting the different candidate sources (textual features). This rescorer sets the average precision at the first position of the rank, 
                              
                                 avgP
                                 @
                                 1
                              
                            (calculated over training data) as a new score for the top candidate, and modifies the scores 
                              
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                              
                            of the following terms proportionally. Let 
                              
                                 
                                    
                                       s
                                    
                                    
                                       1
                                    
                                 
                              
                            be the old score of the top candidate. The new score 
                              
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                              
                            of the ith candidate tag is given by:
                              
                                 (14)
                                 
                                    
                                       
                                          s
                                       
                                       
                                          i
                                       
                                       
                                          ′
                                       
                                    
                                    =
                                    
                                       
                                          avgP
                                          @
                                          1
                                          ×
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          
                                             
                                                s
                                             
                                             
                                                1
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

After re-scoring, the new scores should be merged in a probabilistic sum. Let 
                              
                                 
                                    
                                       S
                                    
                                    
                                       t
                                    
                                 
                                 =
                                 {
                                 
                                    
                                       s
                                    
                                    
                                       t
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       s
                                    
                                    
                                       t
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       s
                                    
                                    
                                       t
                                    
                                    
                                       n
                                    
                                 
                                 }
                              
                            be a set of different scores for candidate tag t. The merging function is given by:
                              
                                 (15)
                                 
                                    merge
                                    (
                                    
                                       
                                          S
                                       
                                       
                                          t
                                       
                                    
                                    )
                                    =
                                    1
                                    -
                                    
                                       
                                          
                                             ∏
                                          
                                          
                                             
                                                
                                                   s
                                                
                                                
                                                   t
                                                
                                                
                                                   i
                                                
                                             
                                             ∈
                                             
                                                
                                                   S
                                                
                                                
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    (
                                    1
                                    -
                                    
                                       
                                          s
                                       
                                       
                                          t
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    .
                                 
                              
                           
                        

The terms extracted in the first step are then expanded through association rules. However, unlike (Sigurbjörnsson & van Zwol, 2008), CTTR method does not consider any tag that had been previously assigned to the target object. Towards the purpose of generating term candidates by co-occurrences with terms in the target object, Lipczak et al. (2009) and Lipczak and Milios (2011) distinguish two types of co-occurrence relationships: (1) between tags (
                              
                                 
                                    
                                       R
                                    
                                    
                                       TagToTag
                                    
                                 
                              
                           ) and (2) between terms in the title of an object and its tags (
                              
                                 
                                    
                                       R
                                    
                                    
                                       TitleToTag
                                    
                                 
                              
                           ). In other words, while the antecedents of 
                              
                                 
                                    
                                       R
                                    
                                    
                                       TagToTag
                                    
                                 
                              
                            rules are tags of the training set, the antecedents of 
                              
                                 
                                    
                                       R
                                    
                                    
                                       TitleToTag
                                    
                                 
                              
                            are terms in the titles of objects in it.

In the online recommendation step, the rule sets related to the extracted terms are combined. Title terms are used as antecedent in the following equation to find title-related tags:
                              
                                 (16)
                                 
                                    
                                       
                                          S
                                       
                                       
                                          TitleToTag
                                       
                                    
                                    (
                                    t
                                    ,
                                    o
                                    )
                                    =
                                    1
                                    -
                                    
                                       
                                          
                                             ∏
                                          
                                          
                                             x
                                             ∈
                                             
                                                
                                                   F
                                                
                                                
                                                   o
                                                
                                                
                                                   title
                                                
                                             
                                          
                                       
                                    
                                    (
                                    1
                                    -
                                    θ
                                    (
                                    x
                                    →
                                    t
                                    )
                                    ×
                                    
                                       
                                          p
                                       
                                       
                                          x
                                       
                                       
                                          title
                                       
                                    
                                    )
                                    ,
                                 
                              
                           where 
                              
                                 (
                                 x
                                 →
                                 t
                                 )
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       TitleToTag
                                    
                                 
                              
                           , and 
                              
                                 
                                    
                                       p
                                    
                                    
                                       x
                                    
                                    
                                       title
                                    
                                 
                              
                            is the usage of the title term x as a tag, as defined above. In the same way, the resulting terms of the title-description merge are taken as antecedent in:
                              
                                 (17)
                                 
                                    
                                       
                                          S
                                       
                                       
                                          TagToTag
                                       
                                    
                                    (
                                    t
                                    ,
                                    o
                                    )
                                    =
                                    1
                                    -
                                    
                                       
                                          
                                             ∏
                                          
                                          
                                             x
                                             ∈
                                             
                                                
                                                   ⋃
                                                
                                                
                                                   i
                                                
                                             
                                             
                                                
                                                   F
                                                
                                                
                                                   o
                                                
                                                
                                                   i
                                                
                                             
                                             ∪
                                             
                                                
                                                   I
                                                
                                                
                                                   o
                                                
                                             
                                          
                                       
                                    
                                    (
                                    1
                                    -
                                    θ
                                    (
                                    x
                                    →
                                    t
                                    )
                                    ×
                                    
                                       
                                          s
                                       
                                       
                                          x
                                       
                                    
                                    )
                                    ,
                                 
                              
                           where 
                              
                                 (
                                 x
                                 →
                                 t
                                 )
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       TagToTag
                                    
                                 
                              
                           , and 
                              
                                 
                                    
                                       s
                                    
                                    
                                       x
                                    
                                 
                                 =
                                 merge
                                 (
                                 {
                                 
                                    
                                       p
                                    
                                    
                                       x
                                    
                                    
                                       title
                                    
                                 
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       x
                                    
                                    
                                       description
                                    
                                 
                                 }
                                 )
                              
                            is the score of x achieved after the aforementioned title-description merging step. We note that 
                              
                                 
                                    
                                       s
                                    
                                    
                                       x
                                    
                                 
                              
                            may be interpreted as a relevance metric since it is similar to TS, that is, it captures the importance of a term in the textual features of an object.

At the final step, scores obtained from association rules (
                              
                                 
                                    
                                       S
                                    
                                    
                                       TitleToTag
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       S
                                    
                                    
                                       TagToTag
                                    
                                 
                              
                           ) and from the title and description of the target object are re-scored and merged (with Eqs. (14) and (15)), resulting in the final ranking.

The state-of-the-art personalized tag recommendation method analyzed here is called Pairwise Interactions Tensor Factorization (PITF) (Rendle & Lars, 2010). It was the winner of the graph-based personalized tag recommendation task in the PKDD Discovery Challenge 2009. PITF exploits the vocabulary of the target user expressed by the tags assigned by her to other objects as a representation of her interests and as the main evidence to support personalization.

Briefly, this approach explicitly models the two-way interactions between users, tags and objects by factorizing each of the three as a tensor product. From the set of tag assignments 
                              
                                 P
                              
                           , their approach first infers pairwise ranking constraints. The idea is that, for a given 
                              
                                 〈
                                 user
                                 
                                 u
                                 ,
                                 object
                                 
                                 o
                                 〉
                              
                            pair, one can assume that a tag 
                              
                                 
                                    
                                       t
                                    
                                    
                                       a
                                    
                                 
                              
                            is preferred over another tag 
                              
                                 
                                    
                                       t
                                    
                                    
                                       b
                                    
                                 
                              
                            if and only if 
                              
                                 〈
                                 u
                                 ,
                                 o
                                 ,
                                 
                                    
                                       t
                                    
                                    
                                       a
                                    
                                 
                                 〉
                                 ∈
                                 P
                              
                            and 
                              
                                 〈
                                 u
                                 ,
                                 o
                                 ,
                                 
                                    
                                       t
                                    
                                    
                                       b
                                    
                                 
                                 〉
                                 
                                 ∉
                                 
                                 P
                              
                           . These ranking constraints are then used as training data for a learning algorithm, based on a Bayesian Personalized Ranking (BPR) optimization criterion. This learning method is based on stochastic gradient descent with bootstrap sampling. In other words, the pairwise constraints are sampled from the training data.

PITF has the following parameters: the dimension of factorization 
                              
                                 δ
                              
                           , the number of interactions 
                              
                                 τ
                              
                           , the learning rate for BPR 
                              
                                 λ
                              
                           , and the number of pair samples drawn for each training tuple s.

In previous work (Rendle & Lars, 2010), PITF was only evaluated in denser datasets, that is, datasets in which unpopular users, objects and tags were filtered out. In comparison, all strategies here are evaluated in more realistic scenarios, without this kind of filtering. As we will see in Section 6.5.2, our strategies outperform PITF because we exploit several sources of evidence not exploited by it.

Our new heuristics for object-centered tag recommendation extend the 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                         and LATRE baselines to also include one of the four metrics of descriptive power, i.e., 
                           
                              TF
                              ,
                              TS
                              ,
                              wTF
                           
                         or wTS (Section 4.2). We thus propose eight new ranking functions composed by a weighted linear combination of the output of 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                         (or LATRE) and one of the four metrics. Let DP be the selected descriptive power metric (i.e., 
                           
                              TS
                              ,
                              TF
                              ,
                              wTS
                           
                         or wTF), and c be a candidate tag for a target object o associated with a set of previously assigned tags 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                        . The proposed heuristics have the following general structures:
                           
                              (18)
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                                 ,
                                 α
                                 )
                                 =
                                 α
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 (
                                 c
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                                 )
                                 +
                                 (
                                 1
                                 -
                                 α
                                 )
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 ,
                              
                           
                        
                        
                           
                              (19)
                              
                                 LATRE
                                 +
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 ℓ
                                 ,
                                 α
                                 )
                                 =
                                 α
                                 Sum
                                 (
                                 c
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 ℓ
                                 )
                                 +
                                 (
                                 1
                                 -
                                 α
                                 )
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 )
                                 .
                              
                           
                        
                     

Parameter 
                           
                              α
                           
                         (
                           
                              0
                              ⩽
                              α
                              ⩽
                              1
                           
                        ) is used as a weighting factor. Note that 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                         and Sum are computed only over candidates generated from the association rules, whereas DP is computed for terms extracted from other textual features of target object o.

Our new heuristics for personalized tag recommendation extend the 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                              DP
                           
                         and LATRE
                        +
                        DP (Eqs. (18) and (19)) to also include the user related metric UF (Section 4.5). We thus propose eight new ranking functions composed by a weighted linear combination of the output of 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                              DP
                           
                         (or LATRE
                        +
                        DP) and the value of UF. Let c be a candidate tag for target pair 
                           
                              〈
                              u
                              ,
                              o
                              〉
                           
                        . The proposed heuristics have the following general structures:
                           
                              (20)
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                                 +
                                 UF
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 u
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                                 ,
                                 α
                                 ,
                                 β
                                 )
                                 =
                                 β
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                                 ,
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                                 ,
                                 α
                                 )
                                 +
                                 (
                                 1
                                 -
                                 β
                                 )
                                 UF
                                 (
                                 c
                                 ,
                                 u
                                 )
                                 ,
                              
                           
                        
                        
                           
                              (21)
                              
                                 LATRE
                                 +
                                 DP
                                 +
                                 UF
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 u
                                 ,
                                 ℓ
                                 ,
                                 α
                                 ,
                                 β
                                 )
                                 =
                                 β
                                 LATRE
                                 +
                                 DP
                                 (
                                 c
                                 ,
                                 o
                                 ,
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 ,
                                 ℓ
                                 ,
                                 α
                                 )
                                 +
                                 (
                                 1
                                 -
                                 β
                                 )
                                 UF
                                 (
                                 c
                                 ,
                                 u
                                 )
                                 .
                              
                           
                        
                     

Parameter 
                           
                              β
                           
                         (
                           
                              0
                              ⩽
                              β
                              ⩽
                              1
                           
                        ) is used as a weighting factor. Note that 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                              DP
                           
                         and LATRE
                        +
                        DP are computed only over candidates generated from the association rules and terms extracted from other textual features of target object o, while UF is computed for terms which were assigned as tags by user u in the training set. We note that a candidate tag c generated by co-occurrences or extracted from textual features may not be included in the tag assignment history of the target user (personomy). In this case, we set 
                           
                              UF
                              (
                              c
                              ,
                              u
                              )
                              =
                              0
                           
                        . Similarly, a candidate tag extracted from the user’s personomy may not be in any textual feature of the target object o, presenting value 0 for its descriptive power metrics (DP).

Additionally, we propose variants of these two sets of heuristics, defined by the same, Eqs. (20) and (21), but differing in the training set used. While 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                              DP
                              +
                              UF
                           
                         and LATRE
                        +
                        DP
                        +
                        UF exploit co-occurrences between tags assigned to objects by different users (training set 
                           
                              D
                           
                         defined in Section 3), the two variants, referred to here as 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    u
                                 
                                 
                                    +
                                 
                              
                              DP
                              +
                              UF
                           
                         and 
                           
                              
                                 
                                    LATRE
                                 
                                 
                                    u
                                 
                              
                              +
                              DP
                              +
                              UF
                           
                        , exploit co-occurrences between tags assigned to the same object by only one user (training set 
                           
                              
                                 
                                    D
                                 
                                 
                                    ′
                                 
                              
                           
                        , defined in Section 3).

We here investigate the potential benefits of applying L2R techniques to the tag recommendation problem. The basic idea is to use such algorithms to “learn” a good ranking function based on a list 
                           
                              
                                 
                                    L
                                 
                                 
                                    attr
                                 
                              
                           
                         of metrics of tag relevance used as attributes. We here consider three different L2R techniques: the traditional RankSVM method (Section 5.3.1), the Genetic Programming (GP) framework (Section 5.3.2), and the Random Forest algorithm (Section 5.3.3). We chose these L2R methods since they represent three different learning paradigms that have been successfully applied to other IR tasks such as classification, search/ranking and image retrieval (Gomes et al., 2013; Faria et al., 2010; Yeh, Lin, Ke, & Yang, 2007).

We start by focusing on how we apply these techniques to the object-centered tag recommendation task, discussing extensions to address personalization in Section 5.3.4. For object-centered tag recommendation, the list of attributes 
                           
                              
                                 
                                    L
                                 
                                 
                                    attr
                                 
                              
                           
                         exploited by all three L2R methods, shown in Table 2
                         (2nd column) includes: 
                           
                              Sum
                              ,
                              Vote
                              ,
                              
                                 
                                    Vote
                                 
                                 
                                    +
                                 
                              
                              ,
                              IFF
                              ,
                              Stab
                              ,
                              TS
                              ,
                              TF
                              ,
                              wTS
                              ,
                              wTF
                              ,
                              
                                 
                                    H
                                 
                                 
                                    tags
                                 
                              
                              ,
                              Pred
                           
                         and 
                           
                              
                                 
                                    Sum
                                 
                                 
                                    +
                                 
                              
                           
                        , defined in Eqs. (1)–(11). In particular, we include Sum with both 
                           
                              ℓ
                              =
                              1
                           
                         and 
                           
                              ℓ
                              =
                              3
                           
                        , thus generating two attributes for this metric. Moreover, the set of candidate tags 
                           
                              
                                 
                                    C
                                 
                                 
                                    o
                                 
                              
                           
                         for each object o includes all terms generated by LATRE and all terms extracted from other textual features. For each candidate 
                           
                              c
                              ∈
                              
                                 
                                    C
                                 
                                 
                                    o
                                 
                              
                           
                        , for each object o, we compute all attributes in 
                           
                              
                                 
                                    L
                                 
                                 
                                    attr
                                 
                              
                           
                         using the training set 
                           
                              D
                           
                         (e.g., for 
                           
                              Stab
                              ,
                              IFF
                           
                        ) and the textual features associated with o. Each candidate c is then represented by a vector of attribute values 
                           
                              
                                 
                                    M
                                 
                                 
                                    c
                                 
                              
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    m
                                 
                              
                           
                        , where m is the number of considered attributes (
                           
                              m
                              =
                              13
                           
                         for object-centered tag recommendation). We also assign a binary label 
                           
                              
                                 
                                    y
                                 
                                 
                                    c
                                 
                              
                           
                         to each candidate c for each object v in validation set 
                           
                              V
                           
                        , indicating whether c is a relevant recommendation for v (
                           
                              
                                 
                                    y
                                 
                                 
                                    c
                                 
                              
                              =
                              1
                           
                        ) or not (
                           
                              
                                 
                                    y
                                 
                                 
                                    c
                                 
                              
                              =
                              0
                           
                        ), based on the contents of 
                           
                              
                                 
                                    Y
                                 
                                 
                                    v
                                 
                              
                           
                        . Note that we use training set 
                           
                              D
                           
                         only to extract the association rules and to compute the attribute values, relying on validation set 
                           
                              V
                           
                         to learn the solutions.

RankSVM is based on the state-of-the-art Support Vector Machine (SVM) classification method (Joachims, 2006). We use the SVM-rank tool
                              9
                              
                                 http://www.cs.cornell.edu/People/tj/svm_light/svm_rank.html.
                           
                           
                              9
                            to learn a function 
                              
                                 f
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 )
                                 =
                                 f
                                 (
                                 W
                                 ,
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 )
                              
                           , where 
                              
                                 W
                                 =
                                 〈
                                 
                                    
                                       w
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       w
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       w
                                    
                                    
                                       m
                                    
                                 
                                 〉
                              
                            is a vector of weights associated with the considered attributes (i.e., 
                              
                                 W
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       m
                                    
                                 
                              
                           ). W is learned by a maximum-margin optimization method that tries to find a hyperplane, defined by W, that best separates the “closest” candidate tags (represented by their attribute vectors in 
                              
                                 
                                    
                                       R
                                    
                                    
                                       m
                                    
                                 
                              
                           ) belonging to two different levels of relevance (i.e., relevant and irrelevant) assigned to each object-candidate pair in the training set. They are employed to produce ranking statements (i.e., relevant tags must precede irrelevant ones), which in turn are used as input to the RankSVM learning process.

At recommendation time, 
                              
                                 f
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 )
                              
                            is used to rank all candidates for target object o according to the their relative distances to the separating hyperplane.

RankSVM has two main parameters, namely, the type of kernel function, which indicates the structure of the solution function, and cost j, which controls the penalty given to classification errors in the training process. Section 6.4 describes how we choose the best values for these parameters.

RankSVM is still a very competitive performer when considering average results across all collections in the LETOR 3.0 L2R benchmark,
                              10
                              
                                 http://research.microsoft.com/en-us/um/beijing/projects/letor/.
                           
                           
                              10
                            besides being readily available for experimentation, unlike other methods that are proprietary. Moreover, we also note that we found RankSVM to be statistically tied (if not superior) to the recently proposed FocusedSVM method (Niu et al., 2012), which combines both RankSVM with a listwise SVM approach that directly optimizes mean average precision, targeting the top-k positions of the ranking. Indeed, we have implemented and evaluated FocusedSVM for object-centered and personalized tag recommendation, finding that it produces results that are not statistically superior to those produced by RankSVM in any of our datasets. We conjecture that this is because our training data distinguishes candidate tags in only two levels of relevance (relevant and irrelevant), while the suggested method relies on a larger number of distinct levels of relevance, focusing on the highest positions of the ranking.
                              11
                              We do not present the results of FocusedSVM in Section 6 to avoid hurting presentation and paper readability with too many results.
                           
                           
                              11
                           
                        

We apply GP to find a good ranking function 
                              
                                 f
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 )
                              
                            for tagging recommendation purposes. This is done through the evolution of a population in which each individual represents a different ranking function. This evolution is inspired on the biological mechanisms of natural selection and survival of the “strongest” or most “adapted” individuals. In the following, we provide an overview of the GP framework, and introduce how we model the tag recommendation problem with it.

Genetic Programming (GP) implements a global search mechanism. A GP algorithm evolves a population of tree-represented individuals (i.e., the solutions for the problem at hand), created from a set of terminals and functions related to the target problem. In each generation of the evolutionary process, individuals are evaluated according to a specific quality metric, calculated by a Fitness function. That is, the Fitness value is used as a criterion to select the best individuals, which will transmit their characteristics to the future generations through operations like crossover and mutation. We here implement the tournament selection method, which randomly chooses, with replacement, k individuals from the population and takes the one with highest Fitness value.

While the number of new individuals is smaller than the desired population size n, two individuals are picked through the adopted selection method, and, with probability 
                                 
                                    
                                       
                                          p
                                       
                                       
                                          c
                                       
                                    
                                 
                              , have their “genetic material” exchanged in the crossover operation to generate a new individual. That is, we randomly choose one node of each of the two trees (the two individuals) and exchange the subtrees below them. The role of the crossover operation is to combine good solutions towards the most promising solutions in the search space. Moreover, with probability 
                                 
                                    
                                       
                                          p
                                       
                                       
                                          m
                                       
                                    
                                 
                              , the mutation operation is performed to introduce new individuals (i.e., solutions) in the population, increasing its diversity. This is useful, for example, to avoid that the whole evolutionary process gets trapped in local minima during the search process. Here, the mutation of an individual (i.e., a tree) is performed by first randomly selecting one of its nodes, and then replacing it (and its corresponding subtree) by a new randomly generated subtree, without exceeding a maximum tree depth d.

The whole process, depicted in Fig. 2
                              , is repeated until a target Fitness value 
                                 
                                    
                                       
                                          f
                                       
                                       
                                          target
                                       
                                    
                                 
                               or a maximum number of generations g is reached. At the end, the individual with best fitness value, which usually belongs to the last generation in the evolutionary process, is chosen as the final solution for the problem.

GP is an effective non-linear method that has been successfully employed when there is a large search space and a goal to be optimized, having produced results close to the optimal in many applications (Banzhaf et al., 1998). Indeed, GP has been applied to various Information Retrieval tasks such as classification, search/ranking and image retrieval (e.g., Yeh et al., 2007). However, to our knowledge, we were the first to apply it to tag recommendation (Belém et al., 2011). Our motivations were twofold. First, in comparison with RankSVM, GP exploits a different learning paradigm, which directly optimizes a target function (e.g., recommendation precision). Second, GP has been demonstrated to be competitive with other learning-to-rank techniques such as RankSVM itself and RankBoost (Freund, Iyer, Schapire, & Singer, 2003; Yeh et al., 2007).
                                 12
                                 In some initial tests with RankBoost and with an associative method for learning-to-rank (Veloso, Almeida, Gonçalves, & Meira, 2008), we found them to be very inefficient to train for the size of our collections.
                              
                              
                                 12
                               As we shall see, GP outperforms RankSVM in a few scenarios, being statistically tied with it in many others.

To apply GP to tag recommendation, we need to define the tree representation of an individual, which, in our case, is a tag ranking function, and a Fitness function. A tree is composed of terminals (leaves) and non-terminals (internal nodes). We choose the sum (
                                 
                                    +
                                 
                              ), subtraction (
                                 
                                    -
                                 
                              ), multiplication (
                                 
                                    ×
                                 
                              ), division (
                                 
                                    /
                                 
                              ) and natural logarithm (ln) operations as non-terminals. To ensure the closure property, we implement protected division and logarithm, such that these operators return the default value 0 when their inputs are out of their domains. The terminals are composed of variables and constants (uniformly distributed between 0 and 1). The variable set includes the (values of the) attributes in the given 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          attr
                                       
                                    
                                 
                               list, which, for a candidate c, is given by vector 
                                 
                                    
                                       
                                          M
                                       
                                       
                                          c
                                       
                                    
                                 
                              . Fig. 3
                               shows an example of a possible tree and its corresponding function.

The Fitness of an individual in this context represents the quality of the recommendations produced by the corresponding ranking function. We here assess the quality of a ranking function in terms of the precision of the top-k terms in the ranking of recommended terms (p@k).
                                 13
                                 We also experimented with other Fitness functions (e.g., NDCG), obtaining similar results.
                              
                              
                                 13
                               Let Y be the set of relevant tags to recommend for object o (
                                 
                                    Y
                                    =
                                    
                                       
                                          Y
                                       
                                       
                                          o
                                       
                                    
                                 
                              ), or for the object-user 
                                 
                                    〈
                                    o
                                    ,
                                    u
                                    〉
                                 
                               pair (
                                 
                                    Y
                                    =
                                    
                                       
                                          Y
                                       
                                       
                                          o
                                          ,
                                          u
                                       
                                    
                                 
                              ). Let C be the sorted set of recommendations produced by the GP-generated function being evaluated, and 
                                 
                                    
                                       
                                          C
                                       
                                       
                                          k
                                       
                                    
                                 
                               the top k elements in C. The precision in the top-k positions, 
                                 
                                    p
                                    @
                                    k
                                 
                              , is defined as:
                                 
                                    (22)
                                    
                                       p
                                       @
                                       k
                                       (
                                       C
                                       ,
                                       Y
                                       )
                                       =
                                       
                                          
                                             |
                                             
                                                
                                                   C
                                                
                                                
                                                   k
                                                
                                             
                                             ∩
                                             Y
                                             |
                                          
                                          
                                             min
                                             (
                                             k
                                             ,
                                             |
                                             Y
                                             |
                                             )
                                          
                                       
                                       .
                                    
                                 
                              
                           

The min operator guarantees that the denominator does not exceed 
                                 
                                    |
                                    Y
                                    |
                                 
                              , which is important because the number of available relevant tags in the expected answer Y may be less than k.

The Fitness (i.e., quality) of ranking function 
                                 
                                    f
                                    (
                                    
                                       
                                          M
                                       
                                       
                                          c
                                       
                                    
                                    )
                                 
                               is then computed as the average 
                                 
                                    p
                                    @
                                    k
                                 
                               over all recommendations produced by 
                                 
                                    f
                                    (
                                    
                                       
                                          M
                                       
                                       
                                          c
                                       
                                    
                                    )
                                 
                               in a sample of objects of size s, extracted from the validation set 
                                 
                                    V
                                 
                              .

The Random Forest (RF) algorithm (Breiman, 2001) is an ensemble method that combines a collection of decision trees. Each decision tree is “learned” in a recursive way: first, the most discriminative attribute (according to some measure, such as Information Gain) is selected as a decision node. The selected candidate tags are split according to a split value (e.g., average attribute value), and the process repeats in a top-down fashion to form a tree with l terminal nodes, where l is a tuning parameter. Once the decision tree is built, it can assign a real-valued score as output to an unseen (test) candidate tag.

The RF method exploits the bagging ensemble technique, that is, each tree within the forest is built with a different bootstrap sample drawn from the original set of pairs 
                              
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       c
                                    
                                 
                                 )
                              
                            that represents each candidate tag c for the considered objects in our dataset, where, as discussed before, 
                              
                                 
                                    
                                       M
                                    
                                    
                                       c
                                    
                                 
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       m
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       y
                                    
                                    
                                       c
                                    
                                 
                                 ∈
                                 {
                                 0
                                 ,
                                 1
                                 }
                              
                           . The attribute selection for each split in a tree is conducted on a randomly selected subset of attributes, instead of on the full attribute set, as usually done in traditional decision tree algorithms. Each leaf in each tree corresponds to an output score to be assigned to a candidate tag. Once the forest is built, for each tag candidate c in a target object o, the scores given by each tree to c are averaged and used to produce the final ranking of candidates.

Besides l, the number T of trees (in each bootstrap sample) to grow, and the number of attributes n to consider when splitting each node are tuning parameters in RF. We note that, although each decision tree may suffer from overfitting, the aggregation of a larger number of low-correlated trees can mitigate this problem. The generalization error of a RF depends on both the correlation between trees in the forest and the strength of each individual tree. The more correlated each tree is, the higher the error rate becomes. The stronger each individual tree is (high accuracy), the lower the error rate becomes. By increasing n or lowering l, both the correlation and the strength of each tree increases. By lowering n or increasing l, each tree becomes more independent (less correlated), but also weaker. Thus, there exists some optimal values of n and l that provide the optimal balance between the correlation and the strength to get the minimum generalization error. We set those parameters using the validation set, as described in Section 6.4. The implementation of RF is provided by the RankLib learning to rank tool.
                              14
                              
                                 http://people.cs.umass.edu/vdang/ranklib.html.
                           
                           
                              14
                           
                        

RF has been shown consistently effective and competitive in several real world benchmarks (Mohan, Chen, & Weinberger, 2011). Some of its strengths are its insensitivity to parameter choices, resilience to overfitting, and high degree of parallelization due the fact that single decision trees are built independently from others, thus making RFs inherently parallel.

The L2R-based strategies described in Sections 5.3.1–5.3.3 can be easily extended to include new relevance metrics. In particular, in order to extend them to address personalized recommendations, we included the metric UF in the list 
                              
                                 
                                    
                                       L
                                    
                                    
                                       attr
                                    
                                 
                              
                            of attributes. The complete list of attributes is shown in Table 2 (3rd column). Recall that, for personalized tag recommendations, each co-occurrence metric presents two variations, depending on whether the training data used is separated per user or not. Thus, we adopted the best performing version when they are used as heuristics.
                              15
                              For example, LATRE
                                 +
                                 wTS
                                 +
                                 UF performs better than 
                                    
                                       
                                          
                                             LATRE
                                          
                                          
                                             u
                                          
                                       
                                    
                                 
                                 +
                                 wTS
                                 +
                                 UF, while 
                                    
                                       
                                          
                                             Sum
                                          
                                          
                                             u
                                          
                                          
                                             +
                                          
                                       
                                       wTS
                                       +
                                       UF
                                    
                                  is better than 
                                    
                                       
                                          
                                             Sum
                                          
                                          
                                             +
                                          
                                       
                                       wTS
                                       +
                                       UF
                                    
                                 . Thus, we include 
                                    
                                       Sum
                                       (
                                       l
                                       =
                                       3
                                       )
                                    
                                  (component of LATRE
                                 +
                                 wTS
                                 +
                                 UF) and 
                                    
                                       
                                          
                                             Sum
                                          
                                          
                                             u
                                          
                                       
                                       (
                                       l
                                       =
                                       1
                                       )
                                    
                                  (component of 
                                    
                                       
                                          
                                             Sum
                                          
                                          
                                             +
                                          
                                       
                                       wTS
                                       +
                                       UF
                                    
                                 ) as attributes of 
                                    
                                       
                                          
                                             L
                                          
                                          
                                             attr
                                          
                                       
                                    
                                 . An alternative would be to include both variations as attributes, but we opted for a smaller set of less redundant attributes.
                           
                           
                              15
                            Besides that, all tags assigned by the target user to objects in the training set 
                              
                                 D
                              
                            were included as candidates. That is, the candidate set 
                              
                                 
                                    
                                       C
                                    
                                    
                                       o
                                       ,
                                       u
                                    
                                 
                              
                            for a given object-user pair 
                              
                                 〈
                              
                           
                           
                              
                                 o
                                 ,
                                 u
                              
                           
                           
                              
                                 〉
                              
                            includes all terms generated by LATRE, all terms extracted from other textual features in o, and all terms assigned as tags by user u in the training set 
                              
                                 D
                              
                           . For each candidate 
                              
                                 c
                                 ∈
                                 
                                    
                                       C
                                    
                                    
                                       o
                                       ,
                                       u
                                    
                                 
                              
                           , we compute the values of all attributes in 
                              
                                 
                                    
                                       L
                                    
                                    
                                       attr
                                    
                                 
                              
                            using 
                              
                                 D
                              
                            and the textual features associated with o.

Thus, the algorithms for personalized tag recommendation are the same as those described in the previous sections, except for the additional candidates and slightly different set of attributes. We argue that these methods perform well for both personalized and object-centered recommendation because they are flexible and robust strategies to generate relevant recommendation to the target object and to the target object-user pair, as we will discuss in Section 6.5.2.1. In particular, our methods can provide relevant recommendations to a user even when she does not have a history of tag assignments. In that case, the extraction of candidates from tag co-occurrences and multiple textual features provide more general recommendations to the considered object, which may be relevant to any user.
                              16
                              Alternatively, in the absence of tag assignment history, recommendation strategies based on collaborative filtering (Jäschke et al., 2007) could be applied.
                           
                           
                              16
                            As the user becomes more active, however, our methods can provide a higher level of personalization, thanks to the use of the UF metric.


                           Table 3
                            lists all analyzed tag recommendation methods, while Table 4
                            summarizes key characteristics of the different techniques employed in our L2R-based methods.

In this section, we first present the datasets used to evaluate the tag recommendation strategies (Section 6.1) as well as our evaluation methodology (Section 6.2) and metrics (Section 6.3). Next, we describe how we parameterized each strategy (Section 6.4), and discuss a set of representative results (Section 6.5).

We evaluate the tag recommendation methods on four datasets, each containing the title, tags and description associated with real objects from Bibsonomy, LastFM, YouTube and YahooVideo. The Bibsonomy, LastFM and YouTube datasets also include the set of tag assignments (
                           
                              P
                           
                        ),
                           17
                           On YouTube, only the video owner can assign tags to it.
                        
                        
                           17
                         thus allowing the evaluation of object-centered and personalized tag recommendation methods. The YahooVideo dataset, in contrast, does not identify the user who assigned each tag, and thus is here used only in the evaluation of object-centered methods.

The Bibsonomy dataset is a recent snapshot of the system, obtained on January 1st 2012, comprising 543,872 objects (bibtex records of publications). It is publicly available,
                           18
                           
                              http://www.kde.cs.uni-kassel.de/bibsonomy/dumps.
                        
                        
                           18
                         and has been used in several previous efforts (Guan et al., 2009; Lipczak & Milios, 2011; Lipczak et al., 2009; Rendle & Lars, 2010). The LastFM and YouTube datasets
                           19
                           Visit http://vod.dcc.ufmg.br/recc/ for information on data availability.
                        
                        
                           19
                         were collected in August 2009, following a snowball sampling. That is, starting from a set of users (the most popular users) selected as seeds, the crawler recursively collects the objects posted by them and follows their social links to other users, collecting the objects posted by them. Our datasets include the textual features and tag assignments associated with 2,758,992 LastFM artists and with more than 9 million YouTube videos. The YahooVideo dataset was also gathered by snowball sampling, but using the most popular objects as seeds and following links of related videos.
                           20
                           We adopted a slightly different sampling strategy for LastFM and YouTube, exploiting users and social links as opposed to videos and related video links, as we use the collected datasets to evaluate personalized recommendation strategies. As YahooVideo does not publish per-user information on tag assignment, we chose not to crawl that application again, thus relying on our previously gathered dataset and evaluating it only for object-centered recommendation.
                        
                        
                           20
                         It was gathered in October 2008, and contains the features of 160,228 objects.

We considered only objects with textual features in English, and used the Porter Stemming algorithm
                           21
                           
                              http://tartarus.org/martin/PorterStemmer/.
                        
                        
                           21
                         to remove the affixes of each word in each collected feature. Stemming was performed to avoid trivial recommendations such as plurals and other simple variations of the same word. We also removed stopwords, as well as terms that are either too frequent (with more than 100,000 occurrences in the dataset) or too rare (with fewer than 30 occurrences), as such terms are hardly good recommendations
                           22
                           We note that the Stab metric also helps eliminating potentially noisy recommendations. However, we chose to explicitly remove terms that are either too frequent or too rare to be fair with some of the baselines, such as LATRE, its extensions and PITF, which do not exploit the 
                                 
                                    Stab
                                    (
                                    )
                                 
                               metric, and thus are more susceptible to recommend this kind of noise.
                        
                        
                           22
                         (Sigurbjörnsson & van Zwol, 2008).

We adopted a fully automatic evaluation methodology that has been used by most prior studies on tag recommendation (Heymann et al., 2008; Gemmell, Schimoler, Mobasher, & Burke, 2010; Lipczak et al., 2009; Lipczak & Milios, 2011; Menezes et al., 2010; Rendle, Balby Marinho, Nanopoulos, & Schmidt-Thieme, 2009), including personalized tag recommendation (Guan et al., 2009; Garg & Weber, 2008; Rendle & Lars, 2010), as well as content recommendation in general (Guy et al., 2010; Zhang, Séaghdha, Quercia, & Jambor, 2012). It consists of using a subset of the object’s pre-assigned tags as an expected answer, that is, as the relevant tags for that object. For personalized tag recommendation, specifically, a subset of the tags assigned by the target user to the target object is used as expected answer.

Following the proposed methodology, for object-centered recommendation, for each object o in the test and validation sets, we randomly select half of its tags to be included in 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                        . The other half are included in 
                           
                              
                                 
                                    Y
                                 
                                 
                                    o
                                 
                              
                           
                        , the expected answer for o. Similarly, for personalized tag recommendation, for each object o in the test and validation sets, half of the tags assigned by the target user u to the object o are included in 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                         and the other half in 
                           
                              
                                 
                                    Y
                                 
                                 
                                    o
                                    ,
                                    u
                                 
                              
                           
                        . Tags assigned by other users to object o (i.e., 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                    ,
                                    
                                       
                                          u
                                       
                                       
                                          ′
                                       
                                    
                                 
                              
                           
                         for 
                           
                              
                                 
                                    u
                                 
                                 
                                    ′
                                 
                              
                              
                              ≠
                              
                              u
                           
                        ) are also used as input, being included in 
                           
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                           
                        . In both cases, we use title and description as textual features in 
                           
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                              
                           
                        . Each object is thus represented by tuple 
                           
                              〈
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                              ,
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                              
                              ,
                              
                                 
                                    Y
                                 
                                 
                                    o
                                 
                              
                              〉
                           
                         for object-centered recommendation, or 
                           
                              〈
                              
                                 
                                    I
                                 
                                 
                                    o
                                 
                              
                              ,
                              
                                 
                                    F
                                 
                                 
                                    o
                                 
                              
                              ,
                              
                                 
                                    Y
                                 
                                 
                                    o
                                    ,
                                    u
                                 
                              
                              〉
                           
                         for personalized recommendation.

We note that the tags in the expected answer for an object o are not exploited, in any way, to produce the recommendations for o (i.e., they are not used neither for metric computation nor for learning the recommendation function). Thus, from the perspective of the evaluation being performed, these tags are effectively new. This methodology allows us to simulate a scenario where these tags have not been assigned to the object yet and, thus, are potential candidates for new recommendations. Moreover, these tags can be considered relevant as we know that one or multiple users actually used them to annotate the object.

Alternative evaluation methodologies would rely on manual assessment of the tag recommendations by either: (1) real users of the system under study, who created the objects for which tags are recommended and/or have already added some tags to them, or (2) external volunteers. Whereas the former would be desirable, it is extremely hard to perform, particularly when covering different systems and a large number of different methods, as we do here.
                           23
                           We here compare 18 object-centered and personalized tag recommendation methods proposed by us as well as 4 baselines.
                        
                        
                           23
                         In fact, to our knowledge, no previous work on tag recommendation relied on evaluations by real users of the target system, perhaps due to the aforementioned difficulties to perform it in large scale or even in small scale, as it requires implementing a live recommender system to be used by real users.

In contrast, while the vast majority of prior studies adopted the automatic approach we used here, some prior efforts (Bi & Cho, 2013; Prokofyev et al., 2012; Siersdorfer et al., 2009; Sigurbjörnsson & van Zwol, 2008; Wu et al., 2009) used external volunteers to evaluate the recommendations. However, we argue that this approach is not necessarily better than the automatic one. Indeed, in the case of personalized tag recommendations, this approach may not be adequate at all, as the external evaluations might introduce significant biases and inaccuracies to the evaluation which would be very hard to isolate,
                           24
                           A tag that could be extremely meaningful to a particular user could be considered completely irrelevant by an evaluation with a different perception of the object’s content.
                        
                        
                           24
                         possibly invalidating the analyses. To the best of our knowledge, all previous studies on personalized tag recommendations adopted the same automatic evaluation approach used here, i.e., none relied on manual evaluations.

The few prior efforts that relied on manual evaluation focused on object-centered recommendation. In that context, the user bias might be less critical. However, it still exists. The extent at which it impacts the evaluations is not clear and might be non-negligible: if external evaluators are not very familiar with the topic of the object, their evaluations might have a significant impact on the results. In order to minimize this possible impact, a very large number of evaluators might be needed to produce results with statistical significance, thus greatly increasing the costs. In contrast, the automatic evaluation approach is much cheaper and scalable to large experiments. Moreover, we argue that, in a sense, the automatic evaluation is simulating a manual evaluation in which the evaluator is the object’s owner herself, an “ideal” evaluator.

All in all, we have adopted the automatic strategy, which is a well-established and widely adopted evaluation protocol in the area, in favor of a more extensive quantitative evaluation. This choice allowed us to cover a large number of methods and datasets, enabling us to draw solid conclusions from statistically significant results.

To apply the selected methodology, we sampled 150,000 objects from each dataset (120,000 for YahooVideo). Each sample was divided into five equal-sized portions, which were used in a fivefold cross validation. That is, three portions were treated as training set (
                           
                              D
                           
                        ), which was used for extracting association rules and computing all metrics. A fourth portion was used as validation set 
                           
                              V
                           
                        , which, in turn, was considered a part of the training set, being used to “learn” the solutions (that is, to compute the Fitness function in the GP evolutionary process as well as learn vector W in RankSVM and the forest of regression trees in RF), and to tune parameters of all recommendation methods (including the RankSVM and RF-based strategies, using cross-validation in 
                           
                              V
                           
                        ). The last portion was used for testing. Note that, our use of the 5-fold cross-validation process for the three L2R-based strategies is slightly different from the traditional use: we learn the ranking function and select parameter values in the validation set 
                           
                              V
                           
                        . We do so to avoid overfitting, which could occur if the solutions were learned in the same set from which association rules and metrics were extracted (i.e., training set 
                           
                              D
                           
                        ), as metrics derived from the rules could be over-inflated.
                           25
                           We did observe this overfitting problem in initial tests, with the learned solutions having lower generalization capabilities.
                        
                        
                           25
                        
                     

We argue that our experimental design is fair because: (1) we do not use any privileged information from the test set in which results of all methods are reported; (2) all parameters are discovered in the same validation set; (3) our collections are large enough for effective learning; and (4) the very tight confidence intervals reported in our results (Section 6.5) are evidence of low variation and thus learning convergence. Moreover, having a large amount of training data to generate the tag co-occurrence rules can help increasing the coverage of the rules (i.e., more co-occurrences can be potentially found), thus generating more candidates and more precise metric values. This benefits all methods.

We now present the metrics used to evaluate the quality of the recommendations produced by all considered tag recommendation methods. They are also used by the GP framework, whose search process tries to directly maximize the considered evaluation metric, as described in Section 5.3.2.

Our primary metric is 
                           
                              p
                              @
                              k
                           
                        , defined in Section 5.3.2.2 (Eq. 22), with k
                        =5.
                           26
                           We also exploit 
                                 
                                    p
                                    @
                                    k
                                 
                               as objective function in GP framework and as criterion to tune parameters. Using the other evaluation metrics to tune parameters led to the same parameter choices.
                        
                        
                           26
                         However, we also measured the recall and the Normalized Discounted Cumulative Gain (NDCG) in the first 
                           
                              k
                              =
                              5
                           
                         recommendations,
                           27
                           We note that qualitative similar results of precision, recall and NDCG were also obtained for larger values of k.
                        
                        
                           27
                         as well as the Mean Reciprocal Rank (MRR) of the recommendations. Recall is the fraction of the set of relevant tags for an object that were indeed recommended, whereas NDCG considers the order in which tags are recommended, emphasizing ranking relevant tags higher (Baeza-Yates & Ribeiro-Neto, 2011). MRR, in turn, measures where, on average, the first relevant recommendation appears in the ranking (Sigurbjörnsson & van Zwol, 2008). Thus, jointly, these four metrics provide complementary views and a more complete picture of the results.

Specifically, let Y be the set of relevant tags for object o (
                           
                              Y
                              =
                              
                                 
                                    Y
                                 
                                 
                                    o
                                 
                              
                           
                        ), or, in the case of personalized recommendations, for the object-user pair 
                           
                              〈
                              o
                              ,
                              u
                              〉
                           
                         (
                           
                              Y
                              =
                              
                                 
                                    Y
                                 
                                 
                                    o
                                    ,
                                    u
                                 
                              
                           
                        ). Let C be the sorted set of recommendations generated by the method being evaluated, 
                           
                              
                                 
                                    C
                                 
                                 
                                    k
                                 
                              
                           
                         the top k elements in C, and 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                              
                           
                         the ith element in C. Recall in the first k positions of the ranking is defined as:
                           
                              (23)
                              
                                 Recall
                                 @
                                 k
                                 (
                                 C
                                 ,
                                 Y
                                 )
                                 =
                                 
                                    
                                       |
                                       
                                          
                                             C
                                          
                                          
                                             k
                                          
                                       
                                       ∩
                                       Y
                                       |
                                    
                                    
                                       |
                                       Y
                                       |
                                    
                                 
                                 .
                              
                           
                        
                     

Let 
                           
                              DCG
                              @
                              k
                           
                         be the discounted cumulative gain in the first k recommendations, defined as:
                           
                              (24)
                              
                                 DCG
                                 @
                                 k
                                 (
                                 C
                                 ,
                                 Y
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       rel
                                       (
                                       i
                                       )
                                    
                                    
                                       
                                          
                                             log
                                          
                                          
                                             2
                                          
                                       
                                       (
                                       i
                                       +
                                       1
                                       )
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              rel
                              (
                              i
                              )
                           
                         is equal to 1 if the ith candidate returned in C is relevant (i.e., it is in Y), and 0 otherwise. The normalized discounted cumulative gain in the first k recommendations, 
                           
                              NDCG
                              @
                              k
                           
                        , is defined as:
                           
                              (25)
                              
                                 NDCG
                                 @
                                 k
                                 (
                                 C
                                 ,
                                 Y
                                 )
                                 =
                                 
                                    
                                       DCG
                                       @
                                       k
                                       (
                                       C
                                       ,
                                       Y
                                       )
                                    
                                    
                                       IdealDCG
                                       @
                                       k
                                    
                                 
                                 ,
                              
                           
                        where IdealDCG is the value obtained for 
                           
                              DCG
                              @
                              k
                           
                         when there are only relevant candidates at the top-k (or fewer) positions.

Finally, MRR is defined as:
                           
                              (26)
                              
                                 MRR
                                 (
                                 C
                                 ,
                                 Y
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         1
                                                      
                                                      
                                                         r
                                                         (
                                                         C
                                                         ,
                                                         Y
                                                         )
                                                      
                                                   
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   ∃
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   
                                                   such
                                                   
                                                   that
                                                   
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ∈
                                                   Y
                                                   ,
                                                
                                             
                                             
                                                
                                                   0
                                                   ,
                                                
                                                
                                                   otherwise
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              r
                              (
                              C
                              ,
                              Y
                              )
                           
                         is the first position of the ranking where a relevant candidate appears, that is, 
                           
                              r
                              (
                              C
                              ,
                              Y
                              )
                              =
                              
                                 
                                    min
                                 
                                 
                                    1
                                    ⩽
                                    i
                                    ⩽
                                    |
                                    C
                                    |
                                 
                              
                              
                              i
                           
                         such that 
                           
                              
                                 
                                    C
                                 
                                 
                                    i
                                 
                              
                              ∈
                              Y
                           
                        .

Our evaluation starts with a series of experiments with the validation set 
                           
                              V
                           
                         to determine the best parameter values for each method in each dataset. The best choice was defined as the one that maximizes precision (i.e., 
                           
                              p
                              @
                              k
                           
                         for k
                        =5) in the validation set, although the values remain the same if any of the other considered evaluation metrics are maximized. We summarize the parameterization of the object-centered and personalized tag recommendation strategies in Sections 6.4.1 and 6.4.2, respectively.

We found that, for both 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                              
                            (for DP equal to 
                              
                                 TS
                                 ,
                                 TF
                                 ,
                                 wTS
                              
                            and wTF), the best parameter values are 
                              
                                 
                                    
                                       k
                                    
                                    
                                       r
                                    
                                 
                                 =
                                 
                                    
                                       k
                                    
                                    
                                       x
                                    
                                 
                                 =
                                 
                                    
                                       k
                                    
                                    
                                       c
                                    
                                 
                                 =
                                 5
                              
                           . We also set 
                              
                                 
                                    
                                       k
                                    
                                    
                                       s
                                    
                                 
                              
                           , parameter of the Stab metric, equal to 5. We tested these parameters sequentially for values equal to 1, 5, 10, 20 and 50. Best results for 
                              
                                 α
                              
                            varied between 
                              
                                 0.8
                              
                            and 
                              
                                 0.99
                              
                           , depending on the dataset. For both LATRE and LATRE
                           +
                           DP (as well as for the L2R-based strategies), we set 
                              
                                 ℓ
                                 =
                                 3
                              
                           , as in Menezes et al. (2010). Parameters 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                              
                            directly impact the number of association rules generated, thus affecting the processing time of the recommender. We searched for a good tradeoff between processing time and recommendation precision. The lower 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                              
                            (or 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                              
                           ), the larger the number of rules, thus, the longer the processing time. In general, precision decreases as 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                              
                            increase. Thus, we chose 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                              
                            so that the precision loss, with respect to results for 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                                 =
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                                 =
                                 0
                              
                           , is under 3%.

We now turn to the parameterization of the L2R object-centered tag recommendation methods. For the RankSVM based strategy, we tested two kernel functions, namely linear and radial basis function (RBF), choosing the former, as it led to better results more efficiently. Using cross-validation in 
                              
                                 V
                              
                           , we also varied the cost parameter j between 
                              
                                 
                                    
                                       10
                                    
                                    
                                       -
                                       3
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       10
                                    
                                    
                                       3
                                    
                                 
                              
                           , finding that the best choice was j
                           =100 for all datasets.

For the GP based strategy, we experimented with population sizes n equal to 
                              
                                 50
                                 ,
                                 100
                                 ,
                                 200
                              
                            and 500, selecting n
                           =200, as we did not observe improvements for larger values. For this population size, the algorithm converges (i.e., the values of Fitness stop improving) before 200 generations, value assigned to g. We fixed k
                           =2, and set 
                              
                                 d
                                 =
                                 7
                                 ,
                                 
                                    
                                       p
                                    
                                    
                                       c
                                    
                                 
                                 =
                                 0.6
                              
                            and 
                              
                                 
                                    
                                       p
                                    
                                    
                                       m
                                    
                                 
                                 =
                                 0.1
                              
                           , as usually done in the literature (Banzhaf et al., 1998). Computing the Fitness during the evolutionary process over all validation objects can be infeasible. Thus, we used a sample of s
                           =500 of those objects, as this was enough to learn functions that are more effective than our heuristics.

We found our RF-based tag recommender to be very insensitive to parameterization. The results obtained in our cross-validation experiments using different number of trees per bootstrap sample (T
                           =1, 3, 5, 10) are statistically tied (with 95% confidence) for all datasets. We thus set T
                           =1, due to the lower cost. We also fixed the number n of attributes selected in each split of the tree according to the default value originally suggested in Breiman (2001), i.e., 
                              
                                 n
                                 =
                                 ⌊
                                 
                                    
                                       log
                                    
                                    
                                       2
                                    
                                 
                                 (
                                 m
                                 +
                                 1
                                 )
                                 +
                                 0.5
                                 ⌋
                              
                           , where m is the total number of attributes. Despite the fact that this default value has been reported to work well in practice (Liaw & Wiener, 2002), we tested other values ranging from 0.25m to 0.75m, observing no significant impact of the choice on our results. The only parameter that (slightly) impacts the results is the number of terminal nodes l. We used cross-validation to determine the best value of l in the 
                              
                                 
                                    
                                       10
                                    
                                    
                                       2
                                    
                                 
                              
                           –
                              
                                 
                                    
                                       10
                                    
                                    
                                       3
                                    
                                 
                              
                            range, finding that the best choice is l
                           =1000 for all datasets.


                           Table 5
                            shows the selected parameter values for all object-centered tag recommendation methods analyzed. Note that, for any given dataset, the selected values for 
                              
                                 
                                    
                                       σ
                                    
                                    
                                       min
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       min
                                    
                                 
                              
                            are the same for all methods.

For the personalized tag recommendation strategies, the parameters in common with the object-centered methods (both heuristic and L2R-based methods) were set with the same best values discussed in the previous section (shown in Table 5). Moreover, we set the descriptive power metric DP
                           =
                           wTS in the experiments with heuristics 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                                 +
                                 UF
                              
                            and LATRE
                           +
                           DP
                           +
                           UF, and their variants 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       u
                                    
                                    
                                       +
                                    
                                 
                                 DP
                              
                           
                           +
                           UF and 
                              
                                 
                                    
                                       LATRE
                                    
                                    
                                       u
                                    
                                 
                                 +
                                 DP
                                 +
                                 UF
                              
                           , since wTS was the most promising descriptive power metric according to our findings.

The best values of parameter 
                              
                                 β
                              
                           , used by heuristics 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                                 DP
                              
                           
                           +
                           UF and LATRE
                           +
                           DP
                           +
                           UF, and their variants, are shown in Table 6
                           . These values allow us to compare the contribution of the UF metric for personalized recommendation purposes. For example, considering 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       u
                                    
                                    
                                       +
                                    
                                 
                                 wTS
                              
                           
                           +
                           UF strategy, we found that setting 
                              
                                 β
                              
                            according to Table 6 leads to improvements in 
                              
                                 p
                                 @
                                 5
                              
                            of up to 10% in LastFM and up to 7% in Bibsonomy and YouTube, with respect to results obtained with 
                              
                                 β
                                 =
                                 1
                              
                            (that is, the weight assigned to UF equal to 0). The improvements are larger in LastFM probably due to the higher collaborative nature of tags in this application. That is, in LastFM any user has permission to assign tags to an object, whereas in YouTube, only the content publisher has this permission. In Bibsonomy, tags are also collaboratively created, but there is a lower level of activity in this application when compared to LastFM. Thus, LastFM present a richer tag assignment history, which benefits all personalized recommendation methods. This fact reflects also on the best choices for 
                              
                                 β
                              
                           , whose values for LastFM and Bibsonomy are smaller than for YouTube in several cases. Indeed, the importance given to the UF metric in LastFM is slightly higher than in the other two applications, particularly when 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            is used.

The parameters of the PITF baseline were set as following. Similarly to Rendle and Lars (2010), we set the factorization dimension 
                              
                                 δ
                                 =
                                 64
                              
                           , and the sample size s
                           =100. We tested two different values for the learning rate 
                              
                                 λ
                              
                           , namely, 
                              
                                 0.05
                              
                            and 
                              
                                 0.01
                              
                           , obtaining the best results for the smaller value. Moreover, as the algorithm converges before 50 iterations in our experiments, we set this value for 
                              
                                 τ
                              
                           . These parameter values are also shown in Table 6.

In this section, we present the results of all methods in the test sets, using the best parameter values found in the validation set, as explained in Section 6.4. We start by discussing the results of the object-centered strategies (Section 6.5.1), and then present the results of the personalized methods (Section 6.5.2). Finally, in Section 6.5.3, we compare the best object-centered and personalized methods to show the benefits of personalization in tag recommendation.

We discuss the most relevant results of our 11 object-centered tag recommendation methods (8 heuristics and 3 L2R-based strategies), comparing them against the 3 baselines. Table 7
                            shows average 
                              
                                 p
                                 @
                                 5
                              
                            results for all methods and datasets. Average recall@5, NDCG@5 and MRR results are shown in Tables 8–10
                           
                           
                           , respectively.

All reported results are averages over 5 folds (test sets). For the GP-based and RF-based strategies, which are stochastic, each experiment was repeated 5 times. Thus, results are averages over 25 runs (5 folds, 5 seeds). Tables 7–10 also show 95% confidence intervals, indicating that, with that confidence, results do not deviate from the reported means by more than 3%. For each dataset, the tables are broken into 3 blocks: baselines, new heuristics and L2R-based methods. Best results and statistical ties (according to a 2-sided t-test
                           
                              28
                              We applied the t-test with Bonferroni correction (Abdi, 2007) to control for the familywise error rate.
                           
                           
                              28
                            with p-value<0.05) within each block are shown in italics. Best overall results (and statistical ties) are shown in bold.

We start with a general finding: the improvements obtained with our methods over the baselines are much more modest in the LastFM dataset. This is possibly due to two factors: (1) there tends to be less overlap between the contents of title, description and tags associated with the same object on LastFM (Figueiredo et al., 2013), which leads to a greater concentration of TS (and wTS) around small values, making it difficult to distinguish “good” from “bad” terms using these metrics and (2) the number of tags per object tends to be smaller in our LastFM and Bibsonomy datasets (e.g., 48% and 73% of our YahooVideo and YouTube objects have fewer than 10 tags, against 94% of Bibsonomy objects and 88% of LastFM objects). These factors limit the benefits from using TS and wTS and from exploiting co-occurrence patterns among pre-assigned tags in that dataset.

Next, we turn our attention to the relative performance of specific methods, starting with the baselines. Consistently with (Menezes et al., 2010), we find that LATRE outperforms 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            in most datasets. The improvements in p@5 reach 26%, whereas the gains in recall@5, NDCG@5 and MRR are also very impressive, reaching 27%, 22% and 12%, respectively. The only exception is LastFM: the difference between the two methods in this dataset is under 2% for all evaluation metrics. Moreover, CTTR appears as a good alternative to LATRE in the YouTube dataset, with improvements of 53%, 61%, 51% and 48% in average p@5, recall@5, NDCG@5 and MRR, respectively. This occurs because CTTR exploits the terms of other textual features, while 
                              
                                 
                                    
                                       Sum
                                    
                                    
                                       +
                                    
                                 
                              
                            and LATRE are purely based on tag co-occurrences. Next, we discuss the results of our new heuristics and L2R-based strategies.

We find that our best heuristic in each dataset produces gains over the best baseline of 14% in p@5, considering average results across all datasets. Similarly, the average gains in recall@5, NDCG@5 and MRR are 15%, 11% and 9%, respectively. However, taking the best results in any dataset, the improvements reach 20% in 
                                 
                                    p
                                    @
                                    5
                                 
                              , 25% in recall@5, 17% in NDCG@5 and 14% in MRR. Thus, introducing a metric of descriptive power can greatly improve recommendation effectiveness.

Comparing each new heuristic with the original method on which it was based (
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                 
                               or LATRE), we find that our heuristics provide gains, on average, of 36% in p@5, 40% in recall@5, 31% in NDCG@5 and 24% in MRR. These are average results across all datasets. The improvements on any given dataset can be as high as 105% in 
                                 
                                    p
                                    @
                                    5
                                 
                               and 116% in recall@5, such as the case of 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                               on the YouTube dataset. As discussed, the gains for LastFM are much more modest (e.g., under 2% in p@5).

In comparison with CTTR, the improvements in p@5, recall@5, NDCG@5 and MRR produced by our new heuristics reach 57%, 61%, 55% and 51%, respectively, and remain quite impressive even if averaged across all datasets. For example, the corresponding gains produced by LATRE
                              +
                              wTS, which is one of our best performing heuristics (see below), over CTTR, averaged across all four datasets, are 38%, 39%, 39% and 30%, respectively. These results illustrate the benefits of using our descriptive power metrics as well as exploiting pre-assigned tags. Moreover, the strategy adopted by CTTR to combine the different dimensions exploited for tag recommendation (i.e., co-occurrences and terms extracted from textual attributes), which is based on the precision that each dimension provides separately, may not be the best choice (Lipczak & Milios, 2011). Indeed, the same authors later analyzed the potential benefits of introducing a tuning parameter to combine the different dimensions (Lipczak & Milios, 2011). However, they did not propose an explicit recommendation method that uses this parameter. Our new heuristics use the 
                                 
                                    α
                                 
                               parameter that can be adjusted to the dataset (i.e., learned in a training set), producing better results. Moreover, as we show in Section 6.5.1.2, our L2R-based strategies produce further improvements by learning the weights applied to the different dimensions exploited by our methods and by using a larger set of relevance metrics.

Among the new heuristics, the most promising ones are LATRE
                              +
                              wTS and LATRE
                              +
                              wTF, as they yield the best results in most cases. To reach this conclusion, we make two observations. First, for any given descriptive power metric DP (i.e., 
                                 
                                    TS
                                    ,
                                    TF
                                    ,
                                    wTS
                                 
                               or wTF), LATRE
                              +
                              DP slightly outperforms 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    DP
                                 
                               in most cases (up to 4% in 
                                 
                                    p
                                    @
                                    5
                                 
                              , 4% in recall@5, 2% in NDCG@5 and 5% in MRR). Thus there is still (modest) benefits when we exploit more complex association rules, but the inclusion of the textual features mitigates the difference in effectiveness among our heuristics. In the few cases where 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    DP
                                 
                               outperforms LATRE
                              +
                              DP, the gains in 
                                 
                                    p
                                    @
                                    5
                                 
                               are under 3%.

Our second observation is that, comparing all four descriptive power metrics, wTS tends to yield the best results, followed by 
                                 
                                    wTF
                                    ,
                                    TS
                                 
                               and TF. In particular, the use of wTS in LATRE
                              +
                              wTS, as opposed to the traditional TF metric, leads to gains of up to 7% in p@5, 6% in recall@5, 7% in NDCG@5 and 22% in MRR. This is mainly because wTS considers that objects are composed of different features which, in turn, may have different descriptive capacities. TF, in contrast, tends to favor very frequent terms, even if they appear in a single feature. Such terms are often less relevant than those appearing across multiple features.

Turning our attention to the L2R-based strategies, the three analyzed methods provide further improvements over our heuristics. We start by noting that the best L2R-based strategy – RF – outperforms the best heuristic (LATRE
                              +
                              wTS) by up to 23% in p@5, whereas the improvements in recall@5, NDCG@5 and MRR reach up to 22%, 24% and 19%, respectively. The corresponding gains averaged over all datasets are 14%, 13%, 15% and 11%. These improvements confirm the benefits of exploiting supervised L2R methods for tag recommendation, allowing an automatic search for a solution that combines a larger number of attributes when compared to unsupervised heuristics such as LATRE
                              +
                              wTS.

We now turn our attention to the comparison of the three L2R-based strategies. Unlike existing comparisons of different L2R techniques in other domains (e.g., document ranking) (Gomes et al., 2013), there is a clear winner method (RF) in all 4 datasets. The gains in p@5 of the winner method over the best of the remaining L2R techniques considered (i.e., either GP or RankSVM), averaged across all four datasets, are 7%, reaching almost 10% in Bibsonomy and LastFM. The corresponding average gains in NDCG@5, recall@5 and MRR are 7%, 7% and 5%, respectively. These results confirm the effectiveness of methods based on an ensemble of decision trees, which are non-linear L2R strategies that have been shown to be effective and competitive in other studies (Friedman, 2000; Mohan et al., 2011).

The other two L2R-based strategies – GP and RankSVM – have been previously exploited in object-centered tag recommendation (Belém et al., 2011). GP is the most flexible strategy, allowing a wider range of types of recommendation functions (any function built from the considered operators and attributes). However, this can also be a disadvantage because the search space is larger when compared to the search space of the other two L2R-based methods, making it more difficult to find the best function. On the other hand, the shape of functions produced by RankSVM is pre-defined by the kernel function, which was set linear here (as this led to the best results). Thus, all RankSVM-produced functions consist of linear combinations of the attributes. Moreover, we note that the results of the GP-based method exhibit a higher variability than those of RankSVM because the functions generated by GP are inherently more diversified due to the stochastic operations explored by the method (e.g., mutation). Although RF is also stochastic, the variability introduced to its generated functions tends to be smaller than the variability produced by GP, since there exists fewer points in the RF algorithm where randomness can be introduced.

Analyzing the importance of each attribute in each “learned” ranking function, we verified that the most frequently used attribute by the best function produced by the GP process at its final generation is 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                 
                               (also used by LATRE). Considering all datasets, 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                 
                               occurs in 93% of the generated functions. The next most frequent metric is wTS, which occurs in 71% of the functions. 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    ,
                                    IFF
                                 
                               and Pred come next, occurring in 67%, 60% and 57% of the functions, respectively. All other metrics appear in fewer than 50% of the functions. Similarly, we also analyzed the weight vector W learned by RankSVM, finding that the largest weights, on average, are indeed associated with 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                 
                               and wTS. In order to estimate the importance given to each attribute by the RF generated models, we measured the average depth of each attribute in the regression trees, since the most discriminative attributes tend to be located near the roots. The most discriminative attribute, according to this measure is 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                 
                              , followed by 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                    ,
                                    
                                       
                                          Vote
                                       
                                       
                                          +
                                       
                                    
                                 
                               and wTS, an order slightly different from the importance given by the other L2R approaches.

Furthermore, we note that our L2R-based strategies provide flexible frameworks that can be easily extended to incorporate new metrics and to exploit other aspects of the tag recommendation problem (e.g., personalization, as we do in this work). We also note that, after the offline training step, the use of the functions generated by any of the L2R-based strategies at recommendation time does not incur in significant extra processing time in relation to the best heuristic (Belém et al., 2011). One possible source of delay for all of them is the on-demand generation of association rules by LATRE. However, as shown in Menezes et al. (2010), LATRE’s average processing time is well-suited for real-time recommendation.

In sum, we found that: (1) L2R-based strategies can significantly outperform state-of-the-art unsupervised heuristics and (2) RF is the best L2R strategy out of the three analyzed techniques, providing further gains over previously evaluated L2R-based strategies.

We now discuss the most relevant results of our new personalized tag recommendation methods (4 heuristics and 3 L2R-based strategies), comparing them against the PITF baseline. Table 11
                            shows 
                              
                                 p
                                 @
                                 5
                              
                            results for all personalized methods and datasets. Recall@5, NDCG@5 and MRR results are shown in Tables 12–14
                           
                           
                           , respectively.

Once again, all reported results are averages over 5 folds (test sets), whereas the results of GP and RF are averages over 25 runs (5 folds, 5 random generator seeds). Tables 11–14 show 95% confidence intervals, indicating that, with that confidence, most results deviate from the means by less than 2%. For each dataset, the tables are broken into 3 blocks: baseline, new heuristics and L2R-based methods. Best results and statistical ties (according to a 2-sided t-test
                              29
                              Like for object-centered tag recommendation, we also applied the Bonferroni correction on the results of personalized tag recommendation.
                           
                           
                              29
                            with p-value<0.05) within each block are shown in italics. Best overall results (and statistical ties) are shown in bold. Recall that we do not show results of the personalized methods for YahooVideo as our dataset of this system does not identify the user who assigned each tag.

We start by comparing our new heuristics against the baseline PITF. We found that our best heuristic considering overall results (LATRE
                              +
                              wTS
                              +
                              UF) produces gains in p@5 ranging from 48% to 251%, and in recall@5, NDCG@5 and MRR of up to 255%, 295%, and 209% respectively. Average gains across all datasets are 121% (p@5), 122% (recall@5), 157% (NDCG@5), and 120% (MRR). Thus, using a combination of tag co-occurrences, multiple textual features and metrics of relevance, including a metric that captures the tagging history of the user (UF), can greatly outperform recommendation methods that are based only on the interrelationships between users, objects and tags, like PITF.

The effectiveness of PITF is particularly poor in YouTube due to the non-collaborative nature of the application, where the user who uploaded the object can assign tags to it. This characteristic makes training data sparser, limiting the benefits of PITF, which depends on a sufficient amount of postings involving a user u and an object o to recommend relevant tags for the pair 
                                 
                                    〈
                                    u
                                    ,
                                    o
                                    〉
                                 
                              . Nevertheless, we note that even in collaborative tagging applications, such as Bibsonomy and LastFM, the gains of our heuristics over PITF are very large. For example, in Bibsonomy, LATRE
                              +
                              wTS
                              +
                              UF outperforms PITF by as much as 65% in p@5 (see Table 11).

We note that, like PITF, our methods also exploit the vocabulary of the target user, expressed by the tags assigned by her to other objects, as a representation of her interests and main evidence to support personalization. We argue that it is not unlikely that the same user may assign tags to similar objects as these objects better match the user interests and vocabulary. Thus, as our results confirm, it may be interesting to recommend tags that the user had already assigned to other objects.

Next, we compare our four proposed heuristics, focusing first on the two different types of tag co-occurrence patterns exploited by them: (1) between tags assigned to the same object by various users (exploited by 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF and LATRE
                              +
                              wTS
                              +
                              UF) and (2) between tags assigned by the same user to the same object (used by 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          u
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF and 
                                 
                                    
                                       
                                          LATRE
                                       
                                       
                                          u
                                       
                                    
                                 
                              
                              +
                              wTS
                              +
                              UF). In YouTube, these two kinds of co-occurrence patterns lead to the same results, since only one user can assign tags to an object. In the other two applications, interestingly, the most effective type of co-occurrence pattern depends on the co-occurrence based method exploited by the recommendation strategy (
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                 
                               or LATRE). On one hand, if the recommendation is based on 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                 
                              , which exploits relationships between only 2 tags, type (2) is preferred as 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          u
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF produces results that are, if not statistically tied, much better than those produced by 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF. For example, the improvements in p@5 reach 30% in the LastFM dataset. This occurs due to the larger amount of noise generated when co-occurrences between all tags in an object are considered. On the other hand, exploiting co-occurrences between tags assigned to the same object by various users benefits LATRE, which exploits more complex association rules (i.e., co-occurrences between more than 2 tags), being more resilient to noise. For example, the improvements in p@5 of LATRE
                              +
                              wTS
                              +
                              UF over 
                                 
                                    
                                       
                                          LATRE
                                       
                                       
                                          u
                                       
                                    
                                 
                              
                              +
                              wTS
                              +
                              UF vary from 2% up to 23%. This illustrates the benefits of exploiting more complex rules, which can deal with a larger amount of noise. The same conclusions hold for the other three evaluation metrics considered.
                                 30
                                 We also compared the purely co-occurrence based methods 
                                       
                                          
                                             
                                                Sum
                                             
                                             
                                                +
                                             
                                          
                                       
                                     and LATRE with 
                                       
                                          
                                             
                                                Sum
                                             
                                             
                                                u
                                             
                                             
                                                +
                                             
                                          
                                       
                                     and 
                                       
                                          
                                             
                                                LATRE
                                             
                                             
                                                u
                                             
                                          
                                       
                                    , respectively, obtaining the same conclusions.
                              
                              
                                 30
                              
                           

Consistently with the results of the object-centered recommendation methods that they extend, we find that LATRE
                              +
                              wTS
                              +
                              UF outperforms 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          u
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF in all datasets but YouTube. For example, LATRE
                              +
                              wTS
                              +
                              UF improves the p@5 of 
                                 
                                    
                                       
                                          Sum
                                       
                                       
                                          u
                                       
                                       
                                          +
                                       
                                    
                                    wTS
                                 
                              
                              +
                              UF by 3%, on average, in both LastFM and Bibsonomy, while experiencing only a small loss (less than 1%) in YouTube. Similarly, the average gains in recall@5, NDCG@5 and MRR produced by LATRE
                              +
                              wTS
                              +
                              UF on LastFM and Bibsonomy are 4%, 4% and 3%, respectively, whereas the losses in YouTube do not exceed 1.1%. Thus, LATRE
                              +
                              wTS
                              +
                              UF is the best heuristic for personalized tag recommendation.

Like observed for object-centered tag recommendation, all three L2R-based methods provide further improvements over the heuristics for personalized tag recommendation, in all datasets, although the RF-based strategy is clearly the best performer. For instance, the improvements in p@5 achieved with the RF-based strategy over LATRE
                              +
                              wTS
                              +
                              UF are 10%, on average across all datasets. Similarly, average gains in recall@5, NDCG@5 and MRR are 10%, 12% and 9%, respectively. Moreover, the RF-based strategy consistently outperforms the best of the other two L2R-based strategies in around 5%, on average, in any of the considered metrics. These results confirm the benefits of exploiting Random Forest as an L2R approach for tag recommendation, and the resilience of our methods when applied to both object-centered and personalized tag recommendation tasks, as discussed in Section 6.5.2.1.

Analyzing the relative importance of each considered attribute in the“learned” ranking functions, we found that the most frequently used metrics by the best GP-generated function are UF and 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                 
                              , also used by LATRE
                              +
                              wTS
                              +
                              UF. Considering all datasets, these metrics occur in respectively 73% and 63% of the generated functions. The next most frequently used metrics are wTS and IFF, which occur in 42% of the functions. All other metrics appear in fewer than 30% of the functions. The same conclusions hold if we analyze the weight vector W learned by RankSVM. For the RF-based approach, the most important attribute is 
                                 
                                    Sum
                                    (
                                    ℓ
                                    =
                                    3
                                    )
                                 
                              , followed by 
                                 
                                    UF
                                    ,
                                    
                                       
                                          Sum
                                       
                                       
                                          +
                                       
                                    
                                 
                              , and wTS.

Overall, an important factor that explains the success of our personalized methods (both heuristics and L2R-based methods) is that, as previously mentioned, they can provide relevant recommendations for a user even if she does not present a history of tag assignments. In that case, the extraction of candidates from tag co-occurrences and multiple textual features provide more general recommendations for the considered object, which can be relevant to any user. If the user is more active, however, our methods can provide a higher level of personalization, due to the use of the UF metric. In other words, our methods are flexible and robust to deal with both object-centered and personalized tag recommendation tasks. In particular, the RF-based strategy has shown to be the most effective solution for both tag recommendation tasks.

In Section 3 we argued that personalized tag recommendations might provide better descriptions of the object when compared to object-centered recommendations, thus improving services that rely on those descriptions, such as search and content recommendation. We also showed some examples extracted from our LastFM dataset to qualitatively support our argument. In this section, we provide further evidence of it by quantitatively comparing our best object-centered and personalized methods under similar conditions.

Specifically, we compare the results produced by the RF-based object-centered and personalized tag recommendation methods for each user against the same expected answer. In other words, for each target object-user pair 
                              
                                 〈
                                 o
                                 ,
                                 u
                                 〉
                              
                           , we use the same input tags 
                              
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                              
                            to feed both methods, and compare their results against the same expected answer 
                              
                                 
                                    
                                       Y
                                    
                                    
                                       o
                                    
                                 
                              
                           . To guarantee a fair comparison of both methods, we build these two tag sets such that each one contains half of the tags posted by each user who assigned tags to o (randomly selected). Note that this setup is different from the ones used in Sections 6.5.1 and 6.5.2. In the former, the tags of the object were randomly split into 
                              
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       Y
                                    
                                    
                                       o
                                    
                                 
                              
                           , with no consideration to the user(s) who posted them. In the, latter 
                              
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                              
                            consisted of half of the tags posted by the target user u and all tags posted by any other user, and the recommended tags were compared against the other tags posted by u (
                              
                                 
                                    
                                       Y
                                    
                                    
                                       o
                                       ,
                                       u
                                    
                                 
                              
                           ). Thus, the results presented here are different from those discussed in the two previous sections. In particular, unlike in the experiments discussed in Section 6.5.2, we here compare the tags recommended by the personalized method for a user u with all tags that were not used as input (i.e., all tags in 
                              
                                 
                                    
                                       Y
                                    
                                    
                                       o
                                    
                                 
                              
                           ), and not only those posted by u (
                              
                                 
                                    
                                       Y
                                    
                                    
                                       o
                                       ,
                                       u
                                    
                                 
                              
                           ). This is because, unlike in the previous section, our goal here is to assess the relevance of the suggested tags to the target object only (regardless of their relevance to the target user). Note also that, for a given object o, the object-centered method produces the same results to all users.

Precision, recall, NDCG and MRR of both methods are shown in Table 15
                            for the Bibsonomy, LastFM, and YouTube datasets. Note that the personalized strategy produces results that significantly outperform the object-centered method. The average gains in p@5 are 10%, while corresponding gains in recall@5, NDCG@5 and MRR are 15%, 10% and 8%, respectively. That is, having fixed the expected answer, the personalized recommendations match this expected answer more closely than the object-centered recommendations. These results are in alignment with observations in Rendle et al. (2009) and Rendle and Lars (2010), which showed that their personalized tag recommenders outperform even the theoretical upper-bound for any non-personalized tag recommender.

These results are evidence that personalized tag recommendations may help improve the quality of the recommendations, providing tags that not only might be more important to the target user, and thus to other users with similar interests and profiles, but also that cover the different facets of the object, allowing a more complete description of the content than object-centered recommendations.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this article, we proposed several new object-centered tag recommendation strategies that jointly exploit term co-occurrence with pre-assigned tags, multiple textual features and metrics of tag relevance. We also proposed personalized strategies, which exploit the aforementioned dimensions and the tag assignment history of the target user. Our strategies include several heuristics and learning-to-rank based methods. We compared our strategies against four state-of-the-art techniques, in different datasets.

We found that LATRE
                     +
                     wTS, our best heuristic for object-centered tag recommendation produces gains in precision in the top-5 recommended tags in 12%, on average across all datasets. In terms of average recall and average NDCG in the top-5 recommendations, the average gains are 13% and 9%, whereas the improvements in average MRR are 6%. Some further improvements over our best heuristic (14% in precision, averaged across the four datasets) can also be achieved with the L2R-based strategies, particularly with the Random Forest (RF) based method, which produces the best results among the three analyzed L2R-based approaches for tag recommendation. Similarly, we found that LATRE
                     +
                     wTS
                     +
                     UF, our best heuristic for personalized tag recommendation, produces gains in precision, on average, of 121% over the PITF baseline. The improvements in recall, NDCG and MRR are 122%, 157% and 120%, respectively. Moreover, once again further improvements can be achieved by the L2R-based methods, particularly the RF-based method, which improves the precision of the best heuristic in 10%, on average. As a final result, we also quantified the benefits of personalized tag recommendation to also improve the description of the object, finding that our best personalized method produces gains in precision over our best object-centered tag recommendation of 10%, on average.

The superiority of our strategies can be credited to the multiple dimensions they exploit. For example, when a user has no tag assignment history in the application, our methods are still able to recommend tags that are related to the textual content of the target object, which may be relevant to any user. In contrast, users with some history of tag assignments can benefit from more personalized recommendations. Our results illustrate the benefits of jointly exploiting the aforementioned dimensions, particularly metrics of descriptive power and user interests. Moreover, the use of learning-to-rank techniques arise as a promising solution, as they yield very competitive results while still being quite flexible, allowing the easy inclusion of new metrics and the extension of the scope of the problem.

Directions for future work include the exploration of new metrics and techniques (e.g., features extracted from the media content and other user related features) as well as extensions of the methods to consider not only relevance but also other aspects such as novelty and diversity. Another venue of interest is a thorough investigation of the biases and benefits of a manual evaluation of the recommendations by volunteers, for both object-centered and personalized tag recommendation.

@&#ACKNOWLEDGEMENTS@&#

This research is partially funded by the Brazilian National Institute of Science and Technology for Web Research (MCT/CNPq/INCT Web Grant Number 573871/2008-6), and by the authors individual grants from CNPq, CAPES and FAPEMIG. We also would like to thank the reviewers for their comments and suggestions, which greatly contributed for this work.

@&#REFERENCES@&#


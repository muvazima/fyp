@&#MAIN-TITLE@&#Invariant representation of facial expressions for blended expression recognition on unknown subjects

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The organization of facial expressions is person-independent.


                        
                        
                           
                           One expression can be defined by its relative position to 8 other expressions.


                        
                        
                           
                           We synthesized the 8 expressions from plausible distortions.


                        
                        
                           
                           The representation is robust to the type of data (shape and/or texture information).


                        
                        
                           
                           As expression is accurately described in a 4 dimensional expression space.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Facial expression

Invariant representation

Delaunay tessellation

Manifold of expressions

Piecewise affine warping

Transfer learning

@&#ABSTRACT@&#


               
               
                  Facial expressions analysis plays an important part in emotion detection. However, having an automatic and non-intrusive system to detect blended facial expression is still a challenging problem, especially when the subject is unknown to the system. Here, we propose a method that adapts to the morphology of the subject and that is based on a new invariant representation of facial expressions. In our system, one expression is defined by its relative position to 8 other expressions. As the mode of representation is relative, we show that the resulting expression space is person-independent. The 8 expressions are synthesized for each unknown subject from plausible distortions. Recognition tasks are performed in this space with a basic algorithm. The experiments have been performed on 22 different blended expressions and on either known or unknown subjects. The recognition results on known subjects demonstrate that the representation is robust to the type of data (shape and/or texture information) and to the dimensionality of the expression space. The recognition results on 22 expressions of unknown subjects show that a dimensionality of the expression space of 4 is enough to outperform traditional methods based on active appearance models and accurately describe an expression.
               
            

@&#INTRODUCTION@&#

A major goal of many new government programs is to find better ways that will allow the elderly to stay in their own homes longer, rather than moving to a care facility. One main domain for aging in place is to increase security and raise an alarm when some specific changes in behavior occur. Such systems have to be non-intrusive, easy to use and agreeable. Among the ways of finding a change in behavior and feelings, facial expressions analysis plays an important part, for they display human emotions and moods [1].

This paper explores a system based on a camera which can be included into a Set-top box. Such a system requires:
                        
                           •
                           accuracy to detect neighboring blended expressions (as displayed in Fig. 1
                              );

completeness to detect new unknown expressions;

robustness to cope with the diversity of facial morphologies;

flexibility to adapt itself to a subject without a previous learning phase.

Many emotion recognition systems based on facial expression analysis have been proposed in the last decade [2–4]. Efforts have been made to compare these methods. First, popular facial expression databases are available (e.g. the Cohn–Kanade database [5] and the HUMAINE database [6]). More recently, challenges are organized to compare these systems in the same conditions. FERA 2011 [7] aimed at detecting FACS Action Units and discrete emotions. AVEC 2011 [8] and AVEC 2012 [9] aimed at detecting the variations of four affect dimensions (valence, power, expectancy and arousal). The drawback of such challenges is that the results of the challenges are computed on the emotion prediction, so that the performances of the global processes are compared rather than each step of the systems. This is especially true with multimodal systems.

Most emotion recognition systems based on facial expression analysis concatenate two steps: facial feature extraction and classification [2]. They are often influenced by the work of Ekman, so that they either concentrate on the classification of a small amount of facial expressions (most of the time the 6 basic emotions universally associated with distinct facial expressions [1]) or on Action Units (AUs) [10]. Some attempts have been made to cope with other expressions such as pain [11,12]. The systems focus then on the classification of whether or not the expression is shown, let alone the other expressions. These systems do not deal with expressions that are not included in any training database. Yet, real life expressions are rarely prototypic ones [1]. That is why, more recently, systems focus on a continuous representation of emotions. Ishii et al. [13] proposed a method to generate a subject-specific emotion map compliant with Russell’s circumplex model [14]. The mapping is then previously learnt for each subject by a supervised learning algorithm. The AVEC2012 challenge [9] proposed a comparison of methods for automatic emotion analysis, where the emotions were labeled by FEELTRACE [15] in four dimensions [16]. The best scores were obtained by [17] with a system that predicts the emotion by directly applying a radial basis function process on the facial and audio features. The main limit of these systems is that they directly transform facial features into emotion prediction. Unfortunately, the facial features carry both information of expression and identity of the subjects, so that such systems need a huge amount of expressive faces for their learning phase and do not perform good results in generalization to unknown subjects. In FERA 2011 challenge [7], the person-independent discrete emotion recognition did not exceed 75.2%, although the person-specific performance was 100%. That is why we propose an intermediate step between facial feature representation and classification. This step is a continuous invariant expression representation of the facial expressions.

The choice of representation is known to influence the recognition performance. In this article, we focus on a facial expression representation that deals with expressions not included in any training database and with morphological differences between unknown subjects and subjects enrolled in the training database. In our method, we assume that the neutral face of the subject is known for both the known and the unknown subjects. As we need to deal with subtle differences between expressions, we use appearance features based on Active-Appearance Models (AAMs) [18]. AAMs are known to provide important spatial information of key facial landmarks [19]. Yet, good AAM tracking on unknown subjects is still a challenging problem. In this paper, the faces have been annotated by hand to avoid problems due to AAM tracking.

The main contribution of this article is the specification of a new invariant representation of emotional facial expressions. The originality of the approach is that we did not focus on the characteristics of one expression but on the organization of this expression with respect to the others. This organization has been extracted from data and we have attested that this organization is person-independent. We used this invariant organization to transform the appearance space which is person-specific into the expression space which is person-independent and to give a direction–intensity signature to each expression. The recognition tasks are then processed in the expression space with a basic classifier (see overall process on Fig. 2
                     ). Another important contribution of this work is that we create a person-specific appearance space adapted to the morphology of the subject without a previous learning phase of the subject. The particularity of the approach is that we synthesized the expressions of the unknown subjects in order to create their own complete appearance space. The synthesized expressions are compliant with the organization of the expressions previously found, which signifies that the appearance space contains all the expressions defined in the expression space even if the new subject has not displayed them.

The remainder of this paper is organized as follows. In the next section, the relevant previous studies on facial expression representation are examined. Section 3 describes the limits of traditional AAM based expression analysis. In Section 4, we describe the invariant representation used to perform the transformation of the appearance space into the expression space and the individual steps of the transformation. Section 5 generalizes the method to unknown subjects. Section 6 demonstrates the accuracy and the robustness of the proposed system in expression recognition. Section 7 concludes the paper.

@&#RELATED WORKS@&#

It is commonly admitted that the expressions are similar across people [20] and that the identity is person-specific. One main difficulty in facial expression analysis is to cope with the various morphologies of subjects.

The most popular invariant representation to characterize uniquely an expression is the FACS system [10]. In FACS, one expression is characterized by a combination of Action Units (AUs). For example, an expression of surprise is defined by AU1 (inner brow raiser)+AU2 (outer brow raiser)+AU5 (upper lip raiser)+AU25 (lips part). Most of the time, the systems that detect AUs have only two steps: facial feature detection and AUs classification. The question of non-prototypic expressions is not addressed, taking the FACS combinations for granted. To address this question, Pantic and Rothkrantz [21] proposed a three steps process based on AUs description. The first step is hybrid facial feature detection, the second step is AUs detection, the third step is rule based emotion detection. They postulate that every non-prototypic emotional facial expression can be classified in one of the 6 basic emotions. A 6 emotions classification is not accurate enough if we want to analyze more subtle emotions. Moreover, AUs detection is still a challenging problem as FERA 2011 challenge illustrates [7]. Even if the results were encouraging, the recognition rates remained low: the AUs detection only reached 62%. Mixed AUs are also a matter of concern. To deal with this question, Wojdel et al. [22] proposed a fuzzy logical approach to define the dependencies between action units. Finally, the AUs method is based on multiple separate action units, resulting in the natural correlation between multiple facial actions occurring in each facial expression being ignored. Liu and Wu [23] showed that, with their method, training AU6 and AU12 simultaneously performed better for smile deceit detection than training AU6 and AU12 separately, which makes think that AU description is not adapted to Computer Vision.

To overcome morphological differences between subjects in a more unified manner, neutral face subtraction on facial features is often performed. Cheon and Kim [24] aligned different subjects’ expressions by using Diff-AAM before manifold learning and recognition tasks. Diff-AAM features are the difference of active appearance model (AAM) features between the input face image and the reference face image (neutral face). They represent the main distortions of the face. These methods assume that all people have similar patterns of facial expression changing from neutral expression to a specific expression. Nevertheless, the observations of Schmidt and Cohn [25] indicated the possibility of differences in facial behavior among individuals.

Another way of extracting expression features from the facial features is to separate expression and identity via bilinear models. The advantage of bilinear methods is that they need few training images. Wang and Ahuja [26] used HOSVD (High Order Singular Value Description) to decompose appearance features similar to AAM features into a person subspace and an expression subspace. They used the resulting model to synthesize facial expressions of a new subject and to recognize simultaneously face and expression. Abboud and Davoine [27] used bilinear symmetric and asymmetric models on AAM features to perform both facial expression recognition and synthesis. Mpiperis et al. [28] decoupled face and facial expression by bilinear models applied on elastically deformable model. They used the resulting model to perform face and expression recognition simultaneously. For each of these methods, the recognition was performed on the 6 basic expressions and neutral face but it was never mentioned how the system performs with blended expressions.

Dealing with the various identities of the subjects can also be performed by building a specific expression space dedicated to the subject. Esau et al. [29] handled these notions by using a fuzzy emotion model that adapts to the characteristics of individual human faces. The main difficulty is then to be able to align these person-specific expression spaces. In their system, Esau et al. needed a previous learning phase of the subject.

Finally, manifold learning methods have been used for facial expression representation. The facial features are projected on a low dimensional subspace which is optimal for low cost and accurate classification. Such manifolds take into account the mixture of expressions and the notion of intensity. Stoiber et al. [30] embedded AAM features into a disc. The embedding is done in an unsupervised manner by finding the dominant directions of the original appearance space and organizing them on a 2D disk via minimizing the sum of the angles between them. The resulting space leads to promising results for animation purpose but is manually labeled and dedicated to a subject for expression recognition purpose. No experiments have been performed on expression recognition nor on the similarity of the disk between subjects. Chang et al. [31] applied locally linear embedding (LLE) and Lipschitz embedding to learn the expression manifold. They extracted one manifold for each subject and then aligned the different manifolds for all subjects. A k-Nearest Neighbor classifier was used to recognize the expression afterwards. In [32], they addressed the question of blended expressions, that are not included in the training database. They created a person-specific manifold for each subject by Lipschitz embedding applied on video sequences displaying transitions from the neutral face to one of the 6 basic expressions. The transitions between the neutral face and the 6 basic expressions represented 6 paths on the manifold. Blended expressions with varying intensities lied between those paths. They learnt a probabilistic model to recognize such expressions, taking into account the temporal information of the video sequences. Blended expressions were then defined by the positions of the 6 basic paths. Their experiments were limited to only five subjects and they did not deal with unknown subjects. They did not measure the adequacy of the representation of the blended expressions across subjects either. Shan et al. [33] proposed a Supervised LPP method to extract one single manifold for all individuals. There again, a k-Nearest Neighbor classifier was used to recognize the expression afterwards. As for Lipschitz embedding [31,32], this embedding method needs a high density of training data to compute a manifold that properly approximates the organization of the expressions. They did not deal with unknown subjects either.

AUs representation, widely used by psychologists, seem to be not adapted to Computer Vision, for AUs recognition still lead to poor results, and mixed AUs are still a matter of concern. Representations of the expressions in a unified manner seem more performing. In this paper, we propose a representation that uses the distortions of the whole face. Separating expression and identity is then the key problem. Bilinear methods perform well when one of the two components (face or expression) is in the training set, but show difficulties when both face and expression are unknown from the training database, which is the case in lots of real-life applications. That is why we preferred a method based on manifold learning, which shows promising results for blended expressions representation. Current manifold learning methods need a huge amount of images of the subjects to build the manifold of expressions. In this paper, we explore the expression space by building a manifold based on only the neutral face and 8 known expressions. The alignment of different subjects is also a matter. Current systems first create person specific manifold and then need a supervised learning phase to align the various manifolds of the subjects. In this paper, we first analyze the structure of the expression space and show that the representation we propose is person independent. In a second step, we build a manifold compliant with this structure, so that no supervised alignment of the subjects’ manifolds is needed. We also address the extension to unknown subjects. Here, we propose to create an assumed manifold of expressions for unknown subjects. Finally, contrary to the other papers that deal with blended expressions, we measure the relevancy of the representation we propose by computing the recognition rate of blended unknown expressions.

After recalling the definition of appearance vectors based on the Active-Appearance Model (AAM [18]) in Section 3.1, this section presents the limits of the traditional facial expressions analysis methods, that are based on these appearance vectors (Section 3.2). Two methods are analyzed: AAM and differential-AAM. These two methods will further be compared (results and discussions in Section 6) to the new method proposed in the remainder of this paper (see Fig. 3
                     ).

Appearance vectors are obtained using a database of N images of subjects displaying various facial expressions that are annotated with several remarkable points (for example, one remarkable point is the left corner of the lips). For each image, these remarkable points are concatenated to form a vector 
                           
                              
                                 
                                    s
                                 
                                 
                                    i
                                 
                              
                              ,
                              i
                              =
                              1
                              …
                              N
                           
                        , that represents the shape. The pixel intensities contained in the area spanned by the shape form the vector 
                           
                              
                                 
                                    g
                                 
                                 
                                    i
                                 
                              
                              ,
                              i
                              =
                              1
                              …
                              N
                           
                        , that represents the texture. To detect the distortions of shape and texture, a Principal Component Analysis (PCA) is performed on both vectors:
                           
                              (1)
                              
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       s
                                    
                                    
                                       ¯
                                    
                                 
                                 +
                                 
                                    
                                       Φ
                                    
                                    
                                       s
                                    
                                 
                                 .
                                 
                                    
                                       b
                                    
                                    
                                       i
                                    
                                    
                                       s
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       g
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       g
                                    
                                    
                                       ¯
                                    
                                 
                                 +
                                 
                                    
                                       Φ
                                    
                                    
                                       t
                                    
                                 
                                 .
                                 
                                    
                                       b
                                    
                                    
                                       i
                                    
                                    
                                       t
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    s
                                 
                                 
                                    ¯
                                 
                              
                           
                         and 
                           
                              
                                 
                                    g
                                 
                                 
                                    ¯
                                 
                              
                           
                         are the mean shape and texture, 
                           
                              
                                 
                                    Φ
                                 
                                 
                                    s
                                 
                              
                           
                         and 
                           
                              
                                 
                                    Φ
                                 
                                 
                                    t
                                 
                              
                           
                         the matrices formed by the PCA eigenvectors, and 
                           
                              
                                 
                                    b
                                 
                                 
                                    i
                                 
                                 
                                    s
                                 
                              
                           
                         and 
                           
                              
                                 
                                    b
                                 
                                 
                                    i
                                 
                                 
                                    t
                                 
                              
                           
                         are the decomposition of 
                           
                              
                                 
                                    s
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    g
                                 
                                 
                                    i
                                 
                              
                           
                         on the eigenmodes. 
                           
                              
                                 
                                    s
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    g
                                 
                                 
                                    i
                                 
                              
                           
                         are called shape vectors and texture vectors. To take into account the correlation between shape and texture, a third PCA is performed on a vector that concatenates shape and texture vectors 
                           
                              
                                 
                                    b
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             w
                                          
                                          
                                             s
                                          
                                       
                                       .
                                       
                                          
                                             b
                                          
                                          
                                             i
                                          
                                          
                                             s
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      b
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         (
                           
                              
                                 
                                    w
                                 
                                 
                                    s
                                 
                              
                           
                         is a scaling factor that ensures shape and texture parameters have comparable variances).
                           
                              (3)
                              
                                 
                                    
                                       b
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 Φ
                                 ·
                                 
                                    
                                       c
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        where 
                           
                              Φ
                           
                         is the matrix formed by the PCA eigenvectors, and 
                           
                              
                                 
                                    c
                                 
                                 
                                    i
                                 
                              
                           
                         is the appearance vector.

Classical appearance based methods using AAM parameters use a person-independent Active-Appearance Model (AAM [18]), that means the AAM is learnt from a database containing various expressions from different subjects. As the model is person-independent, it is used to align and compare unknown subjects’ expressions. By construction, the appearance vectors carry in their first components the maximum of facial shape and texture distortions. These distortions are due to the differences between the displayed expressions and to the differences between the identities (morphologies and facial texture) of the subjects. In the AAM based method (ABM), the resulting appearance vectors are directly used for recognition computation, whereas in the differential-AAM based method (DABM), the resulting appearance vectors are mapped between subjects by subtracting the neutral face vector for each subject (see Fig. 3).

As we will see in Section 6, the AAM based method (ABM) leads to poor recognition results. This can be justified by the fact that the appearance vectors carry information of both identity and expression, so that the comparison of distances between appearance vectors of different subjects’ similar expression is not relevant. Much better results are obtained by the differential-AAM based method (DABM) because a part of the difference between the identities of the subjects is subtracted. Nevertheless, in DABM, the optimal number of appearance parameters highly depends on the learning database. Moreover, as we will see in Section 6, the recognition results vary a lot according to the type of data used (shape feature, texture features or both) and it is not easy to characterize uniquely and meaningfully a new unknown expression.

To overcome these limits, we propose a method that uses person-specific AAMs, which means that one AAM is learnt for each subject from a database containing various expressions of this subject (see Fig. 3).

This section presents a new invariant representation of expressions that characterizes uniquely an expression, independently from the morphology. We use appearance vectors of person-specific Active Appearance Models. We first extract from these data an organization of facial expressions (Section 4.1), and attest that this organization is person-independent (Sections 4.2, 4.3, and 4.4). We then use this invariant representation to learn the manifolds of expressions of the subjects (Section 4.5) and compute a unique signature for each expression (Section 4.6).

To extract the organization of facial expressions from data, we use K known expressions, each one displayed by each of the P subjects, and the neutral face of each subject. For each subject i, we compute a person-specific AAM from the K expressions and neutral face of subject i. Having a person-specific model increases accuracy, for it focuses on the facial distortions of the studied subject (that are the expressions) and not on the distortions due to morphological differences between subjects. We keep the n first components of the appearance vectors, for they carry the main distortions. To have expressions with comparable intensities, we normalize the appearance vectors according to the neutral face vector of the subject, so that the expressions are located on a hypersphere centered on the neutral face. We finally perform a n-Delaunay tessellation on 
                           
                              K
                              +
                              1
                           
                         normalized vectors to get the organization of the K expressions (the 
                           
                              +
                              1
                           
                         is due to the neutral face).

Three subjects’ normalized appearance vectors and their organizations are presented in Fig. 4
                        . This figure shows that the components of a given expression are very different between the three subjects, but that the triangles from the Delaunay tessellations (for instance the triangles 3/4/5, 3/4/2 and 3/2/7) are organized in the same way.

Comparing organizations is not an easy task [34]. Feature based methods to align meshes use distances between points and we have previously said that the distance is not relevant due to morphological specificities. Other measures such as the computation of the edit distance [35] or the computation of the maximum subgraph [36] do not take into account the specific organization (points on a hypersphere) of our structure.

To compute the similarity between the organizations of the expressions of two subjects, we compare the sets of edges of the n-Delaunay tessellations. For the following 3-Delaunay tessellation of subject i (where 1 is the label of the neutral face)
                           
                              (4)
                              
                                 
                                    
                                       DT
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 {
                                 {
                                 1
                                 /
                                 2
                                 /
                                 3
                                 /
                                 4
                                 }
                                 ,
                                 {
                                 1
                                 /
                                 2
                                 /
                                 3
                                 /
                                 7
                                 }
                                 ,
                                 …
                                 }
                              
                           
                        the set of edges is
                           
                              (5)
                              
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 {
                                 {
                                 2
                                 /
                                 3
                                 }
                                 ,
                                 {
                                 2
                                 /
                                 4
                                 }
                                 ,
                                 {
                                 3
                                 /
                                 4
                                 }
                                 ,
                                 {
                                 2
                                 /
                                 7
                                 }
                                 ,
                                 {
                                 3
                                 /
                                 7
                                 }
                                 ,
                                 …
                                 }
                              
                           
                        We use Sorensen’s similarity index [37] which is applied to presence/absence of edges between the Delaunay tessellations of two subjects. Each edge has the same strength, so that the distance between appearance vectors is not taken into account. The similarity index between two organizations is then defined by
                           
                              (6)
                              
                                 Q
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       S
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       2
                                       .
                                       |
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                       ∩
                                       
                                          
                                             S
                                          
                                          
                                             j
                                          
                                       
                                       |
                                    
                                    
                                       |
                                       
                                          
                                             S
                                          
                                          
                                             i
                                          
                                       
                                       |
                                       +
                                       |
                                       
                                          
                                             S
                                          
                                          
                                             j
                                          
                                       
                                       |
                                    
                                 
                              
                           
                        where 
                           
                              |
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              |
                           
                         is the number of edges of the n-Delaunay tessellation of subject i and 
                           
                              |
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ∩
                              
                                 
                                    S
                                 
                                 
                                    j
                                 
                              
                              |
                           
                         is the number of edges in common of the n-Delaunay tessellations of both subjects i and j. The factor 2 allows having an index between 0 and 1.

We define the similarity index of one organization with all the 
                           
                              P
                              -
                              1
                           
                         others by the mean value of the similarity indexes.
                           
                              (7)
                              
                                 Q
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       P
                                       -
                                       1
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                          ,
                                          k
                                          ≠
                                          i
                                       
                                       
                                          P
                                       
                                    
                                 
                                 Q
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       S
                                    
                                    
                                       k
                                    
                                 
                                 )
                              
                           
                        The person-independent organization of facial expressions is defined as the organization 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         corresponding to the highest similarity index.
                           
                              (8)
                              
                                 Q
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          max
                                       
                                       
                                          i
                                          =
                                          1
                                          …
                                          P
                                       
                                    
                                 
                                 Q
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           
                        
                     

An experiment was conducted on 8 expressions displayed by 17 subjects with a 3D Delaunay tessellation (
                           
                              n
                              =
                              3
                              ,
                              K
                              =
                              8
                              ,
                              P
                              =
                              17
                           
                        ). Choosing 
                           
                              n
                              =
                              3
                           
                         allows to have sufficiently connections between expressions without having all the expressions connected (around 18 out of 28 possible edges). Fig. 5
                         shows in gray the distribution of the similarity index of the 17 subjects (
                           
                              Q
                              (
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                              )
                              ,
                              i
                              =
                              1
                              .
                              .
                              17
                           
                        ). The similarity index is between 0.82 and 1. The differences between the organizations 
                           
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         are most of the time due to substitutions of one edge, but the configurations keep the same neighborhood (see Fig. 6
                        ). As a comparison, one swap of two neighboring vertices with 5 neighbors each would have lead to an index of 0.78 (see Fig. 6). The organizations with an index between 0.8 and 1 can then be considered as similar to 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                        . The distribution of the similarity index between 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         and 10,000 organizations of 8 random parameters is shown in black (Fig. 5). All the similarity indices of the real organizations (in gray) are in the 1.5% of the highest similarity indices of the random organizations. As the random organizations are very different from real ones and all the real ones are similar to 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         (similarity index over 0.8), the organization 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         can then be considered as the person-independent organization.

The person-specific manifold of expressions is the piece-wise linear manifold formed, in the appearance space, by the simplices of the n-Delaunay tessellation 
                           
                              
                                 
                                    DT
                                 
                                 
                                    s
                                 
                              
                           
                         that corresponds to the person-independent organization 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                        . Each new expression of the subject (named ‘unknown expression’) can be approximated by a point on this piece-wise linear manifold.

With a 2-Delaunay tessellation (
                           
                              n
                              =
                              2
                           
                        ), the manifold is a collection of connected triangles, each triangle being formed by the parameters of the neutral face and of two known expressions (see Fig. 7
                        ). With a 3-Delaunay tessellation (
                           
                              n
                              =
                              3
                           
                        ), the manifold is a collection of connected tetrahedra, each tetrahedron being formed by the parameters of the neutral face and of three known expressions.

Similar expressions are organized in the same way from one person to another, so that one expression can be defined by its relative position to other expressions. We use this property to associate a person-independent signature to an expression. We first project the appearance vector of the expression on the person-specific manifold compliant with the organization 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                        .
                           1
                           The projection on the manifold is computed as follows. As the manifold is piece-wise linear, each simplex behaves locally as a linear space. For a new expression:
                                 
                                    1.
                                    We perform an orthogonal projection of the appearance parameters onto each simplex of the manifold.

If the projected points lie out of the boundaries of the simplex (this may append because simplices are limited in space), the projection is performed on each of the 
                                          
                                             n
                                             +
                                             1
                                          
                                        simplices of dimension 
                                          
                                             n
                                             -
                                             1
                                          
                                        that composes each n-simplex.

The one with the minimum of error is kept.


                        Fig. 7 shows an example of this projection for a 2D-manifold. The appearance vector is represented in the appearance space by the point ‘unknown expression’. Its projection on the manifold formed by the person-independent organization is called ‘approximation’ and is represented by a cross on the figure.

The direction–intensity signature of an expression is computed from this projection on the manifold:
                           
                              1.
                              The direction is given by the barycentric coordinates on the outer surface of the manifold.

The intensity is given by the norm of the ‘neutral-expression’ vector normalized such as the outer surface of the manifold has an intensity of 1.

For each expression, its direction is given by K components formed by the n barycentric coordinates and 
                           
                              K
                              -
                              n
                           
                         coordinates set to null (where K is the number of the known expressions used to compute the organization of expressions and n is the dimensionality of the manifold). The intensity is given by 1 component. The direction–intensity signature is therefore a 
                           
                              K
                              +
                              1
                           
                         vector (see Figs. 8 and 9
                        
                        ).

Recognition tasks are then processed in this signature space with a basic voting algorithm.
                           2
                           The recognition rate of one given expression is computed as follows:
                                 
                                    1.
                                    For each couple of subjects 
                                          
                                             (
                                             i
                                             ,
                                             j
                                             )
                                             ,
                                             i
                                             
                                             ≠
                                             
                                             j
                                          
                                       , the expression of subject j that is the nearest neighbor of the given expression of subject i is computed and named 
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                   ,
                                                   j
                                                
                                             
                                          
                                       .

The more frequent expression of the 
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                   ,
                                                   j
                                                
                                             
                                          
                                        when j varies is kept and named 
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                
                                             
                                          
                                        (voting algorithm).

The recognition rate of the given expression is computed from these expressions 
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       .

We have named this method OBM for organization based method.

This section extends the previous algorithm to unknown subjects. To avoid a previous learning phase of the expressions of the subjects, we compute plausible expressions using the neutral face of the subject (see Section 5.1) and generate from these expressions the person-specific appearance spaces of the unknown subjects (see Section 5.2). Section 5.3 presents how we adapt the computation of the signature of an expression.

We chose piece-wise affine warping [38] to create the plausible expressions of an unknown subject. Piece-wise affine warping is less time consuming compared to more realistic warpings [39]. This kind of warping is not adapted to synthesize realistic expressions but can efficiently be used to compute the direction of a facial shape distortion. Park and Kim [40] used it to magnify facial expression images and recognize subtle expressions. It gives the advantage of taking the morphology of the unknown subject into account. In this paper, we suppose that the neutral faces of the unknown subjects are known. One approach of piece-wise affine warping is to partition the convex hull of the points using a triangulation. Shape distortion caused by an expression is then described relative to this triangulation.

The shape is defined by m control points. To learn the distortion of an expression, we take each control point 
                           
                              
                                 
                                    x
                                 
                                 
                                    expr
                                    ,
                                    i
                                 
                              
                           
                         of the expressions 
                           
                              
                                 
                                    I
                                 
                                 
                                    expr
                                 
                              
                           
                         of the known subject and detect which triangle of the neutral face 
                           
                              
                                 
                                    I
                                 
                                 
                                    neutral
                                 
                              
                           
                         of the known subject it belongs to (see Fig. 10
                        ). Suppose 
                           
                              
                                 
                                    x
                                 
                                 
                                    neutral
                                    ,
                                    1
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    neutral
                                    ,
                                    2
                                 
                              
                           
                         and 
                           
                              
                                 
                                    x
                                 
                                 
                                    neutral
                                    ,
                                    3
                                 
                              
                           
                         are the three corners of such a triangle, the point 
                           
                              
                                 
                                    x
                                 
                                 
                                    expr
                                    ,
                                    i
                                 
                              
                           
                         can be written
                           
                              (9)
                              
                                 
                                    
                                       x
                                    
                                    
                                       expr
                                       ,
                                       i
                                    
                                 
                                 =
                                 α
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       1
                                    
                                 
                                 +
                                 β
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       2
                                    
                                 
                                 +
                                 γ
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       3
                                    
                                 
                              
                           
                        The m control points {
                           
                              
                                 
                                    x
                                 
                                 
                                    neutral
                                    ,
                                    i
                                 
                              
                           
                        } of the neutral face 
                           
                              
                                 
                                    I
                                 
                                 
                                    neutral
                                 
                              
                           
                         of the known subject are mapped to new positions 
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             neutral
                                             ,
                                             i
                                          
                                          
                                             ′
                                          
                                       
                                    
                                 
                              
                           
                         of the neutral face 
                           
                              
                                 
                                    I
                                 
                                 
                                    neutral
                                 
                                 
                                    ′
                                 
                              
                           
                         of the unknown subject. We use the coefficients 
                           
                              α
                              ,
                              β
                           
                         and 
                           
                              γ
                           
                         to find the equivalent point of the expression 
                           
                              
                                 
                                    I
                                 
                                 
                                    expr
                                 
                                 
                                    ′
                                 
                              
                           
                         of the unknown subject
                           
                              (10)
                              
                                 
                                    
                                       x
                                    
                                    
                                       expr
                                       ,
                                       i
                                    
                                    
                                       ′
                                    
                                 
                                 =
                                 α
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       1
                                    
                                    
                                       ′
                                    
                                 
                                 +
                                 β
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       2
                                    
                                    
                                       ′
                                    
                                 
                                 +
                                 γ
                                 
                                    
                                       x
                                    
                                    
                                       neutral
                                       ,
                                       3
                                    
                                    
                                       ′
                                    
                                 
                              
                           
                        
                     

Classical piece-wise affine warping is constrained to the convex hull of the control points. To overcome this behavior, we allowed having negative coefficients. We kept the relation 
                           
                              α
                              +
                              β
                              +
                              γ
                              =
                              1
                           
                         and found the triangle that minimizes the distance between 
                           
                              α
                              ,
                              β
                              ,
                              γ
                           
                         and [0,1].


                        Fig. 11
                         shows the steps for the computation of 3 plausible shapes of the same expression: the neutral face (a) and one expression (b) are displayed by 3 known subjects. The distortions between the neutral face and the expression are computed for each of the 3 known subjects, and are applied on the neutral face of the unknown subject (c).

The person-specific appearance space of the unknown subject is created in 4 steps:
                           
                              1.
                              The plausible distortions of a given expression are learnt from the known subjects.

The mean distortion is computed.

This mean distortion is applied on the neutral face of the unknown subject.

The assumed space is computed from these plausible mean expressions.

As we are able to compute an assumed person-specific appearance space for an unknown subject, we can extend the previous organization based method (OBM) to that assumed space in order to be able to recognize unknown blended expressions of an unknown subject.

The direction–intensity signature is computed in the assumed space in 3 steps:
                           
                              1.
                              
                                 P manifolds are created from the K plausible expressions, one manifold for each of the P known subjects.

The direction–intensity signature is processed for each of the P manifolds as in Section 4.6.

The mean value of the P direction–intensity signatures is computed.

Recognition tasks are then processed on this mean signature with the same voting algorithm as in Section 4.6. We have named this method AOBM for assumed organization based method.

This section presents the experimental results of OBM and AOBM and compares them to ABM and DABM. The Section 6.1 describes the database used for the experiments. Section 6.2 analyzes the recognition results of 14 unknown blended expressions on subjects for whom 8 expressions are known. Section 6.3 analyzes the recognition results of 22 unknown blended expressions on unknown subjects. Finally, Section 6.4 extends the analysis to emotion recognition on unknown subjects.

The existing public databases do not have enough different expressions to test our method. For that reason, experiments have been performed on a specific database.
                           3
                           Database available at http://www.rennes.supelec.fr/immemo/.
                        
                        
                           3
                         It consists of 22 blended expressions performed by 17 adults aged from 20 to 55years old (see Fig. 1) with 30% females. Most of the subjects are Caucasian, some subjects wear glasses and some have a beard. Having 22 expressions guarantees to have enough expressions to build the expression space and to test. Subjects were shown 22 pictures of expressive face of the same person and were instructed to perform a series of 22 facial expressions by copying the displayed expressions as closely as possible. These 22 expressions are blended emotional expressions with various intensities. The 22 expressions have been manually labeled with one of the 6 basic categories of emotions [1]. Expression 1–4 were labeled as four kinds of anger, 5–7 disgust, 8–11 joy, 12–13 fear, 14–18 surprise and 19–22 sadness (see Fig. 12
                        ). The differences between expressions are due to the intensity of the expression (for example, a higher intensity of joy for the expressions 8–10), or are due to the mixture of emotion (for example, expression 11 is a mixture of joy and surprise). Even if the subjects were instructed to perform a series of 22 facial expressions by copying the displayed expressions as closely as possible, the expressions are not identical. For instance, some subjects have the mouth opened whereas other do not for the same expression (see expression 7 on Fig. 1). Moreover, some subjects showed difficulties with reproducing some expressions, so that some expressions are very closed (see expressions 12 and 13 or 11 and 17 in Fig. 12).

This section presents the experimental results of the recognition of 14 unknown blended expressions on known subjects. For each subject, 8 expressions are known and used to compute the models in both AAM based and organization based methods. First, the impact of the dimensionality of the manifold is studied. Then, the impact of the type of features (shape and/or texture) is analyzed. And finally, the recognition results of OBM are compared to traditional AAM based methods (ABM and DABM).


                           Fig. 13
                            shows the recognition results of OBM for each of the 14 unknown expressions according to the dimensionality of the manifold. We can notice that the dimensionality of the manifold does not have a big influence on the recognition results. These results show that 4 non-zero components (dimensionality of the manifold equal to 3 plus intensity) are enough to characterize an expression with OBM.

Contrary to appearance features, the organization of expressions and the direction–intensity signature are robust to the type of input data.


                           Impact of the type of data on the organization of the expressions. To evaluate the impact of the shape versus the texture, we have computed the organization of expressions and the distribution of the similarity index with only shape parameters, only texture parameters and both shape and texture parameters. The exact same organization of expressions has been found with only shape parameters and both shape and texture parameters 
                              
                                 
                                    
                                       
                                          Q
                                          
                                             
                                                
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         s
                                                      
                                                      
                                                         shape
                                                         +
                                                         texture
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         s
                                                      
                                                      
                                                         shape
                                                      
                                                   
                                                
                                             
                                          
                                          =
                                          1
                                       
                                    
                                 
                              
                           . The organization found with only texture parameters differs by only 2 substitutions of one edge 
                              
                                 
                                    
                                       
                                          Q
                                          
                                             
                                                
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         s
                                                      
                                                      
                                                         shape
                                                         +
                                                         texture
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         s
                                                      
                                                      
                                                         texture
                                                      
                                                   
                                                
                                             
                                          
                                          =
                                          0.88
                                       
                                    
                                 
                              
                            and can thus be considered as similar according to the analysis that has been done in Section 4.2 where two organizations were considered similar when Q has greater than 0.8.


                           Impact of the type of data on recognition rate. Appearance based methods are very sensitive to the type of data used. ABM and DABM applied on our database show that adding texture information decreases the recognition rate by around 16% on ABM and 19% on DABM (see Fig. 14
                           ). Contrary to our results, the experiments of Cheon and Kim on Diff-AAM [24] show that adding texture information improves the recognition results of both AAM and Diff-AAM. This can be explained by the fact that our database has a larger variety of subjects compared to theirs (which contains only Korean people) and that the texture features then carry too many information of the identity of the subjects (such as beard, skin color, and lip color) to be relevant and comparable between subjects. Our results can also be compared to the work of Martin et al. [41]. They used MLP-based classifier and SVM-based classifier on an approach based on AAM and compared the recognition rate on shape features and on shape and texture features. They achieve best results by adding texture features. A reason for this could be that the MLP-based classifier and the SVM-based classifier learn the different kinds of morphology during the training phase. These comparisons underlines the fact that ABM and DABM recognition results vary a lot according to the type of data and are highly dependent on the learning database.

With our method OBM, the recognition rates are lightly impacted by having texture information or not, in addition to the shape. Fig. 15
                            shows the recognition results of OBM based firstly on shape features and secondly on shape and texture features according to the dimensionality of the manifold. We can notice that a dimensionality of the manifold over 3 gives a recognition rate on 14 unknown expressions between 55.9% and 61.4% independently the type of features taken into account (shape or shape and texture). On these experiments, the recognition rate with OBM varies less than 3%.


                           Impact of the type of data on the direction–intensity signature. As the organization is robust to the type of data, the signatures found from shape features, from texture features or from shape and texture features have close values. This point is attested by Table 1
                            which shows the recognition results on 14 expressions with OBM where the signatures of the training phase are learnt on one type of data and the signatures of the testing phase are computed on another type of data. These results show that the type of data of the training and the testing phase does not have a big influence on the recognition results.

This robustness can be analyzed by the fact that shape and texture features are correlated and that, contrary to appearance based methods using AAM vectors (ABM and DABM), the parameters of the signature of OBM have a meaning that is known by construction: one expression is in between n others (where n is the dimensionality of the manifold).

This subsection compares the recognition results of the organization based method OBM on known subjects with AAM based methods. Fig. 16
                            compares the previous results of OBM (best recognition rate of 61.4% with shape features and 60.5% with shape and texture features) with the recognition rate of ABM and DABM according to the dimensionality of the AAM vectors.

We first can notice that DABM clearly outperform ABM with an increase around 10%, confirming the work of Cheon and Kim [24].

We can also notice that OBM outperform the recognition rate of DABM no matter the dimensionality of the manifold and no matter the type of features (shape or shape and texture) taken into account. The best recognition rate is 61.4%. The increase is 7.6% compared to the best recognition rate obtained with DABM. These results show that the position of one expression to the others is more relevant information to qualify an expression than the absolute position of this expression and confirm that the expressions are organized in the same way between different subjects.

This section compares the experimental results of the recognition of 22 expressions on unknown subjects computed with appearance parameters (ABM and DABM cf. Section 3.2) and and with direction–intensity signature (AOBM cf. Section 5.3). A leave-one-subject-out method on the subjects has been used in both cases. The results are presented with and without the voting algorithm.


                        Table 2
                         shows the results of AOBM according to the dimensionality of the manifold. As with OBM, the results are stable for a dimension over 3. As expected, the voting algorithm increases the recognition results.


                        Table 3
                         shows the results of ABM, DABM and AOBM. The voting algorithm clearly improves the recognition results for all the methods. The best results are obtained with AOBM which increases the best recognition results of DABM by 1.3% with the voting algorithm and by 4.9% without the voting algorithm. The best recognition rate of AOBM is 45.9%. For comparison, chance would lead to a recognition rate of 4.5% (1 expression out of 22).


                        Fig. 17
                         shows the confusion matrix on the direction–intensity signatures with AOBM. We can notice that the confusion mostly appears when the expression corresponds to the same kind of emotion. For some expressions, we experienced the classical confusion between Anger and Disgust and between Fear and Surprise [42].

@&#CONCLUSION@&#

This paper has presented a new invariant representation of facial expressions and hence a new approach for facial expression analysis. The representation is based on the organization of facial expressions. One expression is then defined by its relative position to the others, so that any new unknown expression has a unique signature (the system deals with the completeness of expressions). To answer the required flexibility, the proposed method has first been applied to known subjects and was then extended to unknown subjects by creating a person-specific appearance space compliant with the morphology of the subject. The proposed method shows better performance in expression recognition than a traditional AAM based method. PCA techniques for creating an expression space are very sensitive to underlying data distribution, and what are the major variations in it. In our method, the person-specific feature spaces are built with the same kind of expressions (similar expressions) and the same number of expressions, whether it is a real or an assumed feature space, so that we do not encounter these problems. Contrary to AAM based methods, this method is robust to the type of data (shape and/or texture features), the parameters are meaningful and few parameters are needed to characterize an unknown blended expression. The recognition rate of 45.9% may seem low and with no practical use. Yet, in a real system, the expression is computed for each image of a video sequence and is integrated in time with a minimum period of 1s (that is around 30 images). The information is then accurate enough to detect the emotion of the subject. In the future, we will extend the method to spontaneous affective video sequences and deal with neutral face detection.

@&#ACKNOWLEDGMENT@&#

This research has been conducted with the support of REPLICA (ANR Techsan).

@&#REFERENCES@&#


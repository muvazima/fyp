@&#MAIN-TITLE@&#Effects of extended lay-off periods on performance and operator trust under adaptable automation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We examined the effects of lay-off period and reliability in adaptable automation.


                        
                        
                           
                           We took measures of trust, automation reliance, performance, and workload.


                        
                        
                           
                           There was no skill decay after the extended lay-off period.


                        
                        
                           
                           Operator trust was influenced by system reliability but not by lay-off period.


                        
                        
                           
                           Automation reliance was unaffected by lay-off period and reliability.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Lay-off period

Skill retention

System reliability

Adaptable automation

Trust

@&#ABSTRACT@&#


               
               
                  Little is known about the long-term effects of system reliability when operators do not use a system during an extended lay-off period. To examine threats to skill maintenance, 28 participants operated twice a simulation of a complex process control system for 2.5 h, with an 8-month retention interval between sessions. Operators were provided with an adaptable support system, which operated at one of the following reliability levels: 60%, 80% or 100%. Results showed that performance, workload, and trust remained stable at the second testing session, but operators lost self-confidence in their system management abilities. Finally, the effects of system reliability observed at the first testing session were largely found again at the second session. The findings overall suggest that adaptable automation may be a promising means to support operators in maintaining their performance at the second testing session.
               
            

@&#INTRODUCTION@&#

Automation is becoming a common work partner in various domains, such as aviation, industrial process control, or information retrieval. It frequently replaces human activities of various forms, such as acquiring and analysing data, making decisions, implementing or monitoring processes (e.g., Parasuraman et al., 2000). Its benefits are widely recognised, for instance in terms of performance and safety (Lee and See, 2004), but automation may also present drawbacks, including reduced situation awareness, increased complacency, out-of-the-loop problem, and a potential loss of critical skills caused by a lack of engagement with task management (Wickens et al., 2004). In addition to the problems associated with automation use, there are other factors that may be detrimental to operator performance, such as not operating a system for a long period of time (e.g., Arthur et al., 1997), The problems associated with extended lay-off periods may represent new challenges if operators are simultaneously faced with the task of managing highly automated systems.

The regular practice of skills plays an important role in maintaining performance levels. Therefore, performance decrements are often observed when skills cannot be practised for a prolonged period of time, a phenomenon referred to as deskilling, skill decay, or skill loss (e.g., Wiener, 1988, cited in Wickens et al., 2004). There is plenty of evidence for skill decay as a direct consequence of an extended lay-off period in lab-based research with various foci, including memory (e.g., Roediger et al., 2010), motor control (e.g., Savion-Lemieux and Penhune, 2005), and solving complex mathematical problems (e.g., Kwon et al., 2005). Procedural tasks seem to be particularly affected by extended lay-off periods (e.g., Annett, 1979; Hagman and Rose, 1983; Anderson et al., 2011). This apparently inexorable skill decline over time has been examined in various work areas, including medical work (e.g., Einspruch et al., 2007), watchkeeping skills on ship's bridges (O'Hara, 1990), military assignments (e.g., Rose et al., 1984; Sanders, 1999; Schendel and Hagman, 1982), and periods of unemployment (e.g., Edin and Gustavsson, 2008).

Some research aimed at real-world domains has attempted to model the complexity of real work environments by using multi-task simulations in a lab-based context. In a study using a spaceflight simulation called ‘Space Fortress’, it emerged that, after 4 weeks of non-practice, operator performance decreased (Arthur et al., 1997). A simulation of a chemical plant was employed in another study, which showed that performance decreased with increasing duration of the lay-off period, using retention intervals of about 1 week, 2 months, and 6 months (Duncan, 1971). Interestingly, the observed performance decrements were limited to operators with low task abilities, suggesting that the level of operators' general task competence can modify the effect of lay-off period.

A particular advantage of using multi-task simulations is that it also allows the identification of task-dependent differences. A study using a process control simulation showed that a lay-off period of 8 months resulted in performance decrements in certain tasks (e.g., fault diagnosis) while performance improvements were observed in others (e.g., manual system control, Sauer et al., 2000). Such counterintuitive improvement may appear in very well practiced tasks which are less sensitive to an extended lay-off period (Rose, 1989). The study also showed that the effects observed over the skill retention period were affected by the training regime received. Arthur et al. (2010) observed similar influences of training schedule design on skill decay for operators managing a simulation of modern naval warfare. Although having received the same amount of practice, operators in the concentrated training condition (i.e., 10 h over five consecutive days) showed weaker performance than operators in the extended training condition (i.e., 10 h over two weeks).

In order to reduce skill decay during lay-off periods, overlearning of skill (i.e., continuous practice of a skill although the required performance level is already reached) has been successfully applied (e.g., Schendel and Hagman, 1982). Similarly, refresher training (i.e., an additional training session between the initial training and the testing phase) has been found to be an effective measure to maintain skill levels (e.g., Kluge and Frank, 2014). The literature suggests that effective training methods help operators develop critical skills to complete the tasks without major performance decrements, supporting Duncan's (1971) finding about the criticality of operators' skill levels (i.e., only operators with low skill level suffered from performance decrements during the lay-off period). It also suggests that a prolonged skill retention interval represents a risk to performance maintenance but other factors, like operator training and operators' general task competence, may abate any such risks.

The problem of skill maintenance also plays an important role in the design of automation. Even if operators managed a highly automated system for a period as short as 2 h, skill decline can already be observed as soon as operators have to return to manual control (Manzey et al., 2012). Automated systems may have positive and negative effects on skill maintenance. On the one hand, the use of automation may result in loss of skill because operators cannot practise their skills if the automatic system carries out the task. On the other hand, operators who have lost skills due to long periods of non-practice (whether caused by automation or not) may benefit greatly from support by the automatic system to complete the task (e.g., a driver rarely using a car is likely to feel more appreciative of the parking assist system). The first of these two situations may be referred to as the ‘loss of skill’-problem (Wickens et al., 2004); the second as showing benefits of ‘human-machine teamwork’. Both issues are relevant in automation design. Therefore, it is important to design automation such that the “skill loss” problem is minimised, while the benefits of human-machine teamwork are maximised.

Different models have been developed to provide guidance in automation design. Sheridan and Verplank (1978) proposed a model with ten incremental levels of automation (LOA) representing the spectrum of human-machine task allocation. Operators receive no support from automation at LOA 1, whereas tasks are fully automated at LOA 10. Parasuraman et al. (2000) introduced a model addressing which stages of information processing are automated. They distinguished four stages, namely information acquisition (IAC), information analysis and display (IAD), action selection (AS) and action implementation (AI); the automation of each stage can be of different level. Similar to Parasuraman et al., Wickens et al. (2010), (see also Onnasch, 2015; Onnasch et al., 2014) proposed a classification of automated systems based on their degree of automation (DOA). DOA takes both LOAs and stages of information processing into consideration to determine how intensively a system is automated. For instance, a system automated at a high level in the early stages could present a similar DOA to a system automated at low level in the later stages. The choice of a certain LOA or DOA determines the task allocation between the human and the machine. According to the literature, medium levels of automation may be best suited to reduce skill loss since they provide the best outcomes when operators have to return from automated to manual control (e.g., Endsley and Kaber, 1999; Lorenz et al., 2002; Manzey et al., 2012).

The above findings were all observed under static automation (i.e., the task allocation between the human and the machine remained invariable over time, Sheridan, 2002) with operators working at the same support level (i.e., the same LOA/DOA) across the working session. The question arises as to whether operators would benefit from more flexible automation. In such automation design, the authority to change task allocation is given either to the human operator or to the system (adaptive automation, Scerbo, 2006). In comparative studies, adaptable automation provided better outcomes for performance (in the control of unmanned vehicles, Kidwell et al., 2012) and for non-performance measures (e.g., more active control of the system by the operator and higher self-confidence, Sauer et al., 2012) than adaptive automation. Adaptable automation may be advantageous for compensating some skill decay since it can provide very quick support when operators increase the level of automation (e.g., change from full manual control to full automated control). Furthermore, it can reduce uncertainty about system behaviour (Miller and Parasuraman, 2007) because in contrast to adaptive automation (where changes in automation levels are sometimes difficult to anticipate and understand by operators) such problems are usually not encountered by operators when using adaptable automation. Furthermore, it may reduce the negative effects of strain through more operator discretion in system management because theories in work psychology point out the advantages of leaving some discretion to the operator in the task completion (e.g., Karasek and Theorell, 1990). More operator discretion is clearly offered under adaptable automation than adaptive automation.

According to Wickens et al. (2004), operators are more inclined to rely on automation than on their own skills when they trust it. In the context of automation, trust may be defined as “the attitude that an agent will help achieve an individual's goals in a situation characterised by uncertainty and vulnerability” (Lee and See, 2004, p.51). Few studies have investigated the evolution of trust over time. Lee and Moray's (1992) study required participants to manage a central heating simulation supported by an automated support system 60 times over three days. Results showed that acute (i.e., one-time) system failures produced an instantaneous but also short-lived drop in trust, whereas a prolonged decrease in trust was observed during the chronic (i.e., prolonged) failure. Similarly, Riley (1996) showed in a series of experiments that, by measuring automation use, uncertainty and automation reliability have an impact on operator trust. Participants were asked to complete two tasks simultaneously for 1 h, aligning a marker with a target location and categorising a character (the latter can be automated). Uncertainty was manipulated by increasing the frequency of characters that did not belong to any answer categories, while the frequency of wrong automatic categorisation determined automation reliability. Results showed an increased use of automation when uncertainty rose and a decreased use of automation when reliability diminished. Furthermore, participants continued to use automation after automation failures. Other studies have shown that low system reliability produces a decrease not only in trust but in performance (e.g., Bailey and Scerbo, 2007; Chen and Barnes, 2012; Ma and Kaber, 2007; Rovira et al., 2007; Wiegmann et al., 2001).

For adaptive and adaptable automation, there are fewer studies available in the literature but they provide very similar results. In a study using adaptive automation in a central heating simulation, operators in the 100%-reliability condition showed better performance under automation than under manual control, whereas the opposite pattern was observed in the low-reliability conditions (Moray et al., 2000). A study examining adaptable automation in a complex process control simulation also showed the expected positive association between performance and system reliability (Chavaillaz et al., 2015). However, other research has shown a dissociation of the two measures, with trust ratings being affected but not performance (Dzindolet et al., 2003; Manzey et al., 2012), or conversely (Rovira et al., 2007).

One possible reason for the inconsistency of the relationship between trust, reliability and performance may be due to the role of self-confidence in modifying the interplay of these factors (see Lee and Moray, 1994). When operators had high self-confidence and believed they could perform better than the automatic system, they preferred manual over automatic control (Lee and Moray, 1994). Conversely, operators relied more strongly on automatic control when their trust in automation exceeded their self-confidence. Because of this complex interplay, determining operator use of automation requires the measurement of performance, trust, and self-confidence.

The present study aims to examine the effect of prolonged non-practice of skills on performance and other important variables (notably trust) during the use of a complex simulation of process control. It also aims to investigate to what extent reduced system reliability will aggravate possible skill decrements resulting from an extended lay-off period. Using a simulated work environment incorporating varying degrees of automation allowed us to examine whether the availability of adaptable automation would prevent decrements of operator performance.

Operators were given the task of managing a complex process control simulation, called AutoCAMS (Automated Cabin Air Management System), during two (identical) testing sessions, separated by approximately 8 months. They were primarily asked to monitor the system to detect the occurrence of technical problems. When such faults were detected, they had to diagnose them, while manually stabilising the system. In addition, a prospective memory task and a probe detection task were to be completed. Since different priority levels are assigned to operator tasks, this offers the opportunity to measure workload, in the form of secondary task performance. This is important because it has been argued that, in complex work environments, high work demands affect performance on secondary tasks more strongly than primary tasks (Hockey, 1997). In addition, to obtain a better understanding of operators' mental state, subjective measures of trust, self-confidence and workload were taken. The influence of system reliability on trust was examined by implementing three different reliability levels (60, 80, and 100%; see Ma and Kaber, 2007; Wiegmann et al., 2001). These levels reflected the proportion of misdiagnoses suggested by the support system during fault scenarios (i.e., faults are detected but incorrectly diagnosed), and were kept constant in the two testing sessions.

The AutoCAMS simulation used was similar in its basic structure to the one used by Sauer et al. (2000) in their experiment on skill retention, in which they also used an 8-month retention interval. Therefore, this earlier experiment serves as a reference study. However, there are also some differences between the simulations used in the two studies. The present simulation provided operators with an automated support system to help them diagnose system faults. In contrary to previous research, which has typically only allowed for a binary choice (manual vs. automation), operators could freely choose between five incremental levels of automation of the support system. The first LOA provided no support to operators; LOA2 supported information acquisition; LOA3, information analysis and display; LOA4, action selection; and LOA5, action implementation (Parasuraman et al., 2000).

The experimental design allowed us to investigate changes in performance and use of automation over an extended time period, and to examine the influence of reliability. This is of particular interest since as yet no study has empirically examined the effects of system reliability over an extended lay-off period. Finally, the present simulation offered a larger range of LOAs (LOA 1–5) than previous research, which has typically only allowed for a binary choice (manual vs. automation).

Parts of the data set of the present study have been published elsewhere (Chavaillaz et al., 2015). While the first publication was concerned with the data collected at the first testing session (focusing on the effects of automation reliability and time on task), the present article examined changes between testing sessions separated by an extended lay-off period.

Since the literature provides little guidance about the impact of system reliability after an extended lay-off period, the present study is largely of an explorative nature. On the basis of related research, hypotheses can still be derived concerning the effects of extended lay-off period and reduced system reliability.

According to the skill retention literature (e.g., Duncan, 1971), we expected that performance and skill levels would be lower in the second testing session and that the prolonged lack of practice would also reduce operator self-confidence in their abilities to complete their primary tasks manually. If operators believed that automation performance would be better than their own (reflected by high trust ratings), they would use a higher LOA to prevent performance decrements (e.g., Moray et al., 2000).

We also expected that performance and trust in automation would reflect the level of system reliability (i.e., the lower system reliability is, the lower performance and trust ratings will be, e.g., see Bailey and Scerbo, 2007; Ma and Kaber, 2007; Rovira et al., 2007). However, the opposite pattern will be observed for self-confidence, secondary task performance, and perceived workload. Automation failures will force operators to use their own skills, which would then increase their self-confidence in system management (e.g., see Moray et al., 2000). Furthermore, poorer secondary task performance would be expected under less reliable systems than under more reliable systems A similar pattern will be found for perceived workload (e.g., see Onnasch et al., 2014).

@&#METHOD@&#

28 student participants (7 females), aged from 18 to 31 yrs (M = 22.5, SD = 2.6), took part in the study. They were required to have a background in science or engineering to ensure a comparable technical competence as real process control operators. Participants received CHF 180 (about € 150) for their participation.

@&#EXPERIMENTAL DESIGN@&#

A mixed 2 × 3 design was used in this study. Lay-off period was varied as a within-subjects factor (first versus second testing session) while level of system reliability (high, medium, low) was a between-subjects factor.

A simulation of a complex process control task, called AutoCAMS (e.g., Sauer et al., 2012), was used to model a life support system of a space shuttle. Representing a generic process control task, this PC-based simulation environment was developed over many years by different research groups (e.g., Hockey et al., 1998; Lorenz et al., 2002; Manzey et al., 2008). The version of the simulation employed in the present study allowed for adaptable and adaptive automation to be modelled (Sauer et al., 2013). The main interface of the simulation is presented in Fig. 1
                        .

The operator's primary responsibility was to maintain the air quality in a space shuttle by monitoring the following five parameters: CO2, O2, pressure, temperature, and humidity (see Fig. 1A). Under normal functioning, each parameter was maintained within a predefined target range by automatic controllers. When a system fault occurs (e.g., a leak in an oxygen pipe), participants were asked to diagnose and fix any such fault as fast as possible and, at the same time, to stabilise the system through manual control of the subsystems (Fig. 1B). A fault was characterised by a parameter deviating from its target range or presenting an unusual pattern. To help participants in their primary tasks, they received a manual with step-by-step procedures for making the correct diagnosis. These procedures required them to check different information such as the flow meter readings and the technical symbols representing the working of different subsystems (see Fig. 1C). Furthermore, participants were asked to perform two secondary tasks: prospective memory and probe detection. The former involves the recording of the current N2 tank level at 1-min intervals (see Fig. 1D). The latter consists of acknowledging the connection between space shuttle and ground control by clicking as fast as possible on a symbol (“transmission control” icon), which appears at fairly regular intervals (on average every 30 s, see Fig. 1E).

Finally, the lower right quadrant displays the support system, named Automated Fault Identification and Recovery Agent (AFIRA, Fig. 1F). This system offers assistance to the operator during the occurrence of a system fault. The assistance is offered at 5 levels (based on the task allocation model of Sheridan and Verplank, 1978), which can be freely selected by the operator to fit best his/her needs for task completion (i.e., free choice in automation level selection). At LOA1, the support system provides no support to the operator; at LOA2, the support system indicates the occurrence of a system fault (IAC stage); at LOA3, the support system proposes a diagnosis (IAD stage); at LOA4, a procedure to remedy to the failure is added to the diagnosis proposition (AS stage); finally, at LOA5, the system proposes a diagnosis and executes the proposed procedure if the operator accepts it (AI stage).

Operator skills and knowledge about the system were measured by a purpose-built questionnaire at the end of the training and after each testing session. Comprising four parts, the questionnaire was based on Sauer et al. (2000)'s questionnaire on AutoCAMS knowledge, measuring operator knowledge of (1) the content and priorities of different operator tasks, (2) fault management procedures, (3) the function of each LOA, and (4) the impact of system faults on specific cabin air parameters. Participants could obtain a maximum score of 29 points.

Automation management was measured by three dependent variables: (a) the average LOA chosen during system faults was used to quantify the degree of assistance required by participants; (b) the stability of LOA selection was measured by the frequency of LOA changes; (c) the frequency of use of the different manual controllers per minute served to index the preference for manual control activity.

Five measures of operator performance were taken during system faults, distinguishing between primary and secondary tasks. For the primary tasks, two indicators of diagnostic performance were measured: (a) the percentage of correctly diagnosed faults (i.e., fault identification accuracy) and (b) the time needed by the operator to order the correct repair (i.e., fault identification time). The third measure of primary task performance was (c) the stability of system state (or system control performance), which represents the percentage of time that any parameter deviated from its target range. For the secondary tasks, (d) the reaction time to report N2 tank level readings served as a measure of prospective memory performance, and (e) for probe detection, the frequency was measured of participants failing to acknowledge on time the connection between ground control and the space shuttle (i.e., percentage of omissions).

Operator trust in automation was measured by two questionnaires. The Checklist of Trust between People and Automation (CTPA) is a 12-item questionnaire (Jian et al., 2000) using a 7-point Likert rating scale (not at all – totally agree). An item example is “I can trust the system”. Participants filled in this questionnaire twice during each experimental session to detect changes in trust over the course of the operational scenarios. In the present study, the internal consistency of the scale was excellent (Cronbach's alpha = .97). A more elaborate scale, the Human Computer Trust (HCT) questionnaire (Madsen and Gregor, 2000), comprised 25 items which also had to be rated on a 7-point Likert scale. The items cover five facets of perceived trust toward automation (perceived understandability, perceived technical competence, perceived reliability, personal attachment, and faith). An item example is “I believe advice from the system even when I don't know for certain that it is correct”. The internal consistency in the present study was also excellent (Cronbach's alpha = .97). According to Madsen and Gregor, substantial experience with a technical system increases the instrument's validity. Therefore, the HCT was administrated only once, which was at the end of the experimental session.

Two questions, adapted from Lee and Moray's (1994) questionnaire on trust and self-confidence, were used to measure operator self-confidence in their ability to manage the two primary tasks: “How confident were you in your fault diagnosis (very little – a great deal)?”, “How confident were you in manually controlling the system parameters (very little – a great deal)?”

The NASA-TLX (Hart and Staveland, 1988) served as an indicator of operator workload. It contains 6 items (mental demand, physical demand, temporal demand, performance, frustration, and effort). In the present study, the internal consistency of the scale was good (Cronbach's alpha = .82).

The three experimental conditions of system reliability differed in the percentage of correct diagnoses suggested by the automated support system, AFIRA. In the high-reliability condition (100%), the support system always provided the operator with the correct diagnosis in all ten fault scenarios. In the medium-reliability condition (80%), the second and seventh fault scenario was misdiagnosed. In the low-reliability condition (60%), four fault scenarios (2nd, 4th, 7th, and 9th) were incorrectly diagnosed. To ensure that the incorrect diagnoses were plausible, each had a symptom pattern that showed a close match to the actual system fault (e.g., a block in the N2 valve was diagnosed as a leakage in the N2 valve). This made the detection of failures of the support system more challenging.

@&#PROCEDURE@&#

After being welcomed in the laboratory, participants were told that the primary aim of the study was to investigate how human participants manage complex technical systems. They were informed that the experiment consisted of three sessions (one for training and two for testing). The first testing session was separated from training by a one-week interval while there was a lay-off period of about 8 months between the first and the second testing session.

The 3-h training session (with a 15-min break) covered all technical aspects of system management. Up to four participants were trained together each working on their own computer. Experience gained form previous experiments with AutoCAMS (e.g., Sauer et al., 2012) was used to calculate the duration of the training session. Six system faults (i.e., leak in the O2 valve, block in the N2 valve, heater stuck on, CO2 scrubber inefficient, dehumidifier stuck on, and malfunction of the N2 sensor) were practised twice during the session. To help the operator in his/her fault management, a fault-diagnosis manual was provided that explained in a step-by-step procedure how to correctly diagnose a fault. The fault scenarios were first presented in full manual control (i.e., LOA 1) to allow participants to learn how to manually manage the different subsystems. Afterwards, the fault scenarios were presented for a second time and participants were given the opportunity to practise these by using the four other levels of automation. To develop a high level of trust in the support system, each diagnosis proposed by AFIRA was correct (i.e., participants experienced a perfectly reliable support system during training). At the end of the session, both trust questionnaires (CTPA and HCT) and the self-confidence scale were filled in by participants. This was to test whether we obtained similar trust level across all participants and to collect baseline measures of each variable. Furthermore, a questionnaire was administrated to assess operator knowledge about the functioning of the simulation, as detailed above.

The approximate duration of each testing session was 2.5 h (with a 15-min break). The first session consisted of two blocks. Five fault scenarios (three were practised during training and two were novel – i.e., unpractised – ones) were presented in each 39 min block. The order of fault presentation in each block is displayed in Table 1
                           . In the high-reliability condition, the support system proposed a correct diagnosis for each fault scenario, whereas in the medium-reliability condition the second scenario of each block was misdiagnosed by AFIRA. In the low-reliability condition, AFIRA also failed in the second and fourth scenario.

At the beginning of the first block, participants were reminded again of the four tasks and their priority gradients. Furthermore, it was stressed that the automation levels of the support system could be switched at any time throughout the session. Participants were informed that the support system AFIRA might fail occasionally throughout the testing session, but no indication about its exact reliability was provided. At the end of each block, participants filled in NASA-TLX, CTPA, and the self-confidence scale. The HCT was completed only once at the end of the testing session. Participants could also refer to the fault-diagnosis manual at any time during the testing session.

The procedure of the second testing session was identical to the first, including the order of fault scenarios and the questionnaires to be filled in. The only difference was that participants were asked to complete a 3 min warm-up before the testing session to refresh their knowledge of the AutoCAMS environment.

A mixed two-factorial analysis of variance (ANOVA) was carried out to determine the influence of lay-off period (2 levels) and support system reliability (3 levels). Degrees of freedom were adjusted according to Huynh-Feldt correction, if necessary, and multiple comparisons according to Bonferroni correction.

To check that levels of operator trust, as a critical experimental variable, did not differ prior to completing the experimental sessions, two questionnaires on trust towards automation (CTPA and HCT) were administered at the end of the training session. ANOVA confirmed that there were no significant differences in trust between reliability conditions, Mlow = 5.1, Mmedium = 5.0, Mhigh = 5.1, FCTPA(2,25) < 1, and Mlow = 4.8, Mmedium = 4.6, Mhigh = 4.91, FHCT(2,25) < 1, respectively. As expected, a high level of trust toward automation was achieved at the end of training for all participants. To ensure that a sufficient level of expertise was achieved at the end of the training, operator filled in a questionnaire assessing their skills and knowledge about the system (see above). The results showed that participants developed high skill levels during training (25.1 points out of 29). An ANOVA confirmed that there was no significant differences in skills between reliability conditions, F(2,25) = 1.39, p > .05 (Mlow = 24.3, Mmedium = 26.3, Mhigh = 24.8).

@&#RESULTS@&#

Participants showed a lower skill level at the end of the second testing session (see Table 2
                        ), F(1,25) = 5.38, p < .05, η2
                        partial = .18. However, neither the interaction effect, nor the main effect of reliability was significant, both F's < 1.

As the data in Table 2 and Fig. 2
                            show, participants used a rather high LOA throughout both testing sessions, i.e., before and after the lay-off. The results also indicated that the LOA chosen was highly stable across testing sessions, resulting in the main effect of lay-off period being not significant, F(1,25) = .19, p > .05, η2
                           partial = .01. The interaction between lay-off period and reliability was not significant either, F(2,25) = .19, p > .05, η2
                           partial = .02. No difference between the three conditions of system reliability was observed, F(2,25) = 1.16, p > .05, η2
                           partial = .09.

The prolonged lay-off period did not affect the frequency of LOA changes between sessions, F(1,25) = 3.18, p > .05, η2
                           partial = .11 (see Table 2). The interaction between lay-off period and reliability was not significant either, F(2,25) = .89, p > .05, η2
                           partial = .07. However, the difference between reliability levels proved to be significant, F(2,25) = 4.76, p < .05, η2
                           partial = .28 (see Fig. 2). Multiple comparisons between means showed that only a system with a low-reliability level (M = 1.0) caused participants to change LOA significantly more often than a high-reliability system (M = 0.2), t(14.81) = 3.24, p < .05, r2 = .41. The medium-reliability condition was not significantly different from the two others (M = 0.5).

Participants used significantly more frequently manual control in the first (M = 2.4) than in the second testing session (M = 1.8), F(1,25) = 8.55, p < .01, η2
                           partial = .26 (see Table 2). However, there was no interaction between lay-off period and system reliability, F(2,25) = .23, p > .05, η2
                           partial = .02. Finally, system reliability significantly influenced the participant's manual use of controls, F(2,25) = 4.90, p < .05, η2
                           partial = .28. Multiple comparisons between means showed that participants working under a high-reliability system (M = 1.3) used significantly less often manual control than participants under a system of medium reliability (M = 2.6), t(15) = 3.29, p < .05, r2 = .44. The low-reliability group (M = 2.2) did not differ from the other groups.

As the data in Table 2 shows, no deterioration of fault identification accuracy was observed across testing sessions, F(1,25) = .07, p > .05, η2
                           partial = .00. There was no interaction between lay-off period and reliability, F(2,25) = 1.00, p > .05, η2
                           partial = .07, although as would be expected with higher system reliability, more faults were correctly diagnosed, F(2,25) = 15.88, p < .001, η2
                           partial = .56. Multiple comparisons revealed participants with a highly reliable system correctly identified significantly more faults (M = 98.1) than participants with a system of low or medium reliability level, respectively t(15.06) = 6.68, p < .001, r2 = .75 and t(13.89) = 3.11, p < .05, r2 = .40. Furthermore, participants in the medium-reliability group (M = 87.2) identified more faults than did participants in the low-reliability group (M = 77.7), t(17.59) = 2.81, p < .05, r2 = .31.

Between the two testing sessions, there was no difference in the time needed by participants to diagnose a system fault (see Table 2), F(1,25) = 2.57, p > .05, η2
                           partial = .09. Furthermore, there was no interaction between the two factors, F(2,25) = 1.60, p > .05, η2
                           partial = .11. Again, as would be expected, the more reliable the system, the faster the fault was diagnosed by participants (Mhigh = 70.6, Mmed = 127.0, Mlow = 181.8). This effect was highly significant, F(2,25) = 22.88, p < .001, η2
                           partial = .65. Multiple comparisons revealed that the high-reliability group identified faults significantly faster than the low and medium-reliability groups, respectively, t(17) = 7.33, p < .05, r2 = .76 and t(15) = 3.21, p < .05, r2 = .41, while the medium-reliability group was significantly faster than the low-reliability group, t(18) = 3.26, p < .05, r2 = .37.

The system was more frequently disturbed during the second testing session than during the first (see Table 2). This decrease in system control performance was significant, F(1,25) = 5.57, p < .05, η2
                           partial = .18. The decrement in performance was not affected by system reliability, with the interaction between lay-off period and system reliability being not significant, F(2,25) = 1.70, p > .05, η2
                           partial = .12. The main effect of system reliability was not significant either, F(2,25) = 1.1, p > .05, η2
                           partial = .08.

The reaction time data for the prospective memory task are presented in Table 2. There was no significant difference between testing sessions, F(1,25) 3.31, p > .05, η2
                           partial = .12. The analysis did not reveal an interaction between lay-off period and system reliability either, F(2,25) = .23, p > .05, η2
                           partial = .02. However, system reliability influenced prospective memory performance, F(2,25) = 6.84, p < .01, η2
                           partial = .25. Multiple comparisons between means revealed that participants in the medium-reliability group (M = 3.8 s) needed significantly more time to log the N2 tank level than the low and the high-reliability groups (Mlow = 2.5 s and Mhigh = 2.1 s), respectively t(17.54) = 2.86, p < .05, r2 = .32 and t(14.10) = 3.89, p < .05, r2 = .52.

Overall, participants did not detect 9.1% of probes on time during a fault scenario (see Table 2). The analysis did not reveal a main effect of lay-off period, F(1,25) = .34, p > .05, η2
                           partial = .01. There was no interaction between lay-off period and reliability, F(2,25) = 1.10, p > .05, η2
                           partial = .08. Finally, no effect of system reliability was found, F(2,25) = .97, p > .05, η2
                           partial = .07.

Overall, the trust level for the 12-item questionnaire was well above the scale average (M = 4.9 on a 7-point scale). The data in Table 2 shows that a prolonged lay-off period did not modify trust ratings, F(1,25) = .03, p > .05, η2 = .00. There was no interaction between lay-off period and system reliability, F(2,25) = .05, p > .05, η2 = .00. However, trust ratings dropped as would be expected when system reliability decreased, F(2,25) = 8.00, p < .005, η2 = .39. Multiple comparisons between means showed that participants rated a perfectly reliable system as more trustworthy (M = 5.9) than systems with lower reliability levels (Mlow = 4.2, Mmedium = 4.7), t(14.81) = 4.45, p < .005, r2 = .57 and t(14.09) = 2.8, p < .05, r2 = .37.

This questionnaire showed similar results to the CTPA. Neither the main effect of lay-off period (see Table 2) nor the interaction between lay-off period and system reliability were significant, F(1,25) = 1.53, p > .05, η2
                           partial = .06, and F(2,25) = .54, p > .05, η2
                           partial = .04, respectively. However, a significant effect of system reliability was observed, F(2,25) = 5.97, p < .01, η2
                           partial = .32. Multiple comparisons revealed that trust for the high-reliability group (M = 5.7) was significantly higher than for the low reliability group (M = 4.2), t(17) = 3.56, p < .01, r2 = .43. There was no significant difference between the other pairwise comparisons. This main effect of reliability was observed for each subscale, all F's > 3.9, p < .05, η2
                           partial > .23, except for the subscale ‘faith’, F(2,25) = 1.02, p > .05. Neither the main effect of lay-off period, nor the interaction was significant for any of the subscales.

In contrast to trust, self-confidence ratings were found to be lower in the second testing session than in the first (see Table 2). This decrease in self-confidence was statistically significant, F(1,25) = 31.42, p < .001, η2
                           partial = .56. There was no significant interaction, F(2,25) = .37, p > .05, η2
                           partial = .08. Although a significant main effect of system reliability was found for self-confidence (Mhigh = 7.7, Mmedium = 6.4, Mlow = 6.4), F(2,25) = 3.88, p < .05, η2
                           partial = .24, none of the pairwise comparisons was found to be significant (all t's < 2.7). When analysing each item separately, the measures of fault diagnosis and manual control displayed the same pattern (i.e., both showed a significant main effect of lay-off period).

The overall levels of workload were slightly below the mid-point of the scale (M = 8.1), indicating that participants experienced a meaningful degree of challenge, though task demands were not excessive. The extended lay-off period did not influence operator workload as the data in Table 2 demonstrate, F(1,25) = .75, p > .05, η2
                        partial = .03. Furthermore, there was no interaction between lay-off period and system reliability, F(2,25) = .65, p > .05, η2
                        partial = .05. Although workload seems to decrease with increasing system reliability (Mhigh = 6.6, Mmed = 8.1, Mlow = 9.4), this difference did not reach significance, F(2,25) = 2.52, p > .05, η2
                        partial = .17. A separate analysis of each item revealed no significant effects.

@&#DISCUSSION@&#

The main goal of the present study was to investigate the impact of an extended lay-off period on operator performance, automation management and trust when using an adaptable automatic system. Although operator knowledge about the system decreased at the second testing session, they managed the system rather efficiently in both testing sessions across the different reliability levels. System control was the only performance measure that indicated a decrement during the second testing session. Operator self-confidence decreased at the second testing session and so did the number of manual control actions. Finally, trust ratings and automation reliance were unaffected by extended skill lay-off.

While in the skill retention literature a principal concern has been the risk of performance decrements after an extended lay-off period, in the present study most performance measures did not show any decrements (i.e., diagnostic speed, diagnostic accuracy, probe detection, and prospective memory showed considerable stability). Only system control performance deteriorated. This is an interesting finding for two reasons. First, it represented an encouraging result that, after an 8-month lay-off period, only one out of five performance indicators deteriorated and the decrement observed in control performance was far from being dramatic (decrease of about 15%). This is important against a background which suggests much more dramatic decrements even after rather short lay-off periods (e.g., Duncan, 1971). Second, in some ways the present study provided similar findings to the reference study (Section 1.4, Sauer et al., 2000), which employed the same task environment and lay-off period. This earlier study also found only very limited performance decrements, but an important difference between the two studies emerged. It was system control performance that showed a decrement in the present study rather than diagnostic performance; in the reference study performance decrements were observed for diagnostic speed (by about 20%) but none for system control.

An explanation might be found in the strategies participants used to compensate for the risk of skill decay, which appeared to be influenced by the introduction of automation in work environments. As there was no automatic support available for fault diagnosis in older versions of AutoCAMS, participants in the reference study might have decided to stabilise the system first (via a more frequent use of manual controllers), and then to engage in fault diagnosis and repair. This may have increased fault identification time. In contrast, due to the availability of highly automated support system, priorities in primary task management might have been different in the present study. Although it was emphasised during training that fault diagnosis and maintaining stability had similar priorities, participants seemed to have focused on fault diagnosis first, and then to stabilise the system via multiple control actions, and this may have resulted in a faster stabilisation. That participants were more preoccupied with making the correct diagnosis is consistent with the reduction of manual activity observed in the second testing session. The availability of the support system may also have alleviated decrements in diagnostic speed since participants do not have to go through a complex procedure; remembering step-by-step procedures after extended time periods represents a difficult task for human operators (Hagman and Rose, 1983; Rose, 1989). Overall, introducing an automated support system might have had direct positive effects on certain primary tasks (i.e., diagnostic performance) but, at the same time, produced negative side-effects on others (i.e., system stability).

The availability of a support system like AFIRA also raises the question of how it is used after a retention interval. Contrary to our hypotheses, the findings showed that operator use of the AFIRA support system did not change as a function of lay-off period: no increase in automation reliance and frequency of changes in LOA were observed between testing sessions. The absence of any change in these measures suggests that the compensatory potential of adaptable automation was not used by participants during the second testing session (e.g., by increasing LOA to compensate for impending skill decrements). It is also conceivable that participants were reluctant to change LOA frequently, since it would draw their attention away from their chief tasks in a critical situation (i.e., a system fault to manage). This is consistent with concerns in the literature that adaptable automation requires additional mental resources by adding another task (i.e., deciding whether to change LOA or not, e.g., Kaber and Riley, 1999; Bailey et al., 2006). The temporal stability of the automation reliance measures supports the argument that durable behavioural norms have been formed during training, which determines the operator's future reliance on the automatic system (Chavaillaz et al., 2015). A further factor may have also contributed to the high level of stability in participants' use of automation. Automation use was already characterised by high LOA during the first testing session (on average 3.8 out of a maximum of 5), which obviously limited the possibility to increase LOA in the second session. It is therefore difficult to judge whether adaptable automation was considered useful by participants in compensating for loss of skill as a consequence of the long lay-off period.

Participants overall opted for a rather high LOA, but they never used automation to its full potential. This finding was in the line with previous work showing better performance in manual control for operators previously working with a system that is not fully automated (e.g., Endsley and Kaber, 1999; Lorenz et al., 2002; Manzey et al., 2012). Furthermore, this finding suggests that participants appreciated the advantages this particular level provides, i.e., the master alarm, the decision selection regarding the diagnosis, and the related course of action. However, they preferred to implement manually the appropriate repair and stabilisation actions to keep control of the situation (automation at LOA 5 can automatically implement support system recommendations), and consequently balance automation costs and benefits (Manzey et al., 2012). Furthermore, similar to previous work (e.g., Lee and Moray, 1994; Muir and Moray, 1996), this result may suggest that participants were able to assess separately the reliability of each piece of information provided by the support system. They made good use of the fully reliable information (fault occurrence [IAC], parameter affected [IAD], and course of action [AS]), but carefully processed the potentially incorrect information (diagnosis [AI]). Opting for a medium LOA seemed therefore the most obvious choice since it provided each type of information while leaving the complete control of the simulation in operator hands.

The temporal stability in automation management was paralleled by stable trust ratings. Despite the importance of trust in automation management, no research has examined effects of system reliability on trust after a prolonged lay-off period. The present study showed that participants did not change their trust ratings at the second testing session although they had not operated the system for an extended period of about 8 months. These results contradict the hypothesis (based on Moray et al. (2000)'s findings), which assumed an increase in operator trust toward the support system. This stability may reflect a high level of global trust (indicated by the generally high level of LOA selected) in the support provided by the automation which, apart from the diagnostic facility, provided useful information. This may have counterbalanced the propensity for compensating a decrease in self-confidence by an increased reliance on external help.

Finally, as hypothesised, the system knowledge of the operator significantly decreased at the second testing session, though this difference was rather small (around 1.5 points). One explanation may be found in the experimental procedure in which operator knowledge were assessed after the testing session. Managing the system during the second testing session was likely to have updated operator knowledge. A larger decrease in knowledge might have been observed if knowledge had been measured prior to the second testing session.

In addition to the issues surrounding the impact of skill lay-off, the present study also provides evidence about the impact of support system reliability on performance and trust ratings. This was in line with our hypothesis. The results also largely confirmed the findings from the first testing session (Chavaillaz et al., 2015). It is also important to note that none of the measures showed a significant interaction between lay-off period and reliability, indicating that both subjective trust ratings and the majority of performance measures were stable between both testing sessions. Both measures were positively associated with system reliability. The findings confirmed the influence of support system reliability on performance and trust ratings observed in previous studies (e.g., Bailey and Scerbo, 2007; Rovira et al., 2007).

The results for workload did not show such effects. The hypothesis for perceived workload was not confirmed, because the higher level of workload observed under low reliability was not significant. Similarly, no clear effects of system reliability were found on secondary task performance, which may also be considered an objective indicator of operator workload. While no effect of reliability was recorded for probe detection, an effect describing a curvi-linear relationship between system reliability and prospective memory performance was observed, with performance being lowest for medium reliability whereas no difference occurred between low and high reliability. This pattern may reflect the inconsistent results observed in the literature for objective workload measures (as reported in a meta-analysis by Onnasch et al., 2014). This issue needs therefore to be investigated in more details in future research.

Contrary to our expectations, self-confidence was not affected by automation reliability in a linear fashion. In the present study, higher ratings were found in the fully reliable automation condition than in the two others (see also Rovira and Parasuraman, 2010). It was an unexpected finding that self-confidence did not grow with increasing practice of managing automation failures. It may be that participants still found automation failures difficult to manage and their experience of having to do so may not have convinced them that they were as well prepared as participants who had never had that experience. It is a rating of their own confidence to be able to complete the tasks and may not necessarily correspond to their actual competence in managing the system. This implies that facing difficult working condition such as automation failures may have negative effects on operator self-confidence because it may increase awareness of their own limitations in system management.

@&#LIMITATIONS@&#

The study has a number of limitations. First, the positive and negative effects of adaptable automation are based on indirect evidence (i.e., by comparing current results with those of Sauer et al., 2000) since a direct comparison using a control group working without automation was not possible due to the small number of participants. As the reference study bears considerable similarity with regard to the methodological approach (including a very similar task environment), we nonetheless feel that tentative conclusions are justified. Second, the sample size was rather small (due to drop-outs during the lay-off period), which may have underestimated the effects of lay-off and reliability considering that significant results showed at least medium effect sizes. Third, a randomisation of the order of presentation of automation failures between blocks is likely to have reduced the operators' chance of noticing any regularity in the pattern of fault occurrence. Finally, it is acknowledged that an additional measurement of participants' skill, self-confidence, and trust prior to the beginning of the second testing session would have strengthened the conclusions of the present study.

@&#CONCLUSION@&#

The present results have implications for automation design and training in process control environments. Providing participants with adaptable automation may have prevented decrements in diagnostic performance in the second testing session and ensured that no increases in operator workload occurred, as it was suggested by stable levels of secondary task performance and subjective workload measures. However, automation designers need to be aware of possible long-term side-effects of adaptable automation since it may reduce operator self-confidence in system management, their capability for manual system control, and the propensity to engage in manual control activities as observed in the present study. These unwanted side-effects may be reduced by providing appropriate refresher training to operators, if they are confronted with an extended lay-off period. Furthermore, the present findings confirm the overall preference of operators for using partially, rather than fully, automated systems (e.g. Parasuraman and Manzey, 2010). This may maximise automation benefits (i.e., support in fault management) while minimising its costs (i.e., unstable system state resulting from misdiagnosis). There are a number of issues that future research may look at. It may compare performance under manual and automatic control after the lay-off period to provide more evidence about the impact of adaptable automation on operator behaviour. Moreover, measuring trust toward automation after each fault scenario may provide a more fine-grained understanding of its long-term dynamic, especially after a lay-off period. Further research may also explore whether adaptive automation might result in better performance than adaptable automation, since decisions on LOA changes would be the responsibility of the support system.

@&#ACKNOWLEDGEMENTS@&#

The financial support for this research was generously provided by the Swiss National Science Foundation (No 100014_134566). Thanks are also due to Elisabeth Aman and Ilka Roessler for their help with data collection.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Unsupervised visual hull extraction in space, time and light domains

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Background likelihood estimation based on temporal pixel intensity analysis.


                        
                        
                           
                           A new type of filtering that preserves edges in a signal.


                        
                        
                           
                           Information fusion from different domains and its integration into an MRF.


                        
                        
                           
                           An implementation framework capable of producing VH for highly challenging situations.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Shape from silhouette

Multi-view image segmentation

Multi lighting

Visual hull

Graph cut

@&#ABSTRACT@&#


               
               
                  This paper presents an unsupervised image segmentation approach for obtaining a set of silhouettes along with the visual hull (VH) of an object observed from multiple viewpoints. The proposed approach can deal with mostly any type of appearance characteristics such as texture, similar background color, shininess, transparency besides other phenomena such as shadows and color bleeding. Compared to more classical methods for silhouette extraction from multiple views, for which certain assumptions are made on the object or scene, neither the background nor the object appearance properties are modeled. The only assumption is the constancy of the unknown background for a given camera viewpoint while the object is under motion. The principal idea of the method is the estimation of the temporal evolution of each pixel over time which provides a stability measurement and leads to its associated background likelihood. In order to cope with shadows and self-shadows, an object is captured under different lighting conditions. Furthermore, the information from the space, time and lighting domains is exploited and merged based on a MRF framework and the constructed energy function is minimized via graph cut. Experiments are performed on a light stage where the object is set on a turntable and is observed from calibrated viewpoints on a hemisphere around the object. Real data experiments show that the proposed approach allows for robust and efficient VH reconstruction of a variety of challenging objects.
               
            

@&#INTRODUCTION@&#

The reconstruction of an object’s geometry from multiple images is still a challenging problem in computer vision. This problem, also referred to as multi-view geometry, consists of processing a set of 2D images of an object, taken from several viewpoints, in order to produce an interpretation of its geometrical structure. In the real world, object interaction with light involves many effects such as: shadows, self-shadows, color bleeding, light inter-reflection, transparency, subsurface scattering and others. All these phenomena influence the object’s appearance in the captured image, and as a result, its analysis is not trivial in the general case.

At some point, the reconstruction process involves the segmentation of the object and the background in all images, resulting in a set of silhouettes. The aim of our work is to obtain these silhouettes automatically in the more general case, that is: without any assumption about object appearance or structure. For this objective a roboticized system was designed. It allows the rotation of an object on a turntable, the control of the lighting conditions around an object and the selection of the camera viewpoint on a hemisphere as illustrated in Fig. 1
                     . Since images can be captured from any viewpoint on the hemisphere above the object, it is practically not possible to model the background at the pixel level before positioning the camera even if the viewpoints are calibrated. It is also not possible to exploit an active background for all possible viewpoints, like in [1]. Instead we address the problem with a more fundamental approach where the object moves while the camera remains static at each viewpoint. Moreover, we exploit the possibility to change the – unknown – lighting conditions in the scene. Thus, the only assumption for any type of object and background is that background pixels should, more or less, remain constant while the object is moving and is being observed from a given viewpoint. In contrast to classical approaches where the background model is known a priori and a camera is fixed [2,1] or object photometric consistency between views is requested [3,4], the proposed approach makes it possible to address very difficult situations such as transparent objects.

Controlling the lighting conditions also helps in interpreting the silhouettes since low intensity areas will change their location in the image and it will be possible to correctly analyze these areas when they are well illuminated. Nevertheless, phenomena such as color bleeding from the object to background could lead to misinterpretation of background pixels. In this case, the combination of the silhouettes captured from several viewpoints into a visual hull (VH) will be a minimal 3D interpretation to eliminate such view-dependent effects.

The basic experiment takes place under the following conditions: the object is put on a turntable and the camera is stable. The turntable is rotated and, each time, an image of an object is captured under several lighting conditions. Then all the captured images are grouped by light sources and each group is processed as a time sequence. The difference between images in one group is characterized by the motion of an object and its interaction with the light. Based on these observations and the constant background assumption, the background likelihood at each pixel is estimated by our method. Finally, the resulting background likelihood is used to compute the object’s silhouette and the process is repeated for another viewpoint.

The key idea of the method is to examine the evolution of each pixel over time. The pixels for which the intensity is stable with respect to their temporal neighbors are more likely to belong to the background, while pixels whose intensities vary are more likely to belong to the foreground due to object motion. It can be observed in Fig. 2
                     (a) that the intensity of each pixel (blue curve) in the intervals from 0 to 140 and from 240 to 359 is similar to that of its temporal neighbors. These constant intervals correspond to our expectation of background behavior. On the other hand, the intensity signal in the interval from 140 to 240 is not stable, the value of each point is different from that of its temporal neighbors and such a signal is assumed to correspond to an object. These observations are reflected in the estimated stability signal (red curve). When the intensity signal is stable and uniform, the value of the estimated background likelihood is high, while in the other case it is low.

One of the key features of the experimental setup that has to be emphasized is the possibility to switch on and off light sources. This procedure helps the method to cope with shadows present in the scene and, for that reason, the background likelihood is estimated for different lighting conditions (see Fig. 2(a) and (d)). In addition we show the benefits of switching on light sources sequentially instead of turning all of the light sources on simultaneously. More generally, the acquisition process switches between steps in time and light changes. In the latter case, no spatial neighborhood is defined but we still consider the processing over a volume of images, parameterized in time and light source index.

The ideas stated above are integrated into a Markov Random Field (MRF) optimization framework, and the optimization is performed through graph cut. This optimization framework makes it possible to further consider spatial neighborhood in images. The proposed approach will thus produce a set of silhouettes along with a visual hull from the simplest to the most difficult situations.

The contributions of our work are:
                        
                           •
                           The temporal analysis of a pixel intensity signal which leads to automatic estimation of background likelihood. The processing of this signal also integrates a new type of filtering that preserves edges in a signal.

The fusion of information from different domains such as multiple space, time, light conditions and its integration into an MRF framework.

The practical implementation of a general framework capable of producing visual hulls as a first step in multiview geometry for various and highly challenging situations.

The paper is organized as follows: in Section 2 an overview of the related work is given. Section 3 introduces the hypothesis and notation used in the paper. In Sections 4 and 5 the details of the estimation of background and object likelihoods as well as the segmentation framework are presented. In Section 6 some experiments are described and results are demonstrated. In the last Section we conclude and propose a direction for future work.

@&#RELATED WORK@&#

@&#OVERVIEW@&#

The concept of VH was first introduced by Baumgart [5]. This concept is strongly linked to image segmentation into background and foreground, since the object’s silhouettes are required for VH construction. One of the classical and simplest techniques for silhouette extraction is chroma keying. The basic idea is to take a picture of an object against a uniform or known background, then by using color thresholding or background subtraction, a silhouette of an object is obtained. This approach was formally described in [6]. This idea is often used in 3D reconstruction systems for silhouette extraction [1,7]. Even though this method is easy to implement and provides fairly good results, there are some drawbacks. First the environment must be modified in order to set up the background. This limits possible camera placement on a hemisphere since the background has to be visible from all viewpoints. Second, an object part with the same color as the background may create holes in the object’s silhouette.

Chroma keying was extended in several works with an active background system such as in [1,8]. As an active background, authors set up several monitors around an object and capture images with and without an object with different patterns. Such an approach allows color bleeding to be addressed and enables the extraction of an alpha matte of an object. However this approach suffers from its lack of flexibility, i.e. the active background system as well as cameras are always fixed. In contrast, in our method we state that the background is constant, which allows a camera to be positioned freely on any point on a hemisphere and does not require a reference image (without an object) to be captured.

Another group of algorithms with explicit background modeling is based on background subtraction. Good reviews can be found in [9–11]. In general, background subtraction techniques first build a background model of a scene and then find pixels that do not fit the model and classify them as foreground. The major drawback of these methods is the requirement of an explicit estimation of the background. This requirement forces the background model to be updated every time the position of the camera is changed, which is impractical.

Active lighting based approaches make it possible to directly estimate the geometry of an object without silhouette estimation. These methods can be classified into several subcategories: range scanners, structured light and photometric stereo. Laser range scanning [12] and structured light [13] are limited in the type of materials that can be scanned since they may perform poorly on shiny and transparent surfaces or materials with low albedo.

An interesting active lighting approach for recovering object geometry is photometric stereo [14,15]. One of the particularities of these types of methods is an explicit assumption about the reflectance model of an object. As a result, applying this method to an object whose reflectance does not satisfy a simple diffuse model proves to be less reliable. We consider that photometric stereo may be used as a complementary technique to Shape From Silhouette, in order to increase the quality of the reconstructed geometry.

Another aspect of the image segmentation field involves the use of initialization obtained from a user [16]. Here, the idea is to consider object segmentation as an energy minimization problem on a graph, and then apply a min-cut algorithm to find the global minimum. In order to construct an energy function, information about object location in the image is supplied by a user. An interactive approach was also used for silhouette extraction from multiple views in [17]. While it requires user interaction in only one image in order to estimate object and background color models and outputs fast and qualitative result, the method is able to produce robust results only for a single color object. In contrast to these methods, we focus on automatic estimation of object and background likelihoods for a general type of object.

Semi-automatic image segmentation in a single image by graph cut was extended to automatic silhouette extraction in multiple views in [18,19]. The main difference between these methods is that in [18], energy minimization is performed on a 3D volume and in [19], energy is minimized on individual images. Although these methods may work well, there is still one disadvantage: the requirement of explicit color modeling of an object and background. Thus if the same color belongs to the object and background model, the result may lead to over- or under- silhouette estimation. In our work, we try to avoid explicit color modeling of an object and background in order to overcome this limitation.

As was mentioned above, there are many methods that build a color model of an object and background based on different initialization procedures. These models are used to estimate object and background likelihood distributions. For the case where only a single image is available, an initialization procedure such as tri-map or rectangle is normally used [16,20,21]. In the case where several images or a video sequence are available, initialization based on fixation point, background subtraction or stereo is used [18,22–24]. This initialization step allows the construction of object and background prior likelihoods based on a color model such as a Gaussian Mixture Model (GMM) or intensity histograms. Even though it is sufficient in many cases to model color distributions to obtain a qualitative result, in some situations this may lead to poor segmentation results. The main limitation of color modeling arises for the case where the object and background colors are very similar or mixed together in the color space, see Figs. 3 and 4
                        
                        . As a result, the information obtained at the initialization step is not accurate enough to discriminate the object from the background.

To demonstrate this issue, a GrabCut algorithm was used [25]. The experiments were performed on synthetic images (see Fig. 3), as well as on real images (see Fig. 4). The images were selected such that the color models of an object and background were mixed. These experiments demonstrate that segmentation may fail when color models of an object and background are mixed or very similar, and the result highly depends on the gradient inside the object region.

In Fig. 3(a), the body of a teapot has smoothly varying color without texture, however there is a strong gradient between the teapot’s body and its nose. Due to very similar object and background color model 3(c), the gradient between the object’s parts is interpreted as an edge between the foreground and the background, see Fig. 3(b). Furthermore, a few artificial lines were added to the body of the teapot in order to add extra gradient, see Fig. 3(d). As expected, due to insufficient dissimilarity between the object and background models, the strong gradient on the teapot’s body was used as a cutting edge in some places. With grayscale images, the quality of the segmentation is degrading. Due to the limited number of the possible intensity values, the histograms of an object and background are always mixed for a more or less complex scene. As demonstrated in Fig. 4(a) and (d), it is not possible to separate the object from the background based on the histogram, and there are many high gradient edges on the object itself. However, if more discrimination between the object and background is provided for the same scene by selecting sub-images, see Fig. 4(d)–(f), then the segmentation result improves. Our conclusion is that the use of color modeling for object and background likelihood may result in a poor segmentation when these models are mixed in a color space.

The key idea of our approach is the estimation of the background likelihood based on the single assumption that the background is constant although unknown and non-uniform. It is assumed that the position of the camera is fixed for a viewpoint, and the object changes its position in every frame. The total number of frames is defined as 
                        
                           
                              
                                 N
                              
                              
                                 T
                              
                           
                        
                     . An object is captured 
                        
                           
                              
                                 N
                              
                              
                                 L
                              
                           
                        
                      times under different lighting conditions located at different positions. Thus the total number of images acquired for an object is 
                        
                           
                              
                                 N
                              
                              
                                 T
                              
                           
                           ·
                           
                              
                                 N
                              
                              
                                 L
                              
                           
                        
                     . Since our method is independent from background modeling, it is also possible to change the camera position during image acquisition, and therefore to capture an object from a completely different view.

The captured image set is organized into a 4D volume. The dimensions of this volume are: 
                        
                           U
                           ,
                           
                           V
                           ,
                           
                           T
                        
                     , and L. U and V are spatial dimensions, they represent the image domain. The third dimension is time T, parameterizing object displacement. The last one is the lighting condition L, which defines different light sources. Thus 
                        
                           I
                           (
                           u
                           ,
                           v
                           ,
                           t
                           ,
                           l
                           )
                        
                      is the intensity of a pixel 
                        
                           (
                           u
                           ,
                           v
                           )
                        
                      at time t under lighting condition l. For notational convenience, we define two subvolumes of 
                        
                           I
                           :
                           
                              
                                 I
                              
                              
                                 L
                              
                           
                        
                      and 
                        
                           
                              
                                 I
                              
                              
                                 T
                              
                           
                        
                     . 
                        
                           
                              
                                 I
                              
                              
                                 L
                              
                           
                        
                      is a subvolume comprised of all the images for one object position, collected under all available lighting conditions, and 
                        
                           
                              
                                 I
                              
                              
                                 T
                              
                           
                        
                      is a subvolume comprised of all of the images with a fixed lighting but for multiple object positions. Also we define 
                        
                           
                              
                                 I
                              
                              
                                 ∗
                              
                           
                        
                     , which represents a single image frame, it is used to denote the structure of an image without referencing image intensity.

For clarity, we first describe how to handle data for a single light source, and then introduce the way to exploit data captured under multiple light sources.

Based on the hypothesis described in the previous Section, we give a simple definition for an object and background. A pixel can be called a background pixel if its intensity remains stable for a number of observations among all observations while the object is in motion. On the other hand, a pixel whose intensity deviates with respect to its temporal neighbors is more likely to represent an object pixel. The definition of the background pixel follows from the constant background assumption. The definition of an object pixel follows from the fact that during object motion, the relative normal of any point on an object changes with respect to the light source or a camera view or both, which is reflected in the deviation of pixel intensity.

The stated conditions of an object motion and constant background are satisfied in the 
                           
                              
                                 
                                    I
                                 
                                 
                                    T
                                 
                              
                           
                         subvolume, since the positions of the light source and camera are fixed. Based on our assumption, we develop a method which computes background likelihood for each pixel in 
                           
                              
                                 
                                    I
                                 
                                 
                                    T
                                 
                              
                           
                        .

In order to estimate background likelihood, we process all subsets of pixels along axis T from a subvolume 
                           
                              
                                 
                                    I
                                 
                                 
                                    T
                                 
                              
                           
                        . This is done in the following way: coordinates 
                           
                              u
                              ∈
                              U
                           
                         and 
                           
                              v
                              ∈
                              V
                           
                         are fixed and all the pixel values are collected along the T axis. These values form an intensity profile defined as:
                           
                              (1)
                              
                                 
                                    
                                       I
                                    
                                    
                                       T
                                    
                                 
                                 (
                                 u
                                 ,
                                 v
                                 )
                                 =
                                 X
                                 =
                                 {
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             T
                                          
                                       
                                    
                                 
                                 }
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         is the intensity value of a pixel at time i i.e. 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    I
                                 
                                 
                                    T
                                 
                              
                              (
                              u
                              ,
                              v
                              ,
                              
                                 
                                    t
                                 
                                 
                                    i
                                 
                              
                              )
                           
                        . This profile is depicted by a blue curve in Fig. 2.

The core idea of our algorithm is the estimation of the time stability of each pixel 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         in the intensity profile X. The stability 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         of each pixel is estimated by measuring the minimum standard deviation around each point. The smaller the deviation, the more stable the point is. The minimum deviation is measured as follows: for a given point 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ∈
                              X
                           
                         a window of size w is slid in a way that it always contains 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                        . A standard deviation is measured for each position of the sliding window. Finally, the smallest deviation is chosen, and characterizes the point’s stability. Formally, the measurement of 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         is defined as follows:
                           
                              (2)
                              
                                 S
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          min
                                       
                                       
                                          j
                                          ∈
                                          [
                                          i
                                          -
                                          w
                                          +
                                          1
                                          ,
                                          i
                                          ]
                                       
                                    
                                 
                                 
                                    
                                       σ
                                    
                                    
                                       w
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    σ
                                 
                                 
                                    w
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              )
                           
                         is the standard deviation calculated on subset 
                           
                              {
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    j
                                    +
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    j
                                    +
                                    w
                                    -
                                    1
                                 
                              
                              }
                           
                        . 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         describes the constancy of a point 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         in a region with size w.

Due to the absence of any prior knowledge about object geometry, the computation of 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         only does not guarantee a good result in a general case. Therefore, the background likelihood at each pixel from an intensity profile is estimated in two steps: time dependent and time independent. The necessity of the time independent step is dictated by the possibility that an object may contain holes or gaps between its parts. In such a case the points inside the intensity profile are mixed between object and background, (see Fig. 5
                        ). Thus, by sorting points according to their intensity, the background and object points are grouped separately. The idea of the time dependent step is to evaluate the local property of a point. It is possible that, at some positions, an object point may have the same color intensity as the background (see Fig. 6
                        (a) area marked by a green circle). In this case the result of the time independent step will not find an adequate value for 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                        . This situation is corrected at the time dependent step by measuring 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         inside the original intensity profile. The combination of these two steps leads to an accurate estimation of the background likelihood.

Let us formulate these steps precisely. First, at the time independent step, pixel values in the intensity profile X are sorted in ascending order based on their intensity:
                           
                              (3)
                              
                                 
                                    
                                       X
                                    
                                    
                                       s
                                    
                                 
                                 =
                                 sort
                                 (
                                 X
                                 )
                                 ,
                                 
                                 
                                    
                                       K
                                    
                                    
                                       ind
                                    
                                    
                                       s
                                    
                                 
                                 =
                                 arg
                                 (
                                 sort
                                 (
                                 X
                                 )
                                 )
                                 .
                              
                           
                        
                     

A new sorted profile is defined as 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                           
                         (Fig. 5, on the right, blue curve), and 
                           
                              
                                 
                                    K
                                 
                                 
                                    ind
                                 
                                 
                                    s
                                 
                              
                           
                         is a set of indices that establish a relationship for each element between X and 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                           
                         such that 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                              (
                              
                                 
                                    K
                                 
                                 
                                    ind
                                 
                                 
                                    s
                                 
                              
                              )
                              =
                              X
                           
                        . Once 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                           
                         is computed, the minimum standard deviation 
                           
                              
                                 
                                    S
                                 
                                 
                                    s
                                 
                              
                           
                         is calculated on 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                           
                         with a large window size 
                           
                              
                                 
                                    w
                                 
                                 
                                    g
                                 
                              
                           
                         using Eq. (2), see red curve on the right in Fig. 5. Finally, the estimated minimum deviation values are reordered based on the correspondence between X and 
                           
                              
                                 
                                    X
                                 
                                 
                                    s
                                 
                              
                           
                         (Fig. 5, red curve, on the left) and the estimated stability of the time independent step is obtained as follows:
                           
                              (4)
                              
                                 
                                    
                                       S
                                    
                                    
                                       g
                                    
                                 
                                 =
                                 
                                    
                                       S
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 
                                    
                                       K
                                    
                                    
                                       ind
                                    
                                    
                                       s
                                    
                                 
                                 )
                                 .
                              
                           
                        
                     

Let us note that the size of the window at the time independent step is always larger than the one at the time dependent step (
                           
                              
                                 
                                    w
                                 
                                 
                                    g
                                 
                              
                              >
                              
                                 
                                    w
                                 
                                 
                                    l
                                 
                              
                           
                        ). 
                           
                              
                                 
                                    w
                                 
                                 
                                    g
                                 
                              
                           
                         defines our expectation of the number of times the background can be observed at a certain pixel. Taking into account the constant background assumption and the sorting operation, it is expected that all background pixels will be grouped together on one side. Such an expectation allows us to choose a larger window size at this step to increase the robustness of the estimation.

An example of such a situation is illustrated in Fig. 5. The background in the intensity profile is partitioned into three parts: from 1 to 150, from 225 to 245 and from 250 to 360. Once the intensity profile is sorted, the background points become grouped together. This property allows 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         to be computed with a large window size and a reliable result to be obtained for most of the points. However performing such an estimation of 
                           
                              S
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         on an unsorted profile, for instance for point 
                           
                              
                                 
                                    x
                                 
                                 
                                    230
                                 
                              
                           
                        , leads to an incorrect result due to the mixing of object and background points.

We must note that estimating point stability in the time independent step is similar in a way to histogram computation. The amount of identical intensities can be used as a pixel stability measure, but it is more complicated to incorporate information from pixel neighbors in this case.

At the time dependent step, a similar procedure is carried out. It is applied directly to X and the minimum deviation 
                           
                              
                                 
                                    S
                                 
                                 
                                    l
                                 
                              
                           
                         with a small window size 
                           
                              
                                 
                                    w
                                 
                                 
                                    l
                                 
                              
                           
                         is estimated using Eq. (2) (see Fig. 6(b)). The parameter that influences the estimated result is the window size 
                           
                              
                                 
                                    w
                                 
                                 
                                    l
                                 
                              
                           
                        , which defines the size of the minimum motion that can be detected. For example, let us consider an object with a small hole. If the hole is visible less than 
                           
                              
                                 
                                    w
                                 
                                 
                                    l
                                 
                              
                           
                         times in the intensity profile during its motion, then the deviation in the intensity profile caused by switching between object and background is considered as a deviation in intensity due to object motion.

For real data, the presence of noise in the intensity profile is unavoidable. Since the idea is to estimate how stable each pixel in the image is, image noise adds extra deviation to the intensity at a pixel, and may thus affect the estimation of the background likelihood. We observe two aspects that may influence the level of noise. The first one is that the noise level depends on the measured intensity: the higher the intensity, the more noise is present in the signal. The second observation is that the noise level also depends on surface motion. The turntable is always moving and thus falls under the definition of an object but, since it was painted uniformly and is always rotated around its center in the same plane, it is considered as a component of the background. The non-uniformity of the paint, surface coarseness or non-perfect planar rotation introduces additional noise in the signal. The influence of the noise on the intensity profile is summarized in Table 1
                        . The first set of numbers (column 2) shows the standard deviation for different intensities and for stable and moving backgrounds. The second set (column 3) shows the standard deviation of the same data but only after filtering. From the Table, we observe that the amount of noise is reduced by 
                           
                              ≈
                              2
                           
                         times after filtering the signal for moving background, and more than two times for a stationary background (see last column).

To cope with noise and, at the same time, to avoid signal oversmoothing, we applied the following filter. Filtering is defined as a simple smoothing method based on the calculation of the minimum deviation. We measure the minimum deviation with a small window size 
                           
                              
                                 
                                    w
                                 
                                 
                                    s
                                 
                              
                           
                         (in the experiment we use 
                           
                              
                                 
                                    w
                                 
                                 
                                    s
                                 
                              
                              =
                              5
                           
                        ) using Eq. (2), and for each point 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ∈
                              X
                           
                         we compute not only a minimum 
                           
                              σ
                           
                        , but also the mean on the subset that gives this minimum deviation, the diagram of this procedure is shown in Fig. 7
                        (b). Then, the intensity value of 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         is replaced by the computed mean. This approach allows noise to be reduced and edges to be preserved in the intensity profile at the same time. Formally, the filtering operation can be formulated as follows:
                           
                              (5)
                              
                                 
                                    
                                       L
                                    
                                    
                                       ind
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 arg
                                 
                                    
                                       
                                          min
                                       
                                       
                                          j
                                          ∈
                                          [
                                          i
                                          -
                                          
                                             
                                                w
                                             
                                             
                                                s
                                             
                                          
                                          +
                                          1
                                          ,
                                          i
                                          ]
                                       
                                    
                                 
                                 (
                                 
                                    
                                       σ
                                    
                                    
                                       
                                          
                                             w
                                          
                                          
                                             s
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 )
                                 ,
                                 
                                 
                                    
                                       X
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       μ
                                    
                                    
                                       
                                          
                                             w
                                          
                                          
                                             s
                                          
                                       
                                    
                                 
                                 (
                                 
                                    
                                       L
                                    
                                    
                                       ind
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 )
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    L
                                 
                                 
                                    ind
                                 
                              
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         is the start index of the subset on X, and 
                           
                              
                                 
                                    μ
                                 
                                 
                                    
                                       
                                          w
                                       
                                       
                                          s
                                       
                                    
                                 
                              
                              (
                              k
                              )
                           
                         is the mean value calculated on the subset 
                           
                              {
                              
                                 
                                    x
                                 
                                 
                                    k
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    k
                                    +
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    k
                                    +
                                    
                                       
                                          w
                                       
                                       
                                          s
                                       
                                    
                                    -
                                    1
                                 
                              
                              }
                           
                         that corresponds to the minimum 
                           
                              σ
                           
                        . A few examples of the registered signal and the result of the filtering are shown in Fig. 7(a) and (c).

One may argue that a similar filtering result can be achieved by using a bilateral filter. A simple comparison of these two filters is presented in Fig. 8
                        . The result of the filters is very similar for regions with relatively small deviation, see Fig. 8(a). On the other hand, for regions with high frequency of intensity deviation, the results are different, see Fig. 8(b). The bilateral filter barely changes the original signal when high intensity deviation is present as opposed to the proposed filter which still smooths the input signal, since the computed mean value is used as an output. The new edge preserving filtering operation that preserves edges on a signal is thus one of the contributions of this work.

The whole algorithm for background likelihood estimation can be summarized as follows:
                           
                              1.
                              Input: subvolume 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             T
                                          
                                       
                                    
                                 .

Execute steps 3–8 for all 
                                    
                                       X
                                       ⊂
                                       
                                          
                                             I
                                          
                                          
                                             T
                                          
                                       
                                    
                                  such that 
                                    
                                       X
                                       =
                                       
                                          
                                             I
                                          
                                          
                                             T
                                          
                                       
                                       (
                                       u
                                       ,
                                       v
                                       )
                                    
                                  
                                 
                                    
                                       ∀
                                       u
                                       ∈
                                       U
                                    
                                  and 
                                    
                                       ∀
                                       v
                                       ∈
                                       V
                                    
                                 .

Apply smoothing filter to X to reduce noise and obtain 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             f
                                          
                                       
                                    
                                  using Eq. (2).

Sort all the points from the intensity profile to obtain 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             s
                                          
                                       
                                    
                                  and store the indices 
                                    
                                       
                                          
                                             K
                                          
                                          
                                             ind
                                          
                                          
                                             s
                                          
                                       
                                    
                                  that represent the relationship between 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             f
                                          
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             s
                                          
                                       
                                    
                                  using Eq. (2).

Estimate the time independent constancy 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             g
                                          
                                          
                                             +
                                          
                                       
                                    
                                  for each point from 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             f
                                          
                                       
                                    
                                  using Eq. (2), and normalize the result by corresponding pixel intensity. Thus 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             g
                                          
                                          
                                             +
                                          
                                       
                                    
                                  is computed as follows:
                                    
                                       (6)
                                       
                                          
                                             
                                                S
                                             
                                             
                                                g
                                             
                                             
                                                +
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          =
                                          
                                             
                                                
                                                   
                                                      min
                                                   
                                                   
                                                      j
                                                      ∈
                                                      [
                                                      i
                                                      -
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            g
                                                         
                                                      
                                                      +
                                                      1
                                                      ,
                                                      i
                                                      ]
                                                   
                                                
                                                
                                                   
                                                      σ
                                                   
                                                   
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            g
                                                         
                                                      
                                                   
                                                
                                                (
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      j
                                                   
                                                
                                                )
                                             
                                             
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          .
                                       
                                    
                                 
                              

Based on the correspondence between 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             f
                                          
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             s
                                          
                                       
                                    
                                 , reorder 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             g
                                          
                                          
                                             +
                                          
                                       
                                    
                                  so as to obtain 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             g
                                          
                                       
                                    
                                  using Eq. (4).

Estimate the time dependent constancy of each point in 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             f
                                          
                                       
                                    
                                  by computing 
                                    
                                       
                                          
                                             S
                                          
                                          
                                             l
                                          
                                       
                                    
                                  as follows:
                                    
                                       (7)
                                       
                                          
                                             
                                                S
                                             
                                             
                                                l
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          =
                                          
                                             
                                                
                                                   min
                                                
                                                
                                                   j
                                                   ∈
                                                   [
                                                   i
                                                   -
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         l
                                                      
                                                   
                                                   +
                                                   1
                                                   ,
                                                   i
                                                   ]
                                                
                                             
                                          
                                          
                                             
                                                σ
                                             
                                             
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      l
                                                   
                                                
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                j
                                             
                                          
                                          )
                                          .
                                       
                                    
                                 
                              

Compute background likelihood for each point in 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       ∈
                                       X
                                    
                                  as follows:
                                    
                                       (8)
                                       
                                          
                                             
                                                P
                                             
                                             
                                                B
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          =
                                          
                                             
                                                1
                                             
                                             
                                                exp
                                                (
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      l
                                                   
                                                
                                                (
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                                )
                                                +
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      g
                                                   
                                                
                                                (
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                                )
                                                )
                                             
                                          
                                          .
                                       
                                    
                                 
                              

Eq. (8) is such that it tends to 0 when 
                           
                              
                                 
                                    S
                                 
                                 
                                    l
                                 
                              
                              +
                              
                                 
                                    S
                                 
                                 
                                    g
                                 
                              
                              →
                              ∞
                           
                        , indicating that the point is inside a varying region and most likely belongs to an object; and it tends to 1 when 
                           
                              
                                 
                                    S
                                 
                                 
                                    l
                                 
                              
                              +
                              
                                 
                                    S
                                 
                                 
                                    g
                                 
                              
                              →
                              0
                           
                        , meaning that the point is inside a stable region and most likely belongs to the background.

When direct illumination does not light the turntable due to object occlusion, a shadow (relatively uniform area with low intensity) appears. While the object moves, the shadow follows it, thus violating the constant background assumption. Since shadows produce a moving region that follows an object, the resulting background likelihood decreases. In order to overcome this problem, we use several light sources located at different positions to better interpret the scene. A reasonable question arises here: why not use all the light sources at the same time in order to illuminate an object from all sides and thereby eliminate shadows. Fig. 9
                        (a) provides an answer. The object is illuminated non-uniformly if several light sources are used simultaneously. It would be beneficial to switch on all the light sources when it is possible to provide a uniform light distribution. Unfortunately it is not feasible to provide perfectly uniform lighting in a scene. In Fig. 9(a), the picture of the can is taken with all the light sources turned on, and some shadow penumbras caused by non-uniform distribution of the light are observed. On the other hand, a sequential use of the light sources located at different points affects an object’s shadow in a predictable way, and thus helps to cope with this effect (see Section 4.5).

When an object consists of shiny reflective material such as aluminum, it may reflect light on the turntable and change its appearance, see Fig. 9(b). This phenomenon is called color bleeding. It depends on several factors such as the position of the object, camera, and light source. The result of color bleeding is that a change in intensity is observed on a small area of the turntable near the object. The estimated background likelihood of the surface affected by color bleeding is close to 0 as this effect moves with an object and results in a deviation in intensity. Also when all the lights are on, the area affected is larger than in the case of a single light source, and thus may generate a larger area of false positive background likelihood.

A similar problem occurs with circular calibration markers on the turntable. Their color is different from the turntable and since they move with the turntable, the markers match with the definition of an object.

Although it is not possible to eliminate color bleeding based on the hypothesis of a stable background, it can be solved using multiple views by recovering the VH. The color bleeding is not consistent with different views. Therefore, during the intersection of the visual-cones obtained from object silhouettes, most of this effect will be eliminated. Analogously, markers do not have volume and physically do not intersect with an object. Therefore, they disappear during VH construction.

The estimation of background likelihood for each space–time volume 
                           
                              
                                 
                                    I
                                 
                                 
                                    T
                                 
                              
                           
                         was described above. If the scene is lit uniformly by global ambient light or only a single light source is switched on during the acquisition process, then it is enough to use Eq. (8) to compute the final background likelihood. However, if several directional light sources are exploited (as in our case), then a fusion process should be applied in order to incorporate information from different light sources. The difficulty of the fusion process is caused by contradictory estimations of background likelihoods from different light sources. For example, with one light source, some parts of an object can be in the shadow or self-shadow which results in a high value for background likelihood, and, under another lighting condition, the same part of an object can be fully illuminated and thus have a lower background likelihood. This is shown in Fig. 2, under light source 
                           
                              #
                              1
                           
                        , a point 
                           
                              
                                 
                                    p
                                 
                                 
                                    2
                                 
                              
                           
                         is assigned a high background likelihood due to shadows. However, under light source 
                           
                              #
                              2
                           
                        , the same point was assigned a low background likelihood since it was illuminated well by the source.

In order to choose an appropriate light source, we use a simple yet efficient rule. For a given view and pixel, we consider all the images under different lighting conditions, and for each pixel, we find the one that corresponds to the maximum intensity, see Fig. 10
                        (a). Based on the light source index that corresponds to maximum intensity, see Fig. 10(b), we calculate the background likelihood for each point in the UV space. This provides a good approximation of the background likelihood (Fig. 10(c)). The motivation behind this rule is that we want to make sure that, for a given light source, the pixel was illuminated well. However, such a rule may not always work well, for example, for some parts of a transparent object. Therefore, in addition, we consider several other light sources that illuminate the same pixel well and choose the one with the minimum likelihood. The final background likelihood is thus estimated as follows:
                           
                              (9)
                              
                                 
                                    
                                       P
                                    
                                    
                                       B
                                       
                                       final
                                    
                                 
                                 =
                                 
                                    min
                                 
                                 (
                                 
                                    
                                       P
                                    
                                    
                                       B
                                    
                                 
                                 (
                                 u
                                 ,
                                 v
                                 ,
                                 
                                    
                                       light
                                    
                                    
                                       ind
                                    
                                 
                                 )
                                 )
                                 ,
                              
                           
                        where 
                           
                              
                                 
                                    light
                                 
                                 
                                    ind
                                 
                              
                              =
                              
                                 
                                    arg
                                 
                                 
                                    l
                                 
                              
                              (
                              (
                              
                                 
                                    I
                                 
                                 
                                    L
                                 
                              
                              (
                              u
                              ,
                              v
                              ,
                              l
                              )
                              >
                              
                                 
                                    
                                       
                                          max
                                       
                                       
                                          img
                                       
                                    
                                 
                                 
                                    2
                                 
                              
                              )
                           
                         and 
                           
                              
                                 
                                    max
                                 
                                 
                                    img
                                 
                              
                              =
                              
                                 
                                    max
                                 
                                 
                                    l
                                 
                              
                              (
                              
                                 
                                    I
                                 
                                 
                                    L
                                 
                              
                              (
                              u
                              ,
                              v
                              ,
                              l
                              )
                              )
                           
                        .

The computation of the background likelihood is based on the idea that object pixels in an intensity profile are assigned a low background likelihood due to a high intensity deviation. This knowledge provides a clue on the object location in the image. Therefore, by selecting all the pixels whose values are close to 0 (smaller than a threshold R) in the background likelihood, we obtain an approximation of the object location. For these pixels, a small value f is defined in order to indicate that there is a possibility for an object and value 
                           
                              
                                 
                                    f
                                 
                                 
                                    10
                                 
                              
                           
                         is assigned to the remaining pixels. The object likelihood is estimated as follows:
                           
                              (10)
                              
                                 
                                    
                                       P
                                    
                                    
                                       O
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   f
                                                
                                                
                                                   :
                                                
                                                
                                                   
                                                      
                                                         P
                                                      
                                                      
                                                         B
                                                         
                                                         final
                                                      
                                                   
                                                   <
                                                   R
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         10
                                                      
                                                   
                                                
                                                
                                                   :
                                                
                                                
                                                   otherwise
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

In order to minimize the influence of color bleeding on the silhouette, we select the largest connected area with value f after the classification of 
                           
                              
                                 
                                    P
                                 
                                 
                                    O
                                 
                              
                           
                        , the rest is filled with 
                           
                              
                                 
                                    f
                                 
                                 
                                    10
                                 
                              
                           
                        . Such an heuristic often helps when the area affected by color bleeding is separated from an object. Even though this area would have low background likelihood, low object likelihood will be assigned to it as well. Such an approach often allows this area to be excluded from the silhouette during the energy minimization step as there is a high intensity gradient between the object and the turntable.

In the previous Section, the estimation of prior background and object likelihoods was described. Now the whole segmentation process is presented. The goal of segmentation is to assign to each pixel p from frame 
                        
                           
                              
                                 I
                              
                              
                                 ∗
                              
                           
                        
                      a label 
                        
                           
                              
                                 m
                              
                              
                                 p
                              
                           
                        
                      which can be the object or the background. Segmentation is addressed in an MRF framework. More precisely, it is performed by energy minimization of E through graph cut [16]. Formally,
                        
                           (11)
                           
                              E
                              (
                              M
                              )
                              =
                              λ
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       p
                                       ∈
                                       
                                          
                                             I
                                          
                                          
                                             ∗
                                          
                                       
                                    
                                 
                              
                              P
                              (
                              
                                 
                                    m
                                 
                                 
                                    p
                                 
                              
                              )
                              +
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       p
                                       ,
                                       q
                                       ∈
                                       N
                                    
                                 
                              
                              B
                              (
                              p
                              ,
                              q
                              )
                              [
                              
                                 
                                    m
                                 
                                 
                                    p
                                 
                              
                              
                              ≠
                              
                              
                                 
                                    m
                                 
                                 
                                    q
                                 
                              
                              ]
                              ,
                           
                        
                     where 
                        
                           P
                           (
                           
                              
                                 m
                              
                              
                                 p
                              
                           
                           )
                        
                      is the prior knowledge that each pixel belongs to the object and background; 
                        
                           B
                           (
                           p
                           ,
                           q
                           )
                        
                      is a boundary property of an image and reflects the strength of the connection between neighboring pixels; M is the set of all labels in an image frame 
                        
                           
                              
                                 I
                              
                              
                                 ∗
                              
                           
                        
                     , each element 
                        
                           
                              
                                 m
                              
                              
                                 p
                              
                           
                           ,
                           
                           
                              
                                 m
                              
                              
                                 q
                              
                           
                           ∈
                           M
                        
                      can be either background or object with values 
                        
                           {
                           0
                           ,
                           1
                           }
                           ;
                           λ
                        
                      controls the importance of prior knowledge versus boundary term (
                        
                           λ
                           ∈
                           [
                           0
                           ,
                           ∞
                           ]
                        
                     ); N is the neighborhood which defines connectivity between pixels (in our experiment we use 8 – neighboring connectivity).

The boundary term 
                        
                           B
                           (
                           p
                           ,
                           q
                           )
                        
                      characterizes the relationship between neighboring pixels. It can be considered as a penalty between two neighboring pixels. If pixels belong to the same object, then the difference in intensity between them has to be small, meaning that there is a strong connection. If p and q do not belong to the same object, then a greater gradient is expected to be present, and thus 
                        
                           B
                           (
                           p
                           ,
                           q
                           )
                        
                      should give a value close to 0, thereby forcing a max-flow algorithm to saturate an edge between these points.

We have multiple images of the same view but under different lighting conditions. Due to different locations of each light source, each image reveals different details. For example, the same point may be in the shadow in one image and, under another light source, may be illuminated well as shown in Fig. 2. Therefore, under one lighting condition, we could have a strong gradient, and under another light source, the gradient can be small and even null. Another reason to use all of the lighting in the boundary term is the absence of continuity in the lighting dimension in the 
                        
                           
                              
                                 I
                              
                              
                                 L
                              
                           
                        
                      subvolume. This means that if 
                        
                           
                              
                                 I
                              
                              
                                 L
                              
                           
                        
                      is compressed to one image for example by choosing only the maximum intensity for each pixel, continuity between pixel neighbors is lost and, as a result, some object edges may disappear.

In order to take into account this information, we modify the boundary term from [21]. For a given pair of pixels p and q, we use an average of the sum of the squared differences over all lighting conditions:
                        
                           (12)
                           
                              B
                              (
                              p
                              ,
                              q
                              )
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             L
                                          
                                       
                                    
                                 
                              
                              exp
                              
                                 
                                    
                                       -
                                       
                                          
                                             ‖
                                             
                                                
                                                   I
                                                
                                                
                                                   p
                                                   ,
                                                   i
                                                   ,
                                                   j
                                                
                                             
                                             -
                                             
                                                
                                                   I
                                                
                                                
                                                   q
                                                   ,
                                                   i
                                                   ,
                                                   j
                                                
                                             
                                             
                                                
                                                   ‖
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             2
                                             
                                                
                                                   γ
                                                
                                                
                                                   p
                                                   ,
                                                   q
                                                   ,
                                                   j
                                                
                                             
                                             
                                                
                                                   N
                                                
                                                
                                                   L
                                                
                                             
                                          
                                       
                                    
                                 
                              
                              ·
                              
                                 
                                    1
                                 
                                 
                                    D
                                    (
                                    p
                                    ,
                                    q
                                    )
                                 
                              
                              ,
                           
                        
                     where 
                        
                           
                              
                                 I
                              
                              
                                 p
                                 ,
                                 i
                                 ,
                                 j
                              
                           
                           =
                           I
                           (
                           
                              
                                 u
                              
                              
                                 p
                              
                           
                           ,
                           
                              
                                 v
                              
                              
                                 p
                              
                           
                           ,
                           
                              
                                 t
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 l
                              
                              
                                 j
                              
                           
                           )
                        
                      and 
                        
                           
                              
                                 I
                              
                              
                                 q
                                 ,
                                 i
                                 ,
                                 j
                              
                           
                           =
                           I
                           (
                           
                              
                                 u
                              
                              
                                 q
                              
                           
                           ,
                           
                              
                                 v
                              
                              
                                 q
                              
                           
                           ,
                           
                              
                                 t
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 l
                              
                              
                                 j
                              
                           
                           )
                        
                      are intensities for pixel p and q at time t under lighting 
                        
                           
                              
                                 l
                              
                              
                                 i
                              
                           
                           ,
                           D
                           (
                           p
                           ,
                           q
                           )
                        
                      is the Euclidean distance between two pixel sites, and 
                        
                           ‖
                           ·
                           ‖
                        
                      is L2-norm. 
                        
                           γ
                        
                      is constructed as an expected value over time for each connected pair of pixels. In this way 
                        
                           γ
                        
                      automatically adapts to each viewpoint, lighting condition and each pixel pair. As a result, shadow and background edges are almost absent from the boundary term compared to the case when 
                        
                           γ
                        
                      is constant for the entire image. The formulation of this term is another contribution of this work:
                        
                           (13)
                           
                              
                                 
                                    γ
                                 
                                 
                                    p
                                    ,
                                    q
                                    ,
                                    j
                                 
                              
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             T
                                          
                                       
                                    
                                 
                              
                              
                                 
                                    ‖
                                    
                                       
                                          I
                                       
                                       
                                          p
                                          ,
                                          i
                                          ,
                                          j
                                       
                                    
                                    -
                                    
                                       
                                          I
                                       
                                       
                                          q
                                          ,
                                          i
                                          ,
                                          j
                                       
                                    
                                    
                                       
                                          ‖
                                       
                                       
                                          2
                                       
                                    
                                 
                                 
                                    
                                       
                                          N
                                       
                                       
                                          T
                                       
                                    
                                 
                              
                              .
                           
                        
                     
                  

In case of 
                        
                           
                              
                                 γ
                              
                              
                                 p
                                 ,
                                 q
                                 ,
                                 j
                              
                           
                           =
                           0
                        
                      it is assigned the smallest 
                        
                           γ
                        
                      (but greater than zero) that was computed for the given light source.

The prior knowledge term 
                        
                           P
                           (
                           
                              
                                 m
                              
                              
                                 p
                              
                           
                           )
                        
                      in Eq. (11) defines a preference for pixel p to be object and background:
                        
                           (14)
                           
                              P
                              (
                              
                                 
                                    m
                                 
                                 
                                    p
                                 
                              
                              )
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      P
                                                   
                                                   
                                                      B
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      m
                                                   
                                                   
                                                      p
                                                   
                                                
                                                =
                                                0
                                             
                                             
                                                (
                                                background
                                                )
                                                ,
                                                
                                                obtained
                                                
                                                from
                                                
                                                Eq
                                                .
                                                
                                                9
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      P
                                                   
                                                   
                                                      O
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      m
                                                   
                                                   
                                                      p
                                                   
                                                
                                                =
                                                1
                                             
                                             
                                                (
                                                object
                                                )
                                                ,
                                                
                                                obtained
                                                
                                                from
                                                
                                                Eq
                                                .
                                                
                                                10
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

Finally, the energy from Eq. (11) is optimized through graph cut and the result of this optimization is a silhouette of an object for each view. Each view is calibrated, and it is thus possible to back project each silhouette in 3D space and obtain a union of visual cones H.
                        
                           (15)
                           
                              H
                              =
                              
                                 
                                    
                                       ⋃
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             T
                                          
                                       
                                    
                                 
                              
                              Pr
                              (
                              
                                 
                                    S
                                 
                                 
                                    i
                                 
                              
                              )
                              ,
                           
                        
                     where 
                        
                           Pr
                           (
                           
                              
                                 S
                              
                              
                                 i
                              
                           
                           )
                        
                      is a projection of the silhouette 
                        
                           
                              
                                 S
                              
                              
                                 i
                              
                           
                        
                      to 3D space. After back projecting all the silhouettes to 3D, we allow a 10% error, therefore an isovalue equal to 
                        
                           
                              
                                 N
                              
                              
                                 T
                              
                           
                           -
                           
                              
                                 N
                              
                              
                                 T
                              
                           
                           /
                           10
                        
                      is used. This allows a decision to be made for each voxel in H whether it is located inside or outside of the VH. This isovalue is further used to extract an object surface using the Matlab implementation of the marching cubes algorithm.

@&#EXPERIMENTS@&#

We performed two types of experiments: experiments under a single lighting condition and under multiple lighting conditions. The first group of experiments aims to demonstrate the possibility to apply the proposed method to the general case of moving object detection in a scene. The second group aims to demonstrate that the proposed method can reconstruct the VH of complex objects.

There are no special requirements for image acquisition, just common sense. The captured image must not be too dark (an object has to be distinguishable from the background), otherwise the intensity deviation between object and background will not be sufficient. Another requirement is that the background cannot be over-saturated otherwise, in some views, it could be indistinguishable from an object with high reflective properties (such as the cola can, see Figs. 14(g) and 17(g)).

The selection of the value of the two main parameters of the approach, the window size of the time dependent and time independent steps, needs to be discussed. The window size of the time independent step represents the background expectation i.e. the minimum number of frames where the background is not occluded by an object. This window size can be quite large since it is applied on the sorted sequence. It was set to 
                        
                           ≈
                           
                              
                                 
                                    
                                       N
                                    
                                    
                                       T
                                    
                                 
                              
                              
                                 3
                              
                           
                        
                     , meaning that we expect to see the background in at least one third of the views for each pixel. The second parameter is used to estimate local properties of an object and it can be described as the minimum interval between two object points. It means that if there is a hole or gap between two object parts that is visible and is less than the window size, then these background points will be assigned a high background likelihood. Basically, this parameter controls the smallest hole or gap inside an object that can be detected. The value of the window size has to be much smaller compared to the previous window, but must not be too small (like 1 or 2) since, in that case, the computed deviation will not carry any reliable information. In all our experiments, this parameter was set to 
                        
                           ≈
                           
                              
                                 
                                    
                                       N
                                    
                                    
                                       T
                                    
                                 
                              
                              
                                 30
                              
                           
                        
                     .

Even though the method was presented in the context of multiple light sources, it is still possible to apply it in a more general case, i.e. when only a single light source is present.

In the first experiment we aim to demonstrate that it is possible to apply the method to a quite common case when an ordinary camera is installed inside a building, see Fig. 11
                        . The scene was captured by a color camera under a fixed view and single lighting condition. Each color image was decomposed into 3 separate grayscale images and each image channel was treated as a different lighting condition. Since an image sequence was captured under a single light source, a human shadow was also detected as an object. Despite the limited number of lighting conditions, the proposed method was able to separate the human from the background in each frame, without any modification or parameter tuning.

In the next two experiments, the experimental setup was used. All the lights of the system were turned on and the object was captured only 360 times. In the first experiment, an image sequence of a cup was captured, see Fig. 12
                        . In general, acceptable result were obtained, but some parts of the cup are missing (Fig. 12(b)). There are several problems with image acquisition under single lighting conditions. The first problem is shadows and color bleeding (as already discussed in Section 4.4). Shadows and color bleeding are treated as an object and, therefore, the area of background likelihood is enlarged at the bottom of the object, see Fig. 12(f) and (h). The other problem is the difficulty to illuminate all parts of an object uniformly so it can be separated from the background, see Fig. 12(g–j). The first problem can be handled by the intersection of the visual cones in 3D, since the enlarged parts at the bottom of the object are mostly not consistent over multiple views and the VH of the cup is almost not affected. The second problem is more complex: when some part of an object in several consecutive views is weakly separated from the background, this leads to incorrect estimation of background likelihood and to underestimation of the silhouette. In the current experiment, a small part of a cup handle was in shadow, Fig. 12(g) and (i), and the background likelihood for that part was poorly estimated, Fig. 12(h) and (j). This situation happens in several views, and the problem propagates to the VH, see Fig. 12(b). For an object with complex reflective properties such as a cola can, the situation can be even worse, see Fig. 13
                        . It can be observed that there is almost no edge between the object and the background in several consecutive views, which leads to very poor background likelihood estimation. The problem can be easily overcome using multiple lighting conditions, which will be demonstrated in the next Section.

A calibrated set of images acquired with the roboticized setup (Fig. 1) was used in these experiments. The background behind the object is complex and not uniform: it includes walls, some parts of the setup, and a turntable with circular calibration markers. Several experiments were performed under multiple lighting conditions and with different types of objects. In most of the experiments, one camera view and 6 different light sources were used.

All the experiments were performed on a computer with a third generation Core I7 processor and 8Gb of RAM. All the calculations were done in Matlab. The algorithm can be separated into four blocks: calculation of background likelihood, calculation of 
                           
                              γ
                           
                        , silhouette estimation and VH reconstruction. Even though all the images were captured with a 5megapixel camera, a sub-image with 
                           
                              ≈
                           
                        720p resolution was processed. Background likelihood calculation for a single light source requires ≈4.5min. This block was implemented in C++ but was called from Matlab through mex file. Execution of this block using plain C++ requires around 2.5min. Calculation of 
                           
                              γ
                           
                         for one light source requires 
                           
                              ≈
                           
                        6min. Estimation of the silhouette for one frame requires 
                           
                              ≈
                           
                        1min. For the 3D representation, a voxel grid was used with size 200×200×200, the reconstruction of the visual hull for 360 views requires 
                           
                              ≈
                           
                        5min. For example, the time that was required to obtain the VH of a cola can captured under 6 light sources and depicted in Fig. 14
                         was around 8h.

We must note that the processing time can be significantly reduced due to the possibility to easily parallelize each block of an algorithm at the cost of extra memory usage. For example, the calculation of the background likelihood and 
                           
                              γ
                           
                         for each lighting condition can be executed in parallel since they are independent. Silhouette and VH estimation can also run in parallel since they are view independent.


                        Fig. 14 shows the results of the segmentation and VH of a cola can. This silvery white aluminum can has a bright red
                           1
                           For interpretation of color in Figs. 5, 14 and 15, the reader is referred to the web version of this article.
                        
                        
                           1
                         logo and some text. Due to the material, some parts of the object act like a mirror and reflect light very well, which explains why we observe a specular reflection and non-constant appearance while the object is moving on a turntable. In Fig. 14 part of the can that appears differently in a different view under the same light source is highlighted. Actually, such behavior is beneficial for our method, since it adds extra variation in the intensity profile which in turn results in more reliable calculation at the time dependent step, see Section 4. In Fig. 14(i) it is observed that part of the background was also included in the object’s silhouette. This is due to color bleeding as pointed out in Section 4.4. Notwithstanding, any false segmentation part not consistent with other views is removed while recovering the VH from the intersection of visual cones, see Fig. 14(b–e).

One of the features of the proposed method is that during image acquisition, the camera viewpoint can be changed arbitrarily or several cameras can capture the scene simultaneously. All this information can be easily integrated in the method. In this experiment, an object was captured under two different camera positions, see Fig. 15
                        . A VH was created for each camera position, see Fig. 15(b) and (c) and 15(f) and (g). Since the capturing process was made in the same reference coordinate system, these two voxel grids were simply summed together. A resulting VH is shown in Fig. 15(d) and (h). The main advantage of using several camera positions is that it eliminates almost completely the influence of color bleeding or calibration markers on the VH.

In Fig. 16
                        , the results of the segmentation of a vase are presented. This vase is made of clay, which was not painted on the outside and is thus matte and almost textureless. On the inside, the vase has a glossy lacquer coating, see Fig. 16(e). Due to the shape of the vase, self-shadows occur, see Fig. 16(f). However since there are several light sources and maximum pixel intensity is used as a selection rule (see Section 4.5), the shadow is eliminated. In Fig. 16(h) and (j), we observe that some parts of the background were also included in the silhouette. This is due to the close location of the circular calibration markers to the vase. Such parts are not consistent with other views and are automatically removed at the VH construction stage, see Fig. 16(b–d).

In Fig. 17
                        , the results of the segmentation of a metal bottle are shown. This bottle is made of shiny and textureless material. The appearance of such an object may drastically change between different viewpoints and lighting conditions. During an image acquisition experiment, specular reflection, color bleeding and non-constant appearance are observed, see Fig. 17(f) and (g). Let us note that textureless objects are usually more difficult to handle by 3D reconstruction algorithms. In our case, the absence of texture decreases the level of deviation in the intensity profile. Despite this, the deviation of intensity due to object motion is enough to obtain reliable estimation of background likelihood, see Fig. 17(h–k).The reconstructed VH is shown in Fig. 17(b–e).

The proposed method allows for the segmentation of opaque objects as demonstrated above but can also deal with transparent objects. In Fig. 18
                        , the results of the segmentation of a light bulb are presented. Transparency is the main difficulty with such an object. Due to this physical property it is practically useless to estimate the object color model (using GMM for example) as, instead of learning the object color model, the image of the distorted scene located behind the object is rather learned. Another complication with a transparent object is that a different background is observed during its motion, which makes it difficult to estimate a consistent color model between several views. As observed in Fig. 18(a), the body of the light bulb is transparent and the background is visible through the bulb. Since our approach is not based on modeling the color space of an object, it is possible to obtain a reliable background likelihood for transparent objects, see Fig. 18 second row. Due to more complex reflectance properties of this object compared to previous datasets, it was captured under 30 different light sources. The VH of the light bulb is shown in Fig. 18(b–e). One may wonder why, while the top and side parts of the light bulb have a rounded shape on the extracted silhouettes, only the sides of the bulb have a rounded shape in the VH and the top part has a conic form on this part of the model. It is explained by the relative camera position to the object and the object motion around the Z-axis, see diagram of this case in Fig. 18(f).

Another transparent object that was used in our experiments is a plastic juice bottle, see Fig. 19
                        . The bottom part of the bottle, the one that touches the turntable, is transparent and the intensity of this part thus coincides often with the intensity of the turntable. However the bottle still refracts the light at the edges, which, in conjunction with the object motion, produces enough deviation in the intensity profile to obtain a good estimation of background likelihood, see Fig. 19(f) and (h). Due to the transparency of the bottle bottom, the computed background likelihood is slightly fuzzy in that area compared to that of a matte object (compare the bottom of the objects in Fig. 16(g) and (f)). This leads to over-segmentation, see Fig. 19(g). In the reconstructed VH, see Fig. 19(b–e), one may observe a small saliency on the side of the bottle that is not present on the object. This is due to the moving circular calibration markers on the turntable, see Fig. 19(i), that were assigned low background likelihood values and were thus segmented as a part of the object. This results from the fact that the size of the local window was greater than the empty interval between moving markers or between the marker and the object (see Section 4 for details). Most of these false positive areas are removed during a silhouette intersection, but since the calibration marker motion agrees with the motion of the object, some false positive silhouette area was not completely inconsistent with all the views and could not be eliminated.

In Fig. 20
                        , the result of the Rubik’s Cube segmentation is presented. Each side of the cube is covered with plastic stickers and reflects a lot of light such that a strong color bleeding effect appears at certain locations, as seen in Fig. 20(e). It can be noticed that, in Fig. 20(f) and (h), the bottom boundary of the cube’s background likelihoods are slightly fuzzy due to this phenomenon. As stated in Section 4.4, color bleeding coincides with the definition of an object and results in low background likelihood. In the reconstructed VH, see Fig. 20(b–d), the sides of the cube look inflated although they are completely flat in reality. This is due to the fact that the optical center of the camera did not exactly coincide with the sides of the cube. It is also possible to observe some roughness on the sides of the cube on the VH. One of the reasons for this is that all the silhouettes are computed independently for each view and, as a result, coherence is not guaranteed between boundaries of consecutive silhouettes. This can be easily solved by computing the VH directly in 3D. This will be the next development of the technique.

Note the presence of a cone at the top of each reconstructed object. This is due to the nature of the VH creation, since the only information that is used from each viewpoint is the silhouette of an object.

Even though the algorithm is capable of working on a wide range of objects there is an extreme situation that requires further improvement. A false negative segmentation can be produced when a black object is captured against a black background. Due to the low reflectance property of dark objects, an intensity variation due to their motion may be perceived as background noise and result in incorrect likelihood estimation. However, such a problem is not observed when a bright object is captured against a bright background.

As any other VH construction approach, the reduction of the number of views that are used for VH construction decreases its smoothness and the VH looks more and more like a block. In our case, it is also possible that decreasing number of views causes bumps to appear. This can happen due to color bleeding, see Section 4.4. Another source of error that may lead to VH artifacts with a decreasing number of views is that of circular calibration markers to be included into the silhouette due to its proximity to the object of interest.

We have proposed a framework for non-interactive extraction of object silhouettes and their integration into a VH. The whole approach is based on the single hypothesis that the background is arbitrary but constant for a given light source. The core of the proposed approach consists of two steps: estimating signal stability and data fusion obtained from different light sources. The stability of the signal is estimated by computing time dependent and independent steps. The time independent step analyzes intensity variation irrelevant to its position in time. The idea of the time dependent step is the evaluation of the local properties of the original signal. These two parameters are estimated for different light sources and combined into a single background likelihood. The estimated background likelihood is further used in a MRF framework for silhouette extraction. The framework also allows the information obtained from multiple views and collected under different lighting conditions to be treated equivalently. The advantage of the proposed approach is that, instead of trying to model the color space of an object and background, the evolution of pixel intensity over time is analyzed. Such an approach allows a VH to be created for a wide range of objects with different shapes and reflective properties. We show that the proposed method is capable of dealing with challenging objects with different optical properties: (i) textured or textureless objects, (ii) shiny or lambertian surface reflectance, and iii) opaque or transparent objects.

Our future work aims at increasing the accuracy of the reconstructed geometry by building the VH directly in 3D instead of making independent decisions for each viewpoint. Another direction of investigation would be the use of photometric information for estimating object reflectance properties as well as the actual shape of the object.

@&#ACKNOWLEDGMENT@&#

The authors acknowledge the financial support from the Natural Sciences and Engineering Council of Canada.

@&#REFERENCES@&#


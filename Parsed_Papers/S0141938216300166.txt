@&#MAIN-TITLE@&#New technique of obtaining visually perceived positions of 3-D images using movements of users’ bodies

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This paper presents a new technique for interactive applications of 3-D displays.


                        
                        
                           
                           The positions of 3-D images were obtained from the body movements of users.


                        
                        
                           
                           Interactions occurred when the users’ bodies were at the obtained positions.


                        
                        
                           
                           The accuracy and precision of the obtained positions were evaluated.


                        
                        
                           
                           The evaluation results demonstrate the feasibility of the proposed technique.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

3-D display

3-D image

Interactive application

Interaction

Human body

Human body movement

@&#ABSTRACT@&#


               
               
                  Three-dimensional (3-D) images are perceived as images that float in front of the screens of 3-D displays. Users should be able to interact with these images instantaneously and accurately in applications where their bodies actually seen by them interact with the images. However, conventional techniques using just binocular disparity are too slow and inaccurate. Therefore, we propose a new technique where the visually perceived positions of images are obtained from the body movements of users. The feasibility of this technique was evaluated in an experiment using the positions obtained from users as they reached out to touch the images. These positions were closer to the visually perceived positions of the images than those calculated from binocular disparity. These findings demonstrate the feasibility of the proposed technique for 3-D interactive applications.
               
            

@&#INTRODUCTION@&#

Three-dimensional (3-D) displays have recently seen widespread use among consumers. Currently, they are primarily used to enable consumers to watch 3-D images, e.g., 3-D films, 3-D TV programs, and 3-D games, which are seen as floating images in front of the screens of 3-D displays. Applications where users’ own bodies, which are actually seen by the users unlike images captured using video cameras, interact with 3-D images will become very important in the future. In fact, many researchers have studied such interactive applications [1–3]. The underlying principle behind interactive applications is to carry out interactions when the users’ bodies are exactly at the positions of the floating images in front of the screens. Users typically expect to interact with 3-D images when they see their bodies touch the floating images. Therefore, interactive applications require interactions to take place when the users’ bodies are exactly at the visually perceived positions of the floating images. Although this requirement seems easy to fulfill, conventional techniques find it difficult to do so with the 3-D displays that are used in practice.

Three-dimensional displays in current practical use employ binocular disparity as depth information for 3-D images [4–6]. However, the visually perceived positions of 3-D images often differ from the positions calculated from binocular disparity. Therefore, it is difficult to satisfy the aforementioned requirement if the interactions are carried out when the users’ bodies are exactly at the positions calculated from binocular disparity.

Pre-experiments can be conducted before trials of interactions to measure the visually perceived positions of floating images in front of 3-D display screens, and interactions can be implemented when the users’ bodies are exactly at the positions measured in the pre-experiments. This technique can satisfy the requirement for interactive applications if the visually perceived positions during the trials of interactions match those during the pre-experiments; however, these two sets of visually perceived positions often differ, which makes it difficult to fulfill the requirement.

Because conventional techniques do not meet the requirement for interactive applications, phenomena that are inconsistent with the users’ typical expectations often occur. For example, users often find themselves not able to interact with the floating images in front of the screens although they see their bodies touch the floating images. Conversely, they can often interact with the floating images although they do not see their bodies touch them. Such phenomena adversely impact the usability of interactive applications, especially those that involve precise work.

Conventional techniques suffer from not only the problems described previously but also problems with their specific required preparation. One method, which implements interactions when the users’ bodies are exactly at the positions calculated from binocular disparity, requires the interocular distances of all users to be measured to calculate the exact positions from binocular disparity. Another method, which implements interactions when the users’ bodies are exactly at the positions measured in pre-experiments, requires pre-experiments to be conducted for every instance of the use of the application. Thus, conventional techniques reduce the usability of interactive applications because users cannot readily begin to use them.

This paper presents a new technique that can satisfy the requirement for interactive applications. The visually perceived positions of floating images in front of screens are obtained from human body movements with this technique, and interactions are executed when the users’ bodies, which they can actually see, are exactly at the obtained positions. This paper also demonstrates the feasibility of the proposed technique, which was evaluated in an experiment. In the evaluation, the proposed technique was compared with the first conventional technique (see the second paragraph) with which usability decreased less than with the second method (see the third paragraph) because the preparation for it was easier.

The critical process in fulfilling the requirement for interactive applications is to obtain the visually perceived positions of floating images in front of screens before the users’ bodies reach these positions. The proposed technique achieves this process by using the characteristics of human body movements. The velocity of reaching movements, which are basic movements by which users interact with objects, follows a bell curve as a function of time according to previous studies on human body movements [7–11]. With the proposed technique, data on velocity are fitted into a bell-shaped function, e.g., a Gaussian function, before the reaching movements have finished, and the fitted function is used to obtain the positions where the users will finish their reaching movements, namely, the positions where the velocity of reaching movements will reach zero (Fig. 1
                     ). Because users will stop their reaching movements when they see their hands touch the floating images, the positions obtained with the fitting function are the visually perceived positions of the floating images. Thus, the proposed technique can be used to obtain the visually perceived positions of floating images before the users’ bodies arrive there, and can fulfill the requirement for interactive applications.


                     Fig. 2
                      outlines the four steps of the algorithm used by the proposed technique. In the first step, the current velocity of reaching movements is compared with V
                     beginning, which is the threshold for detecting the beginning of reaching movements; if the current velocity of reaching movements is faster than V
                     beginning, then reaching movements are considered to have started (Fig. 2A). After the beginning of reaching movements is detected, the peak velocity of reaching movements is detected in the second step (Fig. 2B). The velocity V
                     obtain, which is the trigger to obtain the visually perceived positions of floating images, is determined on the basis of the peak velocity, e.g., half the peak velocity or a quarter of the peak velocity. The current velocity of reaching movements is compared with V
                     obtain in the third step (Fig. 2C); if it is lower than V
                     obtain, the data on velocity collected until this moment are fitted to a Gaussian function:
                        
                           (1)
                           
                              
                                 V
                                 =
                                 
                                    
                                       
                                          
                                             p
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       
                                          
                                             p
                                          
                                          
                                             1
                                          
                                       
                                       
                                          
                                             
                                                
                                                   π
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       e
                                    
                                    
                                       -
                                       2
                                       
                                          
                                             
                                                
                                                   (
                                                   t
                                                   -
                                                   
                                                      
                                                         p
                                                      
                                                      
                                                         4
                                                      
                                                   
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             
                                                
                                                   p
                                                
                                                
                                                   3
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where V is the velocity of reaching movements, t is time, and p
                     1, p
                     2, p
                     3, and p
                     4 are fitting parameters. p
                     2 is the area of the fitted function, namely, the positions obtained in the third step. After the visually perceived positions of the floating images are obtained, interaction is achieved if the users’ bodies are exactly at the obtained positions (Fig. 2D). Thus, the proposed technique can satisfy the requirement for interactive applications.

The feasibility of the proposed technique was evaluated by assessing the accuracy and precision of the obtained positions. The absolute value of the difference between the position obtained with the proposed technique and the position where a floating image in front of the screen was actually perceived visually was calculated as
                        
                           (2)
                           
                              
                                 
                                    
                                       D
                                    
                                    
                                       absolute
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             (
                                             
                                                
                                                   P
                                                
                                                
                                                   obtained
                                                
                                             
                                             -
                                             
                                                
                                                   P
                                                
                                                
                                                   perceived
                                                
                                             
                                             )
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     where D
                     absolute is the absolute difference, P
                     obtained is the position obtained with the proposed technique, and P
                     perceived is the visually perceived position of the floating image. The absolute difference decreases when the obtained position is closer to the visually perceived position. Thus, the accuracy and precision of the obtained positions in this evaluation were assessed using the absolute difference.

An experiment was performed to collect the required data. Participants in this experiment reached out to a floating image with their hands that they could actually see, and their reaching movements were measured. After the experiment, the position with the proposed technique, the visually perceived position, and the absolute difference between the two were calculated using the collected data. Details of the experiment and computation are described in the following subsections.

The experiment was conducted in a well-lit room. Fig. 3
                         shows a schematic of the apparatus. Three-dimensional images were generated with a workstation (Precision 390, Dell, Round Rock, TX, USA) and a cathode-ray tube (CRT) display (A201H, Iiyama, Tokyo, Japan). The CRT display was located 70cm from the participants, and the center of the screen was on their median plane and at eye level. The participants wore a pair of liquid crystal shutter glasses for stereoscopic vision (NuVision 60GX, MacNaughton, Beaverton, OR, USA), and their heads were stabilized using a chinrest and a forehead rest. The shutter glasses were synchronized with the CRT display. Videos of the participants’ reaching movements were recorded with a digital camera with the Live MOS sensor (DMC-G10K, Panasonic, Osaka, Japan), which was located to their right, and the positions of the right-hand index fingers were measured by image processing of the video. The spatial resolution was 1mm, and the sampling rate was 30Hz.

Three-dimensional images were presented as red squares, 5cm wide and 5cm high, on the screen. The center of the virtual squares on the screen was 5cm to the right from the participants’ median plane and at their eye level. The positions calculated from binocular disparity were in front of the screen, and were 40cm from the participants.

One employee and 13 students of the Kanagawa Institute of Technology participated in the experiment. Two of them were aware of the purpose of the experiment. All of them had normal or corrective-to-normal visual acuity and normal binocular vision. They were also right-handed.

The tasks of the participants were to reach out to a virtual square, which was seen as a floating image in front of the screen, with their right hands, and to touch it with the right index finger. The participants could actually see their right hands and index fingers. The participants first placed their right elbows on a table in each trial, and then vertically raised the right forearms (see Fig. 3), thus beginning the reaching movements. When the participants saw their index fingers touch the virtual square floating in front of the screen, they stopped moving the fingers, held them there, and orally reported the end of the movement to the experimenters. Five trials were conducted for each participant.

Velocity was calculated from the position of the index finger, and the position of the floating image was calculated with the proposed technique by using the velocity under two conditions. Under the half condition, the data from the beginning of a reaching movement to when the velocity of the reaching movement decreased to half the peak velocity were used to calculate the position. Under the quarter condition, the data from the beginning of a reaching movement to when the velocity decreased to a quarter of the peak velocity were used. These data were fitted to Eq. (1), and p
                        2 was defined as the obtained position (see Section 2). The fitting was conducted with the Levenberg–Marquardt algorithm for the nonlinear least squares method.

The visually perceived position of the virtual square was defined as the position of the index finger where the participant had finished their reaching movement. The standard deviation of the position over a period of 200ms was calculated, and the time when the standard deviation decreased to less than 2mm was defined as the end of the reaching movement. The mean position over the same duration was defined as the position where the reaching movement ended.

We calculated the absolute difference for the position obtained with the proposed technique by using Eq. (2); the absolute difference under conventional-technique conditions was also calculated for comparison. For the position calculated from binocular disparity under conventional-technique conditions, P
                        obtained was set as 40cm in Eq. (2) because conventional techniques achieve interaction at this position (see the second paragraph of Section 1). Thus, the absolute difference was calculated under the half and quarter conditions of the estimated position (see Section 3.5) and under conventional-technique conditions.

@&#RESULTS@&#


                     Fig. 4
                      presents typical results for the participants’ reaching movements. The trajectory of the reaching movements was almost straight, and the movements finished behind the positions calculated from binocular disparity (Fig. 4A). The position of the participants’ right index fingers as a function of time followed an S-shaped curve, and the position where the reaching movements finished was stable (Fig. 4B). The velocities of the reaching movements as a function of time were well fitted to the Gaussian function, and the velocity where the reaching movements finished was almost zero (Fig. 4C). These results suggest that the methods described in Sections 3.5 and 3.6 are reliable.

The mean absolute difference and standard deviation for each condition were calculated for the fourteen participants on the basis of the mean absolute difference of five trials for each participant (Fig. 5
                     ). One-way analysis of variance (ANOVA) was conducted using the Huynh-Feldt ɛ because the sphericity assumption was rejected by Mauchly’s sphericity test (χ
                     2
                     (2)
                     =47.6, W
                     =0.02, p
                     <0.01). The main effect of the condition of the absolute difference was significant (F
                     (1.01,13.2)
                     =7.58, MSE
                     =12.4, p
                     <0.05, ηp
                     
                     2
                     =0.37). Multiple comparisons were conducted with Bonferroni’s method to examine the most significant main effect of the condition of the absolute difference in detail. There were significant differences between the conventional-technique conditions and each of the half and quarter conditions at the 5% level. There were no significant differences between the half and quarter conditions. These results reveal that the absolute differences under the half and quarter conditions were significantly smaller than those under the conventional-technique conditions.

The absolute differences under the conventional-technique conditions were not zero. This result suggests that the visually perceived positions of the virtual squares were different from the positions calculated from binocular disparity. Thus, the conventional-technique conditions replicated the problem where conventional techniques have difficulty in satisfying the requirement for interactive applications (see the second, third, and fourth paragraphs in Section 1).

@&#DISCUSSION@&#

The absolute differences under the half and quarter conditions were smaller than those under the conventional-technique conditions, as mentioned in Section 4. This result demonstrates that the accuracy and precision of the positions obtained with the proposed technique were better than those of the positions where conventional techniques implement interactions, i.e., the positions calculated from binocular disparity. That is, when the proposed technique was used for interactive applications, the positions where interaction was achieved were closer to the visually perceived positions of 3-D images than when conventional techniques were used. Thus, the proposed technique is more capable of satisfying the requirement for interactive applications.

Although the absolute differences under the half and quarter conditions were not zero, we considered that they could be reduced. For example, the accuracy and precision of the obtained positions may be improved by improving the fitting function. As shown in Fig. 4C, the velocities of the participants’ reaching movements obtained in the experiment were well fitted to the Gaussian function; however, some measured velocities were far from the fitted function. This suggests that more accurate and precise positions can be obtained by improving the fitting function. As described in Sections 2 and 3.5, the data on velocity were fitted to a Gaussian function with a symmetrical bell curve, and this meant that the positions obtained in this study were calculated from symmetrical elements in the velocity of reaching movements as a function of time. However, reaching movements not only have symmetrical elements such as ballistic movements related to feedforward mechanisms but also asymmetrical elements such as corrective movements related to feedback mechanisms [12]. The accuracy and precision of the obtained positions would improve if the data on velocity were fitted to a function with an asymmetrical bell curve, e.g., a function of χ
                        2 distribution. We intend to evaluate fitting function improvements in the near future.

We concluded that the proposed technique was feasible on the basis of the discussion above, and assumed that it was useful. That is, when the proposed technique is used for interactive applications, users can interact with 3-D images by using their bodies just as they intend, and the efficiency of interaction does not decrease. We intend to conduct experiments to further examine this assumption in the near future.

Although this study evaluated the proposed technique under restricted conditions, we considered that the proposed technique can be applied under various conditions where users reached out to virtual objects of 3-D images because the proposed technique uses the universal feature of reaching movements. According to previous studies on human body movements, the velocity of reaching movements as a function of time follows a bell curve under various conditions of reaching direction or reaching distance [7–11]. This suggests that the proposed technique can work under reaching direction or reaching distance conditions that are different from the conditions in those studies. We intend to examine this suggestion and evaluate the applicable range of the proposed technique in the near future.

We need to study positions obtained from other movements as this study only used reaching movements. For example, obtaining positions from reaching movements cannot be applied to cases where users hit 3-D images by using their bodies because the visually perceived positions of 3-D images are somewhere in the middle of the hitting movements. Thus, we have to develop new methods for obtaining positions by using the body movements of users if the visually perceived positions of 3-D images differ from the positions where the body movements end.

We conjectured on obtaining positions from hitting movements. As the visually perceived positions of 3-D images are the same as the positions where the velocity of hitting movements reaches its peak, such positions can be obtained by fitting the acceleration of hitting movements to the differential of a Gaussian function. We intend to examine this hypothesis in the near future.

In contrast to conventional techniques, which require specific preparation and thus reduce the usability of interactive applications (see the fifth paragraph in Section 1), the proposed technique does not require any specific preparation, as described in Section 3. For example, the proposed technique does not require the interocular distances of all users to be measured, nor any pre-experiments to measure the visually perceived positions of 3-D images. Note that the position calculated from binocular disparity was under conventional-technique conditions (see Sections 3.2 and 3.7). All users can readily begin to use interactive applications when they utilize the proposed technique. It can solve not only the problem where conventional techniques have difficulty in satisfying the requirement for interactive applications (see the second, third, and fourth paragraphs in Section 1) but also the problem where the specific required preparation for conventional techniques reduces the usability of interactive applications.

Although the results obtained under the conventional-technique conditions replicated the problem of difficulty in satisfying the requirement for interactive applications (see the second paragraph in Section 4), some previous studies reported that 3-D images were seen at positions calculated from binocular disparity [13]. The visually perceived positions of 3-D images in those studies were measured under some specific conditions. For example, participants observed random-dot stereograms, which had binocular disparity but did not have any pictorial cues for depth perception of human vision [13]; therefore, binocular disparity dominated the visually perceived positions of 3-D images, so that 3-D images were seen at the positions calculated from binocular disparity. Thus, the problem of difficulty in satisfying the requirement for interactive applications did not occur. Even in these conditions, the proposed technique has benefits against conventional techniques because it does not need any specific preparation that reduces the usability of interactive applications, whereas conventional techniques do.

@&#CONCLUSION@&#

This paper presented a new technique that can achieve interactions when the users’ bodies, which they can actually see, are exactly at the visually perceived positions of 3-D images, which are seen as floating images in front of the screens of 3-D displays. The main principle underlying the proposed technique is that the visually perceived positions of floating images can be obtained using the body movements of users, and that interactions can be executed when the bodies are exactly at the obtained positions. The feasibility of the proposed technique was evaluated by conducting an experiment to examine the accuracy and precision of the positions obtained with the proposed technique. The results showed that the proposed technique obtained more accurate and precise positions than the conventional techniques, which calculated the positions from binocular disparity. Therefore, the proposed technique is demonstrated to be feasible for 3-D interactive applications.

@&#ACKNOWLEDGMENTS@&#

This study was a revision of our conference papers presented at IEEE ISM 2009, ICAT 2010, ICIPT 2011, and Electronic Imaging 2012, and was supported by the Academic Frontier Promotion Program of the Ministry of Education, Culture, Sports, Science and Technology in Japan, the Support Center for Advanced Telecommunications Technology Research in Japan, and the 
                     Japan Society for the Promotion of Science
                   (JSPS) KAKENHI Grant Number 24500155, 15K00289. We are grateful to Mr. Minoru Yokono, Ms. Kazumi Sugiyama, and Messrs. Hitoshi Sakai, Keigo Takazawa, Hiroshi Unno, Ayumu Kanazawa, and Kazuki Matsushima for their cooperation in this study.

@&#REFERENCES@&#


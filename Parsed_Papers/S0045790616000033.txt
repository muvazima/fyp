@&#MAIN-TITLE@&#The role of facial asymmetry in recognizing age-separated face images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Facial asymmetry based approach is proposed to classify age-separated face images.


                        
                        
                           
                           Facial asymmetry is measured and evaluated across temporal variations.


                        
                        
                           
                           A 3 D matching-scores space is built using holistic, local and asymmetric features.


                        
                        
                           
                           SVM is used as classifier to separate genuine and imposter classes in score space.


                        
                        
                           
                           Results show better performance of proposed approach compared to existing methods.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Facial asymmetry

Temporal variations

Matching-score space

Holistic features

Densely sampled asymmetric features

Local features

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Human face contains a number of recognition-specific clues including age, gender, race and expressions. Over the past five decades, several face recognition algorithms have been proposed in the literature. Currently, face recognition of age-separated face images is receiving continuous attention of research community. The major challenge in recognition of age-separated face images is to extract such discriminatory information, which can reduce matching-scores gap between gallery and corresponding probe images. Facial temporal variations are highly complex in nature due to number of factors including facial asymmetry. Although facial asymmetry has been used in previous face recognition studies [1–6], yet these studies lack facial asymmetry evaluation across temporal variations and its discriminatory role in recognizing age-separated face images. Motivated by this fact, we aim at: (1) evaluating facial asymmetry with small and large temporal variations; and (2) combining asymmetric facial features along with holistic (PCA) [7] and local feature descriptors (LBP) [8] to exploit the discriminatory information for recognition of age-separated face images.

@&#RELATED WORK@&#

Recently a number of face recognition methods have been proposed for recognition of age-separated face images [9-13]. Existing methods to recognize age-separated face images can be broadly classified into two categories: (1) generative methods; and (2) discriminative methods. The generative methods rely on modeling of facial aging process. Though such methods are successful in discriminating age-separated face images, yet involve complex age simulation process. On the other hand, discriminative methods, such as [10,11,13], use multiple feature representations to improve face recognition performance. In [10], a multi-feature discriminant analysis is presented to recognize age-separated face images. In [11], Bacteria foraging fusion (BFF) scheme is used to optimize the weights assigned to different facial regions to maximize the recognition performance. A multi-view discriminative learning (MDL) approach based on three different local feature descriptors is presented in [13]. In a most recent approach [12] reported in the literature, human perception based fusion strategy has been proposed to recognize age-separated face images.

As described earlier, facial asymmetry has long been studied as a critical factor in face recognition. In [1], partial asymmetric left or right faces have been used for recognition. Bilateral facial symmetry has been used in [2] to calculate gender and degree of facial symmetry scores. In [3], facial symmetry has been used to correct pose variations for 3D face images for face recognition. In [4], facial symmetry based left half faces have been used for face recognition. In [5], mirrored face images, based on facial symmetry are used to construct highly accurate 3D face models. In [6], an optical flow based facial asymmetry measurement is presented to facilitate face reconstruction and recognition. Despite recent progress in recognizing age-separated face images, yet there are two main limitations including: (1) lack of facial features evaluation with temporal variations; (2) most of the existing methods rely on a single feature representation, such as local features and hence lack the discriminatory information. Furthermore, such features can be manipulated by certain age groups using artificial facial variations, for example, by facial make up, as suggested in [14]. In this study we address these limitations by: (1) evaluating asymmetric facial features with temporal variations; and (2) combining existing feature descriptors with asymmetric facial features to improve recognition performance of age-separated face images. Keeping in view the presented methods and to the best of our knowledge, the current research is the first to explore the role of facial asymmetry towards recognition of age-separated face images on three public domain facial aging databases, the FERET [15], MORPH Album II [16] (termed as MORPH in the rest of text) and FG-NET [17].

FERET is one of the largest publically available databases with 3540 face images of 1196 subjects in the age range of 10–70 years. It contains a gallery termed as fa set, fb set with alternative facial espressions and two aging sets termed as dup I and dup II, representing small and large temporal variations, respectively. MORPH is another large facial aging database, which contains 55134 age-separated face images of more than 13000 subjects in the age range of 16–77 years. FG-NET aging database contains 1002 age-separated face images of 82 subjects in the age range of 0–69 years. Some age-separated face images from these databases are shown in Fig. 1.
                        
                     

Facial asymmetry, which refers to non-correspondence in shape, size, and arrangement of facial landmarks on both sides of the face, is common in humans, even in young healthy subjects [18]. Facial asymmetry may be classified as intrinsic and extrinsic asymmetry [19]. Intrinsic asymmetry corresponds to bilateral structural variations of face while extrinsic asymmetry is related to external facial variations, such as pose and illumination. Causes of intrinsic facial asymmetry in humans can generally be classified into four categories: (1) acquired; (2) functional; (3) congenital; and (4) developmental [20]. As an intrinsic characteristic of face and its presence in general population, an evaluation of intrinsic facial asymmetry across temporal variations and its potential role in recognizing age-separated face images is presented in the current study.

Rest of this study is organized as follows. Section 2 gives measurement and evaluation of facial asymmetry. Section 3 presents proposed face recognition methodology including feature representation, experiments, and results. Result related discussion is presented in Section 4, while last section gives conclusions with future research directions.

In this section, we present facial asymmetry measurement and evaluation across small and large temporal variations on three widely used face aging databases, the FERET, MORPH, and FG-NET, with necessary face pre-processing and landmarks detection given in the following sub-sections.


                        Pre-processing: To compensate for different appearance variations, face images are pre-processed as described in following steps.
                           
                              (1)
                              Each face image is rotated such that it is vertically upright.

The face images are aligned based on eyes coordinates such that inter-pupillary distance is same for all images.

Illumination variations are corrected by using Histogram Equalization.

Each face image is tightly cropped (based on eye coordinates) as suggested in [13] into 128×128 pixels size, including middle of forehead to just below the mouth and from outer corner of one eye brow to the other, to remove unwanted background and hair regions.


                        Landmarks detection: Sixty-four facial landmarks are detected on each face image by following two methods: (1) manual annotation, and (2) automatic landmarks detection, using Face++ [21] (a publically available state of the art facial landmarks detection tool). To check the validity of both methods, we calculate average error in detecting facial landmarks, which results into 1 pixel per image. Keeping in view this minimal error, we use automatic method for facial land mark detection. A sample original face image and its cropped version with detected landmarks using Face++ is shown in Fig. 2.
                        
                     

To analyze the relationship between facial asymmetry and increasing age, we are interested in measuring and evaluating facial asymmetry across small and large temporal variations. For this purpose, we select image sets with small and large temporal variations from FERET, MORPH, and FG-NET databases. In case of FERET database, we select 75 face images, each from fa, dup I (representing small temporal variations) and dup II (representing large temporal variations) sets, such that the face images of subject present in fa set are also present in dup I and dup II sets. In case of MORPH database, we select three subsets consisting of 10000 face images each, representing the youngest, older (representing small temporal variations) and oldest (representing large temporal variations) face images of selected subjects. Similarly for FG-NET database, we select three subsets consisting of 82 face images each, representing the youngest, older and oldest face images of selected subjects. Facial asymmetry is then measured and evaluated as described in following steps:
                           
                              (1)
                              A facial midline y1y2 perpendicular to the line x1x2 (joining eye coordinates) is determined for each face image through an iterative process such that difference between left and right half face is minimum, as shown in Fig. 3
                                 (a).

Nine pairs of bilateral facial landmarks (shown in Fig. 3(b) and illustrated in Table 1
                                 ) are selected from facial regions which are least affected by facial expressions.

Facial asymmetry of selected landmarks is then measured in terms of inter-pixel linear distances dl
                                  and dr
                                 , reference to the facial midline y1y2. The difference D between dl
                                  and dr
                                  is given as shown in Eq. 1.
                                    
                                       (1)
                                       
                                          
                                             
                                                
                                                   
                                                      D
                                                      =
                                                      
                                                         d
                                                         l
                                                      
                                                      −
                                                      
                                                         d
                                                         r
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

In Eq. 1, D gives measure of facial asymmetry for respective bilateral landmarks. If D is positive then a given landmark will be skewed towards left and vice versa.
                           
                              (4)
                              Absolute values of D are used to calculate mean and standard deviation (SD), which are recorded as bar graphs as shown in Fig. 4
                                 , for the selected subsets of FERET, MORPH and FG-NET databases.

In case of FFRET database, mean and standard deviation of fa set is compared with that of dup I and dup II sets, while mean and standard deviation of the youngest face images set is compared with that of older and oldest face images sets in case of both the MORPH and FG-NET subsets.

From the comparative results of facial asymmetry variation with small and large temporal changes (see Fig. 4), it is observed that: (1) facial asymmetry is more evident for the landmarks located on lower part of face than those for middle and upper parts of face; (2) facial asymmetry increases with age for all the selected image subsets. We observe a slight increase in facial asymmetry in lower part of face including sub-alare to crista philtre for small temporal variations. On the other hand, in case of large temporal variations we see a comparatively increased facial asymmetry, specifically for lower parts of the face including alare, sub-alare, crista philtre and cheilion for all the selected face images subsets. Keeping in view the earlier related studies, our results are largely in line with those described in [20]. The evaluation results give us a clue that facial asymmetry is an intrinsic property of face and a strong indicator of age and hence can be used to recognize age-separated face images.

After assessment of facial asymmetry, we aim at using asymmetric facial features towards recognition of age-separated face images. The corresponding feature extraction and proposed face recognition algorithm is presented in this section.

In proposed study we represent face images with three feature descriptors including: (1) PCA based holistic features; (2) LBP based local features; and (3) facial asymmetry based Densely Sampled Asymmetric Features (DSAF), as described in the following sub-sections.

Principal Component Analysis (PCA) [7] is used to extract holistic facial features. Eigen-faces are a set of Eigen-vectors, widely used in face recognition algorithms. In PCA, a set of Eigen-vectors is derived as follows.

Consider N number of training images with a × b as size of each image. Suppose F be a matrix with each column containing mean-subtracted face images. Then as suggested by original study, the size of covariance matrix C can be reduced by calculating FTF instead of FFT
                           . Multiplication of F with the Eigen vectors of FTF results into Eigen-faces, which are termed as basis vectors and form a projection matrix. In projection phase the required numbers of image vectors V are projected onto this projection matrix to achieve the templates.

Local Binary Patterns (LBP) introduced in [8], can encode shape and texture of an underlying face image. These local facial features are robust to geometric and illumination variations. Uniform circular local binary patterns are extracted by dividing face image into non overlapping square regions. An LBP histogram is then computed independently for each region. Finally, all the resulting histograms are concatenated together to form a spatially enhanced histogram.

A histogram of a labeled face image f(x, y) can be given as shown in Eq. 2.
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   H
                                                   i
                                                
                                                =
                                                
                                                   ∑
                                                   
                                                      x
                                                      ,
                                                      y
                                                   
                                                
                                                J
                                                
                                                   {
                                                   f
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                   =
                                                   i
                                                   }
                                                
                                                ,
                                                i
                                                =
                                                0
                                                ,
                                                ⋯
                                                ,
                                                
                                                   l
                                                   1
                                                
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           where
                              
                                 J
                                 
                                    {
                                    Z
                                    }
                                 
                                 =
                                 {
                                 
                                    
                                    
                                       0
                                       ,
                                       
                                       
                                       
                                       Z
                                       
                                       i
                                       s
                                       
                                       f
                                       a
                                       l
                                       s
                                       e
                                    
                                    
                                       1
                                       ,
                                       
                                       
                                       
                                       
                                       Z
                                       
                                       i
                                       s
                                       
                                       t
                                       r
                                       u
                                       e
                                    
                                 
                              
                           
                        

In order to retain the spatial information, the image is divided into regions 
                              
                                 
                                    R
                                    0
                                 
                                 ,
                                 
                                    R
                                    1
                                 
                                 ,
                                 
                                    R
                                    2
                                 
                                 ,
                                 ⋯
                                 ,
                                 
                                    R
                                    
                                       l
                                       −
                                       1
                                    
                                 
                              
                           , which results into a spatially enhanced histogram as shown in Eq. 3.
                              
                                 (3)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   H
                                                   
                                                      i
                                                      ,
                                                      j
                                                   
                                                
                                                =
                                                
                                                   ∑
                                                   
                                                      x
                                                      ,
                                                      y
                                                   
                                                
                                                J
                                                
                                                   {
                                                   f
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                   =
                                                   i
                                                   }
                                                
                                                J
                                                
                                                   {
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                   ∈
                                                   
                                                      R
                                                      j
                                                   
                                                   }
                                                
                                                ,
                                                i
                                                =
                                                0
                                                ,
                                                1
                                                ,
                                                2
                                                ,
                                                ⋯
                                                ,
                                                
                                                   l
                                                   1
                                                
                                                −
                                                1
                                                ,
                                                j
                                                =
                                                0
                                                ,
                                                1
                                                ,
                                                2
                                                ,
                                                ⋯
                                                ,
                                                
                                                   l
                                                   2
                                                
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           where l
                           1 and l
                           2 represent labels produced by LBP operator. The histogram in Eq. 2 contains information about corners, edges and flat areas, while histogram in Eq. 3 results into a global description of face image.

In order to extract asymmetric facial information, we propose Densely Sampled Asymmetric Features (DSAF). The proposed feature extraction scheme consists of three steps with extraction of: (1) difference half face image; (2) facial asymmetries from difference half face image; and (3) geometrical moment invariants to characterize facial asymmetries. An overview of the steps involved in extraction of proposed DSAF features from a pre-processed face image is shown in Fig. 5
                           , with detail of each step given in following sub-sections.

To start with, each pre-processed face image is divided into two parts, the left half face (LHF) and right half face (RHF) using facial midline as determined in Section 2. The mirror image of LHF is subtracted from RHF to extract a difference half face image, as illustrated in Fig 6.
                              
                           

As shown in Fig. 6, each difference half face image represents facial asymmetries (termed as asymmetries in the rest of text), which are mainly composed of iso-intensity pixels (pixels with same intensity). Such pixels can be straightforwardly grouped together and considered as unique recognition-specific asymmetries. From this point of view, it is possible to extract such asymmetries using attribute profiles (APs). APs as an extension of morphological profiles (MPs) [22] are used as an advanced mechanism for a multilevel analysis of image by the sequential application of morphological attribute filters (AFs). AFs are connected component (CC) transformations used to model different kinds of the structural information. Recall that a connected component is a region of iso-intensity connected pixels in an image. AFs can process an image by removing or preserving connected components according to a given criterion. AFs are flexible operators since they can transform an image according to many different attributes. An attribute is any measure computable on the regions (e.g. area, perimeter etc.). AFs have two important criterions, the increasing and non-increasing criterion. If a criterion is satisfied for a connected region K, it will also be satisfied for all those regions that include K, it is called increasing criterion (e.g., area and length of bounding box of a region), otherwise it is called non-increasing criterion (e.g., moment of inertia and standard deviation of pixels intensities). If the criterion considered is increasing, the resulting transformation is increasing (i.e., it is an opening). In contrast, if the increasingness property is not fulfilled by the criterion, the transformation is called a thinning. Analogous considerations can be made for the dual transformation. If the criterion is increasing, the transformation is actually a closing, otherwise it is a thickening. The filtering operation implemented in APs is based on the evaluation of how a given attribute (attr) is computed for every connected component of an image I, for a given threshold value λ. For a connected component of the image, if the attribute meets a predefined condition (e.g., attr(CC) > λ), then the component is preserved, otherwise it is removed. Given an ordered sequence of n number of thresholds 
                                 
                                    {
                                    
                                       λ
                                       1
                                    
                                    ,
                                    
                                    
                                       λ
                                       2
                                    
                                    ,
                                    
                                    …
                                    ,
                                    
                                    
                                       λ
                                       n
                                    
                                    }
                                 
                              , an AP is obtained by applying a sequence of attribute thickening and thinning transformations to image I as shown in Eq. 4.
                                 
                                    (4)
                                    
                                       
                                          A
                                          P
                                          
                                             (
                                             I
                                             )
                                          
                                          =
                                          {
                                          
                                             ϕ
                                             
                                                u
                                                
                                                   λ
                                                   L
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          ,
                                          
                                          
                                          
                                             ϕ
                                             
                                                u
                                                
                                                   λ
                                                   
                                                      L
                                                      −
                                                      1
                                                   
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          ,
                                          
                                          …
                                          ,
                                          
                                             ϕ
                                             
                                                u
                                                
                                                   λ
                                                   1
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          ,
                                          
                                          
                                          f
                                          ,
                                          
                                          
                                          
                                             γ
                                             
                                                u
                                                
                                                   λ
                                                   1
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          ,
                                          …
                                          ,
                                          
                                             γ
                                             
                                                u
                                                
                                                   
                                                      λ
                                                      L
                                                   
                                                   −
                                                   1
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          ,
                                          
                                          
                                          
                                             γ
                                             
                                                u
                                                
                                                   λ
                                                   L
                                                
                                             
                                          
                                          
                                             (
                                             I
                                             )
                                          
                                          }
                                       
                                    
                                 
                              whereϕ and γ represent the thickening and thinning transformations, respectively, 
                                 
                                    u
                                    =
                                    {
                                    
                                       u
                                       λ
                                    
                                    
                                    :
                                    
                                    
                                    λ
                                    =
                                    0
                                    ,
                                    
                                    …
                                    ,
                                    
                                    n
                                    }
                                 
                               represents the family of non-increasing criteiria which also fulfils the property of increasingness and L represents the level of corresponding transformation, with a total of 2L+1 levels. To extract asymmetries, we compute four AFs on each difference half face image by considering corresponding attributes of area (a), length of diagonal of bounding box (d), moment of inertia (m), and standard deviation of pixels intensities (t), resulting into four APs: area attribute profile (APa
                              ), length of diagonal of bounding box attribute profile (APd
                              ), moment of inertia attribute profile (APm
                              ) and standard deviation of pixels intensities attribute profile (APt
                              ). For multilevel image analysis, we select the following threshold values of λ to createAPa
                              : 2, 6, 15, and 30. For APd
                              , the following threshold values of λ are selected: 2, 4, 6, and 12. To create APm
                              , the difference half face image is filtered by progressively suppressing those regions with corresponding attribute values smaller than the following increasing thresholds: 0.3, 0.5, 0.8, and 0.9. APt
                               models the homogeneity of the gray levels of the pixels in the image. The profile is built according to the following reference values of the standard deviation: 4, 6, 8, and 10. To consider the effect of all computed APs simultaneously, we define combined attribute profile APc as shown in Eq. 5.
                                 
                                    (5)
                                    
                                       
                                          
                                             
                                                
                                                   A
                                                   
                                                      P
                                                      c
                                                   
                                                   =
                                                   A
                                                   
                                                      P
                                                      a
                                                   
                                                   +
                                                   A
                                                   
                                                      P
                                                      d
                                                   
                                                   +
                                                   A
                                                   
                                                      P
                                                      m
                                                   
                                                   +
                                                   A
                                                   
                                                      P
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           


                              Fig. 7
                               shows the application of APc
                               to a sample input difference half face image. The output difference half face image shows the extracted asymmetries with iso-intensity pixels (white pixels).

Each extracted asymmetry can be geometrically characterized by computing its geometrical moment invariants. For this purpose, each difference half face image with extracted asymmetries is divided into a set of overlapping patches and geometrical moment invariants (introduced by Hu [23] and termed as Hu moment invariants in the rest of text) are computed for each patch resulting into Densely Sampled Asymmetric Features (DSAF), as described below.

Consider a difference half face image with extracted asymmetries of size h × w, with patch size p × q and overlapping radius r, then the number of horizontal (X) and vertical (Y) patches obtained are given in Eq. 6.
                                 
                                    (6)
                                    
                                       
                                          X
                                          =
                                          
                                             
                                                h
                                                −
                                                r
                                             
                                             
                                                p
                                                −
                                                r
                                             
                                          
                                          
                                          
                                          
                                          
                                          
                                          
                                          a
                                          n
                                          d
                                          
                                          
                                          Y
                                          =
                                          
                                             
                                                w
                                                −
                                                r
                                             
                                             
                                                q
                                                −
                                                r
                                             
                                          
                                       
                                    
                                 
                              
                           

For each patch, we can extract a d-dimensional Hu moment invariant feature vector resulting into a d × X × Y-dimensional DSAF feature vector for a given difference half face image with extracted asymmetries.

Motivated by our findings of varying facial asymmetry for different facial landmarks, we divide each difference half face with extracted asymmetries into four equal regions: region 1, region 2, region 3 and region 4, to analyze the importance of each region in subsequent face recognition experiments. Each region is divided into U × V overlapping patches to extract d′-dimensional Hu moment invariant feature vectors from each patch resulting into a d′ × U × V- dimensional DSAF feature vector for each region. The procedure to extract the proposed DSAF features from difference half face image with extracted asymmetries and each region, using Hu moment invariants is illustrated in Fig. 8.
                              
                           

The resulting DSAF features can be used to match two similar asymmetries in two different face images of the same subject in face recognition task described in the following section.


                        Fig. 9
                         illustrates the block diagram of proposed face recognition algorithm, which is described in the following steps. (i) The training images are partitioned into two datasets, dataset 1 and dataset 2, such that both datasets contains images of same subjects acquired under different conditions. (ii) Each face image is pre-processed as described in Section 2. (iii) For each pre-processed face image, we extract a set of three different feature vectors:

(1) A 100-dimensional PCA based feature vector is extracted for each 128 × 128 face image. (2) LBP based feature vector is extracted for each 128 × 128 face image by dividing it into 15 × 15 blocks with a patch size of 16 × 16 and overlapping radius of 8 pixels. We extract a 256-dimensioanl LBP feature for each patch resulting into a 15 × 15 × 256=57600-dimensional LBP feature vector for each face image. (3) Each difference half face image with extracted asymmetries is divided into four regions, region 1, region 2, region 3, and region 4, of size 32 × 64 each. Each region is further divided into 7 × 3 blocks with a patch size of 16 × 16 and overlapping radius of 8 pixels. A 7-dimensional Hu moment invariant feature vector is extracted for each patch, resulting into 3 × 7 × 7 = 147-dimensional DSAF feature vector for each region.

(iv) Once feature vectors are extracted, the next step is to calculate matching scores using PCA, LBP, and DSAF features vectors. In case of PCA and LBP, respective feature vectors of images in dataset 1 are compared with those of dataset 2, to calculate matching scores. Genuine matching scores are obtained by comparing the feature vectors of same subjects while imposter matching scores are obtained by comparing the feature vectors of different subjects present in dataset 1 and dataset 2. In case of DSAF, a region-wise feature vector comparison of images in dataset 1 and dataset 2 is made to calculate genuine and imposter matching scores (e.g., feature vector of region 1 of an image in dataset 1 is compared with feature vector of same region of the same image present in dataset 2). We assign different weights to scores pertaining to each region (region 1, region 2, region 3, and region 4). The weights are calculated using the individual recognition accuracy achieved by each region R as shown in Eq. 7.
                           
                              (7)
                              
                                 
                                    W
                                    e
                                    i
                                    g
                                    h
                                    t
                                    
                                       (
                                       R
                                       )
                                    
                                    =
                                    
                                       
                                          I
                                          n
                                          d
                                          i
                                          v
                                          i
                                          d
                                          u
                                          a
                                          l
                                          
                                          r
                                          e
                                          c
                                          o
                                          g
                                          n
                                          i
                                          t
                                          i
                                          o
                                          n
                                          
                                          a
                                          c
                                          c
                                          u
                                          r
                                          a
                                          c
                                          y
                                          
                                          o
                                          f
                                          
                                          r
                                          e
                                          g
                                          i
                                          o
                                          n
                                          
                                          R
                                       
                                       
                                          ∑
                                          
                                             (
                                             I
                                             n
                                             d
                                             i
                                             v
                                             i
                                             d
                                             u
                                             a
                                             l
                                             
                                             r
                                             e
                                             c
                                             o
                                             g
                                             n
                                             i
                                             t
                                             i
                                             o
                                             n
                                             
                                             a
                                             c
                                             c
                                             u
                                             r
                                             a
                                             c
                                             y
                                             
                                             o
                                             f
                                             
                                             a
                                             l
                                             l
                                             
                                             r
                                             e
                                             g
                                             i
                                             o
                                             n
                                             s
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Once the weights are assigned, the matching scores of all four regions are fused together to get combined DSAF matching scores Sw
                        , using weighted sum rule as shown in Eq. 8.
                           
                              (8)
                              
                                 
                                    
                                       S
                                       w
                                    
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       4
                                    
                                    
                                       w
                                       i
                                    
                                    
                                       s
                                       i
                                    
                                 
                              
                           
                        wheresi
                         and wi
                         represent number of the scores and weights pertaining to each of four region, respectively. The resulting matching scores are termed as weighted DSAF matching scores. For A number of subjects in dataset 1 and B number of subjects in dataset 2, we get a matching-score matrix Mj
                         of size A × B, each for PCA, LBP, and DSAF feature vectors. Since A and B have same number of subjects in training, Mj
                         is always a diagonal matrix as shown in Eq. 9.
                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             
                                                M
                                                j
                                             
                                             =
                                             
                                                [
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  m
                                                                  11
                                                               
                                                               
                                                                  m
                                                                  12
                                                               
                                                               
                                                                  m
                                                                  13
                                                               
                                                               ⋯
                                                               
                                                                  m
                                                                  
                                                                     1
                                                                     A
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  m
                                                                  21
                                                               
                                                               
                                                                  m
                                                                  22
                                                               
                                                               
                                                                  m
                                                                  23
                                                               
                                                               ⋯
                                                               
                                                                  m
                                                                  
                                                                     2
                                                                     A
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               .
                                                               .
                                                               .
                                                               ⋯
                                                               .
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               .
                                                               .
                                                               .
                                                               ⋯
                                                               .
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  m
                                                                  
                                                                     B
                                                                     1
                                                                  
                                                               
                                                               
                                                                  m
                                                                  
                                                                     B
                                                                     2
                                                                  
                                                               
                                                               
                                                                  m
                                                                  
                                                                     B
                                                                     3
                                                                  
                                                               
                                                               ⋯
                                                               
                                                                  m
                                                                  BA
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                ]
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where each mrow, column
                         represents a matching score with diagonal entries as genuine and non-diagonal entries as imposter scores, respectively. We get three matching score matrices M1, M2
                        , and M3
                         each for PCA, LBP and weighted DSAF matching scores, respectively. Each matching-score matrix is normalized row-wise on a scale of 0 to 1 using simple 
                           
                              m
                              i
                              n
                              −
                              m
                              a
                              x
                           
                         rule [24] to get a normalized matching-score matrix 
                           
                              M
                              
                                 j
                                 r
                                 o
                                 w
                              
                              ′
                           
                         as shown in Eq. 10.
                           
                              (10)
                              
                                 
                                    
                                       M
                                       
                                          j
                                          r
                                          o
                                          w
                                       
                                       ′
                                    
                                    =
                                    
                                       
                                          
                                             M
                                             
                                                j
                                                r
                                                o
                                                w
                                             
                                          
                                          −
                                          m
                                          i
                                          n
                                          
                                             (
                                             
                                                M
                                                
                                                   j
                                                   r
                                                   o
                                                   w
                                                
                                             
                                             )
                                          
                                       
                                       
                                          m
                                          a
                                          x
                                          
                                             (
                                             
                                                M
                                                
                                                   j
                                                   r
                                                   o
                                                   w
                                                
                                             
                                             −
                                             m
                                             i
                                             n
                                             
                                                (
                                                
                                                   M
                                                   
                                                      j
                                                      r
                                                      o
                                                      w
                                                   
                                                
                                                )
                                             
                                             )
                                          
                                          −
                                          m
                                          i
                                          n
                                          
                                             (
                                             
                                                M
                                                
                                                   j
                                                   r
                                                   o
                                                   w
                                                
                                             
                                             −
                                             m
                                             i
                                             n
                                             
                                                (
                                                
                                                   M
                                                   
                                                      j
                                                      r
                                                      o
                                                      w
                                                   
                                                
                                                )
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        wheremax(Mjrow) and min(Mjrow
                        ) denote the maximum and minimum values in a particular row of matching-scores matrix, respectively.

(v) The normalized matching-scores matrices 
                           
                              
                                 M
                                 1
                                 ′
                              
                              ,
                              
                              
                                 M
                                 2
                                 ′
                              
                              ,
                           
                         and 
                           
                              M
                              3
                              ′
                           
                        , each for PCA, LBP, and weighted DSAF matching scores are then fused to get a 3-dimensional matching-score space (MSS) by applying information combination approach [24]. In information combination approach, the matching scores from corresponding matrices form a score vector to represent a genuine or imposter class. Thus the vector 
                           
                              (
                              
                                 m
                                 1
                                 ′
                              
                              ,
                              
                              
                              
                                 m
                                 2
                                 ′
                              
                              ,
                              
                              
                              
                                 m
                                 3
                                 ′
                              
                              )
                           
                         is a score vector, where 
                           
                              m
                              1
                              ′
                           
                        , 
                           
                              m
                              2
                              ′
                           
                         and 
                           
                              m
                              3
                              ′
                           
                         represent the matching scores of corresponding algorithms.

(vi) Once matching scores are fused in 3-dimensional MSS, they are classified either as genuine or imposter matching scores using Support Vector Machine (SVM) [25] as a binary classifier for face verification task.

(vii) For face identification task, PCA, LBP and weighted DSAF matching scores calculated in step (iv) are fused using simple sum rule to get a matching-score matrix Mk
                         as shown in Eq. 11.
                           
                              (11)
                              
                                 
                                    
                                       M
                                       k
                                    
                                    =
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          
                                             M
                                             ′
                                          
                                       
                                       k
                                    
                                 
                              
                           
                        wheren represents number of individual algorithms. The matching-scores matrix in Eq. 11 is normalized to calculate normalized matching-score matrix 
                           
                              M
                              k
                              ′
                           
                         as shown in Eq. 12.
                           
                              (12)
                              
                                 
                                    
                                       M
                                       k
                                       ′
                                    
                                    =
                                    
                                       
                                          
                                             M
                                             k
                                          
                                          −
                                          m
                                          i
                                          n
                                          
                                             (
                                             
                                                M
                                                k
                                             
                                             )
                                          
                                       
                                       
                                          m
                                          a
                                          x
                                          
                                             (
                                             
                                                M
                                                k
                                             
                                             −
                                             m
                                             i
                                             n
                                             
                                                (
                                                
                                                   M
                                                   k
                                                
                                                )
                                             
                                             )
                                          
                                          
                                             −
                                             m
                                             i
                                             n
                                             (
                                          
                                          
                                             M
                                             k
                                          
                                          −
                                          m
                                          i
                                          n
                                          
                                             (
                                             
                                                M
                                                k
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                     

These normalized matching scores are used to determine recognition rates for face identification task.

(viii) In testing stage, we calculate the same set of feature vectors for a given probe set of face images and compare with feature vectors of face images present in dataset 1 to calculate genuine and imposter matching scores. The matching scores are then used to perform face verification and face identification experiments.

@&#EXPERIMENTS AND RESULTS@&#

We evaluate our proposed method by conducting face verification and face identification experiments on FERET, MORPH, and FG-NET databases with corresponding accuracies reported in terms of 0.001 false acceptance rate (FAR) and rank 1 identification rates, respectively. The experimental setup and results are given below.


                           
                              
                                 (i)
                                 For face verification experiments, we use 501 pairs of frontal face images from fa and fb sets in training to calculate 501 genuine and 250500 imposter matching scores each for PCA, LBP, and weighted DSAF algorithms. Dup I (722 images) and dup II (234 images) sets are used as probe sets for face verification against small and large temporal variations, respectively. A sample scatter plot showing genuine and imposter scores in proposed MSS is shown in Fig. 10
                                     for FERET training dataset. From scatter plot, it can be seen that : (1) it is possible to combine matching scores from different algorithms in proposed MSS to represent genuine and imposter scores; (2) once combined, these scores are reasonably seperated in MSS and are classified by using SVM as a classifier with radial basis function (RBF) kernel.

We have used a publically available libsvm [25] for implimentation of SVM in all of our experiments.
                              
                                 (ii)
                                 For face identification experiments, we use fa set as gallery set while dup I and dup II sets are used as probe sets. In case of weighted DSAF weights pertaining to each region are assigned using the individual recognition accuracies of region 1, region 2, region 3, and region 4 of difference half face images with extracted asymmetries as recorded in Table 2
                                    , for the above mentioned experimental setup. The performance of proposed combined, DSAF, and weighted DSAF methods is given by ROC and CMC curves for dup I and dup II sets as shown in Fig. 11.
                                    
                                 

(i) For face verification experiments, we select a subset consisting of 40000 face images of 10000 subjects from MORPH database. Starting from youngest face image of each subject, we select 2 images per subject in training. We get 10000 genuine and 99990000 imposter matching scores in training, each for PCA, LBP, and weighted DSAF algorithms. 10000 older and 10000 oldest images are used as probe sets for face verification against small and large temporal variations, respectively. (ii) For face identification experiments, we use the youngest face images set as gallery set, while older and oldest face images sets are used as probe sets. For weighted DSAF, weights pertaining to each region are assigned using the individual accuracies of four regions as given in Table 2 for the above mentioned experimental setup. The performance of proposed combined, DSAF, and, weighted DSAF methods is given by ROC and CMC curves for older and oldest image sets, as shown in Fig. 12.
                           
                        

(i) For face verification experiments, we select a subset consisting of 328 face images of 82 subjects from FG-NET database. Starting from youngest face image of each subject, we select 2 images per subject in training. We get 82 genuine and 6642 imposter matching scores in training, each for PCA, LBP, and weighted DSAF algorithms. 82 older and 82 oldest images are used as probe sets for face verification against small and large temporal variations, respectively. (ii) For face identification experiments, we use the youngest face images set as gallery set, while older and oldest face images sets are used as probe sets. In case of weighted DSAF, weights pertaining to each region are assigned using the individual recognition accuracies of four regions recorded in Table 2 for the same experimental set up as described above. The performance of proposed combined, DSAF, and weighted DSAF methods is given by ROC and CMC curves for older and oldest image sets, as shown in Fig. 13.
                           
                        

We compare the performance of proposed combined, DSAF, and weighted DSAF approaches with individual algorithms including PCA and LBP, as shown in Figs. 11–13. We also compare performance of our proposed methods with the following two state-of-the-art algorithms, developed for recognition of age-separated face images. (i) Bacteria foraging fusion (BFF) [11]: In BFF, LBP descriptor is used to calculate matching scores for different facial parts (mouth, binocular, and periocular). Weights pertaining to different facial parts are then optimized to enhance the recognition performance of age-separated face images. (ii) Multi-view discriminative learning (MDL) [13]: In MDL, three local facial features, LBP, scale invariant feature transform (SIFT), and gradient orientation pyramid (GOP), are extracted from overlapping patches of face images. An optimization problem is then solved to maximize inter-class separation and minimize intra-class separation to recognize age-separated face images. Rank 1 recognition performance of proposed methods is compared with existing methods in the form of CMC curves as shown in Figs. 11–13, both for small and large temporal variations on FERET, MORPH, and FG-NET databases.


                           Table 3
                            summarizes face verification accuracies at 0.001 FAR and rank 1 identification accuracies for proposed and existing methods for FERET, MORPH, and FG-NET databases on two protocols: the image sets with (i) small temporal variations and (ii) large temporal variations are used as probe sets.

The computational complexity of proposed combined method is analyzed in terms of feature extraction, matching scores calculation, and classification stage. We assume that number of pixels and overlapping patches in face image is N and xy, while for difference half face image is Nd
                         and XY, respectively. The computational complexity of feature extraction algorithms (PCA, LBP, and weighted DSAF) is given in Table 4
                        . The computational complexity of matching scores calculation stage has an order ofO(s
                        2), where s represents the number of matching scores calculated for PCA, LBP and weighted DSAF feature vectors. Finally, the computational complexity of SVM classifier with RBF kernel is O(KNsv) where K and Nsv represent number of testing samples and support vectors, respectively. Table 5
                         compares the computational time of proposed combined approach with that of state-of-the-art approaches BFF and MDL, computed on a machine equipped with 2.2GHz processor (Intel Core i-7) and 8.00GB RAM.


                     (i) Face verification performance: The verification results show that it is more difficult to recognize face images with large temporal variations compared to those with small temporal variations. The proposed combined and weighted DSAF approaches achieve superior performance compared to that of PCA, LBP, and DSAF. At 0.001 FAR, we achieve verification accuracy of 71.32% and 66.23% on FERET, 77.20% and 72.80% on MORPH, while 75.60% and 70.73% on FG-NET database for small and large temporal variations, respectively. Thus proposed combined approach boosts the recognition performance of age-separated face images, considerably.


                     (ii) Face identification performance: The proposed combined and weighted DSAF approaches achieve better rank 1 recognition accuracy compared to PCA, LBP, and DSAF. We achieve an accuracy of 70.08% and 63.24% on FERET, 75.40% and 69.40% on MORPH while 74.39% and 69.51% on FG-NET database for small and large temporal variations, respectively. Thus a considerable increase in identification performance is achieved by combined approach. Performance of proposed methods is also compared with two recent algorithms, BFF and MDL, developed for recognition of age-separated face images. In all identification experiments, we observe that proposed combined approach outperforms the existing methods. MDL gives 67.03% and 60.68% on FERET, 67.00% and 59.90% on MORPH while 68.29% and 63.41% on FG-NET database for small and large temporal variations, respectively. BFF gives 68.42% and 61.11% on FERET, 71.00% and 62.10% on MORPH while 70.73% and 64.63% on FG-NET database for small and large temporal variations, respectively. Compared to the proposed combined approach, BFF and MDL rely only on local facial features which, in our view, can be manipulated by extrinsic facial variations like facial make-up. In the current research we have combined holistic and local facial features with asymmetric facial features which are difficult to be manipulated by such facial variations. The complexity analysis shows that proposed algorithm is linear with respect to PCA, LBP, and APs along with SVM classifier. The most demanding stages are computation of Hu moment invariants and calculation of matching scores, with upper bound of O(N2
                        d) and O(s2), respectively. Finally, the proposed combined approach achieves better recognition results with reduced computational time compared to the state-of-the-art methods, BFF and MDL.

@&#CONCLUSIONS@&#

We presented a facial asymmetry based approach to recognize age-separated face images. Each face image was represented by extracting existing PCA and LBP based features along with newly proposed DSAF features. Matching scores of respective feature vectors were then combined in proposed matching-score space (MSS) to discriminate between genuine and imposter classes, using support vector machine (SVM) as a classifier. In conclusion, firstly it is observed that facial asymmetry is an intrinsic facial feature, which can be used to recognize age-separated face images. Secondly, it is deduced that the proposed matching-score space based approach yields better recognition results compared to those of individual matching scores of PCA, LBP, and weighted DSAF features. Thirdly, the proposed approach is more adaptable to recognize age-separated face images with reduced computational time, compared to some existing state-of-the-art methods. Finally, the recognition results suggest that it is more difficult to recognize face images with large temporal variations compared to those with small temporal variations, due to change in facial features with increasing age.

Change of facial asymmetry with progression of age and its role in recognition of age-separated face images is still a challenging problem in our view and needs continued focus of research community. Future works include the development of similar procedure using 3D facial data. Modeling facial asymmetric variations in facial age simulation process can be another direction to be sought.

@&#ACKNOWLEDGMENTS@&#

Portions of this research use the FERET database, sponsored by the DOD Counterdrug Technology Development Program Office. The authors would like to acknowledge the University of North Carolina Wilmington for providing MORPH database. The authors also thank FG-NET Consortium for providing FG-NET Aging Database.

@&#REFERENCES@&#


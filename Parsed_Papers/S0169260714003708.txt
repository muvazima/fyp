@&#MAIN-TITLE@&#Machine learning algorithms and forced oscillation measurements to categorise the airway obstruction severity in chronic obstructive pulmonary disease

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Our aim was to develop automatic classifiers to help the categorisation of airway obstruction level in patients with chronic obstructive pulmonary disease (COPD).


                        
                        
                           
                           We used different techniques, including k-nearest neighbour (KNN), random forest (RF) and support vector machines with linear and radial basis function kernels.


                        
                        
                           
                           Feature selection methods were also used to improve the performance of the classifiers.


                        
                        
                           
                           Our findings revealed that KNN and RF classifiers improved categorisation accuracy.


                        
                        
                           
                           Our study and findings will contribute to improvement of tracking COPD progression and guiding therapy.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Clinical decision support

Classification

Artificial intelligence

Airway obstruction severity

Forced oscillation technique

Chronic obstructive pulmonary disease

@&#ABSTRACT@&#


               
               
                  The purpose of this study was to develop automatic classifiers to simplify the clinical use and increase the accuracy of the forced oscillation technique (FOT) in the categorisation of airway obstruction level in patients with chronic obstructive pulmonary disease (COPD). The data consisted of FOT parameters obtained from 168 volunteers (42 healthy and 126 COPD subjects with four different levels of obstruction). The first part of this study showed that FOT parameters do not provide adequate accuracy in identifying COPD subjects in the first levels of obstruction, as well as in discriminating between close levels of obstruction. In the second part of this study, different supervised machine learning (ML) techniques were investigated, including k-nearest neighbour (KNN), random forest (RF) and support vector machines with linear (SVML) and radial basis function kernels (SVMR). These algorithms were applied only in situations where high categorisation accuracy [area under the Receiver Operating Characteristic curve (AUC)≥0.9] was not achieved with the FOT parameter alone. It was observed that KNN and RF classifiers improved categorisation accuracy. Notably, in four of the six cases studied, an AUC≥0.9 was achieved. Even in situations where an AUC≥0.9 was not achieved, there was a significant improvement in categorisation performance (AUC≥0.83). In conclusion, machine learning classifiers can help in the categorisation of COPD airway obstruction. They can assist clinicians in tracking disease progression, evaluating the risk of future disease exacerbations and guiding therapy.
               
            

@&#INTRODUCTION@&#

According to the World Health Organisation, chronic obstructive pulmonary disease (COPD) is a serious global health problem. COPD is the fourth leading cause of death worldwide, with the mortality rate estimated to rise to the third-highest position by 2030 [1]. The main pathologic feature of COPD is chronic airway obstruction [2,3]. The majority of patients follow a path of disease progression that tracks the severity of airway obstruction. Thus, the assessment of airway obstruction severity is crucial to evaluate the risk of future exacerbations and to guide therapy [2,3]. This assessment is usually performed by spirometry; however, spirometry requires a considerable degree of effort and cooperation from patients. Elderly patients, those with an inability to comprehend, or those with serious medical conditions usually have difficulty in completing this test successfully [4]. There is an agreement in the literature that research into new technologies to improve non-invasive testing of lung function should be a priority [5–8].

The Forced Oscillations Technique (FOT) allows for a simple, sensitive analysis of the respiratory system [9,10]. This method consists of applying small sinusoidal pressure variations to stimulate the respiratory system at frequencies higher than that of normal breathing and measuring the flow response. The FOT is performed during normal breathing, requiring only minimal cooperation and no forced expiratory manoeuvres. Thus, the FOT can be used in situations when standard measurement of lung function by spirometry is difficult, impractical or not feasible. The FOT characterises the respiratory input impedance (Zrs) and its two components, respiratory system resistance (Rrs) and reactance (Xrs), addressing different properties from that evaluated by forced expiratory flow. Indeed, this technique is likely complementary to spirometry [4]. This method has been successfully used in research environments for detailed studies of respiratory biomechanics [9–11] and represents the current state-of-the art in assessing lung function [12]. Despite the advantages of the FOT in terms of its non-invasiveness and lack of dependence on patient cooperation, the FOT has not become a standard methodology for the routine assessment of lung function. In the context of a diagnostic framework, although obtaining respiratory impedance values is easy, the interpretation of resistance and reactance curves and the derived parameters requires training and experience, and it is a difficult task for the untrained pulmonologist.

To simplify the diagnostic use of the FOT, our group initially developed clinical decision support systems based on machine learning (ML) algorithms that were able to help diagnose COPD [13,14]. Continuing this research, we developed automatic classifiers able to help diagnose early smoking-induced respiratory abnormalities using the FOT [15]. These classifiers also contributed to the improvement of diagnostic accuracy [13–15]. However, these studies are not focused on the assessment of airway obstruction severity, which is of utmost importance in the therapy of COPD [2,3].

Based on these promising results and limitations, we hypothesised that the use of ML algorithms associated with FOT measurements would help in the categorisation of airway obstruction severity in patients with COPD. There has been no research dedicated to this problem to date.

In this context, the aims of this study were (1) to evaluate the capability of the FOT parameters alone to correctly differentiate between different COPD conditions; (2) to investigate several ML algorithms to help the categorisation of airway obstruction severity in patients with COPD; and (3) to identify the best configuration for this task.

The remainder of this article is organised as follows. The healthy and COPD patient groups we examined are characterised in Section 2, along with a description of the measurement protocol. This section also presents the evaluated classifiers and describes the methods used for performance evaluation, classifier comparison, and experimental design. The third section presents the results, and the fourth section discusses the results with respect to the search for the best classifier and parameters for the categorisation of airway obstruction severity in the different stages of COPD. Finally, Section 5 summarises the main outcomes of this investigation and proposes future steps in this research topic.

@&#METHODS@&#

This study was approved by the Medical Research Ethics Committee of the State University of Rio de Janeiro. The work was carried out in accordance with The Declaration of Helsinki. The demographic data, including age, height and weight, were obtained from each subject at the time of the procedures. Informed consent was obtained from all volunteers before inclusion in the study.

The study included 126 patients with stable COPD who were classified according to the GOLD criteria as having a mild (G1, n
                        =24), moderate (G2, n
                        =50), severe (G3, n
                        =37), or very severe (G4, n
                        =15) airway obstruction [3]. The eligibility criteria for COPD included a history of smoking of >10 packs of cigarettes per year, an FEV1/FVC ratio of <0.7, no respiratory infections in the previous 3 weeks and an absence of other respiratory diseases or extrathoracic comorbidities including cardiovascular disease, malignant disease and chest deformities. All patients were stable at study entry. The tests were performed in the morning. Before the study, all patients were taking their usual medication as recommended by the GOLD [3], but medication that could interfere with the assessment of the BD response was suspended [as established by the American Thoracic Society/European Respiratory Society (ATS/ERS)] [16]. The sample included a control group (CG, n
                        =42) composed of healthy individuals without any previous history of pulmonary or cardiac disease or smoking. During spirometric measurements, the best of the three repeatable manoeuvres was recorded, the percentage of the predicted values of FEV1, FVC, FEV1/FVC, and FEV1%VC ratio were calculated.

In the present work, experiments were performed using eleven different datasets. For example, dataset Control_G1 presents 198 FOT measurements acquired from 66 volunteers, 42 healthy subjects (Control) and 24 COPD subjects with obstruction level 1 (G1).

Zrs was measured using a FOT device developed in our laboratory, as described previously [17]. Small amplitude pressure oscillations less than 2cmH2O peak-to-peak generated by a loudspeaker were applied at the individual's mouth while the individual breathed normally. The forced pseudorandom noise used in this study was composed of 16 harmonics (4–32Hz) of the fundamental frequency (2Hz). The subjects wore nose clips and sat upright on a chair with their cheeks and the soft tissue below the chin supported by their hands. The resulting pressure (P) and flow (V′) changes were recorded by a pressure transducer and a pneumotachograph, respectively. The pressure and the flow signals were sampled at 1024Hz for 16s in each exam. A Fast Fourier Transform (FFT) algorithm was applied to four primary data blocks of 4s and three secondary blocks obtained by 50% overlapping between the primary blocks. The average of these 7 determinations was used to reduce the statistical variability of the FFT estimation. Impedance data (Zrs=FFT(P)/FFT(V′)) corresponding to coherence values higher than 0.9 were retained for analysis and calculated by averaging three 16s exams. Measurements were conducted in concordance with the recommendations issued by a task force of the European Respiratory Society [9].

The interpretation of the multi-frequency resistive respiratory impedance data was performed using a linear regression analysis from 4 to 16Hz, which extrapolated the respiratory resistance at 0Hz (R0) and the slope (S) of the linear relationship of resistance versus frequency. These parameters are related to the total resistance and homogeneity of the respiratory system, respectively [18–20]. The analysis also included the mean resistance (Rm). This parameter is primarily sensitive to airway calibre [11].

The imaginary part of the impedance was modelled by the mean reactance (Xm) and the resonant frequency (fr), which are associated with ventilation homogeneity [21]. The respiratory system dynamic compliance (Cdyn) and the absolute value of respiratory impedance in 4Hz (Zrs4Hz) were also evaluated. Zrs4Hz represents the total mechanical load of the respiratory system [9,11] and is associated with the work required to move air in the respiratory system.

When the biometric and pulmonary function characteristics of the studied groups exhibited a normal distribution (parametric behaviour), the one-way ANOVA was applied for intergroup analysis followed by Tukey's test to compare among several groups. When the distribution exhibited a non-normal character (non-parametric), the Kruskal–Wallis ANOVA was applied for intergroup analysis, and the Mann–Whitney test was used to compare among several groups.

In the present study, the following classification algorithms were evaluated:
                           
                              •
                              K-Nearest Neighbour [22,23];

Support Vector Machines (SVM) with Linear Kernel (SVML) [24,25];

Support Vectors Machines with Radial Basis Function (RBF) Kernel [23,24]; and

Random Forest (RF) [26].

These algorithms were chosen because they represent a variety of classifier algorithms [22] and because they are some of the classifiers that performed well in previous studies [27]. A brief description of the k-nearest neighbour (KNN) classifier may be found in previous works [13,15], and a complete description can be found in the literature from References.

SVM are learning systems based on statistical learning theory [23] and have been successfully used in a variety of classification and regression problems [28,29]. For binary classification problem, the basic form of SVM is a linear classifier that performs classification by constructing a hyperplane that optimally separates the classes. The optimal hyperplane is the one that provides the maximal margin, where the margin is defined as the distance between a training sample and the hyperplane. It can be proven that this particular solution has the highest generalisation ability. This formulation can be generalised by applying a non-linear mapping of the training set. The Radial Basis Function (RBF) Kernel is frequently used to accomplish this non-linear mapping and is frequently the first non-linear mapping considered. The data are transformed into a new feature high-dimensional space where the classes are more easily separable and a decision surface (optimal hyperplane) can be found. Albeit the separating hyperplane is linear in the high-dimensional feature space created by the non-linear mapping, the decision surface found by mapping back to the original low-dimensional feature space, will be no longer linear, indicating that SVM can also be applied to data that is not linearly separable [30]. RF is an ensemble learning method that produces and combines several decision trees [26]. When used for classification, RF outputs the class that is the mode of the class's output by individual trees, while when used for regression, RF presents the average of the individual tree's results. The algorithm was developed by Breiman [26] and Cutler and involves two key aspects: Breiman's “bagging” idea and the random selection of features [31,32]. The use of bagging helps to reduce the variance by averaging many noisy, but approximately unbiased, models. Trees are ideal candidates for bagging because they can capture complex interaction structures in the data and have relatively low bias [23]. The random selection of features aids in reducing the variance of bagging by reducing the correlation between the trees. This is achieved in the tree-growing process through random selection of the input variables. Specifically, in the process of growing an individual tree on a bootstrapped dataset, before each split, a subset of m
                        ≤
                        p of the p input variables is selected at random as candidates for calculating the best split of the training set. RF is fast and presents state-of-the-art performance [27]. It can handle a very large number of input variables and offers an internal estimation of the generalisation error as forest-building progresses. Another important feature is the ability to construct variable importance plots. At each split in each tree, the improvement in the split criterion is recorded as an importance score attributed to the splitting variable. These importance scores are accumulated over all the trees in the forest separately for each variable. It is also possible to access the out-of-bagging samples to construct a different variable importance measure to measure the prediction strength of each variable. Additionally, RF can compute proximities between cases, which is useful for clustering, detecting outliers, and visualising the data (by scaling).

@&#PERFORMANCE EVALUATION@&#

To obtain the best classifier model and predict its performance on future examples (termed “generalisation”) [33,34], it is necessary to define the performance evaluation criteria. First, the performance function must be chosen based on the specific domain of the application. Some well-known performance criteria include accuracy, sensitivity, specificity, true positive rate, false positive rate, recall, precision and the area under the Receiver Operating Characteristic (ROC) curve (AUC) [35]. In this work, we chose sensitivity (Se), specificity (Sp) and AUC for the ROC curves because they are often used in medical diagnoses and allow comparison of our results to other recent studies performed by our group [13,15]. After the definition of the performance evaluation criteria, the evaluation structure must be specified to estimate the performance of the learned model from available data. We want to assess the performance of an algorithm in unobserved examples to determine its generalisation capability. This performance evaluation can be executed using either holdout or k-fold cross-validation procedures [33]. In holdout validation, it is necessary to split the available datasets into training and test datasets.

The classifier is trained with the training data set, and the performance of the trained classifier is evaluated in the test data set to estimate the generalisation accuracy. One of the limitations of holdout validation is that different data splits (i.e., different holdout sets) can produce very different results. Additionally, depending on the size of available data, the generalisation capability can be underestimated [36]. We chose to use k-fold cross-validation because it makes better use of the available dataset. The dataset is partitioned into k equal (or approximately equal) data subsets or folds [37]. For each fold in turn, that folder is used for testing, and the remaining k-1 folders are used for training a classifier. The performance of each learning algorithm on each fold can be tracked. Upon completion, k samples of the performance metric are available, and different strategies, such as averaging, can be applied as an aggregate measure of classification accuracy from these samples. This is an important feature because it prevents reporting an optimistic result obtained from a specific division of the dataset in training and test sets and helps to reduce over-fitting. It is also possible to use these samples to compare two or more ML algorithms with statistical hypothesis testing.

The hypothesis test is another key element for comparing two or more ML algorithms. In hypothesis testing, we want to determine if there is no difference in the performance of two classifiers (null hypothesis) under a certain confidence level (usually 95%). In other words, one wants to find out if the observed results be attributed to real characteristics of the classifiers under scrutiny or are they observed by chance. For comparison within one data set, Student's t-test (t-test) or one of its variations [33] is appropriate. Dietrich [34] notes that the use of a t-test has a risk of Type I errors (i.e., a false positive, or determining a difference where none exists) and suggests the use of 5×2 cross-validation or McNemar's test. For multiple data sets from different domains, Demsar [38] recommends Wilcoxon's Signed-Rank test, Friedman tests and post hoc tests. We used McNemar's test and Wilcoxon's Signed-Rank test as recommended by Dietrich [34] and Demsar [38]. The comparison of two classifiers using these tests was performed following the procedure found in [22]. The statistical tests were applied after the cross-validation, in the AUCs of the test folds. To compare the performance of multiple classifiers in multiple data sets, the Friedman test and Nemenyi post hoc test were used [39,40]. The Friedman test was used to verify if it is possible to identify a single classifier that presents a statistically significant better performance when one takes in account all the different datasets used.

@&#EXPERIMENTAL DESIGN@&#

We conducted our study in two steps. In the first step, we evaluated the capability of each of the FOT parameters alone to correctly differentiate between different COPD conditions in all datasets. The experiments performed in this step are described schematically in Fig. 1
                        .

In the second step, ML algorithms were applied to see if an increase in performance could be achieved (experiments 12–17). The AUC was used as a performance metric because it has a clinically useful interpretation of representing the probability of correctly discriminating between two subjects in a randomly selected pair of subjects with different conditions [41,42]. In a previous study [43], a single FOT parameter was considered a useful discriminator if the AUC≥0.75. However, in the present study, the cut-off was chosen to be AUC≥0.9. We increased the AUC cut-off level because the added complexity in applying ML algorithms needed to be justified with an improvement in diagnosis capability. According to the literature, ROC curves with AUCs between 0.50 and 0.70 indicate low diagnostic accuracy, AUCs between 0.70 and 0.90 indicate moderate accuracy, and AUCs between 0.90 and 1.00 indicate high accuracy [42]. Therefore, ML algorithms were applied only in the situations where the FOT parameters alone were not able to provide high accuracy.

For each dataset where the FOT parameters alone could not discriminate correctly between two conditions, ML algorithms were applied. The four classifiers (SVML, 1-NN, RF and SVM with an RBF Kernel) were implemented with a pattern recognition toolbox (prtools) in Matlab [40]. The SVML had only the regularisation parameter C. In the KNN method, K was set to 1, so we had a one nearest-neighbour classifier (1-NN). In the RF method, the parameters were the number of trees to be generated and the size of the subset of features used in each split in the individual tree-growing procedure. Because RF is an ensemble method that builds several trees, it was desirable to avoid a long time to train each tree; therefore, the number of generated trees was set to 50 and the size of the subset was set to 1. The SVM with an RBF kernel had two parameters, the regularisation parameter C and the standard deviation of the radial basis function r.

The search for the best parameters was performed individually in the training procedure for each classifier. Because a 10-fold cross-validation was used, the training was repeated 10 times; each training procedure used the chosen fold as a test set and the remaining folds as a training set. A second 5-fold cross-validation (also called internal cross-validation), which used only the training set, was performed to find the parameters to be used for each classifier. The average AUC was the performance metric. This method to find the classifier parameters was based on the nested cross-validation [44] procedure and provided extra protection against over-fitting. There is always a possibility of over-fitting with ML algorithms. Over-fitting occurs when the algorithm captures the random error or noise instead of underlying relationship present in the data. It usually occurs when a model is highly complex, for instance, having too many parameters in regard to the number of observations. A model (classifier and its chosen parameters) that has been overfit will generally have poor predictive performance, which means it will fail awfully when making predictions about new or unseen data, since it has not learned to generalise at all. To avoid over-fitting, we used nested cross-validation and carefully chose the classifier complexity and model. The SVML is a linear model trained to construct a hyperplane that optimally separates the classes (i.e., one that provides the maximal margin). It can be proven that this particular solution has the highest generalisation ability, so it is less prone to over-fitting. Furthermore, the SVM training procedure uses regularisation. This technique helps to prevent over-fitting by penalising model complexity. In the SVM algorithm, the parameter C controls the amount of regularisation. If C is small, then there is a small penalty to increase the margin, hence improving the generalisation at the cost of a few misclassified training points. If C is large, the penalty to increase the margin is higher, so there will be less of an improvement in the generalisation. Therefore, to maintain a good generalisation capability, the search for the appropriate value of C is restricted to a small interval. The RF method uses an ensemble of un-pruned decision trees trained with a bootstrapped dataset. The ensemble takes a combination of several trees, which tends to cancel out over-fitting errors.

The k-nearest-neighbour classifier, with the number of neighbours set to 1, does not have any mechanism in the training procedure to avoid over-fitting. In this case, and also for all other classifiers, the use of the k-fold-cross-validation provided an estimate of the generalisation error (and other performance criteria), which was obtained by averaging the performance criteria in the k test folds. It means that the reported result was the average performance of k classifiers trained and tested with k different partitions of the available dataset. This procedure helps to reduce over-fitting because it prevents optimistic results obtained from a specific division of the dataset in training and test sets from being reported. As previously discussed, the use of nested cross-validation in the search of the classifier parameters also helps to avoid over-fitting.

For all experiments in this part of the study, the ROC curve for the best individual FOT parameter (BFP) for the particular dataset was used to compare the performance of the classifiers (SVML, 1-NN, and RF and SVM RBF). Our choice of one-feature classification using the BFP was motivated by the current clinical scenario, where this method is used in the classification of COPD severity, which is based only in FEV1 
                        [2]. For all experiments in this part of the study, the comparisons between the designed classifiers were performed using McNemar's and Wilcoxon's tests implemented in Matlab 7.4.0 using the Statistics Toolbox (version 6.0). Both tests were utilised since there was no preference for using either one of them. It also made possible to observe the relation between the results of the two tests which could provide more information about the difference in the performance of the classifiers. In addition, the ROC curve for the best individual FOT parameter (BFP) for the particular dataset was used to compare the performance of the classifiers (SVM with Linear Kernel, 1-NN, and Random Forest and SVM with RBF Kernel). The AUCs obtained during the experiments were compared using MedCalc 8.2 (Medicalc Software, Mariakerke, Belgium) with the methodology described in Delong et al. [45]. The online supplement tables also present an indication where the tests found a statistically significant difference, since it can be useful to verify if there is an agreement with the methodology described in Delong et al. [45].

@&#RESULTS@&#

There were no significant biometric differences among the groups (Table 1
                     ). As expected, the spirometric parameters reduced progressively with COPD progression (p
                     <0.0001).


                        Fig. 2
                         shows the respiratory resistance and reactance curves as a function of frequency for the control group and for patients with COPD. The average Rrs values for the COPD subgroups increased with airway obstruction, while the Xrs values became increasingly negative as the severity of the disease increased.


                        Table 2
                         depicts the results of the comparative analysis of the resistive and reactive parameters among the studied groups. Significant increasing of R0, Rm and Zrs4Hz were observed (ANOVA, p
                        <0.001). The comparison showed a significant reduction in S (p
                        <0.0001), Xm (p
                        <0.0001) and Cdyn (p
                        <0.0001).

The detailed results of experiments 1–11 described in Fig. 1 are provided in the online supplement. It includes the ROC curves for the FOT parameters (Figs. S1–S11), associated areas under the curve (AUCs), standard errors and 95% confidence intervals (Tables S1–S11).

@&#SUMMARY@&#


                           Fig. 3
                            presents a summary of our findings in the first part of the study. FOT parameters alone are capable of providing highly accurate diagnoses (0.9≤AUC≤1.0) for the presence of COPD when the level of obstruction is high (C_G3 and C_G4). The FOT parameters also discriminate well between the levels of obstruction in COPD patients when the difference in obstruction is extensive (G1_G3, G1_G4, G2_G4).

The detailed results of experiments 12–17 are provided in the online supplement. Figs. S12–S23 depict ROC curves for the best FOT parameter (BFP) and the average ROC curve for each classifier studied. For an additional analysis of the ROC, these figures also include the Se observed at a Sp of 75% (representing moderate specificity) and a Sp of 90%. The 90% specificity level was included because it theoretically forces the cases presumed to be the most difficult into the correct disease group by allowing only 10% false positives [38]. Tables S12–S23 show the sensitivity (Se), specificity (Sp), AUC and comparison among the AUCs for the ROC curves in the figures cited. In these tables, the optimal Se and Sp points were chosen to balance the highest values of these parameters. The tables also include comparison among the AUCs (i.e., the difference between AUCs) obtained with the BFP and each studied classifier. These tables also show the agreement with the methodology presented in Delong et al. [45]. It is worth mention that these tests were applied only to compare the designed classifiers, while the methodology was applied to compare the classifiers with themselves and with the BFP. One can see that there is a high degree of agreement between the results and it was also possible to identify, for this application, that the Wilcoxon's test detected a higher number of statistical significant differences than McNemar's test.

@&#SUMMARY@&#


                           Fig. 4
                            shows a summary of the second part of the study. The use of ML algorithms improved diagnostic accuracy, allowing an AUC>0.90 in experiments C_G_ALL, C_G2, G2_G3 and G3_G4. Fig. 5
                            shows the results for the Se observed at a Sp of 75%, representing a moderate specificity, and for the Se at a Sp of 90%.

@&#DISCUSSION@&#

In this study, we designed and evaluated several ML algorithms to develop an automatic classifier to help identify the different stages of COPD using forced oscillation measurements. We have demonstrated that such a clinical decision support system, based on the use of KNN and RF classifiers, may increase the accuracy of the FOT in categorising these respiratory abnormalities, allowing us to obtain high diagnostic accuracies.


                     Fig. 3 shows that the FOT parameter alone (Zrs4Hz) is already capable of providing a high diagnostic accuracy (AUC≥0.9) for the presence of COPD when the level of obstruction is high (C_G3 and C_G4). COPD is known as a disease characterised by airway obstruction and expiratory flow limitation (EFL) [2,3]. While airway obstruction results in increased respiratory resistance, EFL introduces more negative values of respiratory reactance [9–12]. The high diagnostic accuracy presented by Zrs4Hz (Fig. 3) may be explained by the fact that this parameter reflects the combined effects of respiratory resistance and reactance. Thus this parameter is affected by both cited phenomena, which results in a high sensitivity to COPD abnormalities. The reactive FOT parameters (Xm and Cdyn) also discriminate well between levels of obstruction in COPD subjects when the difference in obstruction is extensive (G1_G3, G1_G4, G2_G4). The high diagnostic performance of these parameters may be explained, at least in part, by the increasing presence of EFL in more advanced stages of COPD [2,3].

It was established during the design of the study that an AUC≥0.9 is a useful cut-off; ML algorithms were only applied in situations where high diagnostic accuracy (AUC≥0.9) was not achieved by the FOT parameters alone. Experiments C_G1 and C_G2 reveals that FOT parameters do not provide adequate accuracy in identifying COPD subjects in the first levels of obstruction, as well as in discriminating between close levels of obstruction (G1_G2, G2_G3, G3_G4) (Fig. 3). These situations are important because they help detect COPD in the early stages of obstruction (C_G1 and C_G2) and keep track of the evolution of the disease.

In the second step of the study, we applied classifiers in cases where the FOT parameters alone did not accurately discriminate between COPD stages. Fig. 4 provides a summary of the experiments. These experiments showed that KNN and RF classifiers allowed us to improve diagnostic accuracy in all cases (C_G_ALL, C_G1, G1_G2, C_G2, G2_G3 and G3_G4). Notably, in four of the six cases, an AUC>0.9 was achieved, which indicates high diagnostic accuracy. Although the ML algorithms could not provide a high diagnostic accuracy level in C_G1 and G1_G2 (representing the early stages of the development of COPD), diagnostic capability was greatly improved. For the C_G1 dataset, AUC was increased from 0.80 (achieved with the FOT parameter Cdyn alone) to 0.87 (accomplished by the KNN classifier). For the G1_G2 dataset, the AUC was raised from 0.74 (fr) to 0.83 (RF). Goedhart et al. [46] considered 0.7 to be a good cut-off value for a useful clinical discriminator. According to Swets [42] and Golpe et al. [47], an AUC of at least 0.80 is widely accepted as adequate for diagnostic use. Although, in the present study, we considered 0.9 to be the minimum value of AUC associated with a high accuracy [42,47], the obtained results indicate that the classifiers analysed have the potential to adequately categorise airway obstruction in COPD.

For an additional analysis of the ROC curves, Fig. 5A shows the Se observed at a Sp of 75% (representing moderate specificity), while Fig. 5B shows the Se observed at an Sp of 90%. The 90% specificity level was included because it theoretically forces the cases presumed to be the most difficult into the correct disease group by allowing only 10% false positives [38]. It is also worth noting that the sensitivities at 90% Sp of the best classifier or classifiers with high diagnostic accuracy (AUC≥0.9) were always higher than the ones found using the BFP. This can also be observed in the sensitivity at 75% Sp, with the exception of the C_G_ALL dataset, where the sensitivity of the best FOT parameters and the SVM with a linear kernel (SVML) were equal. Nevertheless, for the sensitivity levels of the two other classifiers with an AUC≥0.9, KNN and RF were higher than the BFP's sensitivity.

To compare the BFP and the two best classifiers (KNN and RF) across all the data sets in the second part of the study, we used the Friedman test followed by a post hoc test, as suggested by Trawiński et al. [48]. Specifically, the Friedman test was applied and followed by a Nemenyi post hoc test. The tests found a statistically significant difference, and the average ranks were 1.25 (KNN), 1.75 (RF) and 3.00 (BFP) with a critical distance equal to 1.35. This result indicates that only KNN is better than BFP, but RF was close.

Recent recommendations for research in COPD [8] include the need for improved non-invasive mechanical tests of lung function. The present study was conducted as an effort to contribute to this need. The set of classifiers built in this work can assist clinicians not only in diagnosing COPD but also in keeping track of a patient's condition. The first classifier, built with the C_G_ALL dataset (C_G_ALL classifier), can be used to generally diagnose COPD. If the C_G_ALL classifier cannot detect COPD, then it is advisable to apply classifier C_G1 or C_G2; the patient could be in the early stages of COPD, which could be difficult to detect using the C_G_ALL classifier. Conversely, if the C_G_ALL classifier detects COPD, then the next step is to identify the level of obstruction presented in the patient. Higher levels of obstruction (G3 and G4) can be detected with the use of the FOT parameter Zrs4Hz. Lower levels of obstruction (G1 or G2) can be detected with KNN and RF classifiers. Once the level of obstruction is identified, regular appointments can be scheduled to verify obstruction level progression. An increase in the obstruction level from G1 to G2 can be verified with the RF classifier (G1_G2); in addition, an increase in the obstruction level from G2 to G3 can be established with the KNN classifier (G2_G3). Finally, to test if the obstruction level has evolved to G4, either KNN or RF classifiers can be used (G3_G4).

The use of ML and FOT measurements performed well when compared to previous reported methods of COPD diagnosis and severity classifications. Using a texture-based quantitative analysis approach in pulmonary CT images, Sorensen et al. [49] achieved an AUC of 0.713 in classifying COPD and non-COPD subjects. Guo et al. [50] used FOT and the interrupter technique to identify COPD in elderly patients. The best discriminating item was fr, which presented an AUC=0.89. The study performed by Murphy et al. [51] using CT-derived measures and a kNN classifier achieved 67% classification accuracy of subjects into the correct COPD GOLD stage, with a further 29% assigned to a class neighbouring the correct one. In an effort to achieve the diagnosis of emphysema in smokers, Van der Lee et al. [52] investigated the use of the diffusion capacity for nitric oxide (KNO) and the carbon monoxide diffusion capacity (KCO). The obtained AUCs were 0.894 for the KNO, 0.822 for the KCO. Recently Bodduluri et al. [53] evaluated the performance of CT-derived features of lung function in the identification of COPD and severity classification. Optimal features were selected by linear forward feature selection and the classification was done using the KNN algorithm. The better COPD versus non-COPD classification achieved an AUC=0.89. Classifying the subjects into the severity of GOLD stage showed improved performance in the later stages of the disease (mild, AUC=0.75; moderate, AUC=0.76; severe, AUC=0.89 and very severe, AUC=0.92). Despite the difference in the methods, we may observe that the present study exhibit a better diagnostic performance considering the COPD versus non-COPD classification (Fig. 4, AUC=0.94), as well as in the classification of COPD severity (Fig. 4: mild, AUC=0.87; moderate, AUC=0.93; Fig. 3: severe, AUC=0.95 and very severe, AUC=1.0).

The use of multiple-class system could provide a simpler decision support system than that reported in the present work. In this work, there was an extensive use of the ROC analysis in order to understand the importance of each FOT parameter on each stage of the disease. This analysis is straightforward due to the symmetry that exists in the two-class problem. The resulting performance can be graphed in two dimensions, which is easy to visualise [35]. The use of multiple-class systems would have made difficult the use of the ROC analysis. When decision problems have more than two classes the situation becomes much more complex. Instead of ROC curves, one has to deal with ROC surfaces which there are no easy way to provide a useful visualisation. One method for handling multiple (n) classes is to produce n ROC graphs, one for each class. Sometimes this is called “one versus all” approach, because you draw a ROC curve i considering a particular class ci as a positive class and the union of all other classes as a negative class. While this is suitable formulation, it compromises one of the advantages of ROC graphs, the fact they are insensitive to class skew. However, with this warning, the strategy can work well and allows reasonable flexibility in evaluation [35]. It is also possible to calculate AUC for multi-class problem, but introduces the issue of combining multiple pairwise discriminability values. As it was mentioned by Fawcett [35], two possible methods for calculating multi-class AUCs were proposed by Provost and Domingos and by Hand and Till. In the former method, they calculated AUCs for multi-class problems by generating each class reference ROC curve in turn, measuring the area under the curve, and then summing the AUCs weighted by the reference class's predominance in the data. In the latter approach, they derive a formulation that measures the unweighted pairwise discriminability of classes.

In the first exploratory experiments, it was adopted the “one versus all” approach to allow the use of the ROC analysis to evaluate the role of each FOT parameter. In the Control (C) class, Zrs4Hz was found to be the best FOT parameter (BFP) with AUC=0.89. Another good result was also encountered for the class G4 (BFP=Zrs4Hz, AUC=0.94). However, the other classes did not present results as good as classes C and G4. G1 presented BFP=fr and AUC=0.75; G2 presented BFP=S and AUC=0.60 and G3 presented BFP=fr and AUC=0.75. In order to investigate these results, each of datasets used to obtain the BFP and AUC for a particular class was further divided in other datasets with only examples from two groups. For example, the dataset G1_ALL (G1 versus all other classes) was further divided in the following datasets: C_G1, G1_G2, G1_G3 and G1_G4. When the ability to discriminate each pair of classes of the FOT parameter fr was evaluated, it was found out that it present very good differentiation capability in the datasets G1_G3 (AUC=0.90) and G1_G4 (AUC=0.97) but not in C_G1 (AUC=0.56) and in G1_G2 (AUC=0.74). This can explained because it is easier to separate higher levels of airway obstruction (G3 and G4) from lower levels (G1) than to distinguish from Control. Similar results were found in the analysis of the other datasets. For this reason, it was decided to investigate the capability of the FOT in all pairs of groups to get a better understanding of the role of each FOT in the discrimination on each pair of group.

Although the FOT has a long history in the investigation of smoking-induced respiratory diseases [9–11,43,54] and has been widely recognised as a promising method [4] and as the state-of-the art in the evaluation of pulmonary function [12], its present use is predominantly in the research domain. One of the main factors that limit its clinical use is that the interpretation of the derived parameters measured by the FOT requires training and experience. In addition, the GOLD consensus [3] recently noted that diagnostic simplicity is a key feature for the busy non-specialist clinician. The present work provides evidence that ML algorithms may contribute to an improvement in the medical services offered to patients with COPD, simplifying the use of the FOT as well as improving the categorisation of the airway obstruction severity in these patients.

Some potential limitations of the present study need to be acknowledged. First, there is not a consensus in the literature concerning the interpretation of FOT data. Previous studies used other FOT parameters that were not included in present study, which could be potentially useful in the diagnostic of COPD as well as to distinguish obstruction levels in COPD patients. These parameters include the resistance and reactance measured in specific frequencies and that obtained by compartmental model analysis [9–12,55]. Parameters obtained from a fractional order model [56] may also be useful. We believe that the contribution of these parameters should be addressed in future research.

Another limitation in our study is that during the exams, part of the oscillatory flow is shunted by the impedance of the compliant cheeks and pharynx, which are placed in parallel with the respiratory system. The resulting effect is to reduce the impedance measured in relation to its actual value [9,12]. This effect is minimal at low frequencies and becomes increasingly important as oscillation frequency rises [9]. The changes observed in Fig. 2 may be, at least partially, explained by this effect. FOT parameters associated with ML methods presented accurate diagnostic performance (Figs. 3–5). Thus, this limitation is probably not a relevant problem in the present study.

This study was focused on FOT measurements. Other methods could be potentially useful in the diagnostic of COPD as well as to distinguish obstruction levels in COPD patients, including High-resolution Computed Tomography [57] and the airflow interrupter technique [58]. We believe that the evaluation of these methods deserves further studies.

@&#CONCLUSIONS@&#

We designed and evaluated several classifier systems to develop a clinical decision support system to assist in the categorisation of the degree of airway obstruction in patients with COPD. The use of the FOT parameters alone can only help in the identification of patients with high levels of airway obstruction. KNN and RF classifiers were the most robust classifiers, reaching values that allow accurate clinical diagnosis and identifying early respiratory obstruction (levels 1 and 2). In addition, the developed system may be helpful for simplifying the use of the FOT in routine assessments of lung function. These classifiers could enhance the medical services for patients with COPD, a potentially lethal disease.

Future plans include (1) contributing to the diagnosis of airway obstruction in asthma, (2) applying interpretable models to make explaining the diagnosis achieved by the classifiers easier and (3) improving the understanding and management of COPD and its exacerbations by integrating ML algorithms and home monitoring using the FOT and telemedicine services.

None declared.

@&#ACKNOWLEDGEMENTS@&#

This study was supported by the Brazilian Council for Scientific and Technological Development (CNPq) and Rio de Janeiro State Research Supporting Foundation (FAPERJ).

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cmpb.2014.11.002.

The following are the supplementary data to this article:
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                     
                        
                           
                        
                     
                  

@&#REFERENCES@&#


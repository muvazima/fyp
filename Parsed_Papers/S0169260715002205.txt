@&#MAIN-TITLE@&#Design of novel non-contact multimedia controller for disability by using visual stimulus

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A noncontact multimedia controller is proposed to operate via visual stimuli.


                        
                        
                           
                           A wearable EEG acquisition device is developed to monitor EEG in daily life.


                        
                        
                           
                           The proposed system can effectively reduce long-term care burden.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Non-contact

Multimedia controller

Visual stimulus

Electroencephalogram

Wearable and wireless EEG acquisition device

Disabled patients

@&#ABSTRACT@&#


               
               
                  The design of a novel non-contact multimedia controller is proposed in this study. Nowadays, multimedia controllers are generally used by patients and nursing assistants in the hospital. Conventional multimedia controllers usually involve in manual operation or other physical movements. However, it is more difficult for the disabled patients to operate the conventional multimedia controller by themselves; they might totally depend on others. Different from other multimedia controllers, the proposed system provides a novel concept of controlling multimedia via visual stimuli, without manual operation. The disabled patients can easily operate the proposed multimedia system by focusing on the control icons of a visual stimulus device, where a commercial tablet is used as the visual stimulus device. Moreover, a wearable and wireless electroencephalogram (EEG) acquisition device is also designed and implemented to easily monitor the user's EEG signals in daily life. Finally, the proposed system has been validated. The experimental result shows that the proposed system can effectively measure and extract the EEG feature related to visual stimuli, and its information transfer rate is also good. Therefore, the proposed non-contact multimedia controller exactly provides a good prototype of novel multimedia controlling scheme.
               
            

@&#INTRODUCTION@&#

With the dramatic development of emerging electronics and digital media publishers, multimedia has exerted a great influence on our daily life. The revolution of multimedia also brings people new approaches to communication, commerce, education, and entertainment [1]. With the development of new multimedia presentation, novel and refreshing multimedia controllers and interaction forms have entailed huge shifts to human life.

A conventional multimedia control mechanism usually involves in manual operation, such as artificial control panels manipulated directly by hands. However, it is inconvenient for the disabled patients to operate the conventional multimedia systems by themselves. Recently, with the noteworthy improvement in studies and techniques related to multimedia control, many more natural and convenient user interfaces, such as voice control, hand gesture recognition and eye tracking, have been proposed. In 1998, Bolcioni et al. proposed a novel voice-controlled video decoding system by using an on-chip isolated word speech recognizer [2] for implementing command-oriented and menu-based applications. However, the voice-recognition based media controllers were easily affected by noise interference, and required sample training and back-end database. Gupta et al. proposed a gesture-based interaction and communication scheme using automated classification of hand gesture contours in 2001 [3]. By using nonlinear alignment, they achieved relatively high accuracy in hand gesture classification samples. However, the common drawback of these vision-based hand gesture recognition schemes was that they were easily affected by environmental conditions, such as illumination conditions and misidentified normal hand movements. Recently, eye tracking technique was also applied to the design of multimedia controllers. In 2012, Corcoran et al. proposed a real-time eye-gaze tracking scheme for the applications to game design and consumer electronics systems [4]. Instead of using wearable sensors or enhanced infrared (IR) illumination, they only used video feed from a low-resolution user-facing camera. These eye tracking-based multimedia control systems required eye-gaze or eyeball movements to perform active control commands. However, these eye tracking-based control systems were difficult to discriminate when the user wanted or did not want to perform a control command. Unintentional eyes movements and illumination conditions might cause wrong judgment on the active control commands.

Brain–computer interface (BCI) is a distinctive human–computer interface (HCI), which allows the subject performing control commands with active or passive mental commands without muscles and any physical movements [5]. By using this property of BCI techniques, a neoteric non-contact multimedia controller is proposed in this study. By focusing on the control icons of the visual stimulus device, the user can easily operate this multimedia controller without manual operation. In this study, a commercial tablet is successfully used as the visual stimulus device for the first time. This also effectively improves the convenience and practicability of other system integration applications. Moreover, a wearable and wireless electroencephalogram (EEG) acquisition device is also designed to monitor real-time EEG signals in daily life. Different from other BCI systems which require bulky EEG machines and additional processing units, the advantages of light weight, small volume, and easy setup of the proposed wearable and wireless EEG acquisition device also improves the practicability of applications in daily life.

@&#METHODS@&#

Steady state visually evoked potentials (SSVEP) are natural physiological feedback signals generated by individual brain as the responses to visual stimuli of specific frequencies [6]. When receiving a visual stimulus, the brain will transform the signals from the excited retina into EEG signal with exactly the same frequency. Recently, SSVEP is frequently used as one of the mental control methods for BCI systems. In this study, the phenomenon of SSVEP is also used as the mental control method of the proposed system.

The procedures of EEG processing and translation in the proposed system are shown in Fig. 1
                     (a) and (b), respectively. The duration between two cues can be viewed as one of translation cycles, which is less than 5s in this study. In Fig. 1(a), first, the received EEG signal is preprocessed to remove higher frequency interference. Because high-frequent flash may induce epilepsy, the frequency band of visual stimuli is set from 9Hz to 11.5Hz in this study. Therefore, a 512-point fast Fourier transform (FFT) with a 384-point overlap is used for obtaining EEG spectra, and the frequency corresponding to the maximum peak in the EEG spectra between 8Hz and 12Hz is detected. Let EEGMax(1, k), EEGMax(2, k), and EEGMax(3, k) denote the frequencies corresponding to the maximum peaks in the three consecutive EEG spectra at the kth translation cycle, as shown in Fig. 1 (b). When the three consecutive frequencies are the same [EEGMax(1, k)=EEGMax(2, k)=EEGMax(1, k)], this frequency can be viewed as the specific frequency of the visual stimulus focused. Finally, from the estimated specific frequency, the translation procedure can produce a control command corresponding to the flashing control icon focused.

However, most of BCI systems are usually synchronous which need synchronization cues to hint the beginning of each mental task. Therefore, these BCI systems are difficult to discriminate when the user wants or does not want to perform a control command. This issue also seriously reduces the practicability of these BCI systems. In this study, a specific coding scheme, as shown in Fig. 2
                     , is proposed to provide an operational mode similar to self-paced BCI systems. There are two modes in the specific coding scheme. In mode 1, whenever the user wants to perform a control command, he/she has to first focus on the unlock icon to unlock the system for executing the following control sequence. After finishing the control sequence, he/she can either focus on the lock icon to lock up the system manually or simply do nothing to wait for locking up the system automatically. In mode 2, when the multimedia begins to be played, the system is also locked up automatically. By using the proposed specific coding scheme, the user can effectively avoid mal-operation or other inadvertently behaviors that may cause the system response.

The basic scheme of the proposed non-contact multimedia controller is shown in Fig. 3
                     (a). It mainly consists of a visual stimulus device, a wearable and wireless EEG acquisition device, and a host system. First, the visual stimulus device generates six flashing control icons with different flashing frequencies (9–11.5Hz) as the sources of visual stimuli. The user can perform control commands by focusing on the wanted flashing control icon on the visual stimulus device. When the user's eyes receive the specific visual stimulus, the user brain would generate the specific EEG rhythm. Next, the wearable and wireless EEG acquisition device is used for measuring and transmitting these specific EEG rhythms to the host system wirelessly via Bluetooth. Finally, the multimedia controlling program built in the host system receives EEG signals continuously and translates them into control commands to navigate through the multimedia menu. The illustration of the proposed systems is shown in Fig. 3(b).

The wearable and wireless EEG acquisition device consists of EEG electrodes, a wearable mechanical design, and a wireless EEG acquisition circuit. By using the wearable mechanical design, the user can wear the EEG acquisition device more conveniently. The EEG electrode was placed on the occipital area (Oz) of the brain, and the reference electrode was placed near the ear. The wireless EEG acquisition circuit contains a front-end amplifier unit, a microprocessor with a 12-bits analog-to-digital converter (ADC), and a wireless transmission unit. The EEG acquisition device can be operated over 8h and charged through Micro-USB port. The block diagram of the proposed wireless EEG acquisition circuit is shown in Fig. 4
                        , and its specification is listed in Table 1
                        .

In this study, a commercial tablet is used as the visual stimulus device. Different from other LED visual stimulus devices used in most BCI systems, the ubiquitous tablet device is popular and more acceptable for the general users. A visual stimulus program is also designed to provide flashing visual stimulus sources with different flashing frequencies. The visual stimulus program provides six flashing control icons which represent specific functions, such as forward, backward, play, pause, et al. For additional accuracy and mitigating faulty operation possibilities, two additional icons (unlock and lock) are used for initializing and ending the command sequence respectively in order to provide an extra control locking mechanism.

However, the refresh rate of the commercial tablet is usually 60Hz. It is difficult to realize the specific flashing frequencies due to the refresh rate is usually not dividable by these specific flashing frequencies, for example, 9.5Hz flashing frequency generated from 60Hz LCD refresh rate. In this study, an approach was proposed to generate the specific flashing frequency. In order to generate 9.5Hz flashing frequency, 19 frames have to be interleaved in 120 refresh cycles. The division of 120 by 19*2 is equal to 3.16, and its remainder is 6. Therefore, 6 frames with 4 refresh cycles and 13 frames with 3 refresh cycles have to be randomly interleaved in 120 refresh cycles to generate 9.5Hz flashing frequency, and the interval between two frames is 3 refresh cycles. Let B and W denote the black and white frames respectively, then the simulation cycles for 9.5Hz flashing frequency can be expressed by

“WWWBBBWWWWBBBWWWBBBWWWBBBWWWWBBBWWWBBB…”

The software architecture of the visual stimulus program mainly contains resources, thread, and graphic user interface (GUI). The part of resources provides all resources of the additional display elements, which mostly are bitmap files used as menu navigation icons. The part of thread contains the threads of stimulus generation and renderer. The thread of stimulus generation provides the function of rewriting the renderer and generates multiple frequency-relevant elements that virtually represent the visual stimulus. The renderer thread is used for forming visual stimuli by rendering every frame displaying in the canvas of the application. The part of GUI offers a restricted and resource-efficient approach to develop graphic user interface and contains a graphic buffer and a frame buffer. The flowchart of the visual stimulus program is shown in Fig. 5
                        (a). First, the thread of stimulus generation generates the stimulus elements (abstract concepts in data structure) that can only form visual stimuli with a renderer. Then, the renderer thread rewrites the renderer with bitmap resources and generated stimulus elements. Next, the renderer and stimulus generation threads send the generated data to the graphic buffer separately. The other display components, such as menu, are written into the frame buffer along with data in the graphic buffer. In order to improve the performance of display, the elements in the graphic buffer must be presented via the frame buffer. Then, the program uses the data in the frame buffer for generating sequential frames to form continuous visual stimuli. Fig. 5(b) shows the screenshot of the visual stimulus program.

A commercial laptop is used as the platform of the host system. A multimedia controlling program is also designed as the main host application. Besides receiving EEG data and generating relevant multimedia control commands, the multimedia controlling program also provides the function of displaying information and status about the current system and multimedia contents. Based on the abundant multimedia support of the operational system, it makes the whole host system experience flexible and amusing.

The software architecture of the multimedia controlling program consists of resources, graphic user interface (GUI), and threads. The part of resources contains the external resources needed in the program, such as multimedia storage and media codec packs that help decode multiple media forms. The part of GUI is mainly a graphic multimedia content browser linked to multimedia storage. The thread of BT API is used for setting Bluetooth communication between the wireless EEG acquisition device and the host system. The thread of EEG translation is designed to translate EEG signals into control commands; and, the thread of multimedia player performs control commands, such as play/pause multimedia. The flowchart of multimedia controlling program is shown in Fig. 6
                        (a). At first, the program builds GUI, and then the thread of BT API searches for the wearable and wireless EEG acquisition device and creates a secure simple pairing (SSP) stream to connect with the device. Next, the thread of EEG translation translates the received EEG signal into a control command sequence. Then, the program checks the system lock status. When the status is unlocked, the program would execute the sequential control commands successively until a lock instruction or a locked status is detected. Otherwise, when the status is locked, the program would not execute any control commands until an unlock status is detected. During the execution period of instruction sequence, the system would activate the multimedia player with accesses to the multimedia storage and codec packs and lock down the system automatically to avoid mal-operation, when the play control command is performed. Fig. 6(b) shows the screenshot of the multimedia controlling program.

The comparison between the proposed system and other multimedia controllers is shown in Table 2
                        . In 2013, Anderson et al. proposed a tri-modal automatic speech recognition system for consumer applications [7], where a microphone was used for inputting the control command and a thermal camera was used for providing visual analyses to reduce the effects of environmental noises. In general, the voice-based controllers usually involved in sample training, but were also easily affected by environmental noises. The voice-based control system, proposed by Anderson et al., could effectively mitigate the influence of environmental noises, but also required more expensive cost. In particular, the cost and bulky volume of the thermal camera made this system rather unpractical. In 2012, Jeong et al. proposed a television control system based on gesture recognition [8], where a single camera was used for capturing hand gesture and a specific circuit was designed to transform the gesture invariants into control commands. The hand gesture recognition-based controllers usually needed sample training to achieve maximum accuracy, but were also easily affected by the illumination condition and the hand gestures of other people. In 2012, Cho et al. proposed an eye tracking control system with two wide-angle cameras and two narrow-angle cameras to capture and track the movement of eyeballs [9], where an additional infrared illuminator was required for improving the system accuracy and a high-performance backend computer was also required for performing the eye tracking technique. Compared with other multimedia controllers, the proposed system provides a novel operational mode. The user can easily operate this multimedia controller by merely focusing on the control icons without manual operation. Moreover, it also provides the advantages of easy setup and simple training. Besides, it may also contain the application potential for disabled users in the future.

@&#EXPERIMENTAL RESULTS@&#

The reliability of the wearable and wireless EEG acquisition device was validated in this section. In this experiment, the subject was instructed to sit on the chair, and then focused on one of these stimulus control icons on the visual stimulus device for one minute, and a test program would record corresponding EEG signals for analyses. The distance between the visual stimulus device and the participant was about 30cm. The primary input electrode was placed on the location of Oz. The results of raw EEG signals and their spectra corresponding to different visual stimuli are shown in Fig. 7
                        . Obviously, different peaks could be found at the frequencies of the EEG spectra corresponding to different specific frequencies of visual stimuli. Therefore, the proposed wearable and wireless EEG acquisition device could effectively measure steady state visually evoked potentials and be exactly applied to the proposed non-contact multimedia controller.

The performance of the proposed non-contact multimedia controller was tested in this section. Here, information transfer rate (ITR) was used for evaluating the system performance [10], and it was defined as follows.
                           
                              (1)
                              
                                 
                                    Bits
                                    /
                                    symbol
                                    =
                                    
                                       
                                          log
                                       
                                       2
                                    
                                     
                                    N
                                    +
                                    P
                                     
                                    
                                       
                                          log
                                       
                                       2
                                    
                                     
                                    P
                                    +
                                    (
                                    1
                                    −
                                    P
                                    )
                                    
                                       
                                          log
                                       
                                       2
                                    
                                    
                                       
                                          
                                             
                                                1
                                                −
                                                P
                                             
                                             
                                                N
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where the parameter bits/symbol denotes the information transfer rate (bits/trial), N is the number of possible mental choices, and P is the accuracy of EEG translation algorithm. Then the bit rate could be calculated by
                           
                              (2)
                              
                                 
                                    Bit rate
                                    =
                                    (
                                    bits
                                    /
                                    symbol
                                    )
                                    *
                                    (
                                    symbols
                                    /
                                    minute
                                    )
                                 
                              
                           
                        
                     

A total of 10 disabled patients, aged from 25 to 65 years old, attended this experiment in a medical center located in southern Taiwan. All disabled patients did not have experiences in operating this system or pre-training. Before the experiment, a staff instructed the disabled patients how to operate this system. In order to evaluate the performance of this system, several parameters of binary classification test were first defined as follows. True positive (TP) indicated the mental command being correctly detected as the same control command (the output of this system). False positive (FP) indicated no mental command being wrongly detected as a control command or the mental command being wrongly detected as a wrong control command. True negative (TN) indicated no mental command being correctly detected as nothing. And, false negative (FN) indicated the mental command being wrongly detected as nothing. The sensitivity and specificity of this system were about 87.9±7.5% and 90.7±5.2%, respectively. In this system, N was set to 6 as the visual stimulus device contained six different control icons. Therefore, the information transfer rate of the proposed system was about 1.65–2.25 bits per trial. The interval of EEG translation cycles is about 5s in this system so that the optimum bit rate of this system was about 27bits/min.

@&#DISCUSSION@&#

Several groups, such as the Wadsworth Center, Graz group, the Neil Squire foundation, et al., proposed different BCI systems for multimedia communication applications [11], for example, cursor control, and their best bit rate is about 20bits/min. Muller-Putz et al. designed an asynchronous brain-switch based on motor imagery [12]. Here, Laplacian derivation was used to enhance EEG component related to motor imagery, and Fisher's linear discriminant with EEG power was used to discriminate the events of motor imagery. The average of the accuracy is about 80.8%. Erfanian and Hazrati proposed a novel BCI for hand grasping and opening in an interactive virtual reality environment [13]. Adaptive probabilistic neural network was used to detect hand grasping and opening from EEG signals recorded from F3, F4, Fz, Pz, C3, C4, and Cz in the international 10–20 system. The average of the accuracy is about 89.5%. Lehtonen et al. used the average of EEG amplitude in specific band as the BCI feature [14]. The feature was transformed via three linear transformations of feature space. Here, a linear classifier with a logistic output function was used as the classifier. The average accuracy is about 80% and bit rate is about 10bits/min. In previous studies related to SSVEP-based BCIs, the common information transfer rate was about 0.42–2.48 bits per trial [10,15,16]. In 2010, Wang etc. proposed a visual stimulus design for high-rate SSVEP BCI [17]. In this visual stimulator, 16 flashing icons were used, and ITR of this SSVEP BCI could achieve about 75.4bits/min. From the experimental results, ITR of the proposed system is about 1.65–2.25 bits per trial (19.8–27bits/min). Therefore, the experimental results exactly show the reliability of the proposed system.

In this study, in order to reduce the detecting error, the three consecutive frequencies corresponding to the maximum peaks in the EEG spectra have to be the same, and then this frequency can be viewed as the specific frequency of the visual stimulus focused. Moreover, the increase of frequency interval or viewing area of flashing control icons should also improve the above issue effectively. Different from other BCI systems which need bulky EEG machines and multi-channel EEG signals to extract EEG information, the proposed non-contact multimedia controller uses a wearable and wireless EEG acquisition device and single channel EEG signals to extract SSVEP. This also effectively improves the convenient use. Moreover, most of SSVEP-based BCIs use light-emitting diodes (LED) as the visual stimulus device and personal computers or FPGA boards as the backend signal processing unit. The proposed non-contact multimedia controller uses a commercial tablet as the visual stimulus device for the first time, and this also effectively improves the convenience of setup and system integration. The commercial tablet is light and popular, and the acceptability might be enhanced for general users. Although its setup cost is higher than LED, this technique can provide high compatibility for other LCD commercial products, such as LCD television, and can be easily applied to other applications in the future.

The basic concept of the non-contact multimedia controller has been mentioned in our previous study [18], although it was just an immature device in the development stage and did not be applied in clinical applications. Different from the system proposed in Ref. [18], a wearable mechanical design was designed and implemented, and the wireless EEG acquisition circuit was redesigned to reduce its size in this study. In our previous study, the visual stimulus device was developed on a commercial computer. In this study, the specific flashing frequency was redesigned and was first implemented in a commercial tablet as the visual stimulus device. After completing the whole system of the wearable and wireless EEG acquisition device, it could be successfully applied in clinical test.

In order to understand the benefits of the proposed system for disabled patients, there were in-depth interviews with the patients, patients’ families and nursing assistants as qualitative research at first. Then the data of medical questionnaires were referred to devise a questionnaire for the patients, patients’ families and nursing assistants as questionnaire investigation. Therefore we not only took the depth and the breadth of research into account, but also had the reliability and the validity of quantitative research. There were 30 respondents taking part in this questionnaire investigation, and the age of these respondents was between 25 and 65 years old. The content of the questionnaire, which included patients could operate the proposed systems by themselves was shown as Table 3
                     . There were 10 questionnaires provided for patients, and 20 questionnaires for patients’ families and nursing assistants. The result showed the agreement is more than 80%. It meant the respondents confidently approved the proposed system. The result of the questionnaire investigation was shown in Table 3.

@&#CONCLUSIONS@&#

In this study, a novel non-contact multimedia controller is proposed. Based on the technique of brain–computer interface, the proposed system can be used for controlling multimedia without manual operation directly. Here, a tablet is first used as the visual stimulus device, and a specific coding scheme is proposed to provide the property of asynchronous operation in order to improve the practicability of the proposed system. Moreover, a wearable and wireless EEG acquisition device is also developed in this study. By the advantages of light weight, small volume, and easy setup of the proposed EEG sensor, the proposed system can be easily set up and used in daily life. The whole system performance of the proposed non-contact multimedia controller has been tested and validated, and its information transfer rate is good (2.25bits/trial). The properties of non-contact operation and easy setup and use of the proposed non-contact multimedia controller provide a good prototype for novel multimedia controllers, and from Table 3 we knew that patients felt happy because they could operate the proposed system by themselves. Therefore, the proposed system could effectively reduce the long-term care burden of the patients’ families and nursing assistants.

The authors declare no conflict of interest.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cmpb.2015.08.010.

The following are the supplementary data to this article:
                        
                           
                        
                     
                  

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Supporting healthcare management decisions via robust clustering of event logs

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We present an effective way to summarize patients’ pathways.


                        
                        
                           
                           A new spectral approach that emphasizes robustness is proposed for trace clustering.


                        
                        
                           
                           The method is applied to the emergency department of a public hospital.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Process mining

Clustering

Robustness

Knowledge discovery

Healthcare management

@&#ABSTRACT@&#


               
               
                  Business processes constitute an essential asset of organizations while the related process models help to better comprehend the process and therefore to enable effective process analysis or redesign. However, there are several working environments where flows are particularly flexible (e.g., healthcare, customer service) and process models are either very hard to get created, or they fail to reflect reality. The aim of this paper is to support decision-making by providing comprehensible process models in the case of such flexible environments. Following a process mining approach, we propose a methodology to cluster customers’ flows and produce effective summarizations. We propose a novel method to create a similarity metric that is efficient in downgrading the effect of noise and outliers. We use a spectral technique that emphasizes the robustness of the estimated groups, therefore it provides process analysts with clearer process maps. The proposed method is applied to a real case of a healthcare institution delivering valuable insights and showing compelling performance in terms of process models’ complexity and density.
               
            

@&#INTRODUCTION@&#

Business processes are valuable assets of every organization. They control the revenue potential as much as they shape the cost profile of an organization. Processes directly affect the attractiveness of products and services as perceived by the market and they define the ability of organizations to adapt to new circumstances [10]. Therefore, it is no surprise that organizations strive to model, revise, and optimize their internal business processes, as well as the processes shared with other organizations.

In working environments with strong behavioural diversity (i.e., environments where deviations in the process control flows are common), business models are usually ambiguous [13]. In such environments, the problem concerning business process awareness can be defined as follows: are there any dominant patterns of process behaviour? Is it possible to identify groups of cases with similar behaviours? The objective of this paper is to propose a method that delivers compact and comprehensive synopses of flexible behaviours, keeping in mind the end goal to best support their analysis and improvement.

As an example, in this paper we consider a case study involving the clinical pathways of patients in a hospital, where there is a diverse set of paths followed depending on the peculiarities of each patient. The resulting complex behaviour of the business processes in such an environment can be observed through the trace that every patient leaves. On that account, a process mining perspective is followed in this study. The idea of process mining is to discover, monitor and improve real processes by extracting knowledge from event logs, which are readily available in business information systems [37]. Event logs may store additional information about events (like the timestamp and the resource performing the activity). In other words, each case is leaving a trace, which corresponds to the observed behaviour.

When it comes to clinical pathways analysis, process mining techniques face a critical challenge: Patients routes vary significantly and in order to deliver comprehensive models, the event log should be someway summarized [34]. The authors in [17] propose a horizontal summarization, by partitioning the event log into time intervals. In [16], the authors exploit a rich dataset of patients’ traces to summarize the clinical pathways based on a behavioural topic analysis. Indeed, as the authors in [19] discuss, the integration of medical knowledge can significantly improve the comprehensibility of the results.

Often, however, such medical knowledge is not available (e.g., relevant data are not recorded, or data are considered too sensitive to be provided, or even medical experts are not available for the process analysis project). In this paper, we focus on such cases; therefore, we follow a trace clustering approach that mostly relies on the control-flow features of the cases.

Trace clustering aims at discovering clusters with related behaviours. However, considering the set of traces in the event log all at once often leads to ambiguities because the event log contains traces of cases that may refer to very different behaviours (i.e., potentially unique or infrequent cases). By identifying clusters of diverse traces, process discovery techniques could be connected to subsets of behaviours and subsequently deliver more clear, coherent and comprehensible process models.

In this framework, this study contributes by proposing a method that relegates the effect of infrequent behaviours (without ignoring them) and eventually provides effective summarizations of the event log. This is achieved through clustering the traces using a more stable similarity metric. The stability of the metric is reached by introducing the concept of neighbourhood. This addition allows promoting any prevalent patterns, while it reduces the impact of isolated cases to the clusters’ formation. In this way the proposed methodology provides compact information and meaningful insights to managers as it facilitates the derivation of a simple interpretation of a complex business process, thus allowing process stakeholders to communicate on an evidence-based ground.

The rest of the paper is organized as follows. The next section provides a brief overview of related works. In Section 3, we describe the case study of a public hospital and the proposed methodology. The approach is analytically presented in Section 4, while the obtained results are discussed in Section 5. Finally, a short discussion concludes the paper.

@&#RELATED WORKS@&#

Flow variability in healthcare processes arises due to the highly customized medical guidelines that describe how patients are treated. Furthermore, it is possible that process analysts and stakeholders do not actually need a complete process model, but just an understanding of a dominant behavioural pattern. In cases where a process is expected to be realized over instances with very different behaviour, discovering a single model would seldom provide clear answers, since the generated models would be complex and confusing (i.e., “spaghetti” models as in [35], p. 301). Clustering different behaviours and discovering a process model per cluster has been identified as an effective solution [11].

An initial and influential approach, presented in [33], proposes the creation of feature vectors for each trace followed by the application of common clustering techniques. Features could be bag-of-activities, transitions, resources, case attributes, etc., while clustering techniques include k-means, agglomerative hierarchical clustering, and self-organizing maps. That work introduces the concept of “profiles” for traces, which allows for context information to be considered. However, the stability of the results is not discussed. An ordinary clustering technique (e.g., agglomerative hierarchical clustering) is also used in [18]. In this case, traces are evaluated for their similarities by the activities and the transitions vector. This similarity metric is simple, yet quite straightforward to infer control-flow similarities. While hierarchical clustering is effective in showing how different traces differ from each other, this form of clustering has its disadvantages. The primary disadvantage is that hierarchical clustering is only effective at splitting small amounts of data. When the event log is small, patterns and relationships between clusters are easily discernable. As the event log grows, so does the dendrogram, and this usually results in the loss of information. Besides, all determinations are strictly based on local decisions and a single pass of analysis.

The authors in [41] try to resolve spaghetti models through sequence clustering, i.e., identify frequent sequences of activities through a Markov chain representation. The proposed method could support the post-processing of cluster models (e.g., by discarding infrequent elements). However, the applied algorithm could result in multiple cluster solutions. For instance, the applied migrating-drifting means approach makes the final cluster solution dependent, to some extent, on the order in which the traces are considered for relocation.

Another approach is to use syntactic techniques which operate on the whole sequence “as-is” by applying string distance metrics such as the Levenshtein distance and the generic edit distance, in conjunction with standard clustering techniques [2,3]. A distinctive feature of this approach is that instead of assuming the causes that could explain the variation in process instances (e.g., due to different time periods as noted in [23]) – a task that requires intensive domain knowledge – clusters are created based on a simple similarity metric and variability causes are induced a posteriori (that is, we gain knowledge about the domain). An additional contribution is that the whole method is centred on the robustness of the final solution.

Many approaches, from the area of management and information technology, can be adopted by a healthcare organization in order to optimize its efficiency and effectiveness and to be competitive [22]. The authors in [8] provide a brief overview of business intelligence techniques applied to healthcare services. Moreover, data mining approaches can uncover new biomedical and healthcare knowledge for clinical and administrative decision making as well as generate scientific hypotheses from large experimental data [46]. Should the focus of the research is in discovering rules for temporal patterns (and not process models like in this work), several methods based on local patterns mining can be employed. Such rules are extracted as sequence patterns [7,12,29]. Another approach is to exploit temporal probabilistic models to model healthcare problems. In this category, Bayesian networks are the most visible technique [42]. An additional potential is to exploit temporal data of healthcare services to build predictive models. To this end, different learning algorithms have been applied. The focus of these works is on building predictive data mining models with temporal data (see [1]) using supervised or semi-supervised techniques, like positive-unlabelled learning [15]. However, data mining approaches are data-centric and not process centric [36]. Thus, their output is not directly related to the process mining approach proposed in this work.

Concentrating on process mining techniques, a visible work is that in [30], where the authors developed a methodology for the application of process mining techniques that leads to the identification of regular behaviour, process variants and exceptional medical cases. An additional use of process mining is to check for conformance (process stakeholders can match the assumed process model with the real one – derived from discovery in the event logs) and check if medical standards or administrative guidelines are followed.

The hospital under consideration in this study is situated in the city of Chania, Greece. It was established in 2000 and has a capacity of 465 beds and 36 operating departments. The hospital is a general public health unit, providing first and secondary degree health care to the residents of the prefecture of Chania. On an annual basis, the hospital has more than 100,000 emergency patient visits and 120,000 external patient visits for medical exams, while the total number of inpatient visits is 25,000 and the number of surgeries is about 5500. This study focuses on the emergency department process. A rough (verbal) description of the process which was provided through interviewing the manager of the emergency department follows.

The emergency department has two subunits (ED1 and ED2). The first one (ED1), runs 16hours per day and the second one (ED2), 24hours per day. Generally, patients that arrive between 08:00 and 23:00 have to pass through registration (during the night shift there is no secretary available, due to cost cutting). Depending on the triage (extremely important cases are labelled with red triage, not severe cases are labelled with green, and the rest with yellow), patients can skip registration. Patients have to provide the necessary information (e.g., name, age) and pay a fee for medical examination. Afterwards, they have to wait at the waiting room. A nurse asks patients about their problems and characterizes the level of the triage. Patients that arrive by the ambulance are sent directly to ED2. Furthermore, patients with urgent problems (e.g., cardiological incidences or serious accidents) receive the highest priority level (red) and are sent directly to ED2. When a patient enters the room of diagnosis, the nurse checks his/her temperature, blood pressure, and heartbeat. Then the physician provides an initial examination. Depending on the level of triage, a patient waits for the lab results at the waiting room or in bed. When the physician delivers the results of the examination, there are three possible next steps. If the case is serious, the patient is sent to the appropriate department of the hospital. Alternatively, the patient may receive a prescription and is sent back home. The third choice is to decide that the patient will stay at the wards of the emergency department in order to make more lab tests.

The data used in this study were collected manually (by the nurses of the emergency department) during some random days of the first half 2013. Every second patient that visited the emergency department during those days was recorded. In particular, the triage and the type of incident were recorded for every patient, as well as the timestamp for each event of that patient. These events correspond to 21 event classes (the actual steps of the process, like for instance “arrival”, “blood test”, “X-ray test”, etc.). Overall, 1867 events were recorded corresponding to 240 different patients.

@&#METHODOLOGY@&#

The process of the emergency department in our case study is governed by some rules and a general operational plan. However, there is no typical process model, not to mention a process model capable to describe every possible path. The lack of existence of such a model results in three major drawbacks. First, the management does not have a view of the flows inside the process (or it has an idealized view of them). Second, it is very hard to check for the compliance of operations to any guidelines. Finally, the performance-wise optimization of the process is not possible. Therefore, it is essential to come up with a process model to set up any management support activities. For this purpose, we propose the methodology illustrated in Fig. 1
                        .

The first step is to discover the overall process model for the emergency department. Any discovery technique can be used at this step, for example the alpha miner [38] or the heuristic miner [45]. However, since we are particularly interested in assessing the variability of the flows within the process, we shall employ a discovery technique that is able to reveal all the paths instead of just the most frequent ones, for example the fuzzy miner without any abstractions [14] or the ILP miner [40].

The next step is to assess variability, which refers to the comprehensibility of the discovered process model. At this stage we suggest to evaluate variability empirically, through the visualization of the process map (a “spaghetti” or a neat diagram) or through a histogram of the variants’ frequencies. If the process analyst evaluates the process flow variability as low, he/she can move on by showing the process map to the management board. If the analyst considers the variability as high, he/she has to define a similarity metric between different flows and to proceed by comparing the variants’ similarities. Such a pairwise comparison may expose extraordinary, infrequent paths. If such paths are faint or of minor importance, the analyst can directly proceed by clustering the variants. However, if such paths are a critical part of the variants population, then an extra step is required. This step is about modifying the similarity metric towards a more robust version, which can deal more effectively with the presence of many infrequent (or even unique) items.

Eventually, either with the simple similarity metric, or with a more elaborated and robust one, a clustering algorithm may partition the variants into a finite number of coherent clusters. Finally, a process model can be discovered per cluster. The new categorized process models are expected to contain more effective visualizations and to guide more pointed interpretations.

Following the proposed methodology, the first step is to discover the overall model. To this end, we applied the Fuzzy Miner [14] as implemented by Disco (http://fluxicon.com/disco). The discovered model is used as an input for the second step (variability assessment). The discovered process map is illustrated in the spaghetti diagram of Fig. 2
                        , wherein the nodes represent the activities of the process (e.g., “arrival”, “blood test”, etc.) and the arcs represent the corresponding transitions. Due to its complexity (since the process flow does not follow a single specific pattern), the diagram of Fig. 2 is of little usefulness for the management committee.

Moreover, it is not possible to concentrate on the most frequent variants in the process, since, due to the high variation in the process, the most frequent variants would cover only a small percentage of the patients. As Table 1
                         shows, the three most frequent variants correspond to less than one third of the total traces. Moreover, to reach 75% of the traces population we need to consider 25 variants. This fact is illustrated in Fig. 3
                        , where we plot the frequency of each variant. We see that for the 240 patients we observed 84 process variants. Only 31 patients followed the most frequent variant, while there are 68 variants that were followed by just one or two patients.

First of all, we shall note that the proposed method could work with any similarity metric. In [9] different similarity metrics are compared and evaluated. Some of the most popular metrics are the graph-edit distance, the cosine similarity, and the Euclidean, or Hamming distances that can be used for vector space models. However, our view is that there is no single optimal similarity metric for all domains and all kind of applications. In this work we propose a metric based on the cosine similarity, because its range is normalized. Nevertheless, the proposed methodology could accept virtually any other similarity metric, without needing to change anything.

The proposed metric eventually captures the similarities between two traces in terms of both their activities, as well as their sequencing. This approach considers the dependencies among activities simultaneously with the resemblances of the activities in a trace. A similar approach is also followed in [18]. Nevertheless our approach is different in the components used, since in [18] similarities are calculated between process models while in this work, similarities refer to traces’ variants.

To that end, two vectors are created for each trace: The first one, 
                           
                              
                                 
                                    a
                                 
                                 
                                    k
                                 
                              
                              (
                              i
                              )
                           
                         is an ordered binary vector (0 and 1) whose kth
                         element is set equal to 1 if and only if activity 
                           
                              k
                           
                         has been observed in trace 
                           
                              i
                           
                        . The second one, 
                           
                              t
                              (
                              i
                              )
                           
                         is the vector format of a square matrix 
                           
                              M
                              (
                              i
                              )
                           
                         whose rows 
                           
                              k
                           
                         and columns 
                           
                              l
                           
                         are both equal to the number of activities 
                           
                              (
                              k
                              =
                              l
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              K
                              )
                           
                        . The elements of 
                           
                              M
                              (
                              i
                              )
                           
                         are calculated as follows:
                           
                              (1)
                              
                                 
                                    
                                       M
                                    
                                    
                                       k
                                       ,
                                       l
                                    
                                 
                                 (
                                 i
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             d
                                          
                                          
                                             k
                                             ,
                                             l
                                          
                                       
                                       (
                                       i
                                       )
                                    
                                 
                                 
                                 for every trace
                                 
                                 
                                 i
                              
                           
                        where 
                           
                              
                                 
                                    d
                                 
                                 
                                    k
                                    ,
                                    l
                                 
                              
                              (
                              i
                              )
                           
                         is the distance of the transition between activities 
                           
                              k
                           
                         and 
                           
                              l
                           
                         in the ith
                         trace. That is, if 
                           
                              k
                           
                         is directly followed by 
                           
                              l
                           
                        , then 
                           
                              
                                 
                                    d
                                 
                                 
                                    k
                                    ,
                                    l
                                 
                              
                              (
                              i
                              )
                              =
                              1
                           
                        , whereas if 
                           
                              l
                           
                         follows 
                           
                              k
                           
                         after let’s say 5 activities, then 
                           
                              
                                 
                                    d
                                 
                                 
                                    k
                                    ,
                                    l
                                 
                              
                              (
                              i
                              )
                              =
                              5
                           
                        . Assuming that 
                           
                              
                                 
                                    t
                                 
                                 
                                    n
                                 
                              
                              (
                              i
                              )
                              =
                              
                                 
                                    M
                                 
                                 
                                    k
                                    ,
                                    l
                                 
                              
                              (
                              i
                              )
                           
                         with 
                           
                              n
                              =
                              (
                              k
                              -
                              1
                              )
                              K
                              +
                              l
                           
                        , it is easy to observe that 
                           
                              t
                              (
                              i
                              )
                           
                         is an ordered real vector defined in 
                           
                              [
                              0
                              ,
                              1
                              ]
                           
                        .

The cosine similarity for the activities vector will return higher values for pairs of traces that have more common elements (i.e., contain similar activities), while the cosine similarity for the transitions vector will return higher values for pairs of traces that involve similar precedences between two shared activities. The corresponding formulas are:
                           
                              (2)
                              
                                 
                                    
                                       sim
                                    
                                    
                                       activities
                                    
                                 
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             k
                                          
                                       
                                       
                                          
                                             a
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       i
                                       )
                                       ×
                                       
                                          
                                             a
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       j
                                       )
                                    
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                
                                             
                                             
                                                
                                                   a
                                                
                                                
                                                   k
                                                
                                             
                                             
                                                
                                                   (
                                                   i
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                             ×
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                
                                             
                                             
                                                
                                                   a
                                                
                                                
                                                   k
                                                
                                             
                                             
                                                
                                                   (
                                                   j
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       sim
                                    
                                    
                                       transitions
                                    
                                 
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             t
                                          
                                          
                                             n
                                          
                                       
                                       (
                                       i
                                       )
                                       ×
                                       
                                          
                                             t
                                          
                                          
                                             n
                                          
                                       
                                       (
                                       j
                                       )
                                    
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   n
                                                
                                             
                                             
                                                
                                                   t
                                                
                                                
                                                   n
                                                
                                             
                                             
                                                
                                                   (
                                                   i
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                             ×
                                             
                                                
                                                   ∑
                                                
                                                
                                                   n
                                                
                                             
                                             
                                                
                                                   t
                                                
                                                
                                                   n
                                                
                                             
                                             
                                                
                                                   (
                                                   j
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Both formulas will return non-negative values in 
                           
                              [
                              0
                              ,
                              1
                              ]
                           
                        , since all elements of vectors 
                           
                              a
                           
                         and 
                           
                              t
                           
                         are non-negative. Finally, in order to attain a single metric, a weighted sum of the two coefficients can be calculated, so that the similarity 
                           
                              
                                 
                                    s
                                 
                                 
                                    ij
                                 
                              
                           
                         between two traces 
                           
                              i
                           
                         and 
                           
                              j
                           
                         can be expressed by the following formula:
                           
                              (4)
                              
                                 s
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       s
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 
                                    
                                       w
                                    
                                    
                                       a
                                    
                                 
                                 
                                    
                                       sim
                                    
                                    
                                       activities
                                    
                                 
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 +
                                 
                                    
                                       w
                                    
                                    
                                       t
                                    
                                 
                                 
                                    
                                       sim
                                    
                                    
                                       transitions
                                    
                                 
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        where 
                           
                              
                                 
                                    w
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                           
                         are the weights for activities’ cosine similarity and transitions’ cosine similarity, respectively. There are many ways to assign values to these weights, e.g., direct assessment, goal programming or disaggregation methods [32]. In any case, it is important to note that 
                           
                              
                                 
                                    w
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                           
                         in (4) have the role of trade-offs between the different types of similarity (see a detailed discussion in [20]). However, since this is an issue beyond the scope of this work, we choose to work with the relative importance of 
                           
                              
                                 
                                    w
                                 
                                 
                                    a
                                 
                              
                           
                         and 
                           
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                           
                         (i.e., 
                           
                              
                                 
                                    w
                                 
                                 
                                    a
                                 
                              
                              +
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                              =
                              1
                           
                        ), weighting the activities’ similarity factor with 0.3 and the transitions’ similarity factor with 0.7. We decided to promote the transitions similarity because the activities set is relatively small (just 21 distinct activities exist in the process), and many of them are common for most patients, albeit with a different sequence.

In real-world applications and especially in working environments with bending workflows (like healthcare), one should expect noise and outliers in the data. In particular, in the healthcare domain, outliers will often signify patients with special needs (e.g., to re-take some laboratory tests). Labelling these special cases as outliers is not an option (e.g., in our case such an approach would discard more than 2/3 of the data). Thus, such cases should be retained while controlling for their low frequency of occurrence.

Therefore, in this work we propose an adjustment of the similarity metric (which could be applied in general to any similarity metric) in order to handle infrequent data and noise, and therefore reach more robust results. We prefer not to refer to the infrequent cases as outliers since: (i) unique/infrequent routes constitute (overall) a significant percentage of the total variants and (ii) unique/infrequent routes are both accepted and expected for patients flow in an emergency department. The rationale of the proposed method is explained below.

The intuition of all clustering methods is to create coherent clusters, i.e., similarities among intra-cluster objects should be high, while similarities among objects of different clusters should be small. However, the existence of isolated traces would bias the distances (similarities) both to intra-cluster objects (they would appear less connected) and to inter-cluster objects (they would appear more connected). Therefore, in order to identify if an object is an isolated trace (i.e., an infrequent case – a kind of outlier as discussed above), one could take into account the neighbourhood of the object. The more crowded it is (many objects exist in its neighbourhood), the more likely would be for that particular object to describe a frequent behaviour. Thus, our efforts focus on finding a way to weight similarities by local densities.

In order to define the neighbourhood of each object, we adopt the ε-neighbourhood concept, according to which two objects are considered to be in the same neighbourhood when their distance is smaller than a specified threshold 
                           
                              ε
                           
                         (i.e., when their similarity is greater than a specified threshold). The selection of the threshold value is an essential step of the process. In this work, we tested values from 0.6 to 0.9. Empirically, by examining the density distribution of the resulting similarity matrix, we chose to set 
                           
                              ε
                              =
                              0.7
                           
                        .

More formally, let 
                           
                              
                                 
                                    N
                                 
                                 
                                    i
                                 
                              
                           
                         be the neighbourhood of an object 
                           
                              i
                           
                        . Then we introduce a measure 
                           
                              
                                 
                                    l
                                 
                                 
                                    i
                                 
                              
                           
                         to estimate the local density of an object 
                           
                              i
                           
                         as follows:
                           
                              (5)
                              
                                 
                                    
                                       l
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          ∈
                                          
                                             
                                                N
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       s
                                    
                                    
                                       ij
                                    
                                 
                              
                           
                        The new similarity metric, which will be better at detecting isolated cases through the amplification of the neighbourhood concept, is calculated as 
                           
                              
                                 
                                    s
                                 
                                 
                                    ij
                                 
                                 
                                    ′
                                 
                              
                              =
                              
                                 
                                    s
                                 
                                 
                                    ij
                                 
                              
                              
                                 
                                    l
                                 
                                 
                                    i
                                 
                              
                              
                                 
                                    l
                                 
                                 
                                    j
                                 
                              
                           
                        . The authors in [6] propose to assess the locality of the nodes in a graph through a weight function, i.e., to evaluate the vicinity by filtering out isolated cases (each case should have at least one neighbour). In this work, while we follow the neighbourhood concept, we avoid filtering out any cases by relegating the effect of isolated cases.

Having obtained a similarity matrix, the next step is to cluster the items (trace variants) into groups. Since the similarity matrix is a symmetric matrix whose rows and columns are the items, and cells are the values of the items’ pairwise similarity, virtually any partitioning or agglomerative clustering technique can be used. Our selection is spectral clustering. Spectral clustering was selected because of its good results that have been demonstrated in the literature (see [43]), as well as because it provides a good recommendation about the number of clusters. In the next paragraphs, we concisely review spectral clustering and the algorithm proposed in [31].

Let 
                              
                                 G
                                 =
                                 (
                                 V
                                 ,
                                 S
                                 )
                              
                            be an undirected weighted graph with the set of vertices 
                              
                                 V
                              
                            consisting of the given points 
                              
                                 {
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 |
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 …
                                 ,
                                 n
                                 }
                              
                            and 
                              
                                 S
                                 =
                                 
                                    
                                       [
                                       
                                          
                                             s
                                          
                                          
                                             ij
                                          
                                       
                                       ]
                                    
                                    
                                       n
                                       ×
                                       n
                                    
                                 
                              
                            a symmetric matrix with 
                              
                                 
                                    
                                       s
                                    
                                    
                                       ij
                                    
                                 
                              
                            being the similarity (weight) of the edge connecting vertices 
                              
                                 i
                              
                            and 
                              
                                 j
                              
                           . It is very common for the 
                              
                                 
                                    
                                       s
                                    
                                    
                                       ij
                                    
                                 
                              
                            to be calculated as the Gaussian kernel, however, in this work it is calculated by the procedure described in the previous section. We should note that by using the Gaussian kernel, it is not straightforward how multiple similarity dimensions (i.e., the activities and the transitions) can be calculated and weighted by their significance. The graph Laplacian 
                           
                              
                                 L
                              
                            is defined as 
                              
                                 L
                                 =
                                 I
                                 -
                                 S
                              
                            where 
                              
                                 I
                              
                            is the identity matrix. Often the Laplacian is normalized, but in this work we follow [31] who propose to use the non-normalized matrix. In fact, in our case, the normalized version could yield unsatisfactory results, because after reducing the impact of infrequent cases, the graph is likely to contain many vertices with low degrees, thus leading to unstable cluster indicators [44].

The algorithm proceeds by considering the generalized eigenproblem 
                              
                                 Lu
                                 =
                                 λ
                                 Du
                              
                           , where 
                              
                                 u
                              
                            is the eigenvector and 
                              
                                 D
                              
                            is the degree matrix, defined as the diagonal matrix with the elements 
                              
                                 
                                    
                                       d
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                    
                                 
                                 
                                    
                                       w
                                    
                                    
                                       ij
                                    
                                 
                              
                            on the diagonal. Then, a matrix 
                              
                                 U
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       n
                                       ×
                                       k
                                    
                                 
                              
                           , containing the first 
                              
                                 k
                              
                            eigenvectors 
                              
                                 
                                    
                                       u
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       u
                                    
                                    
                                       k
                                    
                                 
                              
                            as columns, is created, which introduces a (possibly non-convex) mapping of the original data to a k-dimensional subspace, which is defined by features corresponding to the derived eigenvectors. As noted in [28], if a partitional clustering algorithm (e.g., k-means) is applied directly to the original data, it may lead to unsatisfactory results, particularly when the clusters of interest correspond to non-convex regions. On other hand, applying a traditional clustering algorithm to cluster the data set 
                              
                                 U
                              
                            into 
                              
                                 k
                              
                            clusters, is equivalent to forming an arbitrary (possibly non-convex) cluster structure for the original data. In accordance with the algorithm of [31] and other spectral clustering algorithms (see for example [27,28]), in this study we employ the k-means algorithm to cluster the rows of 
                              
                                 U
                              
                            (i.e., to derive the final clustering of the trace variants in the sample) as described in the following paragraph.

Matrix 
                              
                                 U
                              
                            is a real-valued matrix, while a matrix with binary entries (1 if item 
                              
                                 i
                              
                            is assigned to cluster 
                              
                                 j
                              
                           , and 0 otherwise) is needed. Therefore, in order to accept 
                              
                                 U
                              
                            as a solution to our problem, it has to get transformed to a binary format. One simple solution, is to set the maximum value of each row equal to one and let the remaining values to be zeros. However, such an approach yields unsatisfactory results, particularly when there is no dominant maximum value at every row of 
                              
                                 U
                              
                           . An alternative approach, which is adopted in this paper, is to treat the 
                              
                                 n
                              
                            rows of matrix 
                              
                                 U
                              
                            as k-dimensional feature vectors. The next step is to apply the k-means clustering algorithm considering the rows of 
                              
                                 U
                              
                            as the population to be clustered in 
                              
                                 k
                              
                            classes. This way, items (traces variants) that have similar values to the eigenvectors (i.e., similar association degrees with the clusters) will eventually get clustered together.

Considering the number of clusters 
                              
                                 k
                              
                           , a good indication is to look for a sudden drop in the eigenvalues. Of course this number will largely depend on the special needs of each problem.

@&#RESULTS@&#

An important decision during the clustering phase is to fix the number of clusters. As noted above, in spectral clustering the number of clusters can be specified by examining the eigenvalues obtained from the generalized eigenvalue problem. Fig. 4
                         illustrates all eigenvalues obtained for our data set. From such a plot, one can select the top 
                           
                              k
                           
                         eigenvalues that are well separated from the rest. According to the results of Fig. 4 it is evident that choosing 
                           
                              k
                              =
                              3
                           
                         satisfies the above rule. We also considered setting 
                           
                              k
                              =
                              4
                           
                        , but in this case it was found that the fourth cluster consisted of very few traces without a meaningful interpretation.

To get an impression of how spectral clustering assigns objects to clusters, we can consider the similarity matrix as an undirected graph, whose nodes are the clustered objects (trace variants) and edges connecting two nodes are their pairwise similarities (the greater the similarity, the greater the weight of the edge). Following this approach, Fig. 5
                         illustrates the clustering results. In particular, nodes are coloured according to their clustering membership, while edges are coloured according with their source node colour. The fact that there are few and thin lines connecting nodes from different clusters, while the intra-cluster edges are dense and thick, indicates that spectral clustering was able to provide coherent clusters.

In order to analyse the validity of the proposed methodology we compare the obtained results with some other trace clustering approaches. In particular, the proposed method is compared with:
                           
                              (a)
                              the New Agglomerative Clustering, as implemented in ProM 5.2 (http://promtools.org/prom5) using Euclidean distance metric and minimum variance method),

the k-means approach,

and The EM clustering algorithm, again as implemented in ProM 5.2 (with the default settings).

The three reference trace clustering approaches are described in [33]. We made comparisons with different number of clusters, but since the results are quite similar, we present just the results for the case of the three clusters.

After having obtained the clusters with every method, we discovered a Petri Net model for each cluster using the ILP algorithm [40], which is known to deliver well-fitting process models. Since the goal of this work is to deliver comprehensive process models, we evaluate the results with respect to their complexity and coupling, as it is measured by a set of objective metrics and discussed in [39]. More specifically, we use:
                           
                              (i)
                              The Control-Flow-Complexity (CFC) metric [4]. The CFC evaluates the complexity introduced in a process by the presence of XOR-split, OR-split, and AND-split constructs and it is highly correlated with the control-flow complexity of processes [5]. The desired situation is to have small complexity.

The structuredness metric, which recognizes different kinds of structures (basic patterns, such as sequence, choice, and iteration) and scores each structure by giving it some “penalty” value [21].

The density of the model as a coupling metric [24]. Density measures the number of interconnections among the activities of the model and has been found to be tightly connected with process models errors [25]. The smaller the density the better the quality of the process model.

The values presented in Table 2
                         refer to the average value for all clusters. Our approach yields better results with respect to the Control-Flow Complexity and the Density metric, and it is the second best one in the Structuredness metric. The technique that performs best in the Structuredness metric (EM) is however the worst performing one in the other two metrics.

The method described in the previous section allows the formulation of three, intuitively explained, process models that summarize all 84 variants. Although the set of all possible activities is relative small (21 activities), and the bags of activities are similar for every cluster (e.g., clusters 1 and 3 contain 20 out of the 21 activities; cluster 3 contains 16), there are significant differences among them.

In cluster 1 (Fig. 6
                        a), ‘Assortment.1’ (assortment during day shifts) never happens, while in cluster 3 (Fig. 6c) ‘Assortment.2’ (assortment during night shifts) is not performed. Cases that belong to cluster 2 (Fig. 6b) do not perform ‘Registration’, ‘Assortment.1’, and the triplet ‘Decision.E.R.Treatment’, ‘Room.Entrance’, ‘Exit.Room’ (refer to the ED2 room).

Considering the whole sample, the distribution with respect to the triage is green ∼34%, yellow ∼57%, and red ∼8%. This distribution is repeated only for cluster 1, which concerns approximately 50% of the patients. Cluster 2 (approximately 10% of patients) contains much more red triage cases than the normal percentage, while in cluster 3 (approx. 40% of cases) the yellow triage cases are over-represented.

In cluster 1, ‘Registration’ is often skipped while the unexpected phenomenon of green triage cases visiting the hospital during the night shift appears. This can be attributed to the economic crisis. Before the crisis, the emergency department in public hospitals in Greece was free). After the crisis and during the data collection period, there is a registration cost of 5 euros. However, in the hospital under consideration, there is no registration during the night because there is no secretary available. So, in cases of minor incidents, people prefer to visit the hospital at night in order to avoid paying the registration fee.

Considering cluster 2, skipping ‘Registration’ can be attributed to the higher emergency of cases. Moreover, this cluster has a higher frequency of lab tests (all patients have blood, biochemical or enzyme tests). Finally, this cluster has a high percentage of patients that enter a clinic rather than just leaving the hospital.

Cluster 3 is closest to the expected flow. People get registered, assorted, have some tests, and are forwarded towards the exit via the expected way (after a prescription or a treatment in the ED room).

In complex environments, process execution may significantly differ from an ideal process model. Process mining discovery techniques can facilitate the description and understanding of real-world process behaviours. However, there exist certain environments where processes are inherently complex. In these cases, direct process discovery usually deliver complex models, which are of limited practical usefulness.

The proposed methodology can address this problem effectively, by delivering a small number of simpler process maps. Our method contributes to trace clustering approaches by recommending a way to ameliorate the effect of unique (i.e., exceptional) cases. Moreover, by integrating a spectral approach to cluster the traces, we were able to obtain compelling results. The process models obtained through the proposed approach provide significant information of practical usefulness as they facilitate the understanding of an actual complex process and provide operational support on how it can be improved.

To illustrate the usefulness of the methodology, a case study from the healthcare sector was employed, involving the analysis of the diverse processes in the emergency department of a hospital. By applying the proposed methodology, we were able to expose three groups of patients that are homogeneous with respect to their pathways, and therefore we can comprehend the process flows more intuitively. Additionally, by correlating the patients’ clusters with their triage and since there exist estimations of the statistical distribution for the triage, it is possible to predict more accurately the workload per activity, or even to create a better resource allocation plan. Moreover, through the effective visualizations, there are credible chances to communicate the parameters of operations management to doctors, who usually claim that medical guidelines cannot allow for operational optimization.

Two critical points in the proposed method are the similarity metric and the choice of the neighbourhood threshold. For this work, the selected similarity metric focused just on control-flow attributes (bag-of-activities and transitions) while for the neighbourhood threshold, the selection was made through several experiments. Future work could concentrate on a further analysis of these two issues. In particular, regarding the similarity metric, additional criteria (case attributes) could be considered through a multi-attribute approach.

Regarding the selection of the neighbourhood threshold, exploiting concepts of preference modelling could contribute to more effective solutions [26]. In addition, adding domain knowledge to the clustering procedure could also be particularly useful. More specifically, domain experts could provide valuable information on the relationships between items (e.g., traces that must be clustered together or be separated). Incorporating such domain knowledge into the proposed computational process could potentially lead to improved results and provide insights derived from the discrepancies between the experts’ knowledge and the algorithmic outcomes.

@&#ACKNOWLEDGEMENTS@&#

This research has been co-financed by the European Union (European Social Fund – ESF) and Greek national funds through the Operational Program “Education and Lifelong Learning” of the National Strategic Reference Framework (NSRF) – Research Funding Program: THALES. Investing in knowledge society through the European Social Fund.

@&#REFERENCES@&#


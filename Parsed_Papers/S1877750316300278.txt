@&#MAIN-TITLE@&#Workflow optimization of performance and quality of service for bioinformatics application in high performance computing

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Implementation of hybrid BWA-MEM improve the performance upto 200%.


                        
                        
                           
                           This hybrid model is named as data-parallel with concurrent Parallelization.


                        
                        
                           
                           Thread parallelization extended into data-parallelization with concurrent execution of BWA-MEM applications.


                        
                        
                           
                           The proposed novel approach measured the performance in terms of application execution time, scalability, parallel efficiency and system utilization (QoS).


                        
                        
                           
                           The experiments are conducted across different architectures and demonstrated the performance is super linear compared to traditional approach.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

High performance computing

BWA-MEM algorithm

Quality of service

Next generation sequencing

Scalability

Application performance and parallel efficiency

@&#ABSTRACT@&#


               
               
                  Nowadays, High Performance Computing (HPC) systems commonly used in bioinformatics, such as genome sequencing, incorporate multi-processor architectures. Typically, most bioinformatics applications are multi-threaded and dominated by memory-intensive operations, which are not designed to take full advantage of these HPC capabilities. Therefore, the application end-user is responsible for optimizing the application performance and improving scalability with various performance engineering concepts. Additionally, most of the HPC systems are operated in a multi-user (or multi-job) environment; thus, Quality of Service (QoS) methods are essential for balancing between application performance, scalability and system utilization. We propose a QoS workflow that optimizes the balancing ratio between parallel efficiency and system utilization. Accordingly, our proposed optimization workflow will advise the end user of a selection criteria to apply toward resources and options for a given application and HPC system architecture. For example, the BWA-MEM algorithm is a popular and modern algorithm for aligning human genome sequences. We conducted various case studies on BWA-MEM using our optimization workflow, and as a result compared to a state-of-the-art baseline, the application performance is improved up to 67%, scalability extended up to 200%, parallel efficiency improved up to 39% and overall system utilization increased up to 38%.
               
            

Due to various advancements in next-generation sequencing technologies (e.g. Illumina, SOLiD), larger volumes of genome data are being produced every year at a lower cost [1]. New functional variants are being discovered due to this ever-growing availability of genome data [2]. However, the analysis applications required for these discoveries typically are performance limited due to their compute and memory-intensive operations [3]. This paper addresses these challenges by optimizing genome alignment applications that are commonly hindered when using traditional High Performance Computing (HPC) systems. To overcome the traditional system limitations, HPC systems are becoming popular in bioinformatics for providing faster genome alignment by utilizing high-throughput and parallel-processing techniques [4,5], referred as “HPC for Bioinformatics” [6]. Thus, large-scale genome analysis can be parallelized to achieve empirically faster results by using HPC architectures, but those gains still have much room for improvement.

Nowadays, multi-core HPC systems used in genome sequencing still have no optimal choice of workflows based on application characteristics, in terms of accuracy, performance and optimal selection of computing resources. Generally, the application performance is dependent on various factors like complexity of the algorithm, application design, data distribution methods, communication cost, workflow dependency conditions, software stack (e.g. compilers, Message passing Interface (MPI)/Thread libraries) and hardware limitations [7]. To achieve the optimal performance of any application, it is necessary to understand the application characteristics and the performance bottlenecks.

Most bioinformatics applications are written in multi-threaded programming models that do not scale well in the modern multi-core HPC systems [3,8]. For example, when a modern GATK Haplotype caller application [9] is executed on a 32-cores HPC system with core steps of 2, 4, 8, 16 and 32, the performance improvement was expected as execution time keep reducing with the increased number of cores. However, when beyond 8 cores, the performance was not improving in relation. Therefore, the optimal computing resources should be selected based on the scalability limitations to achieve the better performance. Alternatively, the utilization of the HPC system is very poor (about 25% of resource utilization) for the above GATK Haplotype caller workload. In this case, it is necessary to improve the system utilization by concurrently submitting more similar workloads within the HPC system. We conducted various case studies of different ways of parallelization and their performance impacts are summarized in [8]. As of now, tools are unavailable to balance between application performance, scalability and system utilization and hence we introduced the Quality of Service (QoS) factor, which uses an effective ratio between parallel efficiency and system utilization. We designed this QoS as an optimization workflow to provide the best performance and linear scalability with optimal set of resources.

@&#LITERATURE REVIEW@&#

In the last few years, hash table based algorithms [10] (e.g. BLAST, SOAP, SeqMap, etc.) and prefix/suffix trees based algorithms (e.g. FM-Index, BWA-MEM, BWT-SW) are commonly used in genome mapping in bioinformatics research [1]. Burrows-Wheeler Aligner (BWA) is the most popular genome mapping software widely used in human genomic sequencing [11–13]. The BWA-backtrack, BWA-SW and BWA-MEM are three different algorithm versions of BWA. The BWA-SW and BWA-MEM algorithms are supported for long-reads (70bp–1Mbp) human genome sequences. Unlike the other algorithms, the BWA-MEM provides fast and accurate alignment for sequence reads and support for long-query and split-alignment in the human genome sequencing [14].

BWA-MEM, BWA-BT, Bowtie2, SMALT and MOSAIC are some of the widely used aligner tools. The aligned reads in BWA-MEM and SMALT are greater than 99%, where the execution time of SMALT is 3 times slower than BWA-MEM. The BWA-MEM and Bowtie2 execution times are relatively comparable to each other but, the Bowtie2 aligned reads are relatively good (98.27%) compared to BWA-MEM (99.10%) [15].

A new MICA aligner is optimized to take advantage of Intel's Many Integrated Core Architecture (MIC), which is 4.9 times faster in execution time compared to the BWA-MEM algorithm [16]. The Regional Hashing-based Alignment Tool (rHAT) produces accurate aligned reads, correctly aligned bases and excellent execution time [17]. In this paper, we compared the rHAT algorithm, even though it uses Hash-Indexing, in order to understand the computational limitations of the BWA-MEM. Overall, the new implementations of aligners, MICA and rHAT, are compared to BWA-MEM [16,17]. The aligned reads and aligned bases are comparatively similar to each other, but the BWA-MEM algorithm failed to produce better execution time due to CPU limitations. Hence, we are optimizing the BWA-MEM algorithm using “data-parallel and concurrent parallelization” [3].

The implementations [15–17] discussed prior are focused in reducing execution time and not the optimal selection of the computational resources. The utilization of the resources is equally important in a multi-user environment, and the performance is not always ideal when all the computing resources are utilized [8]. To address these challenges, we proposed an optimal workflow for bioinformatics applications that will give a better suggestion to balance between application performance, scalability and system utilization, referred to as “best QoS”.

We present a systematic sequence of approaches called “workflow optimization” for the bioinformatics applications on the HPC system. The workflow is developed based on experience and various performance engineering concepts. When the application source code is available, compiler optimization techniques are used to improve the application performance [18]. We used 4 sets of compiler optimization flags: default optimization (-O3/-O2 flag), vectorization, Single Instruction Multiple Data (SIMD) based tunings and architecture aware optimizations (e.g. AVX, AVX2, -qarch=pwr8). For every change in the compiler flags, a different versions of application binary is created and run with a subset of genome data to measure the application execution time, HPC system efficiency and resource utilization. The best set of results is referred as “un-optimized” and it is a “baseline” reference for our workflow optimization.

The application profile based analysis is used to optimize the licensed applications because of its pre-compiled binaries. By using the flat profile (e.g. using GNU profiler and Intel Vtune), the performance bottleneck of both types (source code and licensed based) of applications are analyzed [19]. Based on the flat profile results, the relationship between application instructions and low-level characterizations (e.g. cache miss, translation lookaside buffer (TLB) miss, etc.) are studied. Accordingly, the application is tuned (e.g. parallelize the instruction set, change the order of execution of the instruction to take benefit of the cached registered entries, etc.) and optimized to make use of low-level hardware features. Additionally, the genome data is equally partitioned into independent chunks and equal to the number of cores in the HPC system. The optimized binary, which is used as the “baseline” reference, is concurrently executed with independent chunks of genome data and then measurements are taken of the application execution time (last concurrent job completion time), HPC system efficiency and resource utilization. This set of performance number are referred as “concurrent parallelization” [3].

Due to the larger volume of genome data, the cache miss/translation lookaside buffer (TLB) misses are possible in genome alignment. Hence, the genome data is partitioned into independent multiple chunks (not necessarily equal to the number of cores) based on the level of cache misses. The optimized binary is executed in a multi-threading mode with every independent chunk of data. During binary execution, the number selection of multi-threads is determined for providing the best scalability factor. Accordingly, the system utilization is calculated. The overall execution time is sum of all the execution time of independent chunks of data processing time and this method is referred as “data-parallelization”.

Most of the multi-threaded applications are affected by shared memory contentions. As a result, scalability limitations and poor system utilization are observed. To address these challenges, “data-parallel with concurrent parallelization” is introduced [3]. In this method, optimal number of cores is selected based on the scalability limitation using the data-parallelization concept. The genome data is independently partitioned into an optimal number of cores. The optimal binary is executed with independent partition of data concurrently across all and multi-threading is used, which is equal to the number of optimal number of cores. Additionally, hyper threading (HT) or simultaneous multi-threading (SMT) enabled options are studied to bring the best performance improvement when the application is not affected with shared memory contention.


                     Fig. 1
                      provides a workflow performance optimization overview of bioinformatics applications represented by step-by-step flowchart model. Additionally, we summarized our method of optimization in the automated scripting (Algorithm 1), which is described as follows:


                     Notations and assumptions:
                     
                        
                           1.
                           The HPC system C
                              ={C
                              1, C
                              2
                              …
                              C
                              
                                 n
                              } has ‘n’ cores.

The genome data D
                              ={D
                              1, D
                              2
                              …
                              D
                              
                                 m
                              } can be partitioned into ‘m’ independent chunks.

The execution time E
                              ={E
                              1, E
                              2
                              …
                              E
                              
                                 n
                              } with E
                              1
                              >
                              E
                              2
                              >…>
                              E
                              
                                 n
                               is the set of application performance when the genome data D is processed in C multi-cores respectively.

The Scalability S
                              ={S
                              1, S
                              2
                              …
                              S
                              
                                 n
                              } with S
                              1
                              ≤
                              S
                              2
                              ≤…≤
                              S
                              
                                 n
                               is the scalable performance when the application run with ∀ i
                              =1, 2, …
                              n, C
                              
                                 i
                               number of multi-cores respectively.

The efficiency η
                              ={η/1, η/2…1} are the set of parallel efficiency when ∀i
                              =
                              n, n
                              −1, …1 and C
                              
                                 i
                               number of cores used respectively.

The best execution time, optimal scalability and better efficiency are referred as E
                              
                                 best
                              , S
                              
                                 opt
                               and η
                              
                                 eff
                               respectively.


                     
                        Algorithm 1
                        Method of proposed workflow optimization in the automated scripting. 
                              
                           
                        

@&#METHODOLOGY@&#


                     
                        
                           A.
                           
                              Benchmarking environment: due to advancement in cutting-edge technologies, a larger volume of genome sequences is being produced in high demand at lower cost using Next Generation Sequencing (NGS). The Burrows-Wheeler Transform (BWT) is a well-known permutation algorithm used in NGS [10,11,13]. Due to various enhancement in the in the NGS technology, the genome data size has keep increasing year by year and hence the higher demand of processing these data in a much faster way becomes necessary. The HPC systems addresses the data processing in an empirical parallel way and minimizes the overall execution time; hence, bioinformaticians prefer to process genome data on the HPC systems [12]. For our benchmarking exercise, we used the following two different high-end HPC systems:
                                 
                                    •
                                    
                                       Intel Sandy Bridge: Four E5-4650 CPUs @ 2.7GHz with hyper-threading enabled, 8 physical cores/CPU, totaling 64 cores.


                                       AMD Opteron: Four 6386 SE CPUs @ 2.8GHz, 16 cores/CPU, totaling 64 cores.

Both the above HPC systems use Non-uniform memory access (NUMA) architectures and uses 512GB DDR3 main memory. These high-end systems are running with Red Hat Enterprise Linux operating system, GNU compiler 4.4.7 version and BWA-MEM 0.7.10 version and hence the performance is comparable across the different HPC systems with the similar workload.


                              Application selection: most of bioinformatics applications are multi-threaded and available in open source implementations. The BWA-MEM algorithm is the most popular algorithm for aligning human genome sequences and it performs local alignment using BWT. This algorithm produces multiple primary alignments from different parts of query sequences that are widely used in the NGS technology [12]. The BWA-MEM alignment algorithm is written in C/Multi-threads (pThreads) implementation and it's processes the genome data using thread-parallelization, by default. Since the genome data has multi-million independent reads, the end-user can parallelize the data into independent chunks and process the genome alignment either simultaneously or one-chunk followed by-another. In the former case, all chunks will be processed by the HPC system at the same instant by overlapping is referred as “concurrent parallelization”. Alternatively, in the later case, every chunk of data is processed one-by-one dedicatedly by the HPC system, which is referred as “data parallelization”. Here, the most popular Message Passing Interface (MPI) based distributed processing or fault tolerance [7] (or multiprocessing across the nodes) is not possible because the BWA-MEM algorithm was not written with C/MPI. Based on our literature review [3,8,15–17], the BWA-MEM algorithm has failed to produce better execution time due to CPU limitations. Hence, we preferred to improve the performance by using our workflow optimization method.


                              Genome data selection: the Genome Comparison & Analytics Testing (GCAT) has standard set of genome data (100–400bp) [20]. We used 100–150bp paired-end data sets with large INDELs for our case studies because of our Illumina sequencer will produce a similar 100–150bp human genome data.


                              Results validation: the output of the BWA-MEM algorithm is a SAM/BAM (Sequence Alignment/Map) file that contains TAB-delimited text consisting of a header section (optional) and an alignment section. The SAM file is a sister version of BAM that is in binary format. We used BamUtil tools [21] to validate the correctness of the generated SAM/BAM files. Even though the genome data are split into multiple independent chunks, the percentage of Mapping Rate, Paired Reads, Proper Pair, Duplicate Rate and QC Fail Rate should be same as “baseline” results. Additionally, the summation of number of read records and number of valid records between multiple chunks of genome data should be equal to the “baseline” results.


                              Workflow optimization for BWA-MEM: in thread parallelization, the BWA-MEM algorithm is used to run with 1, 2, 4,…N/4, N/2, N threads with the provided genome data file(s). These multi-threads (N) processes (e.g. mapping of genome sequence to the reference file) use the data file that contains multi-million reads for using functional parallelization. The data boundaries (e.g. reads line 1 to N/8 for thread=1, reads line N/8+1 to N/4 for threads=2, etc.) are controlled by the way of implementation of sequence mapping algorithm. Generally, these algorithms are limited to performance bottlenecks due to cache/TLB misses and shared memory contention due to advancement in the multi-core era [10]. To eliminate those memory bottlenecks, the multi-million reads are equally partitioned into multiple chunks to reduce the read size.

Then the BWA-MEM algorithm is executed with multiple-threads within every chunk. All the chunk results are gathered into the final data parallelization resultant. This data parallelization uses the workflow model because of N threads are used to process every chunk of data and M times required to run BWA-MEM algorithm to process M number of chunks of data.

Alternatively, the concurrent parallelization is the best technique used to improve the throughput of multiple data files (e.g. multiple sequence data files) within pre-defined number of resources (e.g. N threads) with optimal execution time (e.g. less than M× of thread parallelization). This is explained as follows: the throughput in sequence alignment is referred as “multiple data files should be processed optimally with minimal execution time and limited number of resources” [8]. For example, 2 data files should be processed less than 2× times of thread parallelization execution time with subject to N threads, i.e., first data file will be processed using N/2 threads and the second data file will be processed using another N/2 threads running concurrently. The maximum execution time of first and second data file should be less than 2× time of thread parallelization execution time. Hence, the concurrent parallelization will be better for larger number of data files because of the optimal throughput performance.


                              Performance measurement parameters: the following definitions [4] are common in parallel processing and we used these performance metrics for comparing our workflow optimization benchmarking results:
                                 
                                    •
                                    
                                       Application performance: measured as a BWA-MEM algorithm execution time E (in seconds).


                                       Scalability: the scalability is measured as a relative performance S(p)=
                                       T
                                       
                                          s
                                       /T
                                       
                                          p
                                       , where T
                                       
                                          s
                                        is sequential execution time and T
                                       
                                          p
                                        is parallel execution time of BWA-MEM algorithm. In an ideal case, S(p)=
                                       p, where p is the number of parallel threads used by BWA-MEM algorithm.


                                       Quality of Service (QoS): the best result of parallel efficiency is achieved by (i) tuning the application performance by using compiler optimization, architecture aware optimizations and application profile based tuning, (ii) the scalability of the application is improved by using data parallelization, concurrent parallelization and combination of both. The system utilization is calculated based on maximum utilized resources in the HPC architecture (e.g. number of CPUs). As a result, the proposed workflow optimization techniques help to reduce the computational and memory bottlenecks, minimize HPC resource idle time and various synchronization overhead, improve processor cache utilization for aligning concurrent data-intensive workloads and increases Quality of Service (QoS), which is calculated as:
                                          
                                             (a)
                                             Efficiency: η(p)=
                                                S(p)/p is parallel efficiency that measures relative performance of scalability versus number of parallel threads used by BWA-MEM algorithm. In an ideal case η(p)=1 referred as QoSidle.

Resource utilization: δ(p)=(η(p)−
                                                QoS
                                                
                                                   idle
                                                )×100, where δ(p)=0 is for 100% resource utilization, δ(p)<0 for underutilization and δ(p)>0 for overutilization of HPC system resources. Due to various performance tunings (e.g. hybrid programming model) [3,8,10], their may be a possibility of improving the application performance super linearly and hence the resource utilization is demonstrated as a over utilization when the δ(p)>0.

@&#RESULTS AND DISCUSSION@&#

We followed our systematic multi-step approach to optimize the BWA-MEM application. The compiler optimization doesn’t strongly influence the application performance improvement because it is dominated by indexing and sorting of the query genome sequences. The flat profile results also demonstrated the similar performance bottleneck with the increased number of cores. For example: subroutine ksw_u8() is taking >18–25% of total execution time with the increased number of cores in the parallel operation [3]. Additionally, we ran this BWA-MEM application on our high-end HPC systems (32 and 64 cores per node) and the performance keeps improving until cores=16. With the larger core counts (32/64 cores), the performance is almost similar and these set of results are referred as “baseline” results or “un-optimized” performance numbers. The complete application performance results (cores=1, 2, 4, …64) are summarized in Fig. 2
                     .

We used “Amdahl's law of scalability” [22] to measure our “un-optimized” and “optimized” scalability results. In Intel system, “un-optimized” scalability results are super linear until cores=8 and reduced scalability for cores=32 and 64. On the AMD system, the “un-optimized” scalability results are reducing starting from cores=4 and very poor for cores=64. The summary of application scalability is illustrated in the Fig. 3
                     
                  

To improve the performance and scalability, the BWA-MEM algorithm is run with data parallelization and concurrent parallelization. The concurrent execution of multiple genome data (or independent chunks of single genome data) within a node provides the best throughput results and we suggested to run the BWA-MEM application using “concurrent parallelization” [8]. Alternatively, based on the best scalable number of cores, the genome data is partitioned into multiple chunks and run with data-parallel with concurrent parallelization using high-end HPC systems. As a result, the performance of BWA-MEM in Intel and AMD HPC systems are improved until cores=64. The Intel scalability numbers are super-linear from cores=2 to cores=32 and AMD scalability is linear up to cores=32. This set of improved results is referred as “optimized”, which uses “data-parallel with concurrent parallelization” concept. The complete summary of optimized performance and extended scalability results are shown in Figs. 2 and 3.

In the above case studies, the efficiency of the HPC systems and resource utilizations are calculated based on the number of cores used. The Table 1
                      summarizes the parallel efficiency and system utilization based on our above stated performance measurement calculations, which is referred as Quality of Service (QoS).

As an overall outcome of workflow optimization, the BWA-MEM application performance is improved up to 39%, the scalability is extended up to 66%, parallel efficiency is improved up to 28% and overall system utilization is increased up to 38% on the Intel Sandy Bridge system. Similarly, the same set of benchmarks was performed on the AMD Opteron system, where the performance is impressive except for overall system utilization. As a summary of QoS, up to 67% application performance improvement is seen, up to 200% for extending scalability, up to 39% for improvement on parallel efficiency and up to 3% for overall system utilization that are illustrated in Fig. 4
                     .


                     Results validation: the output of the BWA-MEM algorithm will produce the aligned genome data in SAM/BAM format. The BamUtil tool was executed to verify the correctness of the generated SAM/BAM files. The output of the BamUtil results (for cores=1, 2, … 64) are the same across all the “baseline” results. The output of BamUtil is summarized in Fig. 5
                      as a reference.

When the genome data is partitioned into multiple independent chunks, the number of records read may not be similar across different chunks. Alternatively, we observed the percentage of Mapping Rate, Paired Reads, Proper Pair, Duplicate Rate and QC Fail Rate are same across multiple independent chunks and importantly same as “un-optimized” results. To ensure the originality of records read, all the partial chunks records read are added together and the summary is available in Table 2
                     .

From the above results, the summation of chunk-1 to chunk-4 results is matched with “baseline” results. In some of the cases, we observed, that the total bases (Fig. 5) and Bases in Mapped Reads values (Table 2) varies with 0.01–0.03% compared to our “baseline” results. Hence, our proposed workflow optimization provides 99.97% reliable and accurate results.

@&#FUTURE WORK@&#

As of now, we are following the manual process of systematic workflow for optimizing the applications. This manual process requires time overhead to get the best results of QoS, which can be eventually automated by using continuous performance optimization techniques [23]. Additionally, we are in the process of including findings of all best combination in the parallel efficiency and system utilization (i.e., Best QoS) into our automated scripts. Therefore, whenever the application is rerun on the HPC system, the automated script will allocate the required resources based on our older observations (performance and resource); thus, the user application is automatically run with best parallelization and run time parameter options. Also, we are in the process of validating this optimization method using other standard bioinformatics alignment applications like Bowtie2, BLAST and SOAP and variant caller applications like GATK and RNASeq.

@&#CONCLUSION@&#

The proposed optimization workflow helps to improve the bioinformatics application performance and we have demonstrated this improvement in performance, scalability, system utilization and parallel efficiency using the most popular BWA-MEM alignment algorithm. We used a standard genome data downloaded from Bio-planet for our experiments on high-end HPC systems with two different architectures (Intel and AMD) up to 64 cores/node. As a result, the, performance was improved respectively on Intel and AMD systems by 39% and 67%, scalability extended to 66% and 200%, parallel efficiency improved by 28% and 39% in the high-end HPC systems. We were able to improve the system utilization up to 38% on Intel architecture. The optimized results are validated using the standard BamUtil and we observed 99.97% accurate results compared to baseline results. As a summary, the best QoS can be obtained using our proposed systematic workflow optimization for the bioinformatics applications.

@&#ACKNOWLEDGEMENTS@&#

The authors would like to thank Ramzi Temanni, Hakeem Almabrazi, Najeeb Syed and other Sidra Bioinformatics researchers for providing helpful comments and suggestion for running the BWA-MEM application.

@&#REFERENCES@&#

New technology research/design/development.

Parallel and distributed computing.

Algorithm and HPC system optimization.

Heterogeneous environment integration.


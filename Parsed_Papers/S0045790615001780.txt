@&#MAIN-TITLE@&#Performance analysis of classifier for brain tumor detection and diagnosis

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Diagnosis and proper treatment of brain tumors are essential to prevent permanent damage to the brain or even patient death.


                        
                        
                           
                           The brain magnetic resonance (MR) images are used to detect the severities of tumor detections.


                        
                        
                           
                           The performance analysis is measured on various criteria.


                        
                        
                           
                           This work is the differentiation of brain abnormalities from the healthy brain tissue.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Brain tumor

ANFIS

Classifier

Detection

Segmentation

Classification

@&#ABSTRACT@&#


               
               
                  Indefinite and uncontrollable growth of cells leads to tumors in the brain. The early diagnosis and proper treatment of brain tumors are essential to prevent permanent damage to the brain or even patient death. Accurate data regarding the position of the tumor and its size are essential for effective treatment. Hence, an entirely computerized automatic system to provide accurate tumor data is compulsory for physicians. Such developments are necessary to diagnose brain tumors during brain surgery. Brain magnetic resonance (MR) images are proposed for the detection and segmentation of the tumor region via a completely automatic and highly accurate method. The approach discussed in this paper employs an adaptive neuro fuzzy inference system (ANFIS) based on the automatic seed point selection range. The pixels intensity of the proposed algorithm is not dependent on the tumor type. The tumor’s segmentation results are evaluated based on various criteria, including similarity index (SI), overlap fraction (OF), extra fraction (EF) and positive predictive value (PPV), which corresponded to values of 0.817%, 0.817%, 0.182%, and 0.817%, respectively, in this study. These results indicate that the approach proposed in this study performs better compared to many conventional processes. The significance of this work is the differentiation of brain abnormalities from the healthy brain tissue.
               
            

@&#INTRODUCTION@&#

Brain tumors affect people of all ages. A tumor is a mass of tissue made up of accumulated abnormal cells. Most benign brain tumors are noncancerous and are not destructive, and they generally do not spread to nearby tissues, although in some cases benign tumors can be serious. Malignant brain tumors are cancers that originate in the brain and distinctively grow faster than benign tumors, forcefully expending into surrounding tissue. Magnetic resonance imaging (MRI) is widely used to better understand such tumors and to quantify their evolution. Manual segmentation of tumors in MR images by experts is time-consuming, subjective and susceptible to inter-expert variability. Therefore, automatic segmentation is needed as an alternative to manual segmentation. However, the tumor progression often varies regarding the tumor shape, location and volume among patients and even within the same patient. Therefore, automatic segmentation is highly complex, due in part to tumor variability of several factors, such as texture, intensity, shape and size.

Brain tissue and tumor segmentation in MR images have become a topic of great interest. The most widely used types of MRI scans are T1-weighted and T2-weighted scans. In T1 scans, fat and water molecules are differentiated to indicate damaged tissue areas. Darker areas (called hypointense lesions) indicate areas of tissue loss. The visibility of damage can be further enhanced by injecting the non-radioactive element gadolinium, which enhances inflammatory lesions. In T2 scans, areas with more water content become visible as hyperintense spots, which indicate regions of tissue loss. For accurate image segmentation, features must be accurately extracted. The brain is comprised of different tissues such as the white matter (WM), cerebrospinal fluid (CSF) and gray matter (GM). During the segmentation of the MR brain images, variability in certain aspects, such as tumor shape, location, size, intensity and textural properties, makes the segmentation process difficult. In tumor segmentation, the intensity feature plays a vital role in differentiating tumor from other soft brain tissues. However, intensity alone is not sufficient, and therefore other texture-based features, such as local binary patterns (LBPs), gray level-based features, the gray level co-occurrence matrix (GLCM), and wavelet characteristics, can be extracted.

Automatic tumor segmentation aids physician’s in disease diagnoses by not requiring manual labeling. Glioblastoma multiforme (GBM) brain tumors are the most commonly occurring tumor found in brains across patients of all ages. The automatic segmentation of tumors becomes critical due to the variations in the texture, intensity, shape and size of such tumors.

Non-tumor brain structures, such as blood vessels, and soft tissues, are often misidentified as tumors, leading to many false positives (FPs). Most existing techniques for tumor segmentation are not fully automatic. Hence, the existing manual tumor segmentation methods are not fully accurate in detecting tumors.

In this study, an automated technique is proposed that employs textural features to describe the blocks of each MRI slice, along with other features. The process flow of the proposed technique is shown in Fig. 1
                     , which utilizes a trained classifier to differentiate the blocks and to detect the blocks that contain tumor tissue. The classification of the blocks provides an initial coarse segmentation of the MRI image. The textural-based classifier is built using an adaptive neuro fuzzy inference system, one of the most widely accepted algorithms that have been utilized successfully in many imaging and medical applications.

There are several classifying techniques that are used for tumor detection and segmentation, although most existing systems are not fully automated. Such algorithms rely on a specific classifier algorithm that requires manual segmentation.

A computer aided classification technique is proposed, which combines conventional MRI and perfusion MRI for differential diagnosis. Their method consists of ROI definition, feature selection, classification and feature extraction. The feature extraction includes tumor shape and intensity features and rotation-invariant texture features. The features subset selection is carried out using support vector machines (SVMs). The binary SVM classification was applied on 102 brain tumors, and the obtained accuracy, sensitivity, and specificity were 87%, 89%, and 79%, respectively, for differentiation of metastases from gliomas and 87%, 83%, and 96%, respectively, for the discrimination of high grade from low grade neoplasm’s [1]. A Bayesian formulation was used to incorporate soft model assignments into the calculation of conventionally model free affinities. The resulting model-aware affinities were united into a multilevel segmentation by the loaded aggregation algorithm, and the technique for detecting and segmenting the brain tumors was applied to multichannel magnetic resonance (MR) volumes. The simulation results showed improved performance over conventional systems [2]. An efficient brain tumor detection was proposed in [3], which consisted of three steps: enhancement, segmentation and classification. The enhancement process was applied to enhance the image quality before the segmentation phase. The authors used mathematical morphology to increase the contrast in the MRI images. Then, a wavelet transform was applied to the segmentation process to crumble the MRI image. Finally, a k-means algorithm was executed to extract the tumor region. The experimental results were analyzed. Pixel level variation was used to detect abnormalities in the brain region. The brain abnormalities were diagnosed using the pixel distribution surrounding the abnormal tissues in the brain image [4].

Hamamci et al. [5] presented cellular automata (CA)-based seeded tumor segmentation method for contrast-enhanced T1 weighted magnetic resonance (MR) images. The CA-based segmentation method was established according to graph-theoretic methods to show that the iterative CA framework solves the shortest path problem. A sensitivity parameter is introduce to adopted the heterogeneous tumor segmentation problem was also implemented. Then, a tumor probability map was constructed from the CA states for spatial efficiency. Suitable data are collected from the user to initialize the algorithm. The experimental results of the brain tumor dataset show an overlapping performance of 80-90% with respect to several tumor types. Bauer et al. [6] adapted a healthy brain atlas to MR images of tumor patients. To establish correspondence between a healthy atlas and a pathologic patient image, tumor growth modeling was combined with registration algorithms. The tumor is grown in the atlas based on a new multi-scale, multi-physics model that including growth simulation from the cellular level to the biomechanical level, accounting for cell proliferation and tissue deformations. Large-scale deformations are handled using an Eulerian approach for finite element computations, which can operate directly on the image voxel mesh.

The new proposed approach, which we termed the fluid vector flow (FVF) active contour model, is used to address the insufficient capture range and poor convergence for concavities. The FVF model is able to capture a large range and extract concave shapes and demonstrates improvements over techniques such as gradient vector flow, boundary vector flow, and magneto static active contour for three sets of experiments: synthetic images, pediatric head MRI images, and brain tumor MR images obtained from the Internet brain segmentation repository [7]. Clatz et al. [8] used a finite element method (FEM) to simulate the invasion of the GBM in the brain parenchyma and its mechanical interaction with the invaded structures. Depending on the considered tissue, the former effect was modeled with a reaction-diffusion or a Gompertz equation, whereas the latter was based on a linear elastic brain constitutive equation. In addition, a new coupling equation has been proposed, which considers the mechanical influence of tumor cells on the invaded tissues. The tumor growth simulation was assessed by comparing the in-silico GBM growth with the real growth observed in two magnetic resonance images. Clark et al. [9]presented an efficient method for volume rendering of glioma tumors from segmented 2D MRI datasets with user interactive control by replacing the manual segmentation that is required in the state-of-the-art methods. The most common primary brain tumors are gliomas, which evolve from cerebral supportive cells. Lee et al. [10] introduced non-identical unsupervised clustering techniques for thesegmentation of CT brain images. Prior to segmentation, we enhanced the visualization of the original image. Generally, for the presence of abnormal regions in brain images, wepartitioned the image into 3 segments: the abnormal region, the cerebrospinal fluid (CSF), and the brain matter. However, for the absence of abnormal regions in the brainimages, the final segmented regions consist of only CSF and brain matter. Udupa and Samarasekera [11] introduced fuzzy connectedness and its applications for the segmentation of abnormal brain tissue from normal brain tissue. They developed local fuzzy relation (LFR) or affinity methodology to segment brain tissues. Lakshmi and Arivoli [14] used morphological operations to detect and segment brain abnormalities. The authors achieved a similarity index (SI) of 0.78 and an overlapping factor of 0.723.

In this paper is structured as follows. In Section 2 illustrates the proposed system which include Anisotropic filtering and various feature extraction techniques like GLCM, wavelet and law’s energy texture features. A novel approach ANFIS classifier and seed point selection are explained in this section. Performance analysis deal with Section 3 and the evaluation based on the similarity index, overlap fraction, extra fraction and positive predictive values. In Section 4 described the conclusion and future enhancement of the work.

Brain MR Images are subject to corruption by noise during the image transmission and image digitization during the process of imaging. Pre-processing is performed to remove noises from the MRI brain images. The extra-cranial tissues such as bone, skin, air, muscles, and fat, are also removed from the image, the heterogeneous image is converted to a homogeneous image. Filters remove noise from images but also corrupt minute details of the image. In addition, conventional filters smooth the image continuously, and therefore harden the edges of the image. We adopt an anisotropic diffusion filter for the pre-processing of the brain MR image, as this filter removes the noise and preserves the edges. For an image contaminated with noise, the features become blurred at the edges. In this study, we use anisotropic diffusion filtering for denoising. The filter ranks the neighboring pixels based on their intensity, and the median value is determined for the pixel under evaluation. The new median or middle value then replaces the central pixel. Anisotropic diffusion filters perform well for shot or impulse noise, even if the values are extremely high.


                        GLCM features: The gray level co-occurrence matrix (GLCM) is a pattern matrix used to find the texture pattern in an image by modeling texture as a 2-dimensional array gray level variation. This array is called the gray level co-occurrence matrix. The GLCM feature is considered among the set of features to describe the pixel contrast and the energy of the region of interest. These features clearly differentiate normal tissue from the abnormal tissue of the brain based on the extracted contrast and energy. The GLCM is a statistical method that accounts for the spatial relationship among the pixels, and hence it is also known as the gray-level spatial dependence matrix. GLCM facets are calculated in four directions, 0°, 45°, 90° and 135°, and for four distances, 1, 2, 3, and 4. Five properties of the GLCM, namely contrast, correlation, energy and homogeneity, are computed as follows.
                           
                              (1)
                              
                                 Contrast
                                 =
                                 
                                    ∑
                                 
                                 
                                    
                                       
                                          |
                                          i
                                          -
                                          j
                                          
                                             
                                                |
                                             
                                             
                                                2
                                             
                                          
                                          ×
                                          p
                                          (
                                          i
                                          ,
                                          j
                                          )
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 Energy
                                 =
                                 
                                    ∑
                                 
                                 p
                                 
                                    
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 Homogeneity
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       p
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                    
                                       1
                                       +
                                       |
                                       i
                                       -
                                       j
                                       |
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 Correlation
                                 =
                                 
                                    ∑
                                 
                                 (
                                 i
                                 -
                                 μ
                                 i
                                 )
                                 (
                                 j
                                 -
                                 μ
                                 j
                                 )
                                 
                                    
                                       p
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                    
                                       [
                                       σ
                                       i
                                       ·
                                       σ
                                       j
                                       ]
                                    
                                 
                              
                           
                        The number of gray levels in an image resolves the size of the GLCM. The matrix element P(i,j|Δx, Δy) is the relative frequency, where two pixels are divided by the pixel distance (Δx, Δy) within a given neighborhood, one with intensity i and other with intensity j.

A GLCM P[i,
                        j] includes the position of the pixels with similar gray level values and is named by first specifying a displacement vector d
                        =(dx, dy) and counting all the pairs of pixels separated by d that have gray levels of i and j.


                        Wavelet features: Wavelets can be defined as a mathematical function representing small waves that are scaled and shifted replicas of a finite-length waveform, known as the mother wavelet.
                           
                              (5)
                              
                                 
                                    
                                       ψ
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             a
                                          
                                       
                                    
                                 
                                 ψ
                                 
                                    
                                       
                                          
                                             
                                                t
                                                -
                                                b
                                             
                                             
                                                a
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where ‘a’ is the scaling parameter and ‘b’ represents the shifting parameter.

Based on wavelets, a wavelet transform (WT) analyzes the image on various resolution scales and converts the image into a multi-resolution image with different frequency components. The frequency and spatial attributes of the image can be analyzed simultaneously after this conversion.

The wavelet is discontinuous and resembles a step function. For a function f, the Haar WT is defined as:
                           
                              (6)
                              
                                 f
                                 →
                                 
                                    
                                       
                                          
                                             
                                                a
                                             
                                             
                                                L
                                             
                                          
                                          |
                                          
                                             
                                                d
                                             
                                             
                                                L
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where L is the disintegration level, a is the approximation sub-band, and d is the detail sub-band.

Initially, the WT is applied to all rows and then is applied to every column of the image obtained in the initial step.

This resultant image is then divided into four sub-bands: LL, HL, LH, and HH sub-bands. (L=Low, H=High). An approximation of the original image is contained in the LL sub-band, and the other sub-bands contain the missing details. The LL sub-band obtained at any stage is again decomposed into LL, HL, LH, and HH sub-bands. Fig. 2
                         shows the process of pyramid decomposition.


                        Law’s energy texture features: Initially, the 1D kernels of the brain image are transferred into 2D filter kernels in this feature set. The second step includes the filtering of the input mammogram image with Law’s 2D kernels and calculation of the energy traits of the image. All the above features are extracted, and the ANFIS classifier is trained with these features. The training process is outlined in Fig. 3
                        .

An adaptive neuro fuzzy inference system combines neural networks and fuzzy logic. The classification rate is optimum compared to other classifiers. The classifier is dependent on the size of the testing and the training datasets. One hundred twenty brain tumor images (80 abnormal and 40 normal cases) were used for training, and 80 images (30 normal images and 50 images with exudates) were used in the testing phase. Features extracted from the biopsy, which included the area of the tumor region, entropy and homogeneity, were supplied as input to the ANFIS. The classification process of the ANFIS includes two steps, the training phase and the testing phase.

A preliminary model for ANFIS training is created by applying subtractive bunching over the data. In this phase, statistical features of the MRI brain images along with the desired output are generated to guide the network. The scheme constructs membership functions and if-then rules from the ANFIS that suit individual parameters at the beginning and at the end of the training. These membership function parameters are trained to reproduce the training data using aback propagation gradient descent algorithm. After achieving the desired training error objective, the training course is stopped, and the average value of the training error is calculated.

The selection of the seed point is automatic and depends on the appearance of the tumor. Due to differences in the tissues and blood supply within tumors, different tumor intensities occur even within the framework of the same MR imaging protocol. However, the tumors are characterized such that they always have higher or lower intensities compared to normal brain tissue intensities. Despite the inhomogeneities in intensity within tumor regions due to blood vessel, some tumor regions are significantly homogeneous compared to normal brain tissue. Hence, distinct tumor areas of with low intensities are negligible if the local homogeneity of the tumor tissue is considered. To increase the accuracy of the classification, a feature of the tumor region is considered in the proposed method. The steps include,
                           
                              
                                 Step 1: Define the tumor detector matrix (TDM): Apply a tumor detector function on the pixels obtained from the output of the preprocessing step to obtain the tumor detector matrix.


                                 Step 2: Thresholding the TDM: The TDM threshold depends on the smallest and largest values of the tumor detector matrix.

The neighborhood radius R and mean of the images. The threshold is estimated using,
                           
                              (7)
                              
                                 
                                    
                                       T
                                    
                                    
                                       d
                                    
                                 
                                 =
                                 
                                    
                                       Γ
                                    
                                    
                                       1
                                    
                                 
                                 (
                                 
                                    min
                                 
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       T
                                    
                                 
                                 )
                                 -
                                 
                                    max
                                 
                                 (
                                 
                                    
                                       M
                                    
                                    
                                       T
                                    
                                 
                                 )
                                 )
                                 +
                                 
                                    
                                       Γ
                                    
                                    
                                       2
                                    
                                 
                                 (
                                 R
                                 )
                                 +
                                 
                                    
                                       Γ
                                    
                                    
                                       3
                                    
                                 
                                 (
                                 μ
                                 )
                              
                           
                        where 
                           
                              
                                 
                                    Γ
                                 
                                 
                                    1
                                 
                              
                           
                        , 
                           
                              
                                 
                                    Γ
                                 
                                 
                                    2
                                 
                              
                           
                         and 
                           
                              
                                 
                                    Γ
                                 
                                 
                                    3
                                 
                              
                           
                         are the regular coefficients, and μ denotes the entire mean of the images.


                        
                           
                              
                                 Step 3: Calculating the edge image: The Canny edge detection algorithm is used to accurately detect the edges in the brain MR images.


                                 Step 4: Form a counter matrix of the edge points: To construct the counter matrix of edge points, if a value of a point within a radius R of an edge point is equivalent to the value of that edge point, this value is allotted to every point that matches the original image points.


                                 Step 5: Selecting a point set: The incorrectly selected points are removed by comparing the tumor detector matrix with the edge counter matrix.


                                 Step 6: Selecting the seed point: Finally, the center value of the point set (acquired in the previous step) is chosen as the end seed point.

@&#RESULTS AND DISCUSSION@&#

To determine the performance of the recommended algorithm for detecting tumors, the figures obtained using the proposed methodology are compared with its corresponding ground truth images. The proposed technique is analyzed using quality parameters, including the similarity index, the overlap fraction, and the extra fraction, to study its performance.
                           
                              (8)
                              
                                 SI
                                 =
                                 
                                    
                                       2
                                       TP
                                    
                                    
                                       2
                                       TP
                                       +
                                       FP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (9)
                              
                                 OF
                                 =
                                 
                                    
                                       TP
                                    
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (10)
                              
                                 EF
                                 =
                                 
                                    
                                       FP
                                    
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 Sensitivity
                                 
                                 [
                                 Se
                                 =
                                 TP
                                 /
                                 (
                                 TP
                                 +
                                 FN
                                 )
                                 ]
                              
                           
                        
                        
                           
                              (12)
                              
                                 Accuracy
                                 
                                 
                                    
                                       
                                          Acc
                                          =
                                          
                                             
                                                
                                                   TP
                                                   +
                                                   TN
                                                
                                             
                                          
                                          /
                                          
                                             
                                                
                                                   TP
                                                   +
                                                   FN
                                                   +
                                                   TN
                                                   +
                                                   FP
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (13)
                              
                                 Positive Predictive Value
                                 
                                 
                                    
                                       
                                          Ppv
                                          =
                                          TP
                                          /
                                          (
                                          TP
                                          +
                                          FP
                                          )
                                       
                                    
                                 
                              
                           
                        where TP is the exact number of true-positive pixels detected by the algorithm, FP is the number of false-positive pixels that were incorrectly identified by the method, and FN is the number of false-negative pixels in the tumor area via manual segmentation.

SI is a criterion for accurate segmentation in relation to the total fragmented region for both manual segmentation and image segmentation by the recommended method. The OF and the EF specify the tumor areas that are correctly and incorrectly classified respectively, via manual segmentation. The performance parameters are tabulated, as shown in Table 1
                        .

The MRI brain images shown in Fig. 4
                        a and b are the source images in which the tumors must be segmented. Fig. 4c and d shows the corresponding preprocessed images using an anisotropic diffusion filter.

The preprocessed brain images are then processed with our proposed tumor detection algorithm, and the edges are detected using the canny edge detection method. The edge-detected images are shown in Fig. 5
                        a and b. The features are the extracted, and finally, the ANFIS classifier segments the tumor region. The resultant images are shown in Fig. 5c and d.

A few images used in our work for training the ANFIS classifier are shown in Figs. 6 and 7
                        
                        . The training includes both benign and malignant tumor images, which increases the accuracy of the classification. Similarly, the images used in the testing phase are depicted in Fig. 8
                        .

The outcome of the proposed method is compared with other brain tumor classification methods in terms of the SI and OF, as tabulated in Table 2
                        , and in terms of the EF, as listed in Table 3
                        . Table 2 comparisons are graphically represented in Fig. 9
                        a and the positive predictive value graphically represented in Fig.9b. In Fig.9(a), the proposed method is compared with Lakshmi et al. [14] and Udupa et al. [11]. Fig.9(b) presents the comparison of the proposed method with Sharma et al. [12] and Karimaghaloo et al. [13].

The proposed work demonstrates a significant improvement of 0.81% in SI and OF compared to [14,11].

The sensitivity and accuracy rates of the proposed methodology are 0.81% and 0.87%, respectively, calculated using Eqs. (11) and (12).

@&#CONCLUSIONS@&#

The proposed tumor segmentation technique was applied to medical brain images to detect and diagnose brain abnormalities, such as benign and malignant tumors. The algorithm can be used by physicians to classify complicated tumors with reduced computational time and an improved accuracy rate. This will reduce the manpower required for brain tumor diagnoses in developing countries. Automatic tumor segmentation reduces the manual labeling required doctors, aiding in disease diagnosis. Features are extracted from the brain image and used to train a classifier. The ANFIS classifier then classifies brain tumors as benign or malignant based on the features extracted from the brain images. The seed point is used to segment abnormal brain patterns, and the selection of the seed point is automatic and depends on the appearance of the tumor. Morphological functions are used to extract the brain tumor region in the final stage of processing. Many brain images available in open access databases, few images are tested using the proposed algorithm. The proposed method clearly differentiates brain abnormalities from normal brain tissue. The proposed technique is superior to conventional techniques in terms of the positive predictive value. The tumor’s segmentation results are evaluated based on the similarity index, the overlap fraction, the extra fraction and the positive predictive value, whose obtained values are 0.817%, 0.817%, 0.182%, and 0.817%, respectively. In the future, tumor texture features can be extracted for use in automatic selecting the seed point. In addition, fuzzy connectedness can be combined with the proposed method to improve diagnoses and accuracy further. This work can also be extended to the detection and diagnosis of brain strokes by examining various brain tissue patterns.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Unsupervised adaptive microblog filtering for broad dynamic topics

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Broad topics on Twitter are highly dynamic.


                        
                        
                           
                           Boolean filtering retrieve high precision but limited number of tweets.


                        
                        
                           
                           A proposed adaptive filtering achieved 84% gain in recall with slight drop in prec.


                        
                        
                           
                           Proposed method showed robustness over time, across domains, and query formulations.


                        
                        
                           
                           Our method is currently adopted in a live service that follows news from Twitter.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Twitter

Microblog filtering

Unsupervised adaptive filtering

Broad dynamic topics

Arabic tweets

@&#ABSTRACT@&#


               
               
                  Information filtering has been a major task of study in the field of information retrieval (IR) for a long time, focusing on filtering well-formed documents such as news articles. Recently, more interest was directed towards applying filtering tasks to user-generated content such as microblogs. Several earlier studies investigated microblog filtering for focused topics. Another vital filtering scenario in microblogs targets the detection of posts that are relevant to long-standing broad and dynamic topics, i.e., topics spanning several subtopics that change over time. This type of filtering in microblogs is essential for many applications such as social studies on large events and news tracking of temporal topics. In this paper, we introduce an adaptive microblog filtering task that focuses on tracking topics of broad and dynamic nature. We propose an entirely-unsupervised approach that adapts to new aspects of the topic to retrieve relevant microblogs. We evaluated our filtering approach using 6 broad topics, each tested on 4 different time periods over 4 months. Experimental results showed that, on average, our approach achieved 84% increase in recall relative to the baseline approach, while maintaining an acceptable precision that showed a drop of about 8%. Our filtering method is currently implemented on TweetMogaz, a news portal generated from tweets. The website compiles the stream of Arabic tweets and detects the relevant tweets to different regions in the Middle East to be presented in the form of comprehensive reports that include top stories and news in each region.
               
            

@&#INTRODUCTION@&#

Microblogging sites, such as Twitter, are currently one of the main platforms for exchanging real-time information and discussions. This large amount of communicated information motivated many social scientists to study public response towards major events and topics on social media (Ali, Magdy, & Vogel, 2013; Chen et al., 2013; Conover, Ratkiewicz, Francisco, & Gonçalves, 2011; Magdy, 2013; Magdy & Elsayed, 2014; Phuvipadawat & Murata, 2010; Teevan, Ramage, & Morris, 2011; Vieweg, Hughes, Starbird, & Palen, 2010). However, selecting relevant information out of social posts requires, in many cases, scalable and adaptive information filtering techniques, since the topics to be tracked can be of broad and dynamic nature. This has appeared in many recent applications where it was essential to follow broad topics for long periods of time from the social media. These applications are such as news reporting (Elsawy, Mokhtar, & Magdy, 2014; Magdy, 2013), political events analysis (Borge-Holthoefer, Magdy, Darwish, & Weber, 2015; Conover et al., 2011), crisis management (Olteanu, Castillo, Diaz, & Vieweg, 2014; Vieweg et al., 2010), and many others. Most of these topics consist of multiple subtopics that get changed and drifted over time. For example, following microblogs related to “US Elections” requires tracking posts about several subtopics and related entities such as candidates, campaigns, political views, election process, etc. Moreover, the subtopics are also dynamic. For example, “debates” is an important one before elections, while “election results” is the most important during voting. Sometimes subtopics span very short period of time, e.g., press statements by candidates. The broad topics can even be more general or broader than the earlier example, e.g. “US Politics”, which includes “US Elections” as a temporal subtopic. Similarly, in a study about public response to a long-standing event such as “the Syrian conflict”, tracking relevant microblogs is not a straightforward task, since it requires the coverage of as much of the related posted content as possible to cope with the developing sub-events. Tracking such kind of topics, which last for a long period of time and consist of several sub-events that change dramatically over time, requires a set of selective queries (rather than just a single one) to be updated periodically for effectively covering different aspects of these topics.

Two common user-based features that are provided by microblogging platforms are widely used for filtering. The first is the “follow” feature that allows a user to follow other accounts of entities, persons, or events to get their tweets into the user's timeline. The other method for following specific microblogs is searching for given hashtags (i.e., the character “#” followed by a tag (e.g., #Syria) that generally indicates the topic of the mentioning tweet), which is a common way for users to get updates on topics that are indicated by those hashtags. This method is less strict in filtering information, where more tweets are generally presented to user. However, many off-topic tweets would be retrieved because of the misuse of hashtags by some users. Moreover, many tweets that are relevant to the topic may not include the hashtag itself, and thus will be missed.

In this paper, we present an unsupervised approach for microblog filtering that aims at following broad and dynamic topics. Our main objective is to boost recall by retrieving a large number of relevant microblogs, while preserving high precision to avoid bothering users with irrelevant feeds. The main challenge lies in capturing relevant microblogs to temporal short-term subtopics that might only appear for a short period of time. Our approach initially gets a user-defined fixed query or set of queries that cover the most static part of the target topic and retrieves initial set of hopefully-relevant microblogs using simple Boolean search. The initial retrieved set of microblogs is used in a novel, unsupervised, and adaptive manner to train a binary classifier that is used for detecting other relevant content within a stream of microblogs. This classifier is trained and updated automatically and regularly to adapt to the dynamic nature of the tracked topic without any user intervention.

We tested the approach on six hot broad and dynamic topics to simulate the topics typically studied in social studies. We tested our approach with the topics on four different days from four different months to measure the performance consistency of the approach over time. This forms a set of 24 testing points for our approach. Thousands of relevance assessments were created for the evaluation process. Topics were selected from three different domains: politics, war, and sports. Three of the test topics were each represented by a single hashtag, and the other three topics were well-formulated by a rich set of accurate Boolean queries to achieve an initial high-precision set of microblogs. A stream of 3–4 million Arabic tweets per day was used in our experiments with the goal of identifying tweets that are relevant to each of the test topics. Our approach achieved to retrieve large number of relevant microblogs that do not include any of the search queries but still are on topic based on the events on-going on the tested dates. Compared to the baseline approach; experimental results showed a boost in recall of average 84%, while precision is dropped by only 8%.

Our filtering approach is implemented in the backend of TweetMogaz
                        1
                     
                     
                        1
                        
                           www.tweetmogaz.com
                        
                      (Magdy, 2013), which is a framework for following news happening in different regions from Twitter, and presents them in the form of comprehensive report that includes pseudo-articles (Elsawy et al., 2014) and top posts about the topic. The service is live and shows the effectiveness of on practical use on real-life streams of data.

We make the developed test set along with 6 broad topics and relevance assessments for these topics over 4 different days publically available for potential future research studies
                        2
                     
                     
                        2
                        
                           http://alt.qcri.org/∼wmagdy/Resources/FilteringData.htm
                        
                     .

The rest of the paper is organized as follows. Section 2 reviews related work. Section 3 defines our problem. Section 4 describes our proposed approach. Section 5 explains experimental setup. Section 6 reports the results and highlights the success of the approach. Section 7 introduces TweetMogaz, a platform for tweets search and filtering, which uses our filtering approach and demonstrates its effectiveness in practice. Finally, Section 8 concludes the paper and provides possible future directions.

@&#RELATED WORK@&#

In this section we show examples of various applications that depend on following broad topics on social media. Then we present some prior work on microblog filtering.

The purpose of collecting microblogs, especially for broad and dynamic topics, extends beyond reading them; it actually includes analysis, summarization, prediction, or classification. Some of the applications for such task are news monitoring (Elsawy et al., 2014; Magdy, 2013; Phuvipadawat & Murata, 2010), crisis management (Olteanu et al., 2014; Vieweg et al., 2010), customer feedback detection (Chen, Cypher, Drews, & Nichols, 2013), public political polarization analysis (Borge-Holthoefer et al., 2015; Conover et al., 2011), election results prediction (Tumasjan, Sprenger, Sandner, & Welpe, 2010), online reputation management (Amigó et al., 2013), and public healthcare monitoring tools (Ali et al., 2013). All of these applications require the analysis of a large number of social posts, typically tweets. To get that amount of relevant tweets with minimum noise, a relatively high-recall high-precision filtering system is needed. However, the most commonly used method for the majority of these applications rely on using straightforward Boolean filtering to microblogs based on predefined set of keywords (Ali et al., 2013; Borge-Holthoefer et al., 2015; Magdy, 2013; Tumasjan et al., 2010; Vieweg et al., 2010) or hashtags (Conover et al., 2011; Phuvipadawat & Murata, 2010).

Some studies used advanced methods for achieving more effective microblog filtering for their dedicated applications. Dan, Feng, & Davison, 2011 proposed a bootstrapping approach for tracking tweets that are related to specific TV shows. They used domain-knowledge and a 2-stage semi-supervised training of a classifier, where they tagged tweets manually for relevance, then used them to classify candidate tweets. The newly classified tweets were then used to train a second classifier with more data. Chen et al., 2013 realized that keyword-based filtering is not so effective for tracking tweets that express customer opinions about commercial brands (e.g., Delta Airlines). Therefore, they leveraged crowd-sourcing resources to label tweets that satisfy predefined-queries to train a supervised binary classifier. Olteanu et al., 2014 applied pseudo-relevance feedback approach for enriching their initial lexicon used for streaming tweets related to crisis in an attempt to improve the recall of messages that ask for help during crisis situations. They managed to collect related terms to use as additional queries in their search, which led to significantly improving the recall, while leading to acceptable amount of degradation in precision for this task.

RepLab (Amigó et al., 2013) is a shared-task evaluation campaign that focuses on tracking mentions of entities (e.g., organizations or universities) over a stream of tweets with the objective of monitoring the reputation of those entities. As a sub-task, tweets that mention the canonical names of the entities are classified as related or unrelated to the corresponding entities. For example, tweets containing the word “Stanford” referring to the place should be filtered out, while keeping those referring to the university (Amigó et al., 2013). While the sub-task is considered a filtering problem, it focuses on entities (not topics) that are broad but have few sub-entities and of a much-less dynamic nature than our target topics. Moreover, the sub-task focuses more on improving the precision of a mostly-relevant stream of tweets that match a given entity name as the objective was to filter out tweets that contain the name-mention of the entity but referring to a different entity. In our work, improving precision is one of our objectives, but we focus more on significantly-improving the recall by finding topically-relevant tweets regardless of mentioning the given topic terms.

More advanced information filtering technologies can be developed for applications in various domains that require microblog filtering, especially for tasks that track topics of broad, dynamic, and long-standing nature similar to the aforementioned examples.

Information filtering techniques have been studied for more than two decades now (Belkin & Croft, 1992; Oard, 1997). Information filtering deals with an incoming stream of documents and aims to detect relevant ones while filtering the rest out. Traditionally, focus was directed to filtering stream of news articles given a user-defined topic (Allan, 2002). A series of topic detection and tracking evaluations has motivated the research in that direction with topics being event-based and specifically defined by news stories that mark the beginning of events to be tracked (Allan, 2002). In recent years, some initiatives investigated the development of information filtering techniques for microblogs. The main focus has been toward the typical focused topics that are represented by a single free-text query. The objective of most of the investigations was to achieve high precision, while giving less emphasis on recall (Soboroff, Ounis, & Lin, 2012). In fact, the focus on traditional user queries for microblog filtering is motivated by real-life scenarios. Teevan et al., 2011 highlighted the differences between web queries and microblog queries. Microblog queries usually represent users’ interest to find updates about focused topics, such as specific events or people, as opposed to finding relevant pages on a given topic in web search. Thus, most of the developed filtering techniques served the direction of finding relevant tweets to focused topics (Naveed, Gottron, Kunegis, & Alhadi, 2011).

One of the initial introduced approaches for applying microblog filtering was by Lin, Snow, & Morgan, 2011. They used an adaptive language modelling technique to track topics represented by most common hashtags, e.g., “Apple” “Fashion”, and “American football”. Tweets having the hashtags were used in their experiments as training data to build a language model (LM) for each topic. Two LMs were built: a background LM built using a month of tweets matching the hashtag, and a foreground LM built from the most recent N identified relevant tweets from the stream. Several smoothing techniques were tested to integrate both LM models. Results showed the effectiveness of their approach tested over 10 topics (hashtags) in achieving a high precision that exceeded 0.98 and a recall ranging between 0.5 and 0.8. This approach is highly precision-oriented in contrast to our high-recall objective. In a more recent study, Albakour, Macdonald, & Ounis, 2013 proposed an unsupervised approach that exploits traditional query expansion to combat sparsity and a decay smoothing technique besides event detection through either tweet or newswire stream to handle topic drift. Another research work conducted microblog filtering based on importance of tweets, regardless of the topic, by estimating the probability of a tweet to get re-tweeted (Uysal & Croft, 2011). Other focused on microblog filtering, but for detecting spam tweets (Song, Lee, & Kim, 2011).

In a recent work (Li, Wang, Resnick, & Mei, 2014), an adaptive filtering technique was proposed to improve the system recall while preserving high precision values. This aligns with the objective for our approach proposed here. They apply iterative expansion to queries through direct user feedback on multiple sessions while applying classifier to ensure high precision values. Their approach was shown to be effective when examined on focused-topics. However this approach is seen not very scalable for broad long-standing topics, since it requires manual feedback, which is not practical in real-life applications.

More work on filtering tweets on focused topics has been reported for the TREC microblog track that has introduced the filtering task for the first time in 2012 (Soboroff et al., 2012). Most of the experiments adopted either a supervised learning approach using manually labelled tweets for training (Zhang et al., 2012), or a Rocchio-based approach that is updated using the available relevance judgments (Limsopatham et al., 2012).

Less attention was directed to broad dynamic topics filtering that was demonstrated to be essential in many applications. We propose a self-adaptive unsupervised approach designed specifically for this task to better coverage of relevant tweets without degrading the precision significantly compared to the mostly adopted Boolean filtering method.

The properties of topics that we stress on in this paper are:

                        
                           -
                           Broad: consisting of several subtopics, which usually require several queries for tracking.

Dynamic: featuring dramatic changes in the types and number of subtopics over time.

Long-standing: lasting for long periods of time, which requires a robust approach with minimal user intervention.

These topics are potentially of interest by professional institutions and experts, rather than normal users. The expected typical users for this task are social scientists and institutes that strive to track public posts on social media, such as governments, news agencies, and crisis managements organizations.

We define our filtering task as follows. The user seeks to track a targeted broad topic P in a specific time period tp
                     . The topic P is represented by a set of queries Q
                     0 = {q1, q2
                     , …,qn
                     } where n ≥ 1; each can be expressed in keywords, phrases, microblog-user accounts, or hashtags. The set of queries should cover the wide space of the broad topic P. The filtering system is then required to process an upcoming stream of microblogs and presents only the microblogs that are relevant to P based on Q0
                      without the need of manually-updating it. No user feedback is given during the filtering process.

A filtering approach for this task should meet the following objectives:

                        
                           1.
                           Achieving higher recall levels than the typical Boolean method to better model the spectrum of relevant tweets to the broad topics.

Maintaining high precision levels to minimize the amount of noise within the collected tweets.

Self-adapting to the changes occurring to the topics over time, since these topics are highly dynamic.

In our proposed approach, we strive to meet these objectives, as we describe in Section 4.

In this section, we describe our filtering approach for broad dynamic topics. Our approach builds on three simpler filtering techniques and all of which are unsupervised. We discuss those ideas first before presenting our final proposed approach.

The simplest filtering technique, and the most commonly-used one, is the one that views Q
                        0 as a set of Boolean queries and therefore applies a Boolean filter, denoted by fB
                        , to track tweets that satisfy any of the queries in Q
                        0 in the upcoming stream. The resulting matched tweets are denoted by TB
                        . The effectiveness of this technique depends on the quality of the selected queries in Q
                        0; if they are selected precisely, it is expected to retrieve results of very high precision; however recall is expected to be low since topics are highly dynamic and many of the relevant tweets might not include any of the terms in Q
                        0.

A classical idea that extends the Boolean filter fB
                         to achieve better recall is to apply query expansion using the initial query set Q
                        0, aiming to match more tweets. In this approach, a set of related terms R is added to Q
                        0 as expansion terms using pseudo relevance feedback. The new terms are selected from terms in the set of tweets TB
                         that are matched by fB
                         in a given window of time w. In our context, w should precede the beginning of the online filtering process, resembling a training-like period. We denoted the whole set of tweets in the training window w by Tw
                        . Each term t that appears in TB
                         is scored using TF_IDF as in Eq. (1):

                           
                              (1)
                              
                                 
                                    T
                                    F
                                    _
                                    I
                                    D
                                    
                                       F
                                       w
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    =
                                    t
                                    
                                       f
                                       B
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    ·
                                    log
                                    
                                       
                                          N
                                          w
                                       
                                       
                                          d
                                          
                                             f
                                             w
                                          
                                          
                                             (
                                             t
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        where tfB
                        (t) is the total term frequency of term t within TB; dfw
                        (t) is the number of tweets in Tw
                         that contained the term t; and Nw
                         is the total number of tweets in Tw
                        , i.e. |Tw
                         |. The top k terms are selected to form the set of related terms R, which can also be viewed as a set of single-term queries {
                           
                              q
                              ¯
                           
                        
                        
                           1
                        , 
                           
                              q
                              ¯
                           
                        
                        
                           2
                        , …, 
                           
                              q
                              ¯
                           
                        
                        
                           k
                        }. R is then added to Q
                        0 to finally produce an expanded set of queries QE
                         = {q1
                        , …, qn
                        , 
                           
                              q
                              ¯
                           
                        
                        
                           1
                        , …, 
                           
                              q
                              ¯
                           
                        
                        
                           k
                        }. The expanded set is then used for Boolean filtering, similar to the way Q
                        0 was used. We refer to the resulting filter as fBE
                         and the matched tweets as TBE
                        . Although fBE
                         is expected to match more relevant tweets, there is a potential loss in precision due to retrieving more non-relevant tweets as well, since QE
                         is not expected to be as accurate as Q
                        0 that is prepared manually.

Since Boolean filters are strict, a classifier-based filter is expected to get even higher recall. To train a binary classifier, samples of positive and negative examples are required. In our problem, it is straightforward to use the set of tweet TB
                         identified by fB
                         as the positive sample since it is expected to be of high precision (compared to TBE
                        ). A random sample T
                        rand of the tweets that do not match Q
                        0 in Tw
                         can then act as the negative sample.

The trained classifier is then used to classify the stream of microblogs into relevant or non-relevant. We refer to the resulting classifier as fC
                        . This filtering technique can be less strict, since terms can be used as features (as we discuss in Section 4.4) which helps in finding relevant microblogs that do not have to match Q
                        0. However, the main concern about fC
                         is that T
                        rand might include actual relevant tweets, as tweets are selected randomly. This happens when those relevant tweets are not picked by fB
                         due to the static nature of Q
                        0, leading to a trained classifier that is confused over good features. This last concern is one of the key motivations behind our final proposed approach that is discussed in the following section. Notice that no expansion is performed in this filter.

The above three filtering techniques represent the core ideas behind our proposed approach that attempts to achieve higher recall while preserving acceptable levels of precision. Fig. 1
                         illustrates the basic blocks of the approach and shows how the above ideas are leveraged.

Our approach is unsupervised classifier-based, and the key idea behind it is the novel way we utilize the related terms R in the filtering process. Similar to fC
                        , a binary classifier is trained to filter an online stream of tweets. While the positive sample for training the classifier remains the same as in fC
                         (represented by TB
                        ), the negative sample is drawn differently. A random sample T
                        rand is similarly drawn from tweets that appear in the training tweets Tw
                         but not in TB
                        , however it is not directly used as a negative sample to train the classifier. Related terms R extracted from TB
                         using Eq. (1) are used as exclusion terms to “clean” T
                        rand from potentially-relevant tweets (rather than adding them to Q
                        0 as used in fBE
                        ). Thus, any tweets that contains any of the terms in R are excluded from T
                        rand, eventually creating the set of tweets TN
                         used as negative sample to train the classifier.

This process tries to minimize the chance that the negative sample might contain tweets that are possibly relevant to the topic. The rationale is that R can match many potentially-relevant tweets, and thus can “clean” the negative sample from those noisy examples that would negatively affect the performance of the classifier. The fact that it might also match irrelevant tweets as well, and thus exclude them from the negative sample, should not have negative effect since T
                        rand is naturally of no shortage of non-relevant tweets. We refer to the final trained classifier as fCE
                        . Fig. 2
                         sketches the algorithm used in our approach.

In practical use of fCE
                        , the processes of term selection and classifier training are applied periodically to frequently adapt to the expected changes and drifts in the targeted topic. Both the window of time w for collecting the training samples and the frequency of updating the classifier depend on the dynamicity and broadness of the topic. For example, in our experiments, we set w to 20 h of tweets stream, and we update the classifier every 4 h by retraining it on the past w hours. Fig. 3
                         illustrates the training and filtering periods Tw
                         and Tf
                         of two subsequent trained classifiers fCE
                        
                        1 and fCE
                        
                        2 using that setting. The figure shows that the training period of a classifier overlaps with the training period of the subsequent one.

In our experiments, we have used support vector machines (SVM) classifier (Joachims, 2002) with linear kernel. Each tweet is represented as a feature vector. Terms of the tweet, including hashtags, user mentions (@user), and tweet author, are used as the features. Feature values are all binary based on the existence of the terms in the tweet. Since the classifier is trained periodically, it is expected that the set of terms used as features change over time as the training samples change. For an efficient process, we reduce the feature space by selecting only the terms that appear more than 10 times in TB
                         as the features, after removing stop words. Eliminating low frequency features is seen to be beneficial to avoid potential over-fitting caused by these very sparse features. Terms that appear in a tweet but not in the feature space are represented by an additional special feature, denoted by miss, which is defined as the percentage of terms in the tweet that do not exist as features in the feature space. For example, if a tweet has 10 terms after stop-word removal, and only two terms exist in the feature space and the rest do not, then the corresponding features of the two existing terms will be set to one, and the value of the miss feature will be set to 0.8. The miss feature is expected to be dominant for most of the negative samples, but some additional features for confusing terms in the feature space would still exist leading them to have lower weight for identifying relevant tweets. During the filtering process, the classifier assigns a score to each tweet; we only consider tweets of positive scores as relevant.

We note that the set of features are different from one topic to anther and from one training instance to another even for the same topic, since it depends on the terms appearing in the set TB
                        , which changes periodically. We also elect to set the size of the negative samples to be 10 times the size of the positive sample, to better cover the wide space of the non-relevant tweets.

To ensure an adequate evaluation of filtering for broad and dynamic topics in microblogs, we considered the following criteria:

                        
                           1.
                           
                              Testing on broad topics from different domains. Our filtering method mainly targets topics of broad and dynamic nature, which received less attention in literature. Previous studies carried out on information filtering for focused topics on social media posts focused mostly on hot topics from various domains. Therefore, we focused on selecting topics from different domains that would potentially have many relevant posts on social media.


                              Monitoring performance over long and different periods of time. Since we are selecting dynamic topics in our study, we are keen to measure the effectiveness of our filtering approach over long and different periods of time without manually-updating the initial user-defined topic representation Q0
                              . The objective of this criterion is to measure the adaptability of our filtering technique to the dramatic changes that occur to the targeted topics over time.


                              Using real-life microblog stream. Modelling our experiments to match practical applications of the filtering task requires monitoring a real-life stream of microblogs that provides large number of microblogs per second, and that is running for a long period of time. This is essential for an adequate evaluation of the effectiveness and robustness of our approach, since the exposure to some noise in the adaptive filtering process can lead to classifying a large portion of irrelevant tweets as relevant. This could be reliably tested using real-life microblog streams but not small and closed datasets. Unfortunately, none of the available microblog collections has such property (Amigó et al., 2013; Ounis, Macdonald, Lin, & Soboroff, 2011; Soboroff et al., 2012).

In this section, we discuss the used data stream, the created topics, the relevance judgment process, the experimented runs, and the adopted evaluation methodology.

For the microblog data stream, we used the Twitter search API with the general query “lang:ar” to stream tweets of Arabic content. We focused on the Arabic stream for two reasons:

                           
                              1.
                              Events in the Arab world and middle-east are recently very hot, long-standing, and highly dynamic; and the volume of microblogs posted about these events is expected to be high.

The limitation of the freely available Twitter API allows streaming of no more than 1% of the publicly-available tweets. Getting the 1% sample in English or without specifying the language would make the stream highly sparse, which may lead to a limited retrieval of relevant tweets. It was important to restrict the stream to be focused, general, and unbiased. Restricting the 1% sample to Arabic tweets can get up to 50% of the Arabic posts on Twitter (Arab Social Media Report, 2013). In this case, the stream is general enough, since no specific terms are used for streaming, and it potentially has decent amount of relevant content to our targeted topics.

The tweet4j package
                           3
                        
                        
                           3
                           
                              https://code.google.com/p/tweet4j/
                           
                         was used for streaming the Arabic tweets. The average number of tweets received per second was 37 tweets; making an average of 3.2 million Arabic tweets collected per day. To evaluate the consistency of our approach in filtering dynamic topics, we collected tweets of four full days, each from a different month in February, March, April, and May of 2013. The day is considered between 12:00:00 A.M. GMT to 11:59:59 P.M. GMT.

Arabic text of the collected tweets stream is pre-processed using state-of-the-art normalization technique for social Arabic text (Darwish, Magdy, & Mourad, 2012) to facilitate the matching process between queries and tweets. This normalization technique includes letter normalization, diacritics removal, decorative text replacement, and word elongation resolving (Darwish et al., 2012).

In our experiments, we targeted topics of two categories (in terms of representation) that are inspired from applications presented in Section 2.1. The first category has loosely-defined topics that are each defined by one hashtag for a broad dynamic subject. The other has tightly-defined topics that are each defined by a large set of well selected queries.

Targeting the former category is motivated by the fact that it is easy to define and is more popular in a wide range of filtering tasks and particularly in social studies (Conover et al., 2011; Phuvipadawat & Murata, 2010). In several studies of filtering microblogs, hashtags were typically used to represent the topics of interest (Lin et al., 2011). However, focusing on hashtags to represent broad and dynamic topics has several drawbacks. It was reported that the percentage of tweets that mention at least one hashtag is approximately 10% (Lin et al., 2011), which means that some relevant tweets to the topic of the hashtag do not include the hashtag itself. Moreover, hashtags sometimes got abused by users to spam or attract attention to tweets that are completely non-relevant to the hashtags. Thus, we targeted another category of topics that are tightly-defined through a series of well-selected keyword queries that mainly cover the static aspects of the topic. This is also adopted in several studies (Ali et al., 2013; Magdy, 2013; Tumasjan et al., 2010; Vieweg et al., 2010).

We selected three topics in each of these two categories, and tested each of these topics in 4 different days from four different months (Feb., Mar., Apr., and May 2013) to show how effective our proposed approach is in dealing with the dynamic nature of the topics over long time periods. This setup provides a set of 24 testing points to evaluate the performance of our filtering approach, which is almost the number suggested by Sanderson and Joho (Sanderson & Joho, 2004) for an effective evaluation of an IR system.

For the loosely-defined topics, we selected three broad topics that are considered among the hottest worldwide in 2013, #Egypt, #Syria, and #Bahrain (in Arabic), where the three hashtags refer to three countries with conflicts and clashes with many developing events that change dramatically over time. We refer to the three topics as #EGY, #SYR, and #BHR, respectively. Since only hashtags are used, there was no guarantee about the precision of the tweets matching these hashtags.

Another set of three tightly-defined broad topics of different domains were also selected; two of them are related to the loosely-defined ones for performance comparison of loosely- vs. tightly-defined topics referring to similar subjects. The selected topics were: “Egyptian Politics”, “Syrian Conflict”, and a third topic of different domain “International Sports”. We refer to these three topics as EGY, SYR, and SPO, respectively.

To represent the three tightly-defined topics, we asked three Arabic-speaking volunteers in our institutes, each interested in and having good knowledge about one of the three selected topics, to prepare a set of queries that represent them. We refer to the volunteers as topic developers. Each set of the prepared queries represents the most static parts of the corresponding topic. For example, entities such as persons (e.g. politicians and players), institutes (e.g. political parties, fighting groups, and soccer teams), and twitter accounts (e.g., accounts of politicians or dedicated news providers) are potential candidates. Queries representing temporal events were not used. We asked our topic developers to use precise queries that should retrieve relevant tweets with very high probability. Boolean queries were allowed, where AND and OR operators were used in some of the queries to make it more precise. We asked them to use each of the queries to search Twitter and discard those that return any non-relevant tweet among the top 10 tweets to ensure the precision of the individual queries. The number of queries prepared to cover each topic and some sample queries are presented in Table 1.
                        
                     

After getting the microblog stream and developing the topics, we applied the filtering approaches to the collected data; for each test day, the tweets in the first 20 h were used for training (i.e., w = 20 h) and the tweet stream in the last 4 h was used for testing (i.e., filtering). We applied our four filtering approaches fB, fC, fBE
                        (k), and fCE
                        (k), described in Section 4, to filter the stream for each of the 6 topics in each of the 4 test days. The parameter k indicates the number of expansion terms in fBE
                         and number of exclusion terms in fCE
                        . The values of k tested in our experiments were 50, 100, and 200 terms. The first three approaches are all considered baseline approaches, however, in our experiments we compute recall and precision relative to fB
                        , the most commonly used approach for microblog filtering in many applications.

The set of identified tweets in the 4-hour test stream by f
                        B filtering method is referred to as 
                           
                              T
                              B
                              *
                           
                         to distinguish it from TB
                         that refers to tweets matching fB
                         in the 20-hour train stream and used as positive samples for training fC
                         and fCE
                        (k) classifiers.

We attempted to build another baseline for the filtering technique presented by Lin et al. (Lin et al., 2011). We implemented the LM approach and the smoothing techniques used. We used T
                        B as our background LM, and the tweets classified as relevant in the 4-hour stream as the foreground model. Unfortunately, the results of some pilot runs were totally incomparable to the ones reported. On average, we found that 30% of the tweets in the stream were classified as relevant. This means that, within a day, more than 1 million tweets were classified as relevant per topic, which is very far from the expected performance. This was unrealistic and impractical to be evaluated. One potential reason behind that is the different nature of topics they studied which were mainly focused topics, not highly broad and dynamic ones
                           4
                        
                        
                           4
                           We got in contact with Jimmy Lin, the first author of [Lin et al., 2011], regarding the performance of their algorithm on our task; he confirmed our speculation that their approach is mainly designed for focused topics and is not expected to perform well with topics of dynamic nature.
                        . We have also trained the background model over 20 h only rather than one month.

Building the relevance assessments for this task was a real challenge since the number of tweets classified as relevant was always in thousands for each scenario. It was almost impossible to exhaustively assess this large number of tweets for relevance. We could not make the simple assumption that tweets mentioning a certain hashtag are relevant (Lin et al., 2011), since this does not generally hold, and it contradicts with our objective of improving the recall by retrieving relevant tweets that do not match the search query.

We initially attempted to utilize crowdsourcing platforms for assessing the large number of resulting tweets of our runs. Considering that tweets to be assessed are in Arabic, we submitted a pilot run on crowdflower
                           5
                        
                        
                           5
                           
                              http://crowdflower.com/
                           
                        . A set of 500 tweets randomly selected from different runs for EGY topic was submitted and we asked for at least three annotators to assess the relevance of each tweet. Although a well-prepared large set of test questions was provided to ensure high quality annotation, we found that the average agreement among assessors was 75%, which we considered low. To test the quality of the judgments, we then asked the EGY topic developer to assess the 500 tweets carefully himself. He found 19% of the crowdsourcing judgments were clearly incorrect. This highlights the challenge of the annotation task, where the filtering algorithm detects relevant tweets on the broad topic that are not easy to relate unless the assessor carefully explores the archived news on that date that are related to the topic in order to find what is relevant and what is not. For example, if an accident happens on a given date, the name of the casualties may be popular on that specific day, but not later. For such type of task, this error rate was unacceptable, and thus we had to resort to a more efficient and reliable relevance assessment methodology.

To efficiently evaluate our runs, we adopted a different strategy. We sampled the classified-as-relevant tweets by selecting 100 tweets from each run for each topic and in each testing period. If the sample was drawn randomly from the tweets resulting from each run, it would have produced a large assessment job since there would be a very low chance of sampling common tweets across different runs. To alleviate this problem, we adopted a guided sampling strategy; we ranked the tweets resulting from each run based on the number of their retweets (counted as the number of repetitions in the stream), and then assessed the top 100 of each run for relevance. This would raise the probability of having common tweets among different runs in the assessment sample, and hence reducing the number of tweets to be assessed. Moreover, the selected 100 tweets represent more tweets in the stream, since they are highly frequent. We argue that this guided sampling strategy does not produce a biased evaluation; the reason is that our filtering approaches are completely independent of the “retweet” information. To experimentally prove it, we measured the Kendall–Tau correlation (Kendall, 1938) between the ranking of the sampled tweets based on the classification score and their ranking based on their retweets, and we repeated that for each run for all topics. We found that the correlation ranged from −0.1 to 0.1 for all runs. This indicates that the retweets were not correlated with the classification scores and hence the selected sample was not biased towards the tweets of high classification score.

Additionally, we similarly selected the top 100 retweeted tweets in the training set TB
                         in order to estimate the accuracy of the positive samples used to train the classifier-based approaches.

Finally, all sampled tweets from all runs on the same topic and day are merged together and randomly shuffled before being handed to the assessors. To ensure more reliable relevance assessments, we asked the topic developers to assess the relevance of the merged samples of their corresponding topics. Before performing the assessments, we asked each assessor to take a quick look on the events related to the topic occurred on the date of the test day. This would ensure that they are aware of the different aspects of each topic. The total number of tweets assessed was 11,279 tweets. The average number assessed per topic per test day was around 470 tweets. It took about 15–20 h to finish the assessment process for a single topic for the four test days.

The effectiveness of a filtering system can be generally measured by precision and recall of the classified items. The precision of a run is estimated by calculating the number of relevant tweets among the selected sample of 100 tweets. However, it was infeasible to calculate recall, since there is no estimation about the number of relevant tweets in the test stream. Instead, we computed the relative change in recall, denoted by ∆Recallrelative
                        , to measure the effectiveness of our filtering approach in retrieving additional relevant results compared to the baseline filtering method fB
                        .

For a given run (i.e., experimented filter) x, precision, relative change in precision, and relative change in recall are computed as follows:

                           
                              
                                 
                                    P
                                    r
                                    e
                                    c
                                    i
                                    s
                                    i
                                    o
                                    n
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                    
                                       
                                          |
                                          
                                             r
                                             e
                                             l
                                             e
                                             v
                                             a
                                             n
                                             t
                                             
                                             t
                                             w
                                             e
                                             e
                                             t
                                             s
                                             
                                             i
                                             n
                                             
                                             s
                                             a
                                             m
                                             p
                                             l
                                             e
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          |
                                       
                                       100
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    Δ
                                    P
                                    r
                                    e
                                    c
                                    i
                                    s
                                    i
                                    o
                                    
                                       n
                                       
                                          r
                                          e
                                          l
                                          a
                                          t
                                          i
                                          v
                                          e
                                       
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                    
                                       
                                          P
                                          r
                                          e
                                          c
                                          i
                                          s
                                          i
                                          o
                                          n
                                          
                                             (
                                             x
                                             )
                                          
                                       
                                       
                                          P
                                          r
                                          e
                                          c
                                          i
                                          s
                                          i
                                          o
                                          n
                                          
                                             (
                                             
                                                f
                                                B
                                             
                                             )
                                          
                                       
                                    
                                    −
                                    1
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    Δ
                                    R
                                    e
                                    c
                                    a
                                    l
                                    
                                       l
                                       
                                          r
                                          e
                                          l
                                          a
                                          t
                                          i
                                          v
                                          e
                                       
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                    
                                       
                                          Classifie
                                          
                                             d
                                             
                                                R
                                                e
                                                l
                                             
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          *
                                          Precision
                                          
                                             (
                                             x
                                             )
                                          
                                       
                                       
                                          Classifie
                                          
                                             d
                                             
                                                R
                                                e
                                                l
                                             
                                          
                                          
                                             (
                                             
                                                f
                                                B
                                             
                                             )
                                          
                                          *
                                          Precision
                                          
                                             (
                                             
                                                f
                                                B
                                             
                                             )
                                          
                                       
                                    
                                    −
                                    1
                                 
                              
                           
                        where, ClassifiedRel
                        (fB
                        ) = 
                           
                              
                                 |
                              
                              
                                 T
                                 B
                                 *
                              
                              
                                 |
                              
                           
                        .

The overall system performance is evaluated using the mean of the calculated scores over all of the 24 test points.

Unfortunately, we were not able to measure the performance in a single figure of merit that combines both recall and precision, such as F-measure or T11SU, or even other measure using in Replab such as Reliability and Sensitivity (Amigó et al., 2013), due to the absence of the estimation of total number of relevant results in the data stream. However, we believe that measuring the relative gain or drop in precision and recall is sufficient to evaluate the performance of the filtering technique.

In this section, we analyse and discuss the performance of our filtering techniques.


                        Fig. 4.a shows the average performance of our proposed approach along with the baselines over all topics. The left subfigure presents the estimated precision, while the right subfigure illustrates both the estimated change in precision and recall relative to the fB
                        . All measures are estimated from the 100-tweet sample of each run as described earlier in Section 5.

As shown in Fig. 4.a, relying only on Q
                        0 for tracking broad dynamic topics leads to high-precision results, but limited recall, compared to what could be achieved by other filtering approaches. This is clearly shown in the results of fB
                        , which achieved the highest overall precision of 0.86, but the lowest recall among all other filtering techniques, which all achieved higher recall.


                        fC
                         led to only 5% increase in recall compared to fB
                        , while precision was dropped by 1%. Both increase in recall and drop in precision were found to be statistically significant using two-tailed t-test with 95% confidence
                           6
                        
                        
                           6
                           In the following, all cases of drop in precision or increase in recall of all filtering methods compared to baseline Boolean filtering were found to be statistically significant using two-tailed t-test with p-value of 0.05.
                        . However, this change is still not a major change to claim a superior improvement in performance in real applications. Having a deeper look on the classified tweets, it was found that 94% of the tweets detected by fB
                         (i.e. 
                           
                              T
                              B
                              *
                           
                        ) were already identified by this filtering approach. This indicates that training fC
                         in this manner produced a classifier that is highly biased to the set TB
                         used as positive sample in training.

Applying query expansion using different number of expansion terms, k = 50, 100, and 200, without applying any classification to the tweets led to a superior increase in the number of relevant tweets retrieved, but a dramatic drop in precision. This is shown by the fBE
                        (k) runs in Fig. 4.a. More than half of the tweets classified as relevant by this approach were non-relevant, indicated by the very low precision ranged from 0.35 to 0.43. However, same results show that expanding Q
                        0 with additional related terms R led to an estimated increase in recall of more than double. This indicates two important issues. Firstly, there is a large number of relevant tweets in the stream that standard filtering method fB
                         misses the majority of. Secondly, achieving a large increase in recall, while maintaining acceptable precision levels, requires more advanced techniques.

The last set of runs in Fig. 4.a presents our main proposed filtering approach, fCE
                        . As shown, a large increase in recall (in the range of 70–83%) was achieved with a slight drop in precision compared to fB
                         and fC
                         filtering techniques. The best run was achieved when using 200 terms for excluding potentially relevant tweets from the negative samples of the trained classifier fCE
                        , i.e., when k=200. Despite the drop in precision, which is about 8%, we consider it acceptable for real-life microblog filtering applications. Regarding the overlap between the classified tweets by this filtering method and 
                           
                              T
                              B
                              *
                           
                         identified by fB
                        , we noticed that 95, 97, and 97% of tweets of 
                           
                              T
                              B
                              *
                           
                         were also identified by fCE
                        (50), fCE
                        (100), and fCE
                        (200), respectively. This means that most identified tweets by fB
                         are also identified by fCE
                        .

In addition to the previous runs, we also tested a variant of fCE
                         in which the classifier is applied only to the tweets identified as relevant by fBE
                         (i.e., the set TBE
                        ), instead of the full tweet stream. In this run, denoted by fCE
                        
                        *(k), we also considered all tweets in the set 
                           
                              T
                              B
                              *
                           
                         as relevant. This run achieved very similar results to fCE
                        (k). Regarding processing time, fCE
                        *(k) classifies much smaller number of tweets than fCE
                        (k). However, the time taken for identifying the selected tweets TBE
                         is actually larger than the classification time by our linear SVM classifier. In all cases, the time required for both techniques is relatively negligible compared to the time elapsed between tweets in a stream. Therefore, we consider both techniques effective and fast enough to keep up with a real-life stream.

As discussed in Section 4, we added a sample of the tweets identified by f
                           B in the 20-hour training period to the judgment pool so that we can estimate the quality of the positive sample (TB
                           ) used for training the classifiers. As expected, we found that the average estimated precision of TB
                            for the loosely-defined topics was 0.67, which is considerably lower than for the tightly-defined topics (0.92). This is clearly due to the abuse of hashtags in non-relevant tweets. Averaging over all scenarios, the estimated precision of TB
                            was 80%.

Since the loosely-defined topics are constructively different from the tightly-defined topics, it is essential to examine how the different approaches performed in either case. Fig. 4.b illustrates the estimated precision (on the left) and relative change in precision and recall of all approaches for the loosely-defined topics (on the middle) and the tightly-defined topics (on the right). The left subfigure shows that precision on the loosely-defined topics is less than tightly-defined ones, which is proportional to the quality of training data used. This indicates the importance of preparing a high quality seed queries. However, regardless of the quality of training data, it was shown for fCE
                            that it was able to always achieve a relatively decent gain in recall with slight or negligible drop in precision. In fact, fCE
                            achieved a 60% gain in recall with negligible drop in precision for the loosely-defined topics despite that it was trained with low quality training data of 0.67 precision. The gain in recall was nearly double (106%) for the tightly-defined topics that got trained with high-quality positive samples.

To measure the performance of our proposed filtering technique, represented by fCE
                           (200), across different topics and over time, Fig. 4.c presents the relative change in estimated precision and recall for each of the topics in each test date individually. The figure indicates that our approach consistently achieves a decent gain in the recall in all our testing cases while exhibiting a slight increase or drop in most of the cases. The gain in recall ranged from 10 (in #EGY-May) to 190% (in SPO-Apr), while the maximum gain in precision was 19% (in #BHR-Mar) and the maximum drop (excluding #BHR-Feb) was −28% (in EGY-May). Only one test point (#BHR-Feb) achieved a dramatic loss in precision (−78%) with small gain in recall (13%). Upon investigation, we realized that the positive training set in that topic was the smallest in size across all testing cases, and that its precision was 0.66, which is relatively low. The low-quality of the sparse training samples might explain this odd performance compared to the rest of testing cases.


                           Table 2
                            reports the estimated number of identified relevant tweets and (in parenthesis) the total classified-as-relevant tweets by both fB
                            and fCE
                           (200). It shows that there is a large difference in the amount of relevant tweets identified by each approach. It also shows that the number of relevant content to a given topic varies a lot over time, depending on the events happening at the time. For example, the last test day for the SPO topic received relevant posts more than ten times of the average. It was noticed that on that day, there was a Champions League match between Barcelona and Bayern Munich, and large amount of posts were talking about the match. The filtering approach proved to be highly effective with detecting more relevant tweets regardless of its amount as long as enough training samples are provided, otherwise, the training window w should be increased.

@&#DISCUSSION@&#

Reported results showed the effectiveness of the proposed filtering approach in retrieving additional large number of relevant results compared to the Boolean filter, while preserving an acceptable precision. Identifying these tweets is a challenge, since they use ambiguous terms or describe relevant temporal events that expire quickly. We try to analyse the reason behind that performance.

The key idea in our filtering technique is the methodology used for selecting effective training data for the classifier in an unsupervised manner, and updating it frequently to maintain high performance with dynamic events in broad topics. The difference in performance between fC
                         and fCE
                         points out the impact of cleaning the negative training samples by excluding tweets containing terms R that are potentially-related to the topic. Moreover, the number of tweets excluded from the negative training sample was found to be only 2.1, 2.9, and 3.7% of the set Trand for fCE
                        (50), fCE
                        (100), and fCE
                        (200), respectively. Surprisingly, this very small difference in the negative training sample for fCE
                         compared to fC
                         resulted in a superior change in performance. This indicates that most of those excluded tweets were actually relevant and thus their exclusion from the training set severely decreased the confusion of the trained classification model and led to less-biased classification decisions.

The aforementioned results confirm that the performance of our filtering technique is consistently effective with different topics, and over long period of time. In our experiments, the same predefined queries Q
                        0 of each topic were used over the 4 months without any manual modification. In real-life, huge changes were occurring to these topics. To analyse the way the filtering technique was working over time, we computed the overlap between the top 200 related terms in R used to clean the negative samples in each of the topics across the 4 test days. We found the average overlap between the related terms sets for one topic from one test day to another is less than 25%. This indicates a large drift in the topics, and shows that tracking broad dynamic topics using fixed queries or hashtags would be insufficient, since these topics are highly dynamic.


                        Table 3
                         presents samples of the related terms R extracted from the TB
                         of the training stream, which were used in the cleaning process of the negative samples. The first samples of terms are those that were extracted in all four test dates. As shown, these terms are usually relevant terms to the topics, but are general enough to match irrelevant topics as well. For example, the terms “Egypt” and “Syria” for the EGY and SYR topics respectively are typically relevant; however, they still can show up in posts related to non-political issues, and hence become non-relevant to the search topics. Similarly for the term “Madrid” for the SPO topic, it can be referring to “Real Madrid” team, and hence become relevant, or referring to the town, and hence become non-relevant. Therefore, our filtering approach excludes tweets containing these terms from the negative training samples to prevent any confusion in the classification model.

The right column of Table 3 presents samples of the terms that appeared in R for one or two test days only. These are the terms that represent 75% of the top 200 related terms in R. These terms typically represent events related to the topics for a short period of time. For examples, the three terms of the EGY topic were found related to three different clash events happened in Egypt between government and opposition parties during February, March, and April. The example terms for SYR topic; “Hizb” and “Allat” refer to “Hizb Allah” the Lebanon armed group that started to fight in Syria starting from April 2013; therefore, these two terms appeared in the test days of April and May. Also the term “Zineb” is a Holy place in Syria that had some battles in April 2013. Similarly for the SPO topic; for example, “Camp-Nou” was the name of the stadium that hosted a popular game in the champions’ league in May 2013. Another interesting feature that was noticed in the R terms was the example {“مورينهو”} in the SPO topic; this is an Arabic transliteration for the name “Mourinho” that is different from the one used in Q
                        0 shown in Table 1. This shows that the R terms capture general related terms, temporally relevant terms, and also different spellings of relevant terms.

The previous illustrative samples of the R terms demonstrate the high adaptability of the filtering approach, which works in a fully unsupervised mode. However, we do not claim that the initial predefined set of queries Q
                        0, especially for tightly-defined topics, does not require manual update forever. We mentioned earlier that Q
                        0 is formed of the most static part of the dynamic topic. Thus it is expected that these static part will change eventually. For example in a political topic, the president and governments get changed, which would require updating to the set of queries. However, our main objective was to minimize the manual updates to the query while having a high-recall high-precision filtering, which we demonstrated in our experiments. Table 4
                        
                        
                         further illustrates the effectiveness of our approach by showing some examples for the relevant identified tweets for topics #EGPY, #SYR, and #BHR that do not contain the query hashtag within their text.

Finally, we claim that the three objectives for the filtering task listed in Section 3 were achieved. The filter fCE
                         successfully achieved significantly higher recall than Boolean filtering methods without large loss in precision, and the approach proved to be self-adapting to the changes occurred to the targeted topics. We hope our proposed filtering approach would be an effective solution for many studies and applications that target following broad topics on social media instead of using the simple Boolean filter that leads to limited retrieved results.

Our adaptive filtering approach is currently implemented in one of the social media news websites for following broad and dynamic topics related to news in different regions in Middle East. TweetMogaz
                        7
                     
                     
                        7
                        New design of the website is available on: http://www.tweetmogaz.com/
                        
                      (Magdy, 2013) is a news portal that is entirely generated from tweets. It is a platform for following the on-going news in the Arabic hot regions, such as Syria, Egypt, Libya, Iraq, Yemen, etc. It uses the posts of users on Twitter as its news source. The website relies on retrieving relevant tweets to each of the different regions in the Middle East; then it uses the identified tweets to generate a comprehensive report about the on-going news in each region and the public response toward it. It also applies hierarchical clustering approach for stories identification and generation within each tracked topic (Elsawy et al., 2014). Fig. 5 presents the high-level block diagrams of the TweetMogaz platform. As shown, our adaptive information filtering technique is the main enabling technology implemented in the backend of TweetMogaz to retrieve relevant tweets to the tracked topics with both high precision and recall. The same configuration in our experimentation above is applied in the platform, where classification models are trained on 20 h of tweets, and they get updated every 4 h, Fig. 6 shows a snapshot of a sample generated news report about Egypt.

Well-defined topics using large number of queries are prepared for each topic as the seeding queries to the filtering technique. No manual update to the query sets was required for more than a year despite the big drifts in the topics itself, which shows the effectiveness and robustness of our approach. However, this does not negate that manual update to the seeding queries can lead to further improvement in the coverage of the topic. This can be demonstrated from our tested topics when comparing the EGY and SYR to #EGY and #SYR, respectively, where it was noticed that the large set of queries used to represent a broad and dynamic topic lead to larger number of retrieved relevant microblogs, both before and after filtering.

The number of collected Arabic tweets per day, which gets digested by TweetMogaz and through our filtering approach, is 12 million tweets on average. The number of tweets that are assigned to each of the topics ranges significantly according to the hot news happening at that time. For examples, the number of tweets that get identified as relevant to Egyptian politics reached more than 0.5 million tweets during the Egyptian presidency elections, while in some days when there is nothing hot happening, this number can be only few thousands. This shows the scalability and efficiency of our filtering approach with large sizes of microblog streams.

In this paper, we studied microblog filtering for broad dynamic topics. Despite the wide usage of this filtering task in many applications using simple Boolean filtering, it has not received enough attention in research communities to develop a more advanced and effective adaptive filtering technique for this type of topics. We provided a definition of the broad dynamic topic and the corresponding filtering task. We proposed an effective filtering technique and compared it with other potential techniques. We developed a test set for the task that contained 6 different topics of different domains and natures, and we used a stream of Arabic tweets as our data stream. We applied our approaches over four test days of the stream in four different months using a fixed predefined queries set Q
                     0 for each topic. Our results showed high quality performance of our filtering approach, which managed to achieve a consistent increase in recall for 24 testing points, while preserving high values of precision. Our extensive analysis to the results showed high consistency over long periods of time and in different topic domains. We analysed the key idea of our approach, which relies on the ability of collecting clean training data in an unsupervised and adaptive manner to train the classifier frequently. Our illustrative examples showed also the effectiveness of our approach with capturing different spellings of terms related to the topic. Although our approach is tested on Arabic topics and microblogs, it is language-independent and general enough to apply on posts and topics of other languages.

As for future directions, we believe that applying our filtering approach to a wider range of topics of different natures and different domains is an essential task to further evaluate the effectiveness of the approach. Communicating with social scientists and institutes that are concerned with public behaviour on social media in general would be a priority for us to put our filtering approach into practice and to test its effectiveness by experts in the tested topics. Moreover, a more exhaustive evaluation to the filtering technique by assessing all the classified data instead of samples would be interesting, especially for experimenting with different time windows to support different types of topics or for conducting failure analysis. Finally, testing different classifiers other than SVM with different features and testing different term selection algorithms besides the simple TF-IDF might affect the performance of classification.

@&#ACKNOWLEDGMENT@&#

This work was made possible by NPRP grant# NPRP 6-1377-1-257 from the Qatar National Research Fund (a member of Qatar Foundation). The statements made herein are solely the responsibility of the authors
                     8
                  
                  
                     8
                     The first author is not funded by the grant.
                  .

@&#REFERENCES@&#


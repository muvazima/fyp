@&#MAIN-TITLE@&#Iterated Tabu Search and Variable Neighborhood Descent for packing unequal circles into a circular container

@&#HIGHLIGHTS@&#


               Highlight
               
                  
                     
                        
                           
                           A high performance algorithm for packing unequal circles into a circular container.


                        
                        
                           
                           A new insert neighborhood is designed to supplement traditional swap neighborhood.


                        
                        
                           
                           An efficient mechanism to employ the insert neighborhood.


                        
                        
                           
                           The algorithm improves or matches all but one records of three benchmark sets.


                        
                        
                           
                           Analyses on which key new features are important and how they work.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Packing

Tabu Search

Variable Neighborhood Descent

Iterated Local Search

@&#ABSTRACT@&#


               
               
                  This paper presents an Iterated Tabu Search and Variable Neighborhood Descent (ITS-VND) algorithm for packing unequal circles into a circular container (PUCC). The algorithm adapts the Tabu Search procedure of Iterated Tabu Search algorithms and proposes a Tabu Search and Variable Neighborhood Descent (TS-VND) procedure. We observe there are strong complementarities between the small circles and the large vacant places, and propose the insert neighborhood to match up the small circles with the large vacant places. Although the insert neighborhood is inefficient and time-consuming, it is an important supplement to the classic swap neighborhood as it could arrange the small circles properly. Predicated on these features, we employ the insert neighborhood only at chosen local minima of the swap neighborhood that shows promise for an improvement. The traditional Tabu Search procedure is then transformed into a hybrid procedure composed of two alternative parts, namely Variable Neighborhood Descent and Tabu Search respectively. Besides this reformed procedure, ITS-VND also incorporates other new features, such as an adaptive evaluation function, a novel method for accelerating the neighborhood exploration, and the “collision accidents” criterion for evaluating how intensively the area near the current solution has been explored. The computational results on three well established benchmark sets show that the proposed algorithm not only has a good discovery capability but also can provide good results within a reasonable time. For a total of 84 benchmark instances, the proposed algorithm improves the best-known results on 23 instances, matches 60, and only misses one.
               
            

@&#INTRODUCTION@&#

In the past decades, the circle packing problem has been an active research issue in the cutting and packing (C&P) problem family. The problem is to place given rigid circles into a container without overlap. The problem is widely encountered in industry and science fields, including areas such as material manufacturing, logistics, wireless communication, architecture layout, and molecular construction analyses (Adickes et al., 2002; Birgin, Martinez, & Ronconi, 2005; Castillo, Kampas, & Pint´er, 2008). As a classic NP-hard problem, it is difficult to obtain exact solutions. So researchers usually resort to heuristic methods. This paper focuses on an important case of it where the shape of the container is circular and the radii of the circles are not uniform, known as the problem of packing unequal circles into a circular container (denoted by PUCC). We describe it formally as follows.

Given a circular container D
                     0 with undetermined radius R, as well as n (
                        
                           n
                           ∈
                           
                              N
                              +
                           
                        
                     ) circles D
                     1, D
                     2, …, Dn
                      with known radii r
                     1, r
                     2, …, rn
                      (r1
                      ≤ r2
                      … ≤ rn
                     ). Let the center of D
                     0 be the origin of the two-dimensional coordinate system and let the coordinate of the center of Di
                      (i∈[1, n]) be (xi, yi
                     ). The problem is to find a feasible (non-overlapping) solution (R, X) with smallest container radius R, where X is a configuration denoted by (x
                     1, y
                     1, …, xi, yi
                     , …, xn, yn
                     ). The objective can be formulated below:

Minimize R, s.t.

                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                x
                                                i
                                             
                                          
                                          2
                                       
                                       +
                                       
                                          
                                             
                                                y
                                                i
                                             
                                          
                                          2
                                       
                                    
                                 
                                 ≤
                                 R
                                 −
                                 
                                    r
                                    i
                                 
                                 ,
                                 
                                 ∀
                                 1
                                 ≤
                                 i
                                 ≤
                                 n
                                 ,
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             (
                                             
                                                x
                                                i
                                             
                                             −
                                             
                                                x
                                                j
                                             
                                             )
                                          
                                          2
                                       
                                       +
                                       
                                          
                                             (
                                             
                                                y
                                                i
                                             
                                             −
                                             
                                                y
                                                j
                                             
                                             )
                                          
                                          2
                                       
                                    
                                 
                                 ≥
                                 
                                    r
                                    i
                                 
                                 +
                                 
                                    r
                                    j
                                 
                                 ,
                                 
                                 ∀
                                 1
                                 ≤
                                 i
                                 <
                                 j
                                 ≤
                                 n
                                 .
                              
                           
                        
                     Formula (1) forbids any overlap between any circle and the container, and formula (2) forbids any overlap between any two circles.
                     
                  

A solution is feasible if it meets the above formulas. An infeasible solution can exist in the intermediate optimization process, and the following potential energy model is used to measure the infeasibility of an infeasible solution (Huang & Xu, 1999):

                        
                           (3)
                           
                              
                                 U
                                 
                                    (
                                    X
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       i
                                       =
                                       0
                                    
                                    
                                       n
                                       −
                                       1
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          j
                                          =
                                          i
                                          +
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          1
                                          2
                                       
                                       
                                          
                                             
                                                O
                                                2
                                             
                                          
                                          
                                             i
                                             j
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     
                     Oij
                      stands for an overlap. When i = 0, Oij
                      is the overlap between the container and circle Dj
                     :

                        
                           (4)
                           
                              
                                 
                                    O
                                    
                                       0
                                       j
                                    
                                 
                                 =
                                 M
                                 a
                                 x
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                   j
                                                
                                             
                                             2
                                          
                                          +
                                          
                                             
                                                
                                                   y
                                                   j
                                                
                                             
                                             2
                                          
                                       
                                    
                                    +
                                    
                                       r
                                       j
                                    
                                    −
                                    R
                                    ,
                                    
                                    0
                                    }
                                 
                                 .
                              
                           
                        
                     When i > 0, Oij
                      is the overlap between circle Di
                      and circle Dj
                     :

                        
                           (5)
                           
                              
                                 
                                    O
                                    
                                       i
                                       j
                                    
                                 
                                 =
                                 M
                                 a
                                 x
                                 
                                    {
                                    
                                       r
                                       i
                                    
                                    +
                                    
                                       r
                                       j
                                    
                                    −
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   x
                                                   i
                                                
                                                −
                                                
                                                   x
                                                   j
                                                
                                                
                                                   )
                                                
                                             
                                             2
                                          
                                          +
                                          
                                             
                                                (
                                                
                                                   y
                                                   i
                                                
                                                −
                                                
                                                   y
                                                   j
                                                
                                                
                                                   )
                                                
                                             
                                             2
                                          
                                       
                                    
                                    ,
                                    
                                    0
                                    }
                                 
                                 .
                              
                           
                        
                     
                  

Previous algorithms which are based on above model fix the container radius on a proper value, and use the potential energy U alone as the evaluation function. However, since there is no way to compare two feasible solutions by U, when the current solution becomes feasible they have to end the process and reduce the container radius. To evaluate the solutions more adaptively, we combine R and U(X) in lexicographical order to form a new evaluation function. When comparing two solutions, we consider one is better than the other only in two conditions: first, the container radius of the former is smaller; second, they have equal container radii but the former has a smaller potential energy. To make the new evaluation function work, we limit the candidate container radii R to some discrete values kv (
                        
                           k
                           ∈
                           
                              N
                              +
                           
                        
                     and v is a predefined small constant like 0.1). When we reach a feasible solution (R, X), we reduce R to the largest kv which cannot make the solution feasible again by LBFGS (Liu & Nocedal, 1989) optimization. For example, for the left solution illustrated in Fig. 1, by setting R = (a + 1)v we can get a feasible solution through LBFGS optimization, but by setting R = av we cannot. So we set k = a and adjust the container radius to av. Similarly the container radius of the right solution is adjusted to (a + 1)v. By this means, even without knowing the final potential energy U of these two solutions, we still can judge the first solution as better by simply comparing their final container radii. This example illustrates how R works in the evaluation function.

Then we can first minimize the evaluation function 〈R, U(X) 〉 iteratively and then further optimize the final solution into a feasible and compact one by using techniques such as SNOPT (Addis, Locatelli, & Schoen, 2008a). Following this approach we propose the Iterated Tabu Search and Variable Neighborhood Descent algorithm (ITS-VND) to minimize 〈R, U(X) 〉. Compared with the existing Iterated Tabu Search algorithms for this problem (Fu, Huang, & Lü, 2013; Huang, Fu, & Xu, 2013; Huang, Zeng, Xu, & Fu, 2012; Ye, Huang, & Lü, 2013), our algorithm has two major new features: a new neighborhood and a mechanism to combine different neighborhoods.

The first new feature is the new neighborhood. Tabu Search (Glover, 1989, 1990) is the basic search engine of Iterated Tabu Search, and how to define moves to construct proper neighborhoods is one of its most important issues. The existing Iterated Tabu Search algorithms for the PUCC problem use the swap moves or the union of the swap and the random relocate moves to construct neighborhoods for their Tabu Search procedures (Huang et al., 2013
                     , 2012; Ye et al., 2013). They have obtained state-of-the-art results recently. However, although the swap moves are powerful, they cannot efficiently handle some occasions. For example, considering the left solution in Fig. 2, one can relieve its infeasibility considerably by placing circle D
                     1 into a vacant place P
                     1 (see the right solution in Fig. 2). But this is difficult to accomplish by swapping two circles or randomly relocating a small circle. To handle this kind of occasions efficiently, we introduce the insert neighborhood. The new neighborhood is developed from the random relocate neighborhood (Huang et al., 2013) and is inspired by the Vacancy Search algorithm for packing equal circles into a square (Huang & Ye, 2010). A solution in the insert neighborhood is formed by picking out a small circle (such as D
                     1 in Fig. 2) from the current solution, and placing it back at a large vacant place (such as P
                     1 in Fig. 2), and further continuously optimizing the resulting solution (The vacant places are calculated beforehand). Comparing with the existing swap and random relocate moves, one can observe that the insert moves can make the best of the complementarities between the small circles and the large vacant places.

The second new feature is the mechanism for efficiently combining swap and insert neighborhoods. The GP-TS algorithm (Huang et al., 2013) uses the relocate neighborhood at all the iterations of Tabu Search to supplement the swap neighborhood. But during our tests we found that although the insert neighborhood is complementary to the swap neighborhood, it is time-consuming and less productive. Based on these features, it is better to not employ the insert neighborhood frequently. So we decide to only use it on certain “key occasions”. How to define these key occasions may influence the efficiency considerably. The powerful local search method Variable Neighborhood Search (VNS) (Mladenović & Hansen, 1997) switches to inefficient neighborhoods only when the efficient neighborhood gets stuck at a local minimum. Inspired by it, we classify the inner iterations of Tabu Search into two types, namely improving iterations and non-improving iterations. If an iteration improves the current best solution, it is an improving iteration; otherwise it is a non-improving iteration. Fig. 3
                      provides an illustration on improving and non-improving iterations. We regard the turning points between the improving iterations and the non-improving iterations as our key occasions and employ the insert neighborhood only at this kind of points. The insert neighborhood is expected to eliminate some of the turning points and increase the number of the improving iterations (See the difference between Figs. 3 and 4
                     ). It can be observed that the turning points are special among all the local minima. If the insert moves improve the current solution at a turning point, they increase the improving iterations immediately. But it does not necessarily occur at other local minima. Hence these turning points are valuable to the insert neighborhood. After employing the insert neighborhood at these turning points, the Tabu Search procedure then is transformed into a hybrid procedure composed of two alternative parts: Variable Neighborhood Descent (it is the simplest version of Variable Neighborhood Search) and Tabu Search. The Variable Neighborhood Descent part roughly corresponds to the improving iterations, and the Tabu Search part roughly corresponds to the oscillation of the non-improving iterations.

Besides the above two features, we also incorporate other new features in the algorithm, including the adaptive evaluation function 〈R, U(X)〉, and the adaptive greedy-redo method for accelerating neighborhoods explorations. In addition, we give a formal definition to vacant degree and vacant points, show analyses to explain which new features are essential, divide the inner iterations of Tabu Search into improving and non-improving ones and based on it give further analysis on how our key new features work. We also define an original conception of collision accident, which is employed to greedily evaluate how intensively ITS-VND has explored the area near the current solution.

The rest of the paper is organized as follows. The related works are discussed in Section 2. Then, Section 3 presents a detailed description on ITS-VND algorithm. Section 4 provides the computational results and Section 5 analyzes some key features of ITS-VND. We conclude the paper in Section 6.

@&#RELATED WORKS@&#

There are many impressive researches for solving the circle packing problems in the literature. In this section, we only focus on the literature for the PUCC problem.

There are two major categories for the approaches, namely construction methods and optimization methods. The construction methods construct good solutions by placing circles one by one according to certain heuristic rules. They can be further classified into two types. The first type of method fixes the container radius and only arranges the positions of the circles during each constructive procedure. The representative works are the Max Hole Degree (MHD) (Huang, Li, Jurkowiak, Li, & Xu, 2003) based algorithms, including the self-look-ahead search strategy (Huang, Li, Akeb, & Li, 2005; Huang, Li, Li, & Xu, 2006), the Pruned-Enriched-Rosenbluth Method (PERM) (Lü & Huang, 2008), the Beam Search algorithm (Akeb, Hifi, & M'Hallah, 2009), etc. The second type of the construction method adaptively adjusts the container radius and center point during their constructive procedures. The representative works are the Best Local Position (BLP) based algorithms (Hifi & M'Hallah, 2004, 2007, 2008; Akeb & Hifi, 2010).

Different from construction methods, optimization methods pay less attention to constructing a good initial solution, but focus on improving the solution iteratively. They also can be classified into two types: the customized optimization methods and the meta-heuristic optimization methods. The differences between the two are fuzzy. Generally, the customized optimization methods use problem oriented rules to optimize solutions greedily. Yet the meta-heuristic optimization methods define solution space and neighborhoods and then explore the solution space according to certain general-purpose framework. The customized optimization methods are often inspired by some physical or human phenomena (Wang, Huang, Zhang, & Xu, 2002), or from a mathematical or physical perspective (Castillo et al., 2008; Liu, Xue, Liu, & Xu, 2009; López & Beasley, 2013). As to the meta-heuristic optimization methods, according to their employed meta-heuristics, they can be further classified into population based algorithms (Addis, Locatelli, & Schoen, 2008b; Grosso, Jamali, Locatelli, & Schoen, 2010), Simulated Annealing based algorithms (Müller, Schneider, & Schömer, 2009; Zhang & Deng, 2005), Tabu Search based algorithms (Huang et al., 2013; Ye et al., 2013; Zhang & Deng, 2005), Iterated Local Search based algorithms (Huang et al., 2012; Ye et al., 2013), etc.

Our algorithm belongs to the meta-heuristic optimization methods. Recently there are three milestones for the meta-heuristic optimization methods. The first one is the introduction of the swap moves. In a famous contest (www.recmath.org/contest/CirclePacking), Addis et al. (2008b) proposed a high performance neighborhood structure which is formed by swapping two similar circles and then continuously optimizing the resulting solution. They incorporated the neighborhood into a population based algorithm and won the first place of the contest. The second milestone is a Simulated Annealing based algorithm. After the contest, Müller et al. (2009) presented a Simulated Annealing based algorithm for the problem. They used an original hybrid evaluation function and exploit swap, shift, and jump as the basic moves in neighborhood construction. Their algorithm got state-of-the-art results by improving or matching all the records of the contest. Their new records had not been further improved for several years. The third milestone is the introduction of the swap neighborhood based Tabu Search, it is majorly contributed by Huang et al. (2013) and Fu (2011). Based on their work, several new algorithms have been proposed (Huang et al., 2012, 2013; Ye et al., 2013) and have improved many previous best results.
                     
                  

There are still many important works which are not mentioned here. Interested readers can find comprehensive overviews of this area in (Castillo et al., 2008; Hifi & M'Hallah, 2009).

There are three phases in the proposed algorithm ITS-VND (Iterated Tabu Search and Variable Neighborhood Descent): continuous optimization, intensification (local search), and diversification (perturbation). In the continuous optimization phase, we use a LBFGS (Liu & Nocedal, 1989) based method to continuously optimize a solution into its corresponding local minimum. In the intensification phase, based on the search space defined by all the continuous local minima, we use the Tabu Search and Variable Neighborhood Descent (TS-VND) procedure to perform intensive exploration. In the diversification phase, a random reset perturbation strategy is employed to diversify the exploration of TS-VND. The proposed ITS-VND algorithm is constructed by integrating these three phases together in a hierarchical mode. Each phase is called by its higher level phase iteratively. The framework of the proposed algorithm is shown in Fig. 5. In the following sections, we will discuss these three phases in a bottom-up order.

The continuous optimization phase corresponds to the lowest level in Fig. 5. The objective of this phase is to reduce the search space and simplify the problem into a pure discrete optimization problem for the other phases. It maps an input solution to its corresponding continuous local minimum. As shown in Fig. 6, all the solutions in a same valley of the search space will be mapped to the same continuous local minimum (the bottom of the valley). Only these continuous local minima are visible to the other phases. This phase is employed to do the mapping as soon as a new solution is generated (i.e., after a swap or insert move). The continuous optimization method used in this phase is based on LBFGS and is called BS-LBFGS (Binary search augmented LBFGS). BS-LBFGS first uses LBFGS to continuously optimize the input solution. If the result is infeasible, it returns the result as the corresponding continuous local minimum. Otherwise it uses binary search to find the largest container radius R which cannot lead to a feasible solution again through LBFGS optimization (As discussed in Section 1, the candidate container radii are limited to some discrete values kv). Notice that the container radius is fixed during LBFGS and it only adjusts the positions of the circles (i.e. the configuration X).

As depicted in Algorithm 1
                        , the continuous optimization phase includes two steps. At the first step it uses LBFGS to continuously minimize the potential energy U of the input solution under a fixed R. If the obtained solution is infeasible, it returns the result as the continuous local minimum. Otherwise, it goes to the second step and uses binary search to reduce the container radius to the largest permitted value which cannot make the solution feasible through LBFGS optimization (e.g., the radius of the inner circular containers of the two solutions in Fig. 1). Fig. 7
                         gives an example on BS-LBFGS optimization. BS-LBFGS usually involves just one LBFGS call; the second step is seldom triggered.

The intensification phase corresponds to the middle layer in Fig. 5. In the intensification phase, a hybrid local search procedure is employed to intensively explore a local area in the reduced search space. Existing Iterated Local search algorithms for this problem only employ Tabu Search procedure (Huang et al., 2012, 2013; Ye et al., 2013) in the intensification phase. To enhance the search efficiency of the intensification phase, we introduce the insert neighborhood and propose a TS-VND (Tabu Search and Variable Neighborhood Descent) procedure. The TS-VND procedure uses Variable Neighborhood Descent and Tabu Search alternatively. In the following sections, we first introduce the two neighborhoods and the method for accelerating their exploration. Then we describe the Variable Neighborhood Descent subroutine and the Tabu Search subroutine respectively. Finally, we combine the two subroutines together and propose the TS-VND procedure.

Neighborhood definition is critical to local search algorithms. Generally speaking, the neighborhood of the current solution is defined by all the solutions it can reach by performing one of the predefined moves. According to the moves defined, one can construct different neighborhoods. In the proposed Tabu Search and Variable Neighborhood Descent (TS-VND) procedure, we employ two neighborhoods formed by swapping two swappable circles (Addis et al., 2008b) or placing a small circle at a large vacant point respectively. We call them the swap neighborhood and the insert neighborhood.


                           The swap neighborhood. The swap neighborhood was first proposed by Addis et al. (2008b). Huang et al. (2013), and Fu (2011) incorporated it into Tabu Search. A solution in the swap neighborhood is formed by swapping two swappable circles of the current solution and then continuously optimizing the result. Addis et al. (2008b) also limit the swappable circle pairs to similar ones to reduce the neighborhood. In our implementation, we use BS-LBFGS (Section 3.1) to perform continuous optimization, and define the swappable relationship in the following:

                              
                                 (6)
                                 
                                    
                                       S
                                       w
                                       a
                                       p
                                       p
                                       a
                                       b
                                       l
                                       e
                                       P
                                       a
                                       i
                                       r
                                       s
                                       =
                                       {
                                       
                                          (
                                          
                                             
                                                D
                                                i
                                             
                                             ,
                                             
                                                D
                                                j
                                             
                                          
                                          )
                                       
                                       |
                                       
                                          (
                                          
                                             r
                                             i
                                          
                                          <
                                          
                                             r
                                             j
                                          
                                          )
                                          ∧
                                          (
                                          ∀
                                          k
                                          
                                          
                                          
                                             r
                                             i
                                          
                                          <
                                          
                                             r
                                             k
                                          
                                          →
                                          
                                             r
                                             j
                                          
                                          ≤
                                          
                                             r
                                             k
                                          
                                          )
                                       
                                       }
                                       
                                       .
                                    
                                 
                              
                           All the circles are divided into several sets by their radii (as shown in Fig. 8
                           ); all the circles in a same set have the same radius. Two circles in a same set are not swappable, since swapping their positions will not change the solution. Two circles are swappable if and only if they are in neighboring sets. For example, if n = 4, and the radii of the circles are r
                           1 = 10, r
                           2 = r
                           3 = 25, r
                           4 = 26, then SwappablePairs = {(D
                           1, D
                           2), (D
                           1, D
                           3), (D
                           2, D
                           4), (D
                           3, D
                           4)}.


                           The insert neighborhood. 
                           Huang et al. (2013) propose the relocate neighborhood in their Tabu Search procedure. A solution in the relocate neighborhood is formed by picking out a small circle from the current solution, and randomly relocating it in the container, and then performing continuous optimization. In our research, however, we observed that placing the small circle in a large vacant place may be more promising than just randomly relocating it, so we reform the relocate neighborhood and propose the insert neighborhood. The reformation is inspired by the Vacancy Search algorithm (Huang & Ye, 2010) for packing equal circles in a square. The Vacancy Search algorithm uniformly places 2n probation circles with the same size as the packing circles to find the current largest “vacancy”, and places an arbitrary packing circle into it to construct a neighbor solution. Their algorithm got excellent results for packing equal circles into a square. Notice that their conception “vacancy” is intuitive, they did not give a formal definition to it.

To explain our insert neighborhood, we first present the conception “Vacant Degree” (VD). The VD of a point P is used to evaluate the unoccupied area around the point. It is the minimal distance between P and all the circles or container.


                           
                              Definition 1
                              
                                 Vacant Degree. The vacant degree of a given point P = (xp, yp
                                 ) inside the container is:

                                    
                                       (7)
                                       
                                          
                                             
                                                VD
                                                
                                                   (
                                                   P
                                                   )
                                                
                                                =
                                                min
                                                {
                                                D
                                                i
                                                s
                                                (
                                                P
                                                ,
                                             
                                             
                                                D
                                                i
                                             
                                             
                                                
                                                   )
                                                   |
                                                
                                                i
                                                ∈
                                                [
                                                0
                                                ,
                                                
                                                n
                                                
                                                   ]
                                                   }
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              


                           
                              Definition 2
                              
                                 Vacant Point. A Vacant Point is a point within the container having the local maximum 〈VD(P), xp, yp
                                 〉.

As illustrated in Fig. 9, the radii of the dotted circles are the vacant degrees of points P
                           1, P
                           2 and P
                           3, where P
                           2 and P
                           3 are vacant points.

Without loss of generality, let the circles be numbered in non-descending order according to their radii. Then a solution in the insert neighborhood is formed by picking a small circle Dk
                            (1 ≤ k ≤ n/3) out of the current solution, and placing it back at one of the n/3 largest Vacant Points, then continuously optimizing the result by BS-LBFGS. To limit the size of the insert neighborhood, the chosen limit n/3 is independent on the radial distribution. There may be many circles which have the same radius as r[n/3], but only those numbered no greater than n/3 are regarded as small circles. We use a lattices covering method to find the large Vacant Points approximately. We divide the square area {(x, y)|–R ≤ x ≤ R, –R ≤ y ≤ R} into 
                              
                                 4
                                 
                                    
                                       ⌊
                                       
                                          n
                                       
                                       ⌋
                                    
                                    2
                                 
                              
                            lattices evenly. Each time we place a movable probation circle CP
                            with radius 
                              
                                 R
                                 
                                    
                                       2
                                    
                                    
                                       ⌊
                                       
                                          n
                                       
                                       ⌋
                                    
                                 
                              
                            at the center of one of these lattices, and fix all the other circles, then use LBFGS to move this circle (Fig. 10
                           ). We regard the final center of the probation circle as an approximate Vacant Point. The negative potential energy of the probation circle (–U(CP
                           )) is used to greedily evaluate the Vacant Degree of this Vacant Point. After probing all the lattices, we eliminate repetitions and choose the n/3 points that have the largest Vacant Degrees. Since only the probation circle is movable during the probation process, probing a Vacant Point is much faster than exploring a neighborhood solution.

An example of the insert move can be found in Fig. 2. In the left solution, we find a large vacant point P
                           1. We then place the center of a small circle D
                           1 there and further continuously optimize the solution to obtain a neighbor solution (the right solution in Fig. 2). One could observe that there are some complementarities between the two neighborhoods: the insert moves can make certain improvements which are difficult to achieve by the swap moves. So when the swap moves get stuck, the insert moves may be able to provide a further improvement.

We only use the small circles and the large vacant points to construct this neighborhood, as a small circle and a large vacant point can fit each other better and only add a little infeasibility to the solution. Thereafter, the following continuous optimization only needs to adjust the solution slightly and hence the final result can inherit most features of the current solution. In fact, during our tests we have found that limiting the insert circles to small ones and the objective places to large vacant points are both important.

To accelerate the neighborhood exploration in a practicable and adaptive way, we reform Fu's acceleration technique used in the Quasi-physical process (2011) and provide an Adaptive Greedy-Redo acceleration method.

After a swap or insert move, we need to use the continuous optimizer (BS-LBFGS) to get a neighbor solution, but the process is time-consuming. At each of its iterations, LBFGS needs to find all the circle pairs that have mutual overlaps. Since after a few iterations, the whole configuration becomes stable and the positions of the circles only changes slightly afterwards, it is unnecessary to search all the circle pairs and check their overlaps. We only need to check the circle pairs that were already “close enough” at a certain iteration t. We use the following formulas to judge whether two circles are already close enough.

Two circles Di
                            and Dj
                            (i, j > 0) are regarded as close enough to each other if and only if:

                              
                                 (8)
                                 
                                    
                                       D
                                       i
                                       s
                                       
                                          (
                                          i
                                          ,
                                          j
                                          )
                                       
                                       <
                                       Max
                                       
                                          {
                                          
                                             
                                                (
                                                
                                                   r
                                                   i
                                                
                                                +
                                                
                                                   r
                                                   j
                                                
                                                )
                                             
                                             2
                                          
                                          ,
                                          
                                          
                                             
                                                r
                                                n
                                             
                                             4
                                          
                                          }
                                       
                                       .
                                    
                                 
                              
                           
                           Dis(i, j) is the distance between Di
                            and Dj
                            (see Fig 11
                           ), and rn
                            is the radius of the largest circle.

Circle Di
                            (i > 0) and the circular container are regarded as close enough to each other if and only if:

                              
                                 (9)
                                 
                                    
                                       D
                                       i
                                       s
                                       
                                          (
                                          
                                             i
                                             ,
                                             
                                             0
                                          
                                          )
                                       
                                       <
                                       Max
                                       
                                          {
                                          
                                             
                                                r
                                                i
                                             
                                             2
                                          
                                          ,
                                          
                                             
                                                r
                                                n
                                             
                                             8
                                          
                                          }
                                       
                                       .
                                    
                                 
                              
                           
                           Dis(i, 0) is the distance between circle i and the container.

The two formulas give empirical thresholds that incorporate two aspects of considerations. One is the local stability factor – the average radius of the two circles. The other is the global stability factor – the radius of the largest circle (Circle Dn
                           ).

By calculating the “close enough” relationship at a selected iteration t and limiting the distances calculations afterwards within the “close enough” circle pairs, we can accelerate the computation considerably. This greedy method is inspired by Fu's work in Quasi-physical optimization (Fu, 2011), and we reform his formulas by incorporating the global stability factor.

In practice, this greedy method occasionally leads to wrong results. Fu's method checks and fixes the mistakes every time 50 inner iterations of the Quasi-physical optimization have passed. But it is not applicable to the LBFGS optimization. Instead, we check the result only when LBFGS returns, if it is not correct, we redo the LBFGS optimization without using the greedy method to ensure correctness. We also adjust parameter t dynamically to make a tradeoff between redo ratio and computational speed.


                           Fu (2011) set the parameter t at a fixed value 20 in his algorithm. But we found that the configuration stability is strongly dependent on problem cases and the employed neighborhood, so it is not efficient to calculate out the “close enough” relationship at the same iteration time t in all the situations. So we further propose a binary-search-based method to adjust t adaptively according to the current redo ratio. More specifically, when the local search procedure for a specific problem instance I with a specific neighborhood N is first launched, we set the corresponding tIN
                            = 1, lower bound LBIN
                            = 1, upper bound UBIN
                            = + ∞ (in practice, + ∞ is represented by the largest value that computer can express). Each time an iteration of the local search procedure has been performed, we evaluate the current redo ratio. If it is above 10%, LBIN
                            is set at tIN
                            + 1 and tIN
                            is set at min{2 × tIN
                           , (UBIN
                            + LBIN
                           )/2}. If it is below 5%, UBIN
                            is set at tIN
                            – 1, and tIN
                            is set at (LBIN
                            + UBIN
                           )/2. The adjust process stops when UBIN
                            < LBIN
                            or current redo ratio falls between 5% and 10%. At first, tIN
                            will increase quickly (multiplied by 2 repeatedly). As soon as the redo ratio falls below 5%, which means we have found a proper UBIN
                            to replace + ∞, then the process will act exactly the same way as traditional binary search.

Variable Neighborhood Search (Mladenović & Hansen, 1997) is a powerful local search method that uses the complementarities among different neighborhoods to provide better search results. It has been applied into many important optimization problems (Polat, Kalayci, Kulak, & Günther, 2015; Xiao, Zhang, Zhao, Kaku, & Xu, 2014; etc.). Here we use the simplest version of it, i.e., the Variable Neighborhood Descent algorithm (VND) (Hansen & Mladenović, 2003). The algorithm first uses the classic Best Improvement Search (also called Steepest Descent Search) with the most efficient neighborhood. The Best Improvement Search chooses the best solution from current solution's neighbor solutions to replace it repeatedly until no improvement is possible. When the Best Improvement Search gets stuck, it returns the best solution it has found. The VND process then resorts to other optional neighborhoods one by one to seek a further improvement. As soon as a further improvement has been obtained, it switches back to the initial neighborhood immediately. According to our test, the swap neighborhood is much more efficient than the insert neighborhood. So in our implementation, we use the swap neighborhood as the initial neighborhood, and use the insert neighborhood as the supplement. We denote the swap neighborhood as NS, the insert neighborhood as NI, and the VND subroutine is as shown in Algorithm 2
                           , which roughly corresponds to the improving iterations in Fig. 4.
                        

Tabu Search (Glover, 1989, 1990) is a famous and widely used meta-heuristic algorithm. It enhances the performance of Best Improvement Search and First Improvement Search by allowing them to choose a slightly worse neighbor when they get stuck, and forbidding certain solutions to be chosen to avoid endless loops. When gets stuck at a local minimum, the algorithm efficiently oscillates to nearby local minima one by one to find a further improvement. Tabu Search has been proved to be quite useful in different kinds of applications (Glover, Ye, Punnen, & Kochenberger, 2015; Kothari & Ghosh, 2013; Nguyen, Crainic, & Toulouse, 2013; etc.). Recently, it has been used as the local search procedure of Iterated Local search (Lourenco, Martin, & Stützle, 2003) to form the Iterated Tabu Search algorithm. Iterated Tabu Search has provided great results for many problems (Fu et al., 2013; Lü & Hao, 2010, 2012; Ye et al., 2013; etc.).

Our Tabu Search (TS) subroutine only employs the swap neighborhood. When a solution in the swap neighborhood is chosen as the current solution, the swap move which leads to it is marked as tabued and is forbidden to be chosen again in the following δ iterations (δ is the Tabu tenure, we set it at n / 5 + rand(0, 10) empirically). But the tabu status of a move is ignored if it leads to a solution better than the current best solution. At each iteration of the Tabu Search, we choose the best move from the not tabued moves to construct a solution to replace the current solution. The Tabu Search procedure stops in two conditions: first, when it cannot obtain an improvement within a given number of iterations (we call this number TS depth and set it at 10n empirically); Second, whenever it obtains an improvement (i.e., reaches a solution better the current best solution). Fig. 12
                            illustrated the two return conditions of the TS subroutine. Notice that traditional Tabu Searches only stop under the first condition. The Tabu Search subroutine roughly corresponds to the oscillations of non-improving iterations in Fig. 4. The pseudo code of the TS subroutine is provided in Algorithm 3
                            below.

The TS-VND (Tabu Search and Variable Neighborhood Descent) procedure exploits the VND subroutine and the Tabu Search (TS) subroutine alternatively until no improvements can be obtained. The pseudocode of TS-VND is listed in Algorithm 4.

@&#DISCUSSIONS@&#

In general, the number of solutions in the insert neighborhood is much larger than the number of solutions in the swap neighborhood (when circles are all different, it is O(n
                           2) vs. O(n)), and the adaptive Greedy-redo method acts less efficiently with insert moves than with swap moves. This makes the exploration of the insert neighborhood quite expensive. Furthermore, during our tests, we found that the insert neighborhood is much less productive, and Tabu Search cannot enhance its performance significantly. Basing on these considerations, we should not employ the insert neighborhood frequently. So it is reasonable to only use it on certain “key occasions”. Hence in our algorithm, we employ it only when the Best Improvement Search of the swap neighborhood gets stuck. i.e., the turning points in Fig. 3. In fact, we have tried many other combinations, such as using the union of the insert neighborhood and the swap neighborhood as a single neighborhood, but none of them could provide better results.

In this section, we introduce the diversification phase and integrate all the three phases together to form the final ITS-VND algorithm. The diversification phase corresponds to the highest layer in Fig. 5. It uses a random reset perturbation to diversify the exploration of TS-VND. The Iterated Tabu Search and Variable Neighborhood Descent algorithm are formed by integrating this phase and the above phases together in a hierarchical way. Briefly speaking, the ITS-VND algorithm iteratively perturbs the current best solution and then uses TS-VND to optimize the result to seek improvements. There are five key issues in the ITS-VND algorithm, namely perturbation (the key part of the diversification phase), local search (intensification phase), acceptance criterion, iteration stop criterion, and the return value. We have discussed the local search procedure above (TS-VND), and we continue to discuss the other four issues sequentially below. The pseudo-code of the whole ITS-VND algorithm is added in the end.
                     


                        Perturbation strategy. Perturbation operation is the key part of the diversification phase. It is used to diversify the exploration of the intensification (local search) phase. It uses random or guided moves to partly change the current solution and hence leads the local search procedure to explore other nearby promising areas. The number of elements involved in the perturbation is called perturbation strength. Huang et al. (2012) set the perturbation strength at a fixed value of n/10. At each iteration, their algorithm chooses n/10 circles according to the Critical Element Guided strategy (Lü & Hao, 2009) and randomly reset them within the container. Ye et al. (2013) developed the random reset perturbation strategy by choosing the perturbation circles randomly and making the perturbation strength variable. They determine a fixed interval beforehand and randomly choose the perturbation strength from the interval at each iteration. Their strategy obtains state-of-the-art results for utilizing the complementarities among different perturbation strength. We follow their strategy and set the interval of perturbation strength as [1, n/6].


                        Acceptance criterion. At the end of each iteration, ITS-VND should decide whether to accept the resulting solution. In ITS-VND, the resulting solution is accepted only if it is better than the current solution.


                        Stop criterion. 
                        Huang et al. (2012, 2013) ends the ITS process when a time limit is reached. Ye et al. (2013) predefines a parameter PerturbDepth, and ends the iterations of ITS when no improvements have occurred during the last PerturbDepth iterations. Rather than ending the process according to empirical parameters, we think it should be based on how thoroughly the area near the best solution (i.e., the current solution) has been explored. And to evaluate it reasonably, we introduce a conception “collision accident”. A collision accident means: after perturbing the current solution and using TS-VND to process it, we get a solution same as the initial current solution (i.e., hit the current solution). It is reasonable to think that there is a strong relationship between the times the current solution has been hit and the probability for other good solutions near it also has been hit. So it is reasonable to use “collision accidents” to evaluate how thoroughly the area near the best solution has been explored. (Since there are some trivial circles which do not play any role in some instances (Addis et al., 2008b), it is not necessary to require all the corresponding circles in the same place when judging whether two solutions are identical. As a greedy measure, we only consider the evaluation function values in the judgment.)


                        Return value. When the ITS-VND process ends, it returns the best solution it has found.


                        ITS-VND algorithm. Now we can form the ITS-VND algorithm for packing unequal circles into a circular container by integrating the phases presented in the preceding sections. At each iteration, ITS-VND perturbs the current solution with a perturbation strength randomly chosen from interval [1, n/6], then call TS-VND to improve the perturbed solution. If the result of TS-VND is better than the current solution, it is accepted to update the current solution. The process ends when the collision accidents have occurred for CollisionLimit times. CollisionLimit is an empirical parameter, we set it at 50. The pseudocode of ITS-VND is listed in Algorithm 5.

This section provides an idea of the computational effort for different parts of the algorithm, including the BS-LBFGS procedure, the swap iteration, the insert iteration, and the Tabu Search subroutine.
                     


                        BS-LBFGS procedure. BS-LBFGS procedure lies in the lowest layer of the algorithm (See Fig. 5) and it is called every time a move (insert, swap) of the higher layers has been performed. So BS-LBFGS is performed as frequently as all the other moves are. Comparing with those moves, BS-LBFGS process is far more time-consuming. Its major part LBFGS often involves hundreds of iterations and each iteration involves n
                        *(n−1)/2 distance calculations. Hence the computational effort for a module in the higher layers mainly depends on the number of BS-LBFGS calls it includes. Let the average computational time for a BS-LBFGS process be τ, we analyze the computational complexity of the other modules accordingly.


                        Swap iteration. Since a swap iteration involves O(n) to O(n
                        2) swap moves (depending on the radial distribution of the circles) and hence includes O(n) to O(n
                        2) BS-LBFGS calls, so the time complexity of a swap iteration varies from O(n*τ) to O(n
                        2
                        *
                        τ).


                        Insert iteration. The computational effort for an insert iteration includes two parts: probing the vacant places and exploring the insert neighborhood.

                           
                              (1)
                              For the first part, it involves 4n probations, and consequently 4n BS-LBFGS calls. During the probing process, only the probation circle is movable. So rather than calculating distances between any two circles, we just need to calculate the distances involving this probation circle. So during the probation process, the computational cost for a BS-LBFGS call is decreased from O(τ) to O(τ/n). Hence the computational complexity of the probation process is O(n
                                 *
                                 τ/n) = O(τ).

For the second part of the insert iteration, it involves n
                                 2/3 insert moves, and hence n
                                 2/3 BS-LBFGS calls. So the computational complexity for exploring the insert neighborhood is O(n
                                 2
                                 *
                                 τ).

Altogether the computational complexity of the insert iteration is O(n
                        2
                        *
                        τ).


                        Tabu Search subroutine. Tabu Search subroutine can involve up to 10n swap iterations (recall that 10n is the TS depth, refer to Section 3.2.4, Paragraph 2). Hence the upper bound of the computational effort for it varies from O(n
                        2
                        *
                        τ) to O(n
                        3
                        *
                        τ), which is larger than that of an insert iteration. So when the Best Improvement Search gets stuck, we first resort to an insert iteration. On the other hand, since the insert iterations are only employed at the turning points, and according to our experiments, these turning points seldom occur (see Section 5, compare the number of turning points in Fig. 15 and the number of improving iterations in Fig. 14). So adding the insert iterations does not increase total computational effort substantially.

To assess the efficiency of ITS-VND, we implemented it in Visual C++ language and performed two experiments. The computers we used to run the experiments are two PCs each with an AMD FX 8350 CPU (8 cores, 4 GHZ), 4GB RAM. The operation system is windows 7, 32bit. All the results were obtained without special tuning of the parameters. The record results of these experiments are published on www.packomania.com by Eckard Specht (2014). He also further optimized our originally obtained results (See the difference between our results here and the results published online).

The first experiment aims to evaluate the “discovery capability” (Grosso, Locatelli, & Schoen, 2007) of our algorithm, i.e., the ability to find the best possible results. We use the benchmarks of a famous contest (www.recmath.org/contest/CirclePacking), which 155 groups from 32 countries took part in. The contest did not limit the computational resources for participants and only counted their best results. The radii of circles to be packed in are ri
                      = i (1 ≤ i ≤ n). We run our algorithm on each instance for multiple times and choose the best result. We compared our best results with the best-known records before us, the contest records, and the best results of three state-of-the-art algorithms: PBH (Addis et al., 2008b), SA (Müller et al., 2009), and ITS-PUCC (Ye et al., 2013). The best known results of n = 30 and n = 32 were provided by Fu and Huang (Specht, 2012). The experimental results are listed in Table 1. The last column is the difference between our results and the best known results. Our radii values which are better than the best-known results are in bold. The ITS-PUCC results for n = 35 and n = 41(which are marked with*) were first found by an earlier version of our algorithm, and then matched by Ye et al. (2013) (the updating time can be retrieved at www.packomania.com (Specht, 2012)). So we do not use their values as the corresponding best-known results for these two instances. Table 1 only lists the results for n > 25, but we also matched the best known results for the smaller instances. Notice that all the algorithms we compared with focus on finding high quality results and do not report their computational statistics. Table 2
                      provides the average radii obtained by each algorithm. From it one can observe that our algorithm has obtained notably better results on the average.

For the total of 46 instances of this benchmark set, our algorithm is able to find 12 results better than the current best-known records and match another 33, only miss one of them. And this suggests ITS-VND has a good discovery capability.

The second experiment aims to evaluate the efficiency of ITS-VND under a reasonable time limit. We use two sets of benchmarks in this experiment. The first set was proposed by
Castillo et al. (2008). In this benchmark set, the radii of the circles are set as ri
                      = i
                     –1/2 (1 ≤ i ≤ n). The second set was proposed by Huang et al. (2006), which is called the NR benchmarks. For each instance, we run our algorithm under a time limit of 10,000 seconds for 10 times (totally around 30 hours) and choose the best result. The total time limit of around 30 hours is typical for evaluating the efficiency of circle packing algorithms (Akeb, Hifi, & Negre, 2011; Fu et al., 2013; Ye et al., 2013). Each instance is calculated on one of the two computers, occupying only one of its eight CPU cores. During run time, the algorithm sometimes ended before it reached the time limitation (10,000 seconds). When this happened, we simply restarted the algorithm.

For the first set of benchmarks, we compare our results with the best results of three state-of-the-art algorithms: Math Optimizer pro (Castillo et al., 2008), TS/NP (Al-Mudahka, Hifi, & M'Hallah, 2011), and GP-TS (Fu, 2011; Huang et al., 2013) respectively. For the second set of benchmarks, we compare our results with the best results of five state-of-the-art algorithms: A1.5 algorithm (Huang et al., 2006), Beam search (Akeb et al., 2009), Algorithm 2 (Akeb et al., 2010), GP-TS (Fu, 2011; Huang et al., 2013) and ITS-PUCC (Ye et al., 2013) respectively. The experimental results are listed in Tables 3–6
                     
                     
                     
                     , with radii values that are better than the others' in bold. Some of our results were further improved by us after running ITS-VND under relaxed time limits; see www.packomania.com (Specht, 2014).

The experimental results show that ITS-VND improved or matched all the best known results of the two benchmark sets. And this suggests it is competitive in providing good results within reasonable time.

From the above two experiments it can be observed that the proposed algorithm is competitive both in discovery capability and providing good results within a reasonable time. For the three sets of well-established benchmarks with a total of 84 best known results, our algorithm improved 23, matched 60, and only missed one of them.

The objective of this section is two-fold: figuring out which key new features of ITS-VND are important, and analyzing how the key new features work. For the first purpose, we perform two experiments to figure out whether it is important to employ the new neighborhood at the turning points, and whether it is value-added to introduce the insert neighborhood. For the second purpose, we investigate the differences in improving iterations and turning points to explain how the key new features work.
                  

To evaluate whether it is important to employ the insert neighborhood at the turning points, we perform the third experiment. In this experiment, we compare ITS-VND with two other ITS based algorithms. The first algorithm transforms ITS-VND by removing all the insert iterations from the local search phase, denoted by ITS(swap). The second algorithm transforms ITS-VND by using the insert neighborhood at all the iterations of the local search phase to improve its current best solution, denoted by ITS(hybrid). Other settings of the three algorithms, such as TS depth, tenure of Tabu, adaptive greedy redo method, et al., are all the same. All the algorithms are implemented in Visual C++ language, and are tested on the relative large (n ≥ 30) instances of the contest's benchmarks and the NR benchmarks under a time limit of 30 minutes. We did not use the ri
                      = i
                     –1/2 benchmark set, because there are very few large instances. Fig. 13 shows the average packing densities obtained by each algorithm over 50 independent runs. After the experiment, we performed a 99% confidence t-test to compare ITS-VND with ITS(swap) and ITS(hybrid). We found that for 25 (respectively 26) out of the 26 instances, the difference of the computational results obtained by ITS-VND and ITS(swap) (respectively ITS(hybrid)) is statistically significant. These results suggest that it is important to employ the insert neighborhood at the turning points. It also suggests that the mechanism to employ the insert neighborhood is important; simply combining it with the swap neighborhood at each iteration can even decrease the performance (as shown by the differences between the green lines and the blue lines in Fig 13).

To further evaluate the proposed insert neighborhood, we perform the fourth experiment. The objective of this experiment is to find out whether using the insert neighborhood is more efficient than using the relocate neighborhood. For this purpose, we propose a new algorithm and compare its performance with the original ITS-VND algorithm. The compared algorithm simply replaces the insert moves in ITS-VND by randomly relocate moves (Huang et al., 2013). The instances used in this experiment are the five largest instances of NR benchmarks and the five largest instances of the contest benchmarks. The two algorithms were executed on each instance for 50 independent runs. The experimental protocol is same as that of the third experiment. The results in average packing densities are listed in Table 7
                     . Here it can be observed that ITS-VND has provided better results for all the instances. And this suggests the new neighborhood is value-added. It may also be observed that the difference of the results obtained by ITS-VND and ITS(relocate) are less significant in the contest benchmarks. Addis et al. (2008b) pointed out that there are considerable trivial circles which do not play any role and often are “rattlers” in the instances of this benchmark set. We further think that these trivial circles may divide the large vacant places into useless small pieces and hence decrease the performance of the insert moves. In fact, we have further performed the same kind of experiment on this benchmark set after removing the n/4 smallest circles of each instance. The difference of the results obtained by ITS-VND and ITS-VND(relocate) then becomes much more significant, which supports our conjecture. It is possible that removing the trivial circles beforehand will help ITS-VND to provide even better results on this benchmark set. However, our objective is to design a robust algorithm which can solve efficiently a large panel of instances.

To figure out how the key new features of the algorithm work, we performed the fifth experiment. For that purpose, we investigate the number of improving iterations and turning points provided by the local search procedures with and without the insert neighborhood (TS-VND of ITS-VND and TS of ITS(swap) respectively). The instances used in this experiment are same as the third experiment. If an iteration of a local search process improves the current best solution, it is called an improving iteration. Otherwise, it is a non-improving iteration. And the turning points are the demarcation points between the improving iterations and the non-improving iterations (As shown in Fig. 3). Our employment of the insert neighborhood is based on following intuition: the insert neighborhood is complementary to the swap neighborhood, when swap moves get stuck, switch to insert moves will help the local search procedure to get a further improvement. If it is the case, TS-VND procedure will be able to provide more improving iterations. In this experiment, the local search procedure with and without employing the insert neighborhood are executed on each instance for 50 independent runs. The average improving iterations provided by each procedure and its swap neighborhood are recorded (Notice that all the improving iteration of TS are provided by the swap neighborhood). The results are listed in Fig. 14
                     . The blue lines correspond to the average improving iterations obtained by the Tabu Search procedure only using the swap neighborhood (TS), the green lines correspond to the average improving iterations obtained by the swap neighborhood of TS-VND, and the red lines correspond to the average improving iterations obtained by TS-VND totally. It can be observed that on nearly all the instances (except for NR_40), the improving iterations obtained by TS-VND are significantly more than those obtained by TS. On quite a few instances, the insert neighborhood not only contributes considerable improving iterations, but also helps the swap neighborhood to provide more improving iterations (see the differences between the green lines and the blue lines in Fig 14.). Fig. 15
                      also shows the average turning points provided by TS-VND (the red lines) and TS (the blue lines). It can be observed that the employment of the insert neighborhood has eliminated considerable turning points in most instances. The experimental results support our intuition about how the key new features of ITS-VND work: they increase the improving iterations of the local search procedure and eliminate some of its turning points.

@&#CONCLUSIONS@&#

This paper has presented an algorithm for packing unequal circles into a circular container (PUCC), called Iterated Tabu Search and Variable Neighborhood Descent (ITS-VND). The algorithm achieved a very good performance on three well-established benchmark sets with a total of 84 instances. The improvement of efficiency is mainly attributed to the introduction of the new insert neighborhood, and employing the new neighborhood at the turning points to increase improving iterations efficiently. Experimental results show that both the new neighborhood and the mechanism to employ the new neighborhood are important.

Other contributions of this paper include: an adaptive evaluation function 〈R, U(X)〉, a formal definition to vacant degree and vacant points, the collision accidents criterion for ending ITS-VND, the adaptive greedy-redo method for accelerating neighborhoods exploration, and an analysis about which new features are important and how they work.

Although we only focus on solving the PUCC problem in this paper, the idea about how to efficiently combine Tabu Search and Variable Neighborhood Descent together is quite general and would be applicable to other similar problems.

@&#ACKNOWLEDGMENT@&#

This work is supported by National Natural Science Foundation of China (Grant nos. 61272206, 61472147, 61173180, 61100144, 61262011, 41201413); 111 Plan: Collaboration Innovation Base on Educational Digital Media and Visualization; Natural Science Foundation of Hubei Province, China (2014CFB661); National Social Science Foundation of China (Grant no. 14BGL131); Self-determined Research Funds of CCNU from the colleges' basic research and operation of MOE (Grant nos. CCNU15A05013, CCNU15A05010, CCNU15GF001); Key Science and Technology Project of Wuhan (Grant no.
2014010202010108). We sincerely thank Eckard Specht for processing our results and publishing them on the Packomania website. We also thank Prof. Jin-Kao Hao and Prof. Zhipeng Lü for their previous work in the area of Iterated Tabu Search, which inspired us a lot. Finally, we would give our special thanks to the anonymous referees for their professional comments and valuable suggestions that improve this paper significantly.

@&#REFERENCES@&#


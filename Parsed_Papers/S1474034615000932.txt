@&#MAIN-TITLE@&#Image-based retro-reflectivity measurement of traffic signs in day time

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A vision method that remotely measures traffic sign retro-reflectivity in daytime.


                        
                        
                           
                           The method simulates nighttime visibility from images taken during daytime.


                        
                        
                           
                           The impact of time of day and distance on measurements are studied.


                        
                        
                           
                           The method with accuracy of 95.24% is cheaper, faster and safer than current practice.


                        
                        
                           
                           The method satisfies FHWA measurement requirements on accuracy and granularity.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Retro-reflectivity

Traffic sign

Image-based

Remote sensing

Computer vision

@&#ABSTRACT@&#


               
               
                  The visibility of a traffic sign at night depends on its retro-reflectivity, a property that needs to be frequently monitored to ensure transportation safety. In the U.S., Federal Highway Administration (FHWA) maintains regulations to ensure minimum retro-reflectivity levels. Current measurement techniques either (a) use vehicle mounted device during the night, or (b) use manual handheld devices during the day. The former is expensive due to nighttime labor cost. The latter is time-consuming and unsafe. To address these limitations, this paper presents a computer vision-based technique to measure retro-reflectivity during daytime using a vehicle mounted device. The presented algorithms simulate nighttime visibility of traffic signs from images taken during daytime and measure their retro-reflectivity. The technique is faster, cheaper, and safer as it neither requires nighttime operation nor requires manual sign inspection. It also satisfies FHWA measurement guidelines both in terms of granularity and accuracy. The performance of the presented technique is evaluated under various testing conditions. The results are promising and demonstrate a strong potential in lowering inspection cost and improving safety in practical applications on retro-reflectivity measurement.
               
            

@&#INTRODUCTION@&#

Maintaining and improving the performance of high-quantity low-cost roadway assets such as traffic signs, mile markers, and guardrails is critical to safety of the existing transportation systems. The first step in managing these assets is monitoring their as-is conditions and involves evaluating placement, message clarity, line-of-sight, redundancy, daytime color, and nighttime visibility [4]. Due to the significance of the nighttime visibility, the U.S. Federal Highway Administration (FHWA) has enacted new regulations on minimum acceptable level of retro-reflectivity for all traffic signs. As of January 2015, all agencies are required to inspect this material property and comply with retro-reflectivity requirements for red/white “regulatory” signs such as Stop and Speed Limit signs, yellow “warning” signs, and green/white “guide” signs. By January 2018, these requirements will be applicable to overhead guide signs and street name signs as well [11].

Enforcing these regulations requires agencies to frequently measure the current levels of retro-reflectivity and devise replacement plans. Two major measurement techniques are commonly used today: (a) using remote retro-reflectivity measurement device mounted on inspection vehicles. This device automatically measures retro-reflectivity, though the process needs to be done at night; (b) a practitioner using a hand-held device to measure retro-reflectivity. This device must physically touch the sign so the practitioner needs to perform this operation manually and sign-by-sign. This process can be performed during daytime, however, it is time-consuming, unsafe, and expensive [6,23].

To address current limitations, this paper proposes a new technique which is similar to (a) as it performs remote measurements and is similar to (b) as it can be used during daytime. More precisely, computer vision techniques are used to reconstruct nighttime images using images taken during the day. Then, the reconstructed night images are used to measure retro-reflectivity similar to (a).

Retro-reflectivity is a property of surface materials that reflect light transmitted by a distant source [2]. Retro-reflective materials are commonly used for traffic signs to enhance their visibility during night. However, a perfect retro-reflector reflects all the incoming light back toward the headlights, and can cause a safety hazard for the drivers. To create optimum visibility and to divert the reflected light from the driver’s direct line of sight, signs are coated with certain matt sheeting materials that have prismatic and micro-prismatic patterns. This coating mechanism allows the signs to be located safely out of the incoming light’s line of travel and yet be visible to the drivers at night. Fig. 1
                         illustrates the role of retro-reflective material in sign visibility.

According to the FHWA’s Manual on Uniform Traffic Control Devices (MUTCD) [16], minimum retro-reflectivity requirement depends on the color combination of a sign (Table 1
                        ). These guidelines – current as of January 2015 – require retro-reflectivity to be measured in (cd/lx/m2) at an observation angle of 0.2° and an entrance angle of −4.0°. Here cd is candela – the unit of luminous intensity, which is the power that is emitted by the light source in a particular direction (brightness of a display devices) and lx is the unit of illuminance, which is a measure of how much the incident light illuminates the surface (hits and passes through a surface).

The latest MUTCD recommends two approaches for retro-reflectivity management (Fig. 2
                        ):

(1) Management methods which are primarily based on the life expectancy of the overall sign inventory. In these methods, life expectancy is estimated based on a number of factors including warranties, demonstrated performance, or control sign assessments; (2) Assessment methods involving regular nighttime visibility measurements. The MUTCD permits the combination of these methods in any responsible program that reasonably assures compliance.

There are several commonly used management methods which are as follows:


                        Expected sign life method – Using various measures of demonstrated sheeting life, signs are replaced when they reach a certain age. This method requires agencies to track the installation dates using stickers on the back of the signs, bar codes, or computerized sign management systems. However, manually inspecting these stickers or barcodes can be very time-consuming, especially if the stickers or barcodes are not easily visible on the sign.


                        Blanket replacement method is similar to expected sign life method, except that individual signs are not tracked. Instead a group of signs are replaced at the same time based on the location and/or the type of the signs. In this method, as shown in Fig. 2, an agency divides their jurisdiction into corridors and/or zones where the number of areas is related to replacement cycles. Then all signs are replaced in each zone/corridor according to their replacement cycles.

In Control Signs Method, for groups of similar signs, a single representative sign is placed at a controlled location. The control sign is measured for retro-reflectivity periodically. When the control sign is near minimum retro-reflectivity requirement, its in-service companions are replaced. This method has a low cost and does not require labor-intensive processes. However, a large set of control signs and adequate space are required to create statistically significant results.

Even though in management-based methods, signs are assigned a life expectancy at installation, yet their degradation speed varies based on location and environmental conditions. Thus, management methods which replace signs according to a schedule, will result in replacement of many signs that are still fully functional.

Compared to management methods, the assessment methods lead to less frequent sign replacements and improve efficiency. These methods could be performed through visual inspection during nighttime (Nighttime Visual Inspection Method) or using retro-reflectometer devices during daytime (Retro-reflectivity Measurement Method). Through these methods, retro-reflectivity could be measured more regularly, and recommendations can be provided on the best timing for replacing a sign based on degradation levels. Manual visual inspections involve some degree of subjectivity, yet research has shown that trained observers can reasonably identify signs with marginal retro-reflectivity [10]. Measuring sign retro-reflectivity through a systematic process provides the most direct means of monitoring the maintained retro-reflectivity levels and removes subjectivity.

Currently, the most objective method to measure retro-reflectivity is to use handheld retro-reflectometers [9,21]. A single handheld retro-reflectometer costs over ten thousand dollars [31]. Because this device needs to be in direct contact with a sign surface to take measurements – even for the overhead signs and those ground mounted signs that are out of reach (see Fig. 3
                        ) its application can be labor-intensive, expensive, and potentially unsafe for the inspectors [5,27]. A bigger challenge is that these devices can only take measurements on pre-defined geometries which are not the best representatives of the actual driving geometries [3,8,20]. For example, measurements from twisted and leaning signs can result in retro-reflectivity above the minimum levels, while the actual luminance of the sign under nighttime conditions may be lower than the requirements [33]. Overall, all of the management or assessment methods, even those that are standardized by FHWA [16], are costly and/or labor intensive. In the past decade, research has proposed several measurement techniques to address these shortcomings. These techniques are discussed in Section 2.

@&#RELATED WORK@&#

The most recent mobile retro-reflectivity methods include: SMARTS (Sign Management And Retro-reflectivity Tracking System) [34], AMAC (Advanced Mobile Asset Collection) [26], MANDLI (Retro View) [18,24], and VISULISE (Visual Inspection of Signs and Panels) [15].

SMARTS was developed by the Naval Research Laboratory for the FHWA. SMARTS include a xenon flash, a laser range finder, one color camera and two monochrome cameras. The unit first, sets off a flash and takes a digital image. Then the image is processed to estimate the retro-reflectivity of signs [28,30]. This system was an experimental concept and it is not available today. AMAC uses artificial vision and an advanced lighting system to locate, collect, and analyze traffic sign data at night. This data includes: retro-reflectivity, luminance, position, dimensions, and color. AMAC integrates high accuracy GPS with an onboard inertial navigation system to locate and process sign data [26]. MANDLI continuously fires a high-intensity flash and grayscale cameras simultaneously capture frames. One low intensity camera and one high intensity camera are coupled to cover a wide dynamic range. Flashlights fire infrared light that is invisible to human eyes at a rate of two per second while vehicle travels at highway speed [18,24]. VISULISE uses an infrared light. It captures reflected light using a stereoscopic system made up of two high-resolution cameras [15]. While these methods are practical, yet their application is still costly and requires operation at nighttime.

Measuring retro-reflectivity from images taken during the day can address the safety concerns. However, several properties are needed for retro-reflectivity measurements which cannot be directly captured through conventional imaging techniques. Instead, they can be derived by processing pairs of images that are taken in carefully adjusted conditions. Reflection can also be estimated by analyzing two images that are captured with different polarizations [12]. Polarization filtering has long been used in photography through haze. Schechner et al. [32] demonstrated a technique that improves visibility by capturing two images through the haze with different polarizations. Other improvement techniques have also been developed. For example, Agrawal et al. [1] presented a technique to remove flash photography artifacts by processing images taken from different flash exposures. This technique improves image quality by removing unwanted specular reflection caused by the camera flash. Raskar et al. [29] developed a technique to capture and convey shape features from real-world scenes. They used a camera with carefully placed flashes to detect and distinguish depth discontinuities from material discontinuities via edge intensities.

The technique presented in this paper is similar to Raskar et al. [29] as a carefully designed artificial light source is used to capture the physical aspects of the scene. Different from Raskar et al. [29] which is designed toward extracting edges and shapes from the image, in this work a retro-reflectivity map is estimated. To do so, first an understanding of illuminance and luminance is needed. Illuminance is a measure of the light falling on a surface measured in lux and is widely used to specify light levels. Luminance is perceived by the human viewer as the brightness of a light source [19]. Gladly, a pixel intensity value in an image taken with a digital camera is proportional to the luminance in the original scene. This strategy eliminates the need for expensive luminance meters, and has the following advantages [35]:
                        
                           •
                           The millions of pixels in the CMOS sensor of a camera act as luminance sensors, and thus a digital camera can capture the luminance of an entire scene. This speeds up the measuring process and allows multiple measurements to be conducted simultaneously.

The surroundings of the luminance measurement are recorded allowing the measurements to be placed in their context.

For luminance measurement, the field of view (FOV) of a visual sensor must be smaller than the size of the light source. The FOV of a digital camera pixel is on the order of 150 times smaller than the FOV of a luminance meter which is about 1°. Thus, the CMOS sensor of a camera is powerful enough to measure small area light sources such as individual light emitting diodes. These light sources are difficult or impossible to measure with a luminance meter [19].

By photographing a source of known luminance and calibrating the camera, the conversion factor is obtained that links luminance (in candela per square meter (cd/m2)) to the intensity value of a pixel in an image. This creates the basis for the method which is presented in the following:

@&#METHOD@&#

This paper presents a new image-based method to measure retro-reflectivity from a distance during daytime. The proposed method requires a digital camera equipped with a flashing device. By capturing two images almost simultaneously, the method simulates nighttime visibility and performs retro-reflectivity measurement. The accuracy and granularity of the method complies with the FHWA requirements. An overview of the method is illustrated in Fig. 4
                     .

A combination of computational photography and carefully tuned hardware is used to generate realistic photos of night during daytime. To synthesize a night photo; one needs to remove the sun and all of its reflections while adding a controlled light source. To do this, two images are taken from a scene; one with a controlled artificial light source – produced by a commercial flash, and one without. The image without the artificial light source is denoted as 
                        
                           
                              
                                 I
                              
                              
                                 Day
                              
                           
                        
                     . Similarly the image taken under the presence of the artificial light source is denoted as 
                        
                           
                              
                                 I
                              
                              
                                 Flash
                                 +
                                 Day
                              
                           
                        
                     . These two images are jointly processed to remove all the light sources from the scene except for the controlled light source. Since all natural light sources including the sun are removed, the output image resembles a night photo where only the controlled light source is present. This final image is denoted as 
                        
                           
                              
                                 I
                              
                              
                                 Flash
                              
                           
                        
                     . Fig. 5
                     a and b illustrates two photographs taken from the same scene during daytime, one with flash and one without flash. Fig. 5c shows the processed night view of the scene generated by removing natural light sources.

To isolate the controlled light source, true irradiance is extracted first and then subtract the two images as: 
                        
                           
                              
                                 I
                              
                              
                                 Flash
                              
                           
                           =
                           
                              
                                 I
                              
                              
                                 Flash
                                 +
                                 Day
                              
                           
                           -
                           
                              
                                 I
                              
                              
                                 Day
                              
                           
                        
                     . However, a number of important software and hardware measures must be taken before this is practically possible. These measures are as follows:

To better simulate human vision, nearly all cameras apply a non-linear function to recorded raw pixel values. Hence, pixel intensity does not linearly correspond to pixel irradiance (the light incoming to the camera). Therefore direct subtraction would not preserve intensity ratios due to the non-linearity. Rather, this response function depends on camera CCD (Charge Coupled Device) and a number of other factors including exposure time (shutter speed) and f-stop (aperture). Camera is not a photometer and exhibits a limited dynamic range, with an unknown non-linear response. Hence, in order to convert pixel values to true radiance values, there is a need to estimate this film response function. The solution is to calibrate the camera to recover response curve from multiple exposures and then reconstruct the radiance map. As long as the same camera with the same settings is used, this response function does not need to be updated.

This response function is estimated according to a technique developed by Debevec and Malik [14] using multiple images. The goal is to create High Dynamic Range (HDR) images and an HDR tone-mapping from Low Dynamic Range (LDR) images. HDR photography is the method of capturing photographs containing a greater dynamic range than what normal photographs contain. In other words, HDR images store pixel values outside of the standard LDR range of 0–255 and contain higher precision.

Using multiple observations at each pixel with different exposures, image intensities are mapped onto a linear space. This allows us to accurately estimate intensity differences. Inputs are pixel values 
                           
                              
                                 
                                    Z
                                 
                                 
                                    ij
                                 
                              
                           
                         for image with shutter time 
                           
                              Δ
                              
                                 
                                    t
                                 
                                 
                                    j
                                 
                              
                           
                         ((ith pixel location, and jth image). Exposure is irradiance integrated over time and can be expressed with Eqs. (1)–(3). Then pixel values are non-linearly mapped and rewritten to form a linear system as shown in Eqs. (4)–(7) 
                        [14].
                           
                              (1)
                              
                                 Pixel Value
                                 
                                 Z
                                 =
                                 f
                                 
                                 (
                                 Exposure
                                 )
                              
                           
                        
                        
                           
                              (2)
                              
                                 Exposure
                                 =
                                 Radiance
                                 ×
                                 Δ
                                 t
                              
                           
                        
                        
                           
                              (3)
                              
                                 log
                                 (
                                 Exposure
                                 )
                                 =
                                 log
                                 (
                                 radiance
                                 )
                                 +
                                 log
                                 (
                                 Δ
                                 t
                                 )
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    
                                       E
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                                 ·
                                 Δ
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                              
                           
                        
                        
                           
                              (5)
                              
                                 
                                    
                                       Z
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 f
                                 (
                                 
                                    
                                       E
                                    
                                    
                                       ij
                                    
                                 
                                 )
                                 =
                                 f
                                 (
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                                 ·
                                 Δ
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        
                        
                           
                              (6)
                              
                                 ln
                                 f
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       ij
                                    
                                 
                                 )
                                 =
                                 ln
                                 (
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 +
                                 ln
                                 (
                                 Δ
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        
                        
                           
                              (7)
                              
                                 g
                                 (
                                 
                                    
                                       Z
                                    
                                    
                                       ij
                                    
                                 
                                 )
                                 =
                                 ln
                                 (
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 +
                                 ln
                                 (
                                 Δ
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        
                     

Given pixel values 
                           
                              Z
                           
                         at varying exposures 
                           
                              t
                           
                        , the goal is to solve for 
                           
                              g
                              (
                              Z
                              )
                              =
                              ln
                              (
                              E
                              ×
                              t
                              )
                              =
                              ln
                              (
                              E
                              )
                              +
                              ln
                              (
                              t
                              )
                           
                         where 
                           
                              
                                 
                                    Z
                                 
                                 
                                    ij
                                 
                              
                           
                         gives pixels near 0 or 255 less weight, 
                           
                              
                                 
                                    R
                                 
                                 
                                    i
                                 
                              
                           
                         is radiance at particular pixel site which is the same for each image, 
                           
                              Δ
                              
                                 
                                    t
                                 
                                 
                                    j
                                 
                              
                           
                         is known shutter time for image j, and 
                           
                              g
                              (
                              
                                 
                                    Z
                                 
                                 
                                    ij
                                 
                              
                              )
                           
                         is exposure as a function of the pixel value.

This boils down to solving for 
                           
                              E
                              (
                              irradiance
                              )
                           
                         since all other variables are known. By these definitions, 
                           
                              g
                           
                         is the inverse, log response function. This technique is used to compute 
                           
                              
                                 
                                    E
                                 
                                 
                                    day
                                 
                              
                           
                         and 
                           
                              
                                 
                                    E
                                 
                                 
                                    flash
                                    +
                                    day
                                 
                              
                           
                        . This technique is frequently used in HDR photography as it is crucial to have comparable pixel intensity values. In this work, this technique is used to estimate the true irradiance.

In order to subtract the two images, 
                           
                              
                                 
                                    I
                                 
                                 
                                    Day
                                 
                              
                           
                         and 
                           
                              
                                 
                                    I
                                 
                                 
                                    Flash
                                    +
                                    Day
                                 
                              
                           
                        , all elements in the images must be perfectly registered (aligned). A bright edge that is misaligned by one tenth of a pixel (or a few arc-seconds) produces significant artifacts around the edges of an object. This issue is illustrated in Fig. 6
                        . In real-world conditions, both the camera and objects can move within several pixels. For example, a camera that is fixed on a tripod may be affected by some degree of vibration due to wind and other factors. Furthermore, some objects such as moving cars and pedestrians may move a few pixels between the times that the two images are being captured. A camera that is mounted on a vehicle or a camera that moves could exhibit a greater degree of misalignment.

To minimize the effects of vibrations and movements, the images are automatically aligned in two steps: (1) Global alignment; (2) Local sub-pixel alignment. In global alignment, the images are translated so that the misalignment is below one pixel. In the second step, sub-pixel alignment is performed for local area alignment. The second sub-pixel alignment is essential because at that level the misalignment would be different in various locations of the image.

Cross-correlation on the edges of 
                              
                                 
                                    
                                       I
                                    
                                    
                                       Day
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       I
                                    
                                    
                                       Flash
                                       +
                                       Day
                                    
                                 
                              
                            is computed to estimate global displacement. Here image edges are used rather than raw pixel intensities because the alignment of edges is more accurate than the alignment of raw pixel intensities [25]. To speed up the process of cross-correlation, Fast Fourier Transform is used to complete the process in 
                              
                                 O
                                 (
                                 n
                                 log
                                 n
                                 )
                              
                           . The displacement that obtains the maximum alignment is chosen then (see Fig. 7
                           ). If the camera has not moved, the displacement would be zero. This step makes the algorithm robust to displacements.

After the process of global alignment some local misalignments may still exist. Misalignment could be dissimilar in different areas of the image due to tiny movements in the scene or the camera. This misalignment produces artifacts at the edges. A local sub-pixel registration is performed in order to align every local patch in the image.

The usual technique is to up-sample images and performs a pixel-wise cross-correlation. A technique proposed by Guizar-Sicairos et al. [17] is used in this paper to align the images without up-sampling. This algorithm registers a pair of images by retrieving the phase difference within a discrete cosine transform. This alignment is performed for a 100×100 grid of patches in the image. Each of the 10,000 blocks is aligned separately according to the local appearance of the block. Fig. 8
                            compares the effect of using local alignment on the quality of the output.

After 
                              
                                 
                                    
                                       I
                                    
                                    
                                       Day
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       I
                                    
                                    
                                       Flash
                                       +
                                       Day
                                    
                                 
                              
                            are fully registered and the response function g is obtained, 
                              
                                 
                                    
                                       E
                                    
                                    
                                       Flash
                                    
                                 
                              
                            is computed according to the following equation:
                              
                                 (8)
                                 
                                    
                                       
                                          E
                                       
                                       
                                          Flash
                                       
                                    
                                    =
                                    
                                       
                                          E
                                       
                                       
                                          Flash
                                          +
                                          Day
                                       
                                    
                                    -
                                    
                                       
                                          E
                                       
                                       
                                          Day
                                       
                                    
                                    =
                                    g
                                    (
                                    
                                       
                                          I
                                       
                                       
                                          Flash
                                          +
                                          Day
                                       
                                    
                                    )
                                    -
                                    g
                                    (
                                    
                                       
                                          I
                                       
                                       
                                          Day
                                       
                                    
                                    )
                                 
                              
                           
                        

Retro-reflection is the ratio of the amount of light returned from a traffic sign versus the amount hitting the sign. As shown in Fig. 9
                        , to determine the retro-reflectivity level of a traffic sign, the measures of luminance, illuminance, and geometry (angles and distance) are required.

The FHWA has adopted the SI units for retro-reflection; thus by computing illuminance and luminance, retro-reflectivity is measured in units of candelas per lux per square meter (cd/lx/m2):
                           
                              (9)
                              
                                 Light INTO Sign
                                 =
                                 Illuminance
                                 =
                                 lux
                                 (
                                 lx
                                 )
                              
                           
                        
                        
                           
                              (10)
                              
                                 Light OUT of Sign
                                 =
                                 Luminance
                                 =
                                 
                                    
                                       Candela
                                    
                                    
                                       
                                          
                                             m
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 
                                 
                                    
                                       
                                          cd
                                          /
                                          
                                             
                                                m
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 Retro-reflectivity
                                 =
                                 
                                    
                                       R
                                    
                                    
                                       A
                                    
                                 
                                 =
                                 
                                    
                                       Light OUT of Sign
                                    
                                    
                                       Light INTO Sign
                                    
                                 
                              
                           
                        
                        
                           
                              (12)
                              
                                 
                                    
                                       R
                                    
                                    
                                       A
                                    
                                 
                                 ∝
                                 
                                    
                                       Luminance
                                    
                                    
                                       Illuminance
                                    
                                 
                                 
                                 (
                                 cd
                                 /
                                 lx
                                 /
                                 
                                    
                                       m
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                           
                        
                     

Eq. (13) shows the exact relationship between the luminance of a surface (
                           
                              L
                           
                        ) in cd/m2, the illuminance 
                           
                              (
                              E
                              )
                           
                         in lx and reflectance (
                           
                              ρ
                           
                        ) (dimensionless) where 
                           
                              π
                           
                         is the pi number [19].
                           
                              (13)
                              
                                 L
                                 =
                                 
                                    
                                       E
                                       ρ
                                    
                                    
                                       π
                                    
                                 
                              
                           
                        
                     

The digital camera turns an image into a two dimensional array of pixels. Ignoring the complications of color, each pixel has a value that represents the light intensity. The amount of exposure (the brightness in the final image) is proportional to the number of electrons that are released by the photons of light impinging on the sensor. Consequently, it is proportional to the illuminance (in lux) times the exposure time, so the brightness is in lux-seconds. By invoking the parameters of the camera, the following formula from [13] can be used:
                              
                                 (14)
                                 
                                    
                                       
                                          N
                                       
                                       
                                          d
                                       
                                    
                                    =
                                    
                                       
                                          K
                                       
                                       
                                          c
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   tS
                                                
                                                
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         s
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          L
                                       
                                       
                                          s
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    
                                       N
                                    
                                    
                                       d
                                    
                                 
                              
                            is value of the pixel in the image, 
                              
                                 
                                    
                                       K
                                    
                                    
                                       c
                                    
                                 
                              
                            is calibration constant for the camera, 
                              
                                 t
                              
                            is exposure time in seconds, 
                              
                                 
                                    
                                       f
                                    
                                    
                                       s
                                    
                                 
                              
                            is aperture number (f-stop), 
                              
                                 S
                              
                            is ISO sensitivity of the film, and 
                              
                                 
                                    
                                       L
                                    
                                    
                                       s
                                    
                                 
                              
                            is luminance of the scene in cd/m2. One measurement would be sufficient to determine the value of calibration constant. One would photograph some source of known luminance 
                              
                                 
                                    
                                       L
                                    
                                    
                                       s
                                    
                                 
                              
                           , determine the value 
                              
                                 
                                    
                                       N
                                    
                                    
                                       d
                                    
                                 
                              
                            of the pixels in the image, and note the camera settings for ISO exposure time and aperture. To calculate 
                              
                                 
                                    
                                       N
                                    
                                    
                                       d
                                    
                                 
                              
                            and convert pixels to grayscale, the red, green, and blue color channel values are used within the following formula:
                              
                                 (15)
                                 
                                    
                                       
                                          N
                                       
                                       
                                          d
                                       
                                    
                                    =
                                    R
                                    ×
                                    0.299
                                    +
                                    G
                                    ×
                                    0.587
                                    +
                                    B
                                    ×
                                    0.114
                                 
                              
                           
                        

The reason these values are weighted is because pure red, green, and blue are actually darker/lighter than each other, with green being the darkest and blue the lightest [22].

American Standard Association (ASA) has defined incident-light meters as well as reflected-light meters. The incident-light exposure equation is
                              
                                 (16)
                                 
                                    
                                       
                                          
                                             
                                                A
                                             
                                             
                                                2
                                             
                                          
                                       
                                       
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ES
                                             
                                             
                                                x
                                             
                                          
                                       
                                       
                                          
                                             
                                                K
                                             
                                             
                                                c
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 A
                              
                            is the relative aperture (f-number), 
                              
                                 t
                              
                            is the exposure time (shutter speed) in seconds, 
                              
                                 E
                              
                            is the illuminance, 
                              
                                 
                                    
                                       S
                                    
                                    
                                       x
                                    
                                 
                              
                            is the ASA arithmetic film speed, and 
                              
                                 
                                    
                                       K
                                    
                                    
                                       c
                                    
                                 
                              
                            is the incident-light meter calibration constant. By placing the luminance and illuminance in Eq. (11), the sign retro-reflectivity is measured from every pixel in the images taken during the daytime. Finally, the retro-reflectivity of a sign is measured by averaging all pixel-level measurements. This is consistent with current practices, yet instead of using a few (typically up to 4) point-level measurements, all pixels are used to characterize retro-reflectivity more accurately.

For evaluating the performance of the image-based retro-reflectivity measurement of traffic signs in daytime, several experiments were conducted on different types of traffic signs with different shapes, colors and levels of retro-reflectivity including retro-reflective speed limit sign, stop sign, and warning sign, and one non-retro-reflective stop sign. This allows considering all possible variations for proof of concept. A total of 96 experiments were tested to carefully consider all possible modes of variation (4 times-of-day×4 signs with different colors and shapes×6 distances=96 experiments). A Nikon D300 camera together with a Nikon SB-900 flash device was used for data collection (see Fig. 10
                     ). The luminance generated by the flash device (1 million–10 million candela) is significantly greater than of a car’s headlight (10,000–100,000 candela). Therefore, a flashlight has about 100 times more luminance than a headlight during 5ms when the image is being captured. As a result, total flashlight energy is comparable to 100–1000ms of a car’s headlight. However, since the proposed method measures the retro-reflectivity of traffic signs in a daytime, the flash device should be able to compete with sun rather than car’s headlights. In fact at distances less than 30m the luminance is comparable to the sun. Nevertheless the flashlight fire time is less than 5ms, so the total energy used is really small. In our setup, camera exposure time is adjusted to flash time in order to maximize the exposure of the flashlight relative to the sun.

HDR images are used for image-based lighting purposes. To derive the omni-directional lighting information, an HDR image of a spherical mirror is taken (see Fig. 11
                        ) at different exposure times (1/2, 1/30, 1/60, 1/120, 1/200, 1/320, and 1/500) and the response curves are plotted using Eq. (2). Fig. 11 shows these response curves for different color channels. As mentioned, this calibration is a one-time process for each camera and does not need to be repeated for field experiments.

The experiments were conducted in both sunny and cloudy weather conditions for four times of day: 9:00 AM, 12:00 PM, 3:00 PM, and 6:00 PM and at six distances of 7.5m, 15m, 20m, 30m, 60m, and 75m. Fig. 12
                         shows these images. In these experiments, the camera was facing East, which represents the most extreme measurement condition. As a result at 9:00 AM, the sun was in front of the camera and at 6:00 PM the direction of sun light and flash were the same. Camera setting for data collection is shown in Table 2
                        .

@&#PERFORMANCE EVALUATION@&#

In order to compare the performance of the presented technique, the as-is retro-reflectivity of the subject traffic signs was benchmarked at Illinois Department of Transportation (IDOT)’s Bureau of Materials and Physical Research in Springfield, IL. At this facility, the retro-reflectivity of all traffic signs is measured according to ASTM E810-03 guidelines. More specifically, a three-axes goniometer is used to measure the coefficient of retro-reflection on retro-reflective sheeting based the coplanar geometry. The setup, as shown in Fig. 13
                        , involves the use of a light projector source, a receiver, a device to position the receiver with respect to the source, and a test specimen holder in suitable darkened area. The specimen holder is separated from the light source by 15m. The general procedure involved is to determine the ratio of the light retro-reflected from the test surface to that incident on the test surface. The results of this measurement are shown in Table 3
                         where blank represents measurement when there is no traffic sign (could be interpreted as the measurement tolerance for the 3-axis goniometer).

@&#RESULTS AND DISCUSSION@&#

To check the reliability of the method, several experiments have been carried out. Four different traffic signs with different levels of retro-reflectivity were used to test the performance of the image-based method for retro-reflectivity measurement in daytime. Figs. 14–16
                     
                     
                      show the results of image-based retro-reflectivity measurement for speed limit, warning, and retro-reflective stop signs respectively. The retro-reflectivity of each sign at different times of day and for different distances are measured in cd/lxm2 and are compared with the ground truth (measured based on ASTM E810-034). The measurement values are shown under each image in these Figures. In most cases, the measurements shown are above the ground truth values shown in Table 3. In a few cases shown with asterisk, the measured retro-reflectivity numbers are below the ground truth. These are mainly due to distance and the timing of the day used for data collection.

To obtain the criteria for best performance, the impact of distance and lighting condition (the timing of the experiment) on the accuracy of measurement were examined, as follows:


                        Fig. 17
                         compares the retro-reflectivity measurements for different traffic signs at different times of day. Compared to ground truth, the proposed method with camera facing East (worst measurement condition) works properly at 9:00 AM, 12:00 PM, and 3:00 PM and for all distances less than 20m. However, the performance of our method is decreased as the measurement time approaches the timing of the sunset. The decrease is due to the alignment of the sunlight direction and the camera flash light source direction (West–East in our setup). As shown in most extreme case (6:00 PM), when these directions are aligned, the presented method with current hardware setting is not resulting in accurate measurements.


                        Fig. 18
                         compares the measurement of retro-reflectivity for different traffic signs at different distances. As shown, the method works pretty well for distances less than 20m in all the times during the day. However, the method is not robust enough for distances above 30m and more especially in more extreme light conditions (3:00 PM and 6:00 PM). Nevertheless, with current hardware setting the method is capable of measuring the retro-reflectivity of traffic signs for distances less than 20m and at all times in the day. The accuracy and granularity of the measurements show that the performance of the presented technique satisfies the FHWA requirements.

@&#DISCUSSION@&#

For evaluation, the experimental results were compared with corresponding ground truth there were measured in IDOT’s lab according to ASTM guidelines. To do so, the mean and standard deviations between actual and ground truth measurement were calculated for each type of sign. Then the error and accuracy for each type of traffic sign were calculated based on Eq. (17):
                           
                              (17)
                              
                                 
                                    
                                       
                                          Average Error
                                          =
                                          
                                             
                                                |
                                                Ground Truth
                                                -
                                                Mean
                                                |
                                             
                                             
                                                Ground Truth
                                             
                                          
                                       
                                    
                                    
                                       
                                          Average Accuracy
                                          =
                                          1
                                          -
                                          Average Error
                                       
                                    
                                 
                              
                           
                        
                     

Contrasting the experimental measurements with those obtained as ground truth in the lab shows that the presented method has an accuracy of 93.74% in correctly clarifying retro-reflectivity levels in traffic signs. Table 4
                         summarizes these statistics for different types of the signs. For speed limit sign with ground truth retro-reflectivity of 147.625547 (cd/lxm2), the presented method does not produce accurate results at the distance of 75m and at any time between 3:00 and 6:00 PM. The proposed method also does not result in accurate measurements on warning sign, at 6:00 PM for distances more than 20m, and at time of 3:00 PM for distances more than 30m. The same situation applies to retro-reflective stop sign.

Based on current hardware and software settings, the presented method can measure retro-reflectivity of signs at 95.24% accuracy for all distances between 7.5m and 30m and at any time between 9:00 AM and 3:00 PM.

Compared to the current practice of using the retro-reflectometer where only a few measurements are conducted (typically four point-level measurements on sign background, and four point-level measurements on sign text), the presented method considers the entirety of the traffic sign surface and results in a more comprehensive retro-reflectivity measurement. This is important as traffic signs exhibit heterogeneous deterioration rates, and point-level measurements may not be the best representatives for the entirety of the sign surface. Considering current practical limitations – even when the most accurate retro-reflectometers are used – the method at 95.24% accuracy shows significant promise for large scale applications.

All measurements in this study where taken using a fixed setup. Hence the effect of vibrations caused by mounting the prototype system over an inspection vehicle for measuring retro-reflectivity on long stretches of road is not studied yet. Also using this solution together with techniques that can automatically detect, classify, and localize traffic signs such as Balali and Golparvar-Fard [7] is left as future work.

@&#CONCLUSION@&#

One of the key measures for roadway safety at nighttime is signs visibility. Evaluation and replacing traffic signs with low retro-reflectivity is an effective strategy for improving safety of the transportation systems. With the new FHWA requirements on sign retro-reflectivity as outlined in MUTCD, road agencies require cost effective techniques that can enable retro-reflectivity measurement during daytime. To this end, this paper presented and validated a new image-based method for measuring the retro-reflectivity of traffic signs in a daytime. The method has potential to provide quick, safe, and inexpensive compliance inspection for minimum level of retro-reflectivity in traffic signs. With the hardware mounted on a driving vehicle, these measurements can be taken remotely and automatically for longer stretches of roads and highways, and there is no further need for putting measurement equipment in contact with sign and repeating the manual process for one sign at a time. Measurements can also be taken from real roadway geometries rather than prescribed geometries which do not always represent the real world conditions. In particular, the retro-reflectivity of twisted and leaning signs can also be measured under real roadway conditions and for actual driver-view perspectives. The performance of the presented method was evaluated with ground truth and the experimental results showed that the proposed image-based method with current hardware setting is robust enough to measure retro-reflectivity of signs at different times of the day and for any distances less than 30m. Studying the effect of vibrations caused by mounting the prototype system over an inspection vehicle for measuring retro-reflectivity on long stretches of road is left as future work. Such a mobile setup shows promise in facilitating the current work flows by allowing inspection vehicles – widely used in the U.S. – to also measure retro-reflectivity levels during daytime. This method can also minimize the challenges associated with inspecting overhead and difficult-to-reach ground mounted signs.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank the Illinois Center for Transportation for providing different types of traffic signs. The support of Illinois Department of Transportation’s Bureau of Materials and Physical Research in Springfield, IL is also greatly appreciated. The contribution of Drs. Jesus de la Garza and Omidreza Shoghli for literature review and initial discussions on retro-reflectivity is appreciated. The constructive comments of Dr. David Forsyth on this research are appreciated as well.

@&#REFERENCES@&#


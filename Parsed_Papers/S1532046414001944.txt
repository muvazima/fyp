@&#MAIN-TITLE@&#A multi-technique approach to bridge electronic case report form design and data standard adoption

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Electronic case report form design and data standard adoption have a major gap.


                        
                        
                           
                           A multi-technique approach achieves eCRF design with data standard compliance.


                        
                        
                           
                           The multi-technique approach includes information retrieval, natural language processing and ontology-based knowledgebase.


                        
                        
                           
                           The results of evaluation revealed a satisfactory performance. We also analyze the reasons of the missed and failed results.


                        
                        
                           
                           A usage intention of our approach is conducted in this study.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Data standard

Common data elements

Case report form

Natural language processing

Ontology-based knowledgebase

@&#ABSTRACT@&#


               
               
                  Background and objective
                  The importance of data standards when integrating clinical research data has been recognized. The common data element (CDE) is a consensus-based data element for data harmonization and sharing between clinical researchers, it can support data standards adoption and mapping. However, the lack of a suitable methodology has become a barrier to data standard adoption. Our aim was to demonstrate an approach that allowed clinical researchers to design electronic case report forms (eCRFs) that complied with the data standard.
               
               
                  Methods
                  We used a multi-technique approach, including information retrieval, natural language processing and an ontology-based knowledgebase to facilitate data standard adoption using the eCRF design. The approach took research questions as query texts with the aim of retrieving and associating relevant CDEs with the research questions.
               
               
                  Results
                  The approach was implemented using a CDE-based eCRF builder, which was evaluated using CDE- related questions from CRFs used in the Parkinson Disease Biomarker Program, as well as CDE-unrelated questions from a technique support website. Our approach had a precision of 0.84, a recall of 0.80, a F-measure of 0.82 and an error of 0.31. Using the 303 testing CDE-related questions, our approach responded and provided suggested CDEs for 88.8% (269/303) of the study questions with a 90.3% accuracy (243/269). The reason for any missed and failed responses was also analyzed.
               
               
                  Conclusion
                  This study demonstrates an approach that helps to cross the barrier that inhibits data standard adoption in eCRF building and our evaluation reveals the approach has satisfactory performance. Our CDE-based form builder provides an alternative perspective regarding data standard compliant eCRF design.
               
            

@&#INTRODUCTION@&#

The rapidly development of new research area and the wider adoption of informatics systems have resulted in the exponential growth of biological and clinical data. Although “big data” creates new research opportunities [1], researchers also face the difficulty of obtaining data as well as the high cost of data collection. Therefore, it has been inevitable that an urgent need for data harmonization, which would facilitate the subsequent data aggregation and sharing, has arisen.

The use of a data standard is a critical requirement for such harmonization, and is also the first step towards data integration. A data standard is an agreed upon set of rules that allow information to be shared and processed [2]. It could be classified as semantic standard (i.e., terminology artifacts), syntax standard for data representation and format (i.e., markup language), and content standard, such as minimum information checklist or common data elements (CDEs) [3–5].

As the National Institute of Health (NIH) encourages the use of CDEs [6], some researchers have designed their CRFs based on CDEs [7]. Several CDEs have been developed, for example, the Cancer Bioinformatics Grid (caBIG) [8], the National Institute of Neurological Disorders and Stroke (NINDS) common data element project [9], the Parkinson Disease Biomarker Program (PDBP) [7,10], as well as a number of other clinical CDE for a variety of different purposes [11–13]. The CDE is a logical unit of data that provides for the definition of data, including an identifier, an element type to indicate the value type, and detailed information, which is the meta-data that fully defines the semantics of the CDE [14]. To define the CDE in formal representation, the ISO/IEC 11179, which is a metadata repository standard, provides the standard syntax and grammar need to describe data element metadata. Many efforts have been made to adopt this standard, for example, the National Cancer Institute (NCI) Cancer Data Standards Repository (caDSR) implements the ISO/IEC 11179 standard for metadata registries when presenting CDEs in their repository [15]. The cancer Common Ontologic Representation Environment (caCORE) created by National Cancer Institute Center for Bioinformatics (NCICB) is an interoperability infrastructure that is based on model driven architecture and contains a metadata repository based on the ISO/IEC 11179 standard to allow semantic interoperability [16]. Another effort is the CDISC Shared Health and Research Electronic Library (CSHARE) and this utilizes the ISO/IEC 11179 standard as the semantic basis for its metadata and has adopt the ISO 21090 for the formal presentation of CDE data type [17].

The CDE should be able to not only standardize data collection, but also should facilitate the follow-up comparison of results across multiple studies [18]. Nevertheless, CDEs are center-specific and are not a global standard; therefore such an approach, which is called computable semantic interoperability, may exhibits scalability problems when applied beyond a well-defined domain [19]. As a result, using CDEs is still a compromise solution in terms of current research domains. To address the issue of computable semantic interoperability, Payne et al. developed the Translational Research Informatics and Data Management Grid (TRIAD), which leverages the caGrid [20] middleware and extended this to support working interoperability. Such working interoperability means that stakeholders are able to negotiate and use context-relevant semantic models that enable better semantic exchange [19]. In the TRIAD, a CDE metadata registry repository called the MDR (metadata repository) Core is one of the system’s four major components.

In clinical studies, the case report form (CRF) is an important tool for collecting data. The CRF is usually designed by researchers based on their study objective, for example, demographic information, medical history, and/or the results of clinical examination. Many clinical data capturing systems support electronic CFR (eCRF) design [21,22]. Through use of eCRFs, clinical research data is able to be captured and stored in clinical data repositories. For data integration and sharing purposes, Brandt et al indicated that there is a requirement for an information tool that will aid researchers in creating comprehensive and valid CRFs that can be mapped to a data standard [23]. Such an approach would enable the adoption of a data standard that can be used for clinical research applications, particularly if there is a tool supporting the retrieval and reuse of existing standard items [24].

How to efficiently and precisely select data elements from a CDE repository in order to build an eCRF that is able to accurately reflect the study question is the challenge that needs to be met in this context, especially when some researchers might not be familiar with the application of CDEs. Most commercial available clinical data capturing systems do not allow users to associate their research questions with CDEs, but merely provide a list of hundreds of CDE for selection or allow simple searching of the CDEs. The lack of an informatics tool that is able to substantially increase efficiency has become a barrier that inhibits data standard adoption.

To cross this barrier, we developed a multi-technique approach that included the creation of an ontology-based knowledgebase, the development of natural language processing and the creation of an information retrieval technique. In this study, we demonstrated this approach by implementing an eCRF builder that supports researchers and helps them design CDE compatible eCRFs.

There were mainly three parts to the implementation of the multi-technique approach (shown in Fig. 1
                     ): (1) the creation of an ontology-based knowledgebase of the CDEs, (2) the development of an information retrieval strategy for suggesting the CDEs and (3) the linking of the CDEs to the clinical questions.

This study took PDBP CDEs [25] as the example for demonstrating the process of creating an ontology-based knowledgebase. Originally, the PDBP CDEs were hosted in a straightforward relational database format. Our approach is compatible with the relational database format; however, such a format does not support formal semantic definitions. The ontology technique has been widely adopted in the clinical studies to allow semantic interoperability. Some studies have utilized ontology to harmonize their data standards [26] or to model the entities and relationships within study designs [27], while others have presented a clinical data element model using Web Ontology Language (OWL) [28,29]. In this research we would like to develop the CDE ontology to allow further semantic interoperability and to demonstrate the compatibility of our approach with semantic web technology.

Even through PDBP CDEs are not ISO/IEC 11179 compliant; they still have a well defined structure. In this study, we developed a program using the Protégé API [30] that build this ontology using the PDBP CDE relational database. The CDE information contains general details, such as identifier, title, variable name and description, data definitions, which includes element type, the text of the suggested question, guidelines and pre-descriptions, categorization and classification. The categorization and classification predicate the restricted hierarchical structure of the CDEs. The hierarchy is composed of disease, domain and subdomain. Each disease contains specific domains and each domain contains specific subdomains; furthermore, each CDE element belongs to a specific subdomain. To represent these restrictions, we adopted the OWL sequence extension [31] to express the restricted hierarchical structure of the CDEs. The OWL sequence extension uses the hasNext property to point to the next member in the sequence and to identify that the content of the member is associated through the hasContents property. In this study, we created four OWL classes: Disease, Domain, Subdomain and CDE. Those classes are linked with each other in sequence using the OWL object properties (hasDomain, hasSubDoaim and hasCDE) and the owl:individual of the owl:class is associated through the hasIndividual property. By setting the rdfs:domain and rdfs:range of the object property, each owl:individual belonging to a specific owl:class will inherit the restriction. The general details and data definition information is then stored in each CDE entity via the OWL annotation property. There are 426 CDE entities under CDE OWL class. An example of CDE ontology structure is shown in Fig. 2
                        .

In order to allow researchers to adopt the data standard when carrying out eCRF design, this study developed an information retrieval strategy that provides question relevant CDEs to its researchers. The study question, which is input by the user, is treated as the query for CDE information retrieval. Since the question is able to be in a variety of formats, the use of a pattern matching search approach might not be appropriate. Our information retrieval strategy included three major steps (Fig. 1). Firstly, we need to index the CDEs from the knowledgebase to allow information retrieval. The second step was to generate the query from study question, which is in free text, and then to perform searching. Thirdly, we evaluate the quantity of searching results obtained and refined the query if necessary. An open source and full-featured text search engine, Apache Lucene, was adopted for implementing the information retrieval strategy [32].

The description of each CDE entity from the knowledgebase was indexed by Lucene and the indexed result CDE indexed file was then used for searching. To improve the quality of searching, a description of each CDE entity was pre-processed using special characters to filter-out and term normalization based on part-of-speech tagging selection. This study indexed 426 descriptions from the PDBP CDE (see Fig. 3
                           ).

In this step, we utilized natural language processing (NLP) to analyze the narrative study question using the Apache OpenNLP toolkit [33]. Initially, the text analysis is preprocessed to determine factors such as sentence boundary, token removal and symbol removal. In general, nouns and noun phrases are more representative of the research question concept, adjectives and adverbs then support the concept expression, we therefore used nouns, noun phrases, adjectives and adverbs when generating the query. To do this, the preprocessed text is part-of-speech tagged and then filtered through the part-of-speech tag filter so that only nouns, noun phrases, adjectives and adverb left. Finally, we used the SPECIALIST Lexical Tools, “norm” [34], to normalize each term in the text based on its lexical properties, such as inflection, alphabetic case, spelling variants and ligature. Eventually we generated a simple text as a query that was derived from the study question after carrying out the above processing.

Query refinement is triggered if the number of searched results is less than what the researcher has set up. Lucene implements a variant of the TF–IDF scoring formula [35] that ranks the searching results. The TF–IDF weighting has been adopted not only for information retrieval but also for concept specificity [36] and terminology linking [37]. From the scoring formula [38], we should be noted that the Lucene searching is at the syntax level.

However, the study question is usually in a widely varied narrative form, which will limit the syntax searching. To overcome this limitation and to achieve semantically searching, we refined the query text through semantical query expansion. We adopted a general dictionary, the WordNet [39] and the MIT Java Wordnet Interface (JWI) [40], to find semantically relevant words, such as synonyms, for each term in a query. For example, a question text “Is subject receiving drugs?” will have been turned into a query “subject receive drug” by the previous NLP steps. The semantical expansion step would expand this query to be “subject message content individual person receive drug medication” by adding synonyms.

After semantically expansion, the number of terms in a query will increase and provide more opportunities to the retrieval of precise CDEs. However, there may also be a decline in the quality of the retrieved results since not all of semantically expanded queries are necessarily relevant to the study question. Therefore, we have set up a threshold-based method that assesses the quality of each expanded query. The definition of the threshold is shown as below
                              Def
                              For each expanded term in the query, let n be the number of pre-query result, s be the score of result and T be the inclusion threshold. If
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   
                                                      n
                                                   
                                                
                                                
                                                   
                                                      s
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             
                                                n
                                             
                                          
                                          >
                                          T
                                       
                                    
                                 then include this expanded term in refined query.

After the threshold-based refining, the final query would be “subject individual person receive drug medication” and this query has a higher chance of retrieving related CDEs.

To keep a flexible linkage between the CDEs and the clinical questions, our approach is able to suggest up to five CDEs with an average score that is higher than the Lucene score threshold for each study question. The suggested CDEs are then sorted by the Lucene scoring function. The detailed information on each CDE is also provided for the researcher’s reference. A real-time interaction interface is implemented using the Ajax technique [41].

Researchers can click on each CDE link to obtain the detailed information. We used SPARQL to obtain the detailed CDE information from the ontology-based knowledgebase. SPARQL is a query language for retrieving and manipulating data that is stored in the resource description framework (RDF) format [42]. An example described below is a SPARQL query for obtaining detailed information from knowledgebase for a CDE related to the date of an adverse event.
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                PREFIX 
                                                : <http://www.owl-ontologies.com/CDE.owl>
                                             


                                                SELECT 
                                                ?t ?d ?e ?v
                                             


                                                WHERE 
                                                {
                                                
                                                   
                                                      
                                                         :AdvEvntDateTime :title ?t .
                                                      


                                                         :AdvEvntDateTime :description ?d .
                                                      


                                                         :AdvEvntDateTime :elementType ?e .
                                                      


                                                         OPTIONAL{ :AdvEvntDateTime :preDefinedValues ?v .}
                                                      


                                                };
                                             

In this study, we utilized Apache Jena ARQ [43] which is a SPARQL processor to implement the knowledgebase retrieving task. If the researcher is not able to find a relevant CDE from the suggested CDE list, the interface will provide a CDE browser for searching the CDE.

Once a researcher has selected a CDE, the CDE is then associated with the study question and from then onwards the subsequently collected clinical data is no longer linked with narrative question, but with data standard.

To evaluate the performance of our multi-technique approach, we took the 23 PDBP CRFs [25] and the questions from the stackoverflow website [44] as the evaluation dataset. The PDBP CRF includes various collection topics like adverse events, behavioral history, and rapid eye movement behavior disorder. Each study question in the PDBP CRF has been linked with a CDE of the PDBP. Therefore, we treated the already established associations between the CDEs and CRFs as the golden standard when evaluating the performance of our builder. The 23 CRFs contained 433 non-duplicate and CDE effective study questions; those questions formed the positive dataset.

Since the CDEs in our CDE ontology were related to general disease or general clinical research concepts, we need a set of questions that were completely unrelated to the CDEs as the negative dataset. The stackoverflow website is a question and answer site for programmers. All of questions are not related to clinical research but rather to computer science. We randomly select 283 questions from that site as questions that are not associated with any CDE and used these as the negative dataset. This dataset contained 716 questions, including both CDE-related and CDE-unrelated questions. To obtain an appropriate Lucene score threshold, we separate this dataset into a training dataset (215 questions) and a testing dataset (501 questions).

For each question, our approach provided up to 5 CDEs, and four measures were used to describe the performance of multi-technique approach: precision (Eq. (1)), recall (Eq. (2)), F-measure (Eq. (3)) and error (Eq. (4)). To calculate these values, the system’s response was counted and categorized as true positive (TP: this question is CDE-related and its CDE exist in response CDEs), false positive (FP: this question is CDE-related and its CDE does not exist in response CDEs or the approach returned an empty query result), false negative (FN: this question is CDE-unrelated and the approach returned a non-empty query result) and true negative (TN: this question is CDE-unrelated and the approach returned an empty query result).
                           
                              (1)
                              
                                 precision
                                 =
                                 
                                    
                                       TP
                                    
                                    
                                       TP
                                       +
                                       FP
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 recall
                                 =
                                 
                                    
                                       TP
                                    
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 F
                                 -measure
                                 =
                                 
                                    
                                       2
                                       ×
                                       precision
                                       ×
                                       recall
                                    
                                    
                                       precision
                                       +
                                       recall
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 error
                                 =
                                 
                                    
                                       FN
                                       +
                                       FP
                                    
                                    
                                       TP
                                       +
                                       FN
                                       +
                                       FP
                                    
                                 
                              
                           
                        
                     

To better understand the usage intention of our approach, we also did hands-on user testing. We recruited 16 clinical research staffs and system developers from the NIH and the Center for Systems and Synthetic Biology at the National Yang-Ming University. These individuals are independent from this study. We requested users to design an eCRF using our form builder; a 10min training session was carried out before the eCRF design started. Afterwards, the users filled out a post-test questionnaire and participated in an open-ended interview.

@&#RESULTS@&#

In this study, we have outlined the multi-technique approach used to implement a CDE based eCRF builder, which is able to be integrated into any web-based clinical system as an eCRF design modular. The researcher only need to type in the study question and the builder will suggest the relevant CDEs for the study question as shown in step1 and step 2 of Fig. 4
                        . By clicking on each CDE, it will show detailed information and the appropriate question type such as single choice, multiple choice or narrative answer (the step 3 in Fig. 4). Once the researcher selects a CDE and clicks an association button, the association between the CDE and the study question will be established (the result in Fig. 4). Finally, we created a CDE-mapped eCRF for data collection and the data associated with CDE is then able to be further integrated and shared.

Using our approach, the Lucene score threshold is able to determine whether the system will return question-related CDEs. The system get the best performance (highest F-measure and lowest error) when the score threshold was 0.4 (shown in Fig. 5
                        ).

After determining the Lucene score threshold, we evaluate our approach using the testing dataset. Among the 501 testing questions, four values were measured, namely precision: 0.84, recall: 0.80, F-measure: 0.82 and error: 0.31. For the 303 CDE-related questions in the testing data, 11.2% (34/303) were missed by our builder. The return rate of the builder was 88.8% (269/303). Among the 269 returned results, only 9.7% (26/269) did not contain the correct CDE and therefore could be considered a mistake. Therefore, the accuracy of the builder was 90.3% (243/269) for CDE-related questions. Each returned result consisted of five suggested CDEs sorted by Lucene scoring function and the place that correct CDE occurred ought to somehow reflect the performance of the builder. In this context, 73.2% (197/269) of results had the correct CDE in first place, 11.5% (31/269) had the correct CDE in the second place, and 3.8% (10/269) had the correct CDE in the third place.

After reviewing the 60 missed or mistaken results, we found three possible reasons for these errors. The first reason is an unclear concept within the study question, such as ‘end date’, ‘indication’, and ‘outcome’. These terms are too general, and are difficult to define without any additional explanation. This reason accounted for 29.4% (10/34) of the missed results and 42.3% (11/26) of the mistaken results. The second reason is an unclear CDE description. In another word, the CDE description does not provide sufficient information for researcher. For instance, the CDE description for ‘Hamilton Anxiety Rating Scale’ is ‘Tinnitus, blurring of vision, hot and cold flushes, feelings of weakness, pricking sensation scale’. The description only lists the content but does not indicate the purpose of the scale. This reason accounted for 23.1% (6/26) of the mistaken results. The third possible reason is the failure of the builder. While both the study question and CDE description are well-defined, the system may not be able to suggest an appropriate CDE list. This situation occurred in 70.6% (24/34) of the missed results and 34.6% (9/26) of the mistaken results (Table 1
                        ).

Our multi-technique approach is a series of processes that include natural language processing, information retrieval and SPARQL querying. We next estimated the processing time of this tool. Currently, the CDE knowledgebase contains 426 CDE elements. On an average desktop computer with Intel Core 2 Quad-2.83GHz CPU and 2GB RAM, the mean response time for the 433 narrative study questions is less than 0.5 second. This indicates that our approach is able to achieve CDE retrieval in a real-time manner.

In the usage intension survey, sixteen users (included ten system users and six system developers) tried to design an eCRF using data standard compliance on our prototype system. All of users had experience in eCRF design and twelve (75.0%) users had over one year of experience (results shown in Table 2
                        ).

Twelve (75.0%) users agreed/strongly agreed that the technique of matching CDEs and eCRF needs to be improved and only two users were fine with the current technique. All of users agreed/strongly agreed that our approach was able to help them link CDEs and study questions. Two users had no comment on the time saving question and one user disagree with it; however, the others agreed/strongly that this approach should be able to save time in terms of CDE-compliance eCRF design. No one agreed/strongly agreed that our approach increases users’ confusion (results shown in Table 3
                        ).

@&#DISCUSSION@&#

The importance of using a data standard has been recognized in the clinical research field. Without standardized data, collected clinical information is not able to be further exchanged or integrated. Most study questions in CRF are narrative and therefore the collected data is able to be integrated by identifying the questions through sentence similarity detection. At the syntax level, Sadowski et al. developed a hash-based similarity detection method named SimHash [45]. While at semantic level, Li et al. proposed a sentence similarity detection approach based on semantic nets and corpus statistics [46]. However, their performance might not be accurate enough for clinical research. Therefore storing clinical data with data elements rather than a narrative text is a more feasible approach. To bridge the data standard and eCRF design, many research centers have developed tools, such as the NINDS Common Data Element Form Builder Cart [47] and the caDSR Form Builder [48]. These tools allow user leverage CDE metadata to assemble a CRF. Basically, the researchers start from the CDE perspective using the CDE browser and the researcher can then search for CDEs and then place them in a CDE cart. Finally, the researcher uses them to design the study question. If this approach is compared with our tool, it can be seen that we provided another perspective in terms of CRF designing. Our tool allows the researchers to focus on the study questions without losing data standard compliance.

For testing data, our approach has a precision of 0.84 when returning five suggested CDEs. If we increase the number of suggested CDEs, the precision will be 0.87 when returning ten suggested CDEs (with the trained Lucene score threshold set at 0.3). However, we do not recommend such an approach because the greater the number of suggested CDEs will only result in increased confusion and greater fatigue among the users and without there being a significant increase in the precision.

The evaluation results showed that our tool still had 60 missed or mistaken results. This outcome points to the limitations of our approach. The CDE suggestions are based on the query text and the CDE description. However, a CRF is sometimes conceptualized into three levels: form, section and question. For example, an ‘adverse events’ form contains an ‘adverse event information’ section and the study question of ‘start date’ indicates ‘the date of the adverse event start’. To realize the concept of the study question, the user needs to go through the structure of the CRF. Although there is a common design for CRFs, we do not recommend it because this results in limitations to the usability of the study question. In clinical research, very few CRF are able to be reused without changes across different research protocols because of the protocol-centric nature of clinical research [24].

Reusing the whole CFR is relatively limited when comparing individual study question. Therefore, libraries of study questions have been developed to support more flexible CRF design, for example, the caDSR of NCI to bank question and answer in CRFs [15] as well as the Trial/DB for similar clinical research questionnaires integration [23]. When a library of study questions is created, a complete and meaningful question text is required. Too brief question text may be the barrier within the CRF design. The other issue is the CDE description, which is for clarifying the definition of the CDE element. Thus, the CDE description needs to be clear and comprehensive and it should not just contain the expected value or only reflect the CDE title. An unclear CDE description will need more effort to integrate data, both by the researcher and by information system.

During the process of developing the CDEs, the developers need to review all of already existed CDE elements to avoid duplication. Therefore, they would need a CDE browser with a search function to support this task. The core function of our eCRF builder is a CDE information retrieval system. Compared to current CDE browsers, our approach is not only works at the syntax level but also at the semantic level. Our tool therefore should be also useful as part of CDE development.

In the usage intention survey, users provided inspiring feedback. As a suggestion providing system, most users were concerned with accuracy and response rate since this would affect the amount of time needed to complete the task and affect usability. Nevertheless, they were satisfied with our form builder and consider it to be a more intuitive eCRF design. However, the way the system listed all the CDEs when the CDE response failed was considered inadequate. It was felt that allowing the user to become involved in query refinement step in a similar manner to the advanced searching of the Gene Ontology website [49] might provide a significant improvement in terms of the current approach.

There were several limitations in this study. Firstly, this is a prototype and it has not been officially implemented in a real clinical research environment. More surveys to determine the acceptance and feedback of users are warranted. Secondly, we evaluated our approach using the PDBP. Even though our tool was developed for general purposes, it still deserves to be evaluated when applied to a range of different categories of CDEs. The results from such investigations ought to help with system enhancement and continual CDE knowledge base building; this will be part of our future work.

@&#CONCLUSIONS@&#

This study developed a multi-technique approach and demonstrated the approach by implementing a CDE-based eCRF builder that is able to help researchers constructing an eCRF, and use this to collect data that is not only compatible with the CDE content standard, but also allows for further computable semantic interoperability of the data. This approach to enforcing CDEs usage as part of eCRF design may also facilitate working interoperability. The utilization of the multi-technique during the development of the tool was also demonstrated and the results of an evaluation revealed a satisfactory performance. Nevertheless, two issues still need to be improved in the future. The first is the need to implement a better way of developing unambiguous CDEs, while the second is the development of a more precise and user-friendly tool for reusing CDEs.

@&#ACKNOWLEDGMENTS@&#

The authors thank the National Institute of Neurological Disorders and Stroke and the Parkinson Disease Biomarker Program for open data access.

@&#REFERENCES@&#


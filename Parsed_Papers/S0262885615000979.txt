@&#MAIN-TITLE@&#Application of gradient-based edge detectors to determine vanishing points in monoscopic images: Comparative study

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An algorithm has been developed for automatic detection of vanishing points.


                        
                        
                           
                           The behavior of gradient based edge detectors has been analyzed.


                        
                        
                           
                           The results have been analyzed according to the number of vanishing points and image resolution.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Vanishing point

Thales' theorem

Monoscopic image

Discrete gradient operators

Edge detector

@&#ABSTRACT@&#


               
               
                  The detection of vanishing points in a monoscopic image is a first step to the extraction of 3D data. This article shows a partition of the image space in order to determine the type of perspective which is present, thereby allowing the determination of the vanishing point associated with each of the axes of the special reference system (X, Y, Z). Additionally, the Thales' second theorem allows us to determine the position of the vanishing points of the image and to automatize the process. An algorithm has been used with the data provided by the selected edge detector (Prewitt, Roberts, Sobel, Frei-Chen, Kirsch, Robinson 3 levels, Robinson 5 levels and Frei-Chen directional), which provides the location of the vanishing points contained on the image plane. The comparative study includes two variables: the number of vanishing points and the image resolution. The results show that in general the Prewitt's edge detector provides the best results, both positional and statistical. Increasing the image resolution improves the results, although the results obtained for a resolution of 640×480 pixels and another of 1024×768 pixels are very similar.
               
            

@&#INTRODUCTION@&#

A monoscopic image is a two-dimensional representation of a three-dimensional scene, obtained as the projection of this scene from one point of vision, giving a perspective. However, in order to use three-dimensional modeling techniques, it is necessary to obtain three-dimensional information from these images by applying photogrammetric or dimensional perspective analysis.

When the projection of a three-dimensional scene is made on a plane, the parallel lines converge in a single point called vanishing point. The knowledge of this point is key to carrying out qualitative and/or quantitative analysis of the monoscopic image. From a qualitative point of view, vanishing points can be used to group common lines in contiguous images in order to combine them, and from a quantitative point of view, vanishing points can be used for three objectives: to obtain dimensions using perspective dimensional analysis, for three-dimensional reconstruction or for the auto-calibration of the camera.

Therefore, it is necessary to define a reliable methodology for the detection of vanishing points, which is the objective of this research.

@&#BACKGROUND@&#

Models, which use a single image, need the position of the vanishing points. However, it is not always easy to determine their position accurately, quickly and reliably using computational techniques. Some of the methods developed in the last decades and their most important characteristics are shown below.

Barnard [1] proposed a method to obtain vanishing points and vanishing lines using the orientation of parallel lines and planes, such that these orientations represent a Gaussian sphere with a radius of value 1, centered on the optical center of the camera. This method has the advantage of being a finite or closed space, whereas the gradient space is infinite or open; this may present problems when using a computer since it has a finite memory space. In addition, the sphere has the same symmetry as the central projection, that is, it is symmetrical with respect to the camera's perspective (the focal point of the lens), and therefore it is necessary to know the focal length of the camera.

Magee and Aggarwal [2] propose a computationally low-cost algorithm to determine vanishing points from the extraction of the line segments of an image. The algorithm is applied to the image in order to obtain the line segments, using the following sequence: determination of the image gradient using Kirsch's operator, suppression of the non-maximum values of the results obtained, and search for the lines, applying Hough transform to these results. The vanishing points are obtained using the Gaussian sphere with a radius of value 1. The advantage of this method is that it is not necessary to know the camera's focal length, and also that it does not use any accumulator space on the Gaussian sphere; rather, the measurements are taken directly on the sphere.

Collins and Weiss [3] propose the calculation of the vanishing points as a statistical estimation problem on the sphere with a radius of 1. A unitary vector can be represented as a point on the sphere and those which share the same plane tend to be grouped on a large circle. Given that vanishing points can be characterized as an estimation of the true polar axis of the large circle taken from a point sample with size n, the determination of the vanishing point is obtained by studying its statistical distribution.

Brillault-O’Mahony [4] presents a new formulation of the accumulator space for the determination of vanishing points which allows their detection whatever their location on the image plane. He defines a transformation between the image plane and the accumulator space which maintains the expected uncertainty as a constant value; this accumulator space is isotropic and finite.

Palmer and Tai [5] use Hough's transformation in order to extract the segments of the line, as this is a robust method to detect segments of straight lines. The algorithm developed preserves accuracy while maintaining a low level of processing. The location of the vanishing point is carried out using an accumulator space on the Gaussian sphere and incorporates a statistical test in order to take into account the effects of noise and errors in parameters. The result is an algorithm which locates vanishing points accurately and efficiently.

Straforini et al. [6] propose a method for extracting lines which has lineal computational complexity and a high degree of accuracy. The lineal complexity is due to the introduction of a polar space which allows the selection of segments which converge on the same point before the calculation of the vanishing point. These characteristics allow this method to be used in real-time applications, such as the control of the movements of a robot.

Tai et al. [7] propose a method which, instead of using an accumulator space for the intersection points of the pairs of lines, calculates the probability that a group of lines will pass through the same point. This probability allows us to compare and discard the vanishing point hypotheses, which is a better discriminatory factor than the number of lines that converge at a given point, and in addition is independent of the size of the group of lines. The parameter space is open, given that the intersection point of a pair of lines can be taken from the image plane to infinity.

Lutton et al. [8] propose a method to locate three vanishing points in an image, corresponding to the three orthogonal directions of the scene. This method is based on two Hough transforms applied in cascade and consists of two steps: the first is aimed at determining the direction of the vanishing point, ignoring the hypothesis of three mutually orthogonal directions, and using this Gaussian sphere but with the parameters in the Hough space; the second step explores the assumption this hypothesis of three orthogonal directions using a second Hough transform.

McLean and Kotturi [9] present a method for the detection of vanishing points based on the description of lines on the sub-pixel level that recognizes the existence of errors in detection function and which does not need supervision or specification of arbitrary thresholds. The estimation of the vanishing point is based on a set of lineal equations as its fundamental characteristic, and does not use the end points of the line segments. Finally, the detection of the vanishing point is presented as a classification problem and is solved directly on the image plane without the use of any accumulator space technique.

Gamba et al. [10] propose an algorithm for the detection of vanishing points in complex or unstructured scenes, whose technique is based on a voting scheme which in turn is based on line grouping.

Van den Heuvel [11] presents a method based on a statistical hypothesis test that examines the intersection of combinations of three lines of the image or, instead, the three interpretation planes associated with these lines. The perpendicularity between the three main directions of the lines is taken into account from detection of the first vanishing point. Therefore, this method implies excessive computational cost and is not suitable for real-time applications.

Shufelt [12] presents two approaches to improve the performance of the methods of detection of vanishing points based on the Gaussian sphere: first, the detection of the vanishing point based on primitives, which relies on knowledge of the geometry of objects of interest to guide the search for the vanishing points on the Gaussian sphere, and second, modeling of the error of the interpretation plane to estimate the accuracy of the edge, compensating for the effects of the texture. The main contribution of the proposed methods is their use in aerial photography rather than terrestrial close range photography, as is usual.

Braüer-Burchardt and Voss [13] study the 3 methods which use segments to determine vanishing points: those based on the Gaussian sphere (GSM), those based on Thales' theorem (TCM) and finally, those which rely on the minimization of the area of the triangle (TAM) formed by the center of projection and the ends of the considered segment. They demonstrate that knowing of the position of the center of projection is not necessary, as is generally assumed, although it allows for an improvement of the final accuracy, and they conclude that there is not much difference in the accuracy obtained with the TAM and TCM methods, using an optimal reference point. However, the accuracy is double, if compared with the GSM method, where the reference point is the center of projection.

Minagawa et al. [14] propose a simple framework for the detection of both vanishing points and lines using the EM algorithm (maximum expectation). The clustering and detection phase can be seen as a problem of maximum likelihood estimation, using a mixed Gaussian density model to establish restrictions to be met by vanishing points and lines. The developed method is applied to a two-dimensional noise model and can be applied to multiple points and vanishing lines, obtaining accurate results.

Schaffalitzky and Zisserman [15] study the application of three types of geometric groupings that are commonly found in the real world: families of coplanar, equidistant and parallel lines, a pattern obtained by repeating elements by translation on a plane, and a set of elements arranged on a regular grid on a plane. These groupings can be parameterized using their geometry, calculating the vanishing lines, and from them, the vanishing points. Furthermore, these groups define a characteristic that can be used as basis for other tasks such as image connection.

Cantoni et al. [16] propose two techniques to estimate the position of the vanishing points in an image: one based on a probabilistic strategy and the other in a deterministic analysis. The first works in a polar parameter space (ρ, θ) while the second in the Cartesian space (x, y) of the image plane. Both use an accumulator space based on the Hough transform. The main advantage of using a polar space is that the parameters are limited: for an image of size M×M, ρ has a range [0, 
                           
                              2
                           
                         M[ and θ takes values in the range [0, 2π[. With respect to calculation time, the second technique is faster than the first, as it does not require solving a linear system and does not calculate the covariance values.

Rother [17] presents a method for the detection of the three mutually orthogonal directions corresponding to the vanishing points. This author uses the image plane as an accumulator space to locate the intersections of pairs of lines, but this space needs to be limited so that vanishing points in infinity can be dealt with in the same way as those found at a finite distance. For the final search of the vanishing points, he provides a camera model where the position of the principal point and focal length are within a certain range. This is used to eliminate erroneous locations of the vanishing points obtained.

Almansa et al. [18] develop a new detection algorithm that is based on Helmholtz's principle of detection and grouping of lines. This uses a detector of vanishing points with a low false alarm rate and a high level of accuracy, which needs no a priori information about the image or calibration parameters of the camera, and requires no parameter setting. The proposed method has limitations when applied to images where there are no vanishing points or these are difficult to detect.

Aguilera et al. [19] present a method for the detection of vanishing points combining some tried techniques applied in three steps: grouping of mini-segments from edge detection to form the vanishing lines, estimation and calculation of the position of the vanishing points. The estimation step uses a modification of the method of the Gaussian sphere to discriminate erroneous lines and obtain a first approximation of the vanishing points. In the last step a statistical estimator is used together with the minimization of the triangle formed by the end points of the vanishing line and the perspective from which the image was taken (which coincides with the optical center of the lens) to obtain the final position of the vanishing points.

Wildenauer and Vincze [20] present a robust algorithm for the detection of vanishing points in man-made environments which extracts the dominant vanishing directions under a range of conditions. Without knowledge of camera parameters, the algorithm is effective in finding regular structures in ‘human’ environments.

Kalantari et al. [21] propose a simple and robust geometry that allows efficient extraction of the vanishing point without a priori information of the scene and without knowing the internal parameters of the camera used. These authors used the Gaussian sphere to determine the vanishing planes containing line segments detected and grouped by the vanishing point to which they belong. This point is found the line of intersection of these planes, one end of which is the center of the sphere. The novelty is that the distance between the sphere and the image plane is arbitrary, since the focal length of the camera is unknown.

Kalantari et al. [22] describe a method for automatic detection of vanishing points in urban images based on Thales' theorem. The main advantage of this procedure is the automatic and simultaneous detection of all the vanishing points from the detection of circles in a cloud of points, which correspond to the line segments extracted from the image. To extract these circles these authors use a RANSAC (RANdom SAmple Consensus) method. The calculation of the uncertainty of the location of the selected vanishing point is obtained from the variance–covariance matrix of each segment, the result being a temporarily efficient algorithm compared with the methods based on the Gaussian sphere.

Tardif [23] develops an algorithm based on the simultaneous estimation of multiple models. This is a non-iterative solution of the simultaneous estimation of the vanishing points of an image from a minimum set of edges. The method represents the edges in the Gaussian sphere and then obtains the results and errors on the image plane.

Mirzaei and Roumeliotis [24] present an analytical method for the calculation of mutually orthogonal vanishing points in a ‘Manhattan’-type world with a calibrated camera. They apply a classifier of lines based on RANSAC which, from triple lines, generates all hypotheses of the three orthogonal vanishing points in one operation.

Yin and Hao [25] propose a method for detecting vanishing points in images obtained with a mobile phone. Based on existing methods for the detection of base lines of text and the orientation of the slope of characters, they present a fast and robust two-stage procedure: rapid detection of candidates for vanishing points by clustering on the Gaussian sphere, and detection of the final vanishing points with a hybrid approach that combines the results obtained by the clustering and analysis of the projection.

Bazin and Pollefeys [26] present a method that forces the orthogonality of vanishing points by incorporating orthogonality conditions in the model estimation step in the RANSAC procedure, which allows real-time applications. The model is estimated from only three lines corresponding to the theoretical minimum for the estimation of rotation, and which they call 3-line RANSAC. The algorithm is based on the Gaussian sphere, as the internal orientation parameters of the camera are known. Therefore, it is a method with low complexity for real-time processing.

This research continues a study already begun by the authors [27], but studying in greater depth some of the initial objectives. Among these are:
                           
                              1.
                              Show different methods of detection of vanishing points following an extensive review of the literature.

Improve the algorithm developed based on Thales' second theorem [22], implementing new operators based on the gradient which use directional masks (Kirsch, Robinson 3 levels, Robinson 5 levels and Frei-Chen directional) which join with those already implemented (Prewitt, Roberts, Sobel y Frei-Chen).

Verify whether the discretization of the gradient direction provided by directional edge detectors improves the results.

Analyze the influence of the selected type of operator for edge detection in the results, according to two variables: the number of vanishing points and image resolution.

The object of study was the same as that used in the original research article, the C5 building of Campus Las Lagunillas, University of Jaen (Fig. 1
                        ) and the three photographs used in the original study (Fig. 1b, c, d).

The same work stages have been followed as in the previous study:
                           
                              1.
                              
                                 Taking photographs, determining the location and the orientation of the photographic perspectives according to the type of perspective needed.


                                 Photograph processing using an algorithm developed for the automatic detection of vanishing points according to the flow diagram (Fig. 2
                                 ). The algorithm has been developed in Borland Delphi, which allows us to use high level language (Object Pascal) and undertake programming oriented to objects. This programming environment allows the development of complex applications without the need to know C and C++. In addition, it can be used on 32 and 64 bit platforms and with different operating systems such as Windows XP, Vista, 7 or 8. The algorithm improves the previous version [27] including a module for determining the type of perspective that improves the extraction of lines from the support regions and incorporates new directional edge detectors based on the gradient. The main points of the reference [27] were: edge detection, extraction of the support regions lines, classification of application the support regions lines according to orientation of gradient, extraction of lines, application of Thales' second theorem to obtain the cloud of points Hi and calculation of the vanishing points position.


                                 Results analysis, both positional and statistical for each of the photographs, depending on the type of edge detector selected and the resolution of the image.

There are two types of physical edges: those defined by an abrupt change in the local orientation of the surface defining an object, and those which describe the boundary between two or more physically distinct regions of the physical surface of an object [28].

In the case of a photograph, an edge separates adjacent regions which have different characteristics, such as luminance, reflectance, color or texture, so that an edge in the image may not coincide with a physical edge.

Edge detection methods can be classified into: Gradient-based and Laplacian-based [29]. In this paper a comparative study of eight operators based on the gradient is performed; four of them have already been studied in previous research by the authors (Prewitt, Roberts, Sobel and Frei-Chen), and four new directional operators (Kirsch, Robinson 3 Levels, Robinson 5 Levels and Frei-Chen directional) which will provide a broad spectrum of behavior of all gradient-based operators.

Papari and Petkov [30] performed a complete state of the art of other edge detectors that allowed to distinguish between edges and contours. The extraction of both elements will allow to make full 3D models from monoscopic images once vanishing points are known in future research developments.

The clusters of pixels extracted by the edge detector selected do not ensure local similarity, as they can include pixels with a different orientation due to a slight discrepancy in the orientation of the gradient at the corners or joins where lines meet.

To overcome this drawback Burns et al. [31] propose using two sets of overlapping fixed partitions, one with the origin at 0° and the other with the origin at 22.5°. Thus, when one partition cuts a line on the edge of the partition, the other will tend to place it within a partition without fragmenting [27].

To improve the performance of algorithm developed [27] the non-maximum suppression proposed by Canny [32] is incorporated, allowing a thinner-line-support region by improving the definition of the line. The attributes which define the line are extracted from this group of pixels (Fig. 3
                           ).

Given that Canny defines the non-maximum suppression procedure for the directions 0°, 45°, 90° and 135°, which correspond to the partition with origin at 0°, it is necessary to define this procedure for the directions 22.5°, 67.5°, 112.5° and 157.5°, associated with the partition with origin at 22.5°.

The principal axis of the support region of the line allows the definition of the attributes of the associated line [31,33,34].

An important contribution is the incorporation into the algorithm presented [27] of the module for determining the type of perspective from the attributes of the extracted lines.

The choice of type of perspective is made a priori and automatically, allowing the selection of the set of lines that will be involved in the calculation of the position of the associated vanishing point.

Using the attributes of the line, its general equation can be defined as:
                              
                                 (1)
                                 
                                    ax
                                    +
                                    b
                                    y
                                    +
                                    c
                                    =
                                    0
                                 
                              
                           and, from Eq. (1), it is possible to determine its position in a cylindrical system of coordinates (ρ, θ, c):
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                ρ
                                                =
                                                
                                                   
                                                      
                                                         a
                                                         2
                                                      
                                                      +
                                                      
                                                         b
                                                         2
                                                      
                                                   
                                                
                                                =
                                                1
                                             
                                          
                                          
                                             
                                                θ
                                                =
                                                arctg
                                                
                                                   a
                                                   b
                                                
                                             
                                          
                                          
                                             
                                                c
                                                =
                                                c
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

In this way the lines are represented in a limited region called polar space [6], which allows us to partition the image space, where the points located in the same region of the image space correspond to lines which converge in a single vanishing point (Fig. 4
                           ), where:
                              
                                 •
                                 Sector V contains all the vertical lines.

Sector H contains the horizontal lines.

Sector C contains the lines which pass through the center of the image.

Sector L contains the lines which are grouped on the left vanishing point.

Sector R contains the lines which are grouped on the right vanishing point.


                           Fig. 5
                            shows the application of the partition of the image space to the northwest facade of the building C5 of the Las Lagunillas Campus of the University of Jaen.

The classification of the lines provided by the partition of the image space can establish rules (Fig. 6
                           ) to determine the type of perspective of the image [6] and it is possible to define four different types of perspective projections:
                              
                                 1.
                                 Orthographic projection: there is no vanishing point because the object is flat and is taken parallel to the image plane.

Non-central projection: no vanishing point is within the limits of the image.

Central projection: one vanishing point is near the center of the image and the other two are at infinity.

Almost central projection: one vanishing point is at the edge of the image and the other two can be considered to be at infinity.


                           Section 1.1 shows a comprehensive review of methods for detecting vanishing points developed in recent decades. Many of them perform the search for vanishing points using a 3D image coordinate system, whose origin is in the point of view of perspective.

In this research, a method to analyze images from different media is developed: in non-calibrated cameras and in graphical libraries existing on the Internet. Therefore, we selected a method using a 2D image coordinate system with its origin at the principal point of the image which does not require the knowledge of the focal length of the camera. This method is developed by Kalantari et al. [22] based on Thales' second theorem to calculate the vanishing points. Fig. 7
                            shows the flow diagram for determining the vanishing points.

The point cloud Hi is obtained by applying Thales' second theorem to the lines drawn. Their spatial distribution corresponds to three circles through the origin of coordinates adopted (top left corner of the photograph), and which correspond to the vanishing points in the image; therefore, the vanishing points are found on these circles adjusted to the point cloud Hi.

This adjustment is done in two phases [35]. First, adjusting an initial circle to the point cloud Hi associated to the vanishing point using the method of minimization of algebraic distance, and a second phase, using the initial circle as seed, where the method of minimization of geometric distance is applied iteratively to find the circles that best match the selected point cloud Hi 
                           [27].

@&#RESULTS@&#

The results shown below were obtained after applying the algorithm developed for photographs with one vanishing point (spatial Y axis) and with two vanishing points (spatial X and Y axes), disregarding the data associated with the special Z axis as the vanishing point is considered to be at infinity.


                     Figs. 8 to 10
                     
                     
                      show the position obtained for the vanishing points according to the operator used for edge detection (Prewitt, Roberts, Sobel, Frei-Chen, Kirsch, Robinson 3 levels, Robinson 5 levels and Frei-Chen directional), as well as the approximate location obtained using the graphic intersection of lines method.

@&#DISCUSSION@&#

In this section the results obtained after applying edge detectors to Figs. 8–10 are analyzed, focusing on two aspects: the edge detector applied and the image resolution.

From the coordinates of the vanishing points provided by the algorithm that make reference to the circles adjusted to the point cloud (Hi), statistical treatment with the IBM SPSS Statistics software (v.19) has been performed. To compare these results, they have been shown in box-plot graphs.

In Fig. 8, the edge detectors which provide the coordinates which are closest to the positions estimated by the graphic intersection of lines are those of Prewitt (PW) and Roberts (RB). However, the data obtained with Prewitt's detector have a smaller dispersion (Fig. 11
                           ) in statistical terms.


                              Fig. 12
                               shows how the Frei-Chen directional edge detector (FC2) gives the best results from a statistical point of view, presenting the least dispersion. However, the coordinates given by Prewitt's operator (PW) are closest to the estimated solution (Fig. 9), although with a greater statistical dispersion. It should be noted that there was a large dispersion of results obtained using Roberts' detector (RB) and Kirsch directional (KR).


                              Fig. 13
                               shows that there is a greater dispersion in the data obtained for the X coordinate than for the Y coordinate. From a statistical point of view the edge detectors with the best results are Roberts (RB) and Kirsch directional (KR). However, Fig. 9 shows that the edge director which gives the position of the vanishing point which is closest to the estimated position is Prewitt (PW). Therefore, it is considered that Roberts' edge detector (RB) is the solution that presents a better balance between positional and statistical solution.


                              Fig. 14(a) shows that the dispersion of the values obtained for the X coordinate is high because the lines extracted for the determination of the position of the vanishing point have little inclination with respect to the horizontal. This explains that in Fig. 10 the coordinates obtained for the vanishing point show a wide dispersion with respect to the estimated position.

In Fig. 10 it can be seen that the edge detectors used provide the coordinates of the vanishing point closest to those estimated; Prewitt (PW), Roberts (RB) and Robinson 5 Levels (R5N) offer the best coordinates. However, Fig. 15
                               allows us to discriminate statistically which gives the best result.

Thus, it can be seen that the Prewitt's detector (PW) has the lowest dispersion and rules out those of Roberts and Robinson 5 levels. We also noticed that the Frei-Chen edge detectors (FC and FC2 directional) have a wide dispersion of results.


                           Fig. 16
                            shows that the boxes are asymmetric with a downward bias, where the minimum is to be found. It is interesting to note the similarity between the cases represented in both figures for the resolution of 160×107 pixels, which indicates that the performance of values is almost identical and independent of the coordinate. However, configuration of the box-plot graphs of resolution 640×428 and 1024×682 pixels is very similar, so that increasing the resolution does not substantially improve the results, although the best symmetry of the statistical distribution of the data given by the resolution of 1024×682 pixels allows us to highlight it as the optimal resolution.


                              Fig. 17
                               shows the similarity between the boxes represented in both figures for the resolution of 160×107 pixels, with an almost identical performance. The resolutions of 640×480 and 1024×768 pixels show a statistically similar performance, but the coordinates of the vanishing point obtained with the higher resolution are closer to the estimated position (Fig. 9). Considering also that the resolution of 1024×768 pixels also has a smaller statistical dispersion, we can conclude that it provides the best solution.


                              Fig. 18
                               shows that the statistical behavior of the data is similar to that described for Fig. 17. Therefore, the optimal resolution for the calculation of the coordinates of the vanishing point is 1024×768 pixels.


                              Fig. 19
                               shows that the dispersion of the data is very similar in all resolutions, for both the X and Y coordinates. Therefore, increasing the image resolution does not improve the results obtained.


                              Fig. 20
                               shows that the dispersion of the data decreases with increasing image resolution; 1024×768 pixels is the best resolution to obtain the coordinates of the vanishing point.

After analyzing the results obtained with the sample images (Fig. 1), the algorithm has been applied to other images with similar geometric properties in order to check their validity.

In the case of a central projection (Fig. 21
                        ), the position of the vanishing point is located very close to that estimated in Fig. 8.

For almost central projection (Fig. 22
                        ), the position of the vanishing points is similar to that obtained in Fig. 10. The location of the right vanishing point (spatial X axis) cannot be established rigorously because the lines extracted are nearly parallel, as in Fig. 10.


                        Fig. 23
                         shows the application of the algorithm to an image with three vanishing points. The results are similar to those of Fig. 9. Despite the possible existence of a third vanishing point corresponding to the spatial Z axis, the algorithm indicates that this vanishing point is at infinity as the number of lines extracted is very low and they have little inclination relative to this axis.

Thus, the algorithm has repeatability in the results.

@&#CONCLUSIONS@&#

In this paper, we have presented different methods for detecting vanishing points in monoscopic images, using an algorithm based on Thales' second theorem applied to photos with different resolutions and numbers of vanishing points.

The research focuses on the comparison of 8 gradient-based operators for edge detection: Prewitt, Roberts, Sobel, Frei-Chen, Kirsch, Robinson 3 levels, Robinson 5 levels and Frei-Chen directional. The influence of the number of vanishing points and the image resolution on the results obtained have been analyzed.

The methodology followed is accurate, reliable and simple, so that the determination of the vanishing points does not require a large computational effort, contrary to what is necessary for edge detection and line extraction when the resolution of the image is increased.

The following conclusions can be drawn from the study:
                        
                           •
                           The use of line attributes eliminates edges that do not contribute to the search for the vanishing point, as well as false edges.

Determining the type of perspective facilitates the classification of the point cloud Hi, associating them directly to a single vanishing point.

The improvement of the classification of the Hi points allows the algorithm to be more efficient.

In general, Prewitt's edge detector provides the best results, both positional and statistical.

Increasing the image resolution improves the results, although the difference between the results obtained with a resolution of 640×480 pixels and another of 1024×768 pixels are very similar. Therefore, it is necessary to find a compromise between accuracy and the computational cost of using high resolution images.

When the extracted straight lines have little inclination to the spatial axis associated to the vanishing point, the results are not satisfactory.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Globally rotation invariant multi-scale co-occurrence local binary pattern

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This paper proposes a globally rotation invariant multi-scale co-occurrence of LBPs (MCLBP).


                        
                        
                           
                           The proposed MCLBP can effectively capture the correlation between the LBPs in different scales.


                        
                        
                           
                           Three globally rotation invariant encoding methods are introduced for MCLBP.


                        
                        
                           
                           The proposed MCLBP performs very well on texture, material, and medical cell classification.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multi-scale co-occurrence LBP

Globally rotation invariant

Locally rotation invariant

Texture classification

@&#ABSTRACT@&#


               
               
                  This paper proposes a globally rotation invariant multi-scale co-occurrence local binary pattern (MCLBP) feature for texture-relevant tasks. In MCLBP, we arrange all co-occurrence patterns into groups according to properties of the co-patterns, and design three encoding functions (Sum, Moment, and Fourier Pooling) to extract features from each group. The MCLBP can effectively capture the correlation information between different scales and is also globally rotation invariant (GRI). The MCLBP is substantially different from most existing LBP variants including the LBP, the CLBP, and the MSJ-LBP that achieves rotation invariance by locally rotation invariant (LRI) encoding. We fully evaluate the properties of the MCLBP and compare it with some powerful features on five challenging databases. Extensive experiments demonstrate the effectiveness of the MCLBP compared to the state-of-the-art LBP variants including the CLBP and the LBPHF. Meanwhile, the dimension and computational cost of the MCLBP is also lower than that of the CLBP_S/M/C and LBPHF_S_M.
               
            

@&#INTRODUCTION@&#

Texture cue plays an important role in many vision applications, including scene understanding, object recognition, content-based image retrieval, medical image analysis, image segmentation, and more. Due to the existence of strong rotation, illumination, and scale variations, effective description of texture information is challenging.

Local Binary Pattern (LBP) [1] shows great success on many texture-related tasks due to its strong texture discrimination and robustness to image transformations including rotation and gray-scale variations. Meanwhile, besides of texture [2–7] and material classification [8,9], the LBP and its variants have been widely applied to many applications, including face recognition [10], face detection, flower recognition [9], image retrieval, lip reading [11], and dynamic texture classification [12]. A detailed survey about the LBP and its variants can be found in [13].

To capture texture information in different image resolutions, a multi-scale strategy [2,14,8,4,5] has been introduced. Firstly, LBP histogram features are extracted separately from each scale. Then, the histograms in all scales are concatenated into a final image representation. The same multi-scale strategy are used by the LBP and most of its variants. Since the multi-scale strategy usually achieves better performance than a single scale, it is widely recognized as an indispensable means to achieve the state-of-the-art performance.

However, the classical multi-scale strategy ignores correlation among different scales. As shown at the left panel of Fig. 1
                     , a single-scale LBP pattern depicts a kind of local image structure, but the LBP patterns in multiple scales jointly depict a stronger local structure, as shown at the right panel of Fig. 1. In fact, texture patterns in different scales around the same central point usually have strong correlation. Ignoring such correlation will lead to a huge loss of discriminative information.

To capture the correlation between different scales, we propose to jointly encode the LBPs in different scales. We summarize our key contributions as follows:
                        
                           •
                           We propose a globally rotation invariant multi-scale co-occurrence LBP (MCLBP) feature for texture-relevant tasks. In contrast to the classical multi-scale LBP (MS-LBP), our MCLBP can effectively encode the correlation that is ignored by MS-LBP. Compared to the single-scale LBP, the MCLBP can depict stronger local structures and capture richer patterns.

We investigate the rotation invariant property of the MCLBP and introduce three simple and effective rotation invariant encoding methods. Specifically, we partition all MCLBP patterns into different groups according to the properties of the co-patterns. For each group, we can extract a rotation invariant feature using the introduced encoding methods.

We fully evaluate the properties of the MCLBP on five challenging databases. The proposed method achieves superior performance compared to the state-of-the-art LBP variants, such as CLBP_S/M/C [4], LBPHF_S_M [6]. It also greatly improves the performance of our previous conference version (MSJ-LBP). It should be noted that, compared to some powerful LBP variants, the computational cost and feature dimension of the proposed feature is also much lower. The matlab source code of the proposed MCLBP can be downloaded from this link.
                        1
                     
                     
                        1
                        
                           https://www.dropbox.com/s/cl6lv8k0uk82dey/MCLBP.zip.
                     
                  

@&#RELATED WORKS@&#

LBP is an effective texture descriptor that can depict local structures of natural images, such as edge, contour and flat region. For each pixel in an image, its LBP pattern can be computed as follows:
                           
                              
                                 L
                                 B
                                 P
                                 
                                    
                                       s
                                       →
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          k
                                          =
                                          0
                                       
                                       
                                          n
                                          −
                                          1
                                       
                                    
                                    
                                       ϕ
                                       
                                          
                                             
                                                v
                                                k
                                             
                                             −
                                             
                                                v
                                                c
                                             
                                          
                                       
                                       
                                          2
                                          k
                                       
                                    
                                 
                                 ,
                                 
                                 ϕ
                                 
                                    x
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                             ,
                                          
                                          
                                             x
                                             ≥
                                             0
                                          
                                       
                                       
                                          
                                             0
                                             ,
                                          
                                          
                                             x
                                             <
                                             0
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              s
                              →
                           
                           =
                           
                              n
                              r
                           
                           ,
                           n
                         is the number of neighbors and r is the radius of the neighbors. v
                        
                           c
                         is the gray value of the central pixel, and v
                        
                           k
                         is the pixel value of its k-th neighbor. ϕ(.) is a sign function.

In [2], Ojala et al. observed that these patterns with very few spatial transitions described the fundamental properties of the image, and they called these patterns as “uniform patterns.” The number of spatial transitions can be calculated as follows:
                           
                              
                                 Φ
                                 
                                    
                                       L
                                       B
                                       P
                                       
                                          
                                             s
                                             →
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          
                                             ϕ
                                             
                                                
                                                   
                                                      v
                                                      k
                                                   
                                                   −
                                                   
                                                      v
                                                      c
                                                   
                                                
                                             
                                             −
                                             ϕ
                                             
                                                
                                                   
                                                      v
                                                      
                                                         k
                                                         −
                                                         1
                                                      
                                                   
                                                   −
                                                   
                                                      v
                                                      c
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where v
                        
                           n
                         equals to v
                        0. The uniform patterns are defined as the patterns with Φ(LBP(s))≤2. For instance, LBP patterns “00000000” and “00001110” are the uniform patterns, while “00100100” and “01001110” are non-uniform patterns.

The uniform LBP (LBP
                        
                           U
                        ) depends on the start point of the binary sequence. Here, we denote LBP
                        
                           U
                        (s,
                        i) as the uniform LBP pattern on the scale s with i as the start point of the binary sequence, where 0≤
                        i
                        ≤
                        n
                        −1.

To achieve good robustness to image rotation, Ojala et al. also introduced the concept of rotation invariant LBP (LBP
                        
                           RI
                        ) and rotation invariant uniform LBP (LBP
                        
                           RIU
                        ), of which LBP
                        
                           RIU
                         is popularly used for texture classification. The LBP
                        
                           RIU
                         can be defined as:
                           
                              
                                 L
                                 B
                                 
                                    P
                                    
                                       R
                                       I
                                       U
                                    
                                 
                                 
                                    
                                       s
                                       →
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      k
                                                      =
                                                      0
                                                   
                                                   
                                                      n
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   ϕ
                                                   
                                                      
                                                         
                                                            v
                                                            k
                                                         
                                                         −
                                                         
                                                            v
                                                            c
                                                         
                                                      
                                                   
                                                   ,
                                                
                                             
                                          
                                          
                                             Φ
                                             
                                                
                                                   L
                                                   B
                                                   P
                                                   
                                                      
                                                         s
                                                         →
                                                      
                                                   
                                                
                                             
                                             ≤
                                             2
                                          
                                       
                                       
                                          
                                             n
                                             +
                                             1
                                             ,
                                          
                                          
                                             otherwise
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        
                     

For the number of neighbors n
                        =8, LBP has 28
                        =256 patterns, in which there are 58 uniform patterns as shown in Fig. 2
                         and 198 non-uniform patterns. Usually, all 198 non-uniform patterns are summarized into one pattern. Thus, in practice, LBP
                        
                           U
                        (8,1) has 59 patterns. According to the definintion of rotation invariant uniform LBP, the LBP
                        
                           RIU
                        (8,1) has 10 patterns.

After the LBP work, many LBP variants have been proposed and applied to different vision applications including face recognition, dynamic texture classification, scene classification, and medical image analysis. In [15], Tan et al. proposed a local ternary pattern (LTP) for face recognition. LTP is more insensitive to noise than the original LBP. To achieve rotation invariance, Ahonen et al. [16] proposed an effective LBP histogram fourier (LBPHF) feature. In [5], Guo et al. proposed an LBP variant (LBPV) descriptor to depict the local contrast information. To incorporate the sign and magnitude information, Guo et al. [4] introduced a completed LBP (CLBP) and demonstrated its superior performance in texture classification. Partly motivated by the CLBP, Zhao et al. [4] extended the LBPHF and introduced a LBPHF_S_M to fuse the sign and magnitude information. In [17], a novel linear configuration pattern (LCP) was introduced to explore multi-channel discriminative information of both the microscopic configuration and local features. Recently, there are several co-occurrence features introduced, including co-occurrence of adjacent LBP (CoALBP) [18], pairwise rotation invariant LBP (PRICoLBP) [9] and multi-scale joint encoding of LBP (MSJ-LBP) [19]. The CoALBP is sensitive to image rotation. And, as we will point out later, PRICoLBP and MSJ-LBP achieves rotation invariance by locally rotation invariant encoding approaches. Besides of abovementioned variants, there are still many other LBP variants including dominant LBP (DLBP) [20] and LBP difference (LBPD) [21].

Multi-scale strategy is widely used in the LBP and its variants including LBPV, CLBP, and LBPHF_S_M, and it usually boosts the classification performance of the descriptors. For instance, three scales (LBP(8, 1), LBP(16, 2), and LBP(24, 3)) [2] significantly improves the performance of the single scale for the texture classification task. Similar with the traditional LBP, most LBP variants (CLBP, LBPHF_S_M, LBPV, LCP) also use the multi-scale strategy and also obtain substantial improvement. The multi-scale strategy has been widely recognized as an indispensable means to achieve superior performance.

However, regardless of the performance improvement brought by the multi-scale strategy, the abovementioned multi-scale strategy ingores the correlation between the patterns in different scales. Take the multi-scale LBP as an example; first, the LBP histogram is built in each scale invidividually, then the features in all scales are concatenated into the final features. In this encoding strategy, the correlation between different scales can not be captured. Fortunately, this paper will introduce a descriptor that can effectively capture such correlation.

In Section 3.1, we quantitatively analyze the correlation existing in the multi-scale LBPs. Due to the existence of the strong correlation, in Section 3.2, we introduce a multi-scale co-occurrence of LBP (MCLBP) to capture the correlation. Then, in Section 3.3, we design three effective rotation invariant encoding methods for the MCLBP. Section 3.4 conducts a detailed analysis of the relationship between the MCLBP and the existing LBP variants. Finally, in Section 3.5, we introduce the classifiers used in this paper.

As indicated before, each LBP pattern characterizes a local structure, but its discriminative power is limited by its small described region. For instance, LBP(8, 1) corresponds to a 3×3 region. Though the multi-scale strategy can be used to depict multi-scale information, the traditional multi-scale method ignores the correlation between different scales. There exist strong correlations between the LBPs in different scales. Ignoring the correlation will lead to a huge loss of discriminative information. As shown in Fig. 1, the patterns in multiple scales jointly reflect a strong local structure.

In this subsection, we will quantitatively investigate the correlation between the LBPs in different scales. We will use information entropy and mutual information to measure the correlation between the LBP in different scales. In information theory, entropy is used to measure the uncertainty of a random variable. In [22], Shannon defines the information entropy of a discrete random variable as:
                           
                              
                                 H
                                 
                                    X
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       N
                                    
                                 
                                 −
                                 p
                                 
                                    
                                       x
                                       i
                                    
                                 
                                 
                                    log
                                    b
                                 
                                 p
                                 
                                    
                                       x
                                       i
                                    
                                 
                                 ,
                              
                           
                        where p(x
                        
                           i
                        ) is the probability of variable X of i-th state, N is the number of possible states, and b is typically set to be 2, e, or 10.

Similarly, the joint information entropy of two variables can be defined as:
                           
                              
                                 H
                                 
                                    X
                                    Y
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          y
                                          ∈
                                          Y
                                       
                                    
                                 
                                 −
                                 p
                                 
                                    x
                                    y
                                 
                                 
                                    log
                                    b
                                 
                                 p
                                 
                                    x
                                    y
                                 
                                 ,
                              
                           
                        where p(x,
                        y) is the joint probability distribution function of X and Y.

Mutual information is an effective method to characterize the correlation between variables. It provides an effective measurement to characterize the mutual dependence of the two random variables. The mutual information can be defined as:
                           
                              
                                 I
                                 
                                    X
                                    Y
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          x
                                          ∈
                                          X
                                       
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          y
                                          ∈
                                          Y
                                       
                                    
                                 
                                 p
                                 
                                    x
                                    y
                                 
                                 
                                    log
                                    b
                                 
                                 
                                    
                                       
                                          p
                                          
                                             x
                                             y
                                          
                                       
                                       
                                          p
                                          
                                             x
                                          
                                          p
                                          
                                             y
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where p(x,
                        y) is the joint probability distribution function of X and Y, and p(x) and p(y) are the marginal probability distribution functions of X and Y, respectively. The mutual information can also be denoted as I(X,
                        Y)=
                        H(X)+
                        H(Y)−
                        H(X,
                        Y). Larger I(X,
                        Y) means stronger correlation between X and Y. In machine learning, mutual information has been used as a criterion for feature selection and feature transformations.

In this paper, we made a quantitative analysis of texture correlation between the LBPs in different scales based on the Outex_00012 dataset [23]. For instance, for each image, we can build a 256-D histogram for LBP(8,1). With a 256-D L
                        1 normalized histogram, we can compute H(LBP(8,1)) according to the definition of entropy. For the co-occurrence pair, such as the co-occurrence pair between LBP(8,1) and LBP(8,2), each point can be assigned into one co-pattern in all 256×256=65,536 co-patterns, thus we can also build one 65,536-D co-occurrence histogram for each co-occurrence pair. With the L
                        1 normalized co-occurrence histogram, we can also compute its entropy H(LBP(8,1),
                        LBP(8,2)). The I(LBP(8,1),(8,2))=
                        H(LBP(8,1))+
                        H(LBP(8,2))−
                        H(LBP(8,1),
                        LBP(8,2)). All other relevant statistics are shown in Table. 1
                        .

From Table 1, we have the following two key observations:
                           
                              •
                              The LBP patterns in different scales have strong correlation. The big values of the mutual information between the LBPs in different scales validate this observation.

With the increase of the distance, the correlation decreases. For example, the correlation between LBP(8, 1) and LBP(8, 2) is much higher than that between LBP(8, 1) and LBP(8, 3).

Compared with single-scale LBP, the joint encoding of multi-scale LBPs has two obvious advantages. Firstly, multi-scale LBPs depict larger regions, thus they can capture stronger structures. Secondly, the joint encoding of multi-scale LBPs can capture richer patterns. For instance, for LBP(8, 1), it has 256 patterns. But for the co-occurrence of LBP(8, 1) and LBP(8, 2), it has 65,536 co-patterns. Thus, if well encoded, the multi-scale co-occurrence of LBPs will have strong discriminative power.

According to [22], mutual information is an effective correlation measurement method of two variables. Correlation existing between two scales provides a theoretical basis for the joint encoding of two scales. If two variables are independent, joint encoding of them is meaningless because the joint distribution can be separated into two individual marginal distributions. However, on the other hand, strong correlation usually means high redundancy. For instance, if two variables are 100% correlative, joint encoding of both of them equals to encoding one of them. Thus, it is difficult to directly give a relationship between the discriminative power and correlation (the quantity of mutual information). It will be interesting to investigate the relationship between correlation and discriminative power in the experiments.

In natural images, 58 uniform LBP patterns account for most percentage of the 256 patterns. As pointed out by [2], the ratio is about 80%–90%. Thus, instead of the original LBP, we will only use uniform LBP though our method can be directly applied to the original LBP.

First, the LBP
                        
                           U
                         pattern for each point in each scale is calculated. Then, the multi-scale co-occurrence of LBP
                        
                           U
                         (MCLBP) can be denoted as follows:
                           
                              (1)
                              
                                 CoLB
                                 
                                    P
                                    
                                       U
                                       U
                                    
                                 
                                 
                                    
                                       
                                          s
                                          →
                                       
                                       1
                                    
                                    
                                       
                                          s
                                          →
                                       
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       
                                          L
                                          B
                                          
                                             P
                                             U
                                          
                                          
                                             
                                                
                                                   s
                                                   →
                                                
                                                1
                                             
                                             i
                                          
                                          ,
                                          L
                                          B
                                          
                                             P
                                             U
                                          
                                          
                                             
                                                
                                                   s
                                                   →
                                                
                                                2
                                             
                                             i
                                          
                                       
                                    
                                    
                                       c
                                       o
                                    
                                 
                                 ,
                              
                           
                        where i can be fixed to be any one between [0,
                        n
                        −1]. Here, we just set it to 0. 
                           
                              
                                 s
                                 1
                              
                              →
                           
                         and 
                           
                              
                                 s
                                 2
                              
                              →
                           
                         denote two scales. [ , ]
                           co
                         is a co-occurrence operator firstly introduced in [24]. Suppose LBP
                        
                           U
                        (8,1) and LBP
                        
                           U
                        (8,2) have 59 patterns, then their co-occurrence has 59×59=3,481 patterns.

Thus, for each point, its MCLBP pattern can be denoted as one of the 3481 patterns. Note that the above multi-scale co-occurrence patterns are rotation variant. However, if we carefully arrange these patterns into different groups, we can find some interesting phenomenon. Fig. 3
                         shows two example groups of multi-scale co-occurrence LBPs. When the images rotate, the pattern only changes to another one in the same group.

We divide all 3481 co-patterns into 443 groups according to the properties of these co-patterns, as illustrated in Fig. 4
                        . We explain the underlying intuitions for the group division strategy as follows:
                           
                              •
                              (a). We consider two adjacent scales as “inner scale” and “outer scale.” Both scales have 8 neighbors. Thus, they both have 256 LBP patterns, and the 256 patterns can be divided into 58 uniform patterns and 1 non-uniform pattern (the other 198 non-uniform patterns).

(b). The 58 uniform patterns can be divided into “00000000,” “11111111,” and the 56 other uniform patterns (This is motivated by Fig. 2.). The “00000000” or “11111111” denotes one group itself, and the other 56 uniform patterns form 7 groups with 8 patterns in each group. Thus, all 58 uniform patterns can be divided into 9 groups. This division is mainly due to the consideration of image rotation. When the image rotates, the LBP pattern will only change to another pattern in the same group.

(c). If the patterns in both inner and outer scales come from the “56U,” this number of this kind of co-patterns is 56×56=3136 in total. According to Fig. 3, we know that 8 co-patterns will form one group, thus, there will be 3136/8=392 groups formed by this kind of co-occurrence pair (co-occurrence of “56U” and “56U”). Similarly, if the inner pattern comes from the “56U,” and the outer pattern comes from “00000000,” there will be 56×1=56 co-patterns. The 56 co-patterns will form 56/8=7 groups. In this way, we can finally construct 443 groups as shown in Fig. 4.

Once the multi-scale co-pattern of each pixel has been calculated, an image can be represented as a histogram probability distribution P of all 3481 patterns. Again, such a histogram is rotation variant, i.e., the histograms for the same image under different rotations would be significantly different. However, if we only consider the histogram of patterns in the same group as shown in Fig. 3, useful information can be derived about the variance of the distribution under different image rotations. Fig. 5
                         illustrates the distribution variation of the patterns from one group when the image rotates 45 degrees. As we can find, the distribution circularly shifts to the right one bin. These kinds of rules can be fully used to generate a rotation invariant feature.

Let G
                        
                           i
                         denote the i-th group, P(G
                        
                           i
                        ) denotes the probability distribution of the co-patterns in the same group. Suppose G
                        
                           i
                         has eight patterns, then, the dimension of P(G
                        
                           i
                        ) is 8. Denote the feature extracted from the distribution P(G
                        
                           i
                        ) as F
                        
                           i
                        , and denote the feature extraction function as f, then we have
                           
                              (2)
                              
                                 f
                                 :
                                 P
                                 
                                    
                                       G
                                       i
                                    
                                 
                                 →
                                 
                                    F
                                    i
                                 
                                 .
                              
                           
                        
                     

For each group G
                        
                           i
                        , we can extract a feature F
                        
                           i
                         according to the function f. The final feature F representing the image I can be denoted as follows:
                           
                              (3)
                              
                                 F
                                 =
                                 
                                    
                                       
                                          F
                                          1
                                       
                                       ,
                                       
                                       
                                          F
                                          2
                                       
                                       ,
                                       ......
                                       ,
                                       
                                       
                                          F
                                          
                                             K
                                             −
                                             1
                                          
                                       
                                       ,
                                       
                                       
                                          F
                                          K
                                       
                                    
                                 
                                 ,
                              
                           
                        where K is the number of the groups. According to Fig. 4, K equals to 443.

Many methods can be used to encode the histogram distribution. Some may have strong discriminative power, but sensitive to image rotation, and vice versa. A desirable feature extraction function should have good balance between the discriminative power and transformation invariance. In this paper, we propose three rotation invariant encoding methods for this purpose.

Image rotation will change one pattern in one group to another pattern in the same group, but the cumulative probability of all patterns in a group will not change. Thus, we can define the following feature extraction function 
                              F
                              
                                 
                                    1
                                    →
                                 
                                 i
                              
                            for group G
                           
                              i
                            as:
                              
                                 (4)
                                 
                                    F
                                    
                                       
                                          1
                                          →
                                       
                                       i
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                
                                                   N
                                                   i
                                                
                                             
                                          
                                          p
                                          
                                             
                                                G
                                                
                                                   i
                                                   j
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where N
                           
                              i
                            is the number of patterns in group G
                           
                              i
                           ,
                           p(G
                           
                              ij
                           ) is the probability of j-th pattern in i-th group out of all co-patterns. For instance, Fig. 3 shows two groups. Each group has 8 patterns, it means N
                           
                              i
                            equals to 8. In this example, G
                           
                              i
                            corresponds to the group with 8 patterns and G
                           
                              ij
                            means the j-th pattern in this group.
                              Remark
                              Sum pooling is an effective way to capture the cumulative probability in a group. As we have indicated before, regardless of how many degrees the image rotates, the pattern will only turn into another pattern in the same group. Thus, the cumulative probability of this group will not change. Thus, sum pooling is robust to image rotation.

With the image rotating, the probability distributions of all patterns in one group circularly rotate. In such a probability set, moment-based pooling can be used to extract the invariant feature from such a group. The function can be defined as:
                              
                                 (5)
                                 
                                    F
                                    
                                       
                                          2
                                          →
                                       
                                       i
                                    
                                    =
                                    
                                       
                                          m
                                          ,
                                          
                                          
                                             σ
                                             1
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                
                                                   N
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   p
                                                   
                                                      
                                                         G
                                                         
                                                            i
                                                            j
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      m
                                                      
                                                         N
                                                         i
                                                      
                                                   
                                                
                                             
                                             2
                                          
                                       
                                    
                                    ,
                                 
                              
                           where N
                           
                              i
                            is the number of patterns in group 
                              
                                 G
                                 i
                              
                              ,
                              
                              m
                              
                              =
                              
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    
                                       N
                                       i
                                    
                                 
                                 
                                    p
                                    
                                       
                                          G
                                          
                                             i
                                             j
                                          
                                       
                                    
                                    ,
                                    
                                       σ
                                       1
                                    
                                 
                              
                            is a parameter to control the ratio between the 0-th moment and 1-th moment.
                              Remark
                              The proposed moment-based feature extraction method not only captures the cumulative probability in a group but also reflects the relative variance between each bin and the mean distribution.

In the work [16], Ahonen et al. firstly proposed to use Fourier transformation to achieve a rotation invariant feature from the uniform patterns. Motivated by this, we can calculate the discrete Fourier transform (DFT) of all patterns' distributions in a group as follows:
                              
                                 (6)
                                 
                                    H
                                    F
                                    
                                       k
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             j
                                             =
                                             0
                                          
                                          
                                             
                                                N
                                                l
                                             
                                             −
                                             1
                                          
                                       
                                    
                                    p
                                    
                                       
                                          G
                                          
                                             l
                                             j
                                          
                                       
                                    
                                    
                                       exp
                                       
                                          
                                             −
                                             i
                                             2
                                             π
                                             j
                                             k
                                          
                                          
                                             N
                                             l
                                          
                                       
                                    
                                    ,
                                    
                                    k
                                    =
                                    0
                                    ,
                                    .....
                                    ,
                                    
                                       N
                                       l
                                    
                                    −
                                    1
                                 
                              
                           where N
                           
                              l
                            is the number of patterns in group G
                           
                              l
                           .
                           p(G
                           
                              lj
                           ) is the probability of the j-th pattern in the l-th group out of all co-patterns.

After obtaining the DFT of group G
                           
                              l
                           , the magnitude for HF(k) can be calculated as:
                              
                                 (7)
                                 
                                    M
                                    
                                       k
                                    
                                    =
                                    
                                       
                                          H
                                          F
                                          
                                             k
                                          
                                          
                                             
                                                H
                                                F
                                                
                                                   k
                                                
                                             
                                             ¯
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Since the last N
                           
                              l
                           
                           −1 terms are sysmatric, thus, the final Fourier transformation histogram can be denoted as:
                              
                                 (8)
                                 
                                    F
                                    
                                       
                                          3
                                          →
                                       
                                       l
                                    
                                    =
                                    
                                       
                                          M
                                          
                                             0
                                          
                                          ,
                                          
                                          ....
                                          ,
                                          
                                          M
                                          
                                             
                                                
                                                   N
                                                   l
                                                
                                                /
                                                2
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                           
                              Remarks
                              Theoretically, the Fourier transformation pooling is invariant to the rotation degree of the times of 360/n. However, in practice, the natural images are always captured under arbitrary angles.

All 3841 co-patterns can be divided into 443 groups. Thus, the dimension of the sum encoding method is 443 for one co-occurrence pair, and the dimension for moment-based pooling is 886. According to the DFT encoding strategy, the dimension for DFT-based method is 2179. Like the CLBP [4], we also define center gray level MCLBP (MCLBP/C). In MCLBP/C, we divide the image into two parts according to the average gray value of the whole image, and then extract MCLBP features for both parts, and finally, concatenate these two features into the final MCLBP/C feature. Then, the feature dimension for MCLBP/C is two times of the original MCLBP.

There are two ways to achieve rotation invariance: locally rotation invariant encoding and globally rotation invariant encoding. The properties of these two encodings can be summarized as follows:
                           
                              •
                              
                                 Locally rotation invariant (LRI) encoding: locally rotation invariant encoding approaches achieve rotation invariance by estimating the rotation invariant pattern for each point in the image, and accumulates the pattern frequencies into the final rotation invariant histogram. This type includes the original LBP [2], CLBP [4], PRICoLBP [9], MSJ-LBP [19], etc. Most rotation invariant LBP variants belong to LRI.


                                 Globally rotation invariant (GRI) encoding: Instead of estimating rotation invariant pattern for each point, the GRI encoding estimates a rotation invariant histogram from an initial non-rotation invariant histogram. As far as we know, this type contains MCLBP, LBPV [5], and LBPHF_S_M [6]. For example, the LBPV aligns the histograms by the pricinpal orientations. The LBPV and LBPHF_S_M focus on a single LBP point, whereas our MCLBP focuses on the multi-scale co-occurrence of LBPs.

It is clear that the GRI MCLBP is different from its LRI counterparts in nature. Meanwhile, compared to the LBPHF_S_M, the proposed MCLBP focuses on multi-scale co-occurrence of LBPs, but LBPHF_S_M only encodes a single LBP point. The co-occurrence of LBPs has a stronger discriminative power than a single LBP point. There are many LBP variants that only focus on improving the discriminative power of the descriptors, but ignore the rotation invariance of the descriptors, such as LCP [17], DLBP [20], DLBP [25], LGBPHS [26], LBP-TOP [12], CENTRIST [27], mCENTRIST [28], CoALBP [18], and etc.

For classification, χ
                        2 kernel proves to perform well and is widely used. The used χ
                        2 kernel similarity between histogram features X and Y can be calculated as follows:
                           
                              
                                 S
                                 
                                    X
                                    Y
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       N
                                    
                                 
                                 
                                    
                                       2
                                       
                                          X
                                          i
                                       
                                       
                                          Y
                                          i
                                       
                                    
                                    
                                       
                                          X
                                          i
                                       
                                       +
                                       
                                          Y
                                          i
                                       
                                    
                                 
                                 ,
                              
                           
                        where N is the dimension of X and Y. In this paper, to fairly compare with previous works [4,19,6], the same classifier (NN or SVM) was used. We use the Vlfeat [29] to conduct fast computations, such as similarity computation. For SVM, instead of carefully tuning the parameters, we use the Libsvm [30] tool with fixed C=100 for all experiments.

We firstly evaluated the properties of the proposed feature on Outex_TC_00010 (TC10), Outex_TC_00012 (TC12), and CUReT datasets, and then applied it for Protein Cellular Classification [31] and Flickr Material Classification [32].

The used Outex database contains two test suites: TC10 and TC12. Both test suites consist of 24 categories of textures that were collected under three different illuminations (horizon,inca, and t184) and nine different rotation angles (0°, 5°, 10°, 15°, 30°, 45°, 60°, 75°, and 90°). Twenty non-overlapping texture samples with windows size 128×128 are obtained from a given source image, assuming the texture sample spans over the whole image. The experimental setups are as follows: 1). TC10 uses the samples of illuminations “inca” and angle 0 of each class for training and the other eight rotation angles with the same illuminations for testing. Therefore, there are 480 (24×20) training samples and 3840 (24×20×8) testing samples. 2). TC12 uses the same training samples as TC10 and uses all samples captured under illuminations “t184” or “horizon” for testing. Hence, there are 480 (24×20) training samples and 4320 (24×20×9) testing samples for each illumination.


                     CUReT 
                     [33] is a widely used texture dataset. We use the same subset as [34]. The subset consists of 61 classes with 92 images per class. These images are captured under different illuminations from seven different viewing directions. The changes of viewpoint under different illumination greatly varies the texture appearance. Following [34], we use 46 samples per class for training and 46 for testing. Fig. 6
                      shows some examples from TC10, TC12, and CUReT.

Since the proposed MCLBP is designed to encode the joint distribution of LBPs on multiple scales, the most relevant competitor is the classical MS-LBP [2]. We use rotation invariant uniform MS
                        −
                        LBP
                        
                           RIU
                         in this paper because the LBP
                        
                           RIU
                         has better robustness to image rotation than the original LBP and uniform LBP (LBP
                        
                           U
                        ). Besides the MS-LBP, we also compare our MCLBP with some other powerful LBP variants, such as LBPHF [16], DLBP [20], LCP [17], LBPV [5], CLBP [4],
                           2
                        
                        
                           2
                           
                              http://www4.comp.polyu.edu.hk/cslzhang/code/CLBP.rar.
                         and LBPHF_S_M [6].
                           3
                        
                        
                           3
                           
                              http://www.ee.oulu.fi/gyzhao/Download/Codes/LBPHF_S_M.zip.
                         To facilitate readers to reproduce results reported in this paper, we provide matlab source code for the MSJ-LBP
                           4
                        
                        
                           4
                           
                              https://www.dropbox.com/s/6bozay2wx8j3iml/MSJLBP.zip.
                         and MCLBP.
                           5
                        
                        
                           5
                           
                              https://www.dropbox.com/s/cl6lv8k0uk82dey/MCLBP.zip.
                        
                     

As indicated before, the nearer scales have stronger correlation, but strong correlation does not mean strong discriminative power. Thus, it is interesting to investigate the relationship between the discriminative power and correlation. Here, we evaluate six co-occurrence pairs and conduct the comparison experiments on TC10, TC12, and CUReT datasets. For fair comparison, we use the sum encoding strategy for the whole experiments. The experimental results are shown in Table 2
                        .

We have the following two findings from Table 2: 1). All co-occurrence templates work well. For instance, the MCLBP with the co-occurrence pair (r
                        1
                        =1)+(r
                        2
                        =3) achieves superior performance on TC12 even without using the center pixel information. 2). Rather than the nearer scale pair, the co-occurrence pairs with larger distance perform much better. We believe that the nearer scale pair has much redundant information, but the farther scale pair has much more complementary information than the nearer scale pair.

According to our abovementioned observations, we would like to suggest that the co-occurrence between LBP(8, 1) and LBP(8, 3), and the co-occurrence between LBP(8, 1) and LBP(8, 4) are two proper choices for the co-occurrence pairs.

In Section 3, we have presented three rotation invariant encoding methods for MCLBP. In this subsection, we will conduct experiments to compare them on TC10, TC12 and CUReT datasets. We use the same co-occurrence pair (r
                        1
                        =1and
                        r
                        2
                        =3) for all three encoding methods in all experiments. The experimental results are shown in Table 3
                        .

The following two observations can be made from Table 3.
                           
                              •
                              The sum and moment encoding methods outperform the Fourier-based pooling. As indicated before, in theory, Fourier-based pooling is only invariant to the rotations of the times of 360/n degrees. But in practice, the images contain richer rotation angles. For instance, the rotation directions in TC12 contain 0, 5, 10, 15, 30, 45, 60, 75, and 90 degrees. However, the Fourier-based method is not robust to those rotation directions. Compared with the Fourier-based pooling, the sum and moment pooling are more robust to this kind of image rotations.

With comparable performance to the moment-based encoding method, the dimension of the sum encoding method is only half of the moment-based method. Meanwhile, the sum has much better performance than the Fourier-based method but only with about one fifth of the dimension of the latter.

The classical MS-LBP and our previous MSJ-LBP are the most relevant approaches to our MCLBP. The MS-LBP method individually encodes each scale, and the MSJ-LBP jointly encodes multiple scales by locally rotation invariant encoding, but the MCLBP jointly encodes multiple scales by globally rotation invariant encoding. Here, we conduct experiments to directly compare these three approaches to validate the effectiveness of the proposed MCLBP. For our MCLBP and MSJ-LBP, we use eight neighbors for all used scales, but for MS-LBP, we use the widely used configurations. For instance, in "(r
                        1
                        =1)+(r
                        2
                        =3)" in Table 4
                        , we use LBP(8, 1) and LBP(8, 3) for MSJ-LBP and MCLBP and use LBP(8, 1) and LBP(24, 3) for MS-LBP. The experiments are conducted on TC10, TC12 and CUReT datasets. For convenience, we only use the sum pooling strategy. The experimental results are shown in Table 4.

We have the following two observations from Table 4:
                           
                              •
                              The MCLBP significantly outperforms the MS-LBP on all three data sets. For example, on TC12, our MCLBP outperforms MS-LBP for about 6% on “t184” test set and more than 10% on “horizon” test set. The effectiveness of the MCLBP fully proves that multi-scale co-occurrence of LBPs is highly useful.

When the data sets have strong image rotation, such as TC10 and TC12, the MCLBP greatly outperforms the MSJ-LBP. When the data sets do not contain image rotation, MCLBP and MSJ-LBP achieve comparable performance.

In this subsection, we evaluate the computational cost of our feature and compare it with two powerful LBP variants (CLBP_S/M/C, LBPHF_S_M/C). For the CLBP and LBPHF_S_M, we use LBP(8, 1), LBP(16, 2), and LBP(24, 3).

Theoretically, the CLBP_S/M/C, LBPHF_S_M/C should have the similar computational cost, which comes from the interpolations of the neighbors and the computation of LBP patterns. To evaluate the running efficiency, we run the codes on 1000 images with 200×200 on a desktop with Intel Dual-core i7 3.2G CPU, 8GB memory, and Matlab R2012b, and report the average running time. The results, along with the feature dimension of the evaluated features, are shown in Table 5
                        .

According to Table 5, we have the following two observations:
                           
                              •
                              Our feature extraction achieves significantly better efficiency than the CLBP_S/M/C and the LBPHF_S_M/C. Our feature is about six times faster than the CLBP_S/M/C, LBPHF_S_M/C. The high efficiency of our feature is mainly due to the fact that our MCLBP needs fewer interpolations than CLBP_S/M/C and LBPHF_S_M/C. Being constructed on two scales (e.g. LBP(8, 1) and LBP(8, 3)), our MCLBP needs to compute the interpolations for 8 points, while the CLBP_S/M/C, LBPHF_S_M/C (LBP(8, 1), LBP(16, 2), and LBP(24, 3)) need to compute the interpolations for 72 points.

The dimension of our feature is the lowest compared with the CLBP_S/M/C and the LBPHF_S_M/C. When sum pooling was used, our feature's dimension (443) is significantly lower than that of the CLBP_S/M/C (2200) and is slightly lower than that of the LBPHF_S_M/C (956).

In this subsection, we will compare the proposed feature with some state-of-the-art methods (including some powerful LBP variants and some non-LBP-based methods). For our MCLBP, we use two multi-scale co-occurrence pairs (LBP(8, 1) and LBP(8, 3), and LBP(8, 1) and LBP(8, 4)) on all three data sets.

The compared LBP variants include MS-LBP, LBPV, DLBP, LBPHF_S_M and CLBP, non-LBP-based methods include VZ_MR8 and VZ_Joint that have proven to be effective on texture classification task. The results for all features are shown in Table 6
                           . The results of LBPHF_S_M and CLBP are based on three scales (LBP(8, 1), LBP(16, 2), and LBP(24, 3)).

From Table 6, we have the following four observations.
                              
                                 •
                                 Compared with our MCLBP, our MCLBP/C further improves the performance. This proves the effectiveness of the center gray level.

Our MCLBP/C achieves the best performance among all evaluated features. For instance, compared with CLBP/C, our MCLBP/C achieves about 0.5% improvement on TC10 and 3% improvements on TC12. Our MCLBP/C also outperforms the new published LBPD [21] on TC12.

The LBPHF_S_M works quite poorly on TC10 and CUReT. This may explain why the Fourier encoding strategy achieves the worst performance among all three proposed encoding strategies.

The non-LBP-based methods (VZ_MR8 and VZ_joint) work well on CUReT, but perform poor on TC10 and TC12. Our MCLBP/C obtains slightly higher performance than them on CUReT, and performs much better on TC10 and TC12. Although MCLBP/C shows better performance on these datasets, it should be noted that using the intensity of center pixel will reduce robustness to illumination variations and may decrease the classification performance.

To fully evaluate MCLBP, we further test it when only a small number of training samples are available. On CUReT, following the strategy applied in [4], we use 46, 23, 12, and 6 training samples, respectively, and use the remaining images for testing. The results are shown in Table 7
                           . For TC10 and TC12, the standard methods use 20 images from each category for training. Here, without changing the testing samples, we reduce the training samples to 10 or 5 images. For the 10 training samples, we separate the 20 images into two folds and use each fold for training individually, and test on the testing samples. We average the experimental results. The results for TC10 and TC12 are shown in Table 8
                           .

In Table 7, VZ_MR8 is a learning-based algorithm that requires many training samples to create the dictionary. According to [4], when the training samples are not enough, the performance will drop a lot. In contrast, LBPHF_S_M, CLBP_S/M/C, and our method are not sensitive to the number of training samples. Meanwhile, our method achieves the best performance among all evaluated features.

From Table 8, it is easy to find out that LBPHF_S_M, CLBP_S/M/C, and MCLBP/C are robust to the decrease of the training samples, i.e., the performances of these features do not drop too much with the decreased training samples. Meanwhile, we can see that our MCLBP/C achieves the best performance on all training/testing configurations.

The 2D Hela dataset [31] has 862 single-cell images from ten categories: Actin Filaments, Endosome, ER, Golgi Giantin, Golgin GPP130, Lysosome, Microtubules, Mitochondria, Nucleolus, and Nucleus. Each image is a 16-bit grayscale image with image size 512×512. In Fig. 7
                           , we show four categories from this dataset. Following [25], we use a 5-fold cross-validation technique with SVM classifier with χ
                           2 kernel as Eq. (9) which was implemented with Libsvm tool [30]. Compared with RBF kernel (two parameters), the χ
                           2 kernel as Eq. (9) only needs to choose the regularization parameter C. The performance is shown in Table 9
                           .

In the Table 9, the LPQ denotes the local phase quantization descriptor which is based on quantizing the Fourier transformation phase in local neighborhoods, and the EQP is an operator conducted on an elliptic neighborhood.

We can find that the proposed method significantly outperforms LBP
                           
                              P,R
                           
                           
                              ri
                           ,
                           LTP
                           
                              P,R
                           
                           
                              riu2, LQP, and EQP, and achieves slightly better performance than the dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                            
                           [25].

Compared with dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                           , our MCLBP/C has the following advantages. Firstly, the dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                            is a discriminative feature learning method which may be sensitive to the number of training images, but our method does not. Secondly, due to the learning strategy used in dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                           , the dimension of dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                            increases with the categories. Thus, the dis(S
                           +
                           M)
                              P,R
                           
                           
                              ri
                            requires large computational cost when the number of categories is large. However, our MCLBP does not have such a problem.


                           Experiments on Flickr Material Dataset (FMD) is a challenging material database, which consists of ten categories, i.e., fabric, foliage, glass, leather, metal, paper, plastic, stone, water, and wood. Each category has 100 images, where 50 images are close-up views and the rest 50 are of views at object-scale. In Fig. 8
                           , we show some samples from this dataset.

Liu et al. [32] did the earliest work on this database. They explored different types of features, including color, texture, micro-texture, outline shape, and reflectance-based features. All five types of features contain eight local features. Recently, Sharan et al. [39] further studied this work by comparing the classification accuracy of local features with human classification ability under different image equality. Hu et al. [40] found that using kernel SVM significantly outperforms the NN classifier on this task. Meanwhile, they applied several types of kernel descriptors on this task. Recently, Qi et al. [9] proposed an effective rotation invariant co-occurrence LBP for this task. In the work [8], Li et al. [8] proposed to enhance the material recognition through using virtual samples. Following the standard experimental setup, we use 50 samples for training and the remaining 50 for test. We repeat 100 runs and report the average performance in Table 10
                           .

From Table 10, we can observe that our MCLBP significantly outperforms single feature (Color, Jet, SIFT [42], Curvature, Micro-Jet, Micro-SIFT, Edge-ribbon and Edge-slice) in [39]. It should be noted that the computational cost for our MCLBP is significantly lower than that for other features, such as SIFT, Jet, Micro-Jet, and so on. Meanwhile, our MCLBP achieves comparable performance with [9] but with lower feature dimension and computational cost. Our MCLBP also outperforms [40] that combines five kernel descriptors features, and also significantly outperforms [8] that combines LBP and Color.

@&#DISCUSSION AND CONCLUSION@&#

This paper proposes a novel and effective texture descriptor–multi-scale co-occurrence LBP(MCLBP)–for texture-related tasks. The proposed MCLBP is computationally simple and invariant to image rotation. Compared to the classical multi-scale LBP that ignores the correlation among different scales around the center point, the MCLBP jointly encodes the local binary patterns of two scales around the center point and can effectively capture such correlation. Meanwhile, the MCLBP is globally rotation invariant, which is different from some locally rotation invariant methods including multi-scale LBP [2], CLBP [4], and MSJ-LBP [19]. The effectiveness of the proposed descriptor is validated in several challenging data sets.

@&#ACKNOWLEDGEMENTS@&#

This work was supported by the Academy of Finland and Infotech Oulu. Q. Li and L. Shen are supported by grants from Shenzhen Scientific Research and Development Funding Program (No. ZDSY20121019111146499, No. JSGG20121026111056204), and Shenzhen Dedicated Funding of Strategic Emerging Industry Development Program (No. JCYJ20121019111128765).

@&#REFERENCES@&#


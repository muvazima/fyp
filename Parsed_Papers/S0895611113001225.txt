@&#MAIN-TITLE@&#Locating the fovea center position in digital fundus images using thresholding and feature extraction techniques

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A methodology for detecting the fovea center position in fundus images is presented.


                        
                        
                           
                           The methodology was evaluated on 1200 fundus images of the MESSIDOR database.


                        
                        
                           
                           Evaluation criterion: methodology-provided and actual fovea center distance.


                        
                        
                           
                           In 93% of analyzed images, the distance remained below 1/4 of one optic disc radius.


                        
                        
                           
                           These results outperform all the reviewed methodologies available in literature.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Ophthalmic pathologies diagnosis

Fundus images

Diabetic retinopathy

Fovea location

@&#ABSTRACT@&#


               
               
                  A new methodology for detecting the fovea center position in digital retinal images is presented in this paper. A pixel is firstly searched for within the foveal region according to its known anatomical position relative to the optic disc and vascular tree. Then, this pixel is used to extract a fovea-containing subimage on which thresholding and feature extraction techniques are applied so as to find fovea center. The methodology was evaluated on 1200 fundus images from the publicly available MESSIDOR database, 660 of which present signs of diabetic retinopathy. In 93.92% of these images, the distance between the methodology-provided and actual fovea center position remained below 1/4 of one standard optic disc radius (i.e., 17, 26, and 27 pixels for MESSIDOR retinas of 910, 1380 and 1455 pixels in size, respectively). These results outperform all the reviewed methodologies available in literature. Its effectiveness and robustness with different illness conditions makes this proposal suitable for retinal image computer analyses such as automated screening for early diabetic retinopathy detection.
               
            

@&#INTRODUCTION@&#

Diabetic retinopathy (DR) is a retinal disease derived from complications caused by the abnormally high glucose level in blood produced by diabetes mellitus. Nowadays DR is the leading ophthalmic pathological cause of blindness among people of working age in developed countries [1]. Although DR is not a curable disease, laser photocoagulation can prevent major vision loss if detected in early stages [1,2]. However, DR patients usually perceive no symptoms until the later stages, when visual loss develops and treatment is less effective. All diabetic patients are at risk for DR and most of them eventually develop the illness. Therefore, annual eye fundus examination in diabetic patients becomes necessary to ensure timely treatment application [3–5]. However, this preventive protocol involves a huge challenge for health systems due to the great number of patients needing ophthalmologic revision (the estimated prevalence of diabetes for all age groups worldwide is forecasted to rise from 171 million in 2000 to 366 million in 2030 [6]).

DR is diagnosed by the examination of retinographies. This use of digital images of the retinal surface could be exploited for computerized early detection of DR. A robust system that enabled non-experts to filtrate cases of patients not affected by the disease, would reduce the specialists’ workload and increase effectiveness in preventive protocols and early therapeutic treatments. Furthermore, it would also result in outstanding economic benefits for public health systems, a cost-effective treatments associated to early illness detection have been observed to lead to remarkable cost savings [7,8].

The fovea is a small depression at the centre of the retina of about 1mm in diameter and visible as a round dark area in retinal images. The location of this retinal region is particularly important in the development of automated DR diagnosis systems because it is a diagnosis key for disease classification. The fovea is responsible for sharp central vision, usually called photopic or bright-light vision. This central portion in the retina primarily contains the cones, which are light receptors highly sensitive to color connected to their own nerve end: thus, they can resolve fine details. Therefore, the distance at which DR-related pathologies are located from the fovea influences clinical relevance and is used for illness-grade determination.

A new methodology for locating the fovea through its center position in fundus images is presented in this paper. Despite its simplicity, the accuracy achieved by this method exceeds that reported by the most accurate methods in literature. Method evaluation was performed on a wide-range database composed by 1200 retinal images, more than half of them corresponding to retinas presenting different DR grades. This is especially relevant if we keep in mind that our main aim is integrating the method into systems for automated DR diagnosis.

The rest of the paper is organized as follows. Other published solutions for fovea location are reviewed in Section 2, while the testing material used in this study is described in Section 3 and the proposed method is explained and illustrated in Section 4. Section 5 presents the obtained results and compares them to those obtained with other available methods. Finally, the authors’ conclusions put an end to this paper.

The fovea location methods reported in literature are mainly based on exploiting the fovea's visual appearance (this region is recognizable as a round area darker than its surrounding retinal tissue) and its known anatomical position in the retinal surface (on average, fovea center is located at 2.5 optic disc (OD) diameters from the OD center following the horizontal raphe of the retina [9]).

Sinthanayothin et al. [10] present a method for fovea recognition in which the fovea was assumed to be the darkest area in the fundus image, with approximately the same intensity as the blood vessels. Firstly, the fovea was correlated to a template of intensities; the template was chosen to approximate a typical fovea. Then, the location of maximum response was selected as the location of the fovea if it also was at approximately 2.5 times the diameter of the OD from the OD center. Gagnon et al. [11] use a similar approach to detect fovea center. They first generated a coarse resolution image from the original image. Secondly, they selected the darkest pixel in the coarse resolution image following the above-described distance criterion. Finally, fovea center was found by searching in the vicinity for this darkest pixel on the original fine resolution image. On the other hand, Li et al. [12] present a method for fovea location that also use its darkness and the distance criterion, but also propose the use of the vascular arch to reduce the search area. Thus, they presented a model-based approach in which an active shape model was used to extract the main course of the vasculature based on OD location. This course and the distance criterion of the fovea were used to specify a region of interest. Finally, the fovea center was obtained by applying a thresholding scheme to the region of interest. Later, a fovea automated location only by means of the distance criterion and the vascular arch is proposed in [13]. The method started by locating the OD and estimating the vascular arch by means of a parabolic model. Fovea location was ultimately inferred according to these two anatomical landmarks. A method, started with the parabolic modeling of the vascular arch, was presented in [14]. Then, using this elliptical modeling of the major retinal blood vessels, the approximate locations of the OD and the fovea were obtained. Finally, fovea position was refined according to its local darkening. On the other hand, Niemeijer et al. [15] presented a method to model the distribution of all retinal features. The method used an optimization method to fit a point distribution model to the fundus image. After fitting, the points of the model indicated the location of the normal anatomy. Subsequently, these authors presented another work on fovea detection in [16]. They first found the OD and, according to its location, an area of interest for the fovea was defined. The location with the lowest predicted distance to the fovea within this area was selected as the fovea location. Finally, Yu et al. [17] used the above-mentioned distance criterion and the vascular arch to find a region of interest where the lowest response of a template matching was selected as the fovea center position.

To evaluate the fovea location methodology described in the next section, the publicly available MESSIDOR database was used. This database
                        1
                     
                     
                        1
                        Download images section, MESSIDOR: Digital Retinal Images, MESSIDOR TECHNO-VISION Project, France [Online]: http://messidor.crihan.fr/download-en.php.
                      contains 1200 eye fundus color images of the posterior pole acquired by the Paris Hôpital Lariboisière, the Faculté de Médecine St. Etienne and the LaTIM – CHU at Brest (France). 800 of these images were captured with pupil dilation (one drop of Tropicamide at 10%) and 400 without dilation, using a Topcon TRC NW6 non-mydriatic retinograph with a 45° field-of-view (FOV). The images were digitalized to 1440×960, 2240×1488 or 2304×1536 pixels, corresponding to retina diameters of approximately 910, 1380 and 1455 pixels, respectively, and are 8 bits per color plane. All these images are provided in TIFF format.

All fundus images from this database were diagnosed by medical experts attending to a classification designed within the framework of the Messidor – Techno-Vision Project.
                        2
                     
                     
                        2
                        Methods to evaluate segmentation and indexing techniques in the field of retinal ophthalmology – TECHNO-VISION Project. Available: http://messidor.crihan.fr/index-en.php.
                      This classification grades DR into four stages (on a scale of 0–3, with 0 being normal retina) and evaluates the risk of macular edema (ME, a retinal disease closely associated to DR) into three grades (on a scale of 0–2, with 0 being no risk). According to this classification, the whole set of MESSIDOR images includes 540 cases of healthy retinas (DR grade=0; ME risk=0) and 660 cases of pathological retinas showing some DR or ME sign (DR grade≠0 or ME risk≠0). Therefore, the choice of this database allows evaluating the methodology under different illness conditions.

On the other hand, the MESSIDOR database provides no binary masks delineating retina pixels for the images (FOV masks). The use of these masks allows the application of algorithms exclusively within the retina, as well as obtaining outstanding information. For instance, for a given fundus image, retinal diameter can be easily determined by measuring the diameter of the FOV mask. As shown in Sections 4.1 and 5.1, this fact is especially relevant in this paper, as the OD diameter can be estimated from this retina size. Therefore, the FOV masks were manually generated and are publicly available in [18].

@&#METHODOLOGY@&#

The aim of this work is to introduce a new methodology for detecting the fovea center location in fundus images. It is divided into two main stages: Section 4.1 obtaining a pixel located within the fovea by using its known positional features relative to the OD and the vascular tree and Section 4.2 obtaining the fovea center position by applying thresholding and feature-extraction techniques on a fovea-containing subimage centered on the previously obtained fovea pixel. Before describing the proposed methodology, notice that all parameters used were set by experiments carried out on a local database comprising 118 digital retinal images aimed at minimizing the Euclidean distance between methodology-obtained and actual fovea center position, the latter being manually determined by an ophthalmologist. This training database was provided for this study by the Health Ministry of the Andalusian Regional Government (Spain), being available at http://www.uhu.es/retinopathy. The images were acquired with a 45° FOV, retina diameter being 640 pixels. Therefore, the application of the proposed methodology to retinas of different size (i.e., MESSIDOR ones) demands proportional adaptation of the whole set of parameters to new retina size (assuming fundus images taken with 45° FOV). This fact has already been taken into account in the methodology description presented next.

A pixel belonging to the fovea that may be considered as a first estimate of fovea center position is obtained with this methodology, which is based on the well-known fact that, from an anatomical viewpoint, fovea center is located on average at 2.5 OD diameters from the OD center following the horizontal raphe of the retina (see [9]); this is, the line of symmetry separating the superior and inferior retinal regions. This line can be determined by the orientation of the vasculature in relation to the position of the optic nerve. As mentioned in Section 2, this idea has already been exploited in other fovea location methods [10–17]. In this paper, it is applied by making use of our own OD and blood vessel segmentation methods described in [19,20], respectively.

Specifically, the required input data include the diameter and coordinates of the OD center, denoted by D
                        
                           OD
                         and (x
                        
                           OD
                        , y
                        
                           OD
                        ), as well as the vessel-segmented binary image, VT. These data, visually shown in Fig. 1
                        (a) and (b), for a MESSIDOR database fundus image, are landmarks needed to determine the horizontal raphe of the retina and ultimately find a pixel within the fovea. Note that blood vessel pixels in VT are identified as 255. In this paper, possible values of binary image pixels will be 0 or 255, as we always deal with 8-bit images.

Raphe estimation is performed by addressing the parabolic model proposed in [13], whose origin is located at (x
                        
                           OD
                        , y
                        
                           OD
                        ), through a set of vessel points, 
                           
                              S
                              
                                 
                                    VT
                                    POST
                                 
                              
                           
                        . These points are defined by a new vessel binary image, VT
                        
                           POST
                        :


                        
                           
                              (1)
                              
                                 
                                    S
                                    
                                       
                                          VT
                                          POST
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                             
                                          
                                          :
                                          
                                             VT
                                             POST
                                          
                                          (
                                          x
                                          ,
                                          y
                                          )
                                          =
                                          255
                                       
                                    
                                 
                              
                           
                        
                     


                        VT
                        
                           POST
                         is generated by applying two-step postprocessing to VT with the aim of segmenting just the main vessels from the vascular arch. Firstly, a morphological opening operation using a square structuring element whose width is W
                        1 pixels is performed. Thus, narrow vessels that are too small to contain the structuring element are broken or even eliminated if they appear as isolated regions. Secondly, the resulting 8-connected regions with less than A
                        1 pixels are eliminated to obtain the final vessel-segmented image used for raphe estimation. Both operations are illustrated in Fig. 1(c) and (d).

Considering that the methodology is confronted to a retina whose size is estimated through the diameter of the corresponding FOV mask, D
                        
                           FOV
                        , parameters W
                        1 and A
                        1 are determined as follows:


                        
                           
                              (2)
                              
                                 
                                    
                                       
                                          
                                             W
                                             1
                                          
                                       
                                       
                                          =
                                          
                                             round
                                             odd
                                          
                                          
                                             
                                                
                                                   
                                                      3
                                                      640
                                                   
                                                   
                                                      D
                                                      FOV
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             A
                                             1
                                          
                                       
                                       
                                          =
                                          
                                             1000
                                             
                                                
                                                   640
                                                   2
                                                
                                             
                                          
                                          
                                             D
                                             FOV
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where round
                        
                           odd
                         denotes an operation that rounds the input numeric result to the nearest odd integer. As stated above, the whole set of methodology parameters were fixed with the aim of contributing the best methodology performance on our 640-pixel training images (note that in this case optimum W
                        1 and A
                        1 values were found at 3 and 1000, respectively).

Once the raphe of the retina is obtained, a fovea-center estimate can be found at a fixed distance of 2.5 OD diameters from the OD center along this line (see Fig. 1(e)). To avoid possible anomalous values of the required OD diameter, the following criterion was applied:


                        
                           
                              (3)
                              
                                 
                                    D
                                    OD
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      1
                                                      5
                                                   
                                                   
                                                      D
                                                      FOV
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      D
                                                      OD
                                                      *
                                                   
                                                   >
                                                   
                                                      1
                                                      5
                                                   
                                                   
                                                      D
                                                      FOV
                                                   
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      1
                                                      10
                                                   
                                                   
                                                      D
                                                      FOV
                                                   
                                                
                                                
                                                   if
                                                   
                                                   
                                                      D
                                                      OD
                                                      *
                                                   
                                                   <
                                                   
                                                      1
                                                      10
                                                   
                                                   
                                                      D
                                                      FOV
                                                   
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      D
                                                      OD
                                                      *
                                                   
                                                
                                                
                                                   otherwise
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              D
                              OD
                              *
                           
                         stands for the experimental OD diameter obtained by [19] and D
                        
                           OD
                         is the diameter value used in the methodology. Thus, it is assessed if D
                        
                           OD
                         satisfies the assumption that OD size varies substantially from one-tenth to one-fifth of retinal diameter [21], this last being measured by D
                        
                           FOV
                        .

It should be pointed out that the presented procedure searches for a fovea-center estimate. Therefore, deviations of this estimate, caused by possible inaccuracies of the automated OD and blood vessel segmentation used as inputs are not critical in the success of this first stage of the methodology, whose purpose is just obtaining a pixel within or near enough the fovea.

The aim of this stage is the accurate detection of fovea center location by exploiting the visual appearance of this retinal region: in color fundus images, the fovea is recognizable as a round region darker than its surrounding retinal tissue.

This methodology benefits from OD diameter (D
                        
                           OD
                        ), the vessel-segmented binary image (VT) as well as from the coordinates of the pixel within the fovea obtained in the previous stage. Let us denote this pixel as (x
                        
                           fp
                        , y
                        
                           fp
                        ).

Input images to this methodology are fovea-containing subimages extracted from the green band of the RGB original retinography. These subimages are generated by centering on (x
                        
                           fp
                        , y
                        
                           fp
                        ) with a size fixed to 2D
                        
                           OD
                        
                        ×2D
                        
                           OD
                         (an example is shown in Fig. 1(f)). Considering that typical fovea radius is between 1/3 and 1/4 of one OD diameter [22], the subimages are wide enough to include the whole fovea. Moreover, this great size selection allows meeting this requirement although (x
                        
                           fp
                        , y
                        
                           fp
                        ) does not belong to the fovea (it is enough that it is near this retinal region).

Mathematically, input subimages, denoted by I, can be expressed as:
                           
                              (4)
                              
                                 
                                    
                                       I
                                       =
                                       Gb
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    
                                       
                                          
                                             (
                                             x
                                             ,
                                             y
                                             )
                                             ∈
                                             
                                                S
                                                
                                                   (
                                                   
                                                      x
                                                      fp
                                                   
                                                   ,
                                                   
                                                      y
                                                      fp
                                                   
                                                   )
                                                
                                                
                                                   2
                                                   
                                                      D
                                                      OD
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where Gb denotes the green band of a RGB fundus image and 
                           
                              S
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                              W
                           
                         stands for the set of coordinates in a W
                        ×
                        W sized squared window centered on point (x, y).

The methodology, illustrated in Fig. 2
                         for the same fundus image used in Fig. 1, comprises the following steps:
                           
                              1
                              Generating a contour map image by detecting edge pixels on different thresholded images.

Obtaining the fovea center position by applying feature extraction techniques.

The purpose of this step is finding a set of contour lines within the fovea candidates to be centered at the fovea center position. Basically, these boundary lines are generated by doing a thresholding sweep and detecting edge pixels on the resulting images. The procedure can be described as follows.

Blood vessel pixels that can be present outside the fovea in I act as strong artifacts in the process. Their green-channel intensity is approximately the same as that corresponding to fovea pixels and, if they were not taken into account, the fovea could be assumed to be the darkest area in I. Therefore, they should be erased beforehand to reduce false positives. With this purpose, a maximum filter is applied to vessel pixels to replace their gray-level values. Mathematically, this vessel tree-removed image, I
                           1, can be defined as:


                           
                              
                                 (5)
                                 
                                    
                                       I
                                       1
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            max
                                                            {
                                                            I
                                                            (
                                                            s
                                                            ,
                                                            t
                                                            )
                                                            }
                                                         
                                                         
                                                            (
                                                            s
                                                            ,
                                                            t
                                                            )
                                                            ∈
                                                            
                                                               S
                                                               
                                                                  (
                                                                  x
                                                                  ,
                                                                  y
                                                                  )
                                                               
                                                               
                                                                  
                                                                     W
                                                                     2
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      if
                                                      
                                                         VT
                                                         ROI
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      =
                                                      255
                                                   
                                                
                                                
                                                   
                                                      I
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                         
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where W
                           2
                           =
                           round
                           
                              odd
                           ((9/640)D
                           
                              FOV
                           ) and VT
                           
                              ROI
                            is the vessel-segmented binary subimage extracted from VT taking just their pixels within our region of interest:


                           
                              
                                 (6)
                                 
                                    
                                       VT
                                       ROI
                                    
                                    =
                                    
                                       
                                          VT
                                          (
                                          x
                                          ,
                                          y
                                          )
                                       
                                       
                                          
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                                ∈
                                                
                                                   S
                                                   
                                                      (
                                                      
                                                         x
                                                         fp
                                                      
                                                      ,
                                                      
                                                         y
                                                         fp
                                                      
                                                      )
                                                   
                                                   
                                                      2
                                                      
                                                         D
                                                         OD
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        


                           Fig. 2(a), illustrates the application of this vessel removal procedure to the subimage shown in Fig. 1(f).

Now noise smoothing is performed on I
                           1 by applying a W
                           3
                           ×
                           W
                           3 mean filter (see Fig. 2(b)), window size W
                           3 being set as:


                           
                              
                                 (7)
                                 
                                    
                                       W
                                       3
                                    
                                    =
                                    
                                       round
                                       odd
                                    
                                    
                                       
                                          
                                             
                                                29
                                                640
                                             
                                             
                                                D
                                                FOV
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Let us stand for this smoothed subimage as I
                           2. Next, a binary image linked to a certain threshold 
                              Th
                              ,
                              
                                 I
                                 3
                                 Th
                              
                           , is obtained by thresholding I
                           2 as follows:


                           
                              
                                 (8)
                                 
                                    
                                       I
                                       3
                                       Th
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                      
                                                         I
                                                         2
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ≤
                                                      Th
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Then, edge pixels in 
                              
                                 I
                                 3
                                 Th
                              
                            are detected to generate an edge binary image, denoted by 
                              
                                 I
                                 3
                                 
                                    
                                       Ed
                                       Th
                                    
                                 
                              
                           , according to the following equation:


                           
                              
                                 (9)
                                 
                                    
                                       I
                                       3
                                       
                                          
                                             Ed
                                             Th
                                          
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        
                                                                           I
                                                                           3
                                                                           Th
                                                                        
                                                                        (
                                                                        x
                                                                        ,
                                                                        y
                                                                        )
                                                                        =
                                                                        255
                                                                           
                                                                           
                                                                           
                                                                        and
                                                                     
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        
                                                                           
                                                                              min
                                                                              {
                                                                              
                                                                                 I
                                                                                 3
                                                                                 Th
                                                                              
                                                                              (
                                                                              s
                                                                              ,
                                                                              t
                                                                              )
                                                                              }
                                                                           
                                                                           
                                                                              (
                                                                              s
                                                                              ,
                                                                              t
                                                                              )
                                                                              ∈
                                                                              
                                                                                 S
                                                                                 
                                                                                    (
                                                                                    x
                                                                                    ,
                                                                                    y
                                                                                    )
                                                                                 
                                                                                 3
                                                                              
                                                                           
                                                                        
                                                                        =
                                                                        0
                                                                     
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Thus, several 
                              
                                 I
                                 3
                                 
                                    
                                       Ed
                                       Th
                                    
                                 
                              
                            images are generated by selecting multiple threshold values Th. The variation range of Th was set between zero and the gray-level value of I
                           2 provided by Otsu's thresholding method [23], T
                           
                              otsu
                           . Since the fovea can be assumed to be the darkest region in I
                           2, this selection makes Th take values within an interval that comprises the characteristic intensities of fovea pixels. All these images are then joined into a single image that shapes our so-called contour map image, I
                           3:


                           
                              
                                 (10)
                                 
                                    
                                       I
                                       3
                                    
                                       
                                    =
                                    max
                                    
                                       
                                          
                                             
                                                I
                                                3
                                                
                                                   
                                                      Ed
                                                      
                                                         
                                                            Th
                                                            i
                                                         
                                                      
                                                   
                                                
                                             
                                             :
                                             
                                                Th
                                                i
                                             
                                             =
                                             
                                                
                                                   4
                                                   i
                                                
                                                100
                                             
                                             
                                                T
                                                otsu
                                             
                                             ,
                                             i
                                             =
                                             0
                                             ,
                                             1
                                             ,
                                              …
                                             ,
                                             25
                                          
                                       
                                    
                                 
                              
                           
                        


                           Fig. 2(c) and (d), illustrates the results of these thresholding and edge detection steps. In (c), 
                              
                                 I
                                 3
                                 Th
                              
                            images, each one generated with its own Th value, are shown with a different gray-scale color in a single representation. On the other hand, the corresponding 
                              
                                 I
                                 3
                                 
                                    
                                       Ed
                                       Th
                                    
                                 
                              
                            images are all shown in (d). As expected, this image can be observed to include round contour lines inside the fovea.

Contour map image, I
                           3, is composed by pixel boundaries that are candidates to be centered on fovea center (see Fig. 2(d)). Now, the closed boundaries are extracted to select the one whose centroid is located at the darkest region in the green band of the RGB fundus image, G
                           
                              b
                           . According to this methodology, this centroid will be considered as the fovea center position.

The process is performed on the set of pixels 
                              
                                 S
                                 
                                    
                                       I
                                       3
                                    
                                 
                              
                           , with
                              
                                 (11)
                                 
                                    
                                       S
                                       
                                          
                                             I
                                             3
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                      ,
                                                      y
                                                   
                                                
                                             
                                             :
                                             
                                                I
                                                3
                                             
                                             (
                                             x
                                             ,
                                             y
                                             )
                                             =
                                             255
                                          
                                       
                                    
                                 
                              
                           and can be summarized as follows:
                              
                                 •
                                 Every connected region in I
                                    3 is characterized by means of the Euler number (i.e., number of connected components minus the number of holes of the region). By making use of this topological descriptor, only closed boundaries in I
                                    3 are kept (all boundaries whose Euler number is not 0 are removed). This step is illustrated in Fig. 2(e).

For each centroid of the detected closed boundaries, a W
                                    4
                                    ×
                                    W
                                    4 sized subimage is extracted from the Gb centered on it, where W
                                    4
                                    =
                                    round
                                    
                                       odd
                                    ((7/640)D
                                    
                                       FOV
                                    ). Mathematically:
                                       
                                          (12)
                                          
                                             
                                                
                                                   
                                                      IC
                                                      i
                                                   
                                                   =
                                                   Gb
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                
                                                   
                                                      
                                                         (
                                                         x
                                                         ,
                                                         y
                                                         )
                                                         ∈
                                                         
                                                            S
                                                            
                                                               (
                                                               
                                                                  x
                                                                  i
                                                                  c
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  i
                                                                  c
                                                               
                                                               )
                                                            
                                                            
                                                               
                                                                  W
                                                                  4
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             ,
                                                
                                             i
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             
                                                N
                                                c
                                             
                                          
                                       
                                    where IC
                                    
                                       i
                                     is the subimage linked to the ith centroid of coordinates 
                                       (
                                       
                                          x
                                          i
                                          c
                                       
                                       ,
                                       
                                          y
                                          i
                                          c
                                       
                                       )
                                     and N
                                    
                                       c
                                     is the number of closed boundaries.

Then, the centroid providing the minimum gray-scale mean value of its subimage is selected as the fovea center position. If no closed boundary had been detected (N
                                    
                                       c
                                    
                                    =0), the returned-method position is (x
                                    
                                       fp
                                    , y
                                    
                                       fp
                                    ) (coordinates of the pixel generated by the first stage of the methodology, described in Section 4.1). This procedure can be expressed by the following equation:


                                    
                                       
                                          (13)
                                          
                                             
                                                P
                                                cexp
                                             
                                             =
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  arg
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        i
                                                                        c
                                                                     
                                                                     ,
                                                                     
                                                                        y
                                                                        i
                                                                        c
                                                                     
                                                                     )
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        
                                                                           min
                                                                           
                                                                              i
                                                                              =
                                                                              1
                                                                              ,
                                                                              …
                                                                              ,
                                                                              
                                                                                 N
                                                                                 c
                                                                              
                                                                           
                                                                        
                                                                        
                                                                           mean
                                                                           (
                                                                           
                                                                              IC
                                                                              i
                                                                           
                                                                           )
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                            
                                                               if
                                                               
                                                                  N
                                                                  c
                                                               
                                                               ≥
                                                               1
                                                            
                                                         
                                                         
                                                            
                                                               (
                                                               
                                                                  x
                                                                  fp
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  fp
                                                               
                                                               )
                                                            
                                                            
                                                               otherwise
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    where P
                                    
                                       cexp
                                     stands for the center position coordinates.

Therefore, the application of (13) provides the point P
                           
                              cexp
                            that is considered the center fovea location (see an example in Fig. 2(f)).

@&#EXPERIMENTAL RESULTS@&#

Most of the published works designed for detecting the fovea in fundus images are evaluated by measuring the distance between the automatically obtained fovea center position and the actual position of this center [13–17]. This distance is usually expressed in function of the OD radius, which is taken as a reference measurement. This way of evaluating is justified by the lack of border definition in the fovea region.

In this paper, the so-called (1/8)R, (1/4)R, (1/2)R and 1R criteria were used as measures for method evaluation on the 1200 fundus images of the MESSIDOR database. These criteria are based on counting the number of cases where the distance between the fovea center pixel estimated by the method, P
                        
                           cexp
                        , and the actual fovea center position, P
                        
                           creal
                        , is less than (1/8), (1/4), (1/2) and 1OD radius, respectively. Let us denote this distance as D(P
                        
                           cexp
                        , P
                        
                           creal
                        ). Since OD may vary substantially in different equal-sized fundus images (according to [21], from 1/10 to 1/5 of the retinal size), OD radius, R, was fixed to its middle value to avoid distortion in result evaluation:


                        
                           
                              (14)
                              
                                 R
                                 =
                                 0.15
                                    
                                 
                                    
                                       
                                          D
                                          FOV
                                       
                                    
                                    2
                                 
                              
                           
                        where D
                        
                           FOV
                         approximates the retinal diameter value. Thus, R is set to the same value for images of the same retinal size. In our case, this value was fixed to 68, 103 and 109 pixels depending on the resolution of the analyzed MESSIDOR image: 1440×960, 2240×1488 or 2304×1536 pixels, which correspond to retinas of approximately 910, 1380 and 1455 pixels in size, respectively.

In addition, normalized distance between P
                        
                           cexp
                         and P
                        
                           creal
                         was also used to quantify algorithmic performance on a fundus image. This distance, denoted by D
                        *, is defined as:


                        
                           
                              (15)
                              
                                 
                                    D
                                    *
                                 
                                 =
                                 
                                    
                                       D
                                       (
                                       
                                          P
                                          cexp
                                       
                                       ,
                                       
                                          P
                                          creal
                                       
                                       )
                                    
                                    
                                       
                                          D
                                          FOV
                                       
                                    
                                 
                                 100
                              
                           
                        
                     

The required ground-truth set of P
                        
                           creal
                         coordinates was built using the fovea center positions manually marked by two different medical specialists. On one hand, we obtained the fovea centers for each of the 1200 MESSIDOR fundus images with the help of a local ophthalmologic specialist. On the other hand, we were provided with part of the ground-truth set used in [17], in particular, with that corresponding to the 800 MESSIDOR images from the Paris Hôpital Lariboisière and the Faculté de Médecine St. Etienne (unfortunately, authors of this work could not provide us with data from the subset of 400 LaTIM – CHU MESSIDOR images).

With the aim of quantifying the fitting between both 800-image sets of experts’ observations, the above-mentioned performance measures were computed for one of the set of human observations (used as P
                        
                           cexp
                         coordinates) using the other one as ground-truth (P
                        
                           creal
                         coordinates). Table 1
                         presents the results obtained. Although the consensus between the two observers is high for criterion (1/2)R or subsequent (the distance between the fovea center locations established by both experts is lower than (1/2)R in 98.50% of the cases), a strongly decreased agreement is observed when the most exigent criterion, (1/8)R, is considered (72.38%). Therefore, a set of actual fovea center locations more reliable than these individual sets of expert's observations is needed. This fact is specially relevant for evaluating performance under the criteria (1/8)R and (1/4)R, where the observed inter-observer variability is higher. In this paper, a ground-truth set of fovea center locations for the whole MESSIDOR database was built as follows: for the 800 images with information available from [17]'s expert and ours, by averaging the locations established by both experts; for the remaining 400 images, by using the marks of the present work's expert.

The methodology was tested on the 1200 fundus images of the MESSIDOR database using the previously defined (1/8)R, (1/4)R, (1/2)R and 1R criteria and the average normalized distance between the estimated fovea centers and ground-truths. Table 2
                        , top table, compares the evaluation results of the initial fovea center estimate generated by the first stage of the methodology and the final center position provided by the second stage (referenced in the table as Thiswork). The results are presented on sets of healthy and DR- or EM-related pathological retinas attending to the classification described in Section 3.

Analyzing the total number of cases, the methodology can be observed to provide a fovea center pixel categorized within (1/8)R, (1/4)R and (1/2)R criteria in 80.42%, 93.92% and 96.08% of the cases, respectively. These results are clearly better than those corresponding to the first fovea center estimate provided by the first stage of the methodology: only 2.50%, 10.67% and 42.50% of the cases were categorized within the mentioned criteria, the average normalized distance being much higher. Anyway, it has to be pointed out that this part of the methodology fulfills efficiently the aim of finding a pixel within or near enough the fovea: the provided pixel is located at a higher distance than 2R in only 0.83% of the 1200 analyzed images.

Next, the results obtained with the presented methodology are compared to those presented in other relevant works in literature.

Firstly, the following methods were considered for comparison purposes: Fleming et al. [14], Niemeijer et al. [15,16], Tobin et al. [13], and Yu et al. [17]. All these methods are briefly commented in Section 2. The first was evaluated according to the 1R criterion. On the other hand, Tobin et al. [13] and Yu et al. [17] used 2 and (1/2) times the OD radius as referential measurements, respectively (i.e., 2R and (1/2)R criteria). Concerning the methodologies reported by Niemeijer et al. [15,16], a fixed distance was used as a reference: that is, according to image resolution and the FOV size used, this distance is approximately equal to that established by the 1R criterion. Table 3
                         shows the results of this performance comparison. Notice that these results are presented as reported by their authors using their own fundus image databases. With the exception of the MESSIDOR database, used in [17] and in the present work, the remaining databases are not publicly accessible, their images being obtained from screening DR programs [14–16] or ophthalmologic practices [13]. Therefore, our algorithm could not be tested on them. Although an overview of the values presented in Table 3 shows that our method reaches better performance than the other fovea center detection techniques, comparison could not be carried out under identical conditions and thus no solid conclusions can be drawn.

For the sake of rigorousness, we compared the performance provided by our approach to that achieved by the methodologies of Niemeijer et al. [16] and Yu et al. [17] on the 800 MESSIDOR images from the Paris Hôpital Lariboisière and the Faculté de Médecine St. Etienne, using our ground-truth set of fovea center positions. This experiment could be carried out thanks to the authors of these papers sent us the coordinates of the fovea centers produced by their algorithms on the whole set of 1200 MESSIDOR images for Niemeijer et al. and on these above-mentioned 800 images for Yu et al. Table 2, bottom table, presents this performance comparison. The location performance contributed by any of the human observer sets used to build the ground-truth locations is also presented, helping to set a goal for the methodologies’ performance. Performance achieved by Yu et al. [17]'s methodology is observed to strongly decrease when the most exigent criteria, (1/8)R and (1/4)R, are considered. In this methodology, the grid of the template matching applied for fovea detection was set to (1/4)R, which may explain this performance loss. Thus, Niemeijer et al. [16] and our proposed methodologies reach better performance at these criteria.

These two most-accurate methods are also compared in the top table of Table 2 on the whole set of 1200 MESSIDOR images. An overview of the results presented in Table 2 shows that the methodology by Niemeijer et al. [16] provides a higher number of fovea centers separated from the ground-truth fovea center by a maximum distance of (1/2)R or 1R, especially when pathological retinas are considered. However, our algorithm proves more accurate when the referential distance of the applied quality criterion is lower. Thus, our proposal clearly renders better overall performance, in healthy and pathological retinas, at the most exigent considered criteria, (1/8)R and (1/4)R, which are of major interest in this framework of developing methodologies for accurately locating the fovea center position in a fundus image. In order to draw a clearer picture on the effectiveness of these methods, we can analyze their performance in terms of the normalized distance between the estimated fovea center and the one considered as ground-truth. The corresponding average values, presented in the last column of Table 2, clearly show that the fovea centers generated by our approach tend to be located at a lower distance from the actual ones.

@&#CONCLUSIONS@&#

A method for locating the fovea in retinal digital images by detecting its center position is presented in this paper. According to the known geometrical position of the fovea relative to the optic disc (OD) and vasculature, the method firstly obtains a pixel within or near enough this retinal region. Then, a fovea-containing region of interest, centered on this pixel, is extracted. Since the fovea can be identified as the darkest round area in this region, its center is located by applying thresholding and feature extraction techniques.

The methodology was tested on 1200 fundus images from the MESSIDOR database. This database was selected because, apart from being public, it is composed by a large number of retinographies classified according to diabetic retinopathy (DR) grade and macular edema (ME) risk. Specifically, the set of tested images include 540 healthy and 660 DR- or ME-related pathological retinas. Thus, the methodology can be evaluated on a huge number of clinical cases of interest within the framework of automated diagnoses of these retinal diseases. Regarding the evaluation criterion, the distance between the estimated fovea center and the actual one, established by two different experienced ophthalmologists, was measured for each fundus image. Specifically, referential distances 1/8, 1/4, 1/2 and 1 times the OD radius (measured from the real center position of the fovea) were selected to set a quality scale.

The proposed methodology provided a pixel separated from the true fovea center by a maximum distance of (1/8) and (1/4) OD radius in 80.42% and 93.92%, respectively, of the 1200 of analyzed cases (Table 2). According to the methodological comparison in Tables 2 and 3, these results are systematically higher than those achieved by the reviewed fovea-location approaches available in literature. Note that although comparison results in Table 3 could not be carried out on the same set of images, since the authors evaluated their different published methodologies on their own not publicly available databases, performance comparison in Table 2 was carried out under identical conditions. For the sake of facilitating rigorousness in future method comparisons, the coordinates of the fovea centers used in this paper as ground truth for each of the 1200 MESSIDOR images analyzed are available in [18]. Moreover, the manually generated FOV masks are also at researchers’ disposal.

In addition, method simplicity should also be highlighted. The performance results obtained on a massive digital retinal database indicate that simple methods based on basic image processing techniques seem to suffice for fovea location. These results demanded very short computational time. In spite of dealing with high resolutions images (1440×960, 2240×1488 and 2304×1536), average time to process a single image was 0.940s (standard deviation of 0.547s). Its effectiveness and robustness, together with its fast implementation, make this proposed automated fovea location method a suitable tool to be integrated into a complete prescreening system for early DR detection.

@&#REFERENCES@&#


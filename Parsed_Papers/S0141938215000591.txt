@&#MAIN-TITLE@&#Implementation of 21:9 cinema mode function using two ICs supporting full HD resolution

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A 21:9 cinema mode function is implemented by using two ICs that support full HD.


                        
                        
                           
                           We propose efficient information change and computation scheme between two ICs.


                        
                        
                           
                           This scheme has an advantage of reducing the SOC development cost.


                        
                        
                           
                           Not only the 2560×1080 but also can be applied to the 4K×2K resolution.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

21:9 Cinema mode

Stereoscope

Plasma Display Panel

Halftone

Sub-field

Master and slave communication

@&#ABSTRACT@&#


               
               
                  After the appearance of digital broadcasting, realistic images such as 3D and high resolution broadcasting are rapidly developing and evolving. And, recent trend emphasizes not only viewing the information but also using it through the display media. To keep up with this trend, large size display manufacturers are trying to support resolution beyond the full HD, in order to display additional information and high definition broadcasting at the same time. In this paper, we present a 21:9 cinema mode resolution (2560×1080) function using two ICs that support full HD for Plasma Display Panels (PDPs) which is one of the largest flat display panels. In order to achieve this, we first set the master and the slave between the two ICs, and propose an efficient information exchange and computation scheme using serial communication that links the master and the slave. Furthermore, we realize the cinema function with 21:9 resolution through image quality processing and operational parameter exchange and computation in the boundary that is set between the master and the slave. Finally, the cinema mode image realized using the hardware circuit board is demonstrated.
               
            

@&#INTRODUCTION@&#

After the appearance of digital broadcasting, realistic images such as 3D and high resolution broadcasting are rapidly developing and evolving. The display media receives digital TV technology and network based broadcasting signals, and displays various information including SNS and Web surfing in the same scene through bi-directional communication. This shows the display media is not only used for viewing the information but also emphasizes the aspects of using it. To keep up with this trend, large size display manufacturers are putting a lot of effort on supporting resolution beyond the full HD (FHD, 1920×1080) in order to display additional information or realize high definition broadcasting [1].

Several examples are Ultra HD (UHD) 2K (2048×1080) and 4K (3840×2160 or 4096×2160). Fig. 1
                      shows the comparison of display resolutions beyond the FHD. By using a 2560×1080resolution display, the service provider can show the HD broadcasting to the customers, and at the same time, can display additional information in the blank space or use the full screen to express the image for an incoming cinemascope input image. To meet those expectations, a Korean company exhibited a 226.7cm panorama type UHD display with 21:9 ratio at the SID (Society for Information Display) 2014 which was held in San Diego, USA. Based on this fact, we can expect the increasing demand of the 21:9 cinema type for large size displays.

In this paper, a function that can support the 2560×1080 resolution with 21:9 (2.35:1 wide screen or cinemascope [2]) ratio is realized using two identical ICs that can express the FHD resolution. With this feature, it is possible to realize FHD resolution which is one of the digital broadcasting standards, that can be used for displaying information in other regions or cinemascope ratio images in the full screen. Followings are the contents of the paper that describes the procedure how the 2560×1080 resolution is expressed for the Plasma Display Panel (PDP) using two ICs. Section 2 covers the PDP operation and structure, and briefly shows how the 2560×1080 resolution is expressed using two ICs. Section 3 describes the image processing of the boundary region that should be considered for expressing the 2560×1080 resolution, the communication between the two ICs, and implementation of the overall hardware structure along with verification of the functions that are realized. Finally, the conclusions are given in Section 4.

AC-PDPs generally use Address period and Display period Separation with sub-field method (ADS) that has been devised by T. Shindoda at Fujitsu. The ADS scheme includes the wall charge (inside the cell) reset period, the address period that selects the display and the dark region that does not need to be discharged, and the sustain period that enables visualization of the display by selectively discharging the cells that only contain wall charge. In ADS, the gray-level expression is realized by combining the reset, address, and sustain period into one sub-field, and generating a single display frame by combining several sub-fields [3,4].


                     Fig. 2
                     (a) is the back side of the 1920×1080 resolution PDP panel, which shows the overall driver circuit composition. In Fig. 2(a), the left side is the Y electrode, Ysus and Y driver board for generating the scan waveform, the right side is the Zsus board for generating Z electrode driver waveform, the center part is the control board for input signal and image quality processing, and the bottom center shows the X board for data output.

In addition, the Y electrode driver circuit can be divided into 4 sub-parts. First, the sustain that block alternatively applies a pulse with voltage V
                     s to the Y and the Z electrode panel, in order to generate light emission by discharge within the activated cell. In this paper, the serial resonance based energy recovery circuit invented by Weber is used for the sustain pulse input circuit [3]. Second, the reset block that consists of the set-up and set-down part that generates the reset pulse that initializes the state of all the cells using lamp pulse dark discharge. Third, the scan part that applies a sequential pulse to the Y electrode in order to determine the states of each cell depending on the image data, where the driving pulse is applied to the Y electrode using a scan driver IC. The voltage applied to each Y electrode is selected by clock and data signals which are the scan IC control signals. Finally, the pass block separates the sustain circuit to protect the sustain circuit when a negative voltage is applied during the reset and address period.

In addition, as shown in Fig. 2(b) and (c), the Z electrode can be divided into the sustain block and V
                     ZB block, where the Z electrodes are all connected in common. The sustain block is identical to the Y electrode sustain circuit, which applies the sustain pulse alternating with the Y electrode. The V
                     ZB block gathers the wall charge by biasing it with a constant voltage during the scan period so that it is beneficial for addressing. The X electrode driver circuit is included in the data driver IC that consists of the tape carrier package (TCP). The data driver IC supports 384 channels referenced to the data output that is used to apply a pulse to the X electrode in order to determine the cell on/off state located at the cross section of the X and Y electrode, where the scan pulse is applied during the address period.

The cell that has a data voltage input moves to the on state by the address discharge between the Y and the X electrode, and the cell with 0V input becomes off state, since there is no discharge generation [4,5].


                     Fig. 3
                      shows the architecture of the FHD controller system on chip (SOC) that is used for the PDPs. The quad-link low voltage differential signaling (LVDS) Rx part, which convert the image that is sent to LVDS Tx into low voltage transistor level (LVTTL) is the intellectual property (IP). The converted image information is passed through the line buffer to convert it from the pixel clock domain to the system clock domain for stable system operation. The average picture level (APL) control block calculates the average of one frame APL using the image data processed by the line buffer, and generates the X, Ysus, and Zsus board driving signals.

In addition, the APL is averaging is obtained to reduce the panel over discharge due to abrupt change of the image information to comply with the final PDP driving signal. The image information converted into the system clock domain performs the inverse gamma and image quality processing operation. The inverse gamma correction is based on the fact that the luminance signal corresponding to the video input signal is proportional to the square of the gamma, where gamma value for standard displays is 2.2. As a result, for cameras (image capture device), a non-linear circuit with gamma of 1/2.2 is used to adjust the amplitude of the video voltage. However, for PDPs, the inverse gamma processing is necessary, since the luminance of the image corresponding to the input is nearly linear [7].

The SP block shown in Fig. 3 processes the image, which does the image data formation into 10 bit integer and 8 bit fractional part in order to perform a halftone to the inverse gamma processed image. The split data undergoes the mapping using a look up table (LUT) so that the light emission center variation between the gray-level is minimized, which is to comply with the PDP characteristic. The halftone block improves the luminance expression through error diffusion or dithering, and the sub-field mapping (SFM) block determines the on or off sub-fields for the error diffused image data. The data aligner (DA) block converts the image data into the data structure of the PDP sub-field type. The image converted to sub-field domain gets darker as simultaneously charged cells increase more and more. To reduce the effect, a method of load effect compensation has to be introduced. It will be described in more detail in the next section. The image that is processed by the above procedure is converted from the RGB domain into the sub-field domain using external DDR memory. Furthermore, the converted image information is forwarded to the X board using the reduced swing differential signaling (RSDS) IP, which is synchronized with the Ysus board scan signal during the ADS address period, and sends the sub-field converted image information suitable for PDP driving using the TCP.


                     Fig. 4
                      shows the conceptual block diagram for displaying the 2560×1080 sized image information on the PDP. A scalier is used at the system input side, since the image that is transmitted from the broadcasting department to the network, where the service provider transmits maximum 720p. The scalier converts the 720p or analog input image into the 2560×1080 resolution. The frame rate converter (FRC) which contains the function for frame transfer speed adjustment, 3D conversion, and on screen display (OSD), forwards the information using high speed LVDS (HS-LVDS) interface with pixel clock of 95.85MHz to express the 2560×1080resolution image. The field programmable gate array (FPGA) divides the 2560×1080 image information from the FRC to each 1920×1080, and sends it to the FHD PDP controller. The first FHD PDP controller accepts the 1920 image signals referenced from the front blank unit, and inversely, the second FHD PDP controller accepts the 1920 image signals referenced from the back blank unit. The FHD PDP controllers internally adjusts the blanks to each express the 1280×1080 resolution, and eventually express the overall 2560×1080 resolution.

In order to realize a 2560×1080 resolution image using two ICs, the number of X electrodes are extended to 640×3 (RGB) for data transfer based on the 1920×1080 resolution. In aspects of the FHD PDP controller for input signal processing, image quality control, and driving, the 21:9 resolution can be expressed by forwarding the image information to each scan period for the entire 1080 intervals just as the 2560×3 image information sub-field mapped during the address period from the input image is transferred to the X board using RSDS, and performing the sustain. In order to express a 2560×1080 resolution using two FHD PDP controllers, it requires image quality processing for the boundary region and inter communication for APL calculation of each FHD PDP controller input for APL processing of the entire input image. In this paper, the communication between one FHD PDP and the other FHD PDP is realized using the master slave interface (MSIF) that is indicated in Fig. 3 as the dotted line.

In this section, the detail contents of the MSIF shown in Fig. 3 and the inter communication scheme of the FHD PDP controller in order to realize the 21:9 function are covered. Fig. 5
                     (a) shows the block diagram of the MSIF. In this paper, the left and the right side is defined as the master and the slave, respectively, however for the actual design, the master and the slave are set based on the pin configuration so that they operate properly as the master and the slave. The MSIF includes the register storage block that calculates the parameter values for each frame image data applied to the master and slave, and stores it in the register and the buffer that transmits and receives the saved values synchronized with the clock. Fig. 5(b) is the timing diagram that describes read and write operations of the MSIF.

The master reads the slave data by requesting the slave data using the MS_REG signal. The slave responds to the master by sending the requested data and the MS_ACK signal. The master takes the third internal counter data in order to latch the middle value among the received data. The write operation of the master to the slave uses the MS_ACK, which the data and the MS_REQ signal is transmitted to the slave.

The slave takes the middle value among the read data through the internal counter in order to latch the middle value from the received data [8]. Fig. 5(c) shows the verified read and write operations through simulations, where the master and slave values are compared with the actual values obtained from the inter communication. In the first operation, the master reads the data after the slave writes it. The data transmitted by the slave is verified by the checksum result which is performed by the master. The second operation which works in converse (master to slave) is also verified.

PDP drivers generally use the APL scheme to prevent over heating of the panel and maximize the luminance efficiency. In this way, the average luminance that is displayed during one frame time will be consistent by varying the maximum sustain pulses depending on the average value of the digital input data [6]. The FHD controller proposed in this paper calculates the 1280×1080 resolution APL from each input, since a 1920×1080 input resolution is used. The calculated APL value is forwarded to the slave by the master. In this case, the master adds the slave APL, and divides the added result. The divided APL is transferred to the slave through the MSIF. The final APL results are used for master and slave driving.


                     Fig. 6
                      describes the block diagram of the error diffusion scheme and the error diffusion mask that can compensate the weak aspects of the gray level expression originating from the inverse gamma correction process for the PDP. In Fig. 6(a), i(n) is the input, and as the inverse gamma is processed it becomes
                        
                           (1)
                           
                              x
                              (
                              n
                              )
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                i
                                                (
                                                n
                                                )
                                             
                                             
                                                255
                                             
                                          
                                       
                                    
                                 
                                 
                                    2.2
                                 
                              
                              ·
                              255
                           
                        
                     Furthermore, by using the error from the neighboring pixels, u(n) is defined as
                        
                           (2)
                           
                              u
                              (
                              n
                              )
                              =
                              x
                              (
                              n
                              )
                              -
                              (
                              e
                              ∗
                              ω
                              )
                              (
                              n
                              )
                           
                        
                     where e(n) is the error generated from the neighboring pixels and w(n) denotes the error diffusion filter. For the PDP error diffusion algorithm, the error is defined as the difference between the ideal inverse gamma correction value and the expressible value for the actual panel for a given pixel.

The error is given by
                        
                           (3)
                           
                              e
                              (
                              n
                              )
                              =
                              h
                              (
                              n
                              )
                              -
                              u
                              (
                              n
                              )
                           
                        
                     where h(n) is the quantization result of u(n), and it represents the final output value of the error diffusion process [9]. The error generated for a given pixel is redistributed to the neighboring pixels after putting a weight with the error filter. One of the most general error diffusion schemes is the Floyd-Steinberg error diffusion shown in Fig. 6(b), where the error diffusion filter is described as
                        
                           (4)
                           
                              
                                 
                                    w
                                 
                                 
                                    i
                                    ,
                                    j
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                1
                                                /
                                                16
                                             
                                             
                                                5
                                                /
                                                16
                                             
                                             
                                                3
                                                /
                                                16
                                             
                                          
                                          
                                             
                                                7
                                                /
                                                16
                                             
                                             
                                                ∗
                                             
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where wi,j
                      diffuses the error generated by a given pixel to the neighboring pixels, and the * denotes the pixel that is currently being processed. The above scheme is used in this paper, since it can be realized with a relatively simple mask structure [10].

In this paper, to transfer the error diffusion value at the MSIF boundary region, the first blank image signal is delayed with complex programmable logic device (CPLD), and transferred as described in Fig. 7
                     . Generally the error diffusion method uses the values from the 1st to the 4th decimal places in the gamma processed 8.6 bits image in the PDP, and 1st to 2nd decimal places in the 8.2 and 10.2 bits images in the LCD and the LED, respectively. There are forward, backward, and zigzag methods according to the error delivery method. We use the forward one that easily delivers the error at the border area. In the left side of the Fig. 7, the error in region 1 of line N
                     +1 is reflected the propagated error values which are generated in region 0, 1, and 2 of line N and region 0 of line N
                     +1. So, the errors of line N
                     +1 are reflected as such way. The right side of the Fig. 7 shows the propagated errors at the border area which are generated in region 7 of line N and N
                     +1 of which errors are transmitted via the MSIF. All errors of each line at the border area are reflected and calculated as such way.

As mentioned in the previous section, the load effect compensation algorithm can be implemented as Fig. 8
                     . The algorithm in the PDP measures the luminance based on 100% window and the same luminance can be maintained by increasing or decreasing the number of sustaining discharge compared to a 100% window after calculating previously the discharged area of sub-field. The total number of sustain is calculated by the basis value of the input APL. The finally compensated number of sustaining discharge can be determined by calculating the 100% window discharging area per each sub-field, deciding the number of sustaining discharge to be compensated and increasing and decreasing the number of the sustaining discharge. In this paper, we use a general method to decrease the number of the sustaining discharge if the image input converted to each sub-field domain is brighter than the reference bright by the 100% discharge area for each sub-field. Finally, the master adds the number of sustaining discharge at the master and slave side. Then the master sends the parameters to slave via MSIF [11,12].

As a result, the input signal is structured as shown in Fig. 9
                     (a) in order to perform the error diffusion for each MSIF input. The 4 LVDS Rx ICs shown in Fig. 9(a) receive 2560×1080 image, which uses 4 high speed LVDS that operate at 95.85MHz, considering the image speed that has to process for one frame, and to process 3D images. The CPLD receives the input image, and cuts the image data into 1280×1080 for the master and the slave. In addition, in order to transfer the error value for the error diffusion, it performs the operation that delays the slave blank by one blank. After the above procedure, the structure transfers the image data to the FHD PDP controller. Fig. 9(b) is an implemented hardware for 21:9 cinema functions.

Finally, Fig. 10
                     (a) shows the 2560×1080resolution image obtained by using the 21:9 functional board described in Fig. 9. We used 1920×1080 resolution image generated by PC as the input of the PDP to express the 2560×1080resolution. The final image by the process in the Fig. 6 shows that it can support 21:9 cinema mode. In Fig. 10(b), one can additionally see a natural image of the cinema mode without having difference between the left and the right, which is obtained by the MSIF function that transfers parameters such as the APL, the load effect compensation, and the halftone at the border area between the master and the slave.

@&#CONCLUSIONS@&#

In this work, a 21:9 function that supports 2560×1080 resolution is realized using the master and slave based FHD PDP controller. Two ICs are used, where one is set as the master and the other is set as the slave. In addition, the high speed serial communication enables the data transfer between the master and the slave. For the IC that supports FHD, the master computes each calculated parameter of the master and the slave by reading the value from the slave, and performs the operation which keeps the parameter that will be used by the master, whereas forwards the parameter that will be used by the slave to the slave. This scheme has an advantage of reducing the SOC development cost by realizing the communication and computation function inside the ASIC that supports the 21:9 feature, instead of designing a specific ASIC that supports cinemascope. Furthermore, by extending the resolution and image quality processing parameters and applying it to the communication between the two ICs, not only the 2560×1080 but also can be applied to the 4K×2K resolution.

@&#ACKNOWLEDGEMENT@&#

This paper was supported by Research Fund, Kumoh National Institute of Technology.

@&#REFERENCES@&#


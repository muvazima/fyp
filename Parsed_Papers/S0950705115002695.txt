@&#MAIN-TITLE@&#On improving parsing with automatically acquired semantic classes

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           80% of parsing mistakes in appositions are due to a lack of semantic information.


                        
                        
                           
                           We automatically gather evidence on class-instance semantic compatibility from text.


                        
                        
                           
                           Classes are common nouns; instances are entities characterized by name and type.


                        
                        
                           
                           Our best model uses both sources of evidence with smoothed conditional probability.


                        
                        
                           
                           Experiments reach 91.4% accuracy, a 12.9% relative improvement over the baseline.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Apposition parsing

Semantic class extraction

Unsupervised knowledge acquisition

@&#ABSTRACT@&#


               
               
                  Parsing mistakes impose an upper bound in performance on many information extraction systems. In particular, syntactic errors detecting appositive structures limit the system’s ability to capture class-instance relations automatically from texts. The article presents a method that considers semantic information to correct appositive structures given by a parser.
                  First, we build automatically a background knowledge base from a reference collection, capturing evidence of semantic compatibility among classes and instances. Then, we evaluate three different probabilistic-based measures to identify the correct dependence on ambiguous appositive structures.
                  Results reach a 91.4% of correct appositions which is a relative improvement of 12.9% with respect to the best baseline (80.9%) given by a state of the art parser.
               
            

@&#INTRODUCTION@&#

Information extraction systems typically preprocess text through a syntactic parser. However this step is an important bottleneck because parser errors are hard to solve or even identify at the extraction phase.

We can see in literature that parsers achieve overall performances over 90%, but it is well known that their performance drop in highly ambiguous dependencies such as PP attachments [1] or long distance dependencies [2].

Here we focus on appositions, which are grammatical constructions with two contiguous noun phrases where one defines or modifies the other. They are one of the most useful and productive dependence given by parsers because they are frequently used to denote the semantic class of a particular instance [3]. We develop a method to improve the apposition dependence detection that impact the retrieval of instance-class relations.

Consider the following example:


                     David supports the team of his 
                     
                        wife
                     
                     , 
                     Julia.
                        2
                        We denote in bold the named entity and underline the candidate common nouns.
                     
                     
                        2
                     
                  

Dependency parsers often determine that there is an apposition between the common noun wife and the named entity Julia, leading to interpret that Julia belongs to the class wife. People would accept this interpretation using their background knowledge where Julia is a common name for a female person. Now consider the following example with exactly the same syntactic structure:


                     David supports the 
                     
                        team
                      
                     of his 
                     
                        wife
                     
                     , 
                     The Vikings.

Here it is not possible to determine the scope of the apposition without semantic information. However we know that The Vikings is not an usual name for a wife, whereas in the close context there is a different candidate, the common noun team, which is semantically more compatible. Thus, we want parsers to reproduce this behavior and link The Vikings and team. Fig. 1
                      illustrates the problem with an example that shows the original output given by a state of the art parser and the intended result.

Given this scenario, we formulate the next research questions:
                        
                           1.
                           What kind of errors do parsers commit on appositions because of the missing semantic information?

Is it possible to overcome these errors considering information captured previously from text collections? What evidence can it provide to characterize the named entity?

What is the most effective way to measure the semantic compatibility between the candidates and the named entity?

What configuration of evidence and measures achieves the best results?

To answer these questions we have parsed a large text corpus with two objectives: first to have a base to acquire background knowledge, and second, to get a sample of appositions where we compare the behavior of two different dependency parsers in the state of the art.

In Section 2 we define the scope of our study and check the source of errors in parsing. In particular we focus on cases where there are many candidates to govern an apposition. Our hypothesis is that these errors can be overcome by considering some background knowledge automatically extracted from large text collections. In Section 3 we explore how to gather this knowledge. We assume that the most semantically compatible candidate is the correct one. To measure this compatibility we study different configurations to combine the available evidence in Section 4, and show the results on Section 5. In Section 6 we discuss related work, and we provide some conclusions in Section 7. Finally in Section 8 we propose some future work.

Our goal is to study appositions where dependency parsers have a chance to make a mistake selecting a governor because there are several grammatically correct candidates. In particular, we focus on cases where errors come from not taking into account the semantic compatibility between the two parts involved.

One structure where these errors can be found is a phrase where one side of the apposition is a named entity, and the other one has two or more common nouns that can be the nucleus of the noun phrase, and therefore a semantic class of the named entity. We refer to those common nouns as candidates.

We search for this structure in a large collection of textual data belonging to the TAC KBP task [4], composed by around 1.5million documents that belong to different categories including newswire, blogs and phone calls transcriptions. We parse the collection with the Stanford Parser [5].

In this collection we obtain a total of 41,285,844 sentences, with 691,394 apposition dependencies, where 240,392 (34.7%) have more than one candidate.

We took a sample of 300 sentences to build a Gold Standard for evaluation. The following subsections show the qualitative analysis of this Gold Standard. According to the semantic compatibility between candidate classes an instances, we can distinguish the following cases:

In the simplest case, such as the examples in the introduction, the common noun that acts as nucleus of the first noun phrase should be the governor of the apposition and it is more suitable than the other. Consider the next sentence:
                           …the 
                              
                                 leader
                               
                              of its largest rebel 
                              
                                 group
                              
                              , 
                              Manuel Marulanda
                              , …
                        
                     

We target these cases as the ones to solve. Ideally, background knowledge should be able to discriminate suitable candidates. For example, a person as Manuel Marulanda is more frequently a leader than a group.

However, sometimes there are multiple common nouns that are valid candidates to be the governor of the relation. This occurs when either there is an implicit or explicit conjunction. An example of explicit conjunction would be:
                           …a prominent Jewish 
                              
                                 writer
                               
                              and Holocaust 
                              
                                 survivor
                              
                              , 
                              Ralph Giordano …
                        
                     

What we assume is that there are different simultaneous classes of the named entity. In some cases it could be interesting to add an apposition for each of the candidates.

An implicit conjunction occurs when there are noun compounds where common nouns act as modifiers, like in the next examples:
                           …by the IOC ’s 
                              
                                 chief
                               
                              Beijing 
                              
                                 organiser
                              
                              , 
                              Hein Verbruggen
                              , …
                        
                     

In these cases, we perform a linguistic test, where we check if the nouns are a semantic class of the named entity. Following the example, we check if Hein Verbruggen belongs to the classes chief and organiser. As it happens, we say that both candidates are valid.
                           3
                           Recall that the first noun of a noun-noun compound should not be a candidate. Even so, our method is robust enough to consider even these candidates.
                        
                        
                           3
                        
                     

In other cases the noun phrase includes a subordinated sentence that also has a common noun candidate to govern the apposition, for example:
                           
                              Another 
                              
                                 passenger
                               
                              who gave only his 
                              
                                 surname
                              
                              , 
                              Chen …
                        
                     

In some sentences there are two classes referred to two different entities, but some extra-linguistic knowledge is needed to decide how they are related. For example:
                           …at least one 
                              
                                 brother
                               
                              of another 
                              
                                 defendant
                              
                              , 
                              Ali Dayeh Ali
                              .
                           
                        
                     

In the previous example there are two classes, brother and defendant, that refer to two different entities, Ali Dayeh Ali and an unknown entity. Without external knowledge it cannot be decided if Ali Dayeh Ali belongs to the class brother or to the class defendant.

In the manual inspection we have found multiple examples where the parser detects an incorrect apposition relation. To correct these errors is a line of work by itself, but here we limit ourselves to show what cases we have found. These are: Conjunction between two sentences, wrong apposition relation between a noun phrase and a verbal phrase, structures that denote the relation location-region, enumerations and nonsense text.

We have shown how parsers depend on semantic knowledge to solve apposition dependencies with several grammatical alternatives. We have classified the sentences according to the semantic compatibility of the candidates and the named entity. Table 1
                         shows the number and percentage of appositions in each case.

In general, there are two main sources of errors in apposition parsing: When actually there is no apposition and the parser makes a bad choice of the dependency type, and when there are several candidates to govern the apposition and the parser makes a bad identification of the governor of the apposition. We tackle the latter, which include cases with one valid candidate, several valid candidates and undecidable candidates. These cases represent the 78.6% of the appositions of the sample.

We compose a Gold Standard with these appositions where we annotate the right apposition dependence. When there are several valid candidates, or it is undecidable which candidate is valid, we consider all valid choices as correct. Even if this cases are easier to solve, we include them to maintain generalization (i.e. there are cases with several valid candidates but at the same time another one that it is not). For our experimentation, we ignore the non-apposition cases. The result is a Gold Standard of 236 appositions.

In the previous section we saw that there are appositions with several candidates and the parser has to choose among them. We assume that the correct candidate is the most semantically compatible with the named entity. In this section we explain how we gather evidence to get a measure for this compatibility. Our hypothesis is that we can get it from large sources of text following the Open Information Extraction paradigm [6].

The goal in this phase is to extract relations between classes and instances with an associated probability. To acquire this information we use a graphical document representation 
                        
                           
                              
                                 G
                              
                              
                                 d
                              
                           
                        
                      generated from a document d in the set of documents D.

Each document d is processed with Stanford CoreNLP (see Section 2) to obtain part-of-speech annotations [7], named entities [8], syntactic dependencies [5] and coreferences [9].

Graphs 
                        
                           
                              
                                 G
                              
                              
                                 d
                              
                           
                        
                      are defined by a set of nodes 
                        
                           
                              
                                 V
                              
                              
                                 d
                              
                           
                        
                      and set of edges 
                        
                           
                              
                                 E
                              
                              
                                 d
                              
                           
                        
                     . A node 
                        
                           v
                           ∈
                           
                              
                                 V
                              
                              
                                 d
                              
                           
                        
                      contains lexical information about words and multiwords. Edges 
                        
                           e
                           ∈
                           
                              
                                 E
                              
                              
                                 d
                              
                           
                        
                      are typed syntactic dependencies obtained by the parser. Finally, coreferences are used to collapse different mentions of the same entity into a single node.

We obtain a set of classes from the graphs using very simple hand-crafted patterns based on syntactic dependencies where a common noun is a class for a named entity. Named entities have an entity type associated (person, organization or location) given by the named entity recognizer. When we find a match, we assign the common noun as semantic class of the named entity and we get an instance 
                        
                           NE
                           -
                           Class
                           -
                           Type
                        
                     . Table 2
                      details the patterns and provides with some examples of instances collected.

We do not pretend to obtain all the relations instance-class expressed in the collection with these patterns, but to acquire a representative and sufficient number of classes to evaluate their compatibility with named entities. We found a total of 4,410,293 instances.

After obtaining the semantic class assignments, we aggregate the information from all the collection to obtain the frequencies of named entities, classes and types. As a matter of example, Table 3
                      contains some tuples extracted with the associated joint probability.

To measure the semantic compatibility we use the joint probability between the classes and entity names, and also between classes and entity types (see Section 5.2). To get them we use a maximum likelihood estimator and marginalize:
                        
                           (1)
                           
                              p
                              (
                              c
                              ,
                              ne
                              )
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       t
                                    
                                 
                              
                              p
                              (
                              ne
                              ,
                              c
                              ,
                              t
                              )
                           
                        
                     
                     
                        
                           (2)
                           
                              p
                              (
                              c
                              ,
                              t
                              )
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       ne
                                    
                                 
                              
                              p
                              (
                              ne
                              ,
                              c
                              ,
                              t
                              )
                           
                        
                     where c is the candidate, ne the entity name and t is the entity type. Table 4
                      shows a sample of some of the higher probabilities obtained.


                     Algorithm 1 sums up the process of acquiring the background knowledge. 
                        
                           D
                           =
                           {
                           
                              
                                 d
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 d
                              
                              
                                 n
                              
                           
                           }
                        
                      is document collection, 
                        
                           P
                           =
                           {
                           
                              
                                 p
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 p
                              
                              
                                 6
                              
                           
                           }
                        
                      is the set of patterns and 
                        
                           KB
                           =
                           {
                           
                              
                                 t
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 t
                              
                              
                                 m
                              
                           
                           }
                        
                      is the knowledge base extracted. 
                        
                           
                              
                                 G
                              
                              
                                 d
                              
                           
                        
                      is the graph of the document d, and it is defined by a set of nodes 
                        
                           
                              
                                 V
                              
                              
                                 d
                              
                           
                           =
                           {
                           
                              
                                 v
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 v
                              
                              
                                 n
                              
                           
                           }
                        
                      and a set of edges 
                        
                           
                              
                                 E
                              
                              
                                 d
                              
                           
                           =
                           {
                           
                              
                                 e
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 e
                              
                              
                                 m
                              
                           
                           }
                        
                     . 
                        
                           
                              
                                 C
                              
                              
                                 d
                              
                           
                        
                      represent the set of coreferences between pairs of nodes.
                        Algorithm 1
                        Knowledge base acquisition 
                              
                                 
                                    
                                    
                                       
                                          
                                             Input: 
                                             
                                                
                                                   D
                                                   =
                                                   {
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         0
                                                      
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      
                                                         d
                                                      
                                                      
                                                         n
                                                      
                                                   
                                                   }
                                                   ,
                                                   
                                                   P
                                                   =
                                                   {
                                                   
                                                      
                                                         p
                                                      
                                                      
                                                         0
                                                      
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      
                                                         p
                                                      
                                                      
                                                         6
                                                      
                                                   
                                                   }
                                                
                                             
                                          
                                       
                                       
                                          
                                             Output: 
                                             
                                                
                                                   KB
                                                   =
                                                   {
                                                   
                                                      
                                                         t
                                                      
                                                      
                                                         0
                                                      
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      
                                                         t
                                                      
                                                      
                                                         m
                                                      
                                                   
                                                   }
                                                
                                              where 
                                                
                                                   
                                                      
                                                         t
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   =
                                                   〈
                                                
                                             
                                             ne name, class, ne type, frequency 
                                             
                                                
                                                   〉
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             for each 
                                             
                                                
                                                   d
                                                   ∈
                                                   D
                                                
                                              
                                             do
                                          
                                       
                                       
                                          
                                             //transform d into 
                                                
                                                   
                                                      
                                                         G
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                
                                             :
                                       
                                       
                                          
                                             
                                             
                                                
                                                   <
                                                   
                                                      
                                                         V
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   >
                                                   ←
                                                   parse
                                                   (
                                                   d
                                                   )
                                                
                                              
                                             do
                                          
                                       
                                       
                                          
                                             //collapse co-referent nodes
                                       
                                       
                                          
                                             
                                             for each coreference 
                                                
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   )
                                                   ∈
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                
                                              
                                             do
                                          
                                       
                                       
                                          
                                             
                                             
                                             foreach edge 
                                                
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   )
                                                   ∈
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                
                                              
                                             do
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                                
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ←
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ∪
                                                   {
                                                   <
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   >
                                                   }
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                                
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ←
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ⧹
                                                   {
                                                   <
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   >
                                                   }
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                                
                                                   
                                                      
                                                         V
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ←
                                                   
                                                      
                                                         V
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ⧹
                                                   {
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   }
                                                
                                             
                                          
                                       
                                       
                                          
                                             //apply extraction patterns
                                       
                                       
                                          
                                             
                                             for each 
                                             
                                                
                                                   p
                                                   ∈
                                                   P
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                                
                                                   t
                                                   ←
                                                   match
                                                   (
                                                   
                                                      
                                                         G
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                   ,
                                                   p
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                                
                                                   KB
                                                   =
                                                   KB
                                                   ∪
                                                   {
                                                   t
                                                   }
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

In this section we explain our approach to identify and select the candidates to govern an apposition relation. We define the following variables in our method.


                     
                        
                           S
                           =
                           {
                           
                              
                                 s
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 s
                              
                              
                                 n
                              
                           
                           }
                        
                      represents the set of sentences, each one of them is composed by several candidates 
                        
                           
                              
                                 C
                              
                              
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           =
                           {
                           
                              
                                 c
                              
                              
                                 0
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 s
                              
                              
                                 m
                              
                           
                           }
                           ;
                           
                           
                              
                                 E
                              
                              
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                              
                           
                           =
                           {
                           ne
                           ,
                           t
                           }
                        
                      is the named entity with annotated evidence. Finally 
                        
                           F
                           =
                           {
                           
                              
                                 f
                              
                              
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 f
                              
                              
                                 8
                              
                           
                           }
                        
                      denotes the set of configurations. We explain them and their use in more detail in the following sections.

@&#METHOD@&#

We gather sentences 
                           
                              
                                 
                                    s
                                 
                                 
                                    i
                                 
                              
                           
                         that contain an appositive dependence formed by two noun phrases that fulfil two premises. The first one is that the first noun phrase must have more than one common noun. Each one is a candidate to be the governor of the apposition dependence 
                           
                              
                                 
                                    C
                                 
                                 
                                    
                                       
                                          s
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              =
                              {
                              
                                 
                                    c
                                 
                                 
                                    0
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    s
                                 
                                 
                                    m
                                 
                              
                              }
                           
                        .

We use as working example the sentence: “the chief of the Shin Bet security agency, Yuval Diskin”. In this sentence, the candidates are: 
                           
                              
                                 
                                    c
                                 
                                 
                                    0
                                 
                              
                           
                        
                        =
                        agency, 
                           
                              
                                 
                                    c
                                 
                                 
                                    1
                                 
                              
                           
                        
                        =
                        chief, 
                           
                              
                                 
                                    c
                                 
                                 
                                    2
                                 
                              
                           
                        
                        =
                        security.

The second premise is that the nucleus of the second noun phrase has to be a named entity. The named entity is the dependent part of the apposition. It is defined by two aspects, the entity name ne, which is the proper string that forms the named entity, and its entity type t (person, organization or location). We will refer to these values as evidence (E). Following our example, 
                           
                              E
                              =
                              {
                              ne
                              =
                              YuvalDiskin
                              ,
                              
                              t
                              =
                              person
                              }
                           
                        .

Once we have candidates to govern an apposition relation, we select the most suitable by measuring their semantic compatibility with the named entity.

We use three measures of compatibility: normalized pointwise mutual information between candidate and evidence 
                           
                              npwmi
                              (
                              
                                 
                                    c
                                 
                                 
                                    i
                                 
                              
                              ,
                              E
                              )
                           
                        ; conditioned probability of the class given the evidence 
                           
                              p
                              (
                              
                                 
                                    c
                                 
                                 
                                    i
                                 
                              
                              |
                              E
                              )
                           
                        ; and smoothed conditioned probability 
                           
                              
                                 
                                    p
                                 
                                 
                                    JM
                                 
                              
                              (
                              
                                 
                                    c
                                 
                                 
                                    i
                                 
                              
                              |
                              E
                              )
                           
                        .

The formula that describes the normalized pointwise mutual information we use is:
                           
                              (3)
                              
                                 npmi
                                 (
                                 x
                                 ;
                                 y
                                 )
                                 =
                                 
                                    
                                       pmi
                                       (
                                       x
                                       ;
                                       y
                                       )
                                    
                                    
                                       -
                                       log
                                       p
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 pmi
                                 (
                                 x
                                 ;
                                 y
                                 )
                                 =
                                 log
                                 
                                    
                                       p
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    
                                       p
                                       (
                                       x
                                       )
                                       p
                                       (
                                       y
                                       )
                                    
                                 
                              
                           
                        
                        
                           
                              p
                              (
                              x
                              ,
                              y
                              )
                           
                         is the probability estimated in the previous phase, and 
                           
                              p
                              (
                              x
                              )
                           
                         and 
                           
                              p
                              (
                              y
                              )
                           
                         is the result of marginalization. Normalized pointwise information scales the results to the range 
                           
                              (
                              -
                              1
                              ,
                              1
                              )
                           
                        , where −1 is the value where there are not joint observations and 1 is the value where the observations are always together.

In the third measure we introduce a smoothing factor to deal with data sparsity, as we expect to find cases with no evidence, i.e., entities that do not co-occur with some semantic classes. We use the Jelinek–Mercer algorithm with a default value of 
                           
                              α
                              =
                              0.99
                           
                        . 
                           
                              (5)
                              
                                 
                                    
                                       p
                                    
                                    
                                       JM
                                    
                                 
                                 (
                                 e
                                 |
                                 c
                                 )
                                 =
                                 α
                                 p
                                 (
                                 e
                                 |
                                 c
                                 )
                                 +
                                 (
                                 1
                                 -
                                 α
                                 )
                                 p
                                 (
                                 e
                                 )
                              
                           
                        
                     

When 
                           
                              npwmi
                              (
                              e
                              ;
                              c
                              )
                              =
                              -
                              1
                           
                         for each candidate 
                           
                              
                                 
                                    c
                                 
                                 
                                    0
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    c
                                 
                                 
                                    n
                                 
                              
                           
                         we say that we have no evidence. We deal in the same way with 
                           
                              p
                              (
                              c
                              |
                              e
                              )
                              =
                              0
                           
                         and 
                           
                              
                                 
                                    p
                                 
                                 
                                    JM
                                 
                              
                              (
                              c
                              |
                              e
                              )
                              =
                              0
                           
                        . In these cases, we consider that our method fails.

Our baselines are the results obtained in this Gold Standard by two parsers on the state of the art, the Stanford Parser [5] and the Fanse Parser [10].

Stanford Parser has 191 (80.9%) correct appositions over the 236 instances in the Gold Standard, whereas Fanse Parser only reaches 70.7%. Stanford Parser has better results, but still there is a margin of improvement of 19.1%. We estimate that in the whole collection there are around 30.000 mistakes that can be overcome with our method.

In order to evaluate the contribution of each evidence and each measure, we define a configuration as a pair of measure and evidence. Table 5
                         shows the configurations considered.

For each configuration f we will select the candidate that maximizes the compatibility score between a candidate c and a entity E with entity name ne and type t. More formally, given the set of candidates 
                           
                              C
                              =
                              {
                              
                                 
                                    c
                                 
                                 
                                    0
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    c
                                 
                                 
                                    n
                                 
                              
                              }
                           
                        , and the evidence 
                           
                              E
                              =
                              {
                              ne
                              ,
                              t
                              }
                           
                         we select the best candidate 
                           
                              
                                 
                                    c
                                 
                                 
                                    f
                                 
                              
                           
                         such as:
                           
                              (6)
                              
                                 
                                    
                                       c
                                    
                                    
                                       f
                                    
                                 
                                 =
                                 
                                    
                                       arg max
                                    
                                    
                                       c
                                       ∈
                                       C
                                    
                                 
                                 
                                 f
                                 (
                                 c
                                 ,
                                 E
                                 )
                              
                           
                        
                     

@&#RESULTS@&#

Our method always returns the highest scored apposition. Given the Gold Standard, this decision can be just right or wrong. Thus, we evaluate the experiments using accuracy, i.e., the proportion of correct appositions.


                     Fig. 2
                      represents the results obtained for each configuration. Dotted lines show the two baseline systems. Five configurations outperform baseline systems significantly.
                        4
                        We apply the McNemar’s test with p-value 
                           
                              
                                 <
                                 0.0001
                              
                            in each case.
                     
                     
                        4
                      But more interestingly, we find some regularities in the effect of the evidence and measures considered:

We can see how, when considering the same measure, combining both evidence performs better than the use of entity types alone, which in turn performs better than considering only the entity name. This confirms the intuition that entity types are useful to generalize entity names, but combining both is even better to measure semantic compatibility.

As it is expected, there are many cases with no evidence for the entity name. This fact explains the low performance of 
                           
                              npwmi
                              (
                              ne
                              ,
                              c
                              )
                              ,
                              
                              p
                              (
                              c
                              |
                              ne
                              ,
                              t
                              )
                           
                         and 
                           
                              p
                              (
                              c
                              |
                              ne
                              )
                           
                         when they are used without smoothing.

With respect to the measures, it is noticeable how conditional probability outperforms normalized pointwise mutual information regardless the evidence considered.

Smoothing is useful in cases where there is no evidence, because it will favor the most probable candidate classes. For example, if we take into account the entity name, there are 64 instances with no evidence in the sample. Smoothing these cases helps to push the results from 68.1% to 88%.

However, when considering the entity type as evidence, smoothing is not useful because in the sample considered there are no instances without evidence. Thus, the results remain equal.

Considering both entity name and entity type, smoothing it is also very useful. It allows to consider 59 instances that previously had no evidence and classify them better than the baseline, improving the results from 69.4% to 91.4%.

The best performance is reached using both sources of evidence (entity name and entity type) in a smoothed conditional probability (Configuration 8: 
                           
                              
                                 
                                    p
                                 
                                 
                                    JM
                                 
                              
                              (
                              c
                              |
                              ne
                              ,
                              t
                              )
                           
                        ). With this configuration results rise from 80.9% accuracy in the baseline to 91.4%, which represents a relative improvement of 12.9% with respect to the parser.


                        Table 6
                         shows the results of our working example. In this case every evidence and measure considered chooses the correct candidate. As we said, Yuval Diskin is the entity name and its entity type is person. Candidates are agency, chief and security. Both Stanford parser and Fanse parser have chosen agency in the first place, but the correct candidate is chief.

For the sake of completeness Table 7
                         shows the relevant input probabilities used to calculate all configurations in our running example.


                        Table 8
                         shows one case where our method worsens the baselines. In this case, Virginia Casey is the entity name and its entity type is person. Candidates are daughter and cousin. Both Stanford parser and Fanse parser have chosen cousin in the first place, and it is the correct candidate.

The reason of the failure is that we have gather more evidence of persons being daughter than cousin, and we have no evidence of the name Virginia Casey with these classes.

@&#RELATED WORK@&#

The relation between syntactic ambiguity and semantic analysis, and also their application to syntactic disambiguation is a research field that has received attention for many years [11,12].

More recently, [13] shows how to use semantic features in a syntactic parser to improve its performance. To do so, they tag the named entities with a named entity recognizer and consider the entity types as parts of speech. In [14,15] the focus is in using WordNet [16] to generalize related words. For example, take the class tool instead of its instances scissors or knife, to improve syntactic parsers. Instead of WordNet, we use class-instance relations directly gathered from a reference collection, expecting that its coverage and granularity would be better adjusted to the topics and domains involved, and permitting also to calculate prior probabilities. Unlike them, our scope is not to build a parser with new features, but to test our hypothesis about the usefulness of semantic classes on the parsing of appositives.

Our approach is similar to other unsupervised methods for semantic class acquisition, also known as semantic class learning or semantic class induction [17]. Many other authors have processed text with a morphosyntactic parser and then selected one or more surface patterns to extract a set of candidate semantic classes, that in turn are refined [18,19].

In a different direction, [20] argues that text contains general knowledge in form of assertions and they may be exploited after aggregating big amounts of data, like in KNEXT [20], TextRunner [21] or DART [22].

We use both ideas going one step beyond by combining induced classes with named entity types. In this way we find evidence of, for example, that classes spokesman and leader are related with more frequency with entities of type person, whereas group and company are classes that relate to organization.

Regarding appositions, although they are a really useful source of semantic knowledge, most of the research has been done in the context of coreference resolution [23,24] or textual entailment [25]. Recently some efforts have been done in apposition extraction [26,27]. In [27] they also use as a feature the semantic compatibility in appositions between named entities and nouns. To do so, they generalize the noun to a named entity type using WordNet. However, besides the dependence on WordNet, they do not address the problem of choosing between different candidates. Our approach allows to use the countings gathered from the text collection to solve this issue.

@&#CONCLUSIONS@&#

In this article we have studied how semantic classes can be used to solve structural ambiguities in apposition dependencies. To do so we have answered the following research questions:
                        
                           1.
                           
                              What kind of errors do parsers commit on appositions because of the missing semantic information?
                           

Parsers fail when they lack of the semantic information to choose between several grammatically correct candidates. We have estimated that these cases represent the 78.6% of errors on apposition parsing, and have categorized them on three classes: appositions with one valid candidate (70.6%), with several valid candidates (7.3%) or with undecidable candidates (0.6%). We have focus on solving these three cases.

The remaining 21.3% errors correspond to bad choices of the dependency type.


                              Is it possible to overcome these errors considering semantic information captured previously from text collections? What evidence can they provide to characterize the named entity?
                           

We have used automatically acquired semantic classes as background knowledge to measure the semantic compatibility of candidates and named entities. This knowledge was divided in two different evidence, one relating semantic classes with entity names and other relating semantic classes with entity types.

The results obtained reinforce our hypothesis that considering semantic compatibility between the two parts of the apposition can help to overcome parsing errors.


                              What is the most effective way to measure the semantic compatibility that allows a better identification of the dependencies?
                           

We have used two different evidence (entity name and entity type) and three different measures (normalized pointwise mutual information, conditional probabilities and smoothed conditional probabilities).

Using the entity name as evidence alone does not improve the results, since many names could be missing in the reference collection. On the other hand, the main problem of taking entity type alone as evidence is that some classes are very dominant (chief, business), and tend to be overassigned. According with the results, it is more effective to combine both entity name and entity type to get an accurate measure of semantic compatibility.


                              What configuration of evidence and measures achieves the best results?
                           

Regarding the configurations tested, the best results are obtained when combining both sources of evidence with smoothed conditioned probabilities. We reach a 91.4% accuracy which is a 12.9% of relative improvement with respect to the best baseline (80.9%).

@&#FUTURE WORK@&#

This method could benefit from adding extra semantic information. For example, we could characterize entities with gender or age, to get more accurate measures of semantic compatibility. For example:
                        
                           David meets a 
                           
                              friend
                            
                           of his 
                           
                              wife
                           
                           , 
                           Peter.
                     
                  

Knowing that wife is a class used with females and Peter is usually a male name leads us to consider the link between friend and Peter more appropriate.

Although this work focuses on apposition dependencies, it would be interesting to study whether this technique could be extrapolated to solve other types, such as abbreviations, copulative verbs, or even coreference resolution.

We believe that including this method as a feature of current dependency parsers would lead to better performance.

Finally, once we get the new apposition dependencies for a large corpora, we can repeat the process of knowledge acquisition, creating a bootstrap method that iteratively improves the dependence analysis and semantic classes acquisition.

@&#ACKNOWLEDGEMENTS@&#

This work has been partially supported by the Spanish Government (MINECO) in the framework of CHIST-ERA program (READERS project), and Voxpopuli project (TIN2013-47090-C3-1-P).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An automated approach to the segmentation of HEp-2 cells for the indirect immunofluorescence ANA test

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We propose automated segmentation of HEp-2 cells in immunofluorescence imaging.


                        
                        
                           
                           We apply the same pipeline to images with different fluorescent pattern and intensity.


                        
                        
                           
                           Our segmentation approach is based on adaptive marker-controlled watershed.


                        
                        
                           
                           We assess the accuracy of our approach on a public dataset.


                        
                        
                           
                           We compare our performance with significant works from literature.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

HEp-2 cell segmentation

Cell pattern analysis

Indirect immunofluorescence

ANA testing

Microscope image processing

@&#ABSTRACT@&#


               
               
                  The automatization of the analysis of Indirect Immunofluorescence (IIF) images is of paramount importance for the diagnosis of autoimmune diseases. This paper proposes a solution to one of the most challenging steps of this process, the segmentation of HEp-2 cells, through an adaptive marker-controlled watershed approach. Our algorithm automatically conforms the marker selection pipeline to the peculiar characteristics of the input image, hence it is able to cope with different fluorescent intensities and staining patterns without any a priori knowledge. Furthermore, it shows a reduced sensitivity to over-segmentation errors and uneven illumination, that are typical issues of IIF imaging.
               
            

@&#INTRODUCTION@&#

Pattern recognition techniques are at the basis of computer aided diagnosis (CAD) systems in a large number of medical applications. Such systems support and facilitate the decision of the physicians, help reducing diagnosis errors and enable massive screening at a moderate cost, with tremendous positive impact on health care quality and economy [1]. This motivates an ever growing interest of the research community in providing solutions to the most challenging medical problems.

Recently, the analysis of indirect immunofluorescence (IIF) images has received increasing attention, with special regards to the development of systems for the computer-aided diagnosis of connective tissue diseases (CTDs). CTD refers to a broad category of autoimmune disorders that affect a remarkable percentage of the population, such as lupus, rheumatoid arthritis and scleroderma. These autoimmune disorders are usually diagnosed by means of a blood exam called the Antinuclear Antibody (ANA) test. This test leverages on the analysis of IIF images to reveal the presence in the blood serum of antibodies that are responsible for CTDs, typically using HEp-2 (Human epithelial type 2) cells as a substrate for the microscope slides. Different antibodies generate distinct patterns of fluorescence on the HEp-2 cells (see Fig. 1
                     ), allowing differential diagnosis.

While the ANA test has gained a wide recognition for its diagnostic capabilities and has now become a routine exam, the visual analysis of IIF images remains a very challenging task for the physicians, who need to inspect a massive amount of images. Moreover, several studies confirm that the reliability of the diagnosis is critically affected by the subjectivity and variability of the human evaluation [2,3], thus demanding for the automatization of the diagnostic process.

In the last few years, many researchers have applied pattern recognition techniques to this problem, and several automated tools have been proposed to support all the major steps of the IIF analysis procedure, including methods to automatize image acquisition and enhance image quality [4,5], image segmentation techniques [6–10], methods to improve IIF image representation and color conversion [11] as well as classification paradigms applied either to the quantification of the fluorescence intensity [12–14], to the recognition of the mitotic cells [15,16] or to the categorization of the fluorescent patterns [17–22].

Among the other tasks, image segmentation is one of the most critical and challenging in a computer-aided diagnosis system applied to IIF images. It is critical, because the accuracy of segmentation of the HEp-2 cells heavily affects the following steps of the analysis, such as the recognition of mitotic cells and the categorization of fluorescent patterns (details in Section 2.1). Besides that, HEp-2 cell segmentation is challenging because IIF images are intrinsically subject to tremendous variability. The major sources of this variability are: (i) the wide range of staining patterns (Fig. 1) and intensity levels (Fig. 2
                     ) that characterize the cells, (ii) the presence of mitotic cells (i.e. cells undergoing division, Fig. 3
                     ), and (iii) the possible generation of artifacts due to uneven illumination and photo-bleaching effect. This is a very difficult problem that is far from being solved.

In this work, we propose a fully-automated segmentation of HEp-2 cells in IIF images, without any a priori knowledge of their fluorescence intensity or staining pattern. Our method is designed as a multi-step pipeline. Both the segmentation approach and its parameters are adapted to the identified characteristics of the input image. As such, our pipeline is able to segment HEp-2 cells (including mitotic ones) with different intensity levels and with six different fluorescent patterns (see Fig. 1). Furthermore, we assessed the accuracy of our proposed technique on a publicly available dataset of IIF images, which allows a direct comparison with the most significant works in this area.

This paper is organized as follows. After a short overview of the medical context (Section 2.1) and of the most relevant literature on IIF segmentation (Section 2.2), we characterize the image dataset (Section 3), we describe our proposed technique (Section 4) and the parameters’ set-up (Section 5) and we discuss our experimental results (Section 6). Finally, Section 7 concludes the paper and presents future works.

@&#BACKGROUND@&#

The ANA test used in conjunction with indirect immunofluorescence is able to detect in the blood serum the presence of autoantibodies responsible for CTDs. The serum is first diluted and then incubated on a microscope slide coated with HEp-2 cells, whose antigens selectively bind to the serum autoantibodies. This bond can be visualized under the microscope by adding a green fluorescent tag on the slide. The intensity of the fluorescence signal provides information about the level of the autoantibodies. When using the recommended serum dilution of 1:80, these levels can be grouped into three categories: negative (no fluorescence at all), intermediate or positive [2]. Depending on the antibody type, the HEp-2 cells (specifically, only the ones with intermediate or positive level) will be characterized by distinct patterns of fluorescence. The ones that are mainly reported in literature are six: homogeneous, coarse speckled, fine speckled, centromere, nucleolar and cytoplasmic (Fig. 1).

The physicians analyze the microscope slide in three phases. First, they detect the mitotic cells, i.e. cells undergoing division, whose presence guarantees the good quality of the slide. Such cells have very distinct textural characteristics compared to the other cells of the image (Fig. 3). Second, they classify the fluorescence intensity level into negative, intermediate or positive (Fig. 2). Third, only for the intermediate and positive levels, they categorize each of the non-mitotic cells of the slide (namely, the interphase cells) into one of the six staining patterns of Fig. 1. This ultimately provides information about the type of CTD affecting the patient.

Most of the techniques for automated mitosis recognition or fluorescent patterns classification, such as those cited in Section 1, rely on cell segmentation as a preliminary step, even though they do not explicitly propose a method for such task. Hence, in the context of an automatization of the IIF ANA test, the accuracy of cell segmentation heavily affects the whole processing chain.

In this paper we focus solely on the automated segmentation of the HEp-2 cells. For more details about other IIF analysis tasks, the interested reader can refer to the publications cited in Section 1.

The available approaches to HEp-2 cell segmentation can be grouped into three broad categories. A first group includes the simplest procedures based on thresholding followed by morphological operations [23,24]. This approach is generally less accurate in the detection of cells characterized by irregular intensity patterns (e.g. the ones where very dark and very bright areas coexist in the same cell).

A second group of approaches try to overcome this limitation by splitting the segmentation process into two or more branches according to the characteristics of the regions obtained by either thresholding the images [6–8,25] or applying the watershed algorithm [9]. Most of these approaches have many dataset-dependent parameters, and do not tackle the segmentation of complex patterns such as the centromere (present only in [6]) and the cytoplasmic.

Finally, a third approach proposed in [10] is based on machine learning methods. Specifically, it performs a first rough segmentation to label the highest and lowest intensity pixels as foreground or background, respectively. Then, the final classification of the unlabeled pixels (i.e. the pixels with medium intensity) is obtained with a classifier trained on the labeled ones.

HEp-2 cell segmentation methods are often tested on IIF images with different characteristics in terms of resolution, contrast, noise level and fluorescent pattern, which makes a direct comparison impossible. A rigorous assessment of the most significant techniques in literature has been performed in [10] on a public benchmark of IIF images (the same used in this work). As confirmed by their results, the accurate segmentation of HEp-2 cells with different fluorescence patterns and intensity levels is still challenging, and most of the proposed techniques are sensitive to either over-segmentation (e.g. watershed technique) or under-segmentation problems (e.g. machine learning approaches). This motivates further research in this field.

In our experiments we used a public dataset, firstly adopted in [10] as a benchmark for IIF CAD systems and available online at http://mivia.unisa.it. It consists of 28 IIF images acquired with a fluorescence microscope (40-fold magnification) coupled with a 50W mercury vapor lamp and a digital camera with CCD squared pixel of 6.45μm. The 24 bit colour images have a resolution of 1388×1038 pixels and were manually segmented by medical specialists. The dataset contains a similar amount of positive and intermediate intensity images and a total number of 1582 objects, 70 of which are mitotic cells (Fig. 3). The remaining objects are interphase cells of all the six fluorescent patterns shown in Fig. 1. A detailed characterization of the dataset can be seen in Table 1
                     .

@&#PROPOSED METHOD@&#

The objective of our work is to design a segmentation algorithm which is robust to the high variance of the IIF image characteristics. To this end, in this paper we propose an adaptive marker-controlled watershed technique.

Watershed algorithm is a very popular and versatile approach for cell segmentation [26]. The marker-controlled version of this technique leverages on a set of markers defining the position of the cells in the image in order to reduce over-segmentation errors (a well-known limitation of watershed) and it has already been applied, in many variants, to other contexts of computer vision and biological imaging problems [27,28]. Nevertheless, the automatic extraction of “good” markers is very challenging, especially in images with very high variabilities. Hence, previous attempts to perform IIF image segmentation with this method (e.g. [9]) had limited success [10]. The implementation of a marker selection technique which self-adapts to the characteristics of the input image, as the one proposed in this work, is a possible solution to this problem.

Before detailing the contributions of our method, we summarize the two main findings of previous works on HEp-2 cell segmentation (Section 2.2) that were inherited by our technique.
                        
                           (i)
                           One single segmentation approach tackling all the HEp-2 patterns is generally not feasible. A rough pre-classification of the images into two or more categories of textures helps softening this problem [6,8,25].

A HEp-2 image can be generally divided into three main intensity bands. The highest intensity band contains cell pixels and the lowest intensity band contains background pixels. The medium intensity band contains pixels whose label (either cell or background) depends on the fluorescent pattern [10].

In order to provide a more general technique capable of tackling the widest range of HEp-2 images possible, in our work we designed a novel strategy for watershed marker extraction that exploits both these ideas.

In addition to this, the main contributions of our work are the following:
                        
                           (i)
                           a preventive image normalization step, where a morphological processing, self-adapted to the characteristics of the input image, helps softening variabilities due to different fluorescent levels and patterns;

the use of an adaptive technique for foreground object detection based on fuzzy c-means clustering, aimed at reducing the sensitivity to uneven illumination;

an improved technique for the selective separation of touching cells, which leverages on Randomized Hough Transform.

These aspects of our approach are aimed at strengthening the accuracy and robustness of the segmentation.

As an additional contribution, we propose a simple automated procedure to set the values of the algorithm parameters. These parameters are robust to variations in fluorescent intensity and staining pattern, hence they do not need to be adjusted image-by-image.

The main steps of our proposed technique are summarized in Fig. 4
                      and detailed in the following sections.

A preliminary preprocessing step consists in (i) converting the original RGB image into grayscale, by selecting its green channel, and (ii) performing a rough background subtraction to enhance the cell bodies. The latter process is obtained by subtracting from the image a simple model of its background, computed applying a smoothing average filter with a large kernel size K (details about parameter set-up in Section 5).

As anticipated in Section 4, structure and parameters of the processing pipeline automatically adapt to the characteristic of the input image. IIF images can be divided into two broad categories that show different textural characteristics and, hence, demand specific processing strategies:


                        Smooth textured images, characterized by a preponderance of high intensity pixels within the cell bodies and dark pixels in the background (e.g. the first three images of Fig. 1).


                        Rough textured images, where remarkable portions of the cells are as dark as the background (e.g. the last three images of Fig. 1).

It must be noted that there is no direct relation between the fluorescent pattern of the image and the textural categories that we defined. That is to say, two images expressing the same fluorescent pattern may have different textural characteristics and hence fall into different categories.

To label the incoming images as smooth or rough textured, we first binarize them with Otsu's thresholding algorithm, as proposed by [25]. Then, we compute the average area of the connected regions of the foreground and we compare it with a threshold T, roughly equivalent to the area of a HEp-2 cell (details about parameter set-up in Section 5). The rationale of this method is that in rough textured images each high-intensity region is a small portion of a HEp-2 cell. Hence, the average area of all the high-intensity regions in the image is likely to be smaller than the threshold. Vice versa, in smooth textured images this value is equal to or greater than the threshold.

The following steps of the algorithm are then tuned to the specific image category.

Image normalization is aimed at easing the marker extraction process by reducing the variabilities due to different intensity levels and fluorescent patterns. As mentioned before, different processing steps are applied to smooth and rough textured images.


                        Smooth textures. In order to normalize the characteristics of images with different intensity levels (Fig. 2), we first perform a global contrast enhancement through histogram equalization. Then, a gray-scale morphological opening is applied to remove residual noise (i.e. spurious dark pixels within the cell).


                        Rough textures. As in the previous case, we apply histogram equalization to normalize the contrast of intermediate and positive intensity level images. Before doing that, in order to limit the influence of the dark areas inside the cells, we enhance the intensity of the cell bodies with respect to the background. This is obtained by a combination of Top-Hat filtering and morphological greyscale reconstruction. First, white Top-Hat filtering is applied in order to reduce uneven illumination. Such operation subtracts to the original image its morphological opening, computed using a disk-shaped structuring element. Next, we apply morphological greyscale reconstruction as defined in [29], which consists in repeated dilations of a marker image until its contours fit a so-called mask image. In our technique, the morphological dilation of the original image is used as marker and the erosion as mask, respectively.

The automatic marker selection consists of several steps. First, we apply an adaptive fuzzy c-means clustering approach to roughly separate the foreground regions from the background taking uneven image illumination into account. Then, we locate the cell clusters (i.e. the regions including two or more touching cells) and apply a Randomized Hough Transform to split them into separate objects. At the end of this procedure, we obtain a collection of internal markers defining the position of the individual cells in the image, which, in turns, allows to extract a set of external markers defining the position of the background.

As anticipated at the beginning of this section, pixel intensities in IIF images can be roughly grouped into three bands: low, medium and high intensity. While we can assign with some degree of certainty low and high intensity pixels to, respectively, background and foreground, labeling pixels in the medium intensity band depends on the image category. In the smooth textured images, the foreground pixels are mostly gathered in the highest band of the intensity histogram, hence both the medium and low bands can be reliably attributed to the background. This does not hold for rough textured images, since in this case the medium intensity band contains both background and foreground pixels.

Taking this observation into account, we implemented an adaptive fuzzy c-means clustering technique to identify the foreground regions. In order to decrease the probability of segmentation errors due to uneven illumination, this technique is implemented with a sliding window approach, where each image pixel is labelled as foreground or background according to a local threshold on the pixel value. Such threshold is computed as follows. First, we center a square window of size W on a pixel p (details about parameter set-up in Section 5) and we partition the intensity values within such window into three clusters (low, medium and high-intensity) by means of a fuzzy c-means clustering algorithm, FCM [30]. FCM assigns to each pixel in the window a [0,1] degree of membership to each of the three clusters. These values are summarized by the membership functions in Fig. 5
                           , which represent the fuzzy behavior of the algorithm. Then, if the image was labelled as smooth textured, the threshold for pixel p is calculated as the intersection of the high and medium membership functions (value th
                           2 in Fig. 5); otherwise, for images labelled as rough textured, the threshold is calculated as the barycenter of the medium intensity cluster's membership function (value th
                           1 in Fig. 5).

Finally, binary morphological operations (i.e. holes filling, opening) are applied to regularize the foreground regions and eliminate spurious pixels.

The foreground regions identified in the previous step may either contain one individual cell or multiple touching cells. In the latter case, a unique marker must be assigned to each of their composing elements.

Individual cells are more elliptical than cell clusters, which are usually characterized by a very irregular shape. Thus, in order to tell the cell clusters apart from the individual cells, we impose a threshold on the ellipticity value of each foreground region, which is computed as the ratio between the area of a connected component and the area of its best-fitted ellipse. The threshold is estimated by calculating the average ellipticity of all the foreground objects in the image.

Each candidate cell cluster is then divided into a number of elliptical sub-regions through a geometric approach based on the Randomized Hough Transform, RHT [31]. RHT is a probabilistic variant of the classical Hough transform that is commonly used to detect curves. The approach is characterized by an iterative random sampling of three points on the object contour, which are then used to construct the best fitting ellipse. A voting procedure on the ellipse parameters allows to select the ones that are the most representative of the given contour. The resulting ellipses are a very rough approximation of the cell boundaries, and may partially overlap with each other (see Fig. 6
                           ). However, their centers indicate the most likely position of the individual cells within the cell clusters.

Summarizing, we obtain a set of internal markers including the following collections of points: (i) the pixels of the foreground regions labelled as individual cells and (ii) the centers of the ellipses obtained after the RHT-based decomposition of the candidate clusters. The set of external markers is then obtained by picking the edge points of a Voronoi diagram built using the internal markers as seeds.

The final cell segmentation is obtained applying a marker-controlled watershed on the gradient of the normalized image (Section 4.3). As it is widely known, watershed algorithm treats the gradient image as a 3D topography surface, starting a region growing from its regional minima. Here, we modify the gradient image so that the regional minima occur at the locations specified by the internal and external markers.

As discussed in Section 2.2, a frequent limitation of previous HEp-2 segmentation techniques is their dependency on a large number of parameters that need to be manually adjusted by the user. In our work, the segmentation pipeline depends on three parameters only, whose values are strictly related to the dimension of the objects to be segmented. These parameters are the following:
                        
                           
                              K – kernel size of the averaging filter (Section 4.1),


                              T – threshold to separate smooth and rough textured images (Section 4.2),


                              W – window size of the adaptive FCM clustering (Section 4.4.1).

In our experiments, K, T and W were set as follows:
                        
                           (i)
                           we randomly picked six sample images (one per pattern) and performed a binarization by Otsu thresholding as described in Section 4.2;

we evaluated the average diameter d
                              
                                 AVG
                               and the average area A
                              
                                 AVG
                               of all the connected regions obtained from (i);

we set K, T and W as, respectively, 3×
                              d
                              
                                 AVG
                              , A
                              
                                 AVG
                               and d
                              
                                 AVG
                              .

It must be noted that K, T and W are reasonably robust to variations of fluorescent intensity and pattern. Provided that all the images have been acquired with the same magnification, objects with the same pattern exhibit small size differences, compared to the large variation of size displayed by objects with different patterns. Indeed, picking one sample image per pattern allows taking both these variations into account. Hence, the value of the parameters will ultimately be influenced by image resolution only. This is very convenient for the clinical practice, as the parameters can be fixed once-for-all for datasets acquired with the same magnification.

The robustness of the proposed technique is confirmed by our preliminary experiments, where extensive permutations of the images used as samples translated into a very low variation of the estimated parameters values (less than 4%). At the same time, manually changing the automatically set values by up to 30% for K, 20% for T and 50% for W had no effect on segmentation quality.

The described segmentation pipeline was applied to the dataset of IIF images introduced in Section 3. In order to avoid any bias in the validation, the segmentation parameters of each image were calculated using six randomly picked samples (one per pattern, as explained in Section 5) which did not include the tested one. In Fig. 7
                      we show six examples of final segmentations, one per each fluorescent pattern.

Based on the qualitative visual assessment of an expert, who was asked to provide a binary evaluation (correct/not correct) of the automated segmentations, our algorithm was able to correctly identify about 80% of the cells in the dataset and more than 60% of the mitotic cells. Clustered cells were successfully separated (i.e. with individual cells correctly identified) in 83% of the cases. Details of this qualitative assessment in each of the six fluorescent patterns are reported in Table 2
                     .

Besides visual assessment, we performed a thorough quantitative evaluation of the accuracy of our technique, based on a pixel-wise comparison between the ground truth and the corresponding automated segmentation. The following metrics were used:


                     
                        
                           (1)
                           
                              Precision
                              =
                              
                                 TP
                                 
                                    TP
                                    
                                    +
                                    
                                    FP
                                 
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              Recall
                              =
                              
                                 TP
                                 
                                    TP
                                    
                                    +
                                    
                                    FN
                                 
                              
                           
                        
                     
                     
                        
                           (3)
                           
                              f
                              -index
                              =
                              
                                 
                                    2
                                    ·
                                    Precision
                                    ·
                                    Recall
                                 
                                 
                                    Precision
                                    
                                    +
                                    
                                    Recall
                                 
                              
                           
                        
                     where for consistency with the previous works, the values of TP (number of true positives), FP (number of false positives) and FN (number of false negatives) were computed according to the extended cell-level definitions proposed in [10].

Back to the evaluation metrics, the precision is a measure of how exact the system is in assigning pixels to the cells, while the recall (also known as sensitivity) is a measure of its ability to identify cell pixels among the others. These two metrics are meaningful only when considered jointly. In general, under-segmentation leads to high values of precision and low recall, while over-segmentation leads to high recall and low precision. For example, a system that assigns all the pixels of the image to the cells and none to the background would obtain a recall of 100%! Thus, a “good” segmentation translates into a good compromise between precision and recall, which, in turn, reflects into higher f-index values.

Overall, our results show a precision of 89.0%, a recall of 63.9% and an f-index value of 74.4%.

In order to assess these numbers, we performed a comparison with the values obtained on the same IIF images by some of the most representative methods from literature (data from [10]).

Other methods mentioned in Section 2.2, such as the one reported in [25], were not included in this evaluation, because they address private databases of IIF images with different characteristics in terms of intensity levels and fluorescent patterns. Furthermore, some of them rely on a large number of dataset-dependent parameters. Hence, in absence of a clearly defined method to adjust these parameters to different types of images, a direct comparison with our technique would not be fair.

The graph in Fig. 8
                      reports the performance of our proposed technique and of the methods taken for comparison, named with the same nomenclature used in [10]. Such performances are depicted as points in a 2D space, where the x coordinate is the value of precision and the y coordinate the recall. The f-index value is represented by the color, where darker zones of the graph are associated to lower f-index values and brighter ones to higher f-index values, i.e. to better segmentation performance. The ideal segmentation, where all the performance metrics are equal to 1, is represented in this space by the upper right corner of the graph.

As shown in Fig. 8, our method outperforms the other techniques in terms of precision and of f-index, the overall figure of merit. There is only one method obtaining a recall higher than ours, namely the one referred to as Watershed 
                     [9]. Nevertheless, its lower precision (33.5%) suggests over-segmentation problems. The Auto-learning classification-based approach proposed in [10], methods (5) and (6) in the graph, obtained precisions similar to our technique (around 85%) but much lower recalls (around 45%), which indicates higher under-segmentation errors.

Similar considerations can be made analyzing the individual results of the six fluorescent patterns. In the first six rows of Table 3
                      we compare the values of precision, recall and f-index of our technique with the previous work that obtained the best f-index performance in each specific pattern (data from [10]). Again, in all cases we obtained the highest f-index score, higher precision (except for speckled patterns) and higher recall (exception made for centromere pattern). Overall, the performance of our method was good in all the patterns (f-index higher than 70%) with the only exception of the cytoplasmic class, where we obtained a f-index of 49%, still higher than the other techniques by more than 13%. Indeed, cytoplasmic images have a very different pattern compared to all the others, due to the fact that the fluorescent signal generates from the cytoplasm rather than the nucleus of the cell (as the name Antinuclear Antibody would suggest). Hence, even though the cytoplasmic antibodies are often included with the ANAs in the clinical practice, these images would benefit from the implementation of ad-hoc segmentation strategies to cope with their specific criticalities. Moreover, as clarified in [22], in the IIF dataset different types of cytoplasmic antibodies are grouped together in the same category, which contains only four images in total. This translates into even higher variability of this pattern compared to the others.

Finally, the last row of Table 3 shows the performance of our algorithm on the segmentation of the mitotic cells, which is a necessary preventive step of mitosis recognition (see Section 2.1). This is a type of evaluation that was never reported before in the literature. Despite not excellent values of sensitivity and recall (65.5% and 64.5%, respectively), their good balance translates into an interesting f-index of 65% (see the star-shaped marker in Fig. 8).

In this paper we described a procedure for the automated segmentation of HEp-2 cells, which is one of the most critical and challenging steps in a CAD system applied to IIF images.

Our proposed solution is an adaptive marker-controlled watershed approach, aimed at improving the automatic extraction of markers and, ultimately, the segmentation accuracy. The main features of our algorithm are:
                        
                           (i)
                           the adaptiveness of both the preprocessing and the marker selection strategy to the peculiar characteristics of the input image;

an improved pipeline for the watershed marker selection, which takes advantage of domain-specific knowledge about the textural and geometrical characteristics of the HEp-2 cells to reduce the sensitivity to uneven illumination and over-segmentation errors.

Our experiments show that our solution helps softening the main limitations of the previous techniques in approaching datasets with high variations of image characteristics. As such, our algorithm is able to provide segmentation of IIF images with different intensity levels and fluorescent patterns without requiring any a priori knowledge of the image type and with a good level of accuracy and robustness.

In the future, we will investigate further improvements of our work, with special regards to the design of segmentation strategies ad-hoc for the cytoplasmic images. This would require to extend our dataset first. Finally, we plan to integrate our segmentation technique into a complete solution for the automated IIF analysis, including the quantification of fluorescent intensity, the recognition of mitotic cells and the classification of fluorescent patterns.

@&#REFERENCES@&#


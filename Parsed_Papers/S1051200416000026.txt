@&#MAIN-TITLE@&#Audio steganalysis based on reversed psychoacoustic model of human hearing

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Based on a model with maximum deviation from human auditory system, a new steganalysis method is proposed.


                        
                        
                           
                           The method is tested on wide range of data hiding algorithms and in both targeted and universal scenarios.


                        
                        
                           
                           The proposed method improves detection rate of targeted and universal scenarios by 17.3% and 20.8%.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Audio steganalysis

Universal steganalysis

Audio steganography

Mel frequency cepstrum coefficients

Human auditory system

@&#ABSTRACT@&#


               
               
                  During the last decade, audio information hiding has attracted lots of attention due to its ability to provide a covert communication channel. On the other hand, various audio steganalysis schemes have been developed to detect the presence of any secret messages. Basically, audio steganography methods attempt to hide their messages in areas of time or frequency domains where human auditory system (HAS) does not perceive. Considering this fact, we propose a reliable audio steganalysis system based on the reversed Mel-frequency cepstral coefficients (R-MFCC) which aims to provide a model with maximum deviation from HAS model. Genetic algorithm is deployed to optimize dimension of the R-MFCC-based features. This will both speed up feature extraction and reduce the complexity of classification. The final decision is made by a trained support vector machine (SVM) to detect suspicious audio files. The proposed method achieves detection rates of 97.8% and 94.4% in the targeted (Steghide@1.563%) and universal scenarios. These results are respectively 17.3% and 20.8% higher than previous D2-MFCC based method.
               
            

@&#INTRODUCTION@&#

Subliminal channels are types of covert channels which are used for stealth communication over innocuous-looking insecure channels. This concept was first introduced by Simmons as the prisoner's problem [37]. Two accomplices have been arrested and are kept in separate cells. They want to cook up an escape plan but they can only communicate through a vigilant warden who will deliver only innocuous messages. Steganography is among the ways to implement such subliminal channel. Steganography consists of an embedding algorithm (
                        
                           
                              A
                           
                           
                              em
                           
                        
                     ) that hides a message (
                        m
                        ∈
                        M
                     ) into an innocent-looking signal called cover (
                        c
                        ∈
                        C
                     ) and results in a stego signal (
                        s
                        ∈
                        S
                     ). On the receiver side, another algorithm (
                        
                           
                              A
                           
                           
                              ex
                           
                        
                     ) is used to extract hidden message from the stego signal. A steganography system is called secure if the spaces of cover and stego coincide with each other:
                        
                           (1)
                           
                              
                                 C
                                 =
                                 S
                              
                           
                        
                     
                  

On the other hand, steganalysis is the countermeasure of warden to detect presence of any subliminal channel. If cover signals are empirical [4] then for practical steganography systems, assumption of (1) does not hold and there would be a deviation between 
                        C
                      and 
                        S
                     . This discrepancy can be exploited to discriminate between cover and stego signals. If 
                        
                           
                              A
                           
                           
                              em
                           
                        
                      and statistical model of 
                        C
                      are known a-priori, optimum detector can be designed using statistical decision theory, otherwise a set of suitable feature and machine learning techniques should be employed [21].

Considering different types of cover media, steganographic systems can be divided into five major categories including image, audio, video, text, and network. Reviewing literature shows that on the contrary to the image, audio steganographic systems have found less attention so far. It is noteworthy that, steganography and steganalysis like many new trends in cryptology such as multimedia encryption systems [18], multimedia secret sharing, and water marking rely heavily on signal processing techniques.

Regarding the functionality of steganalysis systems, they are either universal or targeted. In the former one, the detector does not have any prior knowledge about 
                        
                           
                              A
                           
                           
                              em
                           
                        
                     , while in the latter one the system is designed specifically for detecting signatures of a particular method. Over the past decade, different audio steganalysis systems have been proposed. Based on the nature of their features, they can be divided into two distinct types:
                        
                           1.
                           Methods that extract their features by comparing the input signal with a reference signal

Methods based on extracting features directly from the signal


                     Steganalysis by comparing signal with a reference:
                  

Extracting a proper reference signal is the main issue in this category. There are different methods to generate the reference signal for this paradigm. One possible solution is applying denoising method to the input signal in order to provide an estimation of the cover signal. The first method in this area was proposed in [28]. They also used audio quality metrics (AQMs) to quantify the deviation between input signal and generated reference signal [29]. In [14], they argued that AQMs have been designed specifically to detect modifications of pure audio contents. They proposed Hausdorff distance for a better representation of dissimilarity between reference and input signal. Johnson et al. proposed another method for creating reference signal. They used a set of bases functions that were localized in both time and frequency domains to capture regularities of audio signals. These bases aimed to estimate a reference for every input signal. The deviation between reference and input signals was modeled by different moments [20]. In another work, a reference signal independent of input signal was applied [1]. Avcıbas showed that if reference is generated from input signal, then the extracted features depend on both message and content of the cover signal. This dependency on the cover signal may diminish generalization property of the system. They used a constant pair of cover-stego signal for referencing. They showed that this technique improves steganalysis results.


                     Steganalysis by direct inspection of input signal:
                  

In this scenario, the features are extracted directly from input signals. First, steganalysis was integrated into an intrusion detection system. This work used ratio of ones and zeros in the LSBs to detect steghide [9]. Ru et al. used wavelet and linear prediction techniques to extract correlation between samples of input signals [34]. They employed different statistical moments calculated from the residual signal of every sub-band of wavelet tree for steganalysis. MFCC as one of the most well-known features were examined to improve steganalysis results in [24]. This work also demonstrated that removing speech relevant components of speech signal is beneficial for improving steganalysis. In [13], the first three moments of time and frequency histograms of input signal and its wavelet sub-bands were exploited for proposing a proper steganalysis scheme. Principle component analysis (PCA) was applied to reduce the features' dimension. In [23], it was argued that due to the existence of chaotic phenomena in speech signals, chaotic-based features may be employed to boost detection of audio steganalysis algorithms. It was shown that steganography noise increases chaoticity and dimension of phase space in the stego signals. Then, values of false neighbor fraction and Lyapunov spectrum were used to quantify chaotic characteristics of the analyzed signals. Markov transition probabilities were proposed in [25]. They introduced a metric for measuring complexity of different cover signals and showed that performance of their method maintained good even for complex signals. Liu et al. showed that second order derivative magnifies the differences between spectrum of cover and stego signals [26]. A steganalysis system based on auto regressive time delay neural network was proposed in [31]. A combination of different invariant moments and features was used by Bhattacharyya to model deviation between cover and stego signals [2].

Investigating previous audio steganalysis methods shows that:
                        
                           1.
                           As the most basic requirement, the effects of steganography should not be detectable by human perception systems. Therefore, processing a cover and its stego version with a “perfect” model of human perception system virtually should produce the same results, and they should be indistinguishable. For example in [24,26] Mel frequency cepstral coefficients (MFCC) have been used for feature extraction. MFCC is a model that mimics frequency resolution of HAS. Other characteristics of HAS that have been used in steganalysis literature include loudness, pre-masking and post-masking [1,28,29]. For instance, loudness belongs to the category of intensity sensations and it is primarily a psychological characteristic. It is known that HAS has the lowest sensitivity in the high frequencies; therefore, incorporating loudness in the feature extraction wipes out faint noises in the high frequency portions of the signal, a region that is very valuable for steganalysis. These ideas are discussed more thoroughly in the section 2 of this paper.

Most of the previous works have investigated only LSB steganography and its different implementations. Furthermore, to address steganography systems that resist active warden, these works have used watermarking methods [1,23,29]. We believe that reliable results for active warden are achieved if robust steganography methods are investigated. The rationale behind this claim is that undetectability is not a prerequisite for watermarking systems. Therefore, reliable detection of watermarking methods does not necessarily lead to a reliable detection of robust steganography methods.

Although most of previous works have claimed a universal steganalysis system but all of them (except for [29], to the best of our knowledge) have only reported results of targeted simulations.

Continuing on our seminal work [16], this paper aims to address these problems. Specifically the following contributions are made:
                        
                           –
                           A new model with the maximum deviation from HAS is proposed. Then, this model is exploited for extracting a new set of features. Finally, genetic algorithm (GA) is invoked for a near optimum feature selection.

The reliability of the proposed steganalysis system is tested on a wide range of steganography methods including LSB, DWT, and DCT domain methods. Also, for the sake of completeness and better comparison with previous works, two watermarking methods are also considered.

Both targeted and universal steganalysis scenarios are pursued.

The rest of this paper is organized as follows. Section 2 includes some preliminaries on the HAS and its relations with steganographic concepts. Section 3 elaborates on the proposed method. Experimental results are presented in section 4. Discussion follows in section 5 and finally conclusions are made in section 6.

Basilar membrane within cochlea of the inner ear is the base for sensory cells of hearing. Previous studies have shown that cochlea operate as a kind of mechanical frequency analyzer [35]. Further studies have discovered that the produced effects in the inner ear are not linear or logarithmic over the whole length of the basilar. In contrast, other scales such as pitch ratio and critical-band can be plotted on linear scales along the basilar membrane. Therefore, in characterizing HAS either the critical-band scale or the pitch ratio scale are more useful than the frequency scale [12].


                     Pitch ratio and Mel Scale:
                  

To measure pitch of a pure tone, one possible procedure is to present human subjects with a pure tone of frequency 
                        
                           
                              f
                           
                           
                              1
                           
                        
                      and ask them to adjust a second frequency 
                        
                           
                              f
                           
                           
                              2
                           
                        
                      such that 
                        
                           
                              f
                           
                           
                              2
                           
                        
                      produces half pitch of the first tone. Subjective measurements have shown that at low frequencies, halving of the pitch sensation corresponds to the ratio of 
                        
                           
                              f
                           
                           
                              1
                           
                        
                        /
                        
                           
                              f
                           
                           
                              2
                           
                        
                        =
                        2
                      while in the frequencies above 1 KHz, this ratio is larger than 2 [12]. According to these observations, for each tone with an actual frequency measured in hertz, a subjective pitch is calculated on a scale called ‘Mel’. Equation (2) shows the mathematical formula for converting a given frequency (f) in hertz to its corresponding Mel value.
                        
                           (2)
                           
                              
                                 
                                    Mel
                                 
                                 =
                                 1127
                                 ×
                                 ln
                                 ⁡
                                 
                                    (
                                    1
                                    +
                                    
                                       f
                                       700
                                    
                                    )
                                 
                              
                           
                        
                     
                  


                     Mel-frequency cepstral coefficients:
                  

Cepstrum is the anagram of the word spectrum which reflects information about the rate of power changes in different spectrum bands. Later, this metric was tweaked to mimic characteristics of HAS. These new coefficients are commonly known as MFCC and have found numerous applications such as speaker identification [33] and speech recognition [30].

Assume that F denotes fast Fourier transform, MFCCs are calculated as:
                        
                           (3)
                           
                              
                                 
                                    
                                       S
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 ∑
                                 F
                                 
                                    (
                                    x
                                    (
                                    t
                                    )
                                    )
                                 
                                 .
                                 
                                    
                                       W
                                    
                                    
                                       k
                                    
                                 
                                 ;
                                 
                                 
                                    
                                       C
                                    
                                    
                                       m
                                    
                                 
                                 =
                                 F
                                 
                                    (
                                    log
                                    ⁡
                                    (
                                    
                                       
                                          S
                                       
                                       
                                          k
                                       
                                    
                                    )
                                    )
                                 
                              
                           
                        
                      Where M is the number of filters in the Mel bank, and 
                        
                           
                              W
                           
                           
                              k
                           
                        
                      is the triangular weighting function corresponding to the k-th filter. These filters are constructed as follows:
                        
                           –
                           In the target scale (R-Mel or Mel), linearly divide the whole spectrum into 
                                 M
                                 +
                                 1
                               parts.

Convert stop and start points of all parts to hertz. This will lead to 
                                 M
                                 +
                                 2
                               distinct points.


                              
                                 
                                    
                                       W
                                    
                                    
                                       k
                                    
                                 
                               is a triangle such that it starts from i-th point, reaches its peak at 
                                 i
                                 +
                                 1
                              th point and returns to zero at the 
                                 i
                                 +
                                 2
                              th point. Sometimes these triangles are normalized such that they have areas equal to one.


                     Steganography and Human Auditory System
                  

Reviewing the steganography literature shows that many works have used peak signal to noise ratio (PSNR) or signal to noise ratio (SNR) to imply security of their methods. Furthermore, Zamani et al. investigated the correlation between PSNR and the capacity of audio steganography [41]. They showed that PSNR decreases with increasing the capacity. Logically, increasing the capacity of a certain method enhances its probability of detection. Therefore, it can be inferred that lower values of PSNR lead to higher probability of detection. Based on this assumption, effect of a typical audio steganography system is investigated. Let us model the effect of steganography as an additive noise:
                        
                           (4)
                           
                              
                                 s
                                 (
                                 t
                                 )
                                 =
                                 c
                                 (
                                 t
                                 )
                                 +
                                 n
                                 (
                                 t
                                 )
                              
                           
                        
                      We take discrete time Fourier transforms from both sides:
                        
                           (5)
                           
                              
                                 S
                                 
                                    (
                                    
                                       
                                          e
                                       
                                       
                                          j
                                          w
                                       
                                    
                                    )
                                 
                                 =
                                 C
                                 
                                    (
                                    
                                       
                                          e
                                       
                                       
                                          j
                                          w
                                       
                                    
                                    )
                                 
                                 +
                                 N
                                 
                                    (
                                    
                                       
                                          e
                                       
                                       
                                          j
                                          w
                                       
                                    
                                    )
                                 
                              
                           
                        
                      Then, the whole spectrum of the signal is divided into L equally spaced sub bands:
                        
                           (6)
                           
                              
                                 (
                                 i
                                 −
                                 1
                                 )
                                 ×
                                 
                                    π
                                    L
                                 
                                 ≤
                                 
                                    
                                       B
                                    
                                    
                                       i
                                    
                                 
                                 ≤
                                 i
                                 ×
                                 
                                    π
                                    L
                                 
                                 ,
                                 
                                 1
                                 ≤
                                 i
                                 ≤
                                 L
                              
                           
                        
                      We define sub-band SNR of signal as:
                        
                           (7)
                           
                              
                                 
                                    
                                       SNR
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 10
                                 
                                    
                                       log
                                    
                                    
                                       10
                                    
                                 
                                 ⁡
                                 
                                    (
                                    
                                       
                                          
                                             
                                                ∫
                                             
                                             
                                                B
                                                i
                                             
                                          
                                          |
                                          C
                                          (
                                          
                                             
                                                e
                                             
                                             
                                                j
                                                w
                                             
                                          
                                          )
                                          
                                             
                                                |
                                             
                                             
                                                2
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∫
                                             
                                             
                                                B
                                                i
                                             
                                          
                                          |
                                          N
                                          (
                                          
                                             
                                                e
                                             
                                             
                                                j
                                                w
                                             
                                          
                                          )
                                          
                                             
                                                |
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                    )
                                 
                                 ,
                                 
                                 1
                                 ≤
                                 i
                                 ≤
                                 L
                              
                           
                        
                     
                  

In order to investigate the effect of steganography on different sub bands, a total number of 4169 audio files were embedded with different data hiding methods. The methods included Hide4Pgp [32], Steghide [19], spread spectrum in the frequency domain [27], error-free wavelet method [36], and two watermarking methods of spread spectrum [22], and the DCT-based robust watermarking method (COX) [7]. After dividing the whole spectrum of cover and noise signals into 29 sub-bands, values of 
                        
                           
                              SNR
                           
                           
                              i
                           
                        
                      were calculated for all files. Fig. 2
                      shows average values of 
                        
                           
                              SNR
                           
                           
                              i
                           
                        
                      over all the files. (Notations are in accordance with those of Table 1
                     .)

The main purpose of steganographic communication is to hide the mere existence of a secret message. Therefore, the most primary requirement of a steganographic system is to remain undetectable. Thus, in its most rudimentary form, it is crucial that the human perception system (ears in the case of audio steganography and eyes in the case of image) should not be able to distinguish between the stego and cover signals. In other words, effects of steganography should not be detectable by human perception systems. According to this fact, a true model of human perception system should be indifferent to steganography. Thus, it is very likely that employing features based on human perception systems leads to discarding vital information.

Investigating different audio covers shows that as frequency increases, their power spectrums decrease so they can be considered as band-limited signals. On the other hand, investigating noise of steganography indicates that it is a broadband signal. Consequently, it is expected that the value of 
                        
                           
                              SNR
                           
                           
                              i
                           
                        
                      decreases with increasing of the frequency. Fig. 2 supports this claim.

Comparing results of Fig. 2 and characteristics of HAS reveals interesting facts. According to Fig. 1, Mel scale has its highest resolution in the lower frequencies and its lowest resolution in the higher frequencies. On the other hand, according to Fig. 2, high frequency portions of the signal tend to reveal the effects of steganography more clearly. Therefore, features based on HAS are not very suitable. It is noteworthy that steganalysis methods [1,28,29] that have incorporated other psychoacoustic characteristics of HAS (such as loudness and masking [12]) in their feature extraction routine, have produced inferior results to MFCC-based systems. We believe these inferior results are due to extracting features from a more accurate model of HAS.


                     Reversed Mel Scale:
                  

Based on our previous discussions, we propose an artificial auditory model that has maximum deviation from HAS. Specifically, our suggested model employs a new scale called reversed-Mel scale (R-Mel) that has reversed frequency resolution of HAS. The new scale has its highest resolution in high frequencies and its lowest resolution in low frequencies. If 
                        
                           
                              F
                           
                           
                              S
                           
                        
                      denotes sampling frequency of the signal, we define the R-Mel value of a given frequency f in hertz as:
                        
                           (8)
                           
                              
                                 
                                    RMel
                                 
                                 =
                                 1127
                                 ×
                                 ln
                                 ⁡
                                 
                                    (
                                    1
                                    +
                                    
                                       
                                          0.5
                                          ×
                                          
                                             
                                                F
                                             
                                             
                                                s
                                             
                                          
                                          −
                                          f
                                       
                                       700
                                    
                                    )
                                 
                              
                           
                        
                     
                  

Based on this new scale, a new set of triangular weighting functions is constructed. These new filters are used in equation (3) to produce reversed-Mel frequency cepstral coefficients (R-MFCC). Fig. 1 compares filter banks constructed based on Mel with R-Mel scale. Investigating filers constructed on the Mel scale shows that these filters are more concentrated in the lower frequencies. In other words because triangles in the low frequencies have smaller width, more coefficients will be extracted from low frequencies. Therefore, we say Mel scale has higher frequency resolution in the lower frequencies. On the other hand, filters constructed on the R-Mel scale have exactly the opposite characteristics. That is, the filters have finer resolutions in the higher frequencies and coarser resolutions in the lower frequencies.

Our proposed method is based on taking advantages of R-MFCC coefficients discussed in the previous section. We believe that these features provide suitable discrimination between cover and stego audio files.


                     Analysis of the Proposed Features:
                  

According to equations (3) and (4), the discriminating factor between the cover and stego is:
                        
                           (9)
                           
                              
                                 
                                    
                                       
                                          D
                                       
                                       
                                          =
                                          F
                                          
                                             (
                                             log
                                             ⁡
                                             
                                                (
                                                ∑
                                                F
                                                (
                                                c
                                                +
                                                n
                                                )
                                                .
                                                
                                                   
                                                      W
                                                   
                                                   
                                                      k
                                                   
                                                
                                                )
                                             
                                             )
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                          −
                                          F
                                          
                                             (
                                             log
                                             ⁡
                                             
                                                (
                                                ∑
                                                F
                                                (
                                                c
                                                )
                                                .
                                                
                                                   
                                                      W
                                                   
                                                   
                                                      k
                                                   
                                                
                                                )
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                      Using some basic manipulation, (9) reduces to:
                        
                           (10)
                           
                              
                                 D
                                 =
                                 F
                                 
                                    (
                                    log
                                    ⁡
                                    
                                       (
                                       
                                          
                                             ∑
                                             F
                                             (
                                             c
                                             +
                                             n
                                             )
                                             .
                                             
                                                
                                                   W
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             ∑
                                             F
                                             (
                                             c
                                             )
                                             .
                                             
                                                
                                                   W
                                                
                                                
                                                   k
                                                
                                             
                                          
                                       
                                       )
                                    
                                    )
                                 
                              
                           
                        
                     
                     
                        
                           (11)
                           
                              
                                 D
                                 =
                                 F
                                 
                                    (
                                    log
                                    ⁡
                                    
                                       (
                                       1
                                       +
                                       
                                          
                                             ∑
                                             F
                                             (
                                             n
                                             )
                                             .
                                             
                                                
                                                   W
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             ∑
                                             F
                                             (
                                             c
                                             )
                                             .
                                             
                                                
                                                   W
                                                
                                                
                                                   k
                                                
                                             
                                          
                                       
                                       )
                                    
                                    )
                                 
                              
                           
                        
                      Now let us investigate equation (11) for both MFCC and R-MFCC cases. According to the discussion of section 2, the most discriminative features would be extracted from high frequency regions; thus, the last weighting function of Mel and R-Mel banks are considered. Assuming 
                        
                           
                              F
                           
                           
                              S
                           
                        
                        =
                        44
                        
                        100
                     , and 
                        M
                        =
                        29
                     , the 
                        
                           
                              W
                           
                           
                              29
                           
                        
                      of MFCC and R-MFCC have non-zero values in the regions of [17 340, 22 050] Hz and [21 869, 22 050] Hz, respectively. Apparently, 
                        
                           
                              W
                           
                           
                              29
                           
                        
                      in the MFCC has larger number of non-zero components; therefore, denominator of equation (11) for MFCC feature is larger than the R-MFCC case.
                        
                           (12)
                           
                              
                                 ∑
                                 F
                                 (
                                 c
                                 )
                                 .
                                 
                                    
                                       W
                                    
                                    
                                       29
                                       -MFCC
                                       
                                    
                                 
                                 >
                                 ∑
                                 F
                                 (
                                 c
                                 )
                                 .
                                 
                                    
                                       W
                                    
                                    
                                       29
                                       
                                          R-MFCC
                                       
                                    
                                 
                              
                           
                        
                      Furthermore, frequency components of noise are much smaller than their cover counterparts; thus, the numerator cannot compensate for this increase in the value of denominator. In other words, in the high frequency regions, the discriminating factors of (11) are larger in R-MFCC case than their MFCC counterparts.
                        
                           (13)
                           
                              
                                 
                                    
                                       D
                                    
                                    
                                       29
                                       
                                          -RMFCC
                                       
                                    
                                 
                                 >
                                 
                                    
                                       D
                                    
                                    
                                       29
                                       -MFCC
                                       
                                    
                                 
                              
                           
                        
                     
                  


                     Feature Extraction:
                  

After normalizing data to 
                        [
                        −
                        1
                        ,
                        1
                        ]
                     , it was segmented into frames of 1024 samples with overlap of 512. Then, R-MFCCs were calculated for each frame. In this paper, 29 different filters were used. Features were calculated as the values of mean, standard deviation, skewness, and kurtosis of each R-MFCC coefficient over all the frames. Previous works have shown that employing second order derivative of the signal leads to better discriminating features [25,26]. Based on this idea, the same procedure was applied on the second order derivative of the input signal. This second set of features is denoted by D2-R-Mel. Fig. 3
                      illustrates the feature extraction procedure.


                     Preprocessing:
                  

Investigating the extracted features shows that:
                        
                           1.
                           The values of extracted features from some observations in the same class are significantly different from each other.

Different features tend to have different dynamic ranges.

Observations with significantly different feature values are called outliers. Outliers are either results of noisy measurements or distribution with long tails [39]. Removing the noise and outliers during training allows the learning algorithm to find more accurate classification boundaries [38]. Therefore, in the training phase, outliers were removed using the distance-based method implemented in [11]. In this method, distances between all observations from the same class were calculated. If the distance between an observation and more than 10% of other observations was larger than a threshold, it was considered as an outlier. Also, the threshold was defined as the mean of distances plus three times their standard deviation.

Another problem in classification stems from features with high values. Such features may influence cost function of the classifier more, regardless of their effectiveness in discrimination. Features were normalized to alleviate this problem. To this end, mean and variance of features over train set were calculated, and then features were normalized according to equation (14):
                        
                           (14)
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                       k
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                             k
                                          
                                       
                                       −
                                       
                                          
                                             m
                                          
                                          
                                             k
                                          
                                       
                                    
                                    
                                       
                                          σ
                                       
                                       
                                          k
                                       
                                    
                                 
                              
                           
                        
                      Furthermore, the values of 
                        
                           
                              m
                           
                           
                              k
                           
                        
                      and 
                        
                           
                              σ
                           
                           
                              k
                           
                        
                      were retained for applying normalization to test samples.


                     Dataset:
                  

Our cover signals consisted of 4169 mono uncompressed audio wave files with frequency of 44 100 Hz and 16 bits resolution. The duration of each excerpt was 10 seconds and they covered wide range of music genres and languages [16]. All covers were embedded with random messages; furthermore, the message was changed for each cover. Different steganography and watermarking algorithms were used to hide message. The steganography algorithms in this study were Hide4Pgp, Steghide, spread spectrum in the frequency domain, error-free wavelet method, and watermarking methods are spread spectrum, and the DCT-based robust watermarking method (COX).


                     Embedding Strength:
                  

Expressing embedding strength of steganographic methods can be accomplished through two different metrics of capacity ratio and bit-per-bit percent (BPB). Capacity ratio is the ratio of embedding rate to the maximum capacity of a particular method. Also, BPB is the ratio of message size to the size of cover. Although previous audio steganalysis studies have used capacity ratio for expressing embedding strength, BPB is much more suitable. First, steganography tries to implement a subliminal channel which its efficiency is equal to the ratio of message size to the cover size. Therefore, BPB quantifies objective of steganography more closely. Furthermore, BPB is a universal metric and can be used across different steganography methods and different bit resolutions of cover signals. Thus, BPB provides a meaningful way of comparing different steganography methods. Table 1 presents details of the employed database.


                     Feature Selection:
                  

In classification tasks, there are usually some irrelevant or redundant features. In fact, there is no useful information with irrelevant features and also redundant features do not provide further information than the currently selected features. Such features increase complexity of feature extraction (as the most time-consuming part of the system) while they provide no useful information. Furthermore, high dimensional space increases the computational complexity of the classifier and it may also diminish its generalization property [40]. Due to its good performance [17], GA was invoked to choose a near-optimum subset of features. We used accuracy of the classifier as the fitness function, population size of 200 individuals, tournament selection [3], and two-point crossover [15]. For selecting k out of n features, genes were encoded as a decimal array of length k. Initially, this array was filled with k random draws from set of 
                        [
                        1
                        ,
                        n
                        ]
                      without replacement. To further improve the performance of GA, selection operation was followed by elitism [8] which was implemented as directly selecting 1% of the mating population from the best chromosomes. Finally, mutation with rate of 1% was implemented as replacing one of already selected features with one of the remaining ones.


                     Classifier:
                  

The process of distinguishing cover from stego samples needs a classifier to define a suitable decision boundary. This work employs support vector machine (SVM) for its superb performance [17]. SVM is basically based on Vapnik's statistical learning theory in which a maximum-margin hyper plane is created to distinguish the training vectors from different classes [6]. Furthermore, if features are not linearly separable, it is possible to map the original problem into a much higher-dimensional space and achieve better classification result. This task is accomplished by applying a suitable kernel function. In this work, SVM is applied by using the non-commercial package LIBSVM [5] with radial basis function (RBF).

@&#EXPERIMENTAL RESULTS@&#

Scatter plots of both MFCC and R-MFCC of the second order derivative of cover signal and steghide@1.563 BPB are shown in Fig. 4
                     .

Comparing Figs. 4.A and 4.B shows that features based on R-Mel scale are more separated than features extracted based on Mel scale. This observation justifies our initial assumption that features extracted based on the idea of maximum deviation from HAS would lead to more discriminative features.

GA was invoked to select the best subset of features for optimum detection of steghide@1.563% BPB. The results showed that the best accuracy was achieved when 21 features were selected. These indexes were used for all of the simulations. The rationales behind this approach are as follows. Firstly, although the selected features may be sub-optimum for other methods, but in scenarios where embedding algorithm is not known a-prior feature selection should be independent from embedding algorithm. Secondly, among the methods considered in this paper steghide@1.563 had the highest values of 
                        
                           
                              SNR
                           
                           
                              i
                           
                        
                      (Fig. 2); thus, it was the most challenging method to detect. Therefore, if a subset of features can detect steghide@1.563 accurately, it is more likely that they would do the same for other methods as well.

Considering search complexity of GA, the feature selection was repeated for 10 times and the numbers of required generations were calculated. The simulations showed that on average after 4.7 generations the algorithm finds the best feature set. If this number is multiplied with the number of individuals in each generation (200), average search complexity of 940 is calculated. Considering the fact that the GA was performed only once (just for steghide), this complexity is acceptable.

To measure efficacy of the proposed method, different tests were conducted. In each test, database was randomly divided into the training (70%) and the testing (30%) sets. Then, SVM was trained using the features extracted from train set. Finally, trained model was evaluated using test set. This procedure was repeated for 20 times and, the performance criteria were eventually calculated by averaging over all the iterations. Criteria used in this paper are sensitivity (SE), specificity (SP), and accuracy (ACC). These criteria are described as follows:
                        
                           –
                           True negative (TN): the number of cover samples that are classified as cover samples.

True positive (TP): the number of stego samples that are classified as stego samples.

False negative (FN): the number of stego samples that are classified as cover samples.

False positive (FP): the number of cover samples that are classified as stego samples.


                     Targeted steganalysis scenario:
                  

In this section, we assume that 
                        
                           
                              A
                           
                           
                              em
                           
                        
                      is known a priori. Table 2
                      compares performance of the proposed features with some of previous works based on HAS. Best results are presented in the bold face letters.

Results of Table 2 shows that the proposed method outperforms previous methods. Comparing accuracy of the proposed method with D2-MFCC method shows that an improvement of 20.4% has been achieved. Another important fact becomes apparent when the rate of change in the accuracy for different capacities are studied. In this fashion, for the proposed method as the capacity reduces from 25%BPB to 1.563%BPB, accuracy of the system only drops by 2.3%. On the other hand this number rises to 20% for D2-MFCC method.

To compare performance of the proposed method and previous works, average value of performance criteria over different embedding algorithms are calculated. These results with other important factors such as number of features (
                        
                           
                              N
                           
                           
                              F
                           
                        
                     ) and number of cover files in the database (
                        
                           
                              N
                           
                           
                              C
                           
                        
                     ) are presented in the Table 3
                     .

Comparing results of Table 3 shows that using R-Mel instead of Mel scale improves performance of steganalysis considerably. Other points become apparent when results of D2-R-MFCC are compared with those of R-MFCC + GA and D2-R-MFCC + GA. Specifically taking second order derivative of audio signals improves sensitivity and specificity of the proposed method by 3.8% and 5.1%, respectively. Also, gains of 1.8% and 4.3% in the average values of sensitivity and specificity are achieved when higher order statistics and GA are incorporated into the proposed method.


                     Universal steganalysis scenario:
                  

In this section, we assumed that 
                        
                           
                              A
                           
                           
                              em
                           
                        
                      was not known. To simulate this scenario, all stego files were placed in a folder and then 4169 of them were selected randomly. In this fashion, stego files were uniformly selected across all data hiding algorithms. To the best of our knowledge, only in [29] result of universal scenario was reported. Therefore, we have also investigated efficacy of universal steganalysis on some of previous works. Table 4
                      compares results of the proposed universal system with some of previous ones.

Comparing results of D2-MFCC and D2-R-MFCC+GA shows that, the proposed method improves sensitivity and specificity of the universal scenario by 20.8% and 9.3%, respectively. Comparing sensitivity and specificity of the AQM method in the universal and targeted scenarios shows that they drop moderately and considerably in the universal case, respectively. On the other hand for the proposed method another trend is observed. That is, sensitivity and specificity of the proposed method in the universal scenario decrease and remain unchanged, respectively. These different behaviors stem directly from differences in the statistical characteristics of AQM and D2-R-MFCC features which in turn would be reflected in the support vectors of each case. That is, support vectors selected for AQM in the universal case are such that they favor more toward designating a signal as stego (therefore, higher value of sensitivity). On the other hand, support vectors selected for D2-R-MFCC are such that they favor more toward designating a signal as cover (therefore, higher value of specificity).


                     Receiver Operating Characteristic (ROC):
                  

ROC is a graphical plot that illustrates performance of the classifier, as the decision boundary is varied. An ROC plot depicts relative tradeoffs between the benefits (true positives) and the costs (false positives) [10]. So, ROC can provide a good tool for assessing classification task and selecting between different classifiers. Fig. 5
                      presents ROC plots of both targeted (for steghide@1.563 BPB) and universal scenarios. According to ROC of different feature sets we can infer that the proposed method is far better than its competitors. This is evident from larger value of area under the curve (AUC) for D2-R-MFCC feature set.

@&#DISCUSSION@&#

Audio media due to its remarkable redundancy and popularity can provide a suitable means to hide data. Therefore, a vast variety of schemes have been proposed to embed secret data in audio files. These methods have mainly attempted to suggest algorithms which benefits from the areas of audio file in time or frequency domain where the resulted changes from embedding were not detectable by HAS. Therefore, in order to detect the effect of steganography, it is better to employ a model that has maximum deviation from HAS. Furthermore, examining the power spectrum of steganography noise 
                        N
                        (
                        
                           
                              e
                           
                           
                              j
                              w
                           
                        
                        )
                      and power spectrum of cover signal 
                        C
                        (
                        
                           
                              e
                           
                           
                              j
                              w
                           
                        
                        )
                      revealed interesting facts. Steganography noise constitutes a broad-band signal with powerful high frequency components. On the other hand, cover signal is a band limited signal. That is, its power spectrum decreases with increasing of the frequency. Therefore, it is expected that the high frequency region of signals leads to more discriminating features. Result of Fig. 2 justifies this notion. On the other hand, frequency response of human ear (Mel filter bank of Fig. 1) shows that HAS has low frequency resolution at high frequencies; consequently some information will be lost. In contrast, frequency response of our proposed model matches with our goals (high resolution at high frequencies). According to Fig. 4, it is obvious that this matching has resulted in very good discriminating features. According to this figure, distributions of the proposed features are more separated than those based on Mel scale.

Comparing results of Steghide@3.125 and Hide4pgp@6.25 in the Table 2 leads to an interesting conclusion. While their accuracy of detection is the same, Steghide provide half capacity of Hide4pgp.

According to Tables 3 and 4, the proposed system has good performance in both targeted and universal scenarios. Also, results of universal systems are lower than targeted paradigm.

@&#CONCLUSION@&#

This paper proposed the idea of maximum deviation from human auditory system for steganalysis. Based on this idea, frequency characteristic of our proposed artificial auditory system was explained. Specifically, this artificial ear had high resolution and sensitivity in high frequencies and lower resolution and sensitivity in low frequencies. Simulation results showed that such artificial ear has potency of distinguishing between stego and cover signals effectively. Proposed method in the targeted scenario achieved accuracy of 97.6% (StegHide@1.563% BPB) and 98.8% (Hide4Pgp@6.25% BPB) which were 20.4% and 14.1% higher than previous MFCC based methods. In the universal test, proposed method achieved sensitivity and specificity of 94.4% and 99.1% which were 20.8% and 9.3% higher than previously reported results.

Supplementary material related to this article can be found online at http://dx.doi.org/10.1016/j.dsp.2015.12.015.

The following is the Supplementary material related to this article.
                        
                           MMC 1
                           
                              Most of the previous audio steganalysis methods have extracted their features based on models of human auditory system. This work shows that such approaches are counter intuitive. Then, this issue is solved by proposing a new method based on a model that has the maximum deviation from human auditory system. Simulation results and provided figures justify efficacy of the proposed method.
                           
                           
                        
                     
                  

@&#REFERENCES@&#


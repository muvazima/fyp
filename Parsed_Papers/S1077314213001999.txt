@&#MAIN-TITLE@&#ChESS – Quick and robust detection of chess-board features

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An efficient and reliable method for detecting chess-board vertices is proposed.


                        
                        
                           
                           The detector is robust to rotation, blur, and poor scene lighting and contrast.


                        
                        
                           
                           The method provides a strength and orientation measure for each detected feature.


                        
                        
                           
                           The algorithm outperforms processes often used in calibration and structured light.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Chess-board corner detection

Feature extraction

Pattern recognition

Camera calibration

Structured light surface measurement

Photogrammetric marker detection

@&#ABSTRACT@&#


               
               
                  Localization of chess-board vertices is a common task in computer vision, underpinning many applications, but relatively little work focusses on designing a specific feature detector that is fast, accurate and robust. In this paper the ‘Chess-board Extraction by Subtraction and Summation’ (ChESS) feature detector, designed to exclusively respond to chess-board vertices, is presented. The method proposed is robust against noise, poor lighting and poor contrast, requires no prior knowledge of the extent of the chess-board pattern, is computationally very efficient, and provides a strength measure of detected features. Such a detector has significant application both in the key field of camera calibration, as well as in structured light 3D reconstruction. Evidence is presented showing its superior robustness, accuracy, and efficiency in comparison to other commonly used detectors, including Harris & Stephens and SUSAN, both under simulation and in experimental 3D reconstruction of flat plate and cylindrical objects.
               
            

@&#INTRODUCTION@&#

Many applications in machine vision depend on having accurately localized the vertices of a chess-board pattern, since such patterns are commonly used in camera calibration. The available methods for this process tend to suffer in the face of severe optical distortion and perspective effects, and often require hand-tuning of parameters, depending on lighting and pattern scale. Manual intervention is time consuming, requiring operator skill and prohibiting automated use.

Another application needing precise vertex detection is 3D surface reconstruction, where a chess-board pattern is employed as part of a simple yet accurate structured light projector-camera system. For such use feature extraction must be highly automated and fast.

We will present a robust process specifically targeting the detection of chess-board pattern vertices, which rather than requiring a binary vertex/not-vertex threshold, provides a measure of strength similar in output to the much-used Harris and Stephens [1] corner detector in the same problem-space. This permits deferral of inclusion decisions to a later stage where one is better able to exploit spatial and geometric considerations. The process is also computationally efficient and well disposed to a variety of parallel processing techniques, with a reference implementation capable of throughput of over 700 VGA-resolution frames per second on commodity PC hardware.

Following a review in Section 2 of known alternative methods applicable to the problem, in Section 3 we advance a principled argument on what information needs to be sampled from an input frame in order to reliably and efficiently detect chess-board vertices. We describe the ChESS algorithm, wherein a per-pixel strength measure is calculated from the sampled pixels, in Section 4, while Section 5 contains suggestions on how best to confidently localize features from the ChESS response image. A further use of the ChESS technique, to describe a chess-board feature’s rotation, is given in Section 6. In Section 7 we present both simulated and real-world verification of the ChESS algorithm’s accuracy, computational efficiency, and resilience to noise. The paper ends with some discussion of applications and extensions, and conclusions.

@&#RELATED WORK@&#

There are various published techniques used for finding the intersections in chess-board patterns, typically employed during a camera calibration routine, though relatively little work focusses on an optimal detector for such commonly used features. As Soh et al. observed in 1997 [2], regarding camera calibration: ‘it is often assumed that the detection of such charts or markers which are designed to enhance their detectability is trivial’. They continue that this assumption is ill-advised, as generic approaches, such as that of Canny [3], do not make use of the specific properties of the features and are likely to suffer under sub-optimal conditions of lighting and object pose. They furthermore highlight the risks of employing lossy ‘remedies, such as wide kernel filtering, which are notorious for degrading the positional information and shape of critical features’.

Soh et al. go onto describe a grid processing scheme using a chain of Sobel operators, local thresholding, non-maximal suppression, edge joining, geometric constraints and finally taking the centres of gravity of the found squares. As de la Escalera and Armingol noted in 2010 [4], such localization methods were abandoned since the centres of gravity do not coincide with the centres of the squares due to perspective effects. De la Escalera and Armingol also make a similar point to Soh et al., that less attention has been paid to locating the points used in calibration algorithms than to the calibration algorithms themselves – a deficit this work aims to redress.

De la Escalera and Armingol’s detection scheme uses the Harris and Stephens corner detector to locate a set of candidate vertices, before employing the Hough transform on the response image to enforce linearity constraints and discard responses from the corner detector which do not lie along strong linear features. This then restricts the method’s use in applications where the grid is potentially distorted, be it due to optical distortion or a non-planar surface. They discount the use of corner positions alone (in a situation where the grid boundary is unknown) due to the excessive number of non-grid corners likely to be found by Harris and Stephens’ general-purpose algorithm elsewhere in a scene.

Yu and Peng describe in [5] an alternative method of finding features, which attempts to pattern-match a small image of an intersection by measuring the correlation of this pattern over all the captured image. Unless a number of such small images are tested however, this method is clearly at a disadvantage when the grid is rotated relative to the intersection view stored in the pattern. A correlation measure is also used in the calibration system presented by (Krüger et al. in [6]), but only a single template is used, portending rotational difficulties.

Chen and Zhang’s paper [7] rediscovers the determinant of the Hessian as being an effective saddle-point detector. The determinant of the Hessian is known to have other image processing uses however, such as being a blob detector (Lindeberg [8]), so will generate responses to features other than chess-board intersections. The Hessian-based method is also likely to suffer in high noise conditions, and, as noted by Krüger and Wöhler in [9], is restricted to orthogonal corners and will fare poorly with projectively transformed features. Xia et al.’s paper [10] is a wavelet-based adaptation of Chen and Zhang’s detector.

Another method is detailed in Sun et al. [11], where they pass a rectangular or circular window over the captured image and for each position transform the 2D points distribution along the perimeter of this window into a 1D vector. For each ring concentric with the perimeter another vector is formed similarly, each vector being termed a ‘layer’, as numbered in Fig. 1
                     a and linearized in Fig. 1b. The layers are binarized using a locally adaptive threshold, open and close morphological operations applied (Haralick et al. [12]), and the positions where some proportion of the layers have four regions (when each layer is viewed as a ring) are determined to be chess-board vertices. Sun et al. claim the technique works well, but note that it produces false corners from noise and is rather slow. The scheme also relies on the thresholding producing an acceptable binary result.

There is a similar method, whose details are unpublished, included in the Parallel Tracking and Mapping (PTAM) [13] reference implementation
                        1
                        see CalibImage.cc, available via http://www.robots.ox.ac.uk/gk/PTAM/.
                     
                     
                        1
                      by Klein and Murray. In this the circular sampling ring from Rosten and Drummond’s FAST detector [14,15] is used, and upper and lower thresholds are formed which are a fixed intensity distance from the mean of the sixteen sampled points. Proceeding around the ring the number of transitions past these thresholds are counted, and, if four such transitions are found, the centre point is flagged as a possible grid corner.

A number of general-purpose detectors are worth consideration, either due to their established use, their speed, or their similarity in basic approach to that described in the following sections, although being general-purpose all are subject to the same criticism as Canny’s above.

FAST is fast, potentially permitting an approach of following initial detection with post-process pruning of non-chess-board features. Corners are flagged when sufficient pixels, contiguous around the sampling ring, are different from the candidate pixel by a threshold value. Its computational efficiency is greatest when a high discriminatory threshold value is used, but since this value is applied globally to the image, features in areas of poor contrast will not be found. An additional stage of processing is also required to gain a strength measure.

Smith’s SUSAN (Smallest Univalue Segment Assimilating Nucleus) detector [16], returns corner strength measures automatically, and, like FAST, samples pixels around a central nucleus, but in this case using a solid mask. To find corners the centroid of the pixels under the mask with similar intensity to the nucleus (the USAN) is located, and it is required that the centroid is both distant from the nucleus, and pixels lying between the nucleus and the centroid are part of the USAN. As observed in Trajković and Hedley [17] SUSAN can exhibit poor stability (inconsistent feature selection) and suffers with poor-quality images.

Trajković and Hedley’s detector develops from SUSAN, considering only pixels around the edge of the circular mask (much like FAST). A strong response is generated when no diametrically opposite samples are similar to the centre pixel sample – such a behaviour will not generally work well on a chess-board vertex.

Harris and Stephens’ corner detector [1] looks for intensity variations in different directions, attempting to find areas with high local pixel intensity autocorrelation via first order derivatives. An approximation is employed to avoid a full per-pixel eigenvalue decomposition, thus retaining reasonable performance. In this approach it has less of a predetermined idea of what a ‘corner’ is, unlike some of the above corner detectors which might struggle with chess-board vertices not meeting their criteria for a corner.

The results of a variety of basic detection and refinement schemes are employed in many camera calibration papers, a well known example being that of Zhang [18], but a review of such publications is beyond the scope of this work.

In general terms the Harris and Stephens detector is the one encountered most frequently in the literature, other notable papers employing it including Shu et al. [19] and Douskos et al. [20]. Several papers such as that of Lucchese and Mitra [21] exist, but these detail refinement strategies to the features given by a Harris and Stephens detector. This paper aims to offer a competing solution to the use of the Harris and Stephens detector in chess-board applications which is intrinsically more accurate (yet also amenable to the use of similar subsequent refinement strategies if the application demands it).

When we consider an outline for an efficient chess-board corner detector, an assumption of the squares of the grid pattern being approximately axis-aligned with the camera’s sensor would lead to a design of very low complexity, but this is obviously an excessive restriction. A further step up the complexity scale would suggest analysing the image for perpendicular linear features and then proceeding with a detector whose axes are aligned to the detected global orientation: in some respects similar to de la Escalera and Armingol’s scheme, but as noted earlier, optical distortion, or use of a non-planar surface for the pattern, will lead to the grid bending significantly. Apart from the consequence that there may then be no strong global orientation found, the wider implication is that a general-purpose detector must cope with vertex features at all orientations. In the interest of consistency, it is obvious that such a detector must strive to award the same strength (in some sense) to features which are identical in all respects apart from image-plane orientation.

For a rotationally invariant detector, we must sample enough directions away from the centre of the feature to produce a result reliable at any angle. In the instance of a chess-board vertex, the feature may minimally be described by finding a point where two samples taken in opposing directions from the feature centre are of one sense (say, black) and another two samples taken at a ninety degree rotation to the first pair have the opposite sense (say, white). This gives a four point sampling pattern, as in Fig. 2
                     a, which may be viewed as a cross with its intersection on the feature centre (the hatched/highlighted squares denoting sampled pixels).

At this point we also consider the nature of the data commonly expected from a typical camera. The sampled pixels around the edges of grid squares often take mid-range intensity values relative to the extremal intensities of pixels sampling the interiors of squares. A couple of reasons for this phenomenon are given below.
                        
                           •
                           
                              Optical blur – due to both imperfect focus and imperfect optics.


                              Pixel quantization – a single intensity value is assigned to an area of 2D optical signal, and the edges of pixels on the sensor are seldom perfectly aligned with the edges of the incoming grid image.

It is clear therefore that should the sampling cross coincide with the edges of the grid squares the result will not be reliable (Fig. 2b). In such a case more pixels must be sampled to get a result, at which point the issue of sample positioning becomes relevant. In order for a computationally efficient feature response (however it may be calculated) at any rotation to be approximately constant, it is vital for the sampling points to be spaced at equal angles incrementally about the feature centre. Then, considering distance away from the feature centre, two things are apparent:
                        
                           1.
                           Pixels close to the vertex are more likely to contain an edge of a square than those further out, as the central angle subtended by the quasi-segment (of a pixel-circle centred on the vertex) enclosing the pixel is much greater. Further away from the vertex, pixels are more likely to be in areas of even intensity, in the interiors of the grid squares. Noting the previous observations on pixels near grid-square edges, sampling pixels close to the centre will lead to a weaker response.

Going too far away from centre risks sampling pixels from squares not forming the current feature, leading to a confused response.

Item 1 above informs our decision to ensure distances from the centre are approximately equal – if blur and quantization issues attenuate with distance from the feature centre it would be unfair to have certain directions sampled further out than others, violating the condition that a feature’s response ought not to vary with rotation. Approximately equal distances and equal angular spacing constrain the sampling points to be arranged in a circle, centred on the feature centre. Furthermore, taking the two items above together, it is apparent that the radius of this circle ought to be minimized (to avoid aliasing onto other grid squares, and allow the use of more dense patterns if desired), but big enough to escape the central region of blurriness. In some respects this circle resembles Sun et al.’s circular-window outer layer, and indeed is quite similar to that used in the PTAM code.

Bearing in mind the samples are to be taken from a discrete pixel grid, and we wish to have equal angular spacing at a small radius, our options are limited. A combined sampling pattern of eight points, as illustrated in Fig. 2c, is a possibility. Clearly in such a case, four of the eight samples have equal intensity and provide no evidence of a chess-board vertex: should a linear metric be employed, the vertex’s response is liable to have half the magnitude of a response from a vertex where the grid edges lie between the arms of the sampling crosses and all eight samples contribute constructively. Sampling more directions ameliorates this unevenness, as more sampling points are liable to be in an area of solid intensity rather than on a grid-square edge, but at increased computational cost of processing the extra samples.

Empirically, for the majority of data considered from VGA-resolution (640×480pixels) cameras, a ring of radius 5pixels (px) with sixteen samples gives a good response without constraining the minimum chess-board square size unduly, and at low computational expense. This circle also has the desirable property that the angular sample spacing closely approximates the 22.5° optimal spacing of a sixteen segment circle, with sampling points spaced by either 21.8° or 23.2° (shown as 
                        
                           α
                        
                      and 
                        
                           β
                        
                      in Fig. 3
                     ).

The same angular spacing may be achieved with a radius 10px circle, and use of such a circle may be appropriate in the case of highly blurred images. The ultimate sizing of the ring is dependent on the application’s optical system. Without loss of generality a radius 5px ring will be considered henceforth, unless stated or illustrated otherwise.

It is worth noting that employing inner rings, as in Fig. 4
                     , combining a concentric radius 3 sampling circle with the radius 5 circle, is not useful, as assuming the outermost ring has been sized appropriately for the expected image blurring, any inner ring will be sampling the blurry area and have little beneficial response. Furthermore, such techniques slow the processing of the image. With this observation our design departs significantly from Sun et al.’s, in that it does not have their multiple layers.

Simply considering the samples taken from a circle leaves a difficulty; how to distinguish the case where the sample circle covers a solid stripe, as in Fig. 5
                     b. Observe that the circle’s samples for the corner feature shown in Fig. 5a will be exactly the same as those for the stripe. The two cases may only be distinguished by taking samples elsewhere – a good location being at the centre of the ring, where due to the aforementioned expectation of a region of intermediate intensity resulting from blur, the centre intensity in the true corner case will take some non-extremal value.

Rather than use the Sun et al./PTAM approach of performing a computationally intensive locally thresholded binarization, and then making a hard decision whether a set of samples appears to be a corner or not, some way of measuring similarity to an exemplar corner is desirable in order to provide more information to later processes using the corner detector’s response. This provides an output more like that of the widely used Harris and Stephens detector than that of detectors giving a Boolean response. The calculation detailed below provides this quantity.

The initial grid vertex response is given by the sum response. When centred on a chess-board vertex, points on opposite sides of the sample circle should be of similar intensities, and the pair of points 90° and 270° out of phase on the circle should be of very different intensity from those at 0° and 180° phase, while being similar to each other, as previously illustrated in Fig. 2a. In the taking of diametrically opposed samples, there is similarity with Trajković and Hedley’s detector, but it is important to note that comparisons are made with the perpendicular diametric samples, and not the centre of the sampling circle. Taking 
                        
                           
                              
                                 I
                              
                              
                                 n
                              
                           
                        
                      as the nth sampling point proceeding around the sampling ring from some arbitrary starting point 
                        
                           
                              
                                 I
                              
                              
                                 0
                              
                           
                        
                     , the magnitude of 
                        
                           (
                           
                              
                                 I
                              
                              
                                 n
                              
                           
                           +
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 8
                              
                           
                           )
                           -
                           (
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 4
                              
                           
                           +
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 12
                              
                           
                           )
                        
                      should be very large when sampling around a vertex. The sum response (SR), so called due to the summation of opposite samples, is then given by
                        
                           (1)
                           
                              SR
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       n
                                       =
                                       0
                                    
                                    
                                       3
                                    
                                 
                              
                              ∣
                              (
                              
                                 
                                    I
                                 
                                 
                                    n
                                 
                              
                              +
                              
                                 
                                    I
                                 
                                 
                                    n
                                    +
                                    8
                                 
                              
                              )
                              -
                              (
                              
                                 
                                    I
                                 
                                 
                                    n
                                    +
                                    4
                                 
                              
                              +
                              
                                 
                                    I
                                 
                                 
                                    n
                                    +
                                    12
                                 
                              
                              )
                              ∣
                              ,
                           
                        
                     and is large at a vertex point. The summation of the sum response enhances the measure’s robustness, as compared to simply taking the maximal component (summand), as the accumulation builds consensus in the detection of a chess-board vertex: a high response in a majority of the summands gives increased confidence against a one-off false-positive detection.

The most common class of false-positives when using a detector simply employing the sum response is that of those occurring along edges, though these are typically much smaller in magnitude than vertex responses. The origin of these may be simply understood by imagining a case where one of the four sampling terms in the sum response, say 
                        
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 8
                              
                           
                        
                     , is one, and the rest zero. These samples are easily seen to be consistent with an edge, and a positive response still results (though half the magnitude that would occur if 
                        
                           
                              
                                 I
                              
                              
                                 n
                              
                           
                        
                      were also one, being the vertex case). Noting that for a simple edge, such as that shown in Fig. 6
                      (where without loss of generality a radius three circle is used for illustrative purposes), points on opposite sides of the sample circle should generally be of differing intensities, the diff response (DR), which may be expressed as
                        
                           (2)
                           
                              DR
                              =
                              
                                 
                                    
                                       ∑
                                    
                                    
                                       n
                                       =
                                       0
                                    
                                    
                                       7
                                    
                                 
                              
                              ∣
                              
                                 
                                    I
                                 
                                 
                                    n
                                 
                              
                              -
                              
                                 
                                    I
                                 
                                 
                                    n
                                    +
                                    8
                                 
                              
                              ∣
                              ,
                           
                        
                     should be large along edges.

Subtracting the diff response from the sum response forms an intermediate response with a much-improved signal-to-noise ratio. Considering the common example described above (one in four samples vastly different from the others) it may be seen that the effect of subtraction is to totally cancel the contribution of the sum response, giving an intuitively correct intermediate response of zero. Later we will consider how the sum and diff responses may be interpreted using an analogy to the Discrete Fourier Transform (DFT).

Finally, we must eliminate the false-positive ‘stripe’ case, previously illustrated in Fig. 5b. By computing a local intensity mean which considers a few (say, for a radius 5px circle, 5) pixels at the centre of the sampling circle (the local mean), and a spatially larger mean of all the circle’s samples (the neighbour mean), an absolute difference of these means, the mean response, can be found:
                        
                           (3)
                           
                              mean
                              
                              response
                              =
                              ∣
                              neighbour
                              
                              mean
                              -
                              local
                              
                              mean
                              ∣
                              .
                           
                        
                     
                  

This will be large in the stripe case: using Fig. 5 as an example, the neighbour mean will be a light grey in both cases, as will the local mean in (a) – leading to a small mean response, whereas for (b) the local mean will be much darker leading to a large absolute difference. Should the image data be nonlinear (for instance, from a camera with a gamma-corrected response), while the sum and diff responses will still work as expected (as the calculations build simply on whether certain pixel intensities are very different, or similar), the mean response will be non-zero in the stripe case, as the gamma-corrected mean of the raw extremal intensities (i.e. the local mean) is not equal to the mean of the gamma-corrected extremal intensities (i.e. the neighbour mean). For an evenly lit scene, with a mildly nonlinear camera, the impairment will be minor.

The mean response, multiplied by the number of sampled pixels (16) in the sum and diff responses, may be subtracted from the existing response, yielding the overall response R:
                        
                           (4)
                           
                              R
                              =
                              sum
                              
                              response
                              -
                              diff
                              
                              response
                              -
                              16
                              ×
                              mean
                              
                              response
                              .
                           
                        
                     
                  

The factor of sixteen ensures a zero overall response in the undesirable case in Fig. 5b, where samples 
                        
                           
                              
                                 I
                              
                              
                                 n
                              
                           
                        
                      and 
                        
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 8
                              
                           
                        
                      have value one and 
                        
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 4
                              
                           
                        
                      and 
                        
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 12
                              
                           
                        
                      have value zero, as does the mean of the pixels centred in the circle.

We call this algorithm, comprising the sampling pattern and the response calculation, the ChESS (Chess-board Extraction by Subtraction and Summation) detector.

The overall response is not claimed to be perspective-invariant – such a claim would make no sense: the detector does not know if the image contains perspectively distorted chess-board intersections or merely features looking like perspectively distorted chess-board intersections. Hence a highly distorted intersection, whether distorted by perspective effects or otherwise, will be assigned a consistent strength; one lower than that if the candidate vertex were viewed ‘face on’.

An additional stage to provide localized contrast/response enhancement in darker areas of the image, such as via per-pixel normalization by the neighbour mean, is not employed in this detector, as the noise amplification in low intensity areas is too great.

If the sixteen samples taken by the sampling circle are linearized into a 1D data vector, it is seen that the Fast Fourier Transform (FFT) of this vector has a high absolute value for the third coefficient when the circle is centred on a grid intersection, with the second coefficient high when centred over an edge (the first coefficient being the DC term).

This makes intuitive sense when considered graphically. In Fig. 7
                        a a corner feature is linearized clockwise from the top-left sample, and the intensity values correlate well with two cycles of a cosine wave of some phase, which is akin to the third DFT component. Likewise in Fig. 7b one cosine cycle is similar to the intensity vector formed from an edge. By inspection it is apparent that any in-plane rotation of the feature described will merely result in a change of phase in the matching cosine.

It may now be seen that the sum response attempts to perform a two-cycle-cosine-like match to find grid intersections, accumulating over four phases. Similarly, the diff response matches edges by a method not dissimilar to one matching a single cycle cosine over eight phases.

As noted in the introduction to this paper, deciding which responses are to be treated as true features is left to be determined by application-specific constraints. However, a few particular steps may be of use in most instances, exploiting larger-scale spatial constraints to eliminate false-positive features, and these are given below.
                        
                           •
                           
                              Positive response threshold – discard response pixels with zero or negative intensity (since the response quantity is designed to ensure only chess-board intersections have positive intensity).


                              Non-maximum suppression – a standard technique to discard non-maximal responses in a small area around each pixel of the response image. This may be used to determine integer pixel co-ordinates for a set of candidate features.


                              Response connectivity – true chess-board vertex responses typically span a number of pixels; any totally isolated positive response pixels may be discarded.


                              Neighbourhood comparison – comparing the magnitudes of maximal responses over a large area, those less than some proportion of the greatest responses (which are those of true chess-board features) are viewed as false features and discarded. In many respects this compensates for the lack of intensity/contrast normalization in the detector.

Typical response patterns are shown for a variety of feature rotations in Fig. 8
                     . We observe that they are symmetrical about the feature centre and it can therefore be seen that for sub-pixel localization a centre of mass technique will give reasonable results, a specific example being a 5×5 patch centred on the maximal pixel. This method is fast and in common use – de la Escalera and Armingol [4] find the centre of mass of each of the points resulting from Harris detection, while Sun et al. [11] also find the centre of mass of their response clusters. More complex refinement techniques such as those typically used to post-process features detected with the Harris and Stephens detector could also be used, but extensive review or comparison is peripheral to this work’s aim of efficient feature detection.

The sum response has a further use: by finding the rotation of the maximal sum response summand, each feature can be assigned one of eight orientations, relative to the pixel axes (returning to the previous DFT analogy, this is determining a quantized value for the two-cycle cosine’s phase). This labelling has many potential uses, but a trivial example is that in finding chess-board vertices the orientation labels of connected vertices ought to be in approximate anti-phase. The details of this labelling are explained below, separately from the main detector, as while the processes could be conducted simultaneously it is often more efficient to only perform the labelling having selected a set of candidate features.

The same measure (M) as used in the detector’s sum response is employed; 
                        
                           
                              
                                 M
                              
                              
                                 n
                              
                           
                           =
                           (
                           
                              
                                 I
                              
                              
                                 n
                              
                           
                           +
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 8
                              
                           
                           )
                           -
                           (
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 4
                              
                           
                           +
                           
                              
                                 I
                              
                              
                                 n
                                 +
                                 12
                              
                           
                           )
                        
                     . 
                        
                           ∣
                           M
                           ∣
                        
                      gives four unique values when rotated around the 16-point sampling circle, there being eight distinct values of M before duplication occurs due to symmetry, and half of those eight simply differing in sign depending on whether a given opposing pair of the four points sampled are in a ‘black’ or ‘white’ grid square.

To achieve the first stage of the orientation binning, for each measure an average (AM) across the adjacent measure-orientations is found. More explicitly, 
                        
                           3
                           
                              
                                 AM
                              
                              
                                 n
                              
                           
                           =
                           
                              
                                 M
                              
                              
                                 n
                                 -
                                 1
                              
                           
                           +
                           
                              
                                 M
                              
                              
                                 n
                              
                           
                           +
                           
                              
                                 M
                              
                              
                                 n
                                 +
                                 1
                              
                           
                           ,
                           
                           n
                           ∈
                           {
                           0
                           ,
                           1
                           ,
                           2
                           ,
                           3
                           }
                        
                      (with care taken when n
                     −1 is −1 or n
                     +1 is 4 to wrap modularly to 3 or 0 respectively and flip the sign of the M in question). The index i of the orientation which has the greatest absolute average measure is taken, i.e. 
                        
                           i
                           =
                           
                              
                                 arg max
                              
                              
                                 n
                              
                           
                           ∣
                           
                              
                                 AM
                              
                              
                                 n
                              
                           
                           ∣
                        
                     . To find the final orientation-bin index, the sign of 
                        
                           
                              
                                 M
                              
                              
                                 i
                              
                           
                        
                      is considered, with features with positive 
                        
                           
                              
                                 M
                              
                              
                                 i
                              
                           
                        
                      being consigned to a different four orientation bins than those with a negative 
                        
                           
                              
                                 M
                              
                              
                                 i
                              
                           
                        
                     .

Because a grid intersection of two black and two white squares has a rotational symmetry of order two, these eight bins correspond to increments of 22.5°. With regard to chess-board decoding, this level of granularity ensures a satisfactory four bin distance between alternate chess-board vertices, which can be viewed as 90° out of phase. With the 22.5° distinction available here, two opposite sense features’ orientations can both have a distance-one (in bins) orientation labelling error while remaining distinct.

@&#EXPERIMENTAL RESULTS@&#

In substantiation of the claims of robustness in detection of chess-board vertices, the ChESS detector must be compared against other detectors in use for the same problem, on the same data. Comparisons with Harris and Stephens’ algorithm [1] and Smith and Brady’s SUSAN method [16] are made below. A separate comparison is made against the PTAM detector due to it only providing a Boolean response.

Each of the detectors under test has a variety of parameters, some of which are promoted as tunable. Table 1
                      summarizes each detector’s parameters, and which portions of the parameter space are explored in the following evaluations. Brief explanations (where required) of the parameter effects are given below.
                        
                           •
                           The Harris and Stephens’ detector’s free parameter k affects the detector’s sensitivity. 0.04 is both the default value for k in the OpenCV implementation,
                                 2
                                 cvCornerHarris, see http://opencv.willowgarage.com.
                              
                              
                                 2
                               and in combination with the other parameter values has been found to work well on chess-board images empirically (good detection to false-positive balance, strong feature responses).

The SUSAN threshold is an intensity range threshold for categorizing pixels as being similar to or different from each other, a value of 20 is the default in Smith’s implementation.
                                 3
                                 Available at http://users.fmrib.ox.ac.uk/steve/susan/susan2l.c.
                              
                              
                                 3
                              
                           

The PTAM gate threshold functions fairly similarly to that of SUSAN; pixel intensities must change by 2 × gate for a white–black or black–white transition to be recorded, 10 being the default value.

Resilience to noise and invariance of response magnitude to rotation can both be quantified by simulating a feature point at varying rotations and noise levels, performing feature detection on the generated image, subsequently localizing the greatest feature response, and measuring the distance of this point from the co-ordinates of the original simulated point.

It is desirable for the simulated images to bear a reasonable resemblance to real data, in order for the results to be meaningful. The simulation images are thus composed of four equal-size rectangles in two colours, arranged to define an intersecting point. Since a common image format of camera output is one channel of eight bits, the two colours are set at 64 and 191, approximately equidistant from saturation and the middle of the intensity range.

The image is then rotated by some angle around the co-ordinates of the intersection, using the ImageMagick library
                              4
                              
                                 http://www.imagemagick.org/index.php.
                           
                           
                              4
                            with a bi-linear interpolation method specified. The image is next cropped to VGA resolution, then a 3×3 Gaussian blur, using two 1D passes of a 
                              
                                 
                                    
                                       1
                                    
                                    
                                       5
                                    
                                 
                                 [
                                 1
                                 
                                 3
                                 
                                 1
                                 ]
                              
                            filter, roughly corresponding to a 0.675 variance, is applied. This produces images similar to those captured by a well focussed VGA-resolution camera.

Finally, noise, generated from randomly sampling a Gaussian distribution with a specified variance is added to each pixel of the image, with saturation occurring at pixel intensities of 0 and 255.

A variant on this approach may also be simulated. The method described above may be thought of as emulating the case where the real-world edge is exactly incident on the edges of the camera’s sensor elements (prior to rotation), but equally probable is the case of the edge coinciding with the middle of the elements. By inserting a transition row and column at mid-magnitude (128) at the rectangle borders and rotating about a point offset from the centre by half a pixel in x and y this case may also be tried. Of course, in reality the incident edge’s centre will fall between these two cases, but together they ought to highlight any undesirable pathological behaviour present in these extreme cases.

In Fig. 9
                           b a portion of an image simulated with a rotation angle of 32.5° and a noise variance of 1 is shown. Fig. 9a shows a similar portion of a black and white intersection captured by a real camera; the two may be seen to be visually similar. Similarly, Fig. 10
                           a, an image captured with a short exposure (leading to higher noise), may be compared with Fig. 10b, a portion of an image simulated with no rotation, half-pixel offsetting, and a noise variance of 5, and found to again be visually similar.

At a coarse level sub-pixel localization is unnecessary – simply taking the integer pixel co-ordinates of the greatest response is sufficient to provide an overall illustration of behaviour. A similar connectivity method to that described in Section 5 is employed to provide a minimal filter, discarding responses which are not connected to any of the eight adjacent pixels (horizontally, vertically and diagonally).


                           Fig. 11
                            displays the performance of the three detectors under test, using what might be considered vanilla, or default, configurations. The ‘ChESS detector’ is that detailed in the preceding sections; the ‘Harris detector’ uses a 5×5 Sobel aperture, a 3×3 block size for the subsequent box filter, and the free parameter k
                           =0.04; and the ‘SUSAN detector’ uses Smith’s implementation of this algorithm, with the brightness threshold value at 20. The colouring of the plots corresponds to the average distance (in pixels, taken over 1000 trials) of the greatest response detected from where the true feature lies, i.e. the measured error increases as the colour changes from blue to red. 
                              5
                              For interpretation of colour in Fig. 11, 12, 15 and 16, the reader is referred to the web version of this article.
                           
                           
                              5
                           
                        

It can immediately be seen that the ChESS detector performs as well or better than the Harris detector at all noise levels and rotations. As expected the new detector’s response displays some periodicity about 22.5°, due to the angular spacing in the sampling ring discussed in Section 3. It can furthermore be seen that the Harris detector’s accuracy varies depending on rotation, performing best when no rotation is applied. The SUSAN detector has not fared nearly as well as the other detectors in this test with increasing noise; the low default brightness threshold leads to noise features dominating at very low noise levels. It may also be observed that the rotational response is uneven.

Considering the detectors in more detail, some variants must be included in the simulations for a more direct comparison. The 5×5 Sobel operation applied in the Harris detector implementation has an effect of smoothing the input image by a 5×5 Gaussian kernel. As the ChESS detector has no such intrinsic smoothing step, it is instructive to simulate two further variants: the ChESS detector processing images smoothed by a 5×5 Gaussian kernel (two 1D 
                              
                                 
                                    
                                       1
                                    
                                    
                                       16
                                    
                                 
                              
                           [14641] (σ
                           2
                           ≈1.04) passes), and a modified Harris detector with no initial smoothing, simply using a [−101] edge-detecting kernel. A further simulation of the SUSAN detector with a higher brightness threshold (40) is also warranted to ascertain its performance when detecting only strong features.

The results of simulating these variants are plotted in Fig. 12
                           , again with the colour showing the error in terms of distance. Note that these are all variations on the basic configurations of Fig. 11, and comparisons are best drawn between the behaviours in both Figures, rather than necessarily within 
                           Fig. 12. Blurring the input data significantly improves the ChESS detector’s resilience to noise, allowing approximately double the noise variance before significant errors occur. Conversely, the Harris detector without the pre-blurring step becomes even more directional, and has very poor noise performance, albeit still superior to the previously simulated SUSAN case. It may therefore be seen that comparing smoothed with smoothed, and unsmoothed with unsmoothed, ChESS has significantly better resilience to noise than the Harris detector.

Setting the brightness threshold of the SUSAN detector to a larger value yields some improvement in noise resilience over the default threshold, but still does not begin to compete with any variant of the other two detectors, and in practical use would lead to weaker features being missed. While the SUSAN principle is intended to not require noise reduction, we note for completeness that, from simulation not presented here, using the same pre-blur as employed with the ChESS detector (and retaining the brightness threshold of 40) merely improves the noise performance to being marginally worse than the smoothed Harris detector; not a dramatic improvement. For these reasons the SUSAN detector is not considered further in this evaluation.

Looking at localization precision at low noise levels, Fig. 13
                           a and b plot the error performance of the remaining four detector schemes, using a 7×7 centre of mass sub-pixel localization method, on the same axes for varying noise (mean of all rotations), and rotation (mean of near-linear noise-error regions) respectively. Use of a 7×7 patch ensures the majority of the Harris response, which may be quite wide, is captured. Other localization schemes could be employed, but it is informative to compare the ability of the raw detection method without additional complex refinement, not least to determine whether more involved post-processing is in fact necessary.

In Fig. 13 the ChESS detector variants perform better than the Harris detectors at all noise levels, have even rotational responses, far more so than the regular Harris detector, and exhibit good performance at all feature rotations. The angular performance of the two ChESS variants is very similar, but the pre-blurred variant is more resilient to image noise. The angular response of the no-smoothing Harris variant is perhaps most even, but the variant’s very poor noise resilience is a major weakness, so the variant plays no further part in this evaluation.

As well as looking at in-plane feature rotation, it is worth considering rotations over other axes, which lead to perspective distortions. Such distortions are naturally very common in real-world use, particularly in standard camera calibration procedures. Rather than attempt to simulate a full perspective model, thereby introducing many more parameters, it may be appreciated that the effects of perspective distortion as applied to a chess-board vertex are to apparently change the angle between the intersecting lines, in addition to some overall in-plane rotation. Considering the rotation case to have been dealt with above, Fig. 14
                            shows the behaviours of the ChESS and Harris detectors as the intersection angle changes. The previously presented cases used an intersection angle of 90°, and it is from this point that the left side of the plot starts. The contours plotted give the mean distance (over two thousand trials, for each noise/angle combination) of the intersection from its true location as noise increases and the intersection angle deviates from 90°. Half-pixel offset and zero offset results have been combined in this figure.

We see that the performance of the unsmoothed ChESS detector and the Harris detector is initially noise-limited, having a roughly constant error distance with reducing intersection angle. Outside of the noise-limited region, it is apparent that the noise tolerance of both ChESS variants degrades smoothly as the minimal angle reduces, with detection universally failing with an angle between 0° and 10°. This is very much in keeping with the design stated towards the end of Section 4, with face-on vertices generating the strongest responses and those distorted generating a consistent lower strength. The Harris detector starts out in a far weaker position with regard to noise, with performance falling sharply beyond the noise-limited region. This behaviour is due to the more acute intersection tending to generate two responses with the Harris detector, which move further apart as the angle moves away from 90°, their separation becoming rapidly greater as the intersection becomes more acute.

Returning to in-plane rotation, we next consider the PTAM detector. To form a comparison when the detector’s output is a per-pixel Boolean response indicating whether a corner feature is present, the output of the ChESS detector is thresholded, with the threshold set at approximately 1.5% of the positive response. Fig. 15
                            presents the distance of the nearest detected corner feature from the true corner location, using a pixel-grid-aligned feature only. The plots’ colours saturate at a distance of five pixels – anything detected at a greater distance from the true feature is unlikely to be due to the true feature. By default the PTAM implementation applies a Gaussian blur with σ
                           =1 before sampling the image, so a Gaussian blur with similar σ is applied prior to processing by either detector in the comparison.

It can immediately be seen that in the simulation results the PTAM detector fares worse than the ChESS detector as the noise increases. A further poor performance region is visible under low noise conditions; this is due to two effects. First, the PTAM detector rejects corners whose central intensity is similar to the detecting region’s mean, an inevitable situation with the simulated optical blur across the initial image’s two intensities (and the inverse of the ChESS detector’s local mean approach). Second, a connectedness filter is still employed in this experiment, which while not ideal, is justified, given the lack of a numeric strength value, and the ease with which single pixel responses are generated to noise; unfortunately many of the responses around the noise level of 10 are also single pixel.

Considering only the comparatively weaker noise performance, like SUSAN the detector offers a parameter to recognize only stronger features, the gate value, the Fig. 15 case using the default value of 10. Plots for gate
                           =20 and gate
                           =30 are shown in Fig. 16
                           .

Pixel intensities around the sampling ring must change by 2
                           
                              
                                 ×
                              
                           
                           
                           gate in order for a white–black or black–white transition to be recorded. Hence while the simulated noise performance of the PTAM detector is seen to improve with a higher gate value, features would have to have black and white regions differing in intensity by more than forty (for gate
                           =20) in order for the feature to be recorded, whereas the ChESS detector will still find a low contrast feature, albeit with a small response. Both due to this, and plotted performance, we conclude that the variant PTAM responses do not compete with that of ChESS.

While in the previous subsection attention was paid to the accuracy of the simulation, it is nevertheless true that results obtained through simulation do not always hold true in reality. In this subsection the accuracy and robustness of the detector is validated by measuring the error and consistency in 3D reconstruction of surfaces of known shape on which a chess-board pattern is projected and multiple views of the surface recorded (a standard structured light technique). The importance of accurate localization is particularly great as the extrinsic calibration of the cameras is performed on the observed data, so any error in calibration resulting from poor localization will tend to degrade the quality of the reconstruction overall.

For the camera calibration and surface reconstruction stages the combination of methods described in de Boer et al.’s paper [22] (and in more detail in de Boer’s M.Phil. thesis [23]) are used, drawing heavily on the Lasenby and Stevenson calibration algorithm [24]. These have been found to be reliable and accurate on a variety of data in previous studies.

A reconstruction test permits both comparison of the ChESS feature detector against other detection schemes, and testing of the ChESS variants against each other. It also constructs the real-world verification experiment in such a way as to test the two most likely applications for this work, namely camera calibration and 3D reconstruction. Using a 7×7 centre of mass sub-pixel interpolation method in each case, the variants under test are:
                           
                              •
                              Inherently smoothed Harris detector (parameters as used in simulation).

ChESS detector without pre-blur.

ChESS detector with pre-blur.

The PTAM detector is not considered here due to its output not being well suited to sub-pixel feature localization.

A flat plate is used to permit easy verification that the reconstructed surface is planar. In the test a moving platform, whose position at any time is precisely known, moved the plate toward and away from the cameras over a travelling distance of approximately 95mm, while the distance of the plate from the cameras was around 1m. Following the motion period the plate was held at a constant displacement; the ‘rest’ period. During the whole recorded period over 500 projected grid points were in view and these were subsequently used for calibration. The relatively large motion is intended to result in an improved calibration of the cameras’ extrinsic parameters, while the rest period permits the plate’s reconstructed flatness to be compared over many frames, as no real-world motion is present.

The first dataset contains an optimally lit and focussed scene – what might be considered high quality data. Fig. 17
                            is a plot of the percentages of grid points successfully found by each tested detection method (irrespective of their precise localization), with the results from this well-lit dataset given by the blue cross (
                              
                           ) markers. It may immediately be seen that for these ‘clean’ data all the detectors are successful.

Using the rest period data a plane was fitted to the reconstructed surface of each frame. The method employed was that described in Matlab’s documentation [25], where a linear regression that minimizes the perpendicular distances from the data to the fitted model is found using Principal Component Analysis (PCA), forming a linear case of total least squares. This produces a unit-vector normal to the plane, and we may find the mean of the distances, normal to the fitted plane, between the plane and the data (an RMSE), 
                              
                                 
                                    
                                       d
                                    
                                    
                                       p
                                    
                                 
                              
                           , indicating the quality of the fit. Any outliers will deteriorate the quality of the fit, but since we aim for a detector that has few or no outliers it is fair to not make any special effort to exclude them separately.

The situation is illustrated in Fig. 18
                            where a number of planes fitted to different frames captured during the rest period are depicted, along with their normal unit vectors. The dotted arrow shows the mean normal unit vector.

For a good stable fit, the distance of each frame’s vector from this mean vector, 
                              
                                 
                                    
                                       d
                                    
                                    
                                       v
                                    
                                 
                              
                           , should be very small, and in Fig. 19
                            the mean and standard deviation of 
                              
                                 
                                    
                                       d
                                    
                                    
                                       p
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       d
                                    
                                    
                                       v
                                    
                                 
                              
                            over all fitted frames are plotted for all methods under test, 
                              
                                 
                                    
                                       d
                                    
                                    
                                       p
                                    
                                 
                              
                            giving a measure of per-frame fit quality, while 
                              
                                 
                                    
                                       d
                                    
                                    
                                       v
                                    
                                 
                              
                            measures consistency of the fits over time. The values are plotted relative to those of the ChESS detector without pre-blurring, which has its values normalized to one. To provide a sense of scale, the calculated values for this normalized case are given in the top row of Table 2
                           ; the unit-vector deviations are expressed as angles due to the minute distances involved. From this it can be seen that in absolute terms the error is very low – sub-millimetre.

Compared to the detection success-rates, the fitting results show greater variety in performance between the detectors, emphasize the poorer localization resulting from the Harris detector, and reinforce the conclusion found in simulation that use of pre-blur can be beneficial when using the ChESS detector.


                           Fig. 17 (
                              
                            markers) and Fig. 20
                            display the same information for a harder dataset, where the light levels are very low and hence the image noise level is much higher. The failure to detect more than 40% of the points by the Harris detector is striking. The lighting difference between the datasets may be appreciated by comparing the left and right halves of Fig. 21
                           a. In Fig. 21b a portion of the dark capture has been contrast-stretched to reveal the more significant noise.

The pattern of performance behaviour for the ChESS variants is similar to that seen for clean data, though the improvement due to using blur is more pronounced. Reference values are again provided in Table 2. While these figures are greater than in the clean data case, the data captured were of exceptionally poor quality.

A cylinder is a more complex surface (yet reasonably easily parameterized for validation) than a flat plate, tending to distort the projected chess-board significantly due to perspective effects, and so a logical choice for a more challenging reconstruction. For the cylinder test the same experimental procedure as for the flat plate was used, with the one change of a cylinder being the projection surface.


                           Fig. 22
                            shows that for low-noise data (again given by 
                              
                            markers) the detection is successful for all methods under test, with only the Harris detector having a noticeably less than perfect performance.

Fitting to a cylinder with arbitrary position, rotation and radius is rather harder than fitting a flat plate. Taking the approach described in Eberly’s document [26], one choice of cost function for the fit to a cylinder may be expressed as
                              
                                 (5)
                                 
                                    E
                                    (
                                    C
                                    ,
                                    V
                                    ,
                                    s
                                    )
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                s
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            X
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      -
                                                      C
                                                      )
                                                   
                                                   
                                                      T
                                                   
                                                
                                                (
                                                ∣
                                                V
                                                
                                                   
                                                      ∣
                                                   
                                                   
                                                      2
                                                   
                                                
                                                I
                                                -
                                                
                                                   
                                                      VV
                                                   
                                                   
                                                      T
                                                   
                                                
                                                )
                                                (
                                                
                                                   
                                                      X
                                                   
                                                   
                                                      i
                                                   
                                                
                                                -
                                                C
                                                )
                                                -
                                                1
                                             
                                          
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                           where 
                              
                                 C
                              
                            is a point on the cylinder’s axis, which in turn is described by 
                              
                                 V
                              
                            (a non-unit-vector, thereby allowing independent variation of its components), s is related to the cylinder radius r by 
                              
                                 s
                                 =
                                 1
                                 /
                                 
                                    
                                       (
                                       r
                                       ∣
                                       V
                                       ∣
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           , and 
                              
                                 
                                    
                                       {
                                       
                                          
                                             X
                                          
                                          
                                             i
                                          
                                       
                                       }
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                    
                                 
                              
                            is the observed surface point set. This permits minimization of the problem over seven parameters, and when supplied with a reasonable initial parameter set does not take many iterations to converge.

Again, the mean and standard deviation of the perpendicular fit error across the rest period frames can be calculated, as can the mean distance from the mean axis unit vector and its standard deviation (similarly to the method used for the flat plate’s fitted normal vector). These are plotted relative to the results of the ChESS detector without pre-blur in Fig. 23
                           , with reference values given in Table 3
                           . The pattern of plots is much the same as for the clean flat plate data, though with the well-lit subject the Harris detector is more competitive.


                           Fig. 22 (
                              
                            markers), Fig. 24
                           , and the lower row of Table 3 contain plots/reference values of the same measures, as calculated from a noisy dataset. It may be observed that the impact of the blurred variant is greater on noisy data. This is in line with expectations: blur will reduce the detrimental effect of noise on the poorly lit captures.

Overall it may be seen that use of the ChESS detector allows superior reconstructions to those generated from the tested Harris detector, and use of pre-blurring can be of significant benefit on real data.

While accuracy and robustness are key requirements of the system, if it is to be capable of processing video in real-time it is imperative that the methods used are fast.

The image processing stage of corner detection, sampling the camera image and calculating the response image, is very computationally intensive and can easily dominate the run-time of an application using its output. A comparison of wall-clock execution time to process a certain frame of VGA-resolution data 5000 times on an Intel Core i5-750 processor (unless noted otherwise) is presented in this subsection, using three of the algorithms previously considered: the ChESS detector, Harris and Stephens’ detector, and the PTAM detector.

The detectors are all carefully implemented in the C language. The Harris algorithm parameters are again a 5×5 Sobel aperture, a 3×3 block size for the box filter, and the free parameter k
                        =0.04; for PTAM, gate
                        =10 – both as used initially in the simulation experiments. Although the algorithms do not give directly comparable output (in particular the PTAM results would require a later stage of processing to refine feature positions to sub-pixel accuracy), one could be relatively easily substituted for another in a standard calibration or tracking application.

The timing results are presented in Table 4
                        . Even though any such results will be influenced by the effort expended on code optimization, it is apparent that the ChESS algorithm is highly competitive with existing approaches, here taking approximately 40% less time than Harris and Stephens’ algorithm, and around 25% less than the PTAM code.

It is important to note that the ChESS detector algorithm is well suited to further optimization using the Single Instruction, Multiple Data (SIMD) vector instructions present on modern CPUs. This allows the responses for multiple pixels to be processed in parallel, and the table also gives execution times for an implementation using these instructions. The detector is therefore capable of processing over 700 VGA-resolution frames per second (fps), more than enough for real-time use in many applications.

Considering the results presented earlier in this section, where the benefits of pre-processing noisy data were noted, examination of the overhead of performing a 5×5 Gaussian blur is necessary. Provided that a similar level of effort is expended in the implementation of the blur as in that of the detector, the run-time addition is not onerous: a basic C language implementation adds around 15% to the ChESS detector written in pure C, while a vectorized convolution is much more efficient and the penalty is an addition of 10% to the SIMD detector’s run-time. In either case the burden is a relatively small hit which in situations with noisy data is clearly worthwhile.

@&#DISCUSSION@&#

As demonstrated in the results section above, the fast, accurate and robust nature of the ChESS detector allows it to be employed with confidence in applications more varied than simply locating a planar or smooth chess-board patterned surface. More varied use of chess-board patterns is common – for example Sun et al. demonstrate pattern finding on printed non-planar sheets and patterns projected onto room corners in [11].

The original motivation behind the detector’s development lies in a structured light setting, where a chess-board pattern is projected onto a 3D object and the surface of the object reconstructed following localization of the projected grid’s vertices in multiple views. Again, chess-board patterns have been employed by others to this end, an example being in Dao and Sugimoto’s paper [27], where Sun et al.’s method is used in the reconstruction of facial geometry.

Our particular use of the detector is in real-time measurement of lung function in humans, observing the change in the surface of the chest of an otherwise static subject over time, as described by de Boer et al. in [22]. As the video frame in Fig. 25
                      illustrates, detection must withstand variable lighting, poor contrast surfaces, significant perspective distortion, and (potentially) surface discontinuities coincident with vertices of the chess-board. The detector presented meets these challenges routinely.

Another avenue of work has noted that since a strong response results from any chess-board-vertex-like feature, rather than necessarily requiring a chess-board pattern, a pattern of chess-board vertices will be equally detected. This permits tiling the symbol shown in Fig. 26
                      at various rotations to form a coded grid of vertices, allowing trivial automatic correspondence determination between multiple views of the same grid. Results using this technique are given in Maldonado and Lasenby’s poster [28].

The matching of linearized feature neighbourhoods against arbitrary phase periodic functions, presented here in the context of chess-board pattern vertices, is applicable to higher-order intersection features, though clearly at a cost of requiring higher resolution images and more sampling to maintain the level of isotropy seen in the chess-board feature detector. Minimal sampling schemes for three and four line intersection features are illustrated in Fig. 27.

The patterns in the two examples may be trivially tessellated, with the pattern in Fig. 27
                        a giving a grid of identical intersections which permit unambiguous triangulation, and that in Fig. 27b giving an interleaved grid of intersections in both the Fig. 27b and chess-board styles. Analysis of the use of such patterns remains a future avenue of work.

@&#CONCLUSION@&#

In this paper we proposed and justified the properties necessary to exclusively and uniformly detect a chess-board pattern vertex at any orientation, given common optical and sensing constraints. From these properties we presented a simple design for a detector, which both provides a strength measure for detected features and penalizes otherwise common false-positives, making its response to diverse scenes robust, all the while using relatively lightweight sampling.

Evaluation of the detector on simulated and real data has borne out its effectiveness in comparison to other freely available detectors commonly used for detection of chess-board vertices. Particular superior function was observed in the isotropy of the response, the resilience against image noise, and in the accuracy of feature localization.

Due both to the economical sampling, and the simplicity of the operations conducted on the sampled data, the detection algorithm is very efficient and was found to be capable of a processing rate greater than other less robust and less accurate schemes considered.

The measurement of performance on real data demonstrated that while extremely well-suited to camera calibration problems, the benefits of this detector combine to permit its use in applications more varied than the detection of a planar chess-board pattern, in particular it has use in structured light 3D reconstruction, potentially permitting real-time processing and in detecting highly distorted chess-board patterns in general.

In the interests of others evaluating and using the ChESS detector, implementations of the algorithm are available for research purposes at http://www-sigproc.eng.cam.ac.uk/∼sb476/ChESS/.

@&#ACKNOWLEDGEMENT@&#

The authors would like to thank Richard J. Wareham for the DFT analogy.

@&#REFERENCES@&#


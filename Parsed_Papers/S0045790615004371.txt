@&#MAIN-TITLE@&#Echocardiography noise reduction using sparse representation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Noise reduction in echocardiography images is proposed.


                        
                        
                           
                           Filtering framework is based on temporal information and sparse representation.


                        
                        
                           
                           Proposed method consists of smoothing intensity variation time curves assessed in each pixel.


                        
                        
                           
                           A smooth version of signal can be reconstructed by using a proper sparse recovery which is followed by an adaptive thresholding method to locate the most important atoms.


                        
                        
                           
                           After a comprehensive comparison of sparse recovery algorithms, three were selected for our method: Bayesian Compressive Sensing (BCS), Bregman Iterative algorithm, and Orthogonal Matching Pursuit (OMP).


                        
                        
                           
                           The proposed method preserves the edges and rapidly moving structures.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Echocardiographic images

Noise reduction

Temporal information

Sparse representation

Adaptive thresholding

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

The presence of speckle noise in ultrasound images frequently limits their contrast, adversely affecting both human interpretation and computer-assisted analysis, including edge detection, segmentation, tracking and registration [1]. Researchers have developed various methods to filter out speckle noise. However, these methods have several crucial limitations. The primary limitations of all existing filters are that they do not use the temporal information in echocardiography sequences and use only single images or sets of a few images. These limitations both decrease the efficiency of the filter and negatively impact on image results, causing the blurring of rapidly moving structures and object edges.

In a previous publication [2], we demonstrated how the temporal information in echocardiographs can be analysed as intensity variation time curves (IVTCs) and the speckle can be interpreted as high-frequency variations added to the IVTCs. In this paper, we introduce a new method that utilizes sparse representation of IVTCs to filter speckle noise adaptively.

In recent years, sparse representation has attracted growing interest in the field of signal and image processing [3]. Many signals, including IVTCs, are sparse—that is, they contain many coefficients close to or equal to zero in a specific domain. The goal of sparse signal representation is to transform the signal into a new domain using a dictionary of functions (called atoms) which efficiently reconstruct the signal with a linear combination of a few of the dictionary atoms. Two methods based on dictionary learning approaches have already been proposed for the de-speckling of ultrasound and SAR images [4,5]. However, these methods do not apply to temporal information.

This paper demonstrates the application of sparse representation to IVTCs. Adding the constraint of sparsity allows IVTC reconstruction by only a small number of non-zero coefficients or a sparse number of atoms in the dictionary. A smooth version of the signal can be reconstructed using a proper sparse recovery method which is followed by adaptive thresholding to locate the most important atoms. After a comprehensive comparison of sparse recovery algorithms, three were selected for our method: Bayesian Compressive Sensing (BCS) [6], the Bregman Iterative algorithm [7], and Orthogonal Matching Pursuit (OMP) [8].

The schematic in Fig. 1
                      is a stepwise portrayal of the method. In the first step, the IVTC signals are extracted by assessing the pixels of sequential echocardiography images. In the second step, prior knowledge of the original IVTC signals is used to select appropriate functions to build an over-complete dictionary. In the third step, a sparse number of atoms from this dictionary are used to represent the signals (i.e. sparse recovery). In the fourth step, an adaptive threshold is set to reconstruct a smooth version of the original signal with reduced speckle noise.

In Section 2, we will review currently available filtering methods and outline their limitations. We will then summarize the use of IVTCs and detail the compilation of an over-complete dictionary of functions via the application of sparse representation. In Section 3, we outline the use of this dictionary to choose an appropriate sparse recovery algorithm via a comprehensive comparison. We will demonstrate how a smooth version of the signal can be reconstructed with an adaptive threshold chosen to filter the results by preserving the most significant coefficients and eliminating the near-zero coefficients. In Section 4, we compare the performance of the proposed filter against that of some currently available filters by applying objective image quality metrics. We present our conclusions in Section 5.

The development of an accurate speckle noise model is an essential step towards achieving an efficient de-speckle filter design. There are two noise models that can be considered, depending on whether the envelope signal is captured before or after logarithmic compression. The multiplicative noise model pertains to signals obtained before logarithmic compression. The additive noise model pertains to signals obtained after logarithmic compression, where the speckle noise becomes very similar to white Gaussian noise [1]. Various speckle reduction methods have been proposed based on these two models. Some well-known filters such as the Lee filter, the Kuan filter, and the Frost filter are prominent examples that presume a multiplicative model. Other filters, such as the median filter, Wiener filters, speckle reducing anisotropic diffusion filter, and wavelet filters are based on the additive noise model.

Although each of these methods provides certain benefits, crucial limitations persist [1]. In some filters, window size affects the quality of the processed image. Both ends of the spectrum are affected, as filtering capacity is reduced for larger and smaller windows: on one hand, blurring increases with large window size, resulting in loss of fine detail in the image; on the other hand, a small window will result in an ineffective filter which does not suppress the noise sufficiently.

Dependency of some filters on thresholds which have to be estimated by trial and error is another limitation. In other de-speckle filters, smoothing of the image near the edges is inhibited in order to preserve edge details, leading to speckles remaining in this vicinity [2]. But the primary limitation of existing filters is that they are applied to a single image and do not use the temporal information in echocardiography sequences. De-speckling consecutive images is highly time-consuming, since each echocardiograph frame must be filtered separately. Averaging consecutive frames is a simple method for temporal filtering, but it is inefficient because it both blurs the moving edges and decreases the frame rates. Schistad and Taxt have proposed a method for temporal filtering by increasing the number of dimensions of spatial filters from two to three, and considering only two neighbourhood frames—one before and one after [9]. However, this method is time consuming and causes the blurring of fast-moving edges. A motion-adaptive temporal filtering method for speckle reduction in echocardiography images has been proposed in [10] which uses eight consecutive frames for filtering. Convergence of this algorithm depends on sensitive parameters and, because of the iterative nature of the method, the computational complexity is high.

Olstad has proposed a method for speckle reduction in time-varying images based on 1-D anisotropic diffusion [11]. Since the quality of anisotropic filtering is dependent on a boundary detector, a time-consuming method was proposed to find the boundary locations on 1-D signals.

In our previous research, we have proposed a method for filtering the long-term temporal pixel signal of echocardiography frames [2]. These intensity variation time curves (IVTCs) (assessed for each pixel) were passed through a Butterworth low-pass filter. The bandwidth of the low-pass filter was chosen by trial and error and may not be applicable to other echocardiographic data. Furthermore, detection of fast-moving objects by simple thresholding, again through trial and error, may not be adaptive enough.
                     

To prevent these limitations, the method presented in this paper applies temporal information using a sparse representation approach, which enables adaptive thresholding.

The first step of our proposed method involves extracting intensity variation time curves (IVTC) for each pixel of consecutive echocardiographic frames. These curves can be defined by p(x,y,t) for the pixel in coordinate (x,y) at the frame time t. The parameter t is in the range of (1 … T), in which T is the total number of frames. A sample IVTC from a fixed coordinate (x,y) of 128 consecutive frames is illustrated in Fig. 2.
                        
                     

In ultrasound imaging, the back-scattered acoustic pulses in the receiver may be in or out of phase. These constructive and destructive interferences appear as a granular pattern of speckle noise on the image texture. The video frames recorded by the transducer pass through attenuation correction and logarithmic transformation of the intensity value. Therefore, the noise model can be assumed to be additive. These patterns can be interpreted as high-frequency variations added to the IVTCs and can be suppressed by low-pass filters [2].

The canonical form of reconstruction algorithms for the sparse signal recovery can be defined as a compressive sensing problem, and therefore expressed as a linear regression formula [12]:

                           
                              (1)
                              
                                 
                                    x
                                    =
                                    Φ
                                    w
                                    +
                                    
                                       ɛ
                                    
                                 
                              
                           
                        where x represents a M × 1 signal vector, w is a N × 1sparse coefficient vector, Φ is a M × N dictionary matrix whose columns contain a possibly over-complete basis (i.e. N > M) and ɛ is noise. The main goal is to find the sparse solution w based on the signal x and the pre-designed over-complete dictionary Φ.

The sparsest representation of a signal can be formulated by finding a vectorw ∈ RN
                         with the smallest number of non-zero elements. That is:

                           
                              (2)
                              
                                 
                                    
                                       w
                                       ^
                                    
                                    =
                                    
                                       
                                          arg
                                          min
                                       
                                       w
                                    
                                    
                                       
                                          ∥
                                          w
                                          ∥
                                       
                                       0
                                    
                                    
                                    
                                       s
                                       .
                                       t
                                    
                                    
                                    
                                       
                                          ∥
                                          
                                             x
                                             −
                                             Φ
                                             w
                                          
                                          ∥
                                       
                                       2
                                       2
                                    
                                    ≤
                                    δ
                                 
                              
                           
                        in which δ is the noise variance. However, this optimization problem requires exhaustive searching and is both numerically unstable and NP-hard
                           1
                        
                        
                           1
                           Non-deterministic polynomial-time hard.
                        .

Many efficient schemes to find the sparsest solution have been proposed in the literature. These solutions can be divided into four categories as follows:

                           
                              (1)
                              Convex relaxation algorithms

In this category, a convex optimization problem is solved through linear programming by converting the l
                                 0- norm penalty to the l
                                 1- norm penalty:

                                    
                                       (3)
                                       
                                          
                                             
                                                w
                                                ^
                                             
                                             =
                                             arg
                                             
                                                min
                                                w
                                             
                                             
                                                {
                                                
                                                   
                                                      ∥
                                                      
                                                         x
                                                         −
                                                         Φ
                                                         w
                                                      
                                                      ∥
                                                   
                                                   2
                                                   2
                                                
                                                +
                                                ρ
                                                
                                                   
                                                      ∥
                                                      w
                                                      ∥
                                                   
                                                   1
                                                
                                                }
                                             
                                          
                                       
                                    
                                 
                              

This group includes Basis Pursuit (BP) [13], Basis Pursuit De-Noising (BPDN) [14], Least Absolute Shrinkage and Selection Operator (LASSO) [14] and Dantzig Selector [15]. These methods are accurate but computationally complex.

Greedy iterative algorithms

In the second category, the algorithm is used to find active coefficients in an iterative procedure. The informative criterion to decide which coefficients are practically active is the correlation between the signal and the atoms of the dictionary. Examples of this group are Matching Pursuit (MP) [16], Orthogonal Matching Pursuit (OMP) [8], Stage-wise OMP (StOMP) [17]. When the signal is not very sparse, greedy iterative algorithms become costly; but otherwise these methods have low implementation cost and a high speed of recovery compared to convex relaxation algorithms.

Iterative thresholding algorithms

This class of algorithms are faster than the convex optimization algorithms. A soft or hard iterative thresholding is performed to decrease the l
                                 1 norm of the coefficients and a gradient descent is also applied to decrease the value of 
                                    
                                       
                                          ∥
                                          
                                             x
                                             −
                                             Φ
                                             w
                                          
                                          ∥
                                       
                                       2
                                       2
                                    
                                 . This category includes Two-step Iterative Shrinkage Thresholding (TwIST) [18], GPSR [19], Bregman iterations [7] and SpaRSA [20]. The advantages of this approach include low computational complexity and easy implementation.

Probabilistic algorithms

In probabilistic approaches, the problem is solved in a Bayesian framework. Sparse Bayesian Learning (SBL) [21] and Bayesian Compressive Sensing (BCS) [6] are the most popular probabilistic approaches. The major disadvantages of SBL algorithms are high computational costs and large memory requirements. The BCS method demonstrates superior performance in speed and has sharp reconstruction in contrast to most CS algorithms. BCS can be considered a much faster variational formulation of SBL which uses the fast Relevance Vector Machine (RVM) algorithm [6].

For this project, we compared sparse recovery algorithms and introduced superior methods for de-noising IVTCs that reduced processing time and reconstruction errors.

There are two methods for designing an over-complete dictionary. The first method involves compiling the dictionary using a set of pre-specified functions, while the second method utilizes a learning process whereby a given set of signal examples are used to compile a more relevant dictionary. However, in many cases, designing the dictionary based on a pre-specified transform matrix is more attractive because it is simpler and enables faster evaluation of the sparse representation.

In this paper we report use of the first methodology to design an over-complete dictionary. Based on our prior knowledge of the IVTC signals’ nature, we compiled a set of pre-specified functions which included four wavelet families and sine and cosine functions. The sine and cosine parts are considered in the dictionary because of the periodic nature of the cardiac cycle; the wavelet parts are considered for the small variations and rapid transitions which are added to sine–cosine signals.

In choosing a proper wavelet family, important concepts were considered; the main one being the application of orthogonal wavelet families rather than biorthogonal wavelets. In wavelet analysis, a signal can be explained by the wavelet function ψ(x) and the scaling function ϕ(x) [22]. In orthogonal wavelets there is one scaling and one wavelet function, and the same number of coefficients in each. In contrast, in the biorthogonal case, there are two scaling functions and accordingly two different wavelet functions, each with a different number of coefficients. Therefore, for simplicity and reduced complexity of dictionary structure, we chose the orthogonal wavelets. The available orthogonal wavelets are: Haar, Daubechies, Symlet, Coiflets and Discrete Meyer. From among these available orthogonal wavelets, four wavelet families were chosen which have the desired shape for constructing the IVTC. These wavelets consist of the following families: Daubechies 4 (db4), Symlet 2 (sym2), Symlet 4 (sym4) and Discrete Meyer (dmey) [22]. It should be noted that since the IVTC is not smooth, the small vanishing moments such as 2 and 4 are proper for Daubechies and Symlet families.

The following paragraphs describe the dictionary in two parts: first, the wavelet functions, and second, the sine–cosine functions.

In the wavelet part of the dictionary, for a length of the temporal signal IVTC (T), we create T signals which are zero except in position t
                        
                           
                              (
                              t
                              =
                              1
                              ,
                              …
                              ,
                              T
                              )
                           
                        . Each signal is then convolved with the wavelet and scaling functions to produce the basis atoms in our dictionary. Fig. 3
                         shows an example for creating the 75th basis atom of the db4 wavelet function.

Accordingly, for a signal with length T, for each wavelet family, we have 2 × T atoms of which T atoms correspond to the convolution of shifted pulse signals with the scaling functions; the other T atoms correspond to the wavelet functions. Overall, for 4 wavelet families, the number of columns in the wavelet part of the dictionary are 4 × 2 × T. For the sine–cosine part of the dictionary, we simply generate sine and cosine functions sin (k × t/T) and cos (k × t/T), 
                           
                              k
                              =
                              1
                              ,
                              …
                              ,
                              T
                              /
                              2
                           
                        , 
                           
                              t
                              =
                              1
                              ,
                              …
                              ,
                              T
                           
                        . Hence, we have T/2 atoms for the sine part and also T/2 atoms for the cosine part. Therefore, the over-complete dictionary has T rows and 9 × T columns (atoms). Note that each atom is normalized to the energy of the atoms of the corresponding family.


                        Fig. 4
                         shows the creation of some atoms in the dictionary in both wavelet and sine–cosine parts; the matrix schematic of the input signal, designed dictionary and corresponding sparse coefficient is illustrated in Fig. 5.
                        
                     

Once our over-complete dictionary contains all the candidate basis functions to be considered in the reconstruction, the remaining task is to apply the sparse recovery algorithm that allows us to solve for w in Eq. (1).

The following section illustrates the experimental results of applying sparse recovery algorithms on IVTC signals and then reconstructing a smooth version of the signals by the most significant atoms using an adaptive threshold.

@&#EXPERIMENTAL RESULTS@&#

The proposed technique has been evaluated using the grey-scale images of two-chamber and four-chamber view sequences of a set of healthy volunteers
                        2
                     
                     
                        2
                        The study was approved by Regional Committee for Medical Research Ethics and was performed according to the HelsinkiDeclaration. Written informed consent was obtained from each participant.
                     . The transthoracic echocardiogram (TTE) image sequences were recorded using a Vivid 3 ultrasound machine with a 2.0 MHz probe. The resolution of each image was 220×320 pixels. There was no built-in temporal or spatial noise reduction applied in these images. Fig. 6
                      illustrates sample frames.

We considered 250 frames for each subject. Hence the parameter T is equal to 250. A sample signal of a fixed coordinate is illustrated in Fig. 7.
                  

In order to choose a suitable sparse recovery algorithm for our application, we compared eight different methods. The comparison was based on the defined over-complete dictionary and sample IVTC signals. These algorithms are: BPDN [14], LASSO [14], OMP [8], GPSR [19], SpaRSA [20], Bregman [7], TwIST [18], and BCS [6]. In order to make a fair comparison, we modified the algorithms to have a fixed number of coefficients then went on to calculate the reconstruction error, which was defined based on 
                           
                              
                                 ∥
                                 
                                    x
                                    −
                                    Φ
                                    w
                                 
                                 ∥
                              
                              2
                           
                        formulation. For each sparse recovery algorithm, the results of the reconstruction error and processing time for the 100 non-zero coefficients are summarized in Table 1.
                        
                     

Except for the GPSR algorithm, which is too slow, the other algorithms are similar in processing time. Hence the processing time parameter is not very discriminating. The more critical parameter for choosing the best sparse recovery algorithm is the reconstruction error. Based on this parameter, the best methods are the BCS, OMP and Bregman algorithms. (Compared to the BCS and OMP methods, the Bregman algorithm showed greater reconstruction error; however, as this method is particularly fast we continued to consider it in our investigations.)

Based on this comparison, we completed the de-noising procedure using the Bregman, BCS, and OMP recovery algorithms, while quality metrics of reconstructed images were compared with other de-noising algorithms.

The active coefficients were extracted by applying the sparse recovery algorithms and using the pre-specified over-complete dictionary. The length of the coefficient vector is equal to the number of columns in the dictionary. This vector is a sparse one, as its elements are mostly zero. Figs. 8–10
                        
                         illustrate the BCS, OMP, and Bregman sparse coefficients corresponding to the signal shown in Fig. 7.

Note that the number of non-zero coefficients is fixed to 100 in each algorithm. Fig. 11
                         illustrates the sorted non-zero normalized coefficients shown in Figs. 8–10: the coefficients rapidly decrease and most are equal to zero, therefore the dictionary atoms are well defined to make a sparse representation of the IVTC signals.

By reconstructing the signal with all coefficients, a signal similar to the original signal is obtained. Fig. 12
                         shows the reconstructed signal with all coefficients calculated using the different methods.

A smooth version of the signal can be constructed by preserving the most significant coefficients and eliminating the near-zero coefficients. This is achieved by choosing an adaptive threshold based on the Square-Root-Log (Sqtwolog) criterion method [23].

The Sqtwolog threshold (λ) is calculated based on a universal threshold:

                           
                              (4)
                              
                                 
                                    λ
                                    =
                                    σ
                                    
                                       
                                          2
                                          log
                                          (
                                          N
                                          )
                                       
                                    
                                 
                              
                           
                        where N is the length of the non-zero coefficients and σis the standard deviation of non-zero coefficients. For a robust estimation ofσ, we applied the Median Absolute Deviation (MAD) estimator which is related to standard deviation by:

                           
                              (5)
                              
                                 
                                    σ
                                    =
                                    1.4826
                                    M
                                    A
                                    D
                                    =
                                    1.4826
                                    m
                                    e
                                    d
                                    i
                                    a
                                    n
                                    (
                                    
                                       |
                                       
                                          
                                             w
                                             ′
                                          
                                          −
                                          m
                                          e
                                          d
                                          i
                                          a
                                          n
                                          
                                             (
                                             
                                                w
                                                ′
                                             
                                             )
                                          
                                       
                                       |
                                    
                                    )
                                 
                              
                           
                        where w′ is the non-zero coefficient.

The thresholding function which is used here was presented in [42]:

                           
                              (6)
                              
                                 
                                    {
                                    
                                       
                                          
                                             
                                                x
                                                −
                                                0.5
                                                
                                                   
                                                      
                                                         λ
                                                         2
                                                      
                                                      x
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   |
                                                   x
                                                   |
                                                
                                                ≻
                                                λ
                                             
                                          
                                       
                                       
                                          
                                             
                                                0.5
                                                
                                                   
                                                      
                                                         x
                                                         3
                                                      
                                                      
                                                         λ
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   |
                                                   x
                                                   |
                                                
                                                ≤
                                                λ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where λ is the universal threshold extracted by Eq. (4) and x is the coefficient. In this function, instead of setting the coefficients below the threshold value to zero, the non-important coefficients are tuned by a polynomial function. This leads to a more powerful function than that accomplished by soft or hard thresholding [24].


                        Figs. 13
                        
                        –15
                         show the reconstructed signal after adaptively attenuating small coefficients for BCS, Bregman and OMP methods, respectively.

In echocardiography images, there are fast-moving objects like mitral valves. These objects have structures that, for some specific spatial coordinates, move rapidly and are only present in a few frames. This phenomenon is visible as some magnified points in the temporal signal. Fig. 16
                         illustrates the temporal signal corresponding to mitral valve spatial coordinates.

One of the advantages of the proposed algorithm is an accurate and adaptive reconstruction of these high intensity points which prevents the blurring of fast-moving objects. The success of this method depends on choosing proper wavelet families when designing the dictionary atoms. Fig. 17
                         illustrates the result of smoothing the temporal signal corresponding to the mitral valve spatial coordinates shown in Fig. 16, using the different methods.
                     

In order to compare the proposed method to dictionary learning based methods, the 1-D KSVD [25] method was also implemented too. The KSVD is an iterative method with three stages. In the first stage, the noisy signal is divided into overlapping small blocks, each rearranged to a column vector xl
                         and the matrix 
                           
                              X
                              =
                              [
                              
                                 x
                                 1
                              
                              ,
                              
                                 x
                                 2
                              
                              ,
                              .
                              .
                              .
                              ,
                              
                                 x
                                 L
                              
                              ]
                           
                         is constructed. In the second stage, sparse coefficients 
                           
                              W
                              =
                              [
                              
                                 w
                                 1
                              
                              ,
                              
                                 w
                                 2
                              
                              ,
                              .
                              .
                              .
                              ,
                              
                                 w
                                 L
                              
                              ]
                           
                         are recovered, fixing the dictionary D and applying the OMP algorithm to the objective function of KSVD:

                           
                              (7)
                              
                                 
                                    
                                       ∀
                                       l
                                    
                                    :
                                    
                                       min
                                       
                                          D
                                          ,
                                          W
                                       
                                    
                                    μ
                                    
                                       
                                          ∥
                                          
                                             w
                                             l
                                          
                                          ∥
                                       
                                       0
                                    
                                    
                                    
                                       s
                                       .
                                       t
                                    
                                    
                                    
                                       
                                          ∥
                                          
                                             x
                                             l
                                          
                                          −
                                          D
                                          
                                             w
                                             l
                                          
                                          ∥
                                       
                                       2
                                       2
                                    
                                    ≺
                                    
                                       
                                          (
                                          C
                                          .
                                          σ
                                          )
                                       
                                       2
                                    
                                 
                              
                           
                        where each wl
                        is a sparse coefficient corresponding to xl, σ is the noise variance, and C is a constant which is usually set to 1.15 [25].

The initial guess of the dictionary is an over-complete DCT (Discrete Cosine Transform) dictionary [25]. In the final stage, fixing the sparse coefficients W, the algorithm attempts to update the atoms of the dictionary one by one to further reduce the error. This method is highly dependent on the accuracy of the estimation of noise variance, which limits the performance. Other important parameters are block size and the dictionary size. In this experiment we set the block size to 25, the redundancy factor to 9, and the number of columns in the dictionary to 225. Accordingly, for each IVTC, the size of the dictionary was 25 × 225. The noise variance was 10, the noise gain C was set to 1.15 and the number of iterations was 20. These parameters were set by trial and error for the best result. For more details refer to [25] and the corresponding MATLAB code available at:http://www.cs.technion.ac.il/∼ronrubin/software.html.


                        Figs. 18–19
                         illustrate a sample de-noised IVTC signal where the 1-D KSVD de-noising method was used. In this case, the algorithm has suppressed the signal too much—some of the rapidly moving structures have not been preserved. As demonstrated above, other proposed methods (pre-specified dictionary and BCS, Bregman or OMP) better preserved such details (Fig. 17).


                        Fig. 20
                         shows both the original noisy image (a) and the corresponding de-noised image in one sample frame using each of the three sparse recovery methods, BCS (b), Bregman (c), and OMP (d). It is obvious that with all filtering methods, the speckle noise is suppressed while the edges are preserved. In the next section, qualitative and quantitative evaluations of the proposed method are described.
                     

For the quantitative assessment, nine image quality metrics were applied: Signal to Noise Ratio (SNR), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Peak Signal to Noise Ratio (PSNR), Pratt's Figure of Merit (FoM) [26], Contrast to Noise Ratio (CNR), Structural Similarity (SSIM), Speckle Suppression Index (SSI) [27] and MSU Blurring Metric [28]. Of these, CNR, SNR and MSU Blurring Metric operate on a single image while the other metrics (FoM, SSIM, RMSE, MAE, PSNR and SSI) are comparative in nature and consider two images. In a similar approach to that taken in [2,29,30], because of the lack of a noise-free reference in clinical tests, the performance of these images is measured relative to the original speckled input.

The FoM and SSIM metrics are used to assess the preservation of edge and structural information, respectively. These metrics have a range between 0 and 1, with unity representing perfect preservation.

The SNR and SSI metrics are commonly used as measurements for speckle strength. SNR quantifies the level of speckle as the ratio of mean to standard deviation of pixel intensity of the image and the SSI is the ratio of the standard deviation to the mean of the filtered image normalized to that of the original image. In the filtered image, speckling is suppressed causing lower variance. Therefore, the smaller the SSI value or the greater the SNR value, the greater the speckle suppression.

This set of popular speckle reduction techniques was used to evaluate the performance of the proposed algorithm on image outcome in comparison to other de-noising filters.

The filters used for comparison were some local statistical filters such as the Lee, Kuan, Frost, 3×3 median and 3×3 Wiener filters; speckle reduction anisotropic diffusion (SRAD); VisuShrink with soft and hard shrinkage; the NeighShrink filter; 2D-KSVD denoising [25] and the non-local means filter.

The perceptual quality comparisons among the proposed and other de-noising techniques of real echocardiographic images are shown in Fig. 21. The proposed method (for all three recovery algorithms; images b, c and d) reduces blurring while preserving the edges more accurately than with the other methods. This perceptual quality outperformance is more obvious again in the echocardiography videos.

For a better demonstration of the outperformance of the proposed method, this paper has supplementary downloadable material (Online Resources). This includes 17 multimedia mpeg1-format movie clips, which show sample original and de-noised versions using the proposed and other methods. The material is 4.94 MB in size. A description of the movie clips is summarized in Table 2.
                     


                        Table 3
                         shows the average assessment metrics for speckle reduction methods of echocardiography images. The values are averaged over the total image set.

The assessment metrics demonstrate the outperformance of the proposed method compared to other methods; this is the case for all three recovery algorithms, although BCS recovery gives the overall best performance. The soft VisuShrink filter achieved the lowest SSI and provided the best speckle suppression but performed poorly in preserving image details, especially in FoM and SSIM metrics. The SSI values are slightly higher in the three proposed filters, but these values are very similar in magnitude to the SSI values for most other filters.

For visual assessment of the proposed algorithm, an experienced echocardiologist evaluated the performance of each filter in a blind manner. She emphasized that the results of the proposed technique are superior to the other methods by vanishing more speckle and causing less blurring of the image. The cardiologist acknowledged that the movement of small structures such as the valves, the papillary muscles, the cords attached to the mitral valves and the left ventricular endocardial surface were preserved, with no blurring effects.

@&#CONCLUSION@&#

An adaptive and accurate de-noising framework for echocardiographic images based on temporal information and sparse representation was presented to improve image processing applications and to enhance visual quality for the echocardiologist. The proposed method builds the foundations for adapting sparse representations of IVTC signals extracted from echocardiographic images. To enable selection of the best sparse recovery algorithm, a comprehensive comparison between different methods was undertaken. Using reconstruction error and processing time as the selection criteria, three methods—BCS, Bregman and OMP—were chosen. By adaptively eliminating small coefficients and conserving a set of sparse significant coefficients to retain certain structures of a signal, an efficient method for de-noising echocardiographic images was developed. Qualitative and quantitative assessment indicated the outperformance of the BCS algorithm compared to the Bregman and OMP recovery algorithms. A comparative evaluation of the proposed method with other de-speckle filtering techniques was performed. The Lee, Frost, Wiener, Kuan and median filters were chosen because they are popular in noise reduction for echocardiographic images. Additionally, various state-of-the-art methods sharing a similar methodological core, such as speckle reduction anisotropic diffusion (SRAD), VisuShrink with soft and hard shrinkage, NeighShrink, 2D-KSVD and nonlocal means were also investigated, all demonstrating inferior performance.

For echocardiography images which are to be used diagnostically, speckle suppression is not the only criterion for successful filtering; multiple criteria should be taken into account to determine which filtering method is optimal. In this paper, nine image quality metrics were measured. This comprehensive results assessment shows that the proposed filter suppresses speckle noise, adaptively preserves edge and structural details and causes no significant blurring. It also preserves the rapidly moving structures exemplified by the mitral valve.

Although the computational complexity for the proposed method is higher than that for the Wiener and median methods, with ever-growing data processing capabilities, computational cost will become secondary in importance to the improved performance achievable by the proposed methods.

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.compeleceng.2015.12.008.


                     
                        
                           Image, 1
                           Image, 1
                           
                        
                     
                  

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Augmented depth perception visualization in 2D/3D image fusion

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We investigate several concepts enabling improvement of current image fusion visualization.


                        
                        
                           
                           We propose a contour enhanced visualization to circumvent hidden information in the X-ray.


                        
                        
                           
                           We implement a new occlusion and depth color-coding algorithm to improve perception in X-ray.


                        
                        
                           
                           Our occlusion correction provides 100% correctness when determining the position of an aneurysm in X-ray.


                        
                        
                           
                           The color-coding schemes improve visualization in 2D/3D overlay images.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

2D/3D registration

Visualization

X-ray

C-arm fluoroscopy

Depth encoding

Depth perception

Color depth encoding

@&#ABSTRACT@&#


               
               
                  2D/3D image fusion applications are widely used in endovascular interventions. Complaints from interventionists about existing state-of-art visualization software are usually related to the strong compromise between 2D and 3D visibility or the lack of depth perception. In this paper, we investigate several concepts enabling improvement of current image fusion visualization found in the operating room. First, a contour enhanced visualization is used to circumvent hidden information in the X-ray image. Second, an occlusion and depth color-coding scheme is considered to improve depth perception. To validate our visualization technique both phantom and clinical data are considered. An evaluation is performed in the form of a questionnaire which included 24 participants: ten clinicians and fourteen non-clinicians. Results indicate that the occlusion correction method provides 100% correctness when determining the true position of an aneurysm in X-ray. Further, when integrating an RGB or RB color-depth encoding in the image fusion both perception and intuitiveness are improved.
               
            

@&#INTRODUCTION@&#

Wilhelm Röntgen's X-ray image is still used as the real-time imaging modality of choice in a majority of interventions [1]. To assist interventionists during procedures pre-operative images can be fused with X-ray. This 2D/3D overlay is obtained via alpha-blending; that is, a compromise in transparency between the data. Even with this shortcoming, the overlay is a gold-standard and widely used in endovascular procedures, neuroradiology, oncology, coronary interventions, electrophysiology studies, and other treatments. Although 3D imaging has the advantage of providing spatial information, intraoperative X-ray remains the focal point and main interest for the interventionist since diagnosing stenosis or aneurysms and positioning a catheter, guide wire, or stent can only be performed by visualizing this modality. Luckily, experienced interventionists have substantial training interpreting X-ray alone [2].

Spatial information (or depth) is a main benefit of using 3D datasets in medical procedures. The 2D/3D overlay allows the interventionist to understand the 3D structure more quickly, especially in complex cases. The transfer functions (TFs) defined to create this overlay are crucial and are used to classify data in volume rendering based on intensity, gradient magnitude [3], curvature [4] and/or local structures [5]. The visualization of the overlay must be meaningful for the interventionist, and in this sense depth perception has been an important issue for volume rendering. Recently, Zheng et al. proposed a method for the improvement of perceptually based ordering in volume rendering [6]. They set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception. Guided by the function, they use a conjugate gradient method to iteratively and judiciously enhance the results. Alternatively, Kniss et al. proposed an interactive shading model based on volumetric light attenuation effects to incorporate volumetric shadows in volume rendering [7]. Solteszova et al. proposed a new method called chromatic shadowing based on a shadow transfer function to handle the over-darkening problem, thus allowing for better perception of details in the shadowed areas [8]. Bruckner et al. introduced volumetric halos in the volume rendering pipeline to facilitate depth perception. The halos are known as the darkened or brightened regions surrounding the edges of a targeted structure. The added halos help judge the spatial relationships more accurately [9]. Everts et al. presented a technique to create depth-dependent halos for 3D line data [10]. Adding colors for improved perception during rendering has been investigated recently. Chuang et al. suggested reducing color saturation in occluded objects only in the overlap region while keeping its lightness [11]. Wang et al. used cold colors such as green, blue, or cyan to encode the foreground, and warm colors such as red, yellow or magenta to encode background [12].

Other volume rendering techniques, such as MIP (maximum intensity projection) and DRR (digital reconstructed radiograph), normally have poor depth perception. Mora et al. introduced the order-independent volume rendering (OIVR) techniques to improve MIP and DRR using gradient signals inside stereo-images. Instead of using only the original signal (the voxel data) to produce the MIP or DRR, gradient magnitude was used in the rendering to convey more information [13]. Lastly, Kersten et al. used a purely absorptive lighting model in DRR rendering to enhance the depth perception of the synthetic X-ray images [2].

In 3D angiography visualization of the vascular structure is important. In principle, general rendering techniques are applicable for vascular visualization. Preim et al. give an overview of 3D vascular visualization. They distinguished two classes of approaches: model-based and model-free [14]. Model-based approaches rely on model assumptions to create easy-to-interpret visualizations, while model-free approaches represent the data more faithfully. Depth-perception is also an important task for vascular visualization. Normally the interventionist views the 3D angiograms with an interactive rotation to get a better understanding and perception of the 3D structure. However, the interventionist may not be interested in rotating the 3D visualization during procedure as their hands may be occupied with surgical instruments or contain traces of blood. Ropinski et al. proposed and evaluated several visualization techniques that support the depth perception of angiogram images [15]. Different depth cues, such as depth based color-coding, edge enhancement and depth-of-field effects, are introduced and combined to enhance depth perception of complex vascular systems. Finally, Ritter et al. and Chu et al. proposed real-time rendering pipelines and efficient modeling for illustrative visualization of vascular systems [16,17].

The general workflow to attain 2D/3D image fusion is shown in Fig. 1
                        . It becomes increasingly difficult to rapidly recognize and differentiate different structures in fused images. As previously noted, the interventionist's visual is altered since the anatomies from each modality appear floating on top of each other in the overlay. This affects the perception and natural ordering of vascular structures. With these issues in mind we note that all pixels in X-ray, and voxels in pre-operative data, do not have the same importance and contribution to the final fused images. This observation suggests extracting only relevant-based data according to the pixels or voxels [18,19].

We now present previous works for visualizing 2D/3D overlays in different medical systems. The first clinical results of 3D roadmapping in neuroangiography are presented by Södermann et al. [20]. The 3D roadmap is a blended image of unsubtracted fluoroscopy with the dataset of the prior volume acquisition. The translucent 3D overlay with enhanced contours preserves much of the 2D information from fluoroscopy, however the depth perception is poor. In 2006, Gorges et al. showcased their work on 3D augmented fluoroscopy in neuroradiology [21]. In their work two visualization options were provided for 2D/3D image fusion: the surface view and the blending view. Almost no catheter/guidewire information is displayed in the surface view whereas no spatial information is visible in the blended view. In 2010, Okumura et al. presented an evaluation of 3D roadmapping for neuroendovascular procedures [22]. An obvious improvement of Okumura's work was the enhanced visualization of catheter projections. Compared to [21], the overlay is almost opaque. Since the catheter information is the main interest for the interventionist, the amplified signal of the 2D projection of the catheter is overlaid on the 3D vessel tree. One problem of this visualization is that signals of other regions are also amplified leading to a noisy image overlay. In contrast, Rossitti et al. presented the 3D roadmapping with syngo iPilot in the treatment of cerebral aneurysms and AVMs [23]. Instead of amplifying the catheter signal, a translucent representation of the 3D vessel tree is overlaid to preserve the 2D information. Another difference is that the subtracted 2D image (i.e. 2D roadmap) is used instead of the native fluoroscopic image. With an accurate 2D/3D registration, the fused 2D/3D roadmap is more efficient in delivering useful information. However, a shortcoming of this visualization is that the vessel tree contains patches of signal noise that are difficult to eliminate. The final rendered result fully depends on the transfer function, and adjusting the transfer function to reach an optimal visualization is difficult. Recently, Wieczorek et al. introduced an interactive X-ray perceptual visualization (IXPV) technique to improve 3D perception in standard X-ray images. With preoperative CT data, it allows the user to interactively manipulate the X-ray image by varying depth [24]. Aichert et al. introduced color transfer functions for the visualization of the overlay with preoperative data [25], while Wang et al. integrated a virtual mirror directly in the X-ray image which provides an interactive and real-time view, to the interventionist, of the 3D preoperative data [26].

The methods presented in the cited literature review share a common drawback: there is a strong compromise between 2D and 3D information coupled with weak depth perception. Therefore, the benefit of using 2D/3D overlays is limited by those visualization methods. High transparency keeps the X-ray visible but reduces the 3D overlaid information. In this paper, we hypothesize that there are alternative techniques to improve the visualization for any 2D/3D overlay. First, we propose a contour enhanced visualization to circumvent hidden information in the X-ray image. This allows the perimeter of vessels to remain visually intact for the interventionist. Second, we implement a new occlusion and depth color-coding algorithm to improve depth perception in X-ray. An evaluation using both phantom and clinical data is performed in the form of a questionnaire. In total, 24 participants including ten clinicians and fourteen non-clinicians were asked to partake in the study.

@&#METHODOLOGY@&#

The 2D images are acquired during C-arm fluoroscopy, and aside from depicting vasculature they may also contain guidewires or catheters depending on procedure. The interventionist can normally choose the image mode between native fluoroscopy and subtracted images. For overlay application, the calibration of the C-arm is essential. With a calibrated system, the working projection parameters can be acquired together with fluoroscopic images. The parameters are then applied to the 3D dataset in order to generate a projection of the 3D volume that matches the 2D image. The 3D datasets can be either obtained intra-operatively using rotational angiography, or pre-operatively using CT/MRI.

Registration of the 2D and 3D data is also crucial for the overlay, especially for the multi-modal cases and the cases with evident deformation of the target anatomy. We recall that the scope of this paper is not a study of registration techniques but solely on improving and evaluating the visualization of 2D/3D overlay. Our algorithm is based on direct volume rendering (DVR) where ray casting is used to generate the final rendered image. The color and opacity values are modified using the Non-Photorealistic Rendering (NPR) based contour visualization.

Contours are very important features in vascular structures. Although non-photorealistic contour rendering for vascular visualization is not new [16,17], to the best of our knowledge it is a novel approach to 2D/3D overlay applications. In the ideal case, a contour is defined as the part of the surface where the normal vector n is perpendicular to the viewing direction v. To provide a more intuitive visualization, the neighboring region is considered instead of the ideal contour, which appears only as a curved line (see Fig. 2
                        ). Since no intermediate geometry such as surface or polygonal mesh is generated, the normal vector of the surface is estimated directly by the local gradient g. The volumetric datasets are in the form of 3D scalar fields. The angle θ between the two vectors is estimated by the dot product v·n, as 
                           
                              θ
                              =
                              arccos
                              (
                              
                                 
                                    
                                       v
                                    
                                    ⋅
                                    
                                       n
                                    
                                 
                              
                              )
                           
                        . With the above variables, we can formulate the basic contour factor κ. The formulation of κ can vary, such as using the dot product of v and n directly to modulate the opacity value [27,28].

Our proposed formulation of κ is given as:
                           
                              (1)
                              
                                 
                                    κ
                                    =
                                    
                                       e
                                       
                                          S
                                          (
                                          θ
                                          −
                                          ψ
                                          )
                                       
                                    
                                 
                              
                           
                        which provides two separate options for modifying the contour visualization property, namely sharpness and thickness, by using two input parameters: (a) 
                           
                              S
                              ∈
                              
                                 ℕ
                                 +
                              
                           
                         controls the sharpness of the contour, and (b) ψ
                        ∈[0; π/2] is a threshold of the angle value controlling the thickness of the contour. The contour factor κ is used to modulate the color opacity of the volume sample (i.e. α-channel of the color). For parts of the surface with smaller θ, the opacity becomes more transparent. In general, smaller ψ yields thicker contours while larger S values yield sharper contours. The above approach for contour visualization is directly based on volumetric gradient in 3D (see Fig. 3
                        ).

For the gradient-based contour rendering proposed in the previous section, we modify the traditional volume rendering. We begin with the default color composition in ray casting rendering, which is known as alpha-blending. The main idea behind alpha-blending consists of evaluating the volume rendering integral. The integral is typically along a ray cast from an image pixel and crossing through the volume. The basic integral formula in the discrete domain is [29]:
                           
                              (2)
                              
                                 
                                    C
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          0
                                       
                                       n
                                    
                                    
                                       
                                          C
                                          i
                                       
                                       
                                          ∏
                                          
                                             j
                                             =
                                             0
                                          
                                          
                                             i
                                             −
                                             1
                                          
                                       
                                       
                                          (
                                          1
                                          −
                                          
                                             α
                                             j
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        where α
                        
                           i
                         and C
                        
                           i
                         are the opacity and color values of the ith sampled voxel x. We can also write the formula in the form of a single ith step. The parameters are defined as:
                           
                              •
                              the color and the opacity of ith sampled voxel C
                                 
                                    i
                                  and α
                                 
                                    i
                                 . The voxel color C
                                 
                                    i
                                  can be modulated by depth color coding (in II-D). The voxel opacity α
                                 
                                    i
                                  is modulated by the contour factor κ defined in (1);

the intermediate color and opacity before compositing the ith sample are C
                                 
                                    i−1 and an intermediate opacity α-value a in Eq. (3);

the intermediate color and opacity after compositing the ith sample are C
                                 
                                    i
                                  and a
                                 
                                    i
                                 .

Then the composition procedure of ith step can be written as:
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      C
                                                   
                                                   i
                                                
                                                =
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                +
                                                (
                                                1
                                                −
                                                
                                                   
                                                      a
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                )
                                                ⋅
                                                
                                                   C
                                                   i
                                                
                                                ⋅
                                                
                                                   α
                                                   i
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      a
                                                   
                                                   i
                                                
                                                =
                                                
                                                   
                                                      a
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                +
                                                (
                                                1
                                                −
                                                
                                                   
                                                      a
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                )
                                                ⋅
                                                
                                                   α
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The standard alpha-blending formula in a single step is given in (3). Note that the volume is rendered in front-to-back ordering. Our approach of occlusive contour rendering modifies the standard alpha-blending. Three parameters need to be introduced: 
                           
                              
                                 α
                                 i
                                 
                                    src
                                 
                              
                           
                        , 
                           
                              
                                 α
                                 i
                                 
                                    occl
                                 
                              
                           
                        , and ω; where 
                           
                              
                                 α
                                 i
                                 
                                    src
                                 
                              
                           
                         is defined as the opacity value of the ith sample before contour modulation, 
                           
                              
                                 α
                                 i
                                 
                                    occl
                                 
                              
                           
                         is defined as the occlusive alpha, which is a virtual alpha value used for α-composition (where normally the real alpha value is used), and ω is in the range∈[0; 1] and defined as the occlusion factor controlling the degree of occlusion. Now, the occlusion-adapted alpha-blending is modified as follows:
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      C
                                                   
                                                   i
                                                
                                                =
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                +
                                                (
                                                1
                                                −
                                                
                                                   
                                                      a
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                )
                                                ⋅
                                                
                                                   C
                                                   i
                                                
                                                ⋅
                                                
                                                   α
                                                   i
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      a
                                                   
                                                   i
                                                
                                                =
                                                
                                                   
                                                      a
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                
                                                +
                                                (
                                                1
                                                −
                                                
                                                   α
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                   
                                                      occl
                                                   
                                                
                                                )
                                                ⋅
                                                
                                                   α
                                                   i
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   α
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                   
                                                      occl
                                                   
                                                
                                                =
                                                
                                                   α
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                   
                                                      occl
                                                   
                                                
                                                +
                                                (
                                                1
                                                −
                                                
                                                   α
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                   
                                                      occl
                                                   
                                                
                                                )
                                                ⋅
                                                
                                                   α
                                                   i
                                                   
                                                      src
                                                   
                                                
                                                ⋅
                                                ω
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The occlusive alpha is used for compositing the opacity value. If ω
                        =1, the following voxel sample in the volume contributes only slightly to the result and the color will still be transparent. In contrast, if ω
                        ≈0, the accumulated occlusive alpha is still near to 0 in the next composition. Thus the occlusion factor, ω, controls the degree of occlusion. To further explain our depth perception via occlusion rendering, as shown in Fig. 4a and b, with the occlusion effect it is clear that the blue rectangle is on the top (or in front of) the green one. The sample on the blue rectangle has C
                        1
                        =(0; 0; 1) and α
                        1
                        =0.95 and the sample on the green rectangle has C
                        2
                        =(0; 1; 0) and α
                        2
                        =0.95. After contour modulation, the alpha values inside the two rectangles are equal to 0.1. In the first composition of blue, the opacity value is small (transparent), but the occlusive alpha, 
                           
                              
                                 α
                                 i
                                 
                                    occl
                                 
                              
                           
                        , is accumulated as 0.95×
                        ω. On the other hand, if ω
                        =1.0, the following sample contributes less significantly to the result and the color will still be transparent no matter if the incoming sample is on the green contour or not. The last two images in Fig. 4c and d shows the situation when ω
                        =1 and ω
                        =0.3. 
                        Fig. 5
                         shows volume rendering examples with three different occluding factors.

Occlusion is a strong and intuitive depth cue, but works only when overlapping exists between objects. In computer graphics, the z-value of the render element (i.e. vertex) in the eye coordinate system is important. It is known as the depth of the render element, and is typically used to generate a depth map or for z-buffering. In NPR volume rendering, color can be modified with featured information. In this section, we describe how the depth value is used for color coding in order to generate depth perceptive contours. The viewing depth of the voxel is mapped into color. Depth ratio γ
                        
                           d
                         is defined as a parameter linearly associated with depth value:
                           
                              (5)
                              
                                 
                                    
                                       γ
                                       d
                                    
                                    =
                                    
                                       
                                          D
                                          −
                                          
                                             D
                                             
                                                n
                                                e
                                                a
                                                r
                                             
                                          
                                       
                                       
                                          
                                             D
                                             
                                                f
                                                a
                                                r
                                             
                                          
                                          −
                                          
                                             D
                                             
                                                n
                                                e
                                                a
                                                r
                                             
                                          
                                       
                                    
                                 
                              
                           
                        In (5), D is the viewing depth while D
                        
                           near
                         and D
                        
                           far
                         are used to define a depth range. Different color patterns can be used for coding. Previously, a pseudo chromadepth technique was used for depth perception in angiography [15]. Here, the same chromadepth and pseudo chromadepth color coding are adapted for contour rendering. Given γ
                        
                           d
                        
                        ∈[0,1] of the ith sample, thus the color C
                        
                           i
                         can be coded based on chromadepth technique as:
                           
                              (6)
                              
                                 
                                    
                                       C
                                       i
                                    
                                    =
                                    
                                       
                                          1.0
                                          −
                                          
                                             γ
                                             d
                                          
                                          ,
                                          
                                             1
                                             2
                                          
                                          [
                                          1
                                          −
                                          cos
                                          (
                                          2
                                          π
                                          ⋅
                                          
                                             γ
                                             d
                                          
                                          )
                                          ]
                                          ,
                                          
                                             γ
                                             d
                                          
                                       
                                    
                                 
                              
                           
                        Pseudo chromadepth is a reduction of color hues to only red and blue, the color C
                        
                           i
                         can be coded as:
                           
                              (7)
                              
                                 
                                    
                                       C
                                       i
                                    
                                    =
                                    (
                                    1.0
                                    −
                                    
                                       γ
                                       d
                                    
                                    ,
                                    0
                                    ,
                                    
                                       γ
                                       d
                                    
                                    )
                                 
                              
                           
                        The color coding defined above uses the RGB color model. As discussed in [15], too many color hues may obscure the clarity of the depth perception. Therefore, we investigate the HSI (hue, saturation and intensity) model for color coding. Both saturation and intensity channels can be coded with γ
                        
                           d
                         for depth perception. However, the coded HSI color needs to be converted to RGB color for rendering. For good measure, we also investigate an adapting gray value color that encodes gray value with depth, such as:
                           
                              (8)
                              
                                 
                                    
                                       C
                                       i
                                    
                                    =
                                    (
                                    1.0
                                    −
                                    
                                       γ
                                       d
                                    
                                    ,
                                    1.0
                                    −
                                    
                                       γ
                                       d
                                    
                                    ,
                                    1.0
                                    −
                                    
                                       γ
                                       d
                                    
                                    )
                                 
                              
                           
                        
                     

It is also possible to modulate the opacity value of the contours with γ
                        
                           d
                        . Accordingly, vasculature farther away becomes more transparent and gives the effect of contours fading as the viewing depth increases. In total, we implemented four models for depth encoding: the RGB, RB, HSI, and gray value color depth encoding (see Fig. 6
                        ).


                     Participants: In order to assess the impact of adding depth cues in the overlay image, a questionnaire was devised and distributed to different specialists in the field. In total, 24 participants were asked to evaluate the methods described in this paper:
                        
                           •
                           14 non-clinical professionals: four engineers from medical industry (X-ray angiography division), nine computer scientists and one engineer from academia (biomedical computing/visualization background).

10 clinical professionals: three neuroradiologists and seven clinicians in interventional angiography.


                     Visualization parameters: these were set empirically. First, the depth ranges D
                     
                        near
                      and D
                     
                        far
                      were initialized as 0 and 100 respectively. The occlusion factor ω equals 1, and to strengthen opacity we chose vascular angles closer to 90° and larger than the threshold ψ
                     =85°. The alpha control factor α, is normally set to 0 to filter out “invisible” samples. The sharpness of contour S, equals 4.


                     Statistics: the evaluation was performed based on the analysis of variance (ANOVA) and the Likert Scale – a psychometric scale most widely used to scaling responses in survey research. The format of our five-point Likert was: 1 – Strongly disagree, 2 – Disagree, 3 – Neither agree nor disagree, 4 – Agree, and 5 – Strongly agree. Results will be divided into the two participant categories (non-clinicians versus clinicians). Further, individual t-tests were performed to assess significance between the coloring-encoding schemes.


                     Questionnaire: The questionnaire was intended to evaluate the significance of our proposed methods. There were 30 questions that included 1 phantom and 2 clinical (unhealthy) datasets. We used CT and rotational angiography for 3D, and the X-ray images for 2D. We randomized questions and techniques, so as to prevent bias when assessing the impact of our proposed visualizations. The following key queries were addressed:
                        
                           •
                           
                              Aneurysm position with occlusion rendering: Participants received the instructions to choose correctly where the aneurysm or blockage in a vessel is truly positioned, given either: (a) standard X-ray image, (b) standard occlusion correction using gradients, or (c) the proposed occlusion-based technique (see Fig. 7
                              ).


                              Vessel ordering with color-coding: Participants received the instructions to position correctly one of 4 vessels from the clinical data and one of 6 vessels from the phantom data and rate the RGB, RB, HSI, and gray color schemes in terms of depth resolution and intuition (see Fig. 8
                              ).


                              Depth perception and intuition: Lastly, we asked the participants to use the Likert scale assessing on how intuitive the color-coding was inside the fused images and whether it improved their understanding of 3D structures.

@&#RESULTS@&#

We begin by presenting results when determining the aneurysm position using the occlusion rendering visualization. From Fig. 9
                     , the success rate for the non-clinicians was: using X-ray (2/14, 14.2%), using the gradient based method (2/14, 14.2%), using our occlusion rendering (14/14, 100%). A one-way ANOVA indicated significance (p-value=4.97E−10). The success rate for the clinicians was: using X-ray (3/10, 30%), using the gradient based method (1/10, 10%), using our occlusion rendering (10/10, 100%). A one-way ANOVA indicated significance (p-value=4.51E−06).

Next, we present results for vessel ordering using color-coding on phantom datasets. From Fig. 10
                     , the success rate for the non-clinicians was: using X-ray (0/14, 0%), using RGB (14/14, 100%), using RB (13/14, 92.9%), using HSI (12/14, 85.7%) and using gray color depth encoding (11/14, 78.6%). A one-way ANOVA indicated significance (p-value=3.37E−14). The success rate for the clinicians was: using X-ray (1/10, 10%), using RGB (9/10, 90%), using RB (9/10, 90%). using HSI (8/10, 80%) and using gray color depth encoding (9/10, 90%). A one-way ANOVA indicated significance (p-value=4.05E−06).

Similarly, we present results for vessel ordering using color-coding on clinical datasets. From Fig. 11
                     , the success rate for the non-clinicians was: using X-ray (2/14, 14.3%), using RGB (14/14, 100%), using RB (13/14, 92.9%), using HSI (11/14, 78.6%), and using gray color depth encoding (12/14, 85.7%). A one-way ANOVA indicated significance (p-value=3.25E−09). The success rate for the clinicians was: using X-ray (0/10, 10%), using RGB (10/10, 100%), using RB (10/10, 100%), using HSI (8/10, 80%), and using gray color depth encoding (7/10, 70%). A one-way ANOVA indicated significance (p-value=1E−09).

Lastly, we asked all participants whether our color-depth encoding improved depth perception and intuition. The final results are depicted in Table 1
                     . Individual t-tests did not show statistical significance between the color-encoding schemes which infers that any scheme could potentially be used to improve depth perception when compared to traditional X-ray.

@&#DISCUSSION@&#

On the experimental side, we included both clinicians and non-clinician participants. Novel concepts of visualization (even the good ones) have the possibility of not being well accepted by clinicians since they have solely experience with the traditional visualization in greyscale (i.e. X-ray). However, a good visualization concept should provide a natural understanding, but not depend on the way clinicians are medically trained. Therefore, if our concept is accepted by non-clinicians, who provide more natural responses, it means that our concept has the possibility of being accepted and used to ease the medical training of new generations of clinicians.

Based on the 24 participant responses, the results indicate that there seems to be no technical bias presented in our questionnaire and set of questions. Both scientists and clinicians perform similar to all the rendering schemes.

@&#CONCLUSION@&#

This work investigated visualization concepts for the 2D/3D overlay in common endovascular clinical applications that effectively enhance spatial information without concealing the 2D information. In order to perceive more of the X-ray, a volume contour rendering technique is introduced for 2D/3D overlay. Instead of modulating the opacity of 3D overlay in a uniform way, contour rendering achieves high opacity of the contours as well as high transparency between vasculature. Occlusion and depth color coding are used as two depth cues to enhance the depth perception of the contours. We evaluated our method using a survey which was designed to test two major hypotheses. First, our occlusion method is superior to current schemes in clinical practice. Second, the RGB and RB color-coding schemes are considered more intuitive for depth perception when compared to the current visualization tools in state-of-the-art. We verified both hypotheses through a large number of participants that included clinicians. Future work includes the use of anatomic models and/or statistical atlas CT instead of patient specific data.

The authors have no conflict of interest.

@&#REFERENCES@&#


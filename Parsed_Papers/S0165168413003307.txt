@&#MAIN-TITLE@&#Transcoding resilient video watermarking scheme based on spatio-temporal HVS and DCT

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Four criteria based on HVS and DCT domain are used to embed a robust watermark.


                        
                        
                           
                           We apply a quantization index modulation scheme to embed and detect the watermark.


                        
                        
                           
                           Watermark scheme is robust to transcoding video codec and low bit rate conversions.


                        
                        
                           
                           Watermark scheme is robust to signal processing and video frame-based attacks.


                        
                        
                           
                           Better performance than four recently reported video watermarking schemes.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Video watermarking

Video transcoding

Human Visual System

Motion distortion threshold

Visual attention region

@&#ABSTRACT@&#


               
               
                  Video transcoding is a legitimate operation widely used to modify video format in order to access the video content in the end-user's devices, which may have some limitations in the spatial and temporal resolutions, bit-rate and video coding standards. In many previous watermarking algorithms the embedded watermark is not able to survive video transcoding, because this operation is a combination of some aggressive attacks, especially when lower bit-rate coding is required in the target device. As a consequence of the transcoding operation, the embedded watermark may be lost. This paper proposes a robust video watermarking scheme against video transcoding performed on base-band domain. In order to obtain the watermark robustness against video transcoding, four criteria based on Human Visual System (HVS) are employed to embed a sufficiently robust watermark while preserving its imperceptibility. The quantization index modulation (QIM) algorithm is used to embed and detect the watermark in 2D-Discrete Cosine Transform (2D-DCT) domain. The watermark imperceptibility is evaluated by conventional peak signal to noise ratio (PSNR) and structural similarity index (SSIM), obtaining sufficiently good visual quality. Computer simulation results show the watermark robustness against video transcoding as well as common signal processing operations and intentional attacks for video sequences.
               
            

@&#INTRODUCTION@&#

With the rapid advance of multimedia and networking technologies, multimedia services such as teleconferencing, video on demand and distance learning have become more popular in our daily life. In these applications the video format is often required to be converted in order to adapt to several channel capacities (e.g., network bandwidth) as well as end-user's terminal capabilities (e.g., computing and display capacity) [1]. The transcoding is one of the key technologies to fulfill this challenging task. Using a transcoder we can convert a previously compressed video bit-stream into another bit-stream with different bit-rates, different spatial resolutions and/or different compression standards, etc. In the copyright protection issue, the transcoding poses new challenges on video watermarking technologies since it performs complex conversion operations that generate problems regarding the preservation of embedded copyright information. Then malicious users can perform the transcoding to obtain copyright-free video sequence with similar quality as the original ones and they can distribute them illegally [2]. Considering the above mentioned situation, watermark robustness against video transcoding must be considered to design an efficient video watermarking algorithm, however in almost all video watermarking techniques proposed in literature, the embedded watermark is not robust against transcoding and therefore the copyright protection is not sufficiently done.

Recently several robust watermarking schemes have been proposed in the literature [3–6], in which the resilience to transcoding is also considered. Lee et al. [3] propose a real-time video watermarking robust against transcoding, in which notable results against spatial reduction are shown, obtaining robustness against conversion of spatial resolution from High-Definition Television (HDTV) to Quarter Video Graphics Array (QVGA). This scheme is performed on MPEG-2 video bit-stream directly in order to satisfy the real-time requirements, however it generates vulnerability against the conversion of other video compression standards with low bit rates. Chen et al. [4] propose a robust video watermarking algorithm using the singular value decomposition (SVD) and slope-based embedding technique, in which synchronization information, together with the watermark sequence, is embedded to combat frame attacks, however re-synchronization mechanism of this scheme is not sufficient for the frame rate reduction caused by some aggressive transcoding. In [5], the Human Visual System (HVS) is used to adapt the watermarking energy of the quantization based video watermarking scheme in DWT domain. This scheme shows watermark robustness to some signal processing attacks; however combined attacks caused by common transcoding tasks remove the embedded watermark sequence. Ling et al. [6] propose a video watermarking algorithm robust mainly to geometrical distortions using Harris-Affine interest point detector. The watermark robustness of this scheme strongly depends on an accurate detection of interest points and generally an aggressive transcoding causes an inaccurate detection of many interest points, reducing the performance of this scheme.

The watermark embedding domain is an important aspect to design a video watermarking scheme robust against video transcoding. Video watermarking algorithms proposed in the literature can be classified into three main categories from embedding domains points of view: base-band domain algorithms [7,8], watermarking during video coding process [9,10] and watermark embedding directly on the encoded video sequence [11,12]. We consider that the base-band domain technique is more suitable for a watermarking scheme robust against aggressive video transcoding, because it is not focused on any video compression standard and also in this domain the watermark embedding energy can be adjusted easily according to its robustness and imperceptivity requirements, since the whole spatial information is available.

In this paper we propose a video watermarking scheme robust against video transcoding which performs in base-band domain using Quantization Index Modulation (QIM) algorithm [13]. To design a video watermarking scheme robust against an aggressive video transcoding task, first the key aspects of video transcoding, such as quality degradation caused by low bit-rate coding, similarities and difference among video compression standards, and effects of the temporal/spatial resolution change, are analyzed in detail. To embed a watermark sequence as robust as possible keeping the watermark imperceptibility, in the proposed scheme the quantization step size of the QIM algorithm is adaptively calculated using spatial and temporal HVS criteria. In the image watermarking techniques, QIM algorithms with adaptive quantization step size based on the spatial HVS properties have been proposed in order to obtain watermark imperceptibility and robustness simultaneously [14,15]. The proposed scheme also considers and exploits temporal information in order to get advantage on deficiency of the HVS to follow regions with high motion speed, using the spatio-temporal contrast sensitivity function and influence of eye movement. Additionally in the proposed scheme, the visual attention region is segmented in each video frame using Information Maximization to obtain more adequate quantification step size. So the watermark embedding process is performed combining four HVS criteria; texture and luminance sensitivity, a motion distortion threshold and visual attention region. The performance of the proposed scheme is compared with four recently reported robust video watermarking schemes [3–6], showing a better performance of the proposed scheme, especially in robustness against video transcoding. We consider that the main contribution of the proposed scheme is robustness to transcoding which is obtained by a detailed analysis of transcoding task and exploiting the spatio-temporal HVS properties in order to obtain adaptively the quantization step size of the QIM algorithm. In our best knowledge there is no another video watermarking scheme that exploits the spatio-temporal HVS criteria and visual attention region estimation to improve watermark robustness against aggressive attacks.

The rest of the paper is organized as follows: In Section 2, we analyze key aspects of video transcoding process to design an efficient watermarking scheme. Section 3 provides a detailed explanation of the watermark energy adaptation based on spatio-temporal HVS-based criteria and the visual attention region segmentation. In Section 4 the proposed scheme is described in detail. The evaluation results of the proposed scheme are compared with four recently reported video watermarking schemes in Section 5 and finally Section 6 provides the conclusions of this research.

Digital video can be dynamically adapted according to the available resources of the end-user's devices, such as computing power and display capability, as well as the channel capacity for transmission of the video sequence, such as channel bandwidth. One common example is the delivery of a high-quality multimedia source, such as a Digital Versatile Disc (DVD) or High Definition TV (HDTV), to a receiver with lower resources, such as Smart Phone, Tablets and Personal Computer. The video transcoding is one of the core technologies to satisfy this challenging task, creating adequate bit-stream directly from the original video sequence without user's conscious about decoding and re-encoding process [16]. The transcoding is defined as the operation of converting a video encoded in some format to another one with different characteristics [17]. In practice, the main characteristics of a digital video which can be transformed by a transcoder are the frame rate, bit-rate, video compression standard and spatial resolution as shown in 
                     Fig. 1. The transcoding task can be classified as homogeneous and heterogeneous. A homogeneous transcoder performs the conversion between video bit-streams of the same video compression standard, while a heterogeneous transcoder provides conversions between video bit-streams with different video compression standards.

Frame rate reduction, also known as temporal resolution reduction, is necessary when the user's end-system has less processing capability that cannot support the same frame rate as that of the original video. There are several strategies to avoid the loss of the embedded watermark signal due to this operation. One possible solution is to limit the watermark embedding process to intra frames (I-frames), since the transcoder discards inter-frames (P or B-frames) mainly to obtain frame rate reduction. However, in a blind watermark detection scheme, the parameters such as the group of pictures (GOP) or frame rate are unknown, and then the I-frame cannot be identified in the detection stage. Although a redundant embedding of the watermark signal in every frame of video sequence can solve this problem regardless of the frame rates of the target video, this method becomes vulnerable to intra-video collusion attacks, which can obtain the watermark sequence from several frames with different scenes [2].

According to the applications, several video compression standards, such as MPEG-2, Motion Picture Expert Group 4 Part 2 (MPEG-4), Windows Media Video 9 Codec (VC-1), Motion Picture Expert Group 4 Part 10 (H.264 AVC) and On2 True-Motion VP6 (VP6) are employed [16,17]. The necessity of the conversions between different video compression standards is generally associated to obtain acceptable visual quality with lower bit rate. In the heterogeneous transcoding the change of the frame format, as a result of change of the video compression standard, can be considered as an aggressive operation for many watermarking schemes, because a significant loss of information caused by quantization process may damage the integrity of the embedded watermark signal. The required bit-rate of the target video determines the quantization parameters and it is responsible for maintaining video quality while satisfying bandwidth, delay and memory space constraints [17,18].

Spatial resolution reduction is required when the display capability of the end-user's device is lower than that of the original one. For example, generally a teleconferencing system uses a Common Intermediate Format (CIF) with a resolution of 352×288 pixels. This resolution must be downscaled if the receiver system has a lower display capability, such as smartphone with Quarter CIF (QCIF) format (176×144 pixels). In this situation, a transcoder can carry out the spatial resolution reduction using different techniques [16].

Analyzing all processes performed by a heterogeneous transcoder, we conclude that in order to obtain an efficient watermarking scheme, the following two parameters must be considered: (a) the 2D-DCT coefficients that result more resilient to the quantization process, in which the watermark is embedded and (b) the maximum watermark energy that allows the embedded watermark to be robust against all attacks mentioned in this section, while preserving the watermark imperceptibility by the HVS.

As mentioned in Section 2, in order to obtain the robustness against aggressive heterogeneous transcoding, we need to embed a sufficiently strong watermark signal, considering the trade-off between watermark robustness and imperceptibility. To achieve this difficult task, the watermark energy is adapted using four HVS criteria, which takes an advantage of video watermarking schemes performed in base-band domain. The first two criteria are based on the relationship between the sensibility of the HVS to the visual quality degradation and spatial characteristics of each frame of the video sequence. The watermarking energy is calculated using the texture and luminance masking [19]. The third criterion is based on the failure of the HVS to follow regions with high motion speed. We use a concept based on the just noticeable distortion (JND) adapted for video as a model of the observer's eye movement [20]. As the fourth HVS criterion, the visual attention region is obtained for each video frame in order to generate less distortion in regions where observer's attention is attracted [21].

The most well-know HVS properties used in image coding fields are frequency sensitivity, texture and luminance masking. The texture masking property suggests that the human eye's sensitivity to error is low in the highly textured image areas, while the luminance masking property suggests that in the bright and dark image regions, the error sensitivity by human eye is low [19]. The luminance space of each frame of a video sequence is segmented into non-overlapped blocks of 8×8 pixels, in which the texture and luminance masking are calculated using the algorithm proposed by [19]. Both criteria are combined to obtain a maximum imperceptible distortion m(n,k) by the HVS for k-th block of n-th video frame, which is given by
                           
                              (1)
                              
                                 m
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 =
                                 T
                                 e
                                 x
                                 M
                                 a
                                 s
                                 k
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 ×
                                 L
                                 u
                                 m
                                 M
                                 a
                                 s
                                 k
                                 (
                                 n
                                 ,
                                 k
                                 )
                              
                           
                        where 
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                         and 
                           L
                           u
                           m
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                         are the texture and luminance masking, respectively. To calculate the texture masking 
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                        , first each block of 8×8 pixels is classified into texture, plain and edge blocks according to their spatial characteristics. To perform this classification, each block is transformed by 2D-DCT and the block in DCT domain is furthermore segmented into four areas as shown in 
                        Fig. 2(a), where the absolute sum of coefficients values of each area is denoted by DC, L, E and H, respectively [19]. The classification process can be summarized by the following conditions: a block is classified as plain block if E+H≤μ
                        1 (μ
                        1
                        =125), otherwise if (L+E)/H>γ (γ=4) then the block is considered as edge block and it is classified as texture block if E+H>κ (κ=290). Subsequently the texture masking 
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                         is assigned according to the type of k-th block. If the block is plain then 
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                           =
                           1
                        , considering that the error in the plain block is most noticeable by the HVS. If the block belongs to the edge block and 
                           L
                           +
                           E
                           ≤
                           400
                         then
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                           =
                           1.125
                        , otherwise 
                           T
                           e
                           x
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                           =
                           1.25
                        
                        [22]. Finally, for texture blocks the texture masking is obtained by
                           
                              (2)
                              
                                 T
                                 e
                                 x
                                 M
                                 a
                                 s
                                 k
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 =
                                 (
                                 
                                    
                                       F
                                    
                                    
                                       maxT
                                    
                                 
                                 −
                                 1
                                 )
                                 ×
                                 
                                    
                                       T
                                       e
                                       x
                                       E
                                       (
                                       n
                                       ,
                                       k
                                       )
                                       −
                                       M
                                       i
                                       n
                                    
                                    
                                       M
                                       a
                                       x
                                       −
                                       M
                                       i
                                       n
                                    
                                 
                                 +
                                 1
                              
                           
                        where 
                           T
                           e
                           x
                           E
                           (
                           n
                           ,
                           k
                           )
                           =
                           E
                           +
                           H
                         is the energy value for the k-th texture block of the n-th video frame; Max and Min represent the maximum and minimum energy for texture blocks, whose values are 1800 and 290, respectively [19], and F
                        
                           maxT
                         is the maximum elevation value used for fine adjustment of the model whose value is set to 2.25.

In the case of luminance masking, the method is divided into two parts: a linear model for middle and high luminance which is based on the Weber's law and a nonlinear model for low luminance where Weber's law is invalid [19]. Fig. 2(b) shows an approximation of the Weber's luminance law, where L
                        
                           min
                         and L
                        
                           max
                         values denote the luminance range for the linear model, which are determined as 90 and 255, respectively [19]. F
                        
                           maxL
                         represents the maximum luminance factor whose value is set to 2 [19]. The luminance masking 
                           L
                           u
                           m
                           M
                           a
                           s
                           k
                           (
                           n
                           ,
                           k
                           )
                         of the k-th block of the n-th video frame is given by
                           
                              (3)
                              
                                 L
                                 u
                                 m
                                 M
                                 a
                                 s
                                 k
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   (
                                                   
                                                      
                                                         F
                                                      
                                                      
                                                         max
                                                         
                                                         L
                                                      
                                                   
                                                   −
                                                   
                                                      
                                                         F
                                                      
                                                      
                                                         r
                                                         e
                                                         f
                                                      
                                                   
                                                   )
                                                   ×
                                                   
                                                      
                                                         D
                                                         C
                                                         (
                                                         n
                                                         ,
                                                         k
                                                         )
                                                         −
                                                         m
                                                         e
                                                         a
                                                         n
                                                      
                                                      
                                                         
                                                            
                                                               L
                                                            
                                                            
                                                               max
                                                            
                                                         
                                                         −
                                                         m
                                                         e
                                                         a
                                                         n
                                                      
                                                   
                                                   +
                                                   1
                                                
                                             
                                             
                                                
                                                   if
                                                   
                                                   D
                                                   C
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   )
                                                   >
                                                   m
                                                   e
                                                   a
                                                   n
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   if
                                                   
                                                   25
                                                   ≤
                                                   D
                                                   C
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   )
                                                   ≤
                                                   m
                                                   e
                                                   a
                                                   n
                                                
                                             
                                          
                                          
                                             
                                                
                                                   1.125
                                                
                                             
                                             
                                                
                                                   if
                                                   
                                                   15
                                                   ≤
                                                   D
                                                   C
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   )
                                                   <
                                                   25
                                                
                                             
                                          
                                          
                                             
                                                
                                                   1.125
                                                
                                             
                                             
                                                
                                                   if
                                                   
                                                   D
                                                   C
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   )
                                                   <
                                                   15
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           D
                           C
                           (
                           n
                           ,
                           k
                           )
                         is the DC coefficient of k-th block of n-th frame, mean is mean luminance value of n-th frame and F
                        
                           ref
                         is the reference factor corresponding to mean luminance value in linear model. 
                        Fig. 3 shows the first frame from “Foreman” video sequences and its texture and luminance masking representation. In the texture masking (Fig. 3(b)), “black” represents plain blocks, where the HVS sensitivity to distortion is larger, while “white” and “gray” represent edge and texture blocks, respectively. In the luminance masking (Fig. 3(c)), regions with higher and lower brightness (darkness) suggest a lower sensitivity to distortion by the HVS than other regions.

The third criterion is based on the deficiency of the HVS to follow regions with high motion speed. Taking in account the perceptual motion speed of each 2D-DCT block, the motion distortion threshold 
                           T
                           (
                           n
                           ,
                           k
                           ,
                           i
                           ,
                           j
                           )
                         can be computed. This threshold value indicates the maximum distortion that can be tolerated in the (i,j)-th sub-band of the k-th 2D-DCT block of the n-th video frame, because a distortion with smaller value than this threshold cannot be perceived by the HVS. To compute this threshold, we use a DCT-domain JND-based method for video sequence proposed in [20], which is given by
                           
                              (4)
                              
                                 T
                                 (
                                 n
                                 ,
                                 k
                                 ,
                                 i
                                 ,
                                 j
                                 )
                                 =
                                 
                                    1
                                    
                                       G
                                       (
                                       n
                                       ,
                                       k
                                       ,
                                       i
                                       ,
                                       j
                                       )
                                    
                                 
                                 ⋅
                                 
                                    M
                                    
                                       
                                          
                                             φ
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             φ
                                          
                                          
                                             j
                                          
                                       
                                       (
                                       
                                          
                                             L
                                          
                                          
                                             max
                                          
                                       
                                       −
                                       
                                          
                                             L
                                          
                                          
                                             min
                                          
                                       
                                       )
                                    
                                 
                                 ⋅
                                 
                                    1
                                    
                                       0.6
                                       +
                                       0.4
                                       
                                          
                                             cos
                                          
                                          2
                                       
                                       
                                          
                                             θ
                                          
                                          
                                             i
                                             ,
                                             j
                                          
                                       
                                    
                                 
                                 ,
                                 
                                 i
                                 ,
                                 j
                                 =
                                 0
                                 ,
                                 1
                                 ,
                                 …
                                 L
                                 −
                                 1
                              
                           
                        where L is the sub-block size, 
                           G
                           (
                           n
                           ,
                           k
                           ,
                           i
                           ,
                           j
                           )
                         is the spatio-temporal contrast sensitivity function (CSF), which is described later, 
                           
                              
                                 L
                              
                              
                                 max
                              
                           
                         and 
                           
                              
                                 L
                              
                              
                                 min
                              
                           
                         represent the maximum and minimum display luminance values while 
                           M
                         is the number of gray levels, which is set to 256, 
                           
                              
                                 ϕ
                              
                              
                                 i
                              
                           
                         and 
                           
                              
                                 ϕ
                              
                              
                                 j
                              
                           
                         are 2D-DCT normalization factors, which are 
                           
                              
                                 φ
                              
                              
                                 u
                              
                           
                           =
                           
                              
                                 1
                                 /
                                 L
                              
                           
                         for u=0 and 
                           
                              
                                 φ
                              
                              
                                 u
                              
                           
                           =
                           
                              
                                 2
                                 /
                                 L
                              
                           
                         for u≠0; 
                           
                              
                                 θ
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                           =
                           arcsin
                           (
                           2
                           
                              
                                 ρ
                              
                              
                                 i
                                 ,
                                 0
                              
                           
                           
                              
                                 ρ
                              
                              
                                 0
                                 ,
                                 j
                              
                           
                           /
                           
                              
                                 ρ
                              
                              
                                 i
                                 ,
                                 j
                              
                              
                                 2
                              
                           
                           )
                         is the visual angle, where 
                           
                              
                                 ρ
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                           =
                           
                              
                                 
                                    
                                       (
                                       i
                                       /
                                       
                                          
                                             ω
                                          
                                          
                                             x
                                          
                                       
                                       )
                                    
                                    2
                                 
                                 
                                    
                                       (
                                       j
                                       /
                                       
                                          
                                             ω
                                          
                                          
                                             y
                                          
                                       
                                       )
                                    
                                    2
                                 
                                 /
                                 2
                              
                           
                         is the spatial sub-band frequency, where 
                           
                              
                                 ω
                              
                              
                                 ℏ
                              
                           
                           =
                           2
                           ⋅
                           arctan
                           (
                           
                              
                                 Λ
                              
                              
                                 ℏ
                              
                           
                           /
                           2
                           l
                           )
                           ,
                           
                           ℏ
                           =
                           x
                           ,
                           y
                         denotes either the horizontal or vertical sizes of a pixel in degrees of visual angle, which are represented by the viewing distance l and display size 
                           
                              
                                 Λ
                              
                              
                                 x
                              
                           
                           ×
                           
                              
                                 Λ
                              
                              
                                 y
                              
                           
                         
                        [20].

The spatio-temporal CSF 
                           G
                           (
                           n
                           ,
                           k
                           ,
                           i
                           ,
                           j
                           )
                         in (4) is defined by [20]
                        
                           
                              (5)
                              
                                 G
                                 (
                                 n
                                 ,
                                 k
                                 ,
                                 i
                                 ,
                                 j
                                 )
                                 =
                                 
                                    
                                       c
                                    
                                    
                                       0
                                    
                                 
                                 
                                    (
                                    
                                       
                                          
                                             k
                                          
                                          
                                             1
                                          
                                       
                                       +
                                       
                                          
                                             k
                                          
                                          
                                             2
                                          
                                       
                                       
                                          
                                             |
                                             
                                                log
                                                
                                                   (
                                                   
                                                      ε
                                                      ⋅
                                                      
                                                         
                                                            v
                                                            (
                                                            n
                                                            ,
                                                            k
                                                            )
                                                         
                                                         3
                                                      
                                                   
                                                   )
                                                
                                             
                                             |
                                          
                                          3
                                       
                                    
                                    )
                                 
                                 ⋅
                                 v
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 ⋅
                                 
                                    
                                       (
                                       2
                                       π
                                       
                                          
                                             ρ
                                          
                                          
                                             i
                                             ,
                                             j
                                          
                                       
                                       )
                                    
                                    2
                                 
                                 ⋅
                                 exp
                                 (
                                 −
                                 2
                                 π
                                 
                                    
                                       ρ
                                    
                                    
                                       i
                                       ,
                                       j
                                    
                                 
                                 
                                    
                                       c
                                    
                                    
                                       1
                                    
                                 
                                 (
                                 ε
                                 ⋅
                                 v
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 +
                                 2
                                 )
                                 /
                                 
                                    
                                       k
                                    
                                    
                                       3
                                    
                                 
                                 )
                              
                           
                        where 
                           
                              
                                 k
                              
                              
                                 1
                              
                           
                           ,
                           
                              
                                 k
                              
                              
                                 2
                              
                           
                           ,
                           
                              
                                 k
                              
                              
                                 3
                              
                           
                         and 
                           ε
                         are constants which are empirically set to 6.1,7.3, 23 and 1.7, respectively [20], and 
                           
                              
                                 c
                              
                              
                                 0
                              
                           
                         and 
                           
                              
                                 c
                              
                              
                                 1
                              
                           
                        are constant values that control the magnitude and the bandwidth of a CSF whose best-fitted values are 7.126 and 0.565, respectively [20]. 
                           v
                           (
                           n
                           ,
                           k
                           )
                         is the perceptual motion speed given by 
                           v
                           (
                           n
                           ,
                           k
                           )
                           =
                           
                              
                                 v
                              
                              
                                 I
                              
                           
                           (
                           n
                           ,
                           k
                           )
                           −
                           
                              
                                 v
                              
                              
                                 E
                              
                           
                           (
                           n
                           ,
                           k
                           )
                        , which corresponds to the motion speed without eye movement, 
                           
                              
                                 v
                              
                              
                                 I
                              
                           
                        , compensated by eye movement speed, 
                           
                              
                                 v
                              
                              
                                 E
                              
                           
                        , where
                           
                              (6)
                              
                                 
                                    
                                       v
                                    
                                    
                                       I
                                    
                                 
                                 (
                                 n
                                 ,
                                 k
                                 )
                                 =
                                 f
                                 ⋅
                                 
                                    
                                       
                                          
                                             (
                                             M
                                             
                                                
                                                   V
                                                
                                                
                                                   x
                                                
                                             
                                             (
                                             n
                                             ,
                                             t
                                             )
                                             ⋅
                                             
                                                
                                                   ω
                                                
                                                
                                                   x
                                                
                                             
                                             )
                                          
                                          2
                                       
                                       +
                                       
                                          
                                             (
                                             M
                                             
                                                
                                                   V
                                                
                                                
                                                   y
                                                
                                             
                                             (
                                             n
                                             ,
                                             t
                                             )
                                             ⋅
                                             
                                                
                                                   ω
                                                
                                                
                                                   y
                                                
                                             
                                             )
                                          
                                          2
                                       
                                    
                                 
                              
                           
                        represents the motion speed of k-th block without eye movement, f is the video frame rate and 
                           (
                           M
                           
                              
                                 V
                              
                              
                                 x
                              
                           
                           (
                           n
                           ,
                           t
                           )
                           ,
                           M
                           
                              
                                 V
                              
                              
                                 y
                              
                           
                           (
                           n
                           ,
                           t
                           )
                           )
                         is motion vector, while 
                           
                              
                                 v
                              
                              
                                 E
                              
                           
                           (
                           n
                           ,
                           k
                           )
                           =
                           
                           min
                           
                           [
                           g
                           ⋅
                           
                              
                                 v
                              
                              
                                 I
                              
                           
                           (
                           n
                           ,
                           t
                           )
                           +
                           
                              
                                 v
                              
                              
                                 min
                              
                           
                           ,
                           
                              
                                 v
                              
                              
                                 max
                              
                           
                           ]
                         is eye movement speed [20], where g is the gain factor related to the object tracking efficiency of eye, 
                           
                              
                                 v
                              
                              
                                 min
                              
                           
                        and 
                           
                              
                                 v
                              
                              
                                 max
                              
                           
                         are minimum and maximum eye movement speed, whose values are set to 0.92, 0.15 and 80.0deg/s, respectively [20].

Visual attention is a mechanism that filters out redundant visual information and detects the most relevant parts of our visual field. It is one of the fundamental properties of the HVS that can be used in several applications, such as image and video coding, and computer vision. Due to that, many research groups are currently investigating computational modeling of the visual attention system [21,22]. In the watermarking schemes, especially in video watermarking schemes where the duration of observation of each frame is short, the detection of the visual attention regions allows us to determine an adequate watermarking energy, strong enough to survive transcoding attacks, while keeping a minimum perceptual distortion.

The visual Attention based on Information Maximization (AIM) [21] is one of the methods most supported by the mechanism of the HVS, in which some orthogonal basis functions are generated using Independent Component Analysis (ICA) from a great amount of visual patches of T×T pixels randomly obtained from a considerably wide range of natural images. After generation of the basis functions, which are matrices with T×T elements, their pseudo-inverse matrices are calculated. Each patch 
                           
                              
                                 C
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                         of T×T pixels with a center (i, j) of the input frame is analyzed in terms of similarity 
                           
                              
                                 S
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                         with the r-th basis function, where r=1,…,R.
                           
                              (7)
                              
                                 
                                    
                                       S
                                    
                                    
                                       i
                                       ,
                                       j
                                       ,
                                       r
                                    
                                 
                                 =
                                 
                                    ∑
                                    
                                       p
                                       =
                                       0
                                    
                                    
                                       T
                                       −
                                       1
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          q
                                          =
                                          0
                                       
                                       
                                          T
                                          −
                                          1
                                       
                                    
                                    
                                       
                                          
                                             C
                                          
                                          
                                             i
                                             ,
                                             j
                                          
                                       
                                       (
                                       u
                                       ,
                                       v
                                       )
                                    
                                 
                                 ⋅
                                 
                                    
                                       Ψ
                                    
                                    
                                       r
                                    
                                 
                                 (
                                 p
                                 ,
                                 q
                                 )
                              
                           
                        where 
                           
                              
                                 Ψ
                              
                              
                                 r
                              
                           
                         is inverse matrix of r-th basis function, 
                           u
                           =
                           i
                           −
                           
                              ⌊
                              
                                 (
                                 T
                                 −
                                 1
                                 )
                                 /
                                 2
                              
                              ⌋
                           
                           +
                           p
                        ,
                           v
                           =
                           j
                           −
                           
                              ⌊
                              
                                 (
                                 T
                                 −
                                 1
                                 )
                                 /
                                 2
                              
                              ⌋
                           
                           +
                           q
                         and R is the number of basis functions. Then 
                           
                              
                                 S
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                         is normalized in order that the range of normalized 
                           
                              
                                 
                                    S
                                    ¯
                                 
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                         is [0, 1], where the highest and lowest 
                           
                              
                                 
                                    S
                                    ¯
                                 
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                         are 1 and 0, respectively. The higher similarity between the (i,j)-th patch 
                           
                              
                                 C
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                         and r-th basis function produces the higher value of 
                           
                              
                                 
                                    S
                                    ¯
                                 
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                        . Considering that the observer's attention is attracted in the regions with unexpected objects or patterns compared with their surround, and then to obtain this unexpectedness, the self-information of the (i,j)-th patch 
                           
                              
                                 C
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                         for r-th basis function is calculated, which is 
                           1
                           /
                           
                           log
                           (
                           
                              
                                 Pr
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                           (
                           r
                           )
                           )
                           =
                           −
                           
                           log
                           (
                           P
                           
                              
                                 r
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                           (
                           r
                           )
                           )
                        , where 
                           
                              
                                 Pr
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                           (
                           r
                           )
                         is the probability density function of the normalized similarity 
                           
                              
                                 
                                    S
                                    ¯
                                 
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 r
                              
                           
                        . For example, if the similarity 
                           
                              
                                 
                                    S
                                    ¯
                                 
                              
                              
                                 
                                    
                                       i
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 
                                    
                                       j
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 r
                              
                           
                         between a patch 
                           
                              
                                 C
                              
                              
                                 
                                    
                                       i
                                    
                                    
                                       k
                                       ,
                                    
                                 
                                 
                                    
                                       j
                                    
                                    
                                       k
                                    
                                 
                              
                           
                         and r-th basis function is high and also many other patches of the frame have same high similarities with the r-th basis function, then the 
                           
                              
                                 Pr
                              
                              
                                 
                                    
                                       i
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 
                                    
                                       j
                                    
                                    
                                       k
                                    
                                 
                              
                           
                           (
                           r
                           )
                         is high meaning that the patch 
                           
                              
                                 C
                              
                              
                                 
                                    
                                       i
                                    
                                    
                                       k
                                       ,
                                    
                                 
                                 
                                    
                                       j
                                    
                                    
                                       k
                                    
                                 
                              
                           
                         is a common pattern in the frame, so its self-information is low. The self-information of the patch 
                           
                              
                                 C
                              
                              
                                 i
                                 ,
                                 j
                              
                           
                         for all basis functions is a sum of the self-information of each basis function, which is
                           
                              (8)
                              
                                 S
                                 M
                                 a
                                 p
                                 (
                                 i
                                 ,
                                 j
                                 )
                                 =
                                 −
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 
                                    log
                                    (
                                    
                                       
                                          Pr
                                       
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    (
                                    r
                                    )
                                    )
                                 
                              
                           
                        The resultant SMap is visual attention map, whose values indicate the unexpectedness grades and then using these values the visual attention regions can be segmented from the rest of the frame. 
                        Fig. 4 shows the visual attention region obtained applying the AIM-based method [21] to the first frame of “Coastguard” video sequence. Once the visual attention regions are obtained, the rest of image is segmented by blocks of 8×8 pixels, denominated as Region of No Interest (RONI) blocks.

@&#PROPOSED METHOD@&#

As we discussed in Section 2, each of the transcoding tasks performs complex conversion operations which generate problems related to the preservation of the embedded copyright information. In the proposed video watermark scheme, the particular tasks of all processes performed in the video transcoding, such as changes of frame rate, bit-rate, compression standard and spatial resolution as shown in Fig. 1, are considered to determine an adequate watermark embedding energy avoiding loss of watermark signal, while keeping high quality of watermarked video sequences.

In order to get robustness against frame rate reduction, we use two strategies: (a) The detector of video scene change is introduced that allows embedding watermark signals generated by different keys in frames of different scenes, which allows the scheme to be robust against frame-based attacks, whose objective is the video temporal de-synchronization, such as frame dropping, frame averaging and frame swapping; (b) the adaptive watermark energy calculation based on the HVS is introduced to avoid the intra-video collusion attack, because the watermark sequence is also different among frames of the same scene.

Since in proposed scheme, robustness against heterogeneous transcoding is considered, the affinities of different video compression standards must be analyzed to obtain robustness against this attack. Some of the most significant similarities of the video compression standards are the macro-block as the basic processing unit for motion estimation, which is used to determine the motion distortion threshold described in Section 3.2, the YCbCr color space usage, the 2D-DCT transform and the Sub Quarter CIF (SQCIF) format (128×96 pixels) as the minimum unit of spatial resolution.

In the proposed scheme we embed the watermark signal into non-overlapped 2D-DCT blocks of 8×8 pixels in luminance space. Considering standard color space qof video and low correlation among three color components, YCbCr color space is used in the proposed video watermarking scheme. To obtain a robust video watermarking scheme against aggressive quantification process, which is used to reduce bit-rate, first we analyzed video quality degradation caused by the quantization process with different bit-rates in several compression standards. We analyzed 10 video sequences with 150 frames, CIF format and 30 FPS each one, under six different bit-rates, which are 4Mbps, 2Mbps, 1Mbps, 512Kbps, 256Kbps and 128Kbps, with five video compression standards, which are MPEG-2, MPEG-4, VC-1, H.264 AVC and VP6. From the results shown in 
                     Fig. 5, we can determine that the average video quality obtained from H.264 AVC with 4Mbps bit-rate causes the lowest degradation of the video quality (PSNR=37.02, SSIM=0.951), while the VC-1 with 128Kbps bit-rate causes the highest degradation of the video quality (PSNR=29.52, SSIM=0.783). The visual quality of both compressed video can be observed in 
                     Fig. 6.

Taking in account that VC-1 compression standard with 128Kbps bit-rate causes the highest distortion of video quality, the goal of proposed scheme can be considered to obtain the watermark robustness against this processing. To determine the DCT coefficients more resilient to the quantization process caused by the VC-1 video compression standard with bit-rate of 128Kbps, the corresponding quantization process is applied to DCT blocks of 8×8 coefficients and the number of non-zero AC coefficients is computed.


                     
                     Fig. 7 shows the percentage of AC coefficients which satisfy |ACi|>0 (i ∈ {1…63}), after quantization process, where 10 video sequences are used. From the figure, two AC coefficients with lowest frequency, AC1 (C
                     1,2) and AC2 (C
                     2,1) are considered as adequate coefficients where the watermark can be embedded in a robust manner against most aggressive case, i.e. the VC-1 video compression standard with bit-rate of 128Kbps. Considering the above results, in the proposed scheme one-bit of the watermark sequence is embedded into AC2 coefficient of each non-overlapping 2D-DCT block of 8×8 coefficients. Finally, in order to obtain robustness against spatial resolution changes, which causes spatial de-synchronization between watermark embedding and detection processes, in the proposed watermark detection process first input video sequence is resized to obtain a standard spatial resolution format, and then the detection process is done.

This section details the proposed watermark embedding process. 
                        Fig. 8 shows the watermark embedding process, which is described as follows: (1) Divide the video sequence into scenes, which will allow embedding watermark signals generated by different keys for each scene. (2) Obtain the luminance space of the original video frame F
                        
                           n
                        , where n= 1, 2,…, N and N is the total number of video frames in a scene. (3) Segment the luminance space into non-overlapping blocks of size 8×8 pixels and the 2D-DCT transform is applied to each block. One bit of the watermark signal is embedded into each block. (4) Calculate the visual attention region by performing the process described in Section 3.3. Each k-th block of the n-th video frame is classified as RONI or ROI block. (5) Only for RONI blocks, compute the values of m(n, k) given by (1) and T(n,k,2,1) given by (4). (6) Generate a watermark vector W= {w
                        1, w
                        2,…,w
                        
                           K
                        } using a user's secret key for a given scene, where 
                           
                              
                                 w
                              
                              
                                 k
                              
                           
                           ∈
                           {
                           0
                           ,
                           1
                           }
                           ,
                           
                           k
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           K
                        . (7) The QIM embedding process is applied to embed a watermark bit into AC2 coefficient of each 2D-DCT block, according to the following equation:
                           
                              (9)
                              
                                 
                                    
                                       C
                                    
                                    
                                       2
                                       ,
                                       1
                                    
                                    
                                       '
                                    
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   s
                                                   i
                                                   g
                                                   n
                                                   (
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         2
                                                         ,
                                                         1
                                                      
                                                   
                                                   )
                                                   ×
                                                   
                                                      ⌊
                                                      
                                                         
                                                            
                                                               |
                                                               
                                                                  
                                                                     C
                                                                  
                                                                  
                                                                     2
                                                                     ,
                                                                     1
                                                                  
                                                               
                                                               |
                                                            
                                                            
                                                               2
                                                               
                                                                  
                                                                     S
                                                                  
                                                                  
                                                                     n
                                                                     ,
                                                                     k
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                      ⌋
                                                   
                                                   ×
                                                   2
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         n
                                                         ,
                                                         k
                                                      
                                                   
                                                   ,
                                                   
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   0
                                                
                                             
                                          
                                          
                                             
                                                
                                                   s
                                                   i
                                                   g
                                                   n
                                                   (
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         2
                                                         ,
                                                         1
                                                      
                                                   
                                                   )
                                                   ×
                                                   
                                                      (
                                                      
                                                         
                                                            ⌊
                                                            
                                                               
                                                                  
                                                                     |
                                                                     
                                                                        
                                                                           C
                                                                        
                                                                        
                                                                           2
                                                                           ,
                                                                           1
                                                                        
                                                                     
                                                                     |
                                                                  
                                                                  
                                                                     2
                                                                     
                                                                        
                                                                           S
                                                                        
                                                                        
                                                                           n
                                                                           ,
                                                                           k
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                            ⌋
                                                         
                                                         ×
                                                         2
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               n
                                                               ,
                                                               k
                                                            
                                                         
                                                         +
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               n
                                                               ,
                                                               k
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                   ,
                                                   
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   1
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 C
                              
                              
                                 2
                                 ,
                                 1
                              
                           
                         and 
                           
                              
                                 C
                              
                              
                                 2
                                 ,
                                 1
                              
                              
                                 '
                              
                           
                         are the original and the watermarked AC
                        2 coefficients, respectively, S
                        
                           n,k
                         represents the dynamic quantization step size for the k-th block and its value is determined as follows:
                           
                              (10)
                              
                                 
                                    
                                       S
                                    
                                    
                                       n
                                       ,
                                       k
                                    
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   Q
                                                   ⋅
                                                   m
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   )
                                                   ⋅
                                                   T
                                                   (
                                                   n
                                                   ,
                                                   k
                                                   ,
                                                   2
                                                   ,
                                                   1
                                                   )
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         B
                                                      
                                                      
                                                         n
                                                         ,
                                                         k
                                                      
                                                   
                                                   ∈
                                                   R
                                                   O
                                                   N
                                                   I
                                                
                                             
                                          
                                          
                                             
                                                
                                                   Q
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         B
                                                      
                                                      
                                                         n
                                                         ,
                                                         k
                                                      
                                                   
                                                   ∉
                                                   R
                                                   O
                                                   N
                                                   I
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where Q represents the static quantization step size (Q-step) determined through the trade-off between robustness and imperceptibility, which is described later.

The watermark extraction process is shown in 
                        Fig. 9 and is described as follows: (1) Divide the video sequence into scenes. (2) Obtain the luminance space of the watermarked video frame
                           
                              
                                 F
                              
                              
                                 n
                              
                              
                                 '
                              
                           
                        . (3) Segment the luminance space into non-overlapping blocks of size 8×8 pixels and apply the 2D-DCT transform to each block. (4) Extract the watermark vector from luminance space of the watermarked frame using the QIM extraction process:
                           
                              (11)
                              
                                 
                                    
                                       
                                          w
                                          ˜
                                       
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                0
                                             
                                             
                                                
                                                   if
                                                   
                                                   r
                                                   o
                                                   u
                                                   n
                                                   d
                                                   (
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         2
                                                         ,
                                                         1
                                                      
                                                      
                                                         '
                                                      
                                                   
                                                   /
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         n
                                                         ,
                                                         k
                                                      
                                                   
                                                   )
                                                   =
                                                   e
                                                   v
                                                   e
                                                   n
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   if
                                                   
                                                   r
                                                   o
                                                   u
                                                   n
                                                   d
                                                   (
                                                   
                                                      
                                                         C
                                                      
                                                      
                                                         2
                                                         ,
                                                         1
                                                      
                                                      
                                                         '
                                                      
                                                   
                                                   /
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         n
                                                         ,
                                                         k
                                                      
                                                   
                                                   )
                                                   =
                                                   o
                                                   d
                                                   d
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 C
                              
                              
                                 2
                                 ,
                                 1
                              
                              
                                 '
                              
                           
                        are the watermarked AC
                        2 coefficient and S
                        
                           n,k
                         represents the dynamic quantization step size for the k-th block of the n-th video frame.

@&#EXPERIMENTAL RESULTS@&#

To evaluate the performance of the proposed scheme, we used 10 video sequences with CIF format and 30 FPS. All video sequences have at least 150 frames which are available in [23]. 
                     Fig. 10 shows video sequences used for evaluation of the proposed scheme. The proposed scheme is evaluated from the watermark imperceptibility and robustness points of view.

Determining an appropriate static quantization step size Q is crucial to obtain a good performance of the proposed scheme from the watermark imperceptibility and robustness points of view. First to evaluate the relationship between static quantization step size Q and watermark imperceptibility, the PSNR and SSIM index are obtained varying this value (
                        Fig. 11(a)). Also the relationship between this factor and watermark robustness is evaluated using the Bit Error Rate (BER) of the extracted watermark bit sequence respect to the embedded one without any attacks (Fig. 11(b)). In both cases, Q value is increased by 2–20. From both figures, we determined that the most adequate value of Q is equal to 16, because using this value the PSNR and SSIM of the watermarked video sequence respect to the original one is approximately 47dB and 0.99, respectively, also the BER is approximately 0.0005. It is worth noting that the SSIM provides a perceptual distortion in range of [0.0, 1.0], when both images are numerically same, this value is equal to 1.

We evaluate the watermark imperceptibility of the proposed scheme using PSNR and SSIM which are calculated using the luminance space of watermarked frame and the original one. To evaluate the effect of adaptive watermark embedding energy based on the HVS, the imperceptibility is calculated under two conditions: (a) watermark is embedded without consider HVS criteria, i.e. only constant Q value is applied to embed watermark into 2D-DCT blocks of whole frame and (b) watermark is embedded considering four HVS criteria described in Section 3. 
                        Table 1 shows the mean and variance values for dynamic quantization step size S
                        
                           n,k
                        , the PSNR and SSIM metrics calculated using the 150 frames of all video sequences under the above mentioned conditions. From Table 1, we can observe that the mean value of dynamic quantization step size 
                           
                              
                                 S
                              
                              
                                 n
                                 ,
                                 k
                              
                           
                         with the four HVS criteria is much larger than that value without the HVS criteria, which means that the watermark robustness is increased considerably when the HVS criteria are used. However, the watermark imperceptibility is not sacrificed, which can be observed specially from the SSIM values of both situations, i.e. with/without HVS. The higher variance values of 
                           
                              
                                 S
                              
                              
                                 n
                                 ,
                                 k
                              
                           
                        , PSNR and SSIM with the HVS criteria than these without the HVS criteria is the result of the adaptive assignation of 
                           
                              
                                 S
                              
                              
                                 n
                                 ,
                                 k
                              
                           
                         depending on characteristics of each video frame. An example of the visual quality distortion as a result of applying four HVS criteria is shown in 
                        Fig. 12.

From Fig. 12, we can observe that four HVS criteria provide an adequate watermark energy to obtain a watermarking scheme robust against aggressive operations without generating a visually quality distortion. According to (10) a higher distortion by watermarking process is caused to blocks belong to RONI, which means that quality distortion is not constant in a frame. To measure partial visual quality distortion, we introduce a SSIM map, in which each frame is divided into 32×32 non-overlapping blocks and then SSIM is computed using the watermarked and original frames. 
                        Fig. 13(a) shows the first frame of container video sequence, the blocks belong to the ROI, which are indicated by black blocks and the rest are RONI regions (Fig. 13(b)) and the SSIM map represented by gray scale values where brighter blocks have higher SSIM values (Fig. 13(c)). We can observe that blocks with higher values of SSIM are inside of observer's attention regions (ROI), which do not belong to the RONI.

The proposed watermarking algorithm was designed to resist legitimate operations, specially transcoding, and malicious attacks. In order to assess the embedded watermark robustness, the watermarked video sequences are attacked using some common signal processing and frame-based attacks. The robustness against video transcoding is evaluated changing all video properties, such as compression standard, bit-rate, spatial/temporal resolution as well as a combination of them. The robustness performance is compared with four recently proposed video watermarking methods [3–6]. These schemes are some of the most robust video watermarking algorithms with similar purpose that the proposed one. In order to do a fair comparison among these video watermarking methods, some criteria are considered: the quality distortion generated by each watermark embedding process is approximately same, which is 47dB in the PSNR; additionally every scheme is evaluated with the same frame format (CIF) and the same 10 video sequences. The watermark robustness in terms of the BER represents an average performance of 10 video sequences.

The watermarked video sequences are subject to signal processing attacks including noise contamination and Gaussian low-pass filtering and volumetric scaling. 
                           Fig. 14(a) and (b) shows the robustness against Gaussian and Impulsive noise contamination, respectively. Lee's scheme [3] shows a better performance than our method against noise contamination attacks, due to the redundant embedding of small amount of watermark bit (23bits) sequence to all frames of the video sequence, while the performances of Chen's [4] and Preda's [5] methods are severely damaged by noise contamination. Ling's method [6] provides a similar performance than the proposed one. In the proposed scheme, the average BER value is 0.197 when the quality degradations by noise contaminations are approximately 23.38dB and 0.522 in terms of the PSNR and SSIM, respectively. Fig. 14(c) shows the robustness against Gaussian low-pass filtering attack, where the proposed scheme obtains the highest performance compared with those of four schemes [3–6]. The results presented in Fig. 14(d) shows the robustness against volumetric scaling attack, where the scaling factors are varied from 0.5 to 1.55. The highest volumetric scaling factor generates visual quality degradation of 20.75dB and 0.611, respectively, in the PSNR and SSIM assessments. In the proposed scheme, an average BER value of 0.194 is obtained with the highest volumetric scaling factor.

To evaluate robustness against the frame rate reduction, the frame rate of the watermarked video sequences is changed from 30 to 10 FPS using a transcoder [24]. Subsequently we extract the watermark sequence in order to analyze the robustness against this operation. 
                           Fig. 15 shows the watermark robustness against the frame rate reduction of the proposed scheme together with the performance of four previously reported schemes [3–6]. The proposed algorithm embeds the same watermark sequence along the frames in each video scene; so the embedded watermark is inherently robust against these attacks obtaining the BER value equals to 0.0005. Lee's method [3] has similar performance that the proposed one; however in this scheme the same watermark signal with same embedding energy is embedded at the same frequency band of all frames of video sequence [3], making it vulnerable against intra-collusion attacks. Ling's method [6] obtains relatively good performance against frame reduction task since the watermark signal is embedded redundantly in every I-frame; the disadvantage of this type of strategy against intra-collusion attacks has been described in Section 2. The methods [4,5] show vulnerability against this operation, since these methods embed the watermark signal along the temporal video information, becoming very sensible against frame rate reduction when the number of reduced frames is beyond their re-synchronization mechanism.

Additionally we evaluate the proposed scheme against frame-based attacks. A video sequence contains a lot of temporal redundancy, so frame-based attacks, such as frame dropping, frame averaging and frame swapping, are efficiently done to remove the watermark sequence, without causing significant quality degradation. In the proposed scheme, the same watermark sequence is embedded, with dynamic step size, into all frames of each scene, which prevents attackers from removing the watermark by frame dropping and frame swapping attacks. If attackers try to remove the watermark they need to remove the whole scene causing a severe damage to the video. On the other hand, if an attacker collects a number of watermarked frames, the watermark sequence can be estimated using statistical averaging if the watermark energy is constant, and then it can be remove from the watermarked video [2]. As mentioned in Section 4, in the proposed scheme, the dynamic step size calculation based on the HVS generates different watermarking energies according to the spatio-temporal features of each frame. This adaptive watermark energy assignment makes hard to perform the frame averaging attack. Moreover, embedding different watermarks in each scene can efficiently avoid possible collusion attacks [25].

In order to evaluate the robustness of the proposed scheme against the change of bit-rate and video compression standard, we use a transcoding [24] to modify these properties of the watermarked video sequence. First, to evaluate only robustness against change of the compression standard, the watermarked video sequences are encoded with bit-rate of 4Mbps in all video compression standards mentioned in Section 2. 
                           Table 2 shows the results of this operation, where we can observe the video container, employed codec, the compression rate, the encoding bit-rate, the PSNR, SSIM and BER values of the extracted watermark sequence respect to the embedded one. From Table 2, we can observe that the proposed algorithm has an excellent performance when the watermarked video sequence is encoded in every compression standards. In all cases, the BER values are sufficiently low, which allows a correct detection of the embedded watermark after conversion of the compression standards listed in Table 2.

Continuously, in order to evaluate the watermark resilience of the proposed method against the change of compression bit-rate, the watermarked video sequences are encoded to lower bit-rates, such as 128Kbps, 256Kbps, 512Kbps, 1Mbps, 2Mbps and 4Mbps, using five compression standards mentioned above. 
                           Table 3 presents the performance of the proposed scheme together with these of four video watermarking schemes [3–6]. It is worth noting that the results for MPEG-2 video conversion are reported until 1Mbps, because MPEG-2 is not optimized for bit-rates lower than 1Mbps. This table shows a good performance of the proposed method when the watermarked video sequence is encoded with six different bit-rates, obtaining small values of the BER, which guarantees a correct watermark extraction after the compression with lower bit-rates. Ling's method [6] is not robust to the compression with bit-rates lower than 512Kbps for all compression standards. The principal reason of this low performance is the instability of the relevant points detected by Harris-Affine detector from the quality degraded video caused by compression with lower bit rates. The BER values obtained for Chen's[4] and Preda's [5] methods with low bit rates equal to 256Kbps and 128Kbps for all compression standards suggest watermark vulnerability of these schemes. Lee's method [3] shows a good performance with bit rates higher than 512Kbps, however the performance decreases with 128Kbps for all compression standards and with 256Kbps for VC-1 and VP6 compression standards.

The robustness of the proposed and four video watermarking schemes [3–6] against the change of spatial resolution is evaluated by converting from CIF (352×288 pixels) to several other standard video formats with different spatial resolutions, such as SQCIF (128×96 pixels), QCIF (176×144 pixels), 4CIF (704×576 pixels) and 16CIF (1408×1152 pixels) video formats. The evaluation results are shown in 
                           Fig. 16, which shows a good performance of the proposed scheme obtaining the BER values lower than 0.2 for change to all spatial resolution formats. The robustness performance of Lee, Chen and Preda's methods [3–5] is affected when the original frame is changed to SQCIF and QCIF, i.e. with a scaling factor less than 1, in which some spatial information is lost and the embedded watermark information cannot be extracted correctly. Lee et al. reported in [3] a good performance in the spatial resolution changes from HDTV to QVGA, however the resolution changes to 4CIF and 16CIF formats, which are smaller than QVGA, cause performance degradation. Ling's method [6] is affected by both downscaling and up-scaling; because the Harris-Affine detector is affected by scaling.

In practice, video transcoding is processed as a combination of changes of compression standard, bit-rate, spatial and temporal resolution. To measure the robustness of the proposed method in practical situations, we simulated homogeneous and heterogeneous video transcoding by combining changes of compression standard, frame rate, spatial resolution and bit-rate. 
                           Table 4 shows the watermark robustness of the proposed and four video watermarking methods [3–6] in the homogeneous transcoding case, in which a frame rate reduction and spatial resolution changes occur simultaneously, from the watermarked CIF video with the 30 FPS. The compression standard for all video sequences is unchanged, which is MPEG-4. The spatial resolutions listed in Table 4 are commonly used in PC monitor and some cellular phone touch screens. From this table we can see that the performance of the proposed method is slightly better than that of Lee's and Ling's methods [3,6], in which we observe that in the proposed scheme, the BER is not affected by frame rate reduction and only the spatial resolution changes degrades slightly the robustness performance. The combination of frame rate reduction and spatial resolution causes severe damage over Chen's and Preda's methods [4,5], because loss of temporal synchronization causes problem of the watermark extraction in their methods.

Another common operation in practice is to change the bit rate, spatial resolution and frame rate parameters as a result of conversion between common profiles of compression standards, which is typical case of heterogeneous transcoding. An example of this task is a video encoded over MPEG-1 to be converted to MPEG-2 (Main profile) and MPEG-4 SP (Simple profile). Unlike MPEG-2, MPEG-4 SP does not support frames type B or interlaced video frames, additionally MPEG-4 SP works with lower spatial resolution and lower frame rate than MPEG-2. To simulate this heterogeneous transcoding case, first a watermarked video sequence is encoded by MPEG-1 compression standard with 15Mbps, 30 FPS and CIF (352×288) format. Next this watermarked video is transcoded generating two video sequences; the first one with MPEG-2 main profile, i.e. a spatial resolution of 480×270 pixels, a bit rate of 15Mbps and 30 FPS; and the second one with MPEG-4 SP, i.e. a spatial resolution of 176×144 pixels, a bit rate of 8Mbps and 15 FPS. The watermark sequences are extracted from these two watermarked videos and their respective results are shown in 
                           Table 5. From this table we can conclude that the proposed video watermarking scheme could detect successfully the embedded copyright information after an aggressive heterogeneous transcoding, showing better performance compared with four video watermarking schemes [3–6]. It is worth noting that the target video properties after heterogeneous transcoding, such as spatial resolutions, the frame rates and bit-rates are common in the practical situation, although the watermark sequence in the proposed scheme will be survived against more aggressive cases as shown in Sections 5.3.2–5.3.4.

It is important to consider the possibility of applying the proposed watermarking scheme under the real-time requirement. In the proposed scheme, the watermarking is performed in the raw video data without considering any special compression standard to obtain the watermark robustness against transcoding. However, generally base-band watermarking schemes have disadvantage compared with compressed domain watermarking schemes when real-time operation is desired, because time consuming 2D-DCT and inverse 2D-DCT computation are required in base-band watermarking scheme.

In the proposed video watermarking scheme, the watermark embedding and extraction are performed in blocks of 8×8 2D-DCT coefficients, and the computation of the dynamic step size of the QIM algorithm, except visual attention region estimation, is also performed directly in the blocks of 8×8 2D-DCT coefficients. Therefore, if visual attention regions are estimated directly in the 2D-DCT domain using fast inter-transformation between 2D-DCT block and its sub-block [26], the proposed video watermarking scheme can be operated in the compressed domain, avoiding 2D-DCT and inverse 2D-DCT operations. The idea of use of the fast inter-transformation of 2D-DCT blocks is the same with the compressed domain video watermarking schemes proposed in [3,6]. The computing times required in watermark embedding and extraction process, realizing the above mentioned strategy, are approximately 4.47 and 4.39s, respectively. These computing times are obtained by Matlab ver. R2010a in Intel Core-i5 2.5GHz.

@&#CONCLUSIONS@&#

In this paper, we proposed a video watermarking technique robust against several signal processing distortions, frame-based attacks and especially video transcoding. To improve robustness and accuracy in the detection, and at the same time obtain a good quality of video sequences, the watermark sequence was embedded and detected using a quantization index modulation (QIM) algorithm with adaptive step size, which is calculated using four HVS-based criteria, such as texture and luminance masking, a motion threshold and visual attention region. The experimental results show fairly good watermark imperceptibility since the obtained PSNR values are near to 47dB and the SSIM is close up to 1, taking in account that the SSIM index is a good indicator of the perceptual quality degradation. The experimental results show the watermark robustness to the five most common video compression standards encoding, such as MPEG-2, MPEG-4, H.264 AVC, VP6 and VC-1 with different bit rates, also the embedded watermark is robust to signal processing, intentional video frame-based attacks and changing spatial resolution. The watermark robustness is evaluated in two practical situations, which are homogeneous and heterogeneous transcoding cases. In both cases, the BERs of the proposed scheme are smaller than 0.1, which provides a reliable copyright protection over the digital video contents in the practical situations. The robustness performance of the proposed scheme is compared with four recently reported robust video watermarking schemes [3–6] under the same conditions. The comparison results show the better performance of the proposed scheme especially in heterogeneous transcoding, which is applied commonly in our daily life.

@&#ACKNOWLEDGMENTS@&#

The authors thank the National Council of Science and Technology (CONACYT) of Mexico, the National Polytechnic Institute and the National Autonomous University of Mexico (UNAM) for financial support of this work.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Automated estimation of choroidal thickness distribution and volume based on OCT images of posterior visual section

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Choroid is statistically separated from sclera using structural similarity index.


                        
                        
                           
                           Smoothness in choroid delineation is achieved using tensor voting.


                        
                        
                           
                           Automated choroidal volume estimation is attempted for the first time.


                        
                        
                           
                           Choroidal thickness and volume estimates are given vis-à-vis observer repeatability.


                        
                        
                           
                           Quotients are defined to fairly compare among methods tested on disparate datasets.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optical coherence tomography (OCT)

Choroidal thickness

Choroidal volume

Structural similarity (SSIM) index

Tensor voting

@&#ABSTRACT@&#


               
               
                  A variety of vision ailments are indicated by anomalies in the choroid layer of the posterior visual section. Consequently, choroidal thickness and volume measurements, usually performed by experts based on optical coherence tomography (OCT) images, have assumed diagnostic significance. Now, to save precious expert time, it has become imperative to develop automated methods. To this end, one requires choroid outer boundary (COB) detection as a crucial step, where difficulty arises as the COB divides the choroidal granularity and the scleral uniformity only notionally, without marked brightness variation. In this backdrop, we measure the structural dissimilarity between choroid and sclera by structural similarity (SSIM) index, and hence estimate the COB by thresholding. Subsequently, smooth COB estimates, mimicking manual delineation, are obtained using tensor voting. On five datasets, each consisting of 97 adult OCT B-scans, automated and manual segmentation results agree visually. We also demonstrate close statistical match (greater than 99.6% correlation) between choroidal thickness distributions obtained algorithmically and manually. Further, quantitative superiority of our method is established over existing results by respective factors of 27.67% and 76.04% in two quotient measures defined relative to observer repeatability. Finally, automated choroidal volume estimation, being attempted for the first time, also yields results in close agreement with that of manual methods.
               
            

@&#INTRODUCTION@&#

Recent advances in medical imaging allow physicians to visualize, understand and diagnose complex medical conditions. For instance, Optical Coherence Tomography (OCT) [1] enables ophthalmologists to image as well as assess pathological changes in blood vessels present in the inner walls of the posterior visual section [2]. Specifically, the choroid layer has complex vasculature, lies sandwiched between the retinal pigment epithelium (RPE) and the sclera, performs critical physiological functions [3–7], and assumes crucial role in determining various disease conditions [8–12]. The advent of OCT has lead to improved visualization of the choroid, and hence improved diagnosis [13]. Among various OCT technologies, the spectral domain OCT (SD-OCT) is perhaps the most ubiquitous [14]. Typical SD-OCT images are shown in Fig. 1
                     . The left portion of each image, called en-face, depicts the infrared face-on view of retina, the innermost layer, while the dashed line on it indicates the vertical location of the OCT plane. The right part depicts an OCT scan, consisting of retina (layered), including RPE (bright), choroid (granular), and sclera (smooth), from top to bottom (from inner to outer layer, physiologically), as labeled in the last image [15]. Usually, OCT is performed at various (e.g., 97) vertical locations, and the ophthalmologist browses through OCT images, paying attention to the choroid region to assess its condition.

In particular, thickness distribution of the choroid estimated from OCT images of the posterior part of the eye has emerged as an important metric in disease management [16]. Consequently, estimation accuracy has assumed a vital role in ensuring accurate diagnostic outcome [19]. Choroidal thickness measurements have in turn been used to obtain choroidal volume. So far, such thickness measurements have been performed by experts by manually delineating the choroid inner and outer boundaries and then taking the difference. On the average, an expert labels about one hundred OCT scans per subject, making this procedure time consuming, laborious as well as susceptible to fatigue-induced error. Further, since the number of available experts is often few compared to the number of subjects (especially, in developing regions), only a fraction of potential subjects actually receive OCT-based diagnosis. Against this backdrop, automated segmentation of choroid layer could be crucial in reducing professional effort and time per subject, potentially allowing more subjects to obtain specialized medical attention. Automation would also avoid human error induced by fatigue and tedium. Accordingly, we propose a novel automated algorithm for choroid segmentation and related thickness and volume measurements.

Since the last three years, automation of choroid segmentation have been attracting considerable attention. Owing to eye physiology, choroid segmentation consists of two tasks: detecting (i) choroid inner boundary (CIB) and (ii) choroid outer boundary (COB). Of these, the first task is relatively well posed because the RPE, defining the CIB, is significantly brighter than adjacent layers. Indeed, the gradient-based approach in various flavors has proven accurate not only in detecting CIB [24–30], but also in the related problem of detecting boundaries between successive retinal layers with well-defined brightness transition [35–38]. Accordingly, we shall also adopt a gradient-based approach for CIB detection. In contrast, the task of detecting the COB poses considerable challenge. This happens because the COB is essentially a notional divide between the choroidal granularity and the scleral uniformity, which is not defined by marked variation in brightness, and often open to subjective interpretation. Even so, gradient-based deterministic methods have been suggested for COB detection [25–27]. However, statistical methods appear more suitable to handle the inherent uncertainties involved. Accordingly, machine learning [28,29] as well as gradient-based probabilistic methods [30] have been attempted. Yet, earlier work does not directly exploit the structural transition from granularity to uniformity across the COB. Against this backdrop, we propose to quantify the structural dissimilarity between choroid and sclera using the yardstick of structural similarity (SSIM) index, and hence, by choosing appropriate thresholds, find an initial estimate of the COB. Unfortunately, an SSIM-based method on its own sometimes leaves discontinuities in the initial estimate. We attempt to remove such discontinuities using an adaptive Hessian analysis step, which has elsewhere proven effective in localizing choroid vessels [24]. The resulting boundary, although adequately separates the choroidal vessels from scleral uniformity, generally is not smooth and deviates substantially from smooth boundaries manually drawn by experts [32]. With a view to obtaining close match with the latter, we finally make use of tensor voting to achieve the desired smoothing.

Despite our systematic approach, it remains problematic to clearly establish the advantages of our method over earlier work. First, experimental datasets used by various researchers differ in terms of mean wavelengths used in SD-OCT acquisition. Further, some scans are obtained from healthy subjects, some from diseased subjects [25,27,28], some from adult, and some from pediatric subjects [30]. Moreover, some scans are taken only near the foveal cross section [26,27], rather than at various vertical locations over a wide range. In addition, a variety of evaluation criteria, including correlation coefficient (CC) [25], Dice coefficient (DC) [26,27,30], mean border position difference (MBPD) [25,29], and mean absolute difference (MAD) [30], have been used. Also, the image quality and subjective complexity appear to vary among various datasets rendering performance comparison among various algorithms. For fair comparison, ideally, there should be standard datasets, fairly representing possible OCT images in an unbiased manner and standardized performance measures. Indeed, desired standardization has been achieved in certain fields, such as stereo vision [33] and electrocardiogram (ECG) signal analysis [34]. However, such standardization requires enormous resources. Till its realization in the study of choroid segmentation, to improve contextual comprehension, we compare results generated by the proposed automated algorithm against observer repeatability figures on the same datasets as those figures implicitly reflect image quality. Various aspects of the reported literature as well as our work are presented in Table 1
                     .

Our algorithm is evaluated on five sets of 97 SD-OCT B-scans each taken one of five healthy adult subjects, and algorithmic results are compared with that obtained manually. We take the average of the two manual segmentations performed by the same expert as the reference following current clinical practices [17,18], and perform both qualitative and quantitative performance assessment. First we visually compare the automated choroid segmentation vis-à-vis the manual reference. Subsequently, we turn to quantitative assessment of the proposed automated algorithm in terms of estimation accuracy of the choroidal thickness distribution and volume. Specifically, we quantify thickness estimation accuracy in terms of four measures namely, difference (D), absolute difference (AD), correlation coefficient (CC), and Dice coefficient (DC), using thorough statistical analysis. We also propose certain quotient measures to fairly compare performance of our algorithm against that of previously reported ones, even when the latter used completely different datasets. However, from a clinical perspective, even accurate estimate of choroidal thickness on its own could sometimes be inadequate in assessing choroidal involvement in chorioretinal diseases. To see this, suppose specific scans are taken at selected foveal locations. Then the thickness measure would clearly be inadequate in representing the overall choroidal distribution. In contrast, volumetric analysis of the choroid would be better suited to assess the disease course and response to treatment [19]. Against this backdrop, we automate choroidal volume measurement for the first time in the literature (to the best of our knowledge). In particular, we obtain volume measurements for the five aforementioned datasets, and compare our results against corresponding manual references. Finally, as earlier, we propose and make use of quotient measures for volume estimation. Using the aforementioned systematic statistical analysis, we demonstrate the algorithmic results to be in general agreement with its manual counterpart.

In summary, our main contributions are as follows:
                        
                           1
                           End-to-end robust automation is demonstrated for choroid segmentation.
                                 
                                    (a)
                                    Structural dissimilarity between choroid and sclera is directly measured by SSIM index and exploited towards automated COB estimation.

Desired smoothness in the COB estimate is achieved using tensor voting.

Automated thickness estimates are reported vis-à-vis respective observer repeatability to facilitate contextual comprehension.

Automated choroidal volume estimation is attempted, and statistical performance analysis is carried out.

Quotient measures are proposed and adopted to facilitate comparison among algorithms tested on different datasets.

Now we set out to automatically detect choroid inner boundary (CIB) and choroid outer boundary (COB), which are manually drawn by an expert in Fig. 2
                     . We begin by describing our experimental datasets and the proposed methodology.

We consider OCT scans performed by a single retina specialist, using Heidelberg Retina Angiograph (HRA – Spectralis, Heidelberg Engineering, Dossenheim, Germany). The Spectralis OCT device provides up to 40,000Ascans/s with a depth resolution of 7μm in tissue and a transverse resolution of 14μm using a superluminescence diode with a mean wavelength of 870nm. Raster imaging consisting of 97 high-resolution B scans was performed with each eye, centered on the fovea. An internal fixation light was used to center the scanning area on the fovea. Each scan was 9.0mm in length and spaced 30μm apart from each other. Single OCT images consisting of 512A lines were acquired in 0.78ms. The scans were obtained for analysis after 25 frames, and averaged using built-in automatic averaging software (TruTrack; Heidelberg Engineering, Heidelberg, Germany) to obtain a high quality choroidal image. In this work, experimental evaluation is performed on B-scans taken from five healthy adult subjects, from whom one eye randomly chosen per subject and 97 B-scans are taken per eye. The third dataset has image resolution 496×1536 (covering larger area), while each of the rest has 351×770. Manual segmentation is performed twice by same expert on each scan to study the observer repeatability. The average of two such manual segmentations is taken as the reference following current clinical practices [17,18].

As depicted in Fig. 3
                        , the proposed automated methodology consists of various steps: (i) denoising, (ii) localization of choroid and (iii) choroid outer boundary (COB) detection.

Generally, OCT images are noisy (Fig. 4
                           a), and appropriate denoising improves algorithmic accuracy. Accordingly, for denoising, we adopted the block-matching and 3D filtering (BM3D) algorithm, which is generally accepted as the state of the art [39]. Indeed, BM3D algorithm has been used for denoising OCT images in a similar context [40]. This algorithm is based on an enhanced sparse representation in transform-domain, where enhancement of the sparsity is achieved by grouping similar 2D image blocks into 3D data arrays called “groups”, followed by performing collaborative filtering on them. As groups exhibit high correlation, a decorrelating transform attenuates noise. Finally, denoised images are obtained by applying the inverse transform (Fig. 4b). We use BM3D toolbox in MATLAB, and use the default noise standard deviation of 25.

Next we locate the RPE layer, and more specifically its inner boundary. This further helps us locate the RPE outer boundary, which defines the CIB, and specify a region of interest (ROI) between CIB and sclera which is expected to contains the COB.

Noting the higher brightness of the RPE compared to that of the adjacent layers, we obtain an initial edge map using the gradient-based Canny edge operator [41], where empirically determined threshold of 0.4 and a standard deviation of 2 for the Gaussian filter have been used. However, also notice in Fig. 4a that sharp change in brightness occurs not only at the RPE inner boundary, but at the retinal inner boundary as well. Accordingly, the edge operator principally detects both the above boundaries alongside some secondary edges (Fig. 4c). We take the outer one of the principal edges as the RPE inner boundary and remove its discontinuities using the dilation operator (Fig. 4d) [41].

Now the various retinal layers inside RPE inner boundary are peeled off (Fig. 4e). The RPE outer boundary, which also defines the CIB, occurs at a more or less uniform distance from the RPE inner boundary, and is then detected based on gradient-based bright-to-dim transition. In particular, CIB possesses a high negative gradient. Accordingly, to detect the CIB, the vertical gradient in Fig. 4e is computed using the Sobel operator [41]. Then the CIB in any column corresponds to that pixel below the RPE inner boundary, where we first encounter a negative gradient. Subsequently, the RPE layer is also peeled off (Fig. 4f). At this point, we are left with detecting the COB. To this end, we select a region of interest (ROI) of sufficient thickness outside the CIB such that the ROI would contain the COB (Fig. 4g).

We now turn to COB detection using steps outlined in the flowchart of Fig. 3.

Observe in Fig. 4a that the sclera (uniform) and the choroid (granular) have dissimilar statistical structure. We exploit such dissimilarity by taking a small window from sclera as a template, and calculate the structural similarity (SSIM) index between the template and the neighborhood (of the same size as the template) of every pixel throughout the ROI. Here SSIM between two windows A and B of equal dimensions (we take 5×5) is given by [20]
                              
                                 
                                    (1)
                                    
                                       SSIM
                                       (
                                       A
                                       ,
                                       B
                                       )
                                       =
                                       
                                          
                                             (
                                             2
                                             
                                                μ
                                                A
                                             
                                             
                                                μ
                                                B
                                             
                                             +
                                             
                                                c
                                                1
                                             
                                             )
                                             (
                                             2
                                             
                                                σ
                                                AB
                                             
                                             +
                                             
                                                c
                                                2
                                             
                                             )
                                          
                                          
                                             (
                                             2
                                             
                                                μ
                                                A
                                                2
                                             
                                             
                                                μ
                                                B
                                                2
                                             
                                             +
                                             
                                                c
                                                1
                                             
                                             )
                                             (
                                             
                                                σ
                                                A
                                                2
                                             
                                             +
                                             
                                                σ
                                                B
                                                2
                                             
                                             +
                                             
                                                c
                                                2
                                             
                                             )
                                          
                                       
                                       ,
                                    
                                 
                              where μ
                              
                                 A
                               and μ
                              
                                 B
                               denote the respective means, and 
                                 
                                    σ
                                    A
                                    2
                                 
                               and 
                                 
                                    σ
                                    B
                                    2
                                 
                               the respective variances of windows A and B, whereas σ
                              
                                 AB
                               denotes their covariance. Further, c
                              1 (=6.5) and c
                              2 (=58.5) are small constants, chosen to stabilize the expression. As the template is chosen from the sclera, we expect scleral pixels to have higher and choroidal pixels to have lower SSIM indices. Indeed the lowest SSIM values are observed in the transition region between sclera and the choroid, i.e., near the COB. More accurately, pixels with SSIM index below a suitable threshold (=0.15, empirically determined) are mostly concentrated in clusters on the choroid side of the COB, and generally isolated on the scleral side (Fig. 4h). Such scleral pixels are removed using the connected components algorithm (Fig. 4i) [41]. Finally, the lower boundary of the remaining sub-threshold pixels is taken as an initial estimate of the COB (Fig. 4j), which however is generally discontinuous.

To remove such discontinuities, we adopt an adaptive Hessian analysis method [21,22]. In particular, we first find whether a pixel belongs to a blood vessel (present only in the choroid). To this end, we estimate the Hessian matrix H at every pixel based on its neighborhood, compute the eigenvalues λ
                              1 and λ
                              2 of H, and verify whether λ
                              1 is small and λ
                              2 is large, which has been shown to correspond to dark tubular structures such as choroidal blood vessels [42]. Accordingly, to improve accuracy, we pick threshold on λ
                              2 in an adaptive manner. In particular, we divide the ROI into small windows (15 pixels wise), and compute the average intensity of each window. Further, each such average intensity is scaled between the range [0,10], and mapped to predefined thresholds for λ
                              2, varying from 40 to 105 in steps of 5. In this premise, the threshold for λ
                              2 is adaptively chosen based on the average intensity of the each window. Further, threshold for λ
                              1 is set to an empirically determined −5. In this setting, the outer boundary of newly detected choroid vessels are added to the initial COB estimate, thereby removing undesirable discontinuities (Fig. 4k).

The refined COB estimate appears to divide the choroidal granularity and the scleral uniformity adequately, albeit in jagged manner. In contrast, manual delineation of the COB by an expert is generally smooth (Fig. 4l). To achieve similar smoothness in our automated COB estimate, we make use of tensor voting [23,43]. Directly applying tensor voting on the refined COB estimate may lead to omission of some choroid vessels, because final boundary may pass through the choroid layer cutting some of the blood vessels. Therefore, post preprocessing is performed on the refined COB estimate, which involves discarding boundary pixels that are close to local minima. This is done by dividing each scan into three windows along the length and fixing a local threshold based on mean thickness value of the corresponding window. Further, threshold is chosen slightly greater than the local mean.

First, we describe in brief the tensor voting technique, which propagates information using tokens, conveying various objects’ orientation preferences (i.e., votes) to their neighbors. When such votes are tallied, objects belonging to the same structure tend to join together. The influence of a vote decays away from the object, and the saliency decay function (DF) is generally taken as Gaussian:
                                 
                                    (2)
                                    
                                       DF
                                       (
                                       s
                                       ,
                                       k
                                       ,
                                       σ
                                       )
                                       =
                                       
                                          e
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            s
                                                            2
                                                         
                                                         +
                                                         
                                                            ck
                                                            2
                                                         
                                                      
                                                      
                                                         
                                                            σ
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              where s denotes arc length, and k curvature, while c controls the degree of decay with curvature, and σ the scale of voting, which in turn determines the effective neighborhood size [43]. In particular, for a given σ, we choose 
                                 s
                                 =
                                 
                                    
                                       θ
                                       l
                                    
                                    
                                       sin
                                       (
                                       θ
                                       )
                                    
                                 
                              , 
                                 k
                                 =
                                 
                                    
                                       2
                                       sin
                                       (
                                       θ
                                       )
                                    
                                    l
                                 
                              , and 
                                 c
                                 =
                                 
                                    
                                       −
                                       16
                                       log
                                       (
                                       0.1
                                       )
                                       ×
                                       (
                                       σ
                                       −
                                       1
                                       )
                                    
                                    
                                       
                                          π
                                          2
                                       
                                    
                                 
                              , where l indicates the distance between the two tokens, namely, voter and receiver, while θ indicates the angle between the tangent of the osculating circle at the voter and the line going through the voter and receiver [43]. Now, in order to achieve the desired smoothing of the post-processed COB, we shall apply tensor voting in two stages. First, a relatively large σ (=140) is applied with a view to finding a mean interpolated COB. Finally, a smaller σ (=40) is used to smoothen small left-over transients. This results in our final estimation of the COB (Fig. 4m). Subsequently, we segment the choroid between the estimated CIB and the estimated COB (Fig. 4n), and hence obtain the thickness distribution (Fig. 4o).

Following the aforementioned steps, we obtain the CIB and the COB estimates in each OCT B-scan of our five datasets. In Fig. 5
                     , we depict results for three representative B-scans per dataset. For visual comparison, manual COB delineations performed by experts are also depicted alongside. Next we present a quantitative assessment of the proposed automated algorithm in terms of estimation accuracy of the resulting choroidal thickness distribution and volume.

First we estimate choroidal thickness distribution, and quantify estimation accuracy.

Choroidal thickness distribution obtained using the proposed method is presented for each dataset in Fig. 6
                           c, while the corresponding distribution obtained using the manual reference, taken as the average of the two manual segmentations following current clinical practices [17,18], is presented in Fig. 6b. For positional reference, corresponding en-face images are depicted in Fig. 6a. Further, the estimation error, measured by the difference (D) between the automated and the manual reference thickness estimates, is presented in Fig. 6d, while the corresponding absolute error/difference (AD) is presented in Fig. 6e. The absolute error appears to be tolerable, while a tendency to underestimate thickness is noticed. Ideally, one desires automated algorithms to perform as well as the manual approach. We now present a thorough statistical analysis to quantitatively establish closeness to such ideal goal as well as comparative advantage over reported algorithms.

For a collection 
                              
                                 
                                    {
                                    
                                       
                                          z
                                          k
                                       
                                    
                                    }
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 N
                              
                            of samples of quantity z, its mean Mz, standard deviation (SD) SDz, and coefficient of variation (CV) CVz are defined by
                              
                                 (3)
                                 
                                    M
                                    z
                                    =
                                    
                                       1
                                       N
                                    
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       N
                                    
                                    
                                       z
                                       k
                                    
                                    ,
                                    
                                    SD
                                    z
                                    =
                                    
                                       
                                          
                                             1
                                             N
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             
                                                (
                                                
                                                   z
                                                   k
                                                
                                                −
                                                M
                                                z
                                                )
                                             
                                             2
                                          
                                       
                                    
                                    ,
                                    
                                    CV
                                    z
                                    =
                                    
                                       
                                          SD
                                          z
                                       
                                       
                                          M
                                          z
                                       
                                    
                                    ,
                                 
                              
                           which respectively measure the central tendency, the dispersion, and the standardized dispersion. In particular, we shall quantify the estimation accuracy of choroidal thickness distribution in terms of four quantities – namely, difference (D), absolute difference (AD), correlation coefficient (CC) and Dice coefficient (DC). Accordingly, we define specific measures, such as MAD, MCC, SDDC, CVCC, CVDC (replacing z by the suitable specific quantity). Here note that the standardized dispersion measure CVz is meaningful only if z is nonnegative. Accordingly, since difference (D) is signed, CVD is not meaningful and not reported. Further, statistical measures are computed for results obtained not only by the proposed algorithm (superscripted ‘auto’) but by manual methods (superscripted ‘ref’) as well. We take as reference the average of the two manual segmentations in such computations. To ensure fair comparison, our results are reported vis-à-vis observer repeatability, i.e., the consistency of performing manual segmentations multiple times by same observer.

Suppose x
                              
                                 i
                               and y
                              
                                 i
                               denote the thickness values at the ith (i
                              =1, …, N) column (A-scan index) in two measurements. Then the difference (D) and the absolute difference (AD) between those measurements at the ith column are respectively given by
                                 
                                    (4)
                                    
                                       
                                          D
                                          i
                                       
                                       =
                                       (
                                       
                                          x
                                          i
                                       
                                       −
                                       
                                          y
                                          i
                                       
                                       )
                                       ,
                                       
                                       
                                          AD
                                          i
                                       
                                       =
                                       |
                                       
                                          x
                                          i
                                       
                                       −
                                       
                                          y
                                          i
                                       
                                       |
                                       .
                                    
                                 
                              For each scan, corresponding mean difference (MD) and mean absolute difference (MAD) are obtained based on (3). For the 485 B-scans from the five datasets, the proposed algorithm achieves MD between −52.98μm and 13.75μm with an average of −15.31μm and standard deviation (SDD) of 17.97μm, while the MD between the two manual segmentations varies between −38.71μm and 20.18μm with an average of −4.51μm and SDD of 13.25μm. Table 2
                               provides further dataset-wise details. Difference plots for the three datasets are furnished in Fig. 6. Inspecting those values, there appears to be a slight negative bias in the proposed method vis-à-vis the reference manual method, indicating room for further improvement. However, the standard deviations appear to be desirably close.

Next we ignore the sign of the error and turn to the absolute difference (AD) measure. The MAD between the estimated thickness and the reference thickness for the five datasets are plotted in the first column of Fig. 7
                              . To facilitate comparison, MAD between two manual segmentations, measuring observer repeatability, are also presented. The proposed automated algorithm achieves MAD between 4.71μm and 52.98μm with an average of 19.15μm and standard deviation (SDAD) of 15.98μm, while the MAD between manual segmentations varies between 3.99μm and 38.71μm with an average of 11.97μm and SDAD of 10.34μm. Notice that although algorithmic results are generally worse compared to (i.e., above) the manual results, the former outperform the latter in certain scans. This (encouragingly) indicates that our algorithm can outperform an expert, albeit in rare occasions.

For two measurements x
                              
                                 i
                               and y
                              
                                 i
                              , i
                              =1, …, N, seen earlier, the correlation coefficient (CC) is defined by [44]
                              
                                 
                                    (5)
                                    
                                       CC
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                
                                                   x
                                                   i
                                                
                                                
                                                   y
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      x
                                                      i
                                                      2
                                                   
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      y
                                                      i
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                       .
                                    
                                 
                              The scan wise CC between the estimated choroid thickness and the reference thickness for the five datasets are now plotted in the second column of Fig. 7. In the same figure, the corresponding CC between the thickness values obtained by two manual segmentations, measuring observer repeatability, are also plotted for comparison. The proposed automated algorithm achieves CC between 97.90% and 99.98% with an average (MCC) of 99.64% and standard deviation (SDCC) of 0.27%, across three datasets, while the CC between manual segmentations varies between 98.18% and 99.98% with an MCC of 99.82% and SDCC of 0.14%, thus demonstrating the general reliability of our method. Even for CC, our algorithm outperforms manual methods for certain scans as indicated in the plots.

Denote the respective sets of pixel indices in the ith (i
                              =1, …, N) column of two segmentations by 
                                 
                                    C
                                    i
                                    x
                                 
                               (
                                 |
                                 
                                    C
                                    i
                                    x
                                 
                                 |
                                 =
                                 
                                    x
                                    i
                                 
                              ) and 
                                 
                                    C
                                    i
                                    y
                                 
                               (
                                 |
                                 
                                    C
                                    i
                                    y
                                 
                                 |
                                 =
                                 
                                    y
                                    i
                                 
                              ). Then the Dice coefficient (DC) is defined by [26]
                              
                                 
                                    (6)
                                    
                                       DC
                                       =
                                       
                                          
                                             2
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             |
                                             
                                                C
                                                i
                                                x
                                             
                                             ∩
                                             
                                                C
                                                i
                                                y
                                             
                                             |
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             |
                                             
                                                C
                                                i
                                                x
                                             
                                             |
                                             +
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             |
                                             
                                                C
                                                i
                                                y
                                             
                                             |
                                          
                                       
                                       .
                                    
                                 
                              Now scanwise DC between the estimated choroid thickness and the reference thickness, for each dataset, are plotted in the third column of Fig. 7, alongside DC between two manual segmentations as a measure of observer repeatability. The proposed algorithm achieves DC between 88.81% and 99.05% with an average (MDC) of 95.47% and SDDC of 1.73%, while DC between two manual segmentations varies between 89.44% and 99.23% with an average (MDC) of 97.28% and SDDC of 1.06%. Again, even for DC, our algorithm occasionally outperforms manual methods.

Next we turn to comparing performance of our algorithm against that of reported algorithms. As alluded earlier, performance comparison among various algorithms is potentially problematic because those are generally tested on disparate datasets. To highlight the issues, consider comparing the algorithm proposed by us against that reported by Alonso-Caneiro et al. [30]. Specifically, we have rival mean difference (MD) values of −15.31μm versus 2.35μm, and rival standard deviation on difference (SDD) 17.97μm versus 15.48μm (see Table 2). If one considers the above numerical figures alone, one would infer the superiority of the latter algorithm. However, such simplistic comparison inherently ignores the fact that the respective datasets on which the competing algorithms are applied do not necessarily pose similar level of difficulty in choroidal delineation. Indeed, when presented to the human expert, those datasets exhibit respective standard deviation (SDD) values of 13.25μm and 6.08μm on observer repeatability, indicating the relatively higher difficulty level posed by the former (our) dataset. In other words, SDD for our algorithm worsens by 35.6% compared to manual methods, while such worsening factor is 155.5% for Alonso-Caneiro et al. Thus, with reference to manual methods, our approach exhibits less relative dispersion.

Now we attempt to make similar comparison based on other performance criteria. In terms of correlation coefficient (CC), proposed method achieves an overall mean CC (MCC) value of 99.64%, which compares well with the corresponding observer repeatability value of 99.82%. Further, our algorithmic MCC value of 99.64% is much higher than the value 93% reported by Hu et al. [25] (refer to Table 1). However, as seen in the previous paragraph, the above comparison is not necessarily fair in the absence of the observer repeatability value for the later method. Turning to Dice coefficient (DC), the results reported by Alonso-Caneiro et al. [30], appears to improve on the earlier methods (refer to Table 1), albeit in an absolute sense, because observer repeatability values are not available. Referring to Table 2, we obtain an overall algorithmic mean DC (MDC) of 95.47%, which compares well with the corresponding observer repeatability of 97.28%. The latter is close to the algorithmic MDC of 96.7% reported by Alonso-Caneiro et al.; however, as their observer repeatability value, expected to be higher, is unavailable, a fair comparison is ruled out.

We now propose quotient measures that incorporate observer repeatability. Such quotient measures should be useful not only for performance comparison with reported algorithms, but also to set benchmarks for future research. Specifically, we define two quotients. The quotient of mean, QMz, is defined by the ratio
                                 
                                    (7)
                                    
                                       QM
                                       z
                                       =
                                       
                                          
                                             |
                                             M
                                             
                                                z
                                                auto
                                             
                                             −
                                             
                                                z
                                                ideal
                                             
                                             |
                                          
                                          
                                             |
                                             M
                                             
                                                z
                                                ref
                                             
                                             −
                                             
                                                z
                                                ideal
                                             
                                             |
                                          
                                       
                                       ,
                                    
                                 
                              where Mz
                              
                                 auto
                               and Mz
                              
                                 ref
                              , respectively, indicate the mean values obtained by the algorithm and the manual method, and z
                              
                                 ideal
                               denotes the ideal value of z. A low QMz value is desirable. Specifically, QMz
                              =1 would make the algorithmic accuracy indistinguishable from the accuracy of manual methods in terms of mean error. Similarly, quotient of CV, QCVz, is defined by
                                 
                                    (8)
                                    
                                       QCV
                                       z
                                       =
                                       
                                          
                                             
                                                
                                                   CV
                                                   z
                                                
                                                auto
                                             
                                          
                                          
                                             CV
                                             
                                                z
                                                ref
                                             
                                          
                                       
                                       ,
                                    
                                 
                              where CVz
                              
                                 auto
                               and CVz
                              
                                 ref
                              , respectively, indicate the CV obtained by the algorithm and that obtained manually. Again, we desire QCVz, measuring relative standard dispersion, to be low, and QCVz
                              =1 would make the algorithm at par with manual methods. In (7) and (8), the general quantity z can specifically be either AD, or CC, or DC, as mentioned earlier.

In this backdrop, we obtain the respective overall QMAD and overall QCVAD values of 1.59 and 0.96. Interestingly, we obtain a QCVAD less than one, indicating that the algorithmic consistency exceeds manual consistency. Such quotient values improve upon the respective quotients of 2.03 and 1.69, reported by Alonso-Caneiro et al. [30] by respective factors of 27.67% and 76.04%. In particular, the proposed method achieves QMAD values within a small range between 1.35 and 1.87 for the five datasets, indicating consistent algorithmic performance across datasets. Such performance consistency is further buttressed by the corresponding consistent QCVAD values ranging from 0.83 and 1.22. In addition, the low overall QMCC and QCVCC (resp. QMDC and QCVDC) values of 2 and 1.92 (resp. 1.66 and 1.66), respectively, further corroborate the effectiveness of the proposed algorithm. Table 2 provides further dataset-wise details.

Finally, we turn to estimating choroidal volume. As mentioned in Section 2.1, each of our datasets consists of 97 B-scans taken at a uniform vertical separation of 30μm. For volume computation, one needs choroidal thickness estimates even at intervening vertical locations. To this end, we perform cubic interpolation, while converting B-scan pixels to the physical unit of length (mm). As earlier, ideally, we would like the automated volume measurement to approximate the reference manual measurement. Accordingly, to quantify the proximity between those volume estimates, we now systematic introduce certain statistical measures.

As alluded earlier, the dataset-3 has larger scan images (in terms of pixels), and pertains to a considerably larger region, compared to the rest four. In dataset-3, the algorithmic volume estimate is 8.4426mm3 compared to the manual estimate of 9.1847mm3. For the rest four, the algorithmic volume estimate ranges between 2.5853mm3 and 3.0473mm3, while the manual estimate range is 2.8755mm3 and 3.1899mm3. Now we turn to more involved performance criteria, beginning with absolute volume difference (AVD). Specifically, the AVD between automated algorithm and manual reference is defined by
                              
                                 (9)
                                 
                                    
                                       AVD
                                       auto
                                    
                                    =
                                    |
                                    
                                       vol
                                       auto
                                    
                                    −
                                    
                                       vol
                                       ref
                                    
                                    |
                                    ,
                                 
                              
                           where vol
                              auto
                            denotes the volume estimated by the proposed method, and vol
                              ref
                            denotes that per the manual reference (average of manual segmentations M1 and M2). Similarly, the AVD between the manual segmentations M1 and M2 is given by
                              
                                 (10)
                                 
                                    
                                       AVD
                                       ref
                                    
                                    =
                                    |
                                    
                                       vol
                                       
                                          M
                                          1
                                       
                                    
                                    −
                                    
                                       vol
                                       
                                          M
                                          2
                                       
                                    
                                    |
                                    ,
                                 
                              
                           which we take as a measure of observer repeatability. As comparing raw AVD values across various eyes could be unfair, we define relative AVD (RAVD) as the ratio of AVD to vol
                              ref
                           :
                              
                                 (11)
                                 
                                    
                                       RAVD
                                       flag
                                    
                                    =
                                    
                                       
                                          
                                             AVD
                                             flag
                                          
                                       
                                       
                                          
                                             vol
                                             ref
                                          
                                       
                                    
                                    ,
                                 
                              
                           where “flag” could stand for either “auto” (automated) or “ref” (manual reference). Further, MAVD
                              flag
                            (resp. MRAVD
                              flag
                           ) indicates the mean of AVD
                              flag
                            (resp. RAVD
                              flag
                           ) values taken across datasets.

For the five datasets, the proposed method achieves an MRAVD
                              auto
                            of 7.12% vis-à-vis observer repeatability MRAVD
                              ref
                            of 2.90%. Table 3
                            provides further dataset-wise details. In particular, for the datasets under consideration, the respective RAVD
                              auto
                            values are 5.01%, 10.09%, 8.08%, 6.34%, and 4.47%. In contrast, the corresponding observer repeatability (RAVD
                              ref
                           ) figures are 0.84%, 2.92%, 4.74%, 1.34%, and 1.06%. Notice that our datasets pose dissimilar challenges to automated and manual methods with regards to volume computation. In particular, dataset-1 is highly amenable to manual approach, but poses significantly more challenge to the automated algorithm. On the other hand, dataset-3 is relatively less amenable to manual approach, but poses only marginally more difficulty to the automated algorithm.

Now, to quantify the closeness of algorithmic performance with observer repeatability in each dataset, we calculate the quotient of absolute volume difference
                              
                                 (12)
                                 
                                    QAVD
                                    =
                                    
                                       
                                          
                                             AVD
                                             auto
                                          
                                       
                                       
                                          
                                             AVD
                                             ref
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             RAVD
                                             auto
                                          
                                       
                                       
                                          
                                             RAVD
                                             ref
                                          
                                       
                                    
                                    ,
                                 
                              
                           for which a low value is desirable. Similarly, the corresponding quotient QMAVD across all three datasets is defined by
                              
                                 (13)
                                 
                                    QMAVD
                                    =
                                    
                                       
                                          
                                             MAVD
                                             auto
                                          
                                       
                                       
                                          
                                             MAVD
                                             ref
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             MRAVD
                                             auto
                                          
                                       
                                       
                                          
                                             MRAVD
                                             ref
                                          
                                       
                                    
                                    .
                                 
                              
                           Over our five datasets, we achieve a QMAVD value of 2.4, i.e., the proposed algorithm incurs just twice the error compared to human expert while computing choroidal volume. However, the dataset-wise QAVD values of 5.9, 3.4, 1.7, 5.6 and 4.2 vary significantly.

The proposed algorithm has been implemented using MATLAB R2013a scientific programming software on a personal computer with Intel® core i7 processor, 16GB system memory, and Windows® 7 Enterprise 64-bit operating system. Further, MATLAB toolboxes have been used for BM3D denoising [45], SSIM index calculation [46] and tensor voting [47]. We recorded an average computational time of approximately 6min and 12min per image for the datasets 1, 2, 4, 5 and the dataset 3, respectively. Tensor voting turns out to be the most compute-intensive step, accounting for about 70% of the computation.

@&#DISCUSSION@&#

In this paper, we proposed a novel technique for automated choroid layer segmentation in OCT images of the posterior visual section. In particular, noting that the choroid and the sclera layers are structurally dissimilar and not associated with sharp intensity variation, we departed from the usual gradient based approach and adopted a technique based on structural similarity (SSIM) index. Further, upon smoothening using tensor voting, we obtained automated choroid segmentation that exhibits close visual agreement with manual segmentation. Based on our segmentation, we then estimated choroidal thickness distribution and volume, and quantified various aspects of estimation accuracy. Our automated choroidal volume estimation is the first such attempt to the best of our knowledge.

We presented exhaustive statistical quantification to (i) establish closeness of the automated estimates to the corresponding manual ones, (ii) demonstrate superior performance of our method over known results, and (iii) facilitate future benchmarking. In particular, we achieved a correlation of greater than 99.6% between choroidal thickness distributions obtained algorithmically and manually. Also, our results improve upon the results of Alonso-Caneiro et al. [30] by respective factors of 27.67% and 76.04% in two quotient measures defined relative to observer repeatability. Of course, standardized datasets would be ideal for comparison among competing algorithms, which, however, could be impractical due large resource requirement. Meanwhile, the said quotients are defined to facilitate comparison among algorithms that have been tested using disparate datasets.

At this point, it is worthwhile to address a methodological issue. Recall that we picked as the average (M) of two manual segmentations (M1 and M2) as the reference following reported practice [17,18]. In this context, one may argue that the better one between M1 and M2 should serve as a more natural reference. Of course, one cannot directly choose one over the other. Instead, including M as well, one can compare the proposed algorithm with each of M1, M2 and M under various criteria. In terms of absolute difference (AD), proposed versus M1 (PvsM1, henceforth) and proposed versus M2 (PvsM2, henceforth) results are respectively 19.75μm and 20.12μm on the average. In comparison, proposed versus M (PvsM, henceforth) gives 19.15μm. In terms of correlation coefficient (CC), PvsM1=99.60%, PvsM2=99.60%, and PvsM=99.64%. In terms of Dice coefficient (DC), PvsM1=95.39%, PvsM2=95.28%, and PvsM=95.47%. In other words, according to all three criteria, PvsM outperforms each of PvsM1 and PvsM2 (although the latter two are numerically close to the former in general). This experimentally validates our choice of the average segmentation as the manual reference, as well as the underlying intuition that the averaging process tends to remove undesired subjective fluctuations.

In the near future, we envision our algorithm to have significant clinical impact. In particular, recall that information about the choroid thickness was traditionally obtained using ICG and ultrasonography before the development of EDI-OCT. The former devices provide low resolution images with poor repeatability and mainly qualitative information. With the advent of EDI-OCT, quantitative assessment of choroid became possible. However, measurement of choroidal thickness provides only single sectional information about the choroid. In contrast, measurement of choroidal volume at the macular region would provide global information about the disease and helps to assess treatment response. This information could be applicable immediately in diseases such as central serous chorioretinopathy and Vogt Koyanagi Harada syndrome where choroid is primarily site of involvement [49,50]. Clinical studies have already shown decrease in choroidal thickness in response to treatment in these diseases, and we anticipate that the assessment of choroidal volume in such situation would provide a broader perspective of the treatment response. However, the time consuming manual methods till now remained the main obstacle in clinical adoption of the aforementioned assessment. Our automated method is well suited to remove such obstacle.

In the long run, we envisage improved quantification and visualization of the choroidal layer and vessels in 3D to enable next-generation screening and diagnosis [51], in which direction certain general mathematical techniques have been suggested [21,22], and significant specific research has been initiated [24]. In closing, we hasten to add that although we argued for the appropriateness of SSIM and tensor voting for COB detection and hence choroidal thickness estimation, a vastly different approach could be appropriate in a different context for detecting a different feature (see, e.g., [52] for optic disk detection), and for dealing with thickness (see, e.g., [53] for thickness of nerve fiber layer).

@&#ACKNOWLEDGEMENTS@&#

This work was supported by theDepartment of Electronics and Information Technology (DeitY), Govt. of India, under the Cyber Physical Systems Innovation Project: 13(6)/2010-CC&BT.

@&#REFERENCES@&#


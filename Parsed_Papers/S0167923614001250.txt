@&#MAIN-TITLE@&#A kernel entropy manifold learning approach for financial data analysis

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A kernel entropy manifold learning algorithm for financial data (MLFD)


                        
                        
                           
                           MLFD employs the information metric to measure the relationships between two financial data points.


                        
                        
                           
                           MLFD yields reasonable and accurate low-dimensional embedding of the original financial data set.


                        
                        
                           
                           The accuracy of the financial early warning is improved by MLFD.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Manifold learning

Financial analysis

Low-dimensional embedding

Information metric

@&#ABSTRACT@&#


               
               
                  Identification of intrinsic characteristics and structure of high-dimensional data is an important task for financial analysis. This paper presents a kernel entropy manifold learning algorithm, which employs the information metric to measure the relationships between two financial data points and yields a reasonable low-dimensional representation of high-dimensional financial data. The proposed algorithm can also be used to describe the characteristics of a financial system by deriving the dynamical properties of the original data space. The experiment shows that the proposed algorithm cannot only improve the accuracy of financial early warning, but also provide objective criteria for explaining and predicting the stock market volatility.
               
            

@&#INTRODUCTION@&#

Traditional financial analysis methodologies include quantitative model and textual analysis. The quantitative model is the analysis about financial data by the use of statistical analysis tools or artificial intelligence technologies, which relies on the selection about basic important factors, such as financial ratios, technical indexes, and macroeconomic indexes [1]. The textual analysis utilizes text mining techniques to analyze the context of financial reports, which are dependent on the identification of a predefined set of keywords [2]. Since different factors or keywords are selected for different studies, the results are often subjective.

The real financial indicators are numerous while the complex high-dimensional data tends to obscure the essential feature of data [4]. Identifying intrinsic characteristics and structure of high-dimensional data is important for financial analysis. Inspired by the Quantitative Structure–Property Relationship (QSPR) method [3], whose core idea is that the microscopic structure of a material determines its macroscopic properties, this paper tries to find the inherent relationships between data points of financial dataset, and further derive the overall characteristics of the financial system.

Manifold learning, which explores the inherent low-dimensional manifold structure of high-dimensional data, is a valid choice for this task. In the field of financial analysis, data information characteristics, i.e. probability distributions, are important. However, many existing manifold learning algorithms concern about space geometric characteristics [5–8]. When Probability Density Functions (PDFs) are constrained to form a sub-manifold of interest, the straight-shot distance is no longer an accurate description of the manifold distance [50]. For financial data sets, each data point represents a listed company, while the distance between the data points indicates the degree of difference between the financial positions of listed companies. If the difference was characterized only by the geometric space distance between data points, it may not only unfit the practical significance of financial analysis, but also cause problems in the subsequent analysis. Therefore, this study employs the information metric to measure the relationships between listed companies and obtains the relationship metric model.

Real-world financial data is often nonlinear [10] and linear mapping manifold learning cannot fully capture the data information. Though Qiao et al. proposed a nonlinear mapping [11], the method is too complicated for the current problem. Kernel is often used to discover nonlinear structure in data [12,13]. The objective of this paper is to propose a kernel entropy manifold learning (KEML) algorithm to obtain the low-dimensional representation of high-dimensional financial data from the perspective of manifold learning. The KEML algorithm is extended to a kernel feature space so that the low-dimensional embedding can reflect the characteristics of the original financial data set. Experiments using small and medium-sized companies from China A-share Stock Market are designed to validate the proposed algorithm.

The rest of the paper is organized as follows: Section 2 reviews related works. Section 3 describes the modeling of financial data manifold and the proposed algorithm. Section 4 reports the experimental study and the last section concludes the paper.

Over the past few decades, machine learning algorithms have been widely used in the financial field and have been reported to be quite effective in some cases [14]. Machine learning quantitative models include single algorithms, such as ANN [15–17], SVM [18–20] and SOM [21,22], and hybrid techniques, which combine two or more algorithms. Many studies have been conducted to develop hybrid techniques for financial analysis. Serrano-Cinca and Gutiérrez-Nieto [23] combined partial least square (PLS) regression model and principal component analysis (PCA) and multiple linear regression (MLR) for bankruptcy prediction. Yolcu et al. [24] used a hybrid artificial neural network containing linear and nonlinear components for time series forecasting. Kao et al. [25] combined multivariate adaptive regression splines (MARS) and support vector regression (SVR) for stock index forecasting. Lu et al. [26] used independent component analysis (ICA) and support vector regression (SVR) in financial time series forecasting.

Context-based text analysis had been used to analyze unstructured data in financial reporting. Groth and Muntermann [27] and Chan and Franklin [2] and Humpherys et al. [28] adopted text mining technology to analyze the unstructured data of financial reports to improve prediction accuracy of financial risk. Schumaker and Chen [29] used textual representations of financial news articles to estimate the discrete stock price. Olson et al. [30] compared data mining methods for bankruptcy prediction.

The financial dataset can be considered as a system, in which each data point is an element. The intrinsic relationships between elements constitute the system structure, which determines the characteristics of the system. Inspired by the idea of QSPR, this study tried to explore the intrinsic structure of the system, and then discover the overall status of the system.

A manifold is a topological space which is locally Euclidean. High-dimensional data observed in real world are often the consequences of a small number of factors [31]. Manifold learning algorithms assume that the input data resides on or close to a low-dimensional manifold embedded in the ambient space [32]. Thus it is possible to construct a mapping that obeys certain properties of the manifold and obtain low-dimensional representation of high-dimensional data with good preservation of the intrinsic structure in the data [32].

Currently dimension reduction techniques are mainly divided into two categories: linear and nonlinear methods. The most well known linear method is principal component analysis (PCA), which is based on correlation matrices [38]. PCA is a classical feature extraction and data representation technique widely used in pattern recognition and computer vision. Sirovich and Kirby utilized PCA to represent pictures of human faces [54]. Turk and Pentland presented the well-known Eigenfaces method for face recognition in 1991 [54]. Kernel PCA (KPCA), a kernel extension of PCA, is also a very influential method. KPCA performs traditional PCA in a kernel feature space, which is nonlinearly related to the input space [38].

Compared with traditional dimension reduction approaches, manifold learning has advantages such as nonlinear nature, geometric intuition, and computational feasibility. Many manifold learning methods have been developed over the years. Isometric Feature Mapping (ISOMAP) [6] and Locally Linear Embedding (LLE) [7] are the earliest ones. The key idea of ISOMAP algorithm is to preserve the geodesic distance among points on the manifold and embed data into low-dimensional space by multidimensional scaling. LLE computes the reconstruction weights of each point and then minimizes the embedding cost by solving an eigenvalue problem to preserve the proximity relationship among data.

Local tangent space alignment (LTSA) constructs local linear approximations of the manifold in the form of a collection of overlapping approximate tangent spaces at each sample point, and then aligns those tangent spaces to obtain a global parameterization of the manifold [5]. LTSA maps the high dimensional data points on a manifold to points in a lower dimension Euclidean space. This mapping is isometric if the manifold is isometric to its parameter space [5]. Local Multidimensional Scaling (LMDS) is a data embedding method based on the alignment of overlapping locally scaled patches [8] and inputs are local distances. A subset of overlapping patches is chosen by a greedy approximation algorithm of minimum set cover. The patches are aligned to derive global coordinates and minimize a residual measure. LMDS is locally isometric and scales with the number of patches rather than the number of data points. LMDS produces less deformed embedding results than LLE [8].

These manifold learning algorithms use geodesic distance metric or weight measurement to calculate similarities between data points. In many problems of practical interest, however, the manifold geometry is unavailable and the calculation of geodesics must be done in a model-free, nonparametric fashion [34]. In applications like financial analysis, for example, only considering the geometry structure of data space may miss some essential characteristics of data and destroy the proximity relations (topology) of the original data space [9].

This study adopted an information theory-based metric to measure the difference between data points. Shannon suggested that “information entropy plays a central role in information theory as measures of information, choice, and uncertainty” [35]. Kolmogorov complexity [36] measures information content of an object. Bennett et al. [37] proposed the information distance theory and proved the fundamental universal theorem. Information distance measures the essential relationship between things. Due to its parameter-free, feature-free, and alignment-free characteristics, it can be used to deal with unstructured and incomprehensible data. A distance is a function D with nonnegative real values, defined on the Cartesian product X
                        ×
                        X of a set X. It is called a metric on X if for every x, y, z
                        ∈
                        X:
                           
                              
                                 
                                    ⋅
                                    
                                    D
                                    
                                       x
                                       y
                                    
                                    =
                                    0
                                    
                                    iff
                                    
                                    x
                                    =
                                    y
                                    
                                    
                                       
                                          the
                                          
                                          identity
                                          
                                          axiom
                                       
                                    
                                    ;
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    ⋅
                                    
                                    D
                                    
                                       x
                                       y
                                    
                                    +
                                    D
                                    
                                       y
                                       z
                                    
                                    ≥
                                    D
                                    
                                       x
                                       z
                                    
                                    
                                       
                                          the
                                          
                                          triangle
                                          
                                          inequality
                                       
                                    
                                    ;
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    ⋅
                                    
                                    D
                                    
                                       x
                                       y
                                    
                                    =
                                    D
                                    
                                       y
                                       x
                                    
                                    
                                       
                                          the
                                          
                                          symmetry
                                          
                                          axiom
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

A set X provided with a metric is called a metric space. For example, every set X has the trivial discrete metric D(x, y)=0 if x
                        =
                        y and D(x, y)=1 otherwise [37]. The information metric between stochastic sources X and Y is defined as D(x, y)=
                        H(x|y)+
                        H(y|x) [37]. Here H(x|y) is used to measure the difference between probability distributions.

In recent years, entropy-based distance metric has been investigated by the manifold learning field. Costa and Hero [33] proposed geodesic-minimal-spanning-tree (GMST) method that jointly estimates both the intrinsic dimension and intrinsic entropy on the manifold. Jenssen [38] developed kernel entropy component analysis (KECA) for data transformation and dimensionality reduction. KECA reveals structure relating to the Renyi entropy of the input space data set. Carter et al. [34] proposed Fisher Information Nonparametric Embedding (FINE) which utilizes the properties of information geometry and statistical manifolds to define similarities between data sets using Fisher information distance. FINE showed that this metric can be approximated using nonparametric methods. Carter et al. [50] presented methods for low-dimensional representation of information-geometric data and illustrated the methods in flow cytometry and demography analysis.

The proposed KEML algorithm is different from the above mentioned methods in the following ways: 1) each data point in a financial data set is regarded as a subset of the probability distribution and all data points constitute a space of probability distributions. It seeks to discover a statistical manifold on a probability density space, while previous algorithms are based on the Euclidean vector space. 2) In the KEML algorithm, information divergence is used for measuring pairwise distance rather than Euclidean distance. 3) Though there are previous manifold learning algorithms using the Rényi entropy, the proposed algorithm utilizes it differently. For instance, Costa and Hero [33] employed the Rényi entropy of the sample points to measure the data compression on the manifold, while the proposed algorithm adopts the Rényi entropy to estimate the distance metric, which was the criteria for the topological relations in high-dimensional data. 4) The construction of the probability density space is different from previous statistical manifold learning algorithms. For example, the Information-Geometric Dimensionality Reduction (IGDR) algorithm proposed by Carter et al. [50] also used the Rényi entropy as the distance metric. However, each index is considered as a class label of a subset with N sample points in the IGDR. Thus the original dataset is divided into d subsets and d is the number of indicators. While in the proposed algorithm, each point x
                        i is considered as a set, in which each feature index is a sample. The original dataset was divided into N subsets.

In 1930s, Whitney proposed the embedding theorem which an m-dimensional manifold can be realized in a Euclidean space of dimension 2m
                        +1. A potentially low-dimensional copy of the manifold can be recovered and a bijection exists between the original and its copy [52]. Based on Whitney's theorem, Takens provided a theoretical foundation for the reconstruction of an m-dimensional manifold when only a scalar time series is observable [52]. Li et al. [53] proved that high-dimensional time series can be parsimoniously represented by a dynamical process defined on a low-dimensional manifold.

The dynamical model parameters can be learned in the dimensionality-reduced state space [53]. The statistical quantities that characterize the properties of a dynamical system can be obtained through the parameters. Kolmogorov entropy (K entropy), a quantitative measure of uncertainty, is used to describe the degree of system movement disorder or random [47]. The larger the K value, the greater the information loss and the greater the degree of chaos. For random behaviors, K entropy is unbounded when the information is completely lost. For regular motions, K entropy should be zero when no information is generated. For a low-dimensional chaotic dynamics system, K entropy is a finite value greater than zero [47].

In this paper, each data set is treated as a dynamical system and the low-dimensional embedding of a dynamical system can be learned through the proposed algorithm. Then the statistical quantity, such as K entropy, can be derived from the low-dimensional embedding to characterize the properties of the dynamical system.

The objects in this study are n listed companies (X
                        1, X
                        2, …, X
                        
                           n
                        ), each Xi
                         has D financial indicators (X
                        
                           i
                        
                        1, X
                        
                           i
                        
                        2, …, X
                        
                           i
                        
                        
                           D
                        ). Each company Xi
                         is a data set consisting of financial indicators, which is X
                        
                           i
                        
                        =(X
                        
                           i
                        
                        1, X
                        
                           i
                        
                        2, …, X
                        
                           i
                        
                        
                           D
                        ). χ is a family of data sets χ
                        ={X
                        1, …, X
                        
                           i
                        , …, X
                        
                           n
                        }(i
                        =1, …, n), where X
                        
                           i
                        
                        =(X
                        
                           i
                        
                        1, X
                        
                           i
                        
                        2, …, X
                        
                           i
                        
                        
                           D
                        ). Assume that each data set Xi
                         has an underlying probability distribution function pi
                         determined by D financial indicators and the parameters are unknown. Then, we can get a collection of Probability Density Functions (PDFs) P
                        ={p
                        1, …, p
                        
                           n
                        } which lie on a statistical manifold π. In the statistical manifold π, each element is a probability distribution pi
                        . We try to reconstruct π in the space of probability densities using available information in P. That is to find an embedding A
                        :
                        p(x)→
                        y, where y
                        ∈
                        ℝ
                        
                           m
                        , m
                        <
                        D. Different from the traditional manifold learning algorithm in Euclidean space, the proposed algorithm is to discover a low-dimensional embedding in the density space, i.e. a statistical manifold of probability distributions.

To obtain the low-dimensional embedding from the high-dimensional data sets, pairwise sample distance which measures the amount of information change between data points should be preserved. There is the corresponding Kullback–Leibler divergence KL(P,Q) [50] between any two probability distributions P and Q, where 
                           
                              KL
                              
                                 P
                                 Q
                              
                              =
                              E
                              
                                 
                                    log
                                    
                                       
                                          f
                                          
                                             x
                                          
                                       
                                       
                                          g
                                          
                                             x
                                          
                                       
                                    
                                 
                              
                              =
                              
                                 ∫
                                 
                                    f
                                    
                                       x
                                    
                                    log
                                    
                                       
                                          f
                                          
                                             x
                                          
                                       
                                       
                                          g
                                          
                                             x
                                          
                                       
                                    
                                    dx
                                 
                              
                           
                        , P and Q are described by the density function f(x) and g(x), respectively. Divergence is an approximate distance function, which meets the non-negative distance definition, but does not satisfy the symmetry and triangle inequality. The Renyi quadratic entropy is h(p)=−log∫
                        p
                        2(x)dx, where p(x) is the probability density function generating the data set, or sample X
                        =
                        x
                        1, x
                        2, …, x
                        
                           N
                         
                        [38]. Since the logarithm is a monotonic function, we may concentrate on the quantity V(p)=∫
                        p
                        2(x)dx. Alternatively, the formula may be formulated as V(p)=
                        ε
                        
                           p
                        (p), where ε
                        
                           p
                        (g) denotes expectation with regard to the density p(x).

To estimate V(p) and h(p), the kernel estimation, given by 
                           
                              
                                 
                                    p
                                    
                                       x
                                    
                                 
                                 ∧
                              
                              ∞
                              
                                 1
                                 N
                              
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    k
                                    
                                       
                                          x
                                          −
                                          
                                             x
                                             i
                                          
                                          ,
                                          σ
                                       
                                    
                                 
                              
                           
                         
                        [39], where k(x
                        −
                        x
                        
                           i
                        , σ)=exp(−‖x
                        −
                        x
                        
                           i
                        ‖2/σ
                        2), is introduced. The non-parametric estimation of Renyi entropy is:
                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             h
                                             ^
                                          
                                          
                                             p
                                          
                                          =
                                          −
                                          log
                                          (
                                          
                                             ∫
                                             
                                                
                                                   
                                                      
                                                         p
                                                         2
                                                      
                                                      
                                                         x
                                                      
                                                   
                                                   ^
                                                
                                             
                                          
                                          dx
                                          )
                                       
                                    
                                    
                                       
                                          =
                                          −
                                          log
                                          
                                             
                                                
                                                   1
                                                   
                                                      N
                                                      2
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            
                                                               ∫
                                                               
                                                                  k
                                                                  
                                                                     
                                                                        x
                                                                        −
                                                                        
                                                                           x
                                                                           i
                                                                        
                                                                        ,
                                                                        σ
                                                                     
                                                                  
                                                                  k
                                                                  
                                                                     
                                                                        x
                                                                        −
                                                                        
                                                                           x
                                                                           j
                                                                        
                                                                        ,
                                                                        σ
                                                                     
                                                                  
                                                                  dx
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          =
                                          −
                                          log
                                          
                                             
                                                
                                                   1
                                                   
                                                      N
                                                      2
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            k
                                                            
                                                               
                                                                  
                                                                     x
                                                                     i
                                                                  
                                                                  −
                                                                  
                                                                     x
                                                                     j
                                                                  
                                                                  ,
                                                                  
                                                                     2
                                                                  
                                                                  σ
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     

Formula (1) indicates that the Renyi second order entropy can be decided by the Mahalanobis distance between any two samples in a collection.

For n listed companies, each company has D financial indicators. The following information metric model can be formulated:

Suppose P
                        
                           i
                        
                        =(p
                        
                           i
                        
                        1, p
                        
                           i
                        
                        2, …, p
                        
                           i
                        
                        
                           D
                        ), (i
                        =1, 2,.., n) is the probability distribution vector of the i-th listed company financial indicators, i.e.,
                           
                              (2)
                              
                                 
                                    
                                       p
                                       i
                                       j
                                    
                                    ≥
                                    0
                                    ,
                                    
                                       
                                          ∑
                                          
                                             j
                                             =
                                             1
                                          
                                          D
                                       
                                       
                                          
                                             p
                                             i
                                             j
                                          
                                       
                                    
                                    =
                                    1
                                    ,
                                    
                                       
                                          i
                                          =
                                          1
                                          ,
                                          2
                                          ,
                                          …
                                          ,
                                          n
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

The information metric between any two companies named Renyi divergence:
                           
                              (3)
                              
                                 
                                    h
                                    
                                       
                                          P
                                          i
                                       
                                       
                                          P
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             m
                                             =
                                             1
                                          
                                          D
                                       
                                       
                                          
                                             p
                                             i
                                             m
                                          
                                          log
                                          
                                             
                                                p
                                                i
                                                m
                                             
                                             
                                                p
                                                j
                                                m
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

Since h(P
                        
                           i
                        , P
                        
                           j
                        )≠
                        h(P
                        
                           j
                        , P
                        
                           i
                        ), the cross entropy does not satisfy the symmetry and can be transformed using the following formula:
                           
                              (4)
                              
                                 
                                    
                                       
                                          Let
                                          
                                          h
                                          
                                             
                                                P
                                                i
                                             
                                             
                                                P
                                                j
                                             
                                          
                                          =
                                          h
                                          (
                                          
                                             P
                                             i
                                          
                                          ,
                                          
                                             P
                                             j
                                          
                                          )
                                          +
                                          h
                                          (
                                          
                                             P
                                             j
                                          
                                          ,
                                          
                                             P
                                             i
                                          
                                          )
                                          =
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   i
                                                   m
                                                
                                                log
                                                
                                                   
                                                      p
                                                      i
                                                      m
                                                   
                                                   
                                                      p
                                                      j
                                                      m
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   j
                                                   m
                                                
                                                log
                                                
                                                   
                                                      p
                                                      j
                                                      m
                                                   
                                                   
                                                      p
                                                      i
                                                      m
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                          =
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   i
                                                   m
                                                
                                             
                                          
                                          log
                                          
                                             p
                                             i
                                             m
                                          
                                          +
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   j
                                                   m
                                                
                                                log
                                                
                                                   p
                                                   j
                                                   m
                                                
                                             
                                          
                                          −
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   i
                                                   m
                                                
                                                log
                                                
                                                   p
                                                   j
                                                   m
                                                
                                             
                                          
                                          −
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   p
                                                   j
                                                   m
                                                
                                             
                                          
                                          log
                                          
                                             p
                                             i
                                             m
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                        pi
                         and pj
                         can be obtained from the above kernel density estimation.

Real world financial data sets are nonlinear. This study proposes a kernel extension of the metric to tackle the nonlinear problem. For a given data set X
                        1, X
                        2, …, X
                        
                           n
                        
                        ∈
                        R
                        
                           D
                         with a positive definite mercer kernel Θ
                        :
                        R
                        
                           D
                        
                        ×
                        R
                        
                           D
                        
                        →
                        R, there exists a unique Reproducing Kernel Hilbert Space (RKHS) Ω of real valued functions on RD
                        . Let ϕ
                        :
                        R
                        
                           D
                        
                        →
                        Ω be a feature map from the input space RD
                         to Ω, and Θ
                        
                           ij
                        
                        =
                        Θ(X
                        
                           i
                        , X
                        
                           j
                        )=〈ϕ(X
                        
                           i
                        ), ϕ(X
                        
                           j
                        )〉=
                        ϕ(X
                        
                           i
                        )
                           T
                        
                        ϕ(X
                        
                           j
                        ). Let ϕ(X) denotes the data matrix in RKHS, such that ϕ(X)=(ϕ(x
                        1), …, ϕ(x
                        
                           n
                        )). The Euclidean distance between ϕ(Xi
                        ) and ϕ(Xj
                        ) in the feature space is
                           
                              
                                 
                                    
                                       
                                          ϕ
                                          
                                             
                                                X
                                                i
                                             
                                          
                                          −
                                          ϕ
                                          
                                             
                                                X
                                                j
                                             
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             Θ
                                             ii
                                          
                                          +
                                          
                                             Θ
                                             jj
                                          
                                          −
                                          2
                                          
                                             Θ
                                             ij
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

Then, in the feature space, the estimated probability density function is
                           
                              (5)
                              
                                 
                                    
                                       
                                          p
                                          
                                             x
                                          
                                       
                                       ∧
                                    
                                    ∞
                                    
                                       1
                                       N
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          k
                                          
                                             
                                                ϕ
                                                
                                                   x
                                                
                                                −
                                                ϕ
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                
                                                ,
                                                σ
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where
                           
                              (6)
                              
                                 
                                    k
                                    
                                       
                                          ϕ
                                          
                                             x
                                          
                                          −
                                          ϕ
                                          
                                             
                                                x
                                                i
                                             
                                          
                                          ,
                                          σ
                                       
                                    
                                    =
                                    exp
                                    
                                       
                                          −
                                          
                                             
                                                
                                                   ϕ
                                                   
                                                      x
                                                   
                                                   −
                                                   ϕ
                                                   
                                                      
                                                         x
                                                         i
                                                      
                                                   
                                                
                                             
                                             2
                                          
                                          /
                                          
                                             σ
                                             2
                                          
                                       
                                    
                                    =
                                    exp
                                    
                                       
                                          −
                                          
                                             
                                                
                                                   Θ
                                                   ..
                                                
                                                +
                                                
                                                   Θ
                                                   ii
                                                
                                                −
                                                2
                                                
                                                   Θ
                                                   
                                                      .
                                                      i
                                                   
                                                
                                             
                                          
                                          /
                                          
                                             σ
                                             2
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

Substitute Eq. (6) with Eq. (5), Eq. (5) can be reformulated as;
                           
                              (7)
                              
                                 
                                    
                                       
                                          p
                                          
                                             x
                                          
                                       
                                       ∧
                                    
                                    ∞
                                    
                                       1
                                       N
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          exp
                                          
                                             
                                                −
                                                
                                                   
                                                      
                                                         Θ
                                                         ..
                                                      
                                                      +
                                                      
                                                         Θ
                                                         ii
                                                      
                                                      −
                                                      2
                                                      
                                                         Θ
                                                         
                                                            .
                                                            i
                                                         
                                                      
                                                   
                                                
                                                /
                                                
                                                   σ
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        and formula (7) can be substituted with Eq. (4). Suppose P
                        
                           i
                        
                        =(p
                        
                           i
                        
                        1, p
                        
                           i
                        
                        2, …, p
                        
                           i
                        
                        
                           D
                        ), (i
                        =1, 2,.., n) is the probability distribution vector of the ith-listed company financial indicators, i.e.,
                           
                              (8)
                              
                                 
                                    
                                       p
                                       i
                                       j
                                    
                                    ≥
                                    0
                                    ,
                                    
                                       
                                          ∑
                                          
                                             j
                                             =
                                             1
                                          
                                          D
                                       
                                       
                                          
                                             p
                                             i
                                             j
                                          
                                       
                                    
                                    =
                                    1
                                    ,
                                    
                                       
                                          i
                                          =
                                          1
                                          ,
                                          2
                                          ,
                                          …
                                          ,
                                          n
                                       
                                    
                                 
                              
                           
                        
                        h(Pi
                        ,Pj
                        ) becomes
                           
                              (9)
                              
                                 
                                    
                                       
                                          h
                                          
                                             
                                                P
                                                i
                                             
                                             
                                                P
                                                j
                                             
                                          
                                          =
                                          
                                             1
                                             N
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            exp
                                                            (
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     ii
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          log
                                          (
                                          
                                             1
                                             N
                                          
                                          
                                             
                                                ∑
                                                
                                                   n
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                exp
                                                (
                                                −
                                                
                                                   
                                                      
                                                         Θ
                                                         ii
                                                         mm
                                                      
                                                      +
                                                      
                                                         Θ
                                                         ii
                                                         nn
                                                      
                                                      −
                                                      2
                                                      
                                                         Θ
                                                         ii
                                                         mn
                                                      
                                                   
                                                
                                                /
                                                
                                                   σ
                                                   2
                                                
                                             
                                          
                                          )
                                          ]
                                          +
                                       
                                    
                                    
                                       
                                          
                                             1
                                             N
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            exp
                                                            (
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     jj
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          log
                                          
                                             
                                                
                                                   1
                                                   N
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      exp
                                                      
                                                         
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     jj
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ]
                                          −
                                       
                                    
                                    
                                       
                                          
                                             1
                                             N
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            exp
                                                            (
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     ii
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          log
                                          
                                             
                                                
                                                   1
                                                   N
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      exp
                                                      
                                                         
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     jj
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ]
                                          −
                                       
                                    
                                    
                                       
                                          
                                             1
                                             N
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                D
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         
                                                            exp
                                                            (
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     jj
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     jj
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          log
                                          
                                             
                                                
                                                   1
                                                   N
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         n
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      exp
                                                      
                                                         
                                                            −
                                                            
                                                               
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mm
                                                                  
                                                                  +
                                                                  
                                                                     Θ
                                                                     ii
                                                                     nn
                                                                  
                                                                  −
                                                                  2
                                                                  
                                                                     Θ
                                                                     ii
                                                                     mn
                                                                  
                                                               
                                                            
                                                            /
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ]
                                          .
                                       
                                    
                                 
                              
                           
                        
                     

In LLE, the local linear structure between the neighbors remains unchanged after dimensionality reduction. For financial data points, the concept and scope of neighbors can be extended. Different from image data sets, adjacency relationships of financial data do not wholly depend on geometric relationships of data points. As stated in Section 3.3, the original data set can be mapped into the linear RKHS by the kernel function. Assume that every data point and its neighborhood data points are located on the same linear manifold. When reproducing low-dimensional manifold, the corresponding data points in the intrinsic low-dimensional space maintain the same global neighbor relationship. To obtain the low-dimensional representation of data sets, KEML algorithm constructs extended local linear structure and preserves the global topological characteristics in the inherent low-dimensional manifold. As mentioned above, the relationship metric hij
                        
                        =
                        h(Pi
                        ,Pj
                        ) reflects the essential relationships between the financial data points. h
                        11 represented the information distance of data point 1 with itself, h
                        12 represented the information distance between data point 1 and data point 2 and so on. Therefore, we can further obtain the global relationship metric matrix 
                           
                              H
                              =
                              
                                 
                                    
                                       
                                          
                                             h
                                             11
                                          
                                       
                                       
                                          
                                             h
                                             12
                                          
                                       
                                       
                                          …
                                       
                                       
                                          
                                             h
                                             
                                                1
                                                n
                                             
                                          
                                       
                                    
                                    
                                       
                                          …
                                       
                                       
                                          …
                                       
                                       
                                          …
                                       
                                       
                                          …
                                       
                                    
                                    
                                       
                                          
                                             h
                                             
                                                i
                                                1
                                             
                                          
                                       
                                       
                                          
                                             h
                                             
                                                i
                                                2
                                             
                                          
                                       
                                       
                                          …
                                       
                                       
                                          
                                             h
                                             in
                                          
                                       
                                    
                                    
                                       
                                          
                                             h
                                             
                                                n
                                                1
                                             
                                          
                                       
                                       
                                          
                                             h
                                             
                                                n
                                                2
                                             
                                          
                                       
                                       
                                          …
                                       
                                       
                                          
                                             h
                                             nn
                                          
                                       
                                    
                                 
                              
                           
                        , which is the reconstruction weight matrix and may be mapped to low-dimensional embedding manifold. The low-dimensional embedding Y reflects the corresponding reconstruction weight relationship of the sample points in the high-dimensional input space. Similar to the LLE method, we obtain the low-dimensional embedding by solving the following optimization problem:
                           
                              (10)
                              
                                 
                                    Min
                                    
                                    Φ
                                    
                                       Y
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                
                                                   
                                                      Y
                                                      i
                                                   
                                                   −
                                                   
                                                      
                                                         ∑
                                                         
                                                            j
                                                            =
                                                            1
                                                         
                                                         n
                                                      
                                                      
                                                         
                                                            h
                                                            ij
                                                         
                                                         
                                                            Y
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       2
                                    
                                    .
                                 
                              
                           
                        
                     

To eliminate the coordinates translation, rotation, and scaling factor of the low-dimensional embedding, two constraints are added: (1) 
                           
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 N
                              
                              
                                 
                                    Y
                                    i
                                 
                                 =
                                 0
                              
                           
                        , (2) 
                           
                              
                                 1
                                 
                                    N
                                    −
                                    1
                                 
                              
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    
                                       Y
                                       i
                                    
                                    
                                       Y
                                       i
                                       T
                                    
                                    =
                                    I
                                 
                              
                           
                        . Furthermore, Eq. (10) can be written as 
                           
                              Φ
                              
                                 Y
                              
                              =
                              
                                 
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          
                                             
                                                Y
                                                i
                                             
                                             −
                                             
                                                
                                                   ∑
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   n
                                                
                                                
                                                   
                                                      h
                                                      ij
                                                   
                                                   
                                                      Y
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 2
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                I
                                                −
                                                H
                                             
                                          
                                          T
                                       
                                       
                                          Y
                                          T
                                       
                                    
                                 
                                 2
                              
                              =
                              tr
                              
                                 
                                    YM
                                    
                                       Y
                                       T
                                    
                                 
                              
                           
                        , where M
                        =(I
                        −
                        H)
                           T
                        (I
                        −
                        H) is a n
                        ×
                        n matrix. In order to minimize the cost function, the low dimensional embedding Y should be taken as the corresponding eigenvectors v
                        1, …, v
                        
                           d
                           +1 to the smallest d
                        +1 eigenvalues of the matrix M, that is Y
                        =[ν
                        2, ⋅⋅⋅, ν
                        
                           d
                           +1], and d is determined by Renyi information dimension [51]. Information dimension was defined as follows:
                           
                              
                                 
                                    d
                                    =
                                    −
                                    
                                       lim
                                       
                                          ε
                                          →
                                          0
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             
                                                P
                                                i
                                             
                                             log
                                             
                                                P
                                                i
                                             
                                          
                                       
                                       
                                          log
                                          ε
                                       
                                    
                                 
                              
                           
                        where Pi
                         represented the probability of a point falling into the i-th unit, and here, it denoted the probability distribution of the i-th company which has been obtained above, ε was the standard body, and N was the number of points. Thus, we can get the intrinsic dimension by information dimension d.

In KEML, the reconstruction weight matrix adopts information matrix H, which reflects the essential relationships between the financial data points. As a bridge between high-dimensional observation space and low dimensional embedding space, the matrix H makes the low-dimensional embedding space maintains the original topological relations. KEML algorithm has the global optimal solution, without iteration. The computational complexity of KEML is dominated by three parts: N data points were projected into kernel space by use of kernel function, which the computational complexity was O(N
                        2); calculated the information distance between the data points in kernel space, which the computational complexity is O(N(N
                        −1)); calculated the low-dimensional embedding through the relationship distance matrix H, which the computational complexity is O(N
                        2).

The proposed KEML algorithm is summarized as follows (Table 1
                        ):
                           
                              Step 1
                              Construct the relationship measure matrix H
                              

Let Θ be the N
                                 ×
                                 N kernel matrix with its (i, j) th entry Θ
                                 
                                    ij
                                 
                                 =
                                 ϕ(x
                                 
                                    i
                                 )
                                    T
                                 
                                 ϕ(x
                                 
                                    j
                                 )=
                                 ϕ(x
                                 
                                    i
                                 , x
                                 
                                    j
                                 ). ϕ is a data-independent kernel associated with the kernel matrix Θ. In the KEML algorithm, the Gaussian kernel was adopted for all the kernel-based methods. Compute the relationship model hij
                                 , which builds the relationships between financial data points, and then get the relationship matrix H.

Calculate the low-dimensional embedding

Compute the eigenvalues of matrix (I
                                 −
                                 H)(I
                                 −
                                 H)
                                    T
                                  and the corresponding eigenvector Y.

Select data

Select the smallest d non-zero eigenvalues and the corresponding eigenvector Y.

The KEML algorithm produces d-dimensional manifold M from the original data set X
                        1, X
                        2, …, X
                        
                           n
                        
                        ∈
                        R
                        
                           D
                        . (R, ρ) is the original space and (M, ρ
                        1) is d-dimensional space, where ρ and ρ
                        1 represent respectively the corresponding space mapping. As known from the preceding analysis, the mapping Φ
                        :
                        R
                        →
                        M meets: (1) Φ is subjective; (2) ∀x, y
                        ∈
                        R, ρ(x, y)=
                        ρ
                        1(Φ(x), Φ(y)) is true. Assume (R, ρ) and (M, ρ
                        1) are isometrically isomorphic. According to Whitney's theorem [48], (M, ρ
                        1) can be embedded in (R, ρ). (M, ρ
                        1) is regarded as the reconstructed space of the system S. Since (R, ρ) and (M, ρ
                        1) are isometrically isomorphic, the evolving trajectory of S in the reconstructed space M is diffeomorphism in the original space R. That is, we can restore the original dynamics of the system in the sense of topologically equivalent to maintain its chaotic characteristics, such as the Kolmogorov entropy [47].

Assuming the d-dimensional reconstructed space attractor track X(t), P(i
                        1, i
                        2, …, i
                        
                           n
                        ) is the joint probability when X(t
                        =
                        τ) in the box i
                        1, X(t
                        =2τ) in the box i
                        2,…, and X(t
                        =
                        nτ) in the box in
                        , then K entropy is defined as
                           
                              
                                 
                                    
                                       
                                          K
                                          =
                                          −
                                          
                                             lim
                                             
                                                τ
                                                →
                                                0
                                             
                                          
                                          
                                             lim
                                             
                                                ε
                                                →
                                                0
                                             
                                          
                                          
                                             lim
                                             
                                                n
                                                →
                                             
                                          
                                          
                                             1
                                             nτ
                                          
                                          
                                             
                                                ∑
                                                
                                                   
                                                      i
                                                      1
                                                   
                                                   ,
                                                   
                                                      i
                                                      2
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      i
                                                      n
                                                   
                                                
                                             
                                             
                                                P
                                                
                                                   
                                                      i
                                                      1
                                                   
                                                   
                                                      i
                                                      2
                                                   
                                                   …
                                                   
                                                      i
                                                      n
                                                   
                                                
                                                log
                                                P
                                                (
                                                
                                                   i
                                                   1
                                                
                                                ,
                                                
                                                   i
                                                   2
                                                
                                                ,
                                                …
                                                ,
                                             
                                          
                                          
                                             i
                                             n
                                          
                                          )
                                       
                                    
                                    
                                       
                                          =
                                          
                                             lim
                                             
                                                τ
                                                →
                                                0
                                             
                                          
                                          
                                             lim
                                             
                                                l
                                                →
                                                0
                                             
                                          
                                          
                                             lim
                                             
                                                n
                                                →
                                                ∞
                                             
                                          
                                          
                                             1
                                             nτ
                                          
                                          
                                             ∑
                                             
                                                
                                                   
                                                      
                                                         K
                                                         
                                                            n
                                                            +
                                                            1
                                                         
                                                      
                                                      −
                                                      
                                                         K
                                                         n
                                                      
                                                   
                                                
                                             
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     


                        K
                        
                           n
                           +1
                        −
                        K
                        
                           n
                         measures the information loss of the system from time n to time n
                        =1. K entropy defines the average loss rate of the system. In the KEML algorithm, we obtain the statistical manifold π
                        ={p(x; θ)|θ
                        ∈
                        ℝ
                        
                           m
                        } of n companies, the joint probability P
                        
                           i
                        
                        =(p
                        
                           i
                        
                        1, p
                        
                           i
                        
                        2, …, p
                        
                           i
                        
                        
                           D
                        ) of the i-th company, and the information distance h
                        
                           ij
                        
                        =
                        h(P
                        
                           i
                        , P
                        
                           j
                        ) between any two companies. If each company in the data set is taken as an independent subsystem, we can measure K
                        
                           n
                           +1
                        −
                        K
                        
                           n
                         by hij
                        , and then K entropy of any company can be obtained as Ki
                        . Furthermore, we can get the K entropy of the system S.

In this section, three experiments are conducted to validate the proposed KEML algorithm using data from China A-share Stock Market. All algorithms are implemented in MATLAB 2010Rb.

The 2006–2010 annual financial data of small and medium-sized companies (a total of 205) from China A-share Stock Market were chosen from Wind Information Database for the experiment. Twenty-seven financial indicators were selected to reflect six aspects of the companies' financial positions [40] (Table 2
                        ).

According to [40], the following relationships between financial indicators can be expected. First, there is a positive correlation between solvency and cash flow. It indicates that when cash flows of a listed company are less than adequate, its debt levels are high. Second, there are positive correlations between operating capacity, profitability and ability to grow. Especially, there exists a significant positive correlation between profitability and ability to grow, indicating that the growth rate of a listed company is consistent with its ability to generate earnings. Third, there exist significant negative correlations between cash flow and operating capacity, profitability, and ability to grow. This suggests that when a listed company pursues an increase in net cash flow, its profitability, growth rate and operational turnaround situation will be negatively affected. Fourth, solvency is negatively correlated to operational index, profitability, and ability to grow.

The experiments are conducted as follows:
                           
                              First, the KEML are compared with six dimensionality reduction methods: KPCA, LTSA, LMDS, ISOMAP, LLE, and PCA. The quantitative indicator Procrustes Measure (PM) is used to measure the resulting low-dimensional embeddings. As a quantitative indicator, PM is a nonlinear measurement of goodness [42–44] and a smaller PM value indicates a more accurate embedding [42]. MATLAB provides a PM function to compute the corresponding PM values.

Second, the resulting low-dimensional embeddings in the first experiment are applied to provide early financial warnings. K-means clustering method is used to divide the low-dimensional embedding into two clusters to identify abnormal companies. The clustering results were examined respectively using F
                                 1
                                 −
                                 scores and risk expectation.

Third, the KEML algorithm is used to analyze the overall running characteristics of the stock market. As financial markets can be viewed as a highly complex evolving system [41], the experimental data constitutes a subsystem of the complex system. KEML explores the subsystem geometric space, which makes it possible to further use the relevant analytical tools to study the running characteristics of the system.

@&#EXPERIMENTAL RESULTS@&#

The low-dimensional embeddings of the high-dimensional financial data sets were obtained through different methods. In the experiment, the essential parameter is the bandwidth selection of Kernel Density Estimation. According to the existing literature, we first set σ
                           ={0.1,......, 100} with the step length of 10 and calculate the value of PM in each situation. After a series of PM values were generated, the smallest one is selected and the corresponding σ is obtained. Similarly, the corresponding optimal parameters were selected for the other six methods in the experiment respectively.


                           Fig. 1(a) shows the three-dimensional embedding results of KEML on the five data sets and Fig. 1(b) summarizes the comparative results. The corresponding PM values of low-dimensional embeddings are illustrated in Table 3
                           .

It can be seen that KEML achieves the best results on all the five data sets. The other methods used Euclidean distances between sample points to drive the dimensionality-reduction algorithm [50], so their performances are unsatisfactory for the financial area problems. One interesting observation is that the linear PCA outperforms ISOMAP and LLE on the selected financial data sets. PCA adopts the relative Euclidean distance as distance metric, compared to the geodesic distance or spatial location, which is closer to the meanings of logic relationship. When Probability Density Functions (PDFs) are constrained to form a sub-manifold of interest, and the true geodesic distance is no longer an accurate description of the manifold distance [50]. In this scenario, PCA may produce better performance than some non-linear manifold learning methods. But in general, nonlinear manifold learning methods produce better results than PCA in the experiment.

To statistically validate the results, a statistical test is conducted. Let 
                              
                                 x
                                 =
                                 KEML
                              
                            
                           
                              
                                 
                                    y
                                    1
                                 
                                 =
                                 KPCA
                              
                            
                           
                              
                                 
                                    y
                                    2
                                 
                                 =
                                 LTSA
                              
                            
                           
                              
                                 
                                    y
                                    3
                                 
                                 =
                                 LMDS
                              
                            
                           
                              
                                 
                                    y
                                    4
                                 
                                 =
                                 ISOMAP
                              
                            
                           
                              
                                 
                                    y
                                    5
                                 
                                 =
                                 LLE
                              
                            
                           
                              
                                 
                                    y
                                    6
                                 
                                 =
                                 PCA
                              
                           , thus we got six pairwise independent observed results: (x, y
                           1), (x, y
                           2), (x, y
                           3), (x, y
                           4), (x, y
                           5), (x, y
                           6). Let D
                           
                              i
                           
                           =
                           x
                           −
                           y
                           
                              i
                           , (i
                           =1, …, 6), then D
                           1, D
                           2, …, D
                           6 were independent to each other. Since D
                           1, D
                           2, …, D
                           6 were caused by the performance of the algorithm, they could be considered to obey the same distribution. Assume D
                           
                              i
                           
                           ∼
                           N(μ
                           
                              D
                           , σ
                           
                              D
                           
                           2), i
                           =1, 2, … n, which means D
                           1, D
                           2, …, D
                           6 constituting a sample of the normal population N(μ
                           
                              D
                           , σ
                           
                              D
                           
                           2), and where μ
                           
                              D
                           , σ
                           
                              D
                           
                           2 were unknown. We test the following hypothesis:
                              
                                 
                                    
                                       
                                          H
                                          0
                                       
                                       :
                                       
                                          μ
                                          D
                                       
                                       ≥
                                       0
                                       ,
                                       
                                       
                                          H
                                          1
                                       
                                       :
                                       
                                          μ
                                          D
                                       
                                       <
                                       0
                                    
                                 
                              
                           
                        

Observed sample mean and sample variance of D
                           1, D
                           2, …, D
                           6 were denoted by 
                              
                                 
                                    d
                                    ¯
                                 
                                 
                                 ,
                                 
                                 
                                    S
                                    D
                                    2
                                 
                              
                           , respectively, and the significance level is α
                           =0.01. The refusal domain of the test is 
                              
                                 t
                                 =
                                 
                                    
                                       d
                                       ¯
                                    
                                    
                                       
                                          S
                                          D
                                       
                                       /
                                       
                                          n
                                       
                                    
                                 
                                 ≤
                                 −
                                 
                                    t
                                    α
                                 
                                 
                                    
                                       n
                                       −
                                       1
                                    
                                 
                              
                           . n
                           =6, t
                           0.01(5)=3.3649 −
                           t
                           0.01(5)=−3.3649. The T-statistics of D
                           1, …, D
                           6 are respectively: 
                              
                                 
                                    t
                                    
                                       D
                                       1
                                    
                                 
                                 =
                                 −
                                 4.1535
                                 ,
                                 
                                 
                                    t
                                    
                                       D
                                       2
                                    
                                 
                                 =
                                 −
                                 3.4581
                                 ,
                                 
                                 
                                    t
                                    
                                       D
                                       3
                                    
                                 
                                 =
                                 −
                                 4.2458
                                 ,
                                 
                                 
                                    t
                                    
                                       D
                                       4
                                    
                                 
                                 =
                                 −
                                 10.9411
                                 ,
                                 
                                 
                                    t
                                    
                                       D
                                       5
                                    
                                 
                                 =
                                 −
                                 3.5981
                                 ,
                                 
                                 
                                    t
                                    
                                       D
                                       6
                                    
                                 
                                 =
                                 −
                                 4.2395
                              
                           .

The hypothesis H
                           0 can be rejected due to 
                              
                                 
                                    
                                       t
                                       
                                          D
                                          1
                                       
                                    
                                    …
                                    
                                       t
                                       
                                          D
                                          6
                                       
                                    
                                 
                                 <
                                 −
                                 
                                    t
                                    0.01
                                 
                                 
                                    5
                                 
                              
                           , which means that the better performances of KEML algorithm in terms of PM values over the five selected data sets, compared to the other dimensionality reduction algorithms, are statistically significant.

The low-dimensional embeddings are then applied for early financial warning, which investigated the effectiveness of KEML, KPCA, LTSA, LMDS, ISOMAP, LLE, and PCA. For Chinese A-share stock market, “ST” or “*ST” will be put before the stock name of a company to warn about the investment risk or delisting risk when there is an abnormal financial condition.

The first stage of the experiment obtained the low-dimensional embeddings of the financial data using the seven algorithms. The K-means algorithm was used to identify companies with abnormal financial positions among these low-dimensional representations. We used the F
                           1
                           −
                           scores 
                           [12] to evaluate the result of each clustering. The F
                           1
                           −
                           scores combines recall (r) and precision (p) with an equal weight in the following form [12]:
                              
                                 
                                    
                                       
                                          F
                                          1
                                       
                                       
                                          r
                                          p
                                       
                                       =
                                       
                                          
                                             2
                                             rp
                                          
                                          
                                             r
                                             +
                                             p
                                          
                                       
                                       .
                                    
                                 
                              
                           
                        

Precision (p) is the ratio of correct assignments by the classifier divided by the total number of the classifier's assignments. Recall (r) is defined to be the ratio of correct assignments by the classifier divided by the total number of correct assignments. The greater F
                           1
                           −
                           score, the better performance of the algorithm is. Fig. 2
                            showed the F
                           1
                           −
                           scores (in percentages) about the clustering results of the seven algorithms on the five data sets, respectively.

It can be seen that KEML algorithm is superior to the other approaches. Similarly, T-test is conducted on the F
                           1
                           −
                           scores. The test results indicate that the hypothesis H
                           1 can be rejected at the level of 0.01 significance, which means the F
                           1
                           −
                           scores of KEML are all higher than the others. F
                           1
                           −
                           scores is called micro-averaging, which tends to be dominated by the classifier's performance on common categories [12].

The expected risk is defined as 
                              
                                 
                                    c
                                    1
                                 
                                 
                                    π
                                    1
                                 
                                 
                                    
                                       n
                                       1
                                    
                                    
                                       
                                          A
                                          1
                                       
                                    
                                 
                                 +
                                 
                                    c
                                    0
                                 
                                 
                                    
                                       1
                                       −
                                       
                                          π
                                          1
                                       
                                    
                                 
                                 
                                    
                                       n
                                       0
                                    
                                    
                                       
                                          A
                                          0
                                       
                                    
                                 
                              
                            
                           [45,46], where A
                           1 and A
                           0 are the sets of abnormal and normal companies in the experimental data, n
                           1 and n
                           0 are the numbers of misclassifications among abnormal and normal companies, π
                           1 is the prior probability of abnormal, and c
                           1 and c
                           0 are misclassification costs of abnormal and normal companies [46]. Altman [49] obtained 32≤
                           c
                           1/c
                           0
                           ≤62 when π
                           1
                           =0.016:0.03. In the experiment, the average percentage of abnormal companies is approximately π
                           1
                           =0.1:0.2, so we got 4≤
                           c
                           1/c
                           0
                           ≤9. Similar to [49], we set c
                           1/c
                           0
                           ≅6, and then the total error rate was 
                              
                                 0.51
                                 
                                    
                                       n
                                       1
                                    
                                    
                                       
                                          A
                                          1
                                       
                                    
                                 
                                 +
                                 0.49
                                 
                                    
                                       n
                                       0
                                    
                                    
                                       
                                          A
                                          0
                                       
                                    
                                 
                              
                           . The results were summarized in Table 4
                           .


                           Table 4 listed the error rates of all the clustering on the resulting low-dimensional embeddings in the first experiment. From the results about T-test, it can be seen that the hypothesis H
                           0 can be rejected, which means that the error rates of KEML (K-means) are lower than the others. KEML algorithm reflects the logical relationship between the financial data. Fig. 3
                            shows the results of KEML (K-means).

In Fig. 3, “×” represents an abnormal company, and “○” represents a normal company. In 2006 and 2007, the number of the abnormal companies was relatively small among the 205 small and medium companies. Starting in 2008, the number rapidly increased and reached the peak in 2009, while it decreased in 2010. In 2006 and 2007, due to the bubble economic expansion of China stock market, a large number of companies were prospered in the surface. In 2008, the financial crisis spread to China, a large number of companies had fallen into financial distress, even bankruptcy. In 2009, the impact of the financial crisis on China was sustained, which many companies were still in financial trouble. In 2010, the crisis was eased under the efforts of the Chinese government. The results of KEML (K-means) reflect the actual situation, which indicates the effectiveness of the KEML algorithm in predicting financial distress in the early stages.

The third stage of the experiment explored the intrinsic relationship structure of the financial data set, which explains and predicts the operational status of stock market. To further analyze the intrinsic structure, we visualized the topology of manifold and established corresponding three-dimensional mesh graphs according to the neighborhood relations obtained by the KEML algorithm. Fig. 4
                            showed the spatial topology logical relationships of data points. In Fig. 4, each data set represented a system. Red areas represent the abnormal composition.

From 2006 to 2008, the red part was increasing every year. From 2009 to 2010, this trend slows down, which confirmed the results of clustering analysis. These irregular structure charts were projected into the corresponding contour plots. We conducted a structural analysis for 2010 dataset. According to the properties of contour plot, data points in the same contour line have the same probability distribution. The distances between different contour lines represent the information divergence between different types of data points. A smaller interval between the contour lines represented a greater information divergence between the two types of data points. The red line represents the abnormal data points in the “Peak”, and the adjacent orange and yellow contours represent the corresponding data points might fall into crisis. In the contour plot of 2010 data set, the blue contour data sets increased much more than other datasets. And the overall distribution of the lines was no longer complex, which illustrates that the number of abnormal data points and the subsystem instability declined and the system tends to stabilize.

The ups and downs of terrains indicate that the system reached a state at this time after a dramatic evolution. Through a series of information change, each data set formed a stable intrinsic structure, which is center manifold. The KEML algorithm provides the information variation between data points and information evolving trajectories of the intrinsic structure. As shown in Fig. 5
                           , the horizontal axis represents the data points and the vertical axis represents the information change between points.

The figure showed that from 2006 to 2008, the information changes gradually increased and reached its peak in 2008. In 2009 and 2010, the magnitude of information change became weak. This indicates that the system had undergone dramatic internal oscillations from 2006 to 2008 and had tended to stabilized in 2009 and 2010. This overall trend can also be seen from the surface of the above three-dimensional mesh graphs. Through the complex information evolution, the system finally reached equilibrium.

This study uses Kolmogorov entropy (K entropy) to characterize this equilibrium state. Because each data set represented a system, K entropies for the five data sets could be obtained through Section 3.7, which reflected the chaotic degree of the systems. Fig. 6
                            showed the trend of the five K entropies and CSI 300 index during the period of 2006–2010.

In the information evolution, positive and negative information shift, severe vibration information changes did not mean that the final entropy value was greater. In 2008, the resulting entropy value was less than 2007. CSI 300 index describes the overall trend of China A-share market, which reflects an overview and running status of the stock price changes of China's securities market. As shown in Fig. 6, the K entropy increased from 2006 to 2007, and peaked in 2007, which means that the uncertainty and instability in the system increased rapidly. At the same time, the CSI 300 Index was peaked. In 2008, the global financial crisis spread to China while CSI 300 Index plummeted. After the crisis, the instability factors were partially removed and K entropy began to reduce. This can be confirmed from the above Fig. 6: the CSI 300 index gradually rose in 2009–2010. Thus, the KEML algorithm can help to forecast the overall trend of a stock market.

The experiment shows that the KEML algorithm is able to extract the objective logical relationships among financial data to improve the accuracy of the early financial warning. It can also derive the overall characteristics of the system, which provide the objective criteria for explaining and predicting the stock market volatility.

@&#CONCLUSION@&#

Based on the assumption that high-dimensional data lie approximately on a low-dimensional manifold embedded in the ambient space, this paper tried to discover the intrinsic manifold (or low-dimensional representation) in high-dimensional financial data by proposing a manifold learning algorithm for financial data.

Different from traditional manifold learning methods, KEML employs the information metric to measure the relationships between financial data points and yields reasonable and accurate low-dimensional embedding of the original financial data set. The results of the experiment indicate that the KEML algorithm outperforms other six dimensionality reduction algorithms in terms of accuracy of low-dimensional embedding. In the subsequent financial early warning experiment, the error rates of the clustering results generated by KEML were lower than the six other algorithms. The experiment further derived the Kolmogorov entropies, which characterize the system dynamical properties of the original data space. In comparison with CSI300 index, the Kolmogorov entropies obtained from the KEML algorithm can explain and predict the stock market volatility.

The theoretical and practical implications of this study are:
                        
                           (1)
                           Introduced kernel entropy manifold learning into financial analysis to explore and analyze the problems of financial field, and proved the effectiveness of the proposed algorithm through experiments.

The traditional manifold learning assumption is that high-dimensional data lie on a manifold in Euclidean space. Through the theoretical and empirical analyses, this study proved that this assumption may not be valid in financial data analysis.

There are several limitations in our approach, which need to be further investigated in the future. First, since the computational complexity of all the kernel-based techniques depends on the number of data points, the computational cost may increase a lot in our approach, when applied to large-scale data sets; Second, our approach may not adaptively extract features of the data set, and need to be extended to other fields, such as population analysis and biometrics, rather than restricted to financial datasets.

@&#ACKNOWLEDGMENTS@&#

This research has been partially supported by grants from the National Natural Science Foundation of China (#71222108), the Research Fund for the Doctoral Program of Higher Education (20120185110031), and Program for New Century Excellent Talents in University (NCET-10-0293).

@&#REFERENCES@&#


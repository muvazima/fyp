@&#MAIN-TITLE@&#Global structure constrained local shape prior estimation for medical image segmentation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Propose a novel target-oriented shape prior modeling method.


                        
                        
                           
                           Measure the intrinsic similarity between the target shape and the training shapes.


                        
                        
                           
                           Incorporate the shape model into an optimized search based segmentation method.


                        
                        
                           
                           Exhibit better performance than other existing methods.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Target-oriented shape modeling

Manifold learning

Manifold assumption

Medical image segmentation

@&#ABSTRACT@&#


               
               
                  Organ shape plays an important role in clinical diagnosis, surgical planning and treatment evaluation. Shape modeling is a critical factor affecting the performance of deformable model based segmentation methods for organ shape extraction. In most existing works, shape modeling is completed in the original shape space, with the presence of outliers. In addition, the specificity of the patient was not taken into account. This paper proposes a novel target-oriented shape prior model to deal with these two problems in a unified framework. The proposed method measures the intrinsic similarity between the target shape and the training shapes on an embedded manifold by manifold learning techniques. With this approach, shapes in the training set can be selected according to their intrinsic similarity to the target image. With more accurate shape guidance, an optimized search is performed by a deformable model to minimize an energy functional for image segmentation, which is efficiently achieved by using dynamic programming. Our method has been validated on 2D prostate localization and 3D prostate segmentation in MRI scans. Compared to other existing methods, our proposed method exhibits better performance in both studies.
               
            

@&#INTRODUCTION@&#

Medical image segmentation plays a crucial role in a wide range of applications, particularly in diagnosing diseases and evaluating the effects of therapy. Manual delineation is still used by radiologists, which, however, is a tedious and time consuming procedure. Thus, automatic segmentation methods are highly desired. A large number of different segmentation methods have been proposed in the past [12]. The existing methods can be roughly divided into two categories: low-level feature based methods such as region based [9] and boundary based [19], and high-level feature based methods like model based [12,13] and atlas based [31,16]. Nevertheless, due to various kinds of perturbing factors, such as noise, partial volume effect and missing information, medical image segmentation is still a challenging problem.

In recent years, model based segmentation approaches have been proven to be quite successful for medical image analysis [12]. Deformable model based segmentation turned out to be one of the most successful techniques for incorporating prior knowledge, which is widely used in medical image analysis [8,34,30]. This kind of approaches is more stable against local image artifacts and perturbation than the conventional low-level feature based algorithms. In other words, it is conducted in a top-down fashion because of containing high-level information such as shape and appearance of the structure of interest from a number of training shapes by statistical means.

A milestone in this direction is the active shape model (ASM) introduced by Cootes et al. [8]. Shape modeling is one of the most important factors affecting the accuracy of segmentation in deformable model based methods. Point distribution model (PDM) has been successfully used in modeling shape statistics [10]. PDM is a statistical approach, which is able to extract a compact representation from a set of training instances. In the framework of PDM, dimensionality reduction is an indispensable step in constructing a statistical shape model. In the existing works, most of them have employed linear learning techniques such as principal component analysis (PCA) [8].

PCA-like algorithms generally focus on a linearized shape space with small deformation modes around a single mean shape. Although successfully applied to various types of shapes (hands, faces, organs) [8], PCA may not always be able to generate shape prior suitable for the targeted structure for two reasons. Firstly, PCA is most useful in the cases, where all the shapes lie in or at least approximately in a linear subspace of the data set. Nevertheless, this assumption may be often violated by data obtained from the real-world. Secondly, PCA-like algorithms can only perform well when the learning shape set is composed of similar shapes.

To overcome the limitations imposed by the linearity requirement, a number of non-linear shape statistics learning methods were reported in the past decades. [23] proposed a hierarchical framework for shape clustering and statistics learning without using explicit models. The method was used for shape retrieval with improved efficiency. [26] presented a method for constructing a Riemannian manifold of curves for tracking deforming objects by prediction and filtering. By using a geometric metric in the space of curves, the manifold can be obtained and used for shape modeling. Those studies showed that shapes are embedded in a manifold structure, which can be efficiently used for shape modeling.

For parametric curves, the explicite manifold structure has been exploited for shape modeling. Srivastava et al. [24], Kurtek et al. [15], Younes et al. [32] presented methods for directly computing the geodesic paths over the manifolds using differential geometric techniques. Shape analysis based on those ideas was performed and improved results were demonstrated.

In stead of performing shape modeling in the original high-dimensional shape space, we look for a more compact representation of the shape model in a lower dimensional space by using the manifold learning techniques. There has also been some work on building non-linear statistical shape model in this direction. For example, Sozou et al. proposed non-linear PCA based on polynomial regression [21] and multi-layer perceptrons [22] for natural representation of variations based on bending and rotation. Twining and Taylor [29] employed Kernel PCA, which is more general than other methods. Etyngier et al. [11] tried to use diffusion maps as a framework for shape modeling. Owing to the limitation of diffusion maps, only shapes on the manifold composing a triangle around the target shape is used. In addition, the manifold assumption is not considered, which leads to the accuracy of shape prior estimation interfered by the “noise” shapes. Although the above methods consider the two limitations of PCA-like algorithms, they failed to exploit the specificity of the patient.

In this paper, our work combines the non-linear statistical shape model and the specificity of the patient to further improve the performance of segmentation. We propose a new segmentation method to estimate target-oriented shape prior. The contributions of our work are threefold:
                        
                           1.
                           A new target-oriented shape prior estimation method us proposed. We model a category of shapes as a smooth finite-dimensional sub-manifold of the infinite-dimensional shape space.

Considering the manifold assumption, shape prior is refined by the similarity of training images measured by the intensity information.

A new shape prior term for image segmentation through a non-linear energy term is introduced to attract a shape towards its projection onto the manifold.

The rest of the paper is organized as follows. In Section 2, the motivation of target-oriented shape prior model is presented. In Section 3, a novel target-oriented shape prior estimation method is proposed to improve the accuracy of the segmentation. In Section 4, the proposed shape prior estimation method is incorporated into a deformable model based framework for image segmentation. In Section 5, a series of experiments are conducted to validate the performance of the proposed method. The paper is concluded in Section 6.

@&#MOTIVATION@&#

Accurate shape prior estimation is one of the major factors affecting the accuracy of deformable model based segmentation methods. Target-oriented shape modeling on account of the speciality of the patient is a promising strategy for enhancing the accuracy. There are two ways to implement the target-oriented shape modeling. Ideally, target-oriented shape statistics should be used. However, such target-oriented model is barely available. An alternative solution is to increase the samples in the training set. In the machine learning area, it’s useful to improve the accuracy by increasing the number of samples in the training set. However, in our problems, it may not make sense. The larger number of samples in the training set may not always be the better, since the learned population-based shape statistics may generate “blurred” shape prior when segmenting an image of a particular subject. The reason is that the population-based shape statistics is getting “smoother” when the number of training samples is larger. That is, the population-based shape statistics lose specific information of the patient.

Therefore, it is meaningful to construct a subset, which contains the training samples similar to the target. The selected training shapes, which are similar to the target shape, can better approximate the target-oriented shape prior. Thus, the key problem is to select those shapes.

It is well known that in the original space images are disturbed by noise, clutter, low signal–noise ratio, etc. It is not sensible to compute the similarity between the training images and target in the original image space. Thus, we propose to do this in the feature space, which can reflect their intrinsic structure. A promising solution is to use manifold learning, which is a recently introduced approach to non-linear dimensionality reduction. The low-dimensional manifold can preserve the structure of data in essence, which can be seen as the feature space [33]. That is to say, the selection of similar shapes is more reliable in the low-dimensional manifold than in the image space. So the manifold learning is used to obtain the intrinsic structure of data in this paper. It is necessary to describe the manifold learning algorithms briefly. Then the motivation of using the manifold learning for shape prior estimation is explained.

Manifold learning algorithms are attracting more and more attention in various fields. Among the most recent and popular techniques, i.e., the Locally Linear Embedding (LLE) [20], ISOMAP [27], Laplacian eigenmaps [4], and diffusion maps [7], we focus on ISOMAP algorithm in this paper. ISOMAP, short for isometric feature mapping, was one of the first algorithms introduced for manifold learning. It may be viewed as an extension to multidimensional scaling (MDS), a classic method for embedding dissimilarity information into Euclidean space. Overall, ISOMAP returns an embedding, where the distance between points is approximately equal to the shortest path distance (on a graph defined on the near-neighbors in the original space). It automatically provides an estimate of the dimensionality of the underlying manifold. The reason why we use the ISOMAP algorithm is that it enjoys simple parameters setting, global optimum guarantee and fast computation speed.

The main steps of the ISOMAP algorithm are described as follows.
                           
                              1.
                              Compute the distance between all pairs of points (traditionally using the L
                                 2 norm distance).

Define the set of points which comprise the neighborhood. The typical way is one of the following:
                                    
                                       •
                                       
                                          k-nearest neighbors
                                       


                                          ∊-ball
                                       

Define a graph with a node for each input point and weighted undirected edges connecting each node to the nodes corresponding to the points. For each edge, the weight equals the corresponding distance between the input points.

Solve for all-pairs shortest paths on this sparse graph to calculate a complete pair-wise distance matrix.

Use MDS to find an embedding of these distances in Euclidean space.

ISOMAP obtains success in many non-linear dimensionality reduction problems. But some important assumptions can not be ignored because ISOMAP is guaranteed to recover the parameters of a manifold under these. We list the assumptions as follows [5]:
                           
                              1.
                              The manifold is isometrically embedded into R
                                 
                                    d
                                 .

The underlying parameter space is convex. Intuitively, the parameter space of the manifold from which we are sampling can not contain any holes.

The manifold is well sampled everywhere.

The manifold is compact.

Some previous work [20,27,4,7,11,5,28] showed that manifold learning is indeed a promising solution to the problem of the similar shapes selection as shown in Fig. 1
                        . However, the previous work ignored the validity of the manifold assumption about the coupled low- and high-dimensional manifolds (original shape space). According to the manifold assumption, the high- and low-dimensional manifolds generally share the common local geometry. However, such assumption is too strict to be directly used in practice. Fig. 2
                         shows the effect of manifold assumption on the shape prior estimation.

In Fig. 2, shapes corresponding to the data points are shown in the images. The shapes in the red dashed circle are the selected neighbors on the low-dimensional manifold by k nearest neighbors (k-NN) algorithm. It can be seen that several nearest neighbor shapes in the low-dimensional manifold are not very similar to the target shape, for example, those in the blue and green boxes. Those shapes in the blue and green boxes can be regarded as “noise” shapes. It means that neighboring shapes in the high-dimensional space may no longer be close to each other in the lower dimensional space. The reason why the “noise” points emerged in the low-dimensional manifold is that the data obtained from the real world may not always satisfy the manifold assumption.

The manifold assumption states that point-pairs from the original space share the local geometry with the corresponding low-dimensional manifold [17]. However, the one-to-multiple mapping from low-dimensional manifold to high-dimensional manifold makes neighbor reconstruction ambiguous and results in blurring and artifacts, which may largely influence accurate shape prior estimation and may generate “blurred” shape prior when segmenting an image of a particular subject [17]. The reason is that the one-to-multiple mapping from low-dimensional manifold to high-dimensional space makes the points selected by k-NN algorithm on low-dimensional manifold non-local in high-dimensional space. Thus, the structure of natural data makes the manifold assumption invalid.

According to the above analysis, we elaborate on the structure-constrained target-oriented shape prior estimation algorithm in this section. The point distribution model (PDM) used in our work is a statistical approach, which has the ability to extract a compact representation from a set of training instances. In PDM, each planar shape is represented by n 2D points as the vector S
                     =(x
                     1,
                     y
                     1,…,
                     x
                     
                        n
                     ,
                     y
                     
                        n
                     )
                        T
                     . Thus, each shape is considered as a point in the 2n dimensional space. In our work, the landmark points are obtained by sampling the contour equally Euclidean distance spaced. Those shapes are then aligned together using rigid transformation to set up the correspondence. Each 2n dimensional shape vector is then mapped to m dimensional manifold for shape learning and prior estimation, where m
                     ≪2n.

Since the proposed segmentation method works iteratively, an initial segmentation is required. In our work, the initial 3D segmentation, denoted by X
                     0, is generated by applying the 2D deformable model separately on each slice.

The structure-constrained shape manifold is constructed as follows:
                        
                           1.
                           Project the training set shape samples {S
                              
                                 i
                              } and the initial shape X
                              0 into the manifold subspace via ISOMAP. The corresponding projections are denoted by {s
                              
                                 i
                              } and the initial shape x
                              0.

Construct the adjacent graph on the low-dimensional manifold. Let G denote a graph with n vertices. Find the geodesics (the shortest paths on the graph) between all pairs of vertices by Dijkstra’s algorithm. The distance between the initial segmentation and the ith shape in the learning set is
                                 
                                    (1)
                                    
                                       
                                          
                                             d
                                          
                                          
                                             i
                                          
                                       
                                       =
                                       g
                                       (
                                       
                                          
                                             s
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             0
                                          
                                       
                                       )
                                       ,
                                    
                                 
                              where g is the length of the shortest path. In our experiments, the Euclidean distance between all pairs of vertices on the shape manifold is a substitute for geodesic distance owing to the limited sample number.

Compute the similarity between the training images and the target image in the image space for providing neighbor selection guidance. In our work, Normalized Mutual Information (NMI) [14] is used to measure the similarity between the training images and the test image. Let I
                              
                                 i
                               denote the similarity between the ith training image and the test image. This can help to satisfy the manifold assumption.

Compute the overall distance measurement matrix as
                                 
                                    (2)
                                    
                                       
                                          
                                             D
                                          
                                          
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             d
                                          
                                          
                                             i
                                          
                                       
                                       +
                                       α
                                       (
                                       1
                                       -
                                       
                                          
                                             I
                                          
                                          
                                             i
                                          
                                       
                                       )
                                       H
                                       (
                                       
                                          
                                             I
                                          
                                          
                                             i
                                          
                                       
                                       -
                                       
                                          
                                             I
                                          
                                          
                                             t
                                          
                                       
                                       )
                                       ,
                                    
                                 
                              where α is a positive weighting parameter and H(x) is a step function of
                                 
                                    (3)
                                    
                                       H
                                       (
                                       x
                                       )
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         0
                                                         ,
                                                      
                                                      
                                                         if
                                                         
                                                         x
                                                         <
                                                         0
                                                         ,
                                                         
                                                         and
                                                      
                                                   
                                                   
                                                      
                                                         1
                                                         ,
                                                      
                                                      
                                                         if
                                                         
                                                         x
                                                         ⩾
                                                         0
                                                         .
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           

According to the above equation, the similarity between the ith training image and the test image based on intensity information is only considered, if it is greater than a certain threshold I
                              
                                 t
                              . In our experiments, the threshold I
                              
                                 t
                               is set to be the mean value of the similarity between the training images.

By using the learned manifold, the shape prior for an image to be segmented is estimated by choosing a certain amount of training shapes, which are closest to the currently obtained shape. Let 
                                 
                                    N
                                    (
                                    
                                       
                                          x
                                       
                                       
                                          0
                                       
                                    
                                    )
                                 
                               denote the neighborhood containing the kNNs of a shape x
                              0 on the learned manifold. The shape X
                              0 can then be represented by a weighted convex combination of the shapes in 
                                 
                                    N
                                    (
                                    
                                       
                                          x
                                       
                                       
                                          0
                                       
                                    
                                    )
                                 
                              . The reconstruction weight for each shape x
                              0 (the projection of X
                              0 on the low-dimensional manifold) is given by
                                 
                                    (4)
                                    
                                       
                                          
                                             w
                                          
                                          
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             e
                                          
                                          
                                             
                                                
                                                   -
                                                   
                                                      
                                                         D
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                                
                                                   σ
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              where the normalization parameter σ is set in the experiments. The shape in the high-dimensional space is computed using high-dimensional features of the k nearest neighbors and the reconstructed weights [6]. The estimated shape prior is given by
                                 
                                    (5)
                                    
                                       
                                          
                                             
                                                
                                                   X
                                                
                                                
                                                   ^
                                                
                                             
                                          
                                          
                                             0
                                          
                                       
                                       =
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                k
                                             
                                          
                                       
                                       
                                          
                                             w
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             S
                                          
                                          
                                             N
                                             (
                                             
                                                
                                                   x
                                                
                                                
                                                   0
                                                
                                             
                                             )
                                          
                                       
                                       ,
                                    
                                 
                              where 
                                 
                                    
                                       
                                          
                                             
                                                X
                                             
                                             
                                                ^
                                             
                                          
                                       
                                       
                                          0
                                       
                                    
                                 
                               can be linearly reconstructed in terms of its neighbors 
                                 
                                    N
                                    (
                                    
                                       
                                          x
                                       
                                       
                                          0
                                       
                                    
                                    )
                                 
                               with corresponding weight w
                              
                                 i
                              .

As described in the above steps, when H returns 0, the shape prior estimation does not take the manifold assumption into account. It only selects the most similar shapes on the low-dimensional manifold by the shape similarity. When H returns 1, this method is called as Low-dimensional Target-oriented Shape Prior estimation Model (LTO-SPM). The method introduces the similarity of training images based on intensity to suppress the ‘noise’ shape, called as Structure-constrained Target-oriented Shape prior estimation Model (SCTO-SPM). It is obvious that LTO-SPM method is a special case in SCTO-SPM method.

Not only considering shape prior on the low-dimensional manifold, but also integrating the similarity of the training images in the image space, the pseudo-codes of SCTO-SPM are listed below,
                        Algorithm 1
                        
                           Structure-constrained Target-oriented Shape Prior Estimation (SCTO-SPM)
                           
                              
                                 
                                    
                                    
                                       
                                          
                                             Objective: Estimate target-oriented shape prior.
                                       
                                       
                                          
                                             Input:
                                       
                                       
                                          
                                             
                                                
                                                   *
                                                   Training shapes {S
                                                      
                                                         i
                                                      };
                                                
                                                
                                                   *
                                                   Initial segmentation X
                                                      0;
                                                
                                                
                                                   *
                                                   Neighbor size k;
                                                
                                                
                                                   *
                                                   Penalty parameter M.
                                                
                                             
                                          
                                       
                                       
                                          
                                             Output: Target-oriented shape prior.
                                       
                                       
                                          
                                             
                                                
                                                   1.
                                                   Compute the average or median values of the similarity between all training images.
                                                
                                                
                                                   2.
                                                   Project the training shapes {S
                                                      
                                                         i
                                                      } and the initial segmentation X
                                                      0 into the feature subspace via ISOMAP algorithm.
                                                
                                                
                                                   3.
                                                   Construct the adjacent graph by Euclidean distance, 
                                                         
                                                            (6)
                                                            
                                                               
                                                                  
                                                                     d
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               =
                                                               ‖
                                                               
                                                                  
                                                                     s
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               -
                                                               
                                                                  
                                                                     x
                                                                  
                                                                  
                                                                     0
                                                                  
                                                               
                                                               
                                                                  
                                                                     ‖
                                                                  
                                                                  
                                                                     2
                                                                  
                                                               
                                                               .
                                                            
                                                         
                                                      where s
                                                      
                                                         i
                                                       and x
                                                      0 denote the lower dimensional data points corresponding to the shapes {S
                                                      
                                                         i
                                                      } and X
                                                      0 after manifold projection.
                                                
                                                
                                                   4.
                                                   The similarity between S
                                                      
                                                         i
                                                       and X
                                                      0 is measured by the distance, which is shown in Eq. (2).
                                                
                                                
                                                   5.
                                                   Compute the optimal weight w
                                                      
                                                         i
                                                       by minimizing the root mean square error, 
                                                         
                                                            (7)
                                                            
                                                               
                                                                  
                                                                     w
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               =
                                                               
                                                                  
                                                                     e
                                                                  
                                                                  
                                                                     
                                                                        
                                                                           -
                                                                           
                                                                              
                                                                                 D
                                                                              
                                                                              
                                                                                 i
                                                                              
                                                                           
                                                                        
                                                                        
                                                                           σ
                                                                        
                                                                     
                                                                  
                                                               
                                                               .
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   6.
                                                   Construct target-oriented shape prior. The shape in the high-dimensional space is computed using appropriate high-dimensional features of the k nearest neighbors and the reconstructed weights [6], 
                                                         
                                                            (8)
                                                            
                                                               
                                                                  
                                                                     
                                                                        
                                                                           X
                                                                        
                                                                        
                                                                           ^
                                                                        
                                                                     
                                                                  
                                                                  
                                                                     0
                                                                  
                                                               
                                                               =
                                                               
                                                                  
                                                                     
                                                                        ∑
                                                                     
                                                                     
                                                                        i
                                                                        =
                                                                        1
                                                                     
                                                                     
                                                                        k
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     w
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               
                                                                  
                                                                     S
                                                                  
                                                                  
                                                                     N
                                                                     (
                                                                     
                                                                        
                                                                           x
                                                                        
                                                                        
                                                                           0
                                                                        
                                                                     
                                                                     )
                                                                  
                                                               
                                                               .
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

The complete segmentation process is presented in this section. As shown in Fig. 3
                     , the proposed SCTO-SPM is incorporated into a deformable model based segmentation framework for medical image segmentation. This framework is illustrated by using 3D data. For 3D data, each element in the training set is a sequence of medical images of a patient and the testing data is also a sequence of slices.

Our proposed target-oriented shape prior model is an iterative approach. At the beginning of each iteration, the contours are first deformed according to the image force. Each landmark is moved along the normal direction of the contour to search for the prostate boundary. After that, the new contour will be constrained by the shape model to get the segmentation result for the current step. Thus, both the image force and the shape model contribute to the segmentation. In the first iteration, the shape of the target is unknown. Under this circumstance, the mean shape is a suitable choice for initialization. In our work, the mean shape is generally close to the true boundary. By searching for the boundary along the normal directions, the true boundary is usually inside the search range.

During the segmentation process, the complete 2D deformable model based segmentation is performed on each slice. For each iteration, the initial segmentation result and training shapes are first mapped to an embedded lower-dimensional manifold, where only the main non-linear local variation between the shapes is preserved. Then, in the low-dimensional manifold, the closest training shapes to the obtained object contour are retrieved. By computing the weighting coefficients of the neighbors for approximating the projected shape in the low dimensional space, a target-oriented shape prior can be generated by combining the corresponding training shapes in the high-dimensional shape space using the same coefficients. Under the guidance of 3D shape prior that is seen as initialization of 2D shape instance, 2D deformable model is employed to segment a series of MR images of the patient for extracting surfaces. The above-mentioned steps will be repeated until a satisfactory result is obtained.

In our work, the initialization of the segmentation is performed by putting the mean shape on each of the corresponding slices. The mean shape is obtained by averaging the corresponding training shapes. After that, the iterative segmentation process begins.

For performance comparison, the LTO-SPM was also applied to segmenting the prostate. LTO-SPM is a special case of SCTO-SPM method when the step function H(x) returns 0. The LTO-SPM method is illustrated in Fig. 4
                     .

The deformable model employed in our work has two terms in its energy functional.
                        
                           (9)
                           
                              E
                              =
                              
                                 
                                    E
                                 
                                 
                                    image
                                 
                              
                              +
                              
                                 
                                    E
                                 
                                 
                                    shape
                                 
                              
                              ,
                           
                        
                     where E
                     
                        image
                      represents the variation of image appearance which is the same as ASM [8]. It relies mostly on the image boundary information as in [13]. The image gradients are computed and locations with large gradient magnitude suggest the possible presence of boundary. In the above equation, E
                     
                        shape
                      denotes the energy of constrained shape from training images. The segmentation is achieved by minimizing the above energy in an iterative way.

The energy functional is the same for the LTO-SPM and SCTO-SPM methods. Each iteration consists of two steps to minimize the image energy E
                     
                        image
                      and shape energy terms E
                     
                        shape
                     , respectively. The two steps are described in detail as follows.
                        
                           •
                           Image energy minimization
                                 
                                    1.
                                    Examine a region of the image around each landmark point S
                                       
                                          i
                                        to find the most possible location for point 
                                          
                                             
                                                
                                                   S
                                                
                                                
                                                   i
                                                
                                                
                                                   ′
                                                
                                             
                                          
                                       .

Update the parameters (X
                                       
                                          t
                                       ,
                                       Y
                                       
                                          t
                                       ,s,θ) to fit the newly deformed S.

In practice, we look along the normal directions of the contour at each landmark point for the object boundary. S is a shape vector containing n landmark points. The parameters (X
                              
                                 t
                              ,
                              Y
                              
                                 t
                              ,
                              s,
                              θ) are called initial parameters representing x-axis shift (right), y-axis shift (down), scale, rotation. The initial parameters should be set by the user at the beginning. The setting of the parameters is discussed later in Section 5.

Shape energy minimization
                                 
                                    1.
                                    Map the current contour X
                                       
                                          j
                                        obtained at the jth iteration to the same low-dimensional manifold.

Compute the Euclidean distance between each training shape and 
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         ˆ
                                                      
                                                   
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       .

Select training shapes according to X
                                       
                                          j
                                        using kNN algorithm on the adjacent graph with considering the similarity of the images based on intensity information in the image space.

Project the results from Step 3 onto the original image space and apply Eq. (8) to achieve 
                                          
                                             
                                                
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         ^
                                                      
                                                   
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       .

@&#EXPERIMENTS@&#

In our experiments, the performance of the proposed method is evaluated on the prostate images. The 2D experiment data consists of 42 MR images of the prostate. Each image contains 512×512pixels, with the pixel size of 0.3;×0.3mm. Manual segmentation of the images obtained by a radiologist was considered as the ground truth for evaluation. The leave-one-out strategy was employed for evaluating the performance of the algorithms.

For quantitatively evaluating the performance of the automatic segmentation methods, the mean absolute distance (MAD) error and the dice similarity coefficient (DSC) were employed. Let p
                           
                              i
                            and 
                              
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                              
                            denote the ith contour point from the segmented contour and the ground truth, respectively, which are sampled by spaced distance. The MAD is defined as
                              
                                 (10)
                                 
                                    MAD
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          n
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                    
                                    ‖
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    -
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                       
                                          ′
                                       
                                    
                                    ‖
                                    ,
                                 
                              
                           where n is the number of sample points of each contour. In order to determine that how much variation exists in the segmentation results for a particular image sequence, the standard deviation of the distance error is also computed as
                              
                                 (11)
                                 
                                    STD
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          n
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             j
                                             =
                                             1
                                          
                                          
                                             N
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                n
                                             
                                          
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                n
                                             
                                          
                                          (
                                          
                                             
                                                d
                                             
                                             
                                                ji
                                             
                                          
                                          -
                                          
                                             
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      ¯
                                                   
                                                
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                    
                                    ,
                                 
                              
                           where d
                           
                              ji
                            is the absolute distance error of the ith contour point in the jth image of the patient and 
                              
                                 
                                    
                                       
                                          
                                             d
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                            is the MAD error of the j image.

The evaluation criterion of DSC is defined as follows:
                              
                                 (12)
                                 
                                    DCS
                                    (
                                    A
                                    ,
                                    B
                                    )
                                    =
                                    
                                       
                                          2
                                          |
                                          A
                                          ∩
                                          B
                                          |
                                       
                                       
                                          |
                                          A
                                          |
                                          +
                                          |
                                          B
                                          |
                                       
                                    
                                 
                              
                           where A is the ground truth image, B is the result of an automatically segmented images, and ∣·∣ denotes the area of the target region. The DSC value varies between 0 and 1. A higher value indicates a better segmentation.

In our experiments, the deformable contour has n
                           =64 contour points. The segmenting processing contains two stages: first, the target-oriented shape statistics is computed; second, the deformation are performed on the deformable contour obtained from the first stage. In the first stage, three parameters affect the accuracy of shape prior estimation. The first one is the parameter k (the number of closest shape manifold). The value of the parameter k chosen in our experiments is based on the statistical result as shown in Fig. 5
                           . It can be seen that the value of 15 is most suitable for our experiments from the Fig. 5. The second is the parameter σ (the constant parameter of heat kernel). The value of σ is also based on our experiments as shown in Fig. 6
                           . The value of 1.4 is the most suitable constant for our experiments. The third is the image similarity threshold parameter I
                           
                              t
                           , whose value was set to be 10 on the basis of the experimental result as shown in Fig. 7
                           .

In the second stage, the initial parameters affect the accuracy of segmented results. Owing to the difference of shapes in the size, orientation and so on, it is difficult to set the same initial parameters for all images, such as (X
                           
                              t
                           ,
                           Y
                           
                              t
                           ,
                           s,
                           θ). (X
                           
                              t
                           , Y
                           
                              t
                           ,
                           s,
                           θ) represent x-axis shift (right), y-axis shift (down), scale, rotation, respectively. The traversal of the initial parameters is employed. The range of these parameters are set to be [−30,30], [−30,30], [0.9,1.1], [−1,1], respectively, which are based on empiric. The terminal condition is that the changes of segmented result between segmentations are less than the threshold, which is set to 0.5mm. From the above description, it can be seen that the segmented result is locally optimal and the globally optimal result are most probably obtained after several iterations. In our experiments, five iterations of deformable segmentation were performed for each image. It is reasonable to compare the final segmented results of our proposed method to other existing methods on the same condition.

The proposed method was implemented in Matlab and took about 60s to segment a 512×512 image on a 3.0GHz Intel PC with 2GB RAM.

Before discussing the segmentation result, it is necessary to interpret the comparative methods. High-dimensional Target-oriented Shape Prior estimation Model (HTO-SPM) method is that the shape prior is estimated in the high-dimensional image space through selecting k nearest neighbors, then is incorporated in the deformable model based segmentation method. The LTO-SPM method is different from the HTO-SPM method on that the shape prior estimation is done in the low-dimensional manifold. Our method includes the LTO-SPM method and SCTO-SPM method, where the LTO-SPM method is a special case in the SCTO-SPM method.

To demonstrate the performance of the proposed method, we apply the methods to segment prostate MR images. As shown in Fig. 8
                           , the segmentation performance has been significantly improved after target-oriented shape statistics was applied, compared with ASM method and HTO-SPM method. The reason is that the target-oriented shape statistics estimate the shape prior accurately for the training set and shape statistics are built according to individual characteristics. It can be observed that the SCTO-SPM method gives the best result for taking the manifold assumption into account. The reason is that the similarity of the training images can help suppressing or eliminating the irrelevant shapes.

The MAD error was computed for all the methods. The quantitative evaluation results are shown in Table 1
                           . It shows that the SCTO-SPM obtained the best results in almost all the cases compared to other methods. When taking a closer look, it can be seen that SCTO-SPM performed better than LTO-SPM and the latter performed better than HTO-SPM. It suggests that the shape prior estimation in the low-dimensional manifold is a promising method, since the low-dimensional manifold can better reflect the intrinsic similarity than the original high-dimensional space. In all those methods, ASM performed the worst. The most important reason is that the ASM method uses PCA to linearly model the shape statistics.

Among the non-linear modeling based methods, the performance of the proposed SCTO-SPM method is superior to that of Etyngier’s method [11], since only shapes on the manifold composing a triangle around the target shape is used. In other words, the shape selection in the low-dimensional manifold is constrained in a triangle, which is constructed by diffusion maps. The result of SCTO-SPM method is better than that of LTO-SPM method, where the MAD of SCTO-SPM was 5.076 pixels (1.523mm) compared with 5.219 pixels (1.566mm) of LTO-SPM method. The result indicates that the image data obtained from the real world may not always meet the manifold assumption. The similarity between the training images is useful to guide the shape prior estimation in the low-dimensional manifold, as the influence of outlier shapes may be eliminated or suppressed for shape prior estimation.

Furthermore, the dice similarity coefficient (DSC) is computed quantitatively compared our proposed methods with ASM and HTO-SPM method as shown in Fig. 9
                           . It can be seen that although the mean value of LTO-SPM method is a little higher than the HTO-SPM method, LTO-SPM method has higher variance than HTO-SPM method. This is because LTO-SPM method assumes that the natural data meet the manifold assumption. As a matter of fact, it does not always make sense, so the negative contribution of the ‘noise’ shapes to the shape prior estimation affects the robustness of the algorithm to some extent. The SCTO-SPM method reduces the above-mentioned problem, so the mean and deviation value of it outperform than the other methods except the Etyngier’s method. It can be seen that the performance of the Etyngier method and the SCTO-SPM method is almost the same. However, with the number of sample increasing, our proposed SCTO-SPM method will outperform than the Etyngier’ method for only shapes on the manifold composing a triangle around the target shape is used to construct the target-oriented shape in Etyngier’s method.

Recently, some researches focused on the 3D deformable model based segmentation. In this framework, their work can be divided into two cases. Some studies have built statistical model directly from 3D training data sets [18,25,2,3,1]. Most of these developments have focused on landmark generation and model construction. Owing to the impractical 3D manual landmarking and non-dense 3D data in the real world, Zhu et al. [34] proposed a hybrid ASM approach. The essential idea of Zhu’s work contains two aspects. First, the 2D deformable model is performed on each slice to get 2D optimization on individual slice. Second, for the sake of obtaining the anatomical boundary of the complete 3D target, the 3D shapes can be constructed from 2D contours using a 3D shape model. Our proposed SCTO-SPM is incorporated into the 3D segmentation framework of Zhu’s method.

In our experiments, the performance of the proposed method is evaluated on the prostate gland MRI sequences. The experiment data consists of 42 prostate gland MRI sequences, totaling 42×26 slices. Each slice contains 512×512pixels, with the pixel size of 0.3mm×0.3mm. Each slice is 0.5mm thick and has 3mm interslice gap. All the images were annotated by an expert radiologist, which were considered as gold standard for validation. The contour of each slice is represented by 64 landmarks.

To evaluate the performance of the proposed method, we apply the proposed method to segment prostate MR images. Zhu’s method [34] and HTO-SPM method are included for comparison. Using target-oriented shape statistics can get better segmentation result as shown in Fig. 10
                           . The segmentation performance has been significantly improved after target-oriented shape statistics was applied compared with other two methods. The reason is that the target-oriented shape statistics estimate the shape prior accurately for the training set and shape statistics are built according to individual characteristics.

The mean absolute distance (MAD) is calculated to evaluate the performances of respective methods quantitatively, which is tabulated in Table 2
                           . We can see that our proposed method is superior or competitive to the ASM and HTO-SPM method. The reason is that our proposed method use the similarity of the training images based on intensity information to eliminate or suppress the “noise” shapes which are brought by the manifold assumption.

@&#CONCLUSION@&#

In this paper, we proposed a structure-constrained target-oriented shape prior model to model shape priors. Our proposed method is incorporated into a model based segmentation framework for medical image segmentation, which can refine the target shape through iterations. The framework is extensively validated on 2D prostate and 3D prostate MR images. Compared with other methods, our shape prior model exhibits better performance in both studies.

In the future, we plan to apply this model to more segmentation tasks especially the direct 3D segmentation of anatomical structures. From the above segmentation results, it can be seen that in the midgland of the prostate, the algorithms is very effective.

@&#ACKNOWLEDGMENTS@&#

This work is supported by the National Basic Research Program of China (973 Program) (Grant No. 2012CB719905) and by the National Natural Science Foundation of China (Grant Nos: 61125106, 61172142, 91120302, and 61072093).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Real-time lossless compression of microarray images by separate compaction of foreground and background

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This research is in the field of hardware based image processing. Even though microarray images are the base of this work but the algorithm has many other applications.


                        
                        
                           
                           The main idea is to separate foreground from background in images that such situation exist.


                        
                        
                           
                           With growing concern in the era of “big data” about the storage space, sharing, and transmission of bio-medical imagery, the proposed strategy could have other applications too.


                        
                        
                           
                           Most CT and digital x-ray images contain vast areas of background. The mentioned foreground/background separation could have application for such images.


                        
                        
                           
                           Hardware compression of microarray images is just an example of big data applications.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image compression

High content screening

Microarray

Hardware implementation

@&#ABSTRACT@&#


               
               
                  Microarray technology is a powerful tool in molecular biology which is used for concurrent monitoring of a large number of gene expressions. Each microarray experiment produces hundreds of images. In this paper, we present a hardware scheme for lossless compression of 16-bit microarray images. The most significant parts of the image pixels are compressed by classifying them into foreground and background regions. This increases the spatial redundancy of the image. The foreground regions are packed together using a novel compaction unit. Real-time compression of these images is achieved while the bit-per-pixel values are comparable with the standard offline compression tools.
               
            

@&#INTRODUCTION@&#

During the past two decades the field of molecular genetics has attracted growing interest of scientists. Biomedical research evolves and advances not only through the compilation of knowledge but also through the development of new technologies. Using traditional methods to assay gene expression, researchers were able to survey a relatively small number of genes at a time. The emergence of microarray technology has enabled researchers to address previously intractable problems and to uncover novel potential targets for therapies. Microarrays allow scientists to analyze expression of many genes in a single experiment quickly and efficiently. They represent a major methodological advance and illustrate how the advent of new technologies provides powerful tools for researchers. Scientists are using microarray technology to try to understand fundamental aspects of growth and development as well as to explore the underlying genetic causes of many human diseases [1,2].

A sample gray scale microarray image is shown in Fig. 1
                     . The size of this sample image is 455×455pixels. In microarray images, the regions of interest are the subset of pixels that correspond to the spots (the foreground). The spots are approximately circular but significant variations are possible due to experimental fluctuations in the spotting procedure. Perturbations on the spot position, irregularities in the spot shape and size, holes in spots, unequal distribution of the probe within spots, variable background and global problem that affect multiple spots (like scratches, contamination, and dust) are common. In general, the shape and the size of the spot can fluctuate significantly across the array. The background is usually much less crucial for the downstream image processing step, although it is used as a reference for background correction operations [3,4]. Each microarray experiment produces thousands of images. Microarray images are large in size and also each experiment is costly. Various organizations share their microarray databases. For efficient storage and for sharing a large number of these images, image compression is essential [5,6].

Compression of microarray images could be done by using lossless or lossy methods. Even though compression ratios of lossless methods are less than those of lossy methods, for biomedical applications lossless methods are the more appropriate choice.

In microarray images, the intensity level of each spot contains important information about the gene expression. Thus, to preserve the intensity and the size of the spots the lossless compression schemes are more suitable. Several compression methods have specifically been proposed for the microarray images. Most of these algorithms are software based while a number of them have been realized by hardware.

The method that Jornsten et al. [7] have proposed performs gridding of the whole image at the beginning and then the spots are segmented. The segmentation of the spots is achieved by using the approximate center of each spot and a seeded region growing procedure followed by a two-component Gaussian mixture model. The segmentation mask is encoded using chain-coding and the interior of the regions is encoded using a modified version of the LOCO-I (LOw COmplexity LOssless COmpression for Images) algorithm. Hence the algorithm is called SLOCO.

Hua et al. [8] proposed a method called BASICA (Background Adjustment, Segmentation, Image Compression and Analysis). The algorithm is based on wavelet transformation. Initially, a segmentation is performed using the Mann–Whitney algorithm, and the segmentation mask is encoded separately. The wavelet-transforms of the foreground and the background are formed separately and the wavelet coefficients are coded using object-based EBCOT (Embedded Block Coding Optimized Truncation). It is possible to code the background in a lossy manner while the foreground is losslessly compressed.

Faramarzpour et al. [9] proposed a software-based lossless compression method. Their method isolates each spot into an individual region of interest. A spiral path is fit on each spot such that its center coincides with the center of mass of the spot. The idea is to convert the 2D structure of the image into a 1D sequence which can scan the image in a highly correlated manner while preserving its spatial continuity. It is expected that the DPCM coding of this one dimensional signal possesses low entropy. Then, predictive coding is applied along this path, with a separation between residuals belonging to the foreground area and those belonging to the background area.

Lonardi and Luo [10] proposed lossless and lossy compression algorithms for microarray images (MicroZip). The method uses a fully automatic gridding procedure, similar to that of Faramarzpour's method, for separating spots from the background (which can be lossy compressed). Through segmentation, the image is split into two channels: foreground and background. Then, for entropy coding, each channel is divided into two 8 bit sub-channels and arithmetic encoded, with the option of being previously processed by a Burrows–Wheeler transform.

The method presented by Zhang [11] performs lossless compression of microarray images. This method uses a known spot segmentation procedure [12] to categorize pixels into foreground and background sets. Compression is then performed separately on each set. Each pixel value is considered as consisting of a MSB part and a LSB part. A prediction step is performed on the MSB part of the pixels. Then PPAM (Prediction by Partial Approximation Matching) compression algorithm is used on the predicted MSB parts and the LSB parts of the foreground and the background, separately.

Reference [13] presents a lossless method for compression of microarray images based on arithmetic coding using a 3D context model. The 3D context modeling is performed on consecutive bit-planes of an image. The compression starts from the MSB plane and works its way toward the LSB plane. In each plane the modeling of each bit is performed using its neighboring bits and the corresponding bit from the previous compressed plane. In [14,15] the lossless method of [13] is improved. In the improved version, for each plane a context is defined based on the causal neighbors in the current plane and non-causal neighbors in the previous plane. Then the current bit, based on the mentioned contexts, is coded using arithmetic coding.

The algorithm presented in [16] is a lossless image compression method which segments the pixels of the image into three categories of background, foreground, and spot edges. The segmentation is performed by finding a threshold value which minimizes the weighted sum of the standard deviations of the foreground and background pixels. Each segment of the image is compressed using a separate predictor.

It has been shown that the quality of DNA microarray data has high variations. Before using the images for biological purposes, usually, extensive gridding and image processing algorithms are needed. Hence, hardware implementations of these algorithms have been proposed to speed up the lengthy software procedures. In [17] cellular neural networks (CNNs) are employed, for microarray image analysis, in a dedicated machine called the CNN universal machine. In [18] two pipeline architectures are proposed for the lossy microarray image compression. The image is first processed and through morphological operations noise and very small spots are eliminated. For compression purposes they process the pixels of the image in a raster scan order. In the first architecture, “pseudo-RLE” method is applied and in the second architecture, “residual Huffman coding” method is used for the compression of images. In the residual Huffman coding method, codes are calculated for the difference between every two neighboring pixels. In [19] a lossy compression scheme is applied which uses real-time techniques. In their method the microarray image is first processed to get an all-zero background. By doing so, relatively high compression ratios were obtained. The main purpose of hardware schemes of [18] and [19] is real-time processing of microarray images. The compression part of these schemes uses simple methods that work on previously processed images with backgrounds that are free of noise. Hardware image compression schemes do exist for many different applications, such as [20], which are proposed for lossy compression of images in a camera sensor networks. Such designs cannot be used for biomedical imagery where changing of pixel values is not tolerable.

The motivation behind the hardware that is proposed in this paper is that right now hardware solutions have been proposed to speed up the complex and time consuming gridding of the microarray images [21]. Also, to speed up the analysis of these images hardware implementations have been employed [18,19]. The last stage in the life cycle of microarray images, before storing them, is their compression. Hence, in this paper we are proposing a hardware solution for the compression of microarray images to complement the existing hardware mechanisms of gridding and analysis. Even though the technology of microarray is a relatively mature one, it is a part of the growing high content screening (HCS) technology [22]. High-throughput cell-based screening has become a field of interest because it allows the advent and test of new drugs in extremely fast pace. Microarrays, fluorescent microscopy, RNAi (RNA interference), and a number of related tools are giving researchers a clear view of cellular activities and a means of creating new drugs [22]. The hardware solutions that are being proposed are needed remedies due to the high-throughput nature of the technologies. Furthermore the hardware solutions that are proposed for the microarray images are all applicable, with modifications, to other HCS technologies.

We propose to perform a classification on the most significant 8 bits of the pixels. The least significant part of the pixels is not compressed. The proposed hardware first classifies the significant part of the image into the foreground and background regions. The classification is done by an efficient thresholding scheme. The foreground pixels, the segmentation map and the background pixels are separately packed by a proposed compaction block. By separate treatment of the foreground and background pixels better exploitation of correlations is possible. The packing, the DPCM prediction, and the entropy coding of each group of pixels are performed by dedicated circuitries. The bit-per-pixel values, which the proposed hardware produces, are comparable with some of the standard compression routines. A part of the proposed hardware, called the compaction unit (CU), could be used in applications such as implementation of the run length encoding (RLE).

The organization of the paper is as follows. The proposed compression method and the thresholding scheme are explained in Section 2. In Section 3 of the paper the proposed architecture is introduced. There, a pipeline structure is presented which receives one line of an image and by sending it through different stages compresses that line. Simulation results are presented in Section 4 where results from different algorithms are compared with those of the proposed method. Finally, concluding remarks are offered in Section 5.

@&#PROPOSED METHOD@&#

In our proposed compression scheme we start by converting the image I into two parts of I
                     
                        H
                      and I
                     
                        L
                     . The I
                     
                        H
                      part consists of the most significant 8 bits of the pixels of I and I
                     
                        L
                      is the remaining low significant part of the image. Our scheme is basically concentrated on I
                     
                        H
                      and we only transmit the I
                     
                        L
                      part.

It has been shown that, usually, the I
                     
                        L
                      of cDNA microarray images does not possess inter-pixel correlations and prediction methods do not help their compression [6]. Therefore, application of elaborate predictive methods or context modeling would not improve their compression. On the other hand, the I
                     
                        H
                      part of these images has high inter-pixel correlation which can be exploited by simple DPCM prediction.

Segmentation of the microarray images is one of the essential steps in the processing of these images. The obtained genetic results are directly affected by the performance of the segmentation step. Methods such as fix circle, adaptive circle, adaptive shape, histogram-based methods such as Mann–Whitney, and seeded region growing are among popular segmentation routines [23]. When the compression is performed separately for each segmented part, the performance of the segmentation routine directly affects the final compression ratio. Separate compression of each segmented part of the image is performed because the data in the foreground have different statistical features compared with the data in the background and must be treated differently.

In lossy image compression methods, the segmentation of a microarray image is very critical since the segmented foreground is retained and the background is compressed with some loss. Hence the uncompressed image may lack some imperative information if the initial segmentation was to be inaccurate. In lossless compression of microarray image the accuracy of the segmentation routine only affects the compression ratio and has no effect on the genetic information that is finally extracted from the image.

Most of the microarray compression methods, such as [7–11] and [16], use microarray image segmentation routines. The goal in microarray segmentation schemes is to extract the spots. There are disadvantages to these schemes if they are used for compression purposes: 1) Regions that are smaller than a spot, such as noise or artifacts, regardless of their intensities, are categorized as background. 2) The intensities of the pixels of a spot depend on the experimental conditions. This means that the pixel intensities of a weak spot in a part of an image may be comparable with the background intensities of another spot in another part of that image. Hence, a segmentation process which is intended to segment spots would categorize these low intensity pixels of a weak spot as foreground. 3) In donut-shape spots [24] the intensities of central pixels of the spot are significantly low but they are grouped as spot pixels. We consider these behaviors as disadvantages because the statistical features of the foreground and background are disturbed which in turn would reduce the resulted compression ratio.

Here we use an adaptive thresholding scheme for segmentation of pixels [16]. This scheme is intended for use by the subsequent compression step and may not be effective for the segmentation of spots. A threshold, T
                     
                        S
                     , is computed according to Eq. (1). Pixels are grouped as foreground (greater than the threshold) and background. The function P(T), as stated in Eq. (2), is the cumulative distribution function of pixels that have intensities lower than or equal to T. Also, σ
                     
                        b
                     
                     2 and σ
                     
                        f
                     
                     2 are the variance of the background and foreground pixels, respectively. The probability of existence of a pixel with intensity i is shown as p(i).
                        
                           (1)
                           
                              
                                 T
                                 S
                              
                              =
                              arg
                              
                              min
                              
                                 
                                    P
                                    
                                       T
                                    
                                    
                                       log
                                       2
                                    
                                    
                                       
                                          σ
                                          b
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          1
                                          −
                                          P
                                          
                                             T
                                          
                                       
                                    
                                    
                                       log
                                       2
                                    
                                    
                                       
                                          σ
                                          f
                                          2
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              P
                              
                                 T
                              
                              =
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       0
                                    
                                    T
                                 
                              
                              
                              p
                              
                                 i
                              
                           
                        
                     
                  

To find the threshold T
                     
                        S
                      we need to compute C(T)=
                     P(T)log2(σ
                     
                        b
                     
                     2)+(1−
                     P(T))log2(σ
                     
                        f
                     
                     2) for every intensity value of the image. Then the intensity value that minimizes C(T) is the threshold. C(T) consists of two functions for the background and the foreground defined by B(T)=
                     P(T)log2(σ
                     
                        b
                     
                     2) and F(T)=(1−
                     P(T))log2(σ
                     
                        f
                     
                     2), respectively. Fig. 2
                      shows the plots of B(T), F(T), and C(T) for all intensity values of a microarray image. Since F(T) is a strictly descending function and B(T) is a strictly ascending function, then C(T) could only have one minimum point. Hence one can use iterative divide and conquer schemes to quickly find T
                     
                        S
                      
                     [16].

Using the obtained threshold we can generate a segmentation map. Fig. 3
                      shows the block diagram of the proposed method for the lossless compression of microarray images.

The segmentation map, M, goes through a morphological opening process with a very small structuring element. This process causes higher compression results from the subsequent run length encoding of the segmentation map. The image is then segmented with the aid of the segmentation map, M′. The image of Fig. 1 is segmented and its map is shown in Fig. 4
                     . This type of segmentation may not be appropriate for extraction of genetic information from the image. We see that in Fig. 4 many of the spots with relatively low intensities are segmented as background. On the other hand, this segmentation has proved to be very much effective for compression purposes. With the aid of M′ the foreground pixels are packed together and a simple differential pulse code modulation (DPCM) prediction is applied to them. Since the packed foreground pixels have relatively close intensities, the application of the DPCM would generate low entropy results. The same process of packing and DPCM application is performed for the background pixels. Subsequently, entropy coding is applied to compress each part.

In this section, hardware architecture for the proposed lossless compression of microarray images is introduced. The image data enters the circuit in a row-by-row manner. A part of the proposed architecture is presented in Fig. 5
                     . The structure shown in Fig. 5 has pipeline architecture. While a row of image is being compacted together the next row can be worked on to get its segmentation map. Without loss of generality, it is assumed that each row of the input image contains 256pixels.

One row of image is inserted to the pipeline at each cycle of the pipeline clock. Thresholding unit and morphological opening circuitry, shown in Fig. 3, are done by stages 1 to 4 of the pipeline and are not shown here. The details of stages 1 to 4 of the pipeline can be found in [18]. Fig. 5 shows only stages 5 and 6 of the pipeline which are responsible for separation of the foreground and background pixels. Also, compaction of the foreground and background pixels is performed by dedicated compaction units of stage 6. All of the compaction units of stage 6 are similar but they are used for different purposes.

Separation of the pixels of a row of an image using the segmentation map, M′, is done by stage 5. All pixels that have a corresponding ‘1’ in the segmentation map are considered as foreground. Hence, background pixels have corresponding ‘0’ in the segmentation map. In order to compress the segmentation map we take one row of the map. Instead of transmitting a whole row of the segmentation map, which consists of consecutive strings of 0's and 1's, we can only send the starting location (index) of each string. One of the compaction units of Fig. 5 (CU3) is responsible for compressing the segmentation map. The internal structure and the function of a CU will be explained later.

Furthermore, foreground pixels of a row are slid to one side and are packed together by CU1. Also, the background pixels in a row are lumped together by CU2. When foreground pixels are packed together a simple differential pulse code modulation scheme will result in relatively low entropy and good compression ratio. The same is true for the background pixels. At the receiver end, to uncompress the image, the original map can be reconstructed using the received indices. Subsequently, the original image can be reconstructed, with no loss, using the segmentation map and the foreground and background pixels.

Now to explain the function of the 5th stage of the pipeline, let us consider a row of the segmentation map which contains strings of 1's and 0's. A part of stage 5 is responsible to obtain the starting locations of these strings. By “XOR”ing the neighboring values at the starting locations of strings, where there are 0 to 1 or 1 to 0 transitions, the output of corresponding XOR's will be 1. All other XOR's produce 0's. In this way for the inner elements of a string, where the neighboring values are the same, the output will be 0. Hence, a row of bitmap is now converted to a row of binary digits with the same number of bits but with mainly 0's and sparse 1's. We call this row of binary digits “start-point” vector. Because each row of a microarray image always begins with background pixels, the first string of the map is always a 0 string and the following strings are alternatively 1's and 0's. Thus knowing only the place of the beginning of each string is enough and the types of the strings are easily distinguishable.

Inputs of a compaction unit are X and Y vectors. A CU shrinks its X input by eliminating those elements of X which have corresponding zero in the Y vector. CU3 is responsible to find an index for each 1 that is produced by the row of XORs. Hence, the X input of CU3 consists of fixed numbers from 00 to 255 representing all possible position indices that could exist in a start-point vector. The output of CU3 is in fact a compressed row of the segmentation map. This compressed version consists of only packed indices.

Next, let us consider the function of CU1 and CU2 that are shown in Fig. 5. As mentioned before, CU1 is responsible for packing of the foreground pixels, and CU2 is responsible for packing of the background pixels. Basically we want CU1 to push all foreground pixels of a row to one side and CU2 is supposed to do the same for the background pixels. Hence we place the pixel values of a row of image on the X input of CU1 and feed the map of the row to the Y input of CU1. Now the compaction unit will push to one side all pixel values at the X input that have a corresponding 1 at the Y input. Therefore, the output of the CU1 we have a row of 8-bit values where all foreground pixels are grouped together toward the left and the rest of the registers at the output of CU1 contain zeros. Compaction of the background pixels is done similarly except that the inverse of a row of the map is fed into CU2. This is done to make 1's in the map to correspond to the background pixels of a row.

Details of a CU are shown in Fig. 6
                     . The designed CU unit is composed of units which we call them routing units (RUs). Details of an RU are shown in Fig. 7
                     . Also shown in Fig. 7 are all possible combinations of control signals, Cin1 and Cin2, and their corresponding routing action. For larger or smaller input vectors, the CU could be scaled up or down. Since the rows of the input image have 256pixels, the CU that is shown in Fig. 6 has 256-element input vectors. In Fig. 6 the 8-bit value of x0 is routed to out0 if and only if y0 is 1. Otherwise, the RUs connected to x0 should allow x1 or the first element of X with a non-zero corresponding Y element to be routed to out0. When out0 is occupied then out1 is available for occupancy.

The internal structure of an RU is presented in Fig. 7(a) where out of the two multiplexers only one can be enabled depending on the value of control input1. When the enable (en) of a multiplexer is 0 its output becomes high impedance. Therefore, as shown in Fig. 7(b) only one of the four possible routings is performed by an RU and only one of the inputs is routed to one of the outputs. Fig. 8
                      shows an example for the routing operation of a CU. The Y input of the CU is, for example, 00100101. The Y input consists of fixed indices from 0 to 7. The CU is to place the indices of the 1's at its X input in a dense manner at its output. Consider an RU in the first column at the left of the CU where its Y bit is 1. This RU enters the index and does not allow anything else to go through it. This RU also informs the unit above it not to send anything down and route to the right.

Every row of an image starts with a string of zeros; therefore, it is not necessary to save the index value for the beginning of these strings. Hence, the first string that we encounter in a row is a string of 1's. Furthermore, every row ends with another string of zeros but the index value of start of that string needs to be saved. By placing a zero at the input of the first XOR at the left in Fig. 5 we consider continuity between consecutive lines which creates a higher compression ratio. In effect, the image is scanned in a raster scan manner.


                     Table 1
                      shows different steps of the pipeline operations on a row of the segmentation map. At the first step the map of a row of pixels is computed. Then the starting positions of different strings of 1's and 0's are found. We are only interested in the index value of these starting positions. We know that the first index in a row belongs to a string of 1's and from there on they alternate between 0's and 1's strings. These sparse positions are fed into CU3 and the output is a dense and ordered group of indices corresponding to the starting positions of the strings. In Table 1 there are three strings and two starting points. The indices corresponding to these start-points are BH and 16H. In this example a string of 32 bits is replaced by two indices.


                     Fig. 9
                      shows the overall operation of the proposed architecture which includes separation of the foreground from the background and independent compaction of each. Fig. 9(a) shows the significant part (I
                     
                        H
                     ) of a portion of a real microarray image containing three spots. Both foreground and background pixels are present. Fig. 9(b) shows the classification map of the image where the 1's are for the foreground pixels and 0's correspond to the background pixels. Fig. 9(c) shows the starting location of the strings of 0's and 1's in the map. Only when a new string starts we see a 1 and elsewhere we have 0's. Fig. 9(d) demonstrates the packing of the indices of these starting positions using CU3. Only these values are required to be stored or transmitted to reconstruct the segmentation map.

As shown in Fig. 5 two compaction units, CU1 and CU2, are responsible for the compaction of a row of image by using the map of that row. Fig. 9(e) and (f) shows the resulted compacted foreground and background. These values are further compressed using DPCM prediction and Huffman coding. Using a reconstructed segmentation map the compressed foreground and background pixels can be used to generate the original image.

When the foreground is compacted a predictive technique is used that capitalizes on inter-pixel spatial redundancy. To do so, we predict the next pixel based on the values of the previous neighboring pixels. This is done by computing the residual pixel which is the difference between the two neighboring pixels. Finally, we losslessly compress the residual data, using the Huffman coding. Therefore, the information of a row has been de-correlated which causes the residual to have lower entropy. The same process is performed for the background pixels. These processes are performed by stages 7 and 8 of the pipeline as shown in Fig. 10
                     . The registers shown at the top of Fig. 10 are actually the outputs of CU1 and CU2 of stage 6 and contain the compacted foreground and background pixels. Stage 7 is responsible for finding the residual pixel values. This residual computation is performed by a row of 8-bit subtractors, SUBs. Each 8-bit SUB computes the difference between two adjacent pixel values and produces a 9-bit result. At stage 8 two lookup tables (LUTs) are present. One contains the Huffman variable length code corresponding to the residuals of the foreground and one belongs to the residuals of the background. The code may be at most k bits long. Hence the length of each entry is stored next to the code which can be at most log2
                     k bits long. With rising edge of each pulse of a local clock one of the residuals is coded and with the falling edge of the same pulse it is latched in a register at the output of stage 8. This would allow the serial transmitter to use the correct number of pulses to send out each code word [18].

In this section we discuss the simulation results of the proposed compression architecture. We used a range of standard microarray images [6] in our experiments which have been referred to in the literature. They are produced by different laboratories and are of different sizes and also contain various numbers of spots, various spot shapes and areas. Tables 2, 3, and 4
                     
                     
                      show the compression results from our proposed method and the results from GZIP [25], JPEG2000 [26], JBIG [27], JPEG_LS [28], and a recent method of reference [14,15]. The thirty two images mentioned in Table 2, namely 1230ko1R to 1230ko8G and 1230c1R to 1230c8G, are from the Apo AI set [29]. Also, shown in Table 3 are results from images Def661Cy3 to Def667Cy5 that are from the ISREC [30] dataset. Furthermore, three images of Array1 to Array3 are from the MicroZip [10] dataset. Using our proposed compression method an average of 11.295 BPP is obtained for the Apo AI image set and averages of 11.260 BPP and 10.330 BPP are achieved respectively for the ISREC image and MircoZip sets.

All of the algorithms that are used in Tables 2, 3, and 4 are software based. References [14,15] and the JPEG-LS use elaborate context modeling. The algorithm of references [14,15] is specifically designed for microarray images and has no time or complexity constraints. The goal of our proposed method is to achieve real-time speeds with acceptable compression ratios. We achieved real-time performance while the compression capability of the circuit is comparable with standard tools and dedicated microarray compression routines.

The achieved higher or comparable bit per pixel results, when compared with some standard packages or specialized microarray routines, are due to fact that the foreground is separated from the background. This separation creates better spatial correlations among the pixels of the foreground and between the pixels of the background. Without the separation and compaction of the pixels, when the predictor crosses a spot's edge, we see an increase in the prediction error. This is due to the fact that spots are surrounded by background pixels and a predictor goes from the background into the foreground or vice versa. When spots are lumped together the prediction error is significantly reduced. The same reasoning is true for the background pixels when they are lumped together. The reduction of prediction errors is translated into bit per pixel values. This separation and compaction became realizable with the aid of the proposed compaction unit.

@&#CONCLUSION@&#

In this paper, we presented a new lossless compression method for microarray images. By statistical studies on microarray images, we concluded that the least significant 8 bits of pixels should be transmitted without any prediction process performed on them. To compress and achieve lower BPP values for the I
                     
                        H
                      part of the image, we separated the foreground pixels form those of the background. For this reason a new hardware was designed and used that could extract out the foreground values. The foreground pixels were placed next to each other in an orderly fashion. The same was done separately for the background pixels.

Modifications to the proposed architecture are possible by applying a 2-dimensional predictor to further exploit spatial correlations. This would require changes at the later stages of the pipeline. Further modifications are possible by adding more LUTs, at stage 8, to work concurrently and reduce the delay of that stage.

The internal structure of an RU consists of two multiplexers and a NOT gate. The VLSI implementation of a 1-bit RU at the transistor level requires only 4 transistors. The ASIC implementation of the circuit would be much more compact than the standard multiplexers that we presented.

The results obtained from the proposed architecture, while being produced at real-time speeds, had lower BPP values than GZIP which is a popular compression tool. Also in many cases our method outperforms JPEG2000. With the accelerated growth of big data applications in bio-informatics we see a growing demand for real-time lossless compression, storage, and transmission of medical images. One of the common factors in many biomedical images is the presence of vast background areas. For such images we suggest that our hardware design be a part of a standard lossless image compression method.

@&#REFERENCES@&#


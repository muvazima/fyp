@&#MAIN-TITLE@&#Automatic cytoplasm and nuclei segmentation for color cervical smear image using an efficient gap-search MRF

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We proposed a novel gap-search Markov random field (MRF) for accurate cervical smear image segmentation.


                        
                        
                           
                           This method could acquire three regions (nuclei, cytoplasm, and background) automatically by a label-map mechanism.


                        
                        
                           
                           The gap-search algorithm is faster than other three algorithms in the experiments.


                        
                        
                           
                           A copy of source codes will be released as an open source project for continuing studies.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Papanicolaou test

Cervical smear image segmentation

Superpixel feature extraction and selection

Superpixel-based MRF

MRF modeling and inference

Faster MRF

@&#ABSTRACT@&#


               
               
                  Accurate and effective cervical smear image segmentation is required for automated cervical cell analysis systems. Thus, we proposed a novel superpixel-based Markov random field (MRF) segmentation framework to acquire the nucleus, cytoplasm and image background of cell images. We seek to classify color non-overlapping superpixel-patches on one image for image segmentation. This model describes the whole image as an undirected probabilistic graphical model and was developed using an automatic label-map mechanism for determining nuclear, cytoplasmic and background regions. A gap-search algorithm was designed to enhance the model efficiency. Data show that the algorithms of our framework provide better accuracy for both real-world and the public Herlev datasets. Furthermore, the proposed gap-search algorithm of this model is much more faster than pixel-based and superpixel-based algorithms.
               
            

@&#INTRODUCTION@&#

According to the World Health Organization (WHO), cervical cancer is the second most common cancer among women, causing nearly 270,000 deaths each year, most of which are in low- and middle-income countries. In contrast, in developed countries, cervical cancer mortality is less due to annual Papanicolaou smear screenings [1]. In 1942, George Papanicolaou reported a technique named a “Pap test” method [2], which is a simple, low-cost, and effective way for diagnosing cervical cancer. Since then, the Pap smear has become the most common measure for cervical cancer cell screening.

Traditionally, Pap smear image analysis is a manual method performed by cytologists. This is time-consuming and error-prone. Because computerized analysis is faster, an automatic and valid method was sought for screening slides [3–9]. But with such a system, cell segmentation is a fundamental step for detecting cancerous cells. First, cells must be divided into three regions: cytoplasmic, nuclear, and background areas. Next, one cell per image is required as well as debris removal from cells [10–12]. Then, morphologic and structural features can be extracted from one cell at a time [13,14]. Finally, abnormal cells must be distinguished from normal ones [15–18]. In real-world cervical cell images, there are complex morphologic structures, “noise” or nonessential information and ambiguous cell boundaries as well as overlapping cells (see Fig. 1
                     ). Thus, the segmentation of cervical cells is an important and long standing research field. The cervical smear image segmentation can be divided into three categories: (1) nuclei segmentation [19–23]; (2) free cytoplasm and nuclei segmentation [24–28]; (3) overlapped cells segmentation [29–32].

Until now, various segmentation methods were proposed for cervical smear images. These methods can be divided into two classes: region and edge-based algorithms. Region-based algorithms include seed-region growing techniques [3], threshold [19], pixel-classified methods [4,29,21], graph-based approaches [26]. Edge-based algorithms mainly include snake-based methods [20,25,31,30], level-set methods [32].

Threshold, seed-region growing, watershed algorithm and Canny edge detector [33] are simple and effective measures. But for real-world images, the situations are complex for perfect cell regions identification. Thus, these techniques are usually used to assist the segmentation process and are sub-steps within a framework. The improved snake-based method [20] proposed by Plissiti has been used to locate nuclear boundaries and Li and colleagues [25] drew both nuclear and cytoplasmic boundaries of a single cell using spatial k-means and a radiating gradient vector flow (RGVF) snake model. Next, Guan׳s group [31] acquired partially overlapped cell contours using a dynamic sparse contour searching (DSCS) and a GVF snake model. These models are accurate for extracting the boundaries for single-cell images but for multi-cell images, detecting bounding-box of each cell is required. Segmentation accuracy relies on the precise of cell bounding-boxes. With a pixel-classified method, Jung and coworkers [29] presented a scheme using an expectation maximum (EM) and a Bayes classifier for separating overlapped nuclei. Kale and GençTav [4] used a threshold technique to remove noise, and then acquired nuclear and cytoplasmic regions using a hierarchical tree and a binary SVM. This work [4] is a segmentation and recognition algorithm of the cervical smear image. For supervised algorithms, labeled-data sets are required to train models such as SVM. Furthermore, the data-labeling process is tedious and labor-intensive. So semi-supervised or unsupervised improvements are required to segment images with little or no training data. In addition, for pixel-classified method the computational complexity of the model must be controlled due to the flexible number of pixels.

Recently, superpixel-based methods [27,28], which divided original pixels into reasonable pixel-sets, were usually more efficient than pixel-based models for cervical smear segmentation. After superpixels division, a space-divided Voronoi diagram [28] was used for the multi-cell segmentation. Based on superpixels, supervised deep leaning network [27] shew good performance with fine trained model. For the combination superpixel division with other methods, an important question is how to manage the relationship of irregular superpixels reasonably.

Here, we propose a novel superpixel-based MRF segmentation model for dealing with this question. We combined the superpixels with an undirected probabilistic graphical model (i.e. MRF) [34] and described the whole image as a graphic net, composed of the superpixel-nodes and connecting-edges. First, the connecting-edges of the graph reflect spatial information between neighboring superpixels by local probabilistic description. Second, this model acquires three regions without training process using a label-map mechanism. Third, the superpixel-based MRF, which is suitable for complex shapes and ambiguous boundaries, saves time compared to the pixel-based model. Forth, the proposed gap-search algorithm can resolve the superpixel-based model more rapidly. Data show that our framework can offer the requisite accuracy, efficiency and speed.

The overview of our framework (see Fig. 2
                     ) includes weakening of “noise” with a non-local means filter, generation of node-elements of the MRF model denoted by superpixels, and extraction of a 13-dimensional feature vector from each superpixel. Then, we modeled the image as a superpixel-based MRF. A solution algorithm of this model, an iterative adaptive classified algorithm (IACA), was proposed and we also improved the IACA with a gap-search algorithm.

To formally define the proposed model, suppose that the observed image 
                           F
                           =
                           {
                           
                              
                                 
                                    
                                       f
                                    
                                    
                                       →
                                    
                                 
                              
                              
                                 p
                              
                           
                           |
                           p
                           ∈
                           φ
                           }
                         consists of 13-dimension feature vectors at each superpixel 
                           p
                           ∈
                           φ
                         denoted by a vector 
                           
                              
                                 
                                    
                                       f
                                    
                                    
                                       →
                                    
                                 
                              
                              
                                 p
                              
                           
                        . The object is to identify the best configuration labeling 
                           
                              
                                 l
                              
                              
                                 ^
                              
                           
                        , which maximizes the posteriori probability 
                           P
                           (
                           l
                           |
                           F
                           )
                        , which is the maximum a posteriori(MAP) estimation:
                           
                              (1)
                              
                                 
                                    
                                       l
                                    
                                    
                                       ^
                                    
                                 
                                 =
                                 arg
                                 
                                 
                                    
                                       
                                          max
                                       
                                       
                                          l
                                          ∈
                                          Ω
                                       
                                    
                                 
                                 P
                                 (
                                 l
                                 |
                                 F
                                 ,
                                 θ
                                 )
                                 =
                                 arg
                                 
                                 
                                    
                                       
                                          max
                                       
                                       
                                          l
                                          ∈
                                          Ω
                                       
                                    
                                 
                                 (
                                 
                                    
                                       Π
                                    
                                    
                                       p
                                       ∈
                                       φ
                                    
                                 
                                 P
                                 (
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             →
                                          
                                       
                                    
                                    
                                       p
                                    
                                 
                                 |
                                 
                                    
                                       l
                                    
                                    
                                       p
                                    
                                 
                                 )
                                 )
                                 P
                                 (
                                 l
                                 )
                              
                           
                        where Ω denotes the set of all possible configuration labels, θ represents the parameters of the MRF model. Because our aim is to segment the image into homogeneous regions, one superpixel class λ will correspond to one or more homogeneous superpixel patches in the input image. Regularities can be modeled by a white noise with covariance 
                           
                              
                                 Σ
                              
                              
                                 λ
                              
                           
                         centered around the expected mean vector 
                           
                              
                                 μ
                              
                              
                                 λ
                              
                           
                        . So we suppose that 
                           P
                           (
                           
                              
                                 
                                    
                                       f
                                    
                                    
                                       →
                                    
                                 
                              
                              
                                 p
                              
                           
                           |
                           
                              
                                 l
                              
                              
                                 p
                              
                           
                           )
                         follows a Gaussian distribution and every superpixel classes 
                           λ
                           ∈
                           Λ
                           =
                           {
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           L
                           }
                         are presented by the mean vectors 
                           
                              
                                 μ
                              
                              
                                 λ
                              
                           
                         and the covariance matrices 
                           
                              
                                 Σ
                              
                              
                                 λ
                              
                           
                        . Furthermore, P(l) is a MRF with respect to a new superpixel-based neighbor system (see Fig. 3
                        ). In Fig. 3, a singleton denotes a first order MRF and describes the probability of labels without context and a doubleton reflects the relationship between two neighboring superpixel labels [35].

And as seen in Fig. 4
                        , the superpixel data field is composed of the black nodes in one image. The label field consists of the gray nodes. Each black node represents superpixel and has one corresponding gray label node.

Maximum global probability is equivalent to minimum global energy function according to the Hammersley–Clifford theorem [36]. When the joint probability distribution of the random variables is strictly positive, it is proven that Gibbs probability distribution is equivalent to the MRF. That is to say, P(l) follows a Gibbs distribution:
                           
                              (2)
                              
                                 P
                                 (
                                 l
                                 )
                                 =
                                 
                                    
                                       exp
                                       
                                       (
                                       −
                                       U
                                       (
                                       l
                                       )
                                       )
                                    
                                    
                                       Z
                                       (
                                       β
                                       )
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∏
                                          
                                          
                                             C
                                             ∈
                                             φ
                                          
                                       
                                       exp
                                       
                                       (
                                       −
                                       
                                          
                                             V
                                          
                                          
                                             C
                                          
                                       
                                       (
                                       
                                          
                                             l
                                          
                                          
                                             C
                                          
                                       
                                       )
                                       )
                                    
                                    
                                       Z
                                       (
                                       β
                                       )
                                    
                                 
                              
                           
                        where U(l) is the energy function, 
                           Z
                           (
                           β
                           )
                           =
                           
                              
                                 ∑
                              
                              
                                 l
                                 ∈
                                 Ω
                              
                           
                           (
                           exp
                           −
                           U
                           (
                           l
                           )
                           )
                         is the partition function and the V
                        
                           C
                         denotes the clique potential of clique 
                           C
                           ∈
                           φ
                         having the label configuration l
                        
                           C
                        . φ is the set of the second order cliques. The energy of singletons directly reflect the probabilistic modeling of labels without context, while doubleton clique potential express the relationship between neighboring superpixel labels. The superpixel sites 
                           p
                           ∈
                           φ
                         and the neighboring superpixel correspond to the energy of singletons 
                           
                              
                                 ∑
                              
                              
                                 i
                                 ∈
                                 
                                    
                                       C
                                    
                                    
                                       1
                                    
                                 
                              
                           
                           
                              
                                 V
                              
                              
                                 1
                              
                           
                           (
                           
                              
                                 l
                              
                              
                                 i
                              
                           
                           )
                         and doubletons 
                           
                              
                                 ∑
                              
                              
                                 i
                                 ,
                                 j
                                 ∈
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                              
                           
                           
                              
                                 V
                              
                              
                                 2
                              
                           
                           (
                           
                              
                                 l
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 l
                              
                              
                                 j
                              
                           
                           )
                        . Thus the energy function of the defined MRF image segmentation model has the following form:
                           
                              (3)
                              
                                 U
                                 (
                                 l
                                 ,
                                 F
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                1
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       V
                                    
                                    
                                       1
                                    
                                 
                                 (
                                 
                                    
                                       l
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 +
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          ,
                                          j
                                          ∈
                                          
                                             
                                                C
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       V
                                    
                                    
                                       2
                                    
                                 
                                 (
                                 
                                    
                                       l
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       l
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          p
                                          ∈
                                          φ
                                       
                                    
                                 
                                 (
                                 
                                    ln
                                    (
                                    
                                       
                                          
                                             
                                                (
                                                2
                                                π
                                                )
                                             
                                             
                                                13
                                             
                                          
                                          |
                                          
                                             
                                                Σ
                                             
                                             
                                                
                                                   
                                                      l
                                                   
                                                   
                                                      p
                                                   
                                                
                                             
                                          
                                          |
                                       
                                    
                                    +
                                    
                                       
                                          1
                                       
                                       
                                          2
                                       
                                    
                                    (
                                    
                                       
                                          
                                             
                                                f
                                             
                                             
                                                →
                                             
                                          
                                       
                                       
                                          p
                                       
                                    
                                    −
                                    
                                       
                                          μ
                                       
                                       
                                          
                                             
                                                l
                                             
                                             
                                                p
                                             
                                          
                                       
                                    
                                    )
                                    
                                       
                                          Σ
                                       
                                       
                                          
                                             
                                                l
                                             
                                             
                                                p
                                             
                                          
                                       
                                       
                                          −
                                          1
                                       
                                    
                                    
                                       
                                          (
                                          
                                             
                                                
                                                   
                                                      f
                                                   
                                                   
                                                      →
                                                   
                                                
                                             
                                             
                                                p
                                             
                                          
                                          −
                                          
                                             
                                                μ
                                             
                                             
                                                
                                                   
                                                      l
                                                   
                                                   
                                                      p
                                                   
                                                
                                             
                                          
                                          )
                                       
                                       
                                          T
                                       
                                    
                                    )
                                 
                                 )
                                 +
                                 β
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          {
                                          i
                                          ,
                                          j
                                          }
                                          ∈
                                          φ
                                       
                                    
                                 
                                 δ
                                 (
                                 
                                    
                                       l
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       l
                                    
                                    
                                       j
                                    
                                 
                                 )
                              
                           
                        
                     

In our work, the label layer is defined to be a multi-value Potts physical model for this multi-classified MRF. The definition of the Potts model is as follows:
                           
                              (4)
                              
                                 δ
                                 (
                                 
                                    
                                       l
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       l
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 {
                                 
                                    
                                       
                                          
                                             0
                                          
                                          
                                             
                                                
                                                   l
                                                
                                                
                                                   i
                                                
                                             
                                             =
                                             
                                                
                                                   l
                                                
                                                
                                                   j
                                                
                                             
                                          
                                       
                                       
                                          
                                             β
                                          
                                          
                                             
                                                
                                                   l
                                                
                                                
                                                   i
                                                
                                             
                                             ≠
                                             
                                                
                                                   l
                                                
                                                
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           β
                           >
                           0
                         is a parameter controlling the homogeneity of the regions. A larger β makes the region more homogeneous.

The nodes of MRF are superpixels, which can be interpreted as a set of neighboring similar pixels. There are many superpixel generated algorithms and we used SLIC [37], a simple line iterative clustering algorithm, to generate superpixels. The parameter setting of this algorithm is a key question as it decides the performance of segmentation model. SLIC has two parameters, m and N. m controls the distance of two superpixels. A smaller m yields more similar pixels in one superpixel and irregular patches (see Fig. 5
                        ). The value of m ranges from 1 to 40 in CIELAB color space. Next, N controls the number of superpixels and as N increases, the running time of superpixel-based MRF rises too. For getting rid of the influence of N, we have improved the solution of our model to be a novel gap-search algorithm.

In this work, we extracted 13-dimensional features from one superpixel including pixel intensities and the shape of superpixel patches. Pixel intensities come from RGB and CIELAB color space. And we calculated the mean and median pixel intensities from each channel. Because two color spaces own six total channels, we acquired a 12-dimensional feature vector. Then, the ratio of patches area to the minimal enclosing rectangle is extracted as one dimensional feature. So the dimension of feature is 13 shown in Table 1
                        . The last column of Table 1 is zijdenbos similarity index (ZSI) of every dimension, reflects a similar degree between segmented and ground truth regions.

In previous [25], spatial k-means was used the pixel for segmentation. We used superpixels instead of the pixels. The number of superpixels is less than the number of original pixels and adopted k-means++ is faster than a k-means [38]. Due to fewer data and a faster clustering algorithm, our initial segmentation is more efficient.

For this unsupervised initial segmentation, labels are generated randomly for every image. So we needed to identify the regions corresponding to nuclei, cytoplasm and background rightly. Thus, we designed a label-map mechanism to adjust the unsupervised labels to the correct labels. This mechanism was accomplished using the differences in lightness of regions. Nuclei are the darkest, and the background is lightest so the rest is cytoplasm. First, the centers are identified from three clusters. Then the mean value of L channel in each center is extracted. Next, the three values are sorted and after this re-map processing, the maximal value is the nucleus and a minimal value depicts the background, and an intermediate one is the cytoplasm.

The objective function is non-convex, so we applied combinatorial optimization techniques to solve it. The parameters θ of this segmentation model consists of the mean vector 
                              
                                 
                                    μ
                                 
                                 
                                    λ
                                 
                              
                           , the covariance matrix 
                              
                                 
                                    Σ
                                 
                                 
                                    λ
                                 
                              
                            and the parameter β. To solve this model, we use an iterative adaptive classified algorithm (IACA) to perform parameter estimation. After the last iteration of IACA, segmentation results can be identified by superpixel labels. IACA has two properties: adaptive and unsupervised. First, the meaning of the adaptive algorithm can be known from its mathematical property. For the algorithm, the MAP estimation becomes as follows:
                              
                                 (5)
                                 
                                    (
                                    
                                       
                                          l
                                       
                                       
                                          ^
                                       
                                    
                                    ,
                                    
                                       
                                          θ
                                       
                                       
                                          ^
                                       
                                    
                                    )
                                    =
                                    arg
                                    
                                    
                                       
                                          
                                             max
                                          
                                          
                                             l
                                             ,
                                             θ
                                          
                                       
                                    
                                    P
                                    (
                                    l
                                    ,
                                    F
                                    |
                                    θ
                                    )
                                 
                              
                           We employ the approximated method instead:
                              
                                 (6)
                                 
                                    
                                       
                                          l
                                       
                                       
                                          ^
                                       
                                    
                                    =
                                    arg
                                    
                                    
                                       
                                          
                                             max
                                          
                                          
                                             l
                                          
                                       
                                    
                                    P
                                    (
                                    l
                                    ,
                                    F
                                    |
                                    
                                       
                                          θ
                                       
                                       
                                          ^
                                       
                                    
                                    )
                                 
                              
                           
                           
                              
                                 (7)
                                 
                                    
                                       
                                          θ
                                       
                                       
                                          ^
                                       
                                    
                                    =
                                    arg
                                    
                                    
                                       
                                          
                                             max
                                          
                                          
                                             θ
                                          
                                       
                                    
                                    P
                                    (
                                    
                                       
                                          l
                                       
                                       
                                          ^
                                       
                                    
                                    ,
                                    F
                                    |
                                    θ
                                    )
                                 
                              
                           
                        

Eq. (5) is the MAP estimation of the label filed based on the MRF model parameters 
                              
                                 
                                    θ
                                 
                                 
                                    ^
                                 
                              
                           . And Eq. (6) is the maximum likelihood (ML) of the observed samples and labels 
                              (
                              
                                 
                                    l
                                 
                                 
                                    ^
                                 
                              
                              ,
                              F
                              )
                           . The solution of Eqs. (6 and 7) is sub-optimal solutions of the object function Eq. (5). Next, we elaborated on the meaning of unsupervision. In unsupervised situation, initial parameters θ are unknown, and in an iterative process we did not use labeled data. This iterative estimation procedure supposes that a cervical smear image has three regions.

For reducing the running time, we improved this IACA by a gap-search mechanism to the literature [39], which proposed a faster algorithm for a pixel-based binary-classified MRF. In our work, each iteration of IACA computes all superpixel labels repeatedly for a optimized solution of multi-classified MRF. Most of labels stay the same with last iteration and most of computations for energy are redundant. Thus, we only needs to update the energy of necessary local regions. So we employed un-smoother regions of k-means++, and drew a searching gap for selecting necessary superpixel to compute energy. The gap-search algorithm of MRF accelerated the solution of model by the set Su of the selected superpixels. In set Su, the elements are the superpixels that overlapped with searching gap patches. The searching gap patches are fixed by the edge pixels of Canny edge detector. We obtained an edge gap by drawing the squares, the centers of which are the pixel points of edge (see Fig. 6
                        .) Algorithm 1 is referred to as the pseudo-code of our gap-search MRF. 
                           Algorithm 1
                           Gap-search algorithm for cervical image segmentation – pseudo-code. 
                                 
                                    
                                       
                                       
                                          
                                             
                                                Input: Cervical smear image I
                                                
                                                   org
                                                , parameter homogeneity β, maximum iterative times I, the number of classes N, iterative differential threshold δ.
                                          
                                          
                                             
                                                Output: Regions of nuclei, cytoplasm and background.
                                          
                                          
                                             
                                                Stage 0 - Preprocessing–filter image 
                                                I
                                             
                                          
                                          
                                             
                                                Stage 1 - Superpixels generation as node-elements of MRF
                                             
                                          
                                          
                                             
                                                1. Generate superpixels with SLIC algorithm.
                                          
                                          
                                             
                                                2. Extract a 13-dimensional feature vector from each superpixel denoted by 
                                                   F
                                                .
                                          
                                          
                                             
                                                3. Save superpixel adjacency graph G
                                                
                                                   adj
                                                 according to the label matrix.
                                          
                                          
                                             
                                                Stage 2 - MRF modeling and solution
                                             
                                          
                                          
                                             
                                                1. Initial segmentation using k-means++.
                                          
                                          
                                             
                                                2. Identify three clustered centers.
                                          
                                          
                                             
                                                3. Extract L⁎ channel mean values of the three centers.
                                          
                                          
                                             
                                                4. Map unsupervised superpixel labels to semantic nuclei, cytoplasm and background rightly using label-map mechanism.
                                          
                                          
                                             
                                                5. Input parameters: β, I, N and δ.
                                          
                                          
                                             
                                                6. Calculate initial μ
                                                
                                                   i
                                                , Σ
                                                
                                                   i
                                                , local energy E
                                                
                                                   local
                                                 and global energy E
                                                
                                                   i
                                                .
                                          
                                          
                                             
                                                7. Selected out the set Su of superpixels using gap-search mechanism.
                                          
                                          
                                             
                                                8. Repeat
                                             
                                          
                                          
                                             
                                                9. Update μ
                                                
                                                   i
                                                 and Σ
                                                
                                                   i
                                                 using maximum likelihood (ML).
                                          
                                          
                                             
                                                10.If the superpixel is the element in set Su
                                             
                                          
                                          
                                             
                                                11. Update E
                                                
                                                   local
                                                 and E
                                                
                                                   i
                                                 according to G
                                                
                                                   adj
                                                .
                                          
                                          
                                             
                                                12. Calculate the difference of energy 
                                                   
                                                      
                                                         δ
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   −
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         k
                                                         −
                                                         1
                                                      
                                                   
                                                .
                                          
                                          
                                             
                                                13. Save best superpixel-labeled list L
                                                
                                                   c
                                                 till current iteration.
                                          
                                          
                                             
                                                14. k=k + 1.
                                          
                                          
                                             
                                                15. If 
                                                   
                                                      
                                                         δ
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   <
                                                   δ
                                                 or 
                                                   k
                                                   >
                                                   I
                                                
                                             
                                          
                                          
                                             
                                                16. Break.
                                          
                                          
                                             
                                                17. Until convergence
                                             
                                          
                                          
                                             
                                                18. Map L
                                                
                                                   c
                                                 to pixel labels 
                                                   L
                                                 and mark the image using three labels.
                                          
                                          
                                             
                                                19. Output regions of nuclei, cytoplasm and background.
                                          
                                       
                                    
                                 
                              
                           

Suppose an image of size: 
                           w
                           ×
                           h
                         with L labels, then there are 
                           
                              
                                 L
                              
                              
                                 (
                                 wh
                                 )
                              
                           
                         possible label configuration. We analyzed the complexities of pixel-based MRF, superpixel-based MRF and gap-search MRF. First, the complexity of pixel-based MRF is O(wh). Second, given an image with N superpixels, the complexity of superpixel-based MRF is O(N) and as N increases, the running time increases. Third, due to computing the energy of the superpixels in selected set Su, the complexity of gap-search MRF is proportional to the number of elements in set Su. And the number of elements in set Su is proportional to the number of edge pixels E. So the complexity of gap-search MRF is O(E) and remains stable for one image.

We used two datasets, Herlev and a real-world, to verify method performance. Herlev [40] is the most commonly used public dataset and can be freely downloaded from the Internet (see Fig. 1). The real-world dataset contained multi-cell images and a part of this dataset came from the literature [31] (see Fig. 7
                           ). Images were acquired by an auto microscopic image screen equipment with a CCD camera (DA-HENG), an optical microscope (Olympus CX31) and a 
                              40
                              ×
                            magnification lens (numerical aperture=0.65). The size of an image is 1360×1024 and the pixel size is 
                              0.238
                              ×
                              0.238
                            (microns) in real-world dataset.

@&#EVALUATION@&#

The performance of segmentation was evaluated using zijdenbos similarity index (ZSI), which is in papers [4,25,31]. The definition of ZSI is
                              
                                 (8)
                                 
                                    ZSI
                                    =
                                    2
                                    
                                       
                                          #
                                          {
                                          
                                             
                                                A
                                             
                                             
                                                1
                                             
                                          
                                          ∩
                                          
                                             
                                                A
                                             
                                             
                                                2
                                             
                                          
                                          }
                                       
                                       
                                          #
                                          {
                                          
                                             
                                                A
                                             
                                             
                                                1
                                             
                                          
                                          }
                                          +#
                                          {
                                          
                                             
                                                A
                                             
                                             
                                                2
                                             
                                          
                                          }
                                       
                                    
                                    ,
                                 
                              
                           where A
                           1 and A
                           2 are the sets of ground truth elements and segmented region elements, 
                              #
                              {
                              }
                            represents the number of the elements in one set. The range of ZSI is [0, 1]. This similarity index considers differences in both size and location of the regions A
                           1 and A
                           2. If the value of ZSI 
                              >
                              0.7
                           , it indicates an excellent agreement between two regions, similar to the dice similarity coefficient [41].

@&#RESULTS@&#

The segmentation results come from pixel-based MRF, superpixel-based MRF, gap-search MRF, RGVF snake [25], hierarchical tree approach [4], threshold and watershed methods. The values of ZSI between results and ground truth images appear in Table 2 and 3
                           
                            for Herlev and real-world datasets respectively. As reported in the literature [4,25], we used some overlapped nuclei and cytoplasm images for evaluation. Data appear in Tables 2 and 3.


                           Table 2 depicts pixel-based MRF with highest ZSI score for both nuclei and cytoplasm in Herlev dataset. The RGVF snake and pixel-based methods were the best techniques. Suerpixel-based MRF and gap-search MRF were slightly worse than pixel-based MRF and RGVF snake. Data from the classic threshold was the worst in Herlev dataset.


                           Table 3 depicts pixel-based MRF which was the best. But the RGVF snake was the worse because it is an edge-based segmentation method and extracts one boundaries once. For multi-cell images and overlapped-cells cluster cases, this cannot be used due to the lack of accurate single cell bounding-boxes detection. The superpixel-based and gap-search MRFs were also slightly worse than pixel-based MRF.


                           Fig. 8
                            shows some examples of gap-search MRF from Herlev dataset and these appear with the original images. Our method could address flexible cell structure, an obscure cytoplasm and our method reduced noise.


                           Fig. 9
                            depicts images from the real-world dataset for in which there is much non-cell debris that disturb segmentation results. Overlapping of nuclei and cytoplasm is a challenge for multi-cell dataset as well. For both pixel-based and superpixel-based methods, time is a major constraint. Thus, we made this framework more rapid using a gap-search MRF.

The proposed algorithms were implemented with Microsoft Visual Studio 2013. Overall processing using C++ program language utilizes the opencv 2.4.11 and armadillo 5.200.1 library. We used a red-black tree instead of a liner list to search for superpixel in gap-search algorithm. This can be improved upon in the future using the parallel programming technique. Experiment running times were obtained from an HP laptop with 1.7GHz Intel Core i5 CPU, 4GB RAM and a Lenovo personal computer with 3.40GHz Intel Core i7 CPU, 8GB RAM. The gap-search algorithm of superpixel-based MRF reduces running time compared to superpixel-based and pixel-based MRFs. Running times of all three algorithms and RGVF snake method appear in Tables 4 and 5
                           
                           . With the HP laptop, for Herlev dataset, the running time of pixel-based MRF is 103.25s per image; the superpixel-based model requires 30.53s (including the time of superpixel division, features extraction, k-means++ and IACA); RGVF snake needs 14.12s; using the gap-search algorithm, the whole time of framework is 2.39s. And for real-world dataset, the running time of four algorithms is 41,716.34, 572.92, 103.45 and 76.96s per image respectively in laptop. For practical application, it usually uses desktop computer at least. So we also gave the running time of these methods on Lenovo desktop computer. RGVF snake used more running time than gap-search MRF in both two datasets. The computing time of gap-search algorithm achieves 0.63s per image for Herlev dataset and 1.55s per image for real-world dataset. Thus, the proposed gap-search algorithm saves time.

The aim of filtering is to reduce noise. We adopted non-local means filtering [42] to remove color images noise. A non-local means filter can preserve boundaries and filter the Gaussian noise, impulse noise. This filtering method is effective for cervical smear image according to Li [25] that refers to a “denoising” quality metric [43].

According to the contribution of superpixel feature to the segmentation (Table 1), we studied the best feature set of superpixels for our model using a technique, which is similar to the grid search [44]. Next, we interpreted the process of feature selection (Table 2). First, we sorted the 13 features in a descending order to ascertain the contribution of each, and selected the top three, six, nine and eleven to construct 4 feature sets I, II, III, and IV. Using a principal components analysis (PCA) technique, we projected the original feature space to a six dimensional feature space as feature set V. The 13-dimensional feature set is denoted by feature set VI. For feature set selection, we set 
                              m
                              =
                              {
                              5
                              ,
                              10
                              ,
                              15
                              ,
                              20
                              ,
                              25
                              ,
                              30
                              ,
                              35
                              ,
                              40
                              }
                            and 
                              N
                              =
                              {
                              500
                              ,
                              1500
                              ,
                              2500
                              ,
                              3500
                              ,
                              4500
                              ,
                              5500
                              ,
                              6500
                              ,
                              7500
                              }
                           . There are 
                              8
                              ×
                              8
                              ×
                              6
                              =
                              384
                            possible initial segmentation results. We calculated the ZSI of 384 combinations and sorted them. Next, we selected the top 5, 10, 15, 20, 25 and 30 (Table 6
                           ). These data show that the combination has a high ZSI ranking using feature set VI, and the rest offer low ZSI. Thus, the best set is the 13-dimensional one, and this was used for subsequent experiments.

Different superpixels division affects performance of model so we studied options for the best SLIC parameters of our model. Fig. 10
                            shows that F1-score is not sensitive to SLIC superpixel numbers N but it is sensitive to the m parameter of the SLIC algorithm. So m influences the performance more than N in this framework.

@&#DISCUSSION@&#

After using proposed MRF to obtain three areas, which are nuclei, cytoplasm and background, we provide a solution for drawing contours of nuclei and cytoplasm. This method employs the model labels to identify the different regions and extract the contours of the connected regions. We can set the label of nuclear area as foreground and others as background, and this acquires the nuclear mark image (see Fig. 11
                           ). Fig. 11 shows each course for extracting the contours. Also, the labels of nuclei and cytoplasm as foreground, then obtain the cell mask image. Using connected components detection algorithm, cell image contours are shown in Fig. 11.


                           Fig. 12
                            shows that accurate contours of free-laying nuclei and cytoplasm could be obtained but in real-world dataset, using an MRF to obtain three regions, the performance of proposed model was not better than in Herlev dataset. Numerous debris and overlapped nuclei and cytoplasm of segmented results were problematic. Thus, we need to remove debris and detect each cell in a multi-cell image [10–12]. At the same time, overlapping is a continual challenging problem [29,31,32,13]. Thus future approaches to modify these two problems will help us identify abnormal cell.

@&#CONCLUSION@&#

In this work, we proposed a probabilistic graphical framework, a superpixel-based MRF segmentation model, to separate nuclei, cytoplasm and background in cervical smear images. First, the pixel-based MRF achieved highest evaluation score but took too long time. Then, a superpixel-based MRF was proposed to accelerate segmentation but it was time consuming. To speed the image resolution, IACA of this model was improved using a searching gap mechanism. This gap search algorithm achieves the state-of-the-art accuracy rapidly. In the future, it also can take advantage of CPU and GPU parallel techniques to accelerate this model. Our continuing studies are an open source project, which is hosted at https://github.com/ylzhhn/cervical_smear_mrf_seg.

None declared.

@&#ACKNOWLEDGMENT@&#

This work was supported by the National Natural Science Foundation of China (Project no. 61170287, 61232016, 61303189). We would like to thank the anonymous reviewers for their valuable comments. We are grateful to Dr. Zhou and Dr. Guan for providing real-world dataset. We also thank Fayao Liu, Yuewei Ming, Xifeng Guo, Yongkai Ye and Sihang Zhou for their help.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Operation room tool handling and miscommunication scenarios: An object-process methodology conceptual model

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A conceptual model of the tools handling subsystem of the operation performed in an OR.


                        
                        
                           
                           Concise specification of the communication events in the surgical setting.


                        
                        
                           
                           Providing a solid formal basis for designing a cybernetic agent which can replace a surgical technician.


                        
                        
                           
                           Our surgeon questionnaire results indicate that the surgeons found the conceptual model useful.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Surgical robots

Concept formation

Conceptual modeling

Operative surgical procedures

Process model

@&#ABSTRACT@&#


               
               
                  Objective
                  Errors in the delivery of medical care are the principal cause of inpatient mortality and morbidity, accounting for around 98,000 deaths in the United States of America (USA) annually. Ineffective team communication, especially in the operation room (OR), is a major root of these errors. This miscommunication can be reduced by analyzing and constructing a conceptual model of communication and miscommunication in the OR. We introduce the principles underlying Object-Process Methodology (OPM)-based modeling of the intricate interactions between the surgeon and the surgical technician while handling surgical instruments in the OR. This model is a software- and hardware-independent description of the agents engaged in communication events, their physical activities, and their interactions. The model enables assessing whether the task-related objectives of the surgical procedure were achieved and completed successfully and what errors can occur during the communication.
               
               
                  Methods and material
                  The facts used to construct the model were gathered from observations of various types of operations miscommunications in the operating room and its outcomes. The model takes advantage of the compact ontology of OPM, which is comprised of stateful objects – things that exist physically or informatically, and processes – things that transform objects by creating them, consuming them or changing their state. The modeled communication modalities are verbal and non-verbal, and errors are modeled as processes that deviate from the “sunny day” scenario. Using OPM refinement mechanism of in-zooming, key processes are drilled into and elaborated, along with the objects that are required as agents or instruments, or objects that these processes transform. The model was developed through an iterative process of observation, modeling, group discussions, and simplification.
               
               
                  Results
                  The model faithfully represents the processes related to tool handling that take place in an OR during an operation. The specification is at various levels of detail, each level is depicted in a separate diagram, and all the diagrams are “aware” of each other as part of the whole model. Providing ontology of verbal and non-verbal modalities of communication in the OR, the resulting conceptual model is a solid basis for analyzing and understanding the source of the large variety of errors occurring in the course of an operation, providing an opportunity to decrease the quantity and severity of mistakes related to the use and misuse of surgical instrumentations. Since the model is event driven, rather than person driven, the focus is on the factors causing the errors, rather than the specific person. This approach advocates searching for technological solutions to alleviate tool-related errors rather than finger-pointing. Concretely, the model was validated through a structured questionnaire and it was found that surgeons agreed that the conceptual model was flexible (3.8 of 5, std=0.69), accurate, and it generalizable (3.7 of 5, std=0.37 and 3.7 of 5, std=0.85, respectively).
               
               
                  Conclusion
                  The detailed conceptual model of the tools handling subsystem of the operation performed in an OR focuses on the details of the communication and the interactions taking place between the surgeon and the surgical technician during an operation, with the objective of pinpointing the exact circumstances in which errors can happen. Exact and concise specification of the communication events in general and the surgical instrument requests in particular is a prerequisite for a methodical analysis of the various modes of errors and the circumstances under which they occur. This has significant potential value in both reduction in tool-handling-related errors during an operation and providing a solid formal basis for designing a cybernetic agent which can replace a surgical technician in routine tool handling activities during an operation, freeing the technician to focus on quality assurance, monitoring and control of the cybernetic agent activities. This is a critical step in designing the next generation of cybernetic OR assistants.
               
            

@&#INTRODUCTION@&#

Verbal and non-verbal miscommunications have a critical effect on the surgical outcomes of a procedure, sometimes being the direct cause of errors, inefficiencies and delays during the operational process. While other high-risk/high-stake disciplines, such as aviation, have adopted methods for systematic characterization and identification of communication errors, healthcare still lags behind in this regard. In the operating room (OR), aspects of communication events that have been observed include the content of the communication, the modality in which the communication is presented (gestures, verbally or implicit), and its direction, i.e., who the initiator and the recipient of the event are. The primary goal of this study is to define and characterize these communications events, through a conceptual model, so insights can be used to streamline certain aspects of the tasks in the OR. The final objective of this work is to use a well-defined conceptual model to re-assign mechanistic tasks to cybernetics solutions to enhance overall efficiency and safety during surgical procedures [1]. Since the analysis of communications events is too broad and complicated, the focus of this paper is about modeling the communication events around the handling of surgical equipment.

Modeling communication events in the OR is complicated since there is not a clear standard about how the communications need to be conveyed, it is highly cultural and biased by the members of the surgical team. Moreover, additional factors shape the communication such as the patient's condition, workload, time-pressure, individual skills and the equipment setting. These types of events may be evoked by any member of the surgical team (e.g. resident, a scrub nurse, a circulation nurse, an anesthesiologist, and a surgical technician) through a number of modalities, including explicit (e.g. verbal, gestures, proxemics, gaze) or implicit (prediction). In such an uncontrolled setting, a conceptual model will allow gaining insights about communication exchanges and how/when mistakes occur.

Automated solutions are increasingly being use to support surgical tasks, and are meant to improve the quality of patient care and reduce costs, while improving the patient's well-being. Recently some of the automation based technologies explored the feasibility of replacing certain mechanistic tasks occurring frequently in the OR. These tasks are initiated by verbal or non-verbal commands, or are a result of some type of communication exchange among the surgical team. Having a machine responding to communication events may be difficult, as is applying a ballistic sequence of actions to a specific surgical procedure. A conceptual model based cybernetic system has the potential to address this problem. A prerequisite for developing such as system is developing computer interpretable representation of all the forms of communications exchanges contained in surgical procedures.

Effective integration of automation into the OR can potentially reduce the number of communication problems. For example, by placing in the OR a robot which can recognize and interpret the voice and gesture commands of the surgical team, and predict the required tool, the length of verbal communication chains in the OR could be reduced. Some major benefits might be shortening of procedure time, reducing surgeons’ cognitive load, monitoring the use of instruments, and avoiding retention of surgical instruments within the patient's body. However, there are challenges with implementing a cybernetic solution of this nature. First, communication among the members of the surgical team is complex, involving verbal and non-verbal forms of communication. While speech recognition algorithms have shown recognition performance over 95%, there are still neither satisfactory technologies nor algorithms that can deliver performance comparable to using gaze, gestures and body interaction. Second, robots would need to have performance that is comparable to human surgical technicians in terms of such parameters as speed, prediction of action, and response to unexpected situations.

To address an important part of the human–machine communication challenge, we have characterized and modeled the communication involving instrument handling between surgeons and the surgical staff via both verbal and non-verbal modalities. In this paper we present and discuss the conceptual model which encompasses the structure and behavior of an operation carried out in an OR with focus on surgical tool handling. The model can serve as a baseline for eliciting requirements of an automated cybernetic solution to tool handling in the OR and designing a robotic system that shall meet these requirements. Thus, the conceptual model presented in this study has a direct application to automation of delivery, retrieval, disposal and tracking of surgical instruments. This conceptual model is implemented through Object-Process Methodology (OPM) [2], a conceptual modeling language and approach which is currently in final process of becoming ISO 19450 Publically Available Specification and ISO standard. In this modeling environment, communication events around the use of instruments are modeled as objects, processes and relations between them. The outcomes, potential pitfalls and overall assessments, together with two observational case studies are discussed in the rest of this paper.

@&#BACKGROUND@&#

Errors in the delivery of medical care are the principal cause of inpatient mortality and morbidity, accounting for some 98,000 deaths annually. Ineffective team communication is often at the root of these errors [3–7]. Recent research assessing verbal and non-verbal exchanges in the operating room (OR) has shown that communication failures are frequent; commands are delayed, incomplete, or not received at all, and frequently left unresolved [3]. Firth-Cozens [4] found that 31% of all communications in the OR represent failures, a third of which had a negative impact on the patient. Halverson et al. [5] found that 36% of communication errors were related to equipment use. Some causes of these errors are team instability, e.g., nurses and surgeons that hardly know each other [8], lack of resources, which results in minimal staffing, and distractions. Poor communication among the surgical team can result in higher likelihood of instrument count discrepancies, which can point to surgical instruments retained in the patient's body, among which sponges and towels are the most common [9]. Research conducted in this area so far has focused on the development of taxonomies and modeling tools to describe verbal communications in the OR. For example, Moss and Xiao [10] captured communication patterns in the OR to characterize the information needs for OR coordination using verbal communication. Blom et al. [11] proposed a classification method for analyzing verbal communication during teaching in the OR and its effects in training. Proxemics was introduced for the first time by Moore et al. [12], where analysis of verbal and non-verbal communication in the operating room was characterized using linguistic tools. A high-level conceptual data model representation of the medical setting was introduced by Dolin [13] to analyze the temporal aspects of patients’ symptoms. A conceptual model for a modeling language for medical terminology was introduced by Rector et al. [14]. Kahn and Weng [15] discussed ways for integrating a conceptual model of clinical research informatics into clinical and translational research workflows. Makary et al. [16] presented a conceptual model for the prevention of wrong side surgery. Neumuth discussed a four-level translational approach for modeling surgical processes [17].

In the context of languages for the medical domain, [18] proposed a set of requirements that any modeling language should fulfill. These include that the language be “formal” with regard to syntax and semantics, “conceptual,” “expressive,” “comprehensible,” “suitable,” and “executable.” Table 1
                      summarizes the desired features for six potential candidate languages.

Previous research proposed other conceptual models to describe surgical interventions in a precise and formal specification through conceptual models. These works appear in the rows of Table 1. Most of these works do not fulfill one or more of the requirements originally proposed by [18]. We have found that after Object-Process Methodology, OPM [2], the most complete model is that of Neumuth et al. [17], in which the only missing feature is the ability to execute and validate the model automatically. This is a feature that does exist in OPM, called Vivid OPM and provides a form of expressive animated simulation and enables visual and computational design-level debugging [19,20]. None of these works has used conceptual modeling to design and validate improved communication among the members of the OR team, yet new technologies can greatly impact OR communication. One example is a gesture recognition tool that enables a surgeon to indicate an instrument she or he needs at the moment by simply pointing to or looking directly at it. Key exploratory steps in the development of such biomedical-specific technologies are lacking, however. The first fundamental step is the development of a conceptual model for verbal and non-verbal communications in the operating room OR.

Conceptual modeling is the process of representing system-related knowledge, and the outcome of this activity is a conceptual model. Subsequent, higher order cognitive activities, including understanding, analyzing, designing, presenting, and communicating the analysis findings and design ideas, can be based on the conceptual model. Modern health care in general and the operating room in particular are complex socio-technical systems of modern society. They must be well-designed and well-understood, so that these systems can be managed effectively to improve the quality of human lives. As argued, OR communication is one of the problems whose solutions can greatly contribute to this cause, and in this research we have harnessed conceptual modeling to achieve this goal.

Understanding physical, biological, artificial, and social systems requires a well-founded, formal, yet intuitive methodology that is capable of modeling these complexities in a coherent, straightforward manner. The same modeling paradigm, the heart of the methodology, should serve for both designing new systems and for studying and improving existing ones. It should apply to artificial as well as natural systems, and faithfully represent physical and informatical things alike. This conceptual model provides the basis for new theories and frameworks needed to characterize operating OR communication.

In our work we have elected to use object-process methodology, OPM [2] as the conceptual modeling paradigm, since it can capture the structure and behavior of complex systems in general and medical systems in particular in one type of diagram—Object-Process Diagram (OPD), which is both formal and intuitive. OPM, which is in the process of becoming ISO standard 19450, is also bimodal—it describes model facts in both graphics and text. The graphic modality is the hierarchical set of Object-Process Diagrams, while the textual modality is a corresponding set of sentences in a subset of English, called Object-Process Language (OPL). The model in this work was prepared using the OPM modeling tool, the object-process case tool (OPCAT) [21].

We process with providing the OPM model of the OR toolset handling system and describing it while exposing OPM concepts as we go. Many important and necessary communication aspects of surgery, such as procedural discussions, diagnostics and treatment conversations, and mentoring instructions are not standard or known in advance, so they are not included in this model, which has a focus on communication exchanges related to the handling of surgical instruments.

Modeling with OPM starts with defining the main function of the system being modeled. In our case, we determined that the function of the system is OR toolset handling. Accordingly, Fig. 1
                        , which is the system diagram – the top-level OPD of the system – presents OR Toolset Handling as the only systemic process. Like all OPM processes, it is denoted as an ellipse. The second process in this OPD is the operation, but since it is not within the boundaries of our system, it is considered environmental, i.e., belonging to our system's environment, rather than systemic. To denote this, the Operation ellipse is dashed.

The rest of the elements in the OPD are objects – the rectangular boxes – and links connecting objects to objects or to processes. Our initial design focus has been to build a model that reflects as accurately as possible communication exchanges in the OR around the use of surgical equipment. To model these communication events, we define the players – the interacting objects – which include the members of the surgical staff, i.e., OR nurse, surgical technician, resident, surgeon, and the patient, whose state affects the nature of the communication events. For example, the object Medical Staff is the agent for the Operation process. This is denoted by the agent link—the line ending with black circle (“black lollipop”) at the process end.

OPM is bimodal (includes both graphic and command line constructs). For example, the graphic construct of the object Medical Staff is linked with an agent link to the process Operation. It is automatically translated by OPCAT to the following OPL sentence:


                           Fig. 2
                            is the OPL paragraph of the OPD in Fig. 1, which describes in a subset of English the exact model facts represented graphically in the OPD. The OPL sentence above is part of this OPL paragraph, and it can be found just below the middle line in Fig. 2. Each of the OPL sentences described and discussed below can also be found in this OPL paragraph.

The agent link is an example of a procedural link—a link between an object and a process which relates to the dynamic aspect of the system. Another example of a procedural link is the effect link connecting Operation to Patient. The semantics of this link is that Operation has an effect on Patient by somehow changing her or his state. The OPL sentence reflecting this graphic construct is:

The other type of OPM links are structural links. These are links between objects. An example of a structural link in Fig. 1 is the aggregation participation link – the black triangle whose apex is connected to the whole – the Medical Staff and whose base is connected to each one of the parts of Medical Staff: OR Nurse, Surgeon, Surgical Technician, and Resident. The corresponding OPL sentence in this case is:


                           Surgical Technician is the Medical Staff member who is in charge of the OR Toolset Handling process. This is again indicated by the agent link from this object to this process, giving rise to the OPL sentence:

Another aggregation participation link is between Operation, which is the whole process, and OR Toolset Handling, which is the part—the subprocess that is the function of our system and on which our model focuses. Operation Room and Surgical Procedure are instruments to the OR Toolset Handling process. The semantics of instrument is expressed as the object which is required for the process execution but is not transformed by it. The fact that Operation Room and Surgical Procedure are instrument is denoted graphically by the link from each one of them, ending with a white circle at the process end (“white lollipop”). The corresponding OPL sentence is:

Objects in OPM interact with each other through processes. For example, the patient and the surgical team interact through “operation” and the surgical technician interacts with the Mayo tray object through the OR Toolset Handling process. This process is of paramount importance. Modeling it correctly and in great detail will help detect communications related to the misuse of instruments, retained instruments, and incorrect instrument counts.

OPM enables modeling of and distinction between informatical objects and processes on the one hand and physical ones on the other hand. This is an important distinction since these two types of things obey different sets of laws. For example, Operation Room is physical – it is material and tangible. Surgical Procedure, on the other hand, is informatical – it is a medical protocol to be followed which is recorded as a piece of information, similar to an algorithm or a recipe or a computer program. Graphically, the distinction is between shaded shapes for physical things (objects and processes) and flat, non-shaded for informatical things. Thus, Operation Room, which is physical, is shaded, while Surgical Procedure, which is informatical, is not.

Tagged structural links are user-defined relations between objects. A tagged structural link is denoted by an open arrow with the tag recorded along it such that the concatenation of the source object, the tag, and the destination object make a meaningful OPL sentence about the relation between the two connected objects, For example, the object Surgical Tool is linked by the tagged structural link tagged “is initially on” to the object Mayo Tray, giving rise to the OPL sentence.

Another structural OPL sentence that reflects the tagged structural relation “initiates and responds to” is:


                           Medical staff initiates and responds to communication event.
                        

An important kind (specialization) of Communication Event is Surgical Instrument Request. Surgical Instrument Request is a Communication Event.

Graphically, this is denoted by the blank triangle, which is the generalization-specialization symbol, whose apex is linked to the general object – Communication Event in our case, and whose base is linked to the specialization – Surgical Instrument Request. Like its general object Communication Event, Surgical Instrument Request is an informatical object. The tagged structural link at the bottom of Fig. 1 is pointing from the informatical object Surgical Instrument Request to Surgical Tool, and with the tag relates to, it yields the OPL sentence.

A major problem in any modeling language is how to cope with the large amount of details that a system encompasses. For example, so far we have only modeled the entire OR Toolset Handling process as a single ellipse, but we certainly want to be able to specify the subprocesses of this process in order to be able to extract value from the model. Balance must be maintained, though, between completeness and clarity. The need to add details arises from the need to include as many details about the system as possible to cater to completeness of the system specification, while the need for maintaining clarity of the model imposes a limit on the number of graphical elements that can be included in any single diagram of the model before it gets cluttered to the extent that it becomes incomprehensible. This problem is solved in OPM by a couple of refining/abstraction mechanisms: in-zooming/out-zooming, and unfolding/folding. In the following section we employ in-zooming to specify the three subprocesses of the OR Toolset Handling process.

There are three phases related to the use of the instruments. These are reflected in the three subprocesses of the OR Toolset Handling process: First, the request for a tool has to be handled, then the tool is used, and finally it is disposed of. The first phase, tool request handling, includes activities such as invoking the instrument request, recognizing the communication request (e.g., did the surgeon say “scissors”, or did she perform a gesture that resembles a scissor?), finding the right location of the instrument in the Mayo Tray, retrieving it from the tray and presenting the instrument to the surgeon. The person who initiates the request is often the surgeon, and the person conducting the tool handling is the surgical technician. The second phase, tool utilizing, encompass the different ways that the surgeon uses the instrument. Generally, dexterous operations involve tool gripping and releasing for completing specific steps in the surgical procedure. Oftentimes, the tools are left on the side of the patient, at a reachable region, but outside the opening, and reused later. Some other tools such as retractors, suture, pads and towels are left within the surgical region.

Tools are usually disposed of by the surgical technician, whose decision whether to dispose or not is based on timing, surgical phase, and implicit and explicit requests. The disposal process involves moving the instrument to a bin containing all instruments that must be sterilized, or a different bin for pads and towels that can be regarded as trash.

We model these three phases as three subprocesses of OR Tool Handling: (a) Tool Request Handling, (b) Tool Utilizing, and (c) Tool Disposal. However, doing this in the OPD in Fig. 1 would render the diagram cluttered beyond being useful for conveying the core modeling idea that a system diagram (i.e., the top-level diagram) should convey, namely to provide an overview of the main function of the system and the objects involved in it. Thus we want to avoid complicating this diagram. Instead, we make use of the OPM's in-zooming capability, see Fig. 3
                        ). The three subprocesses of OR Toolset Handling, which are Tool Request Handling, Tool Utilizing, and Tool Disposal, are exposed inside the blown-up ellipse of the OR Toolset Handling ancestor process. The timeline within the in-zoomed ellipse of a process flows from the top of the ellipse to its bottom, so the order of the processes follows their top-to-bottom ordering. Surgical Tool is shown with its states, represented as rounded-corner rectangles inside it: on tray, held by surgeon, inside patient, on surgical bed, disposable, and disposed. These states are ordered according to the lifecycle of a tool: it starts fresh on the Mayo tray, then it is handed to and held by the surgeon, who uses it and may leave it inside the patient. The tool is then taken out of the patient and can be put on the surgical bed or become disposable if it has been lying beside the patient for too long. As such, it is eventually disposed of.

The OPL sentence which enumerates the states of Surgical Tool is:


                        Surgical Tool can be on tray, held by surgeon, inside patient, on surgical bed, disposable, or disposed.

The on tray state is initial, as denoted by the bold contour, while disposed is the final state, as denoted by the double contour. The Tool Request Handling process transforms the Surgical Tool object by changing its state from its initial on tray state to the next state, held by surgeon. The corresponding OPL sentences are:
                           
                              (1)
                              State on tray of Surgical Tool is initial.

State disposed of Surgical Tool is final.

The first process of the four, Tool Requesting, is done by the Surgeon, who is the agent of that process. This process creates the informatical object Communication Event at the initial state initiated and ongoing. More specifically, it creates the informatical object Tool Request and Handoff, which is specialization of Communication Event, at the initial state requested. The following OPL sentences reflect this:
                           
                              (1)
                              
                                 Tool Request and Handoff is a Communication Event.


                                 Tool Requesting yields initiated and ongoing Communication Event and requested Tool Request and handoff.

A major AI element of our modeling system is its ability to automatically generate natural language (English) text that caters to both humans and machines. This OPL text is generated on the fly by the freely available
                           1
                        
                        
                           1
                           Downloadable from http://esml.iem.technion.ac.il/.
                         OPCAT [21] software environment for each OPD separately, as well as for the entire system. The text changes in response to each semantic editing of the graphical modality of the model by the modeler. Moreover, it is also possible to edit text and the graphic view of the model will be automatically updated. However, since this graphic-from-text direction requires familiarity with the syntax of OPL, graphics-from-text generation is less useful than generating text from graphics.

The unique ability of our system to provide both graphical and textual modalities of the same system model is of paramount importance, as it engages the two major communication channels – the visual and the verbal, catering to dual channel processing [22] – of both the modeler and the target audience to enhance the comprehension of the model. This way, both humans, such as surgeons who are requested to validate the model (as we have indeed done) and machines, can relate to the same textual OPL-based specification. While humans use the text to enhance their model understanding, machines can use relevant portions of the OPL text to perform reasoning using first-order logic and to generate code, because OPL is based on a context-free grammar and can therefore be parsed unambiguously. To gain deeper understanding of the contribution of the OPL text, below is the complete OPL text that is equivalent to the OPD in Fig. 5.

Surgeon is physical.

Surgeon consists of Speech System, Hand, Eyes, and Torso.


                        Speech System is physical.


                        Hand is physical.


                        Eyes is physical.


                        Torso is physical.

Surgeon handles Request Modality Selecting.

Communication Event is initiated & ongoing.


                        Initiated & ongoing is initial.

Surgical Tool Request & Hand-off is a Communication Event.

Surgical Tool Request & Hand-off is requested.


                        Requested is initial.

Surgical Tool Request & Hand-off exhibits Request Expressing Modality.


                        Request Expressing Modality can be verbal, gesture, gaze, or proxemics.

Tool Requesting consists of Tool Name Uttering, Tool Gesturing, Tool Gazing, Request Modality Selecting, and Tool Approaching.

Tool Requesting requires Surgical Procedure.

Tool Requesting zooms into Request Modality Selecting, Tool Name Uttering, Tool Gesturing, Tool Gazing, and Tool Approaching.


                        Request Modality Selecting yields Request Expressing Modality.


                        Tool Name Uttering is physical.


                        Tool Name Uttering occurs if Request Expressing Modality is verbal.


                        Tool Name Uttering requires Speech System.


                        Tool Name Uttering yields requested Surgical Tool Request & Hand-off and initiated & ongoing Communication Event.


                        Tool Gesturing is physical.


                        Tool Gesturing occurs if Request Expressing Modality is gesture.


                        Tool Gesturing requires Hand.


                        Tool Gesturing yields requested Surgical Tool Request & Hand-off and initiated & ongoing Communication Event.


                        Tool Gazing is physical.


                        Tool Gazing occurs if Request Expressing Modality is gaze.


                        Tool Gazing requires Eyes.


                        Tool Gazing yields requested Surgical Tool Request & Hand-off and initiated & ongoing Communication Event.


                        Tool Approaching is physical.


                        Tool Approaching occurs if Request Expressing Modality is proxemics.


                        Tool Approaching requires Torso.


                        Tool Approaching yields requested Surgical Tool Request & Hand-off and initiated & ongoing Communication Event.

Consider specifically the three sentences below that concern Tool Gazing:


                        Tool Gazing occurs if Request Expressing Modality is gaze.


                        Tool Gazing requires Eyes.


                        Tool Gazing yields requested Surgical Tool Request & Hand-off and initiated & ongoing Communication Event.

There is almost no need to repeat the explanation: In order for the Tool Gazing process to occur, the value of the Request Expressing Modality – an attribute of Tool request and Handoff – must be “gaze”. This gazing process requires eyes. It changes the state of Surgical Tool Request and Hand-Off to “requested” and that of Communication Event to “initiated & ongoing”.

When the ontology builder decides to add or change or retract an existing concept or procedure, this can be done easily and flexibly. For example, consider the OPL sentence above “Request Expressing Modality can be verbal, gesture, gaze, or proxemics.” This sentence is the textual equivalent of the attribute Request Expressing Modality with its four values (attribute states): verbal, gesture, gaze, and proxemics. Suppose the modeler received feedback from surgeons that (1) gesture is not the correct word to use, nod is more appropriate, and (2) an additional value is possible, when more than one modality is used simultaneously for the same request, e.g., verbal and proxemics. All the modeler needs to do in order to update the ontology is to change in Fig. 4
                         
                        gesture to nod, and to add a fifth state—multimodal. This will automatically update Request Expressing Modality in all the OPDs in the system in which it appears and the above sentence will now read: “Request Expressing Modality can be verbal, nod, gaze, proxemics, or multimodal.” It is possible to express and learn only part of the ontology. For example, the hospital director who needs not get all the details, can be exposed to just a subset of the ontology which is reflected by the first two levels of depth of the OPD tree.

Based on thorough observations of several surgical procedures at Wishard-Eskenazi Hospital in Indianapolis, Indiana, USA, communication exchanges around the handling of surgical instruments were modeled according to their content, direction, and modality. The conceptual model serves as a taxonomy for this type of communications, and its content was acquired on the basis of subjective knowledge gathered during attendance of these procedures. The different objects representing the communication categories were discussed with three surgeons, educators and researchers. Two main communication types were distinguished: verbal and non-verbal. Verbal communication refers primarily to requesting instruments by their names. For example, retractors are requested by a spoken command “retractors”. A problem with spoken communication in the OR is that they lead to miscommunications due to equipment noise (sound of drills, anesthesia machines, etc.); for example, a surgeon might say “50,000 units,” but the anesthetist would hear “15,000unit” [23].

While verbal communication is explicit, the non-verbal is made of three types: gestures, proxemics and implicit (also referred to as “inferred”). Gestures are specific sign hand poses, or hand movements, face expressions, or gaze orientations that can be assigned to request a particular instrument. For example, gestures like “open palm upwards” (see Fig. 5
                        ) are frequently used to signal a request for a hemostat. Gaze is often used to indicate the direction/position of the instrument, when only a small set of instruments is available.

Proxemics refers to the use of the body and the space around to express an idea. For example change in body alignment is crucial to the surgeon's process of disengaging from the act of operating/using a specific instrument, into the act of requesting and waiting for the next instrument.

Implicit messages are those that are inferred by the recipients of the communication. For example, experienced surgical technicians can predict the most likely surgical instrument required based on the context of task, and they will deliver those to the surgeons before an actual request takes place. As an example, surgical sutures are handed to surgeons before they request them (Fig. 6
                        ).

The final key aspect in this taxonomy is determining the model scope and level of detail of the communication exchanges, which correspond to the boundaries of the model and its level of depth. In order of determining those, we will focus on two types of components: entities and activities. Examples of these entities involve the verbal and gesture lexicon and the specific surgical instruments required per surgery. Activities include the specific type of procedure taking place in the OR, high-dexterity tasks and sub-tasks involving manipulating surgical instruments, larger equipment, or the patient. Since our focus is characterizing the communication (verbal, nonverbal and predictive functions) occurring between surgeons and surgical staff, the conceptual model is detailed mainly at the level involving instrument handling. Still, due to lack of space only the highlights of the model are presented.


                        Tool Requesting, whose agent is the Surgeon, can be done in a variety of ways, or modalities. To model this, zooming into Tool Requesting in Fig. 4 exposes five subprocesses. In the first one, Request Modality Selecting, the Surgeon selects the modality by which the Tool Request and Handoff will be carried out. This process creates the object Request Expressing Modality, which is an attribute (designated by the black-in-white triangle) of Tool Request and Handoff, which, in turn, is a specialization of Communication Event. The Request Expressing Modality can be verbal, gesture, gaze, or proxemics. In this model, we assume that exactly one modality is selected. These are modeled as the four values (attribute states) of Request Expressing Modality. The Surgeon is naturally equipped with (consists of) instruments for expressing each modality. For example, if the verbal Request Expressing Modality was selected, the Surgeon uses her or his Speech System as the instrument for Tool Name Uttering, and if the gesture Request Expressing Modality was selected, the Surgeon uses her or his Hand as the instrument for Tool Name Uttering.

The next process in line, Tool Request Handling, whose two agents are Surgeon and Surgical Technician, changes the state of Surgical Tool from its initial state on tray to the state of being held by surgeon. The following OPL sentence reflects this:


                        Tool Request Handling changes Surgical Tool from on tray to held by surgeon.

The Surgeon then utilizes the Surgical Tool, whose state changes as a consequence from held by surgeon to one of the states inside patient, on surgical bed, or disposable. This exclusive OR logical relationship between the three output links emanating from Tool Utilizing to each one of these three states is denoted by the fact that all three links emanate from the same point and they are joined by a dashed arc. Finally, Tool Disposing, which is at the discretion of Surgical Technician, changes the state of Surgical Tool to the final state disposed. Thus we have completed the modeling of the entire lifecycle of a Surgical Tool from its initial on tray state to its final disposed state. However, we are not done yet, since we have not elaborated on the details of some of the subprocesses described above.

The model allows for representing common miscommunication mistakes and their potential outcomes. Errors may occur in any one of the subprocesses of Tool Request Handling, leading to an unsuccessful communication event.

As long as Communication Event is at its initiated and ongoing state, the Tool Request Handling process can proceed. This is indicated by the instrument link from the initiated and ongoing state to the Tool Request Handling process. If any one of the next subprocesses fails, the state of Communication Event is changed, so control is transferred from Tool Request Handling to Error Handling.

The main errors classified by subprocesses are the following: (a) Tool Type Identifying—the tool request was not properly interpreted; e.g., Aortic cross-clamp instead of Allis clamp. (b) Tool Finding
                        —the tool was not found although it is in place. (c) Tool Fetching—holding the required tool was not conducted properly, e.g., it was mishandled or dropped. (d) Tool Presenting—the tool was presented to the surgeon, but the surgeon rejected it, e.g., wrong instrument, not necessary anymore, or the surgeon changed her mind. (e) Tool Handing Off—the surgeon did not pick the instrument from the surgical technician, because it fell down during handing off, or passed in a way that would risk the patient or the surgeon.

There are two critical errors: (1) Tool finding, which can fail due to a retained instrument. If instruments are left behind in a patient's body due to miscommunications, the results can be fatal or require additional surgical procedure to remedy [24–26]. Mistakes in tool and sponge counts directly related to miscommunications happen in 12.5% of surgeries [9]. (2) Tool Handing Off, which, when it fails, can cause injuries and infections due to mishandling of sharps [27]. A prominent example is passing a scalpel from the technician to the surgeon; experienced teams use the term “sharp-down” for safe scalpel handoff, whereas less trained teams rely on non-verbal cues.

Let us proceed with diving into the details of the Tool Request Handling process, which is a main focus of this research. In the OPD in Fig. 7
                        , the Tool Request Handling process of Fig. 3 is in-zoomed, exposing five subprocesses and specifying how each one of them affects the states of the various objects involved. The first subprocess is Tool Type Identifying. If it succeeds, it changes the state of Tool Type from unknown to known. If it fails, it changes Communication Event from its initiated and ongoing state to identify failed state. The dashed arc joining the output links symbolized by the blue and red arrow going out of Tool Type Identifying arrow denotes a XOR (exclusive OR) relation between them. The state transition from the initiated and ongoing state to identify failed state, in turn, is an event that triggers Error Handling process, discussed in the sequel.

As noted, at this point in time, Tool Request Handling stops executing, since Communication Event exited its initiated and ongoing state, which is required for Tool Request Handling to continue. This is an exception handling mechanism that OPM uses to handle cases where the flow of control must deviate from the “sunny day” scenario, where all goes well as planned, to a particular error that must be addressed before the planned flow can be resumed. In our case, an error in each one of the subprocesses of Tool Request Handling causes Communication Event to exit from the desired initiated and ongoing state, thereby interrupting the normal flow and moving to handling the corresponding error. These exits from the initiated and ongoing state are the set of faint (pink) arrows emanating from this state to each one of the Tool Request Handling subprocesses. Successful completion of Tool Type identifying changes the state of Tool Type – an attribute of Surgical Tool (as expressed in Fig. 3) – from unknown to known. The fact that Tool Type is known is a condition for executing the next subprocess, Tool Finding.

A pattern similar to the one associated with Tool Type Identifying repeats with Tool Finding: If Tool Finding succeeds, the state of Tool Request and Handoff changes from identified to found. However, if Tool Finding fails, the state of Tool Request and Handoff does not change from identified to found; instead, Communication Event changes from initiated and ongoing to find failed.

Tool Fetching is modeled similarly. However, if Tool Fetching succeeds, not only does it change the state of Tool Request & Handoff from found to fetched, but the state of the physical object Surgical Tool itself. It changes from on tray to held by technician. This (Surgical Tool) is the first subprocess that actually affects Tool Request Handling. Tool Presenting (which is the next subprocess) and Tool Fetching do not change the state of the Surgical Tool; and they are part of the communication between the Surgical Technician and the Surgeon. Tool Presenting changes Tool Request and Handoff from fetched to presented. Upon successful completion of Tool Presenting, Tool Handing Off occurs, changing the state of Surgical Tool from held by technician to held by surgeon.

In order to validate the OR Toolset Handling model, we observed three surgeries at the Eskenazi Hospital in Indianapolis, Indiana, USA: trauma, elective, and training. The trauma surgery consisted of repairing a vascular ischemic injury caused to a male cyclist as a result of a traffic accident. The transected blood vessel in the leg was sutured and repaired by the vascular team and an angiogram was used to check proper intravascular flow. The fractured lower leg was then aligned by the orthopedic team. This procedure requires a team of a surgeon and a surgical technician. The surgeon used a small set of instruments, which were anticipated by the technician in most cases. These observations provided the basis for the model. For example, we identified an error during Tool Handing Off, in which a scalpel was passed back toward the surgical technician with the sharp pointing outwards.

The elective surgery was an open abdominal aortic aneurysm repair. An overly dilated portion of the abdominal aorta had to be repaired, requiring dissection and ligation of intervening veins, aneurysm resection and repair, and retroperitoneal and abdominal incisional wound closure. The number of tools used in this procedure was higher than that in the previous one, and they were requested mostly by voice or gestures.

The training procedure was observed and recorded during February 2013 as part of the Trauma Operative Management (ATOM) course, where resident surgeons are trained for damage-control laparotomies by using porcine models. A mentor surgeon is paired with a resident to support complex procedures. The presented scenario was that of 43-year old male stabbed in the lower abdomen, which required repair of the intraperitoneal bladder laceration, and injury of the ileum. The surgical instruments were selected by the resident or by the mentor surgeon. In this procedure the resident used about 20 instruments.

A second study was conducted to validate the conceptual model using a structured questionnaire distributed to surgeons. The goal of this user validation study was to collect data to provide a basis for determining the expressiveness of the conceptual model and its ability to reflect real-world scenarios in the operating room by professionals who would be future users of the target system to be developed—the robotic OR technician. We used the results also to determine the information needs of the surgical staff that are missing in our OPM conceptual model. The questionnaire aimed to address the following issues related to the conceptual model:
                           
                              (1)
                              Accuracy (Q1–4): To what extent are all the main objects and processes related to the delivery of surgical instruments included in the model?

Flexibility (Q5–6): If expanded, how the model can detect failures in the delivery process?

Generality (Q7–8): To what extent does the model help identify the steps and tasks that a robotic scrub nurse should perform in the surgical delivery task?

These issues were addressed through a set of eight questions, which were administered to five surgeons (ages 30–40 years old) at the Sheba Medical Center in Ramat Gan, Israel, over a period of one month (April–May 2014). All were maxillofacial surgeons. Each question included a validated five point Likert scale. A briefing was given to the surgeons before administering the questionnaire. The briefing covered issues related to the meaning and understanding of the symbols in the OPCAT model and what they represent in the context of surgery. A combination of ethnographic field notes and direct observations were used to record additional comments provided by the surgeons surveyed. Questionnaires were administered over two 2-week periods, and were distributed across all days of the week, times within the day and department. This collection method allowed for a representative sample of response to enhance the ability to generalize the results beyond this small group of surgeon.

The questions were clustered into the three themes (accuracy, flexibility and generality). As an example, questions like “To what extent are all the main objects involving the OR Toolset Handling process included in the model?”; “If expanded, to what extent can this model help detect potential problems in the delivery of instruments?”, and “To what extent does replacing the OR technician by a new one affect the accuracy of this model?”, were from themes 1, 2, and 3, respectively. The results are presented in Table 2
                        .

The surgeons agreed that the conceptual model was relatively flexible (3.8 of 5, std=0.69) and could be extended to other processes, e.g., validating the correct side of surgery. The surgeons also ranked the accuracy of the model, i.e., the extent to which it reflects the real system, and its generality as “somehow high” (3.7 of 5, std=0.37 and 3.7 of 5, std=0.85, respectively).

Some general comments were common among the surgeons. There was an overall agreement that the conceptual model faithfully reflects common procedures. However, under unexpected situations and/or complications there are ad-hoc elements that were not included in the model. Two surgeons indicated that some agents involved in the process are missing: the technical assistant in charge of bringing the patient to the OR and the anesthesiologist. The surgeons agreed that the states were well represented, except for a missing state, “on-magnet”, which describes the situation in which instruments are held by a magnet strip placed over the patient to enable easy access to the instruments while preventing them from falling. One surgeon commented that this model could be extended very easily to track missing sponges and surgical pads.

This paper has presented a detailed conceptual model of the tools handling subsystem as they are used during surgical operations in an OR. The model focuses on the details of communications and interactions taking place between surgeons and a surgical technician during an operation, with the objective of pinpointing the exact circumstances in which errors occur. Exact and concise specification of the communication events in general, and in particular for surgical instrument requests, is a prerequisite for a methodical analysis of the various modes of errors and the circumstances under which they occur. This, in turn, has significant potential value in two orthogonal directions. One is a systematic reduction in tool-handling-related errors during operations. The other is providing a solid formal basis for designing a cybernetic agent which can replace a surgical technician or a “scrub nurse” [28] in routine tool handling activities during an operation, freeing the technician to focus on quality assurance, monitoring and control of the cybernetic agent activities. For example, machines are much better at accounting for all the tools being used in an operation, so they can alert when a tool or a sponge is missing, preventing a patient from being wheeled away from the OR with a foreign object in her body. Our surgeon questionnaire results indicate that the surgeons found the conceptual model useful and therefore it can serve as a basis for eliciting requirements for an automated solution to the communication issues between the surgeon and the OR technician. One limitation of this study is the limited amount of surgeons participating in the study, and the fact that they were all maxillofacial surgeons. In order to assess the extent of generality that our conceptual model has, more surgeons need to be recruited among a diverse range of surgical specialties. Having provided a fundamental study about modeling the communications in the OR through conceptual modeling first will facilitate the engaging of a larger group within the clinical community.

We have been conducting research on the physical-informatical duality of threat handling processes [29], and future research will use the tool handling system modeled in this paper as a basis for understanding the reasons for miscommunications stemming from differences between reality and the way it is perceived by the interacting agents, be they human or artificial.

@&#ACKNOWLEDGMENTS@&#

The authors wish to thank EU FP7 VISIONAIR Infrastructure Project #262044 for partially supporting this research. This publication was made possible partially by the NPRP award (NPRP 6-449-2-181) from the Qatar National Research Fund (a member of The Qatar Foundation). The statements made herein are solely the responsibility of the authors.

@&#REFERENCES@&#


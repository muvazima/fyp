@&#MAIN-TITLE@&#A hybrid automated detection of epileptic seizures in EEG records

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new automated seizure detection model is proposed.


                        
                        
                           
                           Applying Weighted Permutation Entropy to classify raw and decomposed EEG signals.


                        
                        
                           
                           Simulating physiological and environmental artifacts to test the model robustness against noise.


                        
                        
                           
                           Comparison between Support Vector Machine and Artificial Neural Network classifier.


                        
                        
                           
                           Comparison with other automatics seizure detection models found in literature.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Electroencephalogram (EEG)

Epileptic seizure detection

Weighted Permutation Entropy (WPE)

Support Vector Machine (SVM)

@&#ABSTRACT@&#


               
               
                  The paper introduces a new automated seizure detection model that integrates Weighted Permutation Entropy (WPE) and a Support Vector Machine (SVM) classifier model to enhance the sensitivity and precision of the detection process. The proposed system utilizes the fact that entropy based measures for the EEG segments during epileptic seizure are lower than in normal EEG. The new suggested model better tracks abrupt changes in the signal and assigns less complexity to segments that exhibit regularity or are subjected to noise effects. The Weighted Permutation Entropy algorithm relies on the ordinal pattern of the time series along with the amplitudes of its sample points. The proposed technique is implemented and tested on hundreds real EEG signals and the performance is compared based on sensitivity, specificity and accuracy. Various experiments have been applied in different scenarios including healthy with eyes open, healthy with eyes closed, epileptic patients during no-seizure state from two different location of the brain. Other scenarios have been applied accompanied by background simulated noise resulting from physiological and environmental artifacts. Results showed outstanding performance and revealed promising results in terms of discrimination of seizure and seizure-free segments. It also manifests high robustness against noise sources.
               
            

@&#INTRODUCTION@&#

Epilepsy is a common long-term neurological condition in which nerve cell activity in the brain becomes disrupted. According to the WHO [1], about 0.6% of the general population suffers from epilepsy and nearly 80% of the affected people are found in developing regions. It manifests clearly through “epileptic seizure”, a period of sudden recurrent and transient disturbances of perception or behavior resulting from excessive synchronous activity of neurons in the brain. Only two third of epileptic patients can control seizures through medications. The remaining third develop drug-resistant epilepsy and are referred for a resection surgery where seizure onset zone (SOZ) is removed. Candidates for the surgery undergo many pre-surgery investigations where the most important is the long term Electroencephalographic (EEG) monitoring to capture seizures for off-line analysis. Expert neurologists then visually inspect the collected EEG data to detect epilepsy-related activity so they can determine the area where the seizures begin, called the seizure focus, and hence conclude whether the surgery is feasible [2]. The EEG has been a very useful clinical tool; it measures the electrical activity and represents potential differences from different sites of the human brain. EEG video monitoring generates a lengthy EEG recordings data for the clinical neurophysiologists to review and analyze seizures that occurred during the monitoring period. However, locating epileptic activity in a continuous EEG recording lasting several days or weeks is an exhausting, demanding and time-consuming task because such activity represents a small percentage of the entire recording. In an earlier study [3], that included 4 human experts to mark an EEG of 8 h, it was shown that here was little variation between readers. High seizure rate, short seizure duration and long seizure durations with ambiguous offsets can complicate the analysis and result in poor correlation. These difficulties have motivated the development of automated methods that scan, identify, and then present to a neurophysiologist epochs containing epileptic events. Such systems help to overcome the limitations of the traditional visual inspection performed by expert neurologists and avoid any misreading or missing information.

This paper introduces an automated seizure detection model that integrates Weighted Permutation Entropy (WPE) as input feature to a Support Vector Machine (SVM) learning model to enhance the sensitivity and precision of the detection process. WPE is a modified statistical parameter of the permutation entropy (PE) suggested by Bandt and Pompe [4]. It measures the complexity and irregularity of a time series by combining the ordinal pattern and the amplitude of its sample points. The feasibility of WPE as a feature for automated seizure detection has not been investigated so far.

The paper is organized as follows: Section 2 provides a cover of some related work presented in literature. Section 3 describes the medical background of epilepsy and brain seizures onto which the work was built, while Section 4 introduces the proposed seizure detection model and the dataset used. The model validation and experiments are demonstrated in Section 5. Results and discussion are illustrated in Sections 6 and 7, respectively. Finally, conclusion and suggestions for future work are illustrated in Section 8.

The automatic seizure detection system is a two stage problem; EEG recordings serve as input to a feature extraction phase, and then the features extracted are fed into a classifier. The features extraction methods exploited by researchers include; time-based features such as amplitude, duration, and sharpness [5]. Also frequency-based features such as fast Fourier transform [6], power spectral density [7]. The EEG signal being a non-stationary signal can be described by time-frequency features such as time frequency distribution [8] and wavelet analysis [9,10]. Complexity measures have been also suggested to describe the chaotic behavior of EEG, such as Lyapunov exponent [11] and fractal dimension [12]. Other nonlinear parameters include second-order difference plot and phase space representation of intrinsic mode functions [13,14]. Fractional linear prediction and Gabor filter have been also applied [15,16].

The work presented in this paper focuses on entropy -based features; it utilizes the fact that the entropy of EEG seizure segments is lower than in normal EEG due to the synchronicity firing of the neurons during an epileptic seizure [17]. Among the entropy measures applied; Approximate Entropy [18]. Sample entropy [19], spectral entropy [20], permutaion entropy [21]; or a combination of more than one entropy measure [22,23]. Others combined time frequency analysis with Approximate Entropy [24]. The classification methods employed vary from naive Bayes classifiers [8], fuzzy logic classifiers [11], linear classifiers [24] but the most used in literature are Support Vector Machines [21,25] and Artificial Neural Networks [8].

The role of EEG in the seizure detection process is very important compared to other approaches such as Magnetoencephalography (MEG) and functional Magnetic Resonance Imaging (fMRI) in terms of safety and cost. For an epilepsy diagnosed patient, the EEG recordings can belong to one of four categories; Pre-ictal refers to the state immediately before the actual seizure, though it has recently come to light that some of characteristics of this stage (such as visual auras) are actually the beginnings of the ictal state. Ictal refers to a physiologic state or event such as a seizure. Post-ictal refers to the state shortly after the event. Inter-ictal refers to the period between seizures characterized by electrical abnormalities known by neurologists as subclinical seizures of an epilepsy disorder. For most people with epilepsy, the inter-ictal state corresponds to more than 99% of their life.

Measuring the brain activity be achieved through two methods; the non-invasive EEG implies fixing the electrodes to the subject's scalp where the electrode positions can be chosen according to the standardized 10–20 system. On other occasions, extra-cranial EEG is not efficient so and invasive approach that involves an operation under general anesthetic to place electrodes either on the surface or deep within the brain. These electrodes are attached to a video electroencephalogram (EEG) monitor and the patient is monitored continuously [26]. The electrical activity along the brain can be divided according to frequency ranges. Activity lower than 4 Hz is called delta (δ) activity. Theta (θ) activity is the range of 4–8 Hz, alpha (α) is 8–13 Hz, beta is (β) 13–30 Hz, and activity above 30 Hz is called gamma (γ) activity.

The proposed model includes a data acquisition phase followed by a pre-processing phase, a phase for segmenting each EEG channel into fixed length windows, a feature extraction phase where the Weighted Permutation Entropy (WPE) is estimated for each window, and finally a classification phase where EEG records are divided into one of two clinically significant EEG classes: (1) seizure and (2) no-seizure. The procedure of the proposed SVM classification for automated epileptic seizure detection system is shown in Fig. 1.
                     
                  

For the suggested model testing, three scenarios were applied. The first scenario implies extracting WPE values from raw EEG data after segmentation directly which requires no pre-processing of the data. A second scenario involves a pre-processing phase of applying wavelet decomposition to extract the different physiologically relevant frequency sub-bands. A third scenario that aims to test the model against signal noise requires projection of artifacts sources into the dataset first.

Most of the patient's data is not generally accessible through hospitals and medical clinics for confidentiality purposes. For this reason, the experimental data used in this paper was obtained from the publically available Bonn data set “Klinik für Epileptologie, Universität Bonn’’ [27]. The dataset includes five different sets (Z, O, N, F and S). Set Z and O contain surface EEG recordings that belong to five healthy subjects in relaxing state. Set Z is recorded with subject's eyes were open while set O was recorded when subjects eyes were closed. Sets N, F, S contain intracranial recordings from depth and strip electrodes collected from five epileptic patients. Set N contains seizure-free intervals from the hippocampal formation of opposite hemisphere, set F contains seizure-free intervals from epileptogenic zone, and set S contains epileptic seizure segments from all channels. Each set contains 100 single channel EEG artifact-free segments of 23.6 s duration. All EEG signals are recorded at a sampling rate of 173.61 Hz using a 128-channel amplifier system with an average common reference, and are band-pass filtered at 0.53–40 Hz. Table 1
                         summarizes the Bonn dataset and Fig. 2
                         shows the first EEG record from each of the five classes available in the dataset.

The WPE was originally suggested by Fadlallah et al. [28], it is a complexity measure which has aspects of both dynamical systems and entropy measures. It extends the main concept of the PE based on comparing neighboring values but at the same time incorporates the different amplitude values per each ordinal pattern. It estimates complexity as the entropy of the distribution of permutations of groups of time samples and the variance of their amplitudes. Thus, the variation of WPE as a function of time can effectively indicate the dynamic changes in any real world data. It has been shown that any continuous time series representing a dynamical system can be mapped on to symbolic sequence. According to the embedding theorem, any arbitrary time series x(t) where t = 1, 2, 3, … , T can be mapped onto `m’ dimensional space with vectors

                           
                              (1)
                              
                                 
                                    
                                       X
                                       t
                                    
                                    =
                                    
                                       {
                                       
                                          x
                                          
                                             t
                                             ,
                                          
                                       
                                       
                                          x
                                          
                                             t
                                             +
                                             τ
                                          
                                       
                                       
                                          x
                                          
                                             t
                                             +
                                             2
                                             τ
                                          
                                       
                                       …
                                       ,
                                       
                                          x
                                          
                                             t
                                             +
                                             (
                                             m
                                             −
                                             1
                                             )
                                             τ
                                          
                                       
                                       }
                                    
                                 
                              
                           
                        The WPE parameters are the embedding dimension (m) representing the number of values in each sequence, and the delay time for embedding (τ) (the number of samples spanned by each section of the sequence).

Each of the N = T − m + 1 sub-vector X is characterized by two properties:

                           
                              i
                              The arrangement of its components in a certain order, each considered as symbolic pattern which will be one of the m! possible permutations of `m’ distinct symbols.

The amplitudes distribution of its components which represents the total weight of the sequence.

The weight ωj of each sequence j can be calculated using the variance as:

                           
                              (2)
                              
                                 
                                    
                                       ω
                                       j
                                    
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       m
                                    
                                    
                                       
                                          (
                                          
                                             x
                                             
                                                j
                                                +
                                                
                                                   (
                                                   
                                                      t
                                                      +
                                                      1
                                                   
                                                   )
                                                
                                                τ
                                             
                                          
                                          −
                                          
                                          
                                             
                                                X
                                                j
                                             
                                             ¯
                                          
                                          )
                                       
                                       2
                                    
                                 
                              
                           
                        where

                           
                              
                                 X
                                 j
                              
                              ¯
                           
                         is the arithmetic mean of sequence j given by:

                           
                              (3)
                              
                                 
                                    
                                       
                                          X
                                          j
                                       
                                       ¯
                                    
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       m
                                    
                                    
                                       x
                                       
                                          j
                                          +
                                          
                                             (
                                             
                                                t
                                                +
                                                1
                                             
                                             )
                                          
                                          τ
                                       
                                    
                                 
                              
                           
                        The probability distribution of each pattern with weight ω can be represented as:

                           
                              (4)
                              
                                 
                                    
                                       P
                                       ω
                                    
                                    
                                       (
                                       
                                          π
                                          i
                                       
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                <
                                                N
                                             
                                          
                                          
                                             1
                                             
                                                u
                                                :
                                                t
                                                y
                                                p
                                                e
                                                
                                                   (
                                                   u
                                                   )
                                                
                                                =
                                             
                                          
                                          
                                             π
                                             i
                                          
                                          
                                             (
                                             
                                                X
                                                j
                                             
                                             )
                                          
                                          .
                                          
                                             ω
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                <
                                                N
                                             
                                          
                                          
                                             1
                                             
                                                u
                                                :
                                                t
                                                y
                                                p
                                                e
                                                
                                                   (
                                                   u
                                                   )
                                                
                                                =
                                             
                                          
                                          π
                                          
                                             (
                                             
                                                X
                                                j
                                             
                                             )
                                          
                                          .
                                          
                                             ω
                                             j
                                          
                                       
                                    
                                 
                              
                           
                        where

                           
                              
                                 ∑
                                 
                                    j
                                    <
                                    N
                                 
                              
                              
                                 1
                                 
                                    u
                                    :
                                    t
                                    y
                                    p
                                    e
                                    (
                                    u
                                    )
                                    =
                                 
                              
                              
                                 π
                                 i
                              
                              
                                 (
                                 
                                    X
                                    j
                                 
                                 )
                              
                           
                         defined as 1 if the pattern π
                        
                           i
                         is the same as the sub-vector Xj
                         and 0 otherwise. j is the total number of vectors for a given time series (1 < j < N), and i is the distinct number of symbols for a given embedding dimension (i ≤ m!). Note that the relation 
                           
                              
                                 ∑
                                 i
                              
                              
                                 P
                                 ω
                              
                              
                                 (
                                 
                                    π
                                    i
                                 
                                 )
                              
                              =
                              1
                           
                         still holds. According to the Shannon entropy, WPE can be computed as:

                           
                              (5)
                              
                                 
                                    
                                       H
                                       ω
                                    
                                    
                                       (
                                       
                                          m
                                          ,
                                          τ
                                       
                                       )
                                    
                                    =
                                    −
                                    
                                       1
                                       
                                          ln
                                          
                                             (
                                             
                                                m
                                                !
                                             
                                             )
                                          
                                       
                                    
                                    
                                       ∑
                                       
                                          P
                                          ω
                                       
                                    
                                    
                                       (
                                       
                                          π
                                          i
                                       
                                       )
                                    
                                    ln
                                    
                                       P
                                       ω
                                    
                                    
                                       (
                                       
                                          π
                                          i
                                       
                                       )
                                    
                                 
                              
                           
                        The 1/ln(m!) is a normalization factor such that the final WPE value ranges from 0 to 1.

In our analysis, feature extraction is performed using a sliding data frame (window/epoch) approach. A single WPE value is calculated for each window; any change in the dynamics of the system will be reflected in the variation of WPE with respect to moving window. For a reliable estimation of WPE, the window length Tw should be greater than m! In our analysis, each EEG channel was buffered in non-overlapping and overlapping windows of approximately 0.35 s which corresponds to 64 values per window. This results in 64 and 128 windows per channel for non-overlapping and overlapping segmentation techniques, respectively. For overlapping window segmentation, the EEG channel has a shift forward of 0.175 s corresponding to 32 values of overlap between consecutive windows.

To compare the results achieved from classifying raw EEG data, wavelet transform has been used as a preprocessing phase to apply the WPE on the various frequency components of the EEG signal. The wavelet transform has the advantage of the variable window size according to the frequency band. The spectral analysis of the EEG signals through wavelet transform translates its lengthy data into few features [29,30]. Wavelet transform can represent EEG sub bands as a weighted sum of shifted and scaled versions of the original wavelet, without any loss of information and energy. In order to extract five physiological EEG bands, delta (0–4 Hz), theta (4–8 Hz), alpha (8–13 Hz), beta (13–30 Hz), and gamma (30–60 Hz), four levels discrete wavelet transform (DWT) with third-order Daubechies (db3) wavelet function have been used. Such choice of the mother wavelet is also supported by many works in literature [9,31]. Since our dataset is in range 0–60 Hz, coefficients D1, D2, D3, D4 and A4 were extracted corresponding to 30–60 Hz, 15–30 Hz, 8–15 Hz, 4–8 Hz and 0–4 Hz, respectively. Weighted Permutation Entropy is calculated for each sub-band separately and then all WPE values are fed into the classifier. Fig. 3
                         shows a sample. EEG channel of dataset S and its decomposed frequency bands.

The features extracted through the estimation of the WPE values serve as input to the classifier and a training model is built to discriminate between seizure and no-seizure intervals. In our study, the results obtained from the Support Vector Machine classifier (with both linear and non-linear kernels) are compared to the results of the Artificial Neural Network Classifier.

Support Vector Machine is a supervised learning algorithm introduced in 1995 by Vapnik. The built model maps the training data into different categories separated by a decision boundary. Given a training example {xi, yi
                           } and a class label with one of two values (yi
                            ∈ {1, −1}). The decision boundary represented by (w, b), where w is a vector containing the hyperplane parameters and b is an offset. The data is rescaled so that that anything on or above the boundary wTx + b = 1 is of one class (with label 1), and anything on or below the boundary wT x + b = −1 is of the other class (with label −1). The in-between distance is called the margin defined as
                              
                                 2
                                 
                                    
                                       |
                                       
                                          |
                                          w
                                          |
                                       
                                       |
                                    
                                    2
                                 
                              
                           . Finding the maximal margin is equivalent to minimizing ||w|| which can be achieved through quadratic programming and the optimal hyperplane can be described by: 
                              
                                 w
                                 =
                                 
                                    ∑
                                    
                                       α
                                       i
                                    
                                 
                                 
                                    y
                                    i
                                 
                                 
                                    x
                                    i
                                 
                              
                           .

However, the separation task is not always linear especially real complex classification problems, SVM then extends the data from the input space into a higher dimensional space where the data is separable. It achieves this type of mapping through kernel induced feature space. A kernel function is a function that only deals with the dot product of the data. The optimal hyperplane can be then expressed as 
                              
                                 f
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       α
                                       i
                                    
                                 
                                 
                                    y
                                    i
                                 
                                 K
                                 
                                    (
                                    
                                       
                                          x
                                          i
                                       
                                       ,
                                       x
                                    
                                    )
                                 
                                 +
                                 b
                              
                            
                           [32].

The mathematical model of the basic artificial neuron is based on three simple sets of rules: multiplication, summation and activation. The inputs are multiplied with individual weight. In the middle section of artificial neuron is a sum function that sums all weighted inputs and bias. At the exit of artificial neuron the sum of previously weighted inputs and bias is passing through activation function that is also called transfer function [33]. The output value y(k) in discrete time kcan be described mathematically as;

                              
                                 
                                    
                                       y
                                       
                                          (
                                          k
                                          )
                                       
                                       =
                                       F
                                       
                                          (
                                          
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   0
                                                
                                                m
                                             
                                             
                                                w
                                                i
                                             
                                             
                                                (
                                                k
                                                )
                                             
                                             .
                                             
                                                x
                                                i
                                             
                                             
                                                (
                                                k
                                                )
                                             
                                             +
                                             b
                                          
                                          )
                                       
                                    
                                 
                              
                           where
m the total number of inputs is, xi
                           (k) is the input value, wi
                           (k) is the weight value, b represents the bias and F is a transfer function. Transfer function defines the properties of artificial neuron and can be any mathematical function. The classification problem to be solved defines the function to be used. Popular transfer functions include step function, linear function and non-linear sigmoid function. Combining artificial neurons constructs an Artificial Neural Network capable of solving complex real-life problems by processing information in their basic building blocks (artificial neurons).

Experiments have been carried out to validate the efficiency of the proposed seizure detection system and also its capability of detection and robustness to noise. Although the data set has five different classes of EEG segments (healthy with eyes open, healthy with eyes closed, interictal state obtained from epileptic zone, interictal state obtained from hippocampus zone of brain, and ictal state). The aim of this study is to detect segments with epileptic seizure activity so the multi-class problem is reduced to a one-against-one classification, i.e. 4 different binary classification problems were formed; set Z versus set S, set O versus set S, set N versus set S and finally set F versus set S.

One common measure of performance is the accuracy, incorporating both a classifier's sensitivity and specificity, defined as follows:

                           
                              (6)
                              
                                 
                                    
                                       Accurcay
                                       =
                                    
                                    
                                       
                                          TP
                                          +
                                          TN
                                       
                                       
                                          TP
                                          +
                                          FN
                                          +
                                          TN
                                          +
                                          FP
                                       
                                    
                                 
                              
                           
                        The confusion matrix parameters for the seizure detection analysis can be interpreted as follows; true positive (TP): seizure events detected by both the algorithm and the expert neurologists, true negative (TN): Events identified as non-seizures by both the algorithm and the expert neurologists, false positive (FP): seizure events detected by the algorithm, but not scored by the expert, and false negative (FN): events identified as seizures by the experts but were missed by the algorithm. The sensitivity represents the number of correctly detected positive patterns/total number of actual positive patterns.

The accuracy of each classifier is assessed using cross-validation with 10 folds. The data will be divided equally 10 subsets, a single subsample is retained as the test set for validating the model, and the remaining 9 subsamples are used as training data. The cross-validation process is then repeated 10 times (the folds), with each of the 10 subsets used exactly once as the validation data. The mean accuracy values are measured for both raw EEG channels (using different segmentation techniques) and also the decomposed frequency bands.

Although the WPE calculation is easy and simple, an important step before extracting the features is to set the parameters (the dimension order and time lag) of the algorithm. The dimension order of WPE (m) should not be too small as this will not give enough number of distinct states. Any change in m will affect the window size of the segmentation as the window size value needs to be larger than m!. Too large values of order `m’ will demand large values of window size which will not effectively detect dynamical changes and will create memory restrictions. Optimum values of order of WPE are reported to be around 3–8 [4]. Table 2
                         shows the set of values tested for dimension order m and the corresponding window sizes chosen and features extracted for each segmentation technique. Fig. 4
                         shows that order dimension of value 3 has the best discrimination performance in classifying the EEG segments. The classification levels mentioned were calculated on the basis of averaging all classification accuracy for each non-seizure dataset versus dataset S.

Many methods exist for the calculation of the appropriate time lag τ such as false nearest neighbor calculation and first minimum of autocorrelation function [34]. Time lag represents the number of samples spanned when dividing the time series. Different values of time lag were tested (τ = 1, τ = 2, τ = 3) and compared. As observed in Fig. 5
                        , the highest overall classification accuracy obtained through linear Support Vector Machine when time lag was set to 1. Greater values of time lag decrease the accuracy achieved by at least 8%. Our findings with regards to the appropriate time lag are in agreement with previous studies, that in EEG processing, τ value is usually set to 1 [35,21]. It is adequate to span each and every value along the signal to extract most of the information in the EEG, hence this value is commonly chosen in EEG analysis.

The data set used in this paper was visually inspected for non-cerebral origin (artifacts) and thus all EEG segments are noise free. However the EEG data acquisition process is usually accompanied by many noise sources [36]. For real-time classification, the proposed model must show enough classification sensitivity to noisy EEG segments.

To be accurate, a solution must distinguish seizure signal from those caused by the activity of artifacts whose spectral domain often overlaps that of seizures. EEG artifacts can be divided into two categories; physiological artifacts and environmental. Physiological artifacts arise from the patient himself and it includes cardiogenic activity, eye movement such as blinking, and muscle artifacts such as perspiration. Environmental or extra-physiological artifacts include external electrical interference from other power sources, electrode pop, instrumental disorder and non-symmetrical electrode placement. To simulate real EEG segments, a noise was added to raw EEG data of the five data sets in this experiment before the segmentation stage even begins. The procedure for creating artifacts was derived from [37].

Eye blinks and muscle artifacts were simulated using random noise band-pass filtered (FIR) between 1–3 Hz and 20–60 Hz, respectively and added to a random number of channels for each dataset (range 20–45). Electrical shift artifacts are implemented through discontinuities and unfiltered linear trends at other randomly selected channels (range 0–5). Fig. 6
                         shows the simulated artifacts and samples of the contaminated EEG channel from the datasets.

@&#RESULTS@&#


                        Fig. 7(
                        a) shows the corresponding estimated WPE values (τ = 1, m = 3) for the entire 23.6 s EEG segments buffered in non-overlapping technique depicted in Fig. 2. The figure shows that the estimated WPE values are the lowest for EEG seizure segments (set S) compared to all the other datasets. A single Weighted Permutation Entropy value is calculated per window. For the overlapping segmentation techniques, same patterns are obtained that can be observed in Fig. 7(b). Furthermore, Fig. 8
                         shows the mean WPE values of all channels for each available dataset. From all means calculated, the lowest belongs to dataset S (seizure EEG recordings) followed by set O (healthy with eyes closed), set N (interictal from hippocampus formation of the brain) and finally set Z and set F (healthy with eyes open and interictal from epileptogenic zone of the brain, respectively).

The WPE values calculated supports the model hypothesis that the entropy of the EEG decreases during seizure intervals, and also assure that the WPE based feature can discriminate seizure activity.

In the classification of 0.35 s segments of seizure and non-seizure activity using the 1-dimensional WPE features, a maximum specificity of 99.5% (linear kernel, non-overlapping windows), 93% (RBF kernel, overlapping windows), 96% (linear kernel, overlapping windows), and 99% (linear kernel, non-overlapping windows) were obtained for sets Z, O, F and N, respectively. Fig. 9
                        (a, b, c and d) show the sensitivity and specificity respectively, obtained for each dataset for linear and non-linear kernels and for both segmentation scheme. The non-linear SVM classifier with RBF kernel consistently performs better than the linear classifiers, but among the non-overlapping and overlapping techniques there seems no clear standout, as each performs best on one of the four datasets. To further investigate the ability of the SVM to identify seizure and no seizure activity, we compared it with the ANN learning model. The sensitivity and specificity of the ANN can be observed in Fig. 10
                        (a, b). Table 3 shows that the SVM with RBF kernel outperforms the ANN in all the classification problems. The linear SVM performance is very similar to that the performance of ANN.

Since our dataset is in range 0–60 Hz, coefficients D1, D2, D3, D4 and A4 corresponding to 30–60 Hz, 15–30 Hz, 8–15 Hz, 4–8 Hz and 0–4 Hz, respectively were extracted, that are almost standard physiological sub-bands. Weighted Permutation Entropy is calculated for each sub-band separately and then all WPE values are fed into the classifier Table 4 shows the classification accuracy for the datasets after the wavelet decomposition. Better performance accuracy is achieved by extracting features from raw EEG data directly compared to the extracted features from the different physiological sub-bands.

WPE values were estimated for the new datasets contaminated with simulated artifacts using both segmentation techniques as in the first experiment. Results in Table 5 show the degradation of accuracy among all classifier due to the added noise effect.

However, the accuracy obtained is still acceptable as it reaches a maximum overall classification accuracy of 90.6% with average sensitivity of 89.5 and average specificity of 91.7 in case of the non-linear SVM classifier with overlapping window segmentation.

As for linear SVM classification a maximum accuracy of 88.5 with average sensitivity of 84.25 and average specificity of 92.75 for overlapping window segmentation was obtained. This can be also observed in Fig. 11.
                           
                           
                           
                           
                        

The systems output must be computationally efficient, allowing on-line prospective, rapid identification of seizure activity, using short time windows and simple feature extraction techniques. With an eye toward real-life monitoring, the time needed for classifying 23.6 s of single-channel EEG for each classifier was measured. We ran 100 trials and calculated the mean time for each classifier over each of segmentation technique. All experiments included in this paper were conducted on a HP Intel(R) core i5-2430M CPUs (2.4) with 8 GB of RAM. The total time needed for a single channel classification can be expressed as:

                              
                                 
                                    
                                       
                                          T
                                          total
                                       
                                       =
                                       
                                          T
                                          seg
                                       
                                       +
                                       
                                          T
                                          WPE
                                       
                                       +
                                       
                                          T
                                          cl
                                       
                                    
                                 
                              
                           where
T
                           seg the time is needed for segmenting each channel into 64 non-overlapping window or 128 overlapping window, T
                           WPE is the time for estimating all the Weighted Permutation Entropy values for the segmented windows of a single channel and T
                           cl is the time for linear or non-linear SVM classification. Table 6 shows the mean time of 100 trials for each stage of the suggested model.

Over the 100 trials for each classification problem, the fastest time along all single trials was completed in 0.1345 s achieved by linear SVM classification with non-overlapping window segmentation. The slowest time for the whole process was 0.346 s for linear classification with overlapping window segmentation. The segmentation of the EEG signal into windows and estimating the WPE value for each window is a constant overhead for the classification time that varies from 0.0745 s for 64 non-overlapping windows per channel and 0.16 for 128 overlapping window per channel.

Even though the number of windows doubles from a segmentation technique to the other but the time taken to preprocess the EEG raw data using the overlapping window segmentation technique exceeds the double time taken for the normal non-overlapping window segmentation scheme by almost 17 
μs. On the other hand, the classification accuracy difference between the non-overlapping segmentation and the overlapping segmentation technique is very small.

@&#DISCUSSION@&#

An automated seizure detection model is introduced based on Weighted Permutation Entropy (WPE) and Support Vector Machine classifier (SVM). The experiments results show that the WPE values decrease during seizures which confirms the findings of previous studies that indicate that the brain activity during ictal state has a repetitive regular sequence and thus less chaos which yields to lower entropy values.

Comparing all obtained results, the best discrimination is obtained for seizure activity (dataset S) versus activity obtained from healthy subjects with eyes open (dataset Z) with accuracy 99.5% followed by datasets F (96.5%), N (93.5%) and finally O (85%) as seen in Table 3. This is expected considering the spread of WPE values estimated for each dataset (Fig. 8a and b).

Even though, intracranial recordings have a greater ability to detect the electrical activity of the brain compared to set scalp EEG but the huge variance in the behavior of the neurons electrical activity between set Z (healthy awake subjects with eyes open) versus the seizure set S in term of chaos led to the accuracy achieved. The fact that set O (healthy awake subjects with eyes closed) is also recorded from the surface contributed to the low accuracy achieved compared to other datasets. But the main reason is the large overlap of the estimated WPE values for both data sets O and S. This is explained by the frequency band alpha (8–15 Hz) that dominates the EEG recorded during closing one's eye. Such frequency band is characterized by its regularity and slow rhythm which leads to lower WPE values compared to the other datasets. The order of the results obtained in this paper is also supported by previous work on the same data [19,21–23]. Table 7
                     
                      presents a comparison between the proposed method and other methods found in literature. Only methods evaluated on the same dataset are included so that a comparison between the results is feasible.

The average accuracy was calculated for the four classification problems performed; classifying seizure EEG versus healthy with eyes open, healthy with eyes closed, epileptic patients during no-seizure state from two different location of the brain. A total accuracy of 93.75% is achieved by the proposed model. It has almost 8% of improvement compared to both [21] and [24], respectively. For classification against the EEG of healthy subjects only, a total accuracy of 99.5% was achieved. In the problem of classification against EEG of epileptic patients while in seizure state, a total accuracy of 96.5% was achieved. In order to gain a complete evaluation, the model was compared with studies performing same classification problem; an improvement of 2% is observed in comparison with [19].

For the sets contaminated with noise, the maximum accuracy achieved are 95%, 93%, 92.5% and 83.5% for datasets N, Z, F and O, respectively. Except for the classification of set Z versus set S, the degradation in the performance of classifiers in the artifact-free datasets and the noise-contaminated datasets does not exceed the 2.5% in the classification of other datasets versus set S. Such a small degradation is a consequence of the ability of the WPE estimation algorithm to give the window sequences with fluctuation caused by noise small weight compared to others, and thus the affected sub-segments of the EEG channel have no great influence on the final WPE value of the window.

The proposed automated seizure detection model suggested scheme better tracks changes in the EEG signal through estimating the WPE value for each segment. Results show that the proposed model performed better than some existing schemes in literature according to the classification problem. The WPE algorithm was applied to raw and decomposed EEG signals. Another scenario was applied to simulate the real-time monitoring process, where the recording of EEG is accompanied by background noise resulting from physiological and environmental artifacts. A sample noise from both types was added and projected into the datasets and the model was re-applied again on the contaminated datasets. Degradation in the performance accuracy is observed. However, the algorithm proved its ability to discriminate seizure and no-seizure EEG records. The technique differentiates noisy segments and clean segments by giving the affected segment a small contribution to the final WPE value.

The classification of the datasets has achieved good level of sensitivity, specificity and accuracy using linear and non -linear classifiers. The proposed model was able to discriminate noisy and clean sub-segments of the EEG. Such factors decrease the complexity and in result the computational power needed to solve the classification problem. These factors along with the results obtained support our model hypothesis of being suitable for EEG analysis.

There are various areas to work with for the improvement of the proposed seizure detection system. Analysis of multi-channel EEG segments instead of single channel can provide more information about the electrical activity of the brain and thus the number of derived features per segment will increase which can better describe the EEG. Further assessment of the model on EEG with real artifacts is also necessary to validate its robustness against noise and to test the ability of the WPE to differentiate noise-free and artifacts segments. The obtained classification performance allows WPE features to be part of an automated seizure detection system. The findings are also encouraging to further investigate and assess whether WPE could be utilized as a feature in an automated seizure prediction system.

@&#REFERENCES@&#


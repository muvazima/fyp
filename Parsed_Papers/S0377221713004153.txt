@&#MAIN-TITLE@&#Iterative approaches for a dynamic memory allocation problem in embedded systems

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Two Mid-term iterative approaches for addressing a dynamic memory allocation problem are proposed.


                        
                        
                           
                           They are compared with Short-term and Long-term iterative approaches form the literature, as well as with an ILP formulation.


                        
                        
                           
                           Statistic analysis is used for showing the superiority of the Mid-term approach.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Memory allocation

Embedded systems

Metaheuristics

VNS

@&#ABSTRACT@&#


               
               
                  Memory allocation has a significant impact on energy consumption in embedded systems. In this paper, we are interested in dynamic memory allocation for embedded systems with a special emphasis on time performance. We propose two mid-term iterative approaches which are compared with existing long-term and short-term approaches, and with an ILP formulation as well. These approaches rely on solving a static version of the allocation problem and they take advantage of previous works for addressing the static problem. A statistic analysis is carried out for showing that the mid-term approach is the best one in terms of solution quality.
               
            

@&#INTRODUCTION@&#

Technology offers more and more features allowing embedded systems (such as smart phones) to surf the Web or to process HD pictures. As a consequence, the design of embedded systems becomes more and more complex. There exist some CAD tools such as Gaut [6] to generate the architecture of a circuit from its specifications. However, the designs produced by a CAD software are generally not energy aware, which is of course a major drawback. An interesting work on buffer minimization for designing embedded system has been conducted in [14], where the objective is minimizing the total surface of the buffers used for communicating data between two tasks of the application.

Designers want to minimize power consumption [1], and to some extent, electronics practitioners consider that minimizing power consumption is equivalent to minimizing the running time of the application to be executed by the embedded system [4]. Moreover, the power consumption of a given application can be estimated using an empirical model as in [9], and parallelization of data access is viewed as the main action point for minimizing execution time, and consequently power consumption.

Memory allocation and data allocation are among the main challenges in the design of embedded systems. This paper is focused on memory allocation in embedded systems because this point has a significant impact on power consumption as shown by Wuytack et al. in [25]. One has to know that the process of memory allocation is done off-line, during the design of the embedded system. Once set, the final embedded system is implemented in a specific architecture and will not be modified on-line. Thus, it is possible to spend some time to optimize memory allocation without consequences on the running time of the final application.

In 2012, Google has suggested a machine reassignment problem as the topic for the ROADeF/EURO Challenge [16]. This problem is a general memory allocation problem and may be considered close to the problem addressed in our study. The machine reassignment problem consists in assigning each process to exactly one machine considering the resource capacity constraints and hard constraints that make some allocations impossible. The objective is to improve the usage of a set of machines by minimizing the total cost, which is the sum of a load cost, a balance cost and several move costs. Thus, the set of machines with a limited resources capacity can be seem as the set of memory banks, and processes are the data structures to be allocated. The conflicts between the processes of a services are represented by conflicts between data structures. However, there are three major differences between the problem addressed in this paper and the machine reassignment problem proposed by ROADEF/EURO in 2012. The first one is that in the machine reassignment problem, the processes of a service have to be executed on distinct machines whereas no such limitations exist in our problem. The second one is the cost computation, especially the balance cost, that is very specific to machine reassignment problem, and that differs significantly from the cost computation for the problem addressed in this paper. Finally, the more significant difference is that the problem addressed in this paper is dynamic. As the application requirements vary over time, a solution is a series of allocations, where each allocation is computed by taking present and future requirements into account.

A relevant problem of data allocation is addressed in [2,12], it consists in finding the optimal allocation of relations to multidisk database such that the expected query cost is minimized. Each query involves two relations and has a probability of occurrence. The register allocation problem [10] is close to the simple version of the memory allocation problem tackled in [21]. This problem consists in assigning variables in a computer program to hardware registers in a processor. The objective is to minimize the number of used registers considering that some variables cannot be assigned to the same register. In these problems, the relations and variables can be modeled as the data structures. Disks and registers can be represented as the memory banks. However, the main differences between these problems and our problem are the external memory available and the objective functions. Also, these problems relate to static memory allocation, whereas this paper addresses the dynamic memory allocation.

This work is an extension of the general work conducted by Marı́a Soto during her PhD thesis [17]. Related problems are covered in [19–21,23].

We have addressed various simpler versions of the memory allocation problem: in Soto et al. [22], we have proposed a mixed integer linear programming formulation for the general memory allocation problem and a variable neighborhood search (VNS) algorithm [13]. We have also studied an even more simplified version of this problem in Soto et al. [21].

We have dealt with the dynamic memory allocation problem in Soto et al. [23] for which an integer linear programming formulation and two iterative approaches have been devised to address this dynamic problem. In this paper, we propose a new iterative approach which combines these two iterative approaches. Similar studies with iterative approaches but in a completely different domain have also been conducted on another problem in [24].

This paper is organized as follows. Section 2 provides a short introduction to dynamic memory allocation problem. Section 3 briefly recalls the two previous iterative approaches and introduces the new method. The proposed approach is compared to previous works in Section 4, and computational results are also discussed. Finally, Section 5 presents conclusions and future work on this problem.

This section presents the dynamic memory allocation problem. Readers interested in more details about this problem, about the ILP formulation and about the 
                        
                           NP
                        
                     -hard status of this problem are referred to Soto et al. [23]. The considered memory architecture is similar to the one of a TI C6201 device [9]. It is composed of m memory banks whose capacity is c
                     
                        j
                      kilo Bytes (kB) for all j
                     ∈{1,…,
                     m} and an external memory denoted by m
                     +1, which does not have a practical capacity limit. The processor needs q milliseconds for accessing data structures located in a memory bank, and it spends an access time which is p times longer when data structures are in the external memory.

Time is split into T time intervals whose durations may be different. The application to be implemented is assumed to be given as C source code, whose n data structures (i.e. variables, arrays, structures) have to be loaded in memory banks or external memory. The size of data structure s
                     
                        i
                      for i
                     ∈{1,…,
                     n} is expressed in kB. During each time interval I
                     
                        t
                     , the application requires accessing a given subset A
                     
                        t
                      of its data structures. Thus e
                     
                        i,t
                      denotes the number of times that data structure s
                     
                        i
                     
                     ∈
                     A
                     
                        t
                      is accessed during time interval I
                     
                        t
                     , for all t
                     ∈{1,…,
                     T}. The processor can access all its memory bank simultaneously, which allows for parallel data loading. Thus, two data structures can be loaded in parallel provided that they are allocated to two different memory banks. Two data structures are said to be conflicting whenever they are required at the same time by the processor. Each conflict has a cost, which is equal to the number of times the conflict appears in the current time interval. This cost might be non-integer if the application source code has been analyzed by a statistic-based code-profiling software [8,11]. Thus, the number of conflicts in I
                     
                        t
                      is denoted by o
                     
                        t
                     , and d
                     
                        k,t
                      is the cost of conflict (k,
                     t)=(k
                     1,
                     k
                     2) during time interval I
                     
                        t
                      for all k in {1,…,
                     o
                     
                        t
                     }, k
                     1 and k
                     2 in A
                     
                        t
                     , and t in {1,…,
                     T}.

A conflict between two data structures is said to be closed if both data structures are allocated to two different memory banks. In any other case, the conflict is said to be open and its cost has to be paid.

Initially, all data structures are in the external memory and memory banks are empty. The time required for moving a data structure from the external memory to a memory bank (and vice versa) is v ms/kB. The time required for moving a data structure from a memory bank to another is ℓ ms/kB. We suppose that v
                     ⩾ℓ and v
                     <
                     p because a DMA (Direct Memory Access) controller is part of the memory architecture, which allows for a direct access to data structures.

The cost of an allocation is expressed in milliseconds and is the sum of two terms. The first term is the access cost for executing operations in the application which also includes the cost of conflicts cost of all the data structures that are in a memory bank, plus the access cost of all the data structures allocated to the external memory minus the closed conflict cost. The second term is the cost of changing the allocation of structures from a time interval to the next one.

The dynamic memory allocation problem consists in allocating a memory bank or the external memory to any data structure of the application for each time interval, so as to minimize the time spent accessing and moving data structures while satisfying the memory bank capacity.

In Soto et al. [23], we have introduced two heuristic iterative approaches which iteratively build a solution. They rely on addressing static memory allocation problems. The first approach called Long-term addresses the MemExplorer problem (ME) [22] which consists in finding a memory allocation for data structures such that the time spent accessing these data is minimized, for a given number of capacitated memory banks and an external memory. The second approach named Short-term addresses the MemExplorer-Prime problem (ME′)[23] which is similar to MemExplorer but that considers an initial memory allocation for data structures. Thus, in addition to minimizing the time spent accessing data, the cost of changing the allocation of these data is also minimized. Table 1
                      points out the differences between these two problems in terms of inputs, outputs, constraints and objective function.

In [23] and [22], these two static problems have been tackled using a Variable Neighborhood Search-based approach hybridized with a Tabu Search. The VNS starts with greedy and random solutions and explores two different neighborhoods. The first neighborhood swaps data structures in memory banks provided that memory banks capacity are not exceeded, whereas the second one performs new allocations which may lead to exceed the memory bank capacity (in that case the allocation is repaired afterward). The Tabu Search procedure uses the same neighborhoods, with a dynamic tabu list whose tenure is smartly adapted during the search.

For each time interval t, Long-term builds a preliminary allocation P
                     
                        t
                      called the seed allocation. The allocation for the time interval t, denoted by X
                     
                        t
                      is built upon that seed allocation. Sections 3.1 and 3.2 present two ways of building a solution based on the seed allocations at each iteration. The present paragraph focuses on the construction of the seed solution P
                     
                        t
                      at time interval t.

The seed allocation is selected among two candidate allocations. The first one is the seed allocation for the previous time interval P
                     
                        t−1. The second candidate is the allocation found by solving MemExplorer on an instance built by gathering all the data structures, number of accesses to data, conflicts and cost involved from the current interval t to the last one. The total cost of both candidate allocations is then computed. This cost is the sum of two sub-costs. The first sub-cost is the cost that we would have if the candidate allocation was applied from the current time interval to the last one. The second sub-cost is the cost that should be paid for changing the memory mapping from the allocation of the previous time interval to the considered candidate allocation. The candidate allocation associated with the minimum total cost is selected as the seed allocation, and referred to as P
                     
                        t
                     .


                     Short-term builds an allocation for a time interval by solving MemExplorer-Prime on an instance built by gathering all the data structures, number of accesses to data, conflicts and costs involved only in the current time interval, and also by considering the allocation in the previous time interval.


                     Long-term takes into account the application’s requirements (data structures, number of accesses to data, conflicts and costs) for the current and future time intervals.

We now explain why Short-term and Long-term produce solutions that tend to have specific features. When the capacity of memory banks is large, Long-term tends to avoid moving data structures from a time interval to the next one. Indeed, for all t, a good seed allocation found at the first time intervals has a high probability to reach a total cost lesser than the other candidate allocation, and to be selected as a seed allocation for the next intervals. This is partly due to the fact that the changing cost of such an allocation is zero, as memory bank capacity allows for keeping the same allocation for all time intervals.

By contrast, Short-term minimizes the cost incurred by accessing data structures and the cost for changing the current allocation of data structures from a time interval to the next one. In general, the cost for moving data structures involved in a conflict is much less than the cost to be paid if the conflict is open. Thus, Short-term is prone to change the allocation of data structures from a time interval to the next one, but often at the expense of global solution quality.

Since Long-term has the advantage of stability over time, and Short-term has the advantage of flexibility, we are interested in a mid-term approach that combines the benefits of both approaches. We propose two mid-term approaches, the first one uses a rolling horizon and the other one weights the time interval requirements. These approaches are described below.


                        Long-term solves MemExplorer for all time intervals and Short-term addresses MemExplorer-Prime only once. Therefore, the mid-term approach should solve MemExplorer and MemExplorer-Prime for an intermediate number of times intervals. Based on this idea, the first version of mid-term approach uses a rolling horizon of length h. Algorithm 1 presents Mid-term with a rolling horizon which proceeds as follows. An allocation of data structures to memory banks has to be set for each time interval sequentially from the first time interval to the last one. As in Long term, the allocation at time interval t is based on a seed allocation (P
                        
                           t
                        ) which is the best one out of three allocations: the seed allocation of the previous time interval (P
                        
                           t−1), the allocation of MemExplorer for the following h time intervals (M
                        
                           t
                        ), and the allocation of MemExplorer-Prime for the same h time intervals with the allocation of the previous interval as initial allocation 
                           
                              (
                              
                                 
                                    M
                                 
                                 
                                    t
                                 
                                 
                                    ′
                                 
                              
                              )
                           
                        .


                        
                           
                              
                           
                        
                     

A complete solution is represented by a matrix X, which is composed of T
                        +1 vectors X
                        
                           t
                         for all t
                        ∈{0,…,
                        T}. Vector X
                        
                           t
                         is the memory allocation at time interval t. Thus element x
                        
                           ti
                         of vector X
                        
                           t
                         represents the allocation of data structure i at time interval t. Element p
                        
                           ti
                         of vector P
                        
                           t
                         represents the seed allocation of data structure i at time interval t. Initially, all data structures are allocated to the external memory, hence x
                        0i
                        
                        =
                        m
                        +1 for all i
                        ∈{1,…,
                        n} (Algorithm 1 – line 3). As mentioned before, the seed allocation in the time interval t is denoted by P
                        
                           t
                        . The initial seed allocation P
                        0 is the initial memory allocation X
                        0 (line 4).

For each time interval t, this algorithm first generates three candidate allocations. The first one is the seed allocation P
                        
                           t−1 used to build the memory allocation of the previous time interval X
                        
                           t−1 (line 7). The second one, M
                        
                           t
                         is the allocation obtained by solving MemExplorer for data structures, number of accesses to data, conflicts and access costs involved from the time interval t to time interval t
                        +
                        h
                        −1 (line 8). The last candidate allocation, 
                           
                              
                                 
                                    M
                                 
                                 
                                    t
                                 
                                 
                                    ′
                                 
                              
                           
                         is generated by MemExplorer-Prime for h time intervals using the memory mapping of the previous time interval X
                        
                           t−1, as the initial allocation. Allocation M′
                           t
                         takes into account the transitional cost for changing the allocation of data structures from the allocation of the previous time interval and the access cost (line 9).

For each of the three candidate allocations, the algorithm computes the total cost which is the sum of two sub-costs. The first one is the access cost that we would have if the candidate allocation was applied from the current time interval t to the last one. The second sub-cost is the transitional cost for moving data structures from time interval t
                        −1 to t that should be paid if the candidate allocation would be applied (line 11).

The selected allocation is the one whose total cost is minimum (line 12). The allocation X
                        
                           t
                         for time interval t is initialized to the seed allocation P
                        
                           t
                         (line 13); then, the data structures that are not required until the current time interval are allocated to the external memory.


                        Long-term is not bound to change data structures allocation, because future and present requirements are considered equally important. In particular, a very high cost conflict occurring in a quite distant future will have a significant impact on all the allocations to be computed before its actual occurrence. On the contrary, Short-term is prone to move data structures in order to find an allocation that only minimizes the cost of moving data structures and access cost incurred by the current time interval. This is of course done at the expense of anticipation of future requirements that are totally ignored, and it can be observed that this approach produces too many moves.

To overcome these drawbacks, we propose another mid-term approach which attempts to balance the number of moves between two successive time intervals. We have then weighted the requirements of each time interval. Future requirements are less and less weighted as they are far away from the current time interval. This mid-term approach considers future requirements but giving more importance to the one appearing in the nearest future. Thus, we avoid the drawbacks of Long-term while taking advantage of the flexible nature of Short-term. Algorithm 2 shows Mid-term with weighted future requirements.


                        
                           
                              
                           
                        
                     

First, the decay rate α
                        ∈[0,1] has to be set. At time interval t, the cost of all the conflicts that arise from time interval t
                        +1 are multiplied by α, those arising from time interval t
                        +2 are multiplied by α
                        2, those arising from time interval t
                        +
                        k are multiplied by α
                        
                           k
                        , until the end of the horizon. Long-term corresponds to α
                        =1, whereas Short-term can be computed with α
                        =0.

Numerical experiments suggest that the best trade off between these two extreme strategies can be found based on the ratio between memory bank capacity and the size of data structures, but it also depends on p, ℓ and v. The decay rate is then empirically defined by:
                           
                              (1)
                              
                                 α
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                   
                                                   if
                                                   
                                                      
                                                         
                                                            
                                                               ∑
                                                            
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            
                                                               m
                                                            
                                                         
                                                         
                                                            
                                                               c
                                                            
                                                            
                                                               j
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               ∑
                                                            
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            
                                                               n
                                                            
                                                         
                                                         
                                                            
                                                               s
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                   ⩾
                                                   1
                                                
                                             
                                             
                                                
                                                   
                                                      min
                                                   
                                                   
                                                      
                                                         
                                                            1
                                                            ,
                                                            
                                                               
                                                                  v
                                                               
                                                               
                                                                  p
                                                                  ·
                                                                  ℓ
                                                               
                                                            
                                                            ·
                                                            
                                                               
                                                                  
                                                                     
                                                                        ∑
                                                                     
                                                                     
                                                                        j
                                                                        =
                                                                        1
                                                                     
                                                                     
                                                                        m
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        c
                                                                     
                                                                     
                                                                        j
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        ∑
                                                                     
                                                                     
                                                                        i
                                                                        =
                                                                        1
                                                                     
                                                                     
                                                                        n
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        s
                                                                     
                                                                     
                                                                        i
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Whenever the memory bank capacity is large enough to accommodate all data structures, Long-term tends to be very efficient as very few modifications from a time interval to the next one may be needed. Then, if the ratio 
                           
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          m
                                       
                                    
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          n
                                       
                                    
                                    
                                       
                                          s
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         increases, then a large α is suitable. In addition, a high cost for moving data structures also leads to favor steady assignments for data structures. Consequently, a large 
                           
                              
                                 
                                    v
                                 
                                 
                                    ℓ
                                 
                              
                           
                         leads to high values for α. However, a large penalty cost p makes it more and more costly to access data structures that are in the external memory. Then, if memory bank capacity is modest, it might be profitable to move the data structures that are required at each time interval in the memory banks, hence favoring flexibility. So, if p is large, then a smaller decay rate α should be desirable to reach high-quality solutions.

Initialization is the same as in the Mid-term approach with a rolling horizon (Algorithm 2 – line 3–4), and a time interval allocation is generated as in Algorithm 1.

At each time interval t, Algorithm 2 generates three candidate allocations (line 7–9). The first one is the seed allocation P
                        
                           t−1 used to build the memory allocation of the previous time interval X
                        
                           t−1 (line 7). The second one, M
                        
                           t
                         is the allocation obtained by solving MemExplorer by weighting the requirements for the current time interval t to the last one as explained above (line 8). The cost of conflicts occurring at time interval t are multiplied by α
                        
                           r−t
                         for all r
                        ∈{t,…,
                        T}. Hence, the future requirements are less and less weighted as they are far away from the current time interval. The last candidate allocation, M′
                           t
                         is the allocation found by MemExplorer-Prime weighting the requirements and using the memory mapping of the previous time interval X
                        
                           t−1 as the initial allocation (line 9). The rest of the algorithm is similar to Algorithm 1.

@&#IMPLEMENTATION@&#

From our experience, it appears that the solution quality of Long-term and Short-term is very sensitive to the ratio of the memory bank capacity over the total size of data structures. We have used two groups of instances for testing our algorithms. Group A is composed of real and artificial instances for which memory bank capacity is too small for accommodating all the data structures (hence the external memory is necessary). The instances in Group B are the same, but the memory bank capacity is large enough for accommodating all the data structures.

Real instances originate from electronic design problems addressed in the Lab-STICC laboratory. Artificial instances are composed of the last eleven instances of Table 2
                        , and originate from DIMACS [15]. They have been enriched by randomly generating conflict costs, number and capacity of memory banks, sizes and number of accesses to data structures. For each instance, we have divided the conflicts and data structures into different time intervals. All instances are available online for download [18].

We have tested our approaches with artificially large instances to assess their practical use for forthcoming needs, as technology tends to integrate more and more functionalities in embedded systems.

All algorithms have been implemented in C++ and compiled with gcc 4.11 in Linux OS 10.04 using an Intel Pentium IV processor system at 3GHz with 1GB RAM. The time q spent by the processor to access data structures to memory banks is set to 1ms. We have set factor p to access data structures to external memory to 16, as with TI C6201. The cost v for moving a data structure from the external memory to memory banks and vice versa is set to 4ms/kB and cost for moving data structures between memory banks is equal to 1ms/kB.

From our experiments for the mid-term approach with rolling horizon, we empirically set h to 2 for the instances with less than 8 conflicts (o
                        <8), and for the remaining instances h is set to 3. The decay rate α is calculated using Eq. (1).

@&#RESULTS@&#

In Tables 2 and 3
                        , we report the results of the ILP formulation [23]. The instances are sorted by non decreasing number of conflicts.

The first three columns show the main characteristics of instances such as instance’s name, number of data structures n, conflicts o, memory bank m and time intervals T. The next columns present the cost reached by the ILP formulation solved with Xpress-MP. The stopping criterion is set to 1hour after the last integer value is reached. The best solution found so far (if any) is then returned by the solver. For the ILP we display the lower bound and the best solution. The solver cannot find any result for some large instances due to memory issues.


                        Tables 4 and 5
                        
                         present the main results concerning the iterative approaches. For each instance, we have run each iterative approach twelve times. Instance names beginning with * are instances whose optimal solution is known (as computed in Table 2 and 3). Table 4 displays the objective function value of the best solution found and its CPU time. Additionally, we have computed the standard deviation (σ) and the coefficient of variance (CV) for each approach. The coefficient of variance is the ratio of the standard deviation to the mean cost. CV allows us to compare the variance of approaches using instances which have widely different means. The coefficient of variance shows that iterative approaches do not have high variability building solutions. Since all iterative approaches have very similar values for CV (around 0.01), they are not reported in the tables.

At the bottom of these tables, we report the number of optimal solutions and the number of best solutions returned by each approach. We also report the average CPU time and the gap to optimality. A star has been added to the instance’s name to locate the one for which the optimal value is known. Mid-term approach with weighted future needs always finds the optimal solution when it is known. For the other cases, it reaches the best cost except for the instance mulsol_i4dyA in group A and mpeg2enc2dy2B in group B. Mid-term approach with rolling horizon returns the best solution for the instance mulsol_i4dyA. For the instance mpeg2enc2dy2A 
                        Long-term reaches the best objective function value. The reason why mid-term does not return the best solution for mpeg2enc2dy2A is that the decay rate α is not one (see the long-term approach).

In group A, the number of best solutions reported by the mid-term approach with weighted needs is 35, compared to 12 with the mid-term approach with rolling horizon, 15 with Short-term, 11 with Long-term and 24 with the ILP model. In group B, the mid-term approach with weighted needs reaches the best solution for 36 instances, while Long-term does it for 25 instances, the mid-term approach with rolling horizon does it for 22 instances and Short-term reaches the best solution for only 14 instances.

In group B, the mid-term approach with weighted needs works with α equals to one, i.e, the future requirements are as important as the present ones, as in Long-term. However, this mid-term approach reports better results than Long-term, because it considers three candidate allocations at each time interval.

In general, Long-term reaches the best results when the capacity of memory banks is sufficiently large, because it requires less allocation changes from a time interval to the next one. When the cost of moving data structures is small enough, then Short-term reaches the best results.

The minimum average gap is reached by the mid-term approach with weighted needs, which shows the competitiveness of this approach over the other ones. The highest CPU time is obtained by the ILP formulation and the lowest one is reached by the Short-term approach, which is not a surprising result.

In order to assess the benefit of comparing three candidate allocations in the mid-term approach with weighted future needs, we have tested this approach using only two candidate allocations. The impact of using three candidate allocations is significant for large instances only. For this reason, Table 6
                         displays the objective value returned by using the approach without the previous seed allocation P
                        
                           t−1, without MemExplorer M
                        
                           t
                         and without MemExplorer-Prime for the largest instances of Group A.

The gap in Table 6 measures the impact of not using one of the candidate allocation in the mid-term approach. If the approach does not consider the MemExplorer allocation as a candidate allocation, then the quality of mid-term solution decreases on average by 28%. If MemExplorer-Prime is not used, the solution quality drops by an average of 10%. Finally, if the previous seed allocation is turned off, the quality solution decreases by an average of 2%.


                        Cost analysis In order to achieve a fair comparison, we use the non parametric Friedman test [7]. We use this test to detect differences in the performance of iterative approaches and ILP formulation using the results presented by the above tables. We can use this test because the result over instances are mutually independent. Thus we apply the Friedman test for costs comparing (univariate model [3]) the performance in terms of solution quality.

The null hypothesis assumes that for each instance, the ranking of the approaches is equally likely. The null hypothesis is rejected at the level of significance 0.95 if the p-value is less than 0.05. Friedman test is 6.9488 for the cost and its p-value is 1.364×10−11. We can reject the null hypothesis for the cost at the level of significance 0.95. Then, there exists at least one approach whose performance is different from at least one of the other ones.

As the null hypothesis of Friedman test was rejected, we can use a Post-Hoc paired comparison to know if two metaheuristics are different [5]. Table 7
                         summarizes p-values for the paired comparisons for the cost. The bold values means the approaches are different in terms of cost.

For these two groups of instances, we conclude that mid-term approach with weighted future needs has the best performance in terms of cost. There does not exist a significant difference between the performance of the ILP formulation, Long-term, Short-term and mid-term with rolling horizon approaches.


                        Impact of the seed solution. We also apply Friedman test to complete the assessment of the mid-term approach with weighted future requirements using the data in Table 6. The value for this test is 5.3358 whose p-value is 6.546×10−7. Then we can conclude that there exists at least one candidate solution whose impact in the mid-term approach is different from at least one of the other ones. Table 8
                         presents the Post-Hoc comparison for evaluating the mid-term approach with weighted approach.

From Tables 6 and 8, we can deduce that the candidate solutions produced by MemExplorer and MemExplorer-Prime have the same impact on the mid-term approach with weighted needs. The statistic analysis confirms that the previous seed solution has quite a small impact on solution quality. Indeed, Table 6 shows that the improvement due to this candidate is on average 2%, which is worth keeping.

@&#CONCLUSION@&#

We have presented two mid-term approaches for iteratively building a solution for the dynamic memory allocation problem that arises in the design of embedded systems. These approaches are based on two static subproblems for addressing memory allocation that have been devised earlier for addressing simplified problem versions. The first approach builds a solution for a time interval by taking into account the requirements involved during the rolling horizon. The other mid-term approach integrates the future needs through a decay rate. The statistic tests show that the mid-term approach with a rolling horizon has not a significant performance in terms of cost and running time. Mid-term approach with weighted future requirements reached the best performance in terms of cost but not in terms of CPU time. Indeed, the main drawback of these approaches is that they do not consider the complete problem in all time intervals. Consequently, future work should concentrate on designing a global approach that builds a solution for all time intervals such as a Greedy Randomized Adaptive Search Procedure or a Variable Neighborhood Search.

@&#REFERENCES@&#


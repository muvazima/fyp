@&#MAIN-TITLE@&#Belief rule-based inference for predicting trauma outcome

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A RIMER methodology-based trauma outcome prediction model is developed.


                        
                        
                           
                           The RIMER-based prediction model is fine-tuned and validated using historical data.


                        
                        
                           
                           LR, SVM, and ANN models are developed and compared with the RIMER model.


                        
                        
                           
                           The RIMER model has the best prediction performance among the four models.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Belief rule base

Evidential reasoning approach

Logistic regression

Support vector machine

Artificial neural network

Outcome prediction

@&#ABSTRACT@&#


               
               
                  A belief rule-based inference methodology using the evidential reasoning approach (RIMER) is employed in this study to construct a decision support tool that helps physicians predict in-hospital death and intensive care unit admission among trauma patients in emergency departments (EDs). This study contributes to the research community by developing and validating a RIMER-based decision tool for predicting trauma outcome. To compare the prediction performance of the RIMER model with those of models derived using commonly adopted methods, such as logistic regression analysis, support vector machine (SVM), and artificial neural network (ANN), several logistic regression models, SVM models, and ANN models are constructed using the same dataset. Five-fold cross-validation is employed to train and validate the prediction models constructed using four different methods. Results indicate that the RIMER model has the best prediction performance among the four models, and its performance can be improved after knowledge base training with historical data. The RIMER tool exhibits strong potential to help ED physicians to better triage trauma, optimally utilize hospital resources, and achieve better patient outcomes.
               
            

@&#INTRODUCTION@&#

Trauma has become one of the leading causes of mortality and disability worldwide. Trauma accounts for 16% of the global burden of disease, and 16,000 people die from injury daily. Death and disability from trauma frequently occur in low- and middle-income countries where approximately 90% of the total burden of trauma is reported [1,2]. In developed countries, pre-hospital triage can help stratify trauma patients into different severity levels, and different levels of trauma centers have been established to treat trauma patients with varying degrees of severity [3–5]. Unfortunately, no nationwide initial trauma assessment guidelines or tools exist to aid physicians in pre-hospital environments or emergency departments (EDs) in many less developed countries [6]. In China, a pre-hospital “120” (the ambulance call number used in China) emergency system adopts the principle of proximity to transport a trauma patient to the nearest hospital. Consequently, some severe trauma patients have been sent to low-level hospitals, which cannot treat severe trauma patients, so these patients have to be retransferred to higher-level hospitals. Trauma patient outcomes in China are relatively poor compared with those in developed countries. More than 400,000 people die from injury in China each year, and trauma is the fifth leading cause of death after malignant tumors and cardiac, cerebral, and respiratory diseases. Trauma is considered the most common cause of death of young people aged 18–40 years in China [7]. Research shows that a large proportion of in-hospital mortality can be predicted and prevented if clinical deterioration is recognized early [8,9]. Therefore, for improved patient outcomes and optimal utilization of hospital resources, physicians in EDs need to provide a rapid initial assessment of illness severity for trauma patients immediately after their arrival at the hospital, so as to make appropriate decisions regarding the treatment of patients with a high probability of in-hospital death or intensive care unit (ICU) admission [10].

Vital signs including pulse rate, systolic blood pressure, respiratory rate, body temperature, and level of consciousness are used to assign an early warning score [11–14] to assess illness severity. In trauma care, other physiological scoring tools such as the Pre-Hospital Index [15], the Trauma Index [16,17], the Glasgow Coma Score [18,19], and the Revised Trauma Score [20] have been developed to assess trauma severity before detailed diagnoses can be made for trauma patients. The nature of existing physiological trauma severity assessment tools is to assign a severity score to a patient based on physician observations and the instrumentally measured vital signs of the patient. However, the existing trauma scoring tools to aid physicians in EDs are most often used to stratify patients into different severity levels and rarely to predict the probability of in-hospital death and ICU admission. To explore the relationship between clinical variables available for data collection in EDs and trauma outcome, such as in-hospital death and ICU admission, logistic regression (LR) [21,22], support vector machines (SVMs) [23,24], and artificial neural networks (ANNs) [25–28] are usually employed to construct prediction models. None of the LR, SVM, or ANN models require concrete knowledge about the relationship between antecedent factors and dependent outcomes, and these methods are completely data-driven, which means sufficiently large sample data are needed to learn prediction models. The performance and efficacy of data-driven prediction models are determined not only by the learning dataset, but also by the unknown dataset to which the prediction model is applied.

In the present study, vital signs are used as antecedent factors to predict in-hospital death and ICU admission. We propose the use of a generic belief rule-based inference methodology using the evidential reasoning approach (RIMER) [29] to develop a clinical decision model. This model is aimed at helping ED physicians predict the probability of in-hospital death and ICU admission for trauma patients [30]. In RIMER, an initial belief rule base (BRB) consisting of belief rules for predicting in-hospital death and ICU admission must first be constructed based on domain expert knowledge and clinical experiences. Inference with the BRB is implemented using the evidential reasoning (ER) approach [31,32], which was originally proposed for combining multiple independent assessments of one alternative on individual criteria or attributes. The ER approach can handle both quantitative and qualitative attributes or criteria under uncertainties [33,34]. In an RIMER-based prediction model, the inputs include the clinical values of vital signs, which are used to infer with or match the belief rules in the BRB. In ER-based inference, the packet antecedent of each belief rule triggered by the inputs is considered a basic attribute with an attribute weight, which is assessed using all possible consequents with belief degrees as presented in the BRB. Thus, assessments on the packet antecedents of multiple triggered belief rules can be combined by the ER approach to achieve aggregated belief degrees in all possible consequents of the BRB. The output of the model is a combined belief degree or probability linked to the trauma outcome, including in-hospital death and ICU admission for each patient. The BRB in the model can be fine-tuned by accumulated historical data. The model is transparent in that all belief rules can be checked by experienced physicians for validity and the inference process is also transparent and can be traced for better informed decision making.

In addition, LR-based, SVM-based, and ANN-based prediction models are constructed for comparison using the same dataset, whereas the antecedent variables and dependent outcome of each of these completely data-driven prediction models are the same as those of the RIMER model. To validate the prediction performance of all RIMER-based, LR-based, SVM-based, and ANN-based models, a five-fold cross-validation method is applied.

The remainder of this paper is structured as follows. The Materials and methodology section provides a brief introduction to the following: the data source, RIMER methodology, LR analysis, SVM, ANN, five-fold cross-validation method, and area under the receiver operating characteristic (ROC) curve (AUC), which we used to measure prediction performance. The Results section compares the prediction performance of the RIMER-based model before and after BRB training, the LR-based model, an optimal SVM-based model, and an optimal ANN-based model in each training round. Discussion section elaborates on the four different types of prediction models, especially the advantages and limitations of the RIMER model. Conclusions section summarizes this study and presents conclusions drawn from the study.

A sample of trauma patients sent to Kailuan Hospital, North China, between 2008 and 2009 was employed for prediction model development and validation. Patients were included for analysis if they met the following criteria: (a) directly sent to the ED from an accident site; (b) with the five vital signs recorded upon their arrival at the ED; and (c) possible to retrieve corresponding in-hospital data. No further restrictions were made on the severity or characteristics of the cases. A total of 1299 trauma patients were directly sent to the ED at Kailuan Hospital within the sampling period, among which 1190 (91.61%) had both ED vital signs data and in-hospital data. The remaining 109 patients had either missing data on vital signs or missing in-hospital data, so they were excluded from data analysis.

The primary outcome of this study is a composite one, including in-hospital death and ICU admission.

In the RIMER methodology, traditional IF-THEN rules are extended to belief rules by embedding belief degrees in all possible consequents of a rule. Meanwhile, other knowledge representation parameters, including rule weights, antecedent attribute weights, and consequent belief degrees, are embedded in the belief rules. Inference with a BRB in a RIMER system is implemented using ER. The RIMER system presents the advantages of using belief rules to represent clinical domain knowledge under uncertainty and inference with uncertain clinical data using the ER approach. The knowledge representation parameters, including rule weights, antecedent attribute weights, and consequent belief degrees in the BRB, can be fine-tuned or trained using accumulated historical data [35]. The RIMER methodology has been employed to stratify patients with cardiac chest pain [36,37], diagnose lymph node metastasis in gastric cancer [38,39], and many other areas [40–42]. A brief introduction to BRB, inference with BRB, and the training of BRB follows.

A belief rule can be described as Rk
                           :

                              
                                 (1)
                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                If
                                                
                                                
                                                   A
                                                   1
                                                   k
                                                
                                                ∧
                                                
                                                   A
                                                   2
                                                   k
                                                
                                                ∧
                                                ⋯
                                                ∧
                                                
                                                   A
                                                   
                                                      
                                                         T
                                                         k
                                                      
                                                   
                                                   k
                                                
                                                ,
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                then
                                                
                                                
                                                
                                                   {
                                                   
                                                      
                                                         (
                                                         
                                                            
                                                               D
                                                               1
                                                            
                                                            ,
                                                            
                                                               β
                                                               
                                                                  1
                                                                  k
                                                               
                                                            
                                                         
                                                         )
                                                      
                                                      ,
                                                      
                                                         (
                                                         
                                                            
                                                               D
                                                               2
                                                            
                                                            ,
                                                            
                                                               β
                                                               
                                                                  2
                                                                  k
                                                               
                                                            
                                                         
                                                         )
                                                      
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         (
                                                         
                                                            
                                                               D
                                                               N
                                                            
                                                            ,
                                                            
                                                               β
                                                               
                                                                  N
                                                                  k
                                                               
                                                            
                                                         
                                                         )
                                                      
                                                   
                                                   }
                                                
                                                
                                                
                                                   (
                                                   
                                                      
                                                         β
                                                         
                                                            j
                                                            k
                                                         
                                                      
                                                      
                                                      ≥
                                                      
                                                      0
                                                      ,
                                                      
                                                         ∑
                                                         
                                                            j
                                                            =
                                                            1
                                                         
                                                         N
                                                      
                                                      
                                                         β
                                                         
                                                            j
                                                            k
                                                         
                                                      
                                                      
                                                      ≤
                                                      
                                                      1
                                                      
                                                   
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                with
                                                
                                                a
                                                
                                                rule
                                                
                                                weight
                                                
                                                
                                                   θ
                                                   k
                                                
                                                
                                                and
                                                
                                                attribute
                                                
                                                weights
                                                
                                                
                                                   δ
                                                   1
                                                
                                                ,
                                                
                                                   δ
                                                   2
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   δ
                                                   
                                                      T
                                                      k
                                                   
                                                
                                                ,
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                
                                                k
                                                ∈
                                                
                                                   {
                                                   
                                                      1
                                                      ,
                                                      …
                                                      ,
                                                      L
                                                   
                                                   }
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                 
                                    A
                                    i
                                    k
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                    
                                    )
                                 
                              
                            is the referential category or grade of the ith antecedent attribute used in the kth rule; 
                              
                                 
                                    β
                                    
                                       j
                                       k
                                    
                                 
                                 
                                    (
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                       ;
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                            is the belief degree assigned to consequent Dj
                           , and it can initially be given by experts; 
                              
                                 
                                    δ
                                    i
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                    
                                    )
                                 
                              
                            is the antecedent attribute weight representing the relative importance of the ith attribute; and θk
                            is the rule weight representing the relative importance of the kth rule. L represents the number of all belief rules in the rule base. Tk
                            is the number of all antecedent attributes used in the kth belief rule. N is the number of all possible consequents in the BRB. Traditional IF-THEN rule can be represented as a special case of belief rule with only one consequent, and the consequent belief degree is always 100%.

Initial belief rules in this study were provided by domain experts, and the five vital signs, namely, body temperature, respiratory rate, systolic blood pressure, pulse rate, and level of consciousness, are used as antecedent factors in the rule base. The possible consequents of the rule base include “occurrence of in-hospital death or ICU admission” and “nonoccurrence of in-hospital death or ICU admission.” The referential grades of the five vital signs include “normal (N)” and “abnormal (AN).” One example of a belief rule is “IF body temperature is AN, respiratory rate is AN, systolic blood pressure is AN, pulse rate is AN, and level of consciousness is AN, THEN {(occurrence of in-hospital death or ICU admission, 70%), (nonoccurrence of in-hospital death or ICU admission, 30%)},” where {(occurrence of in-hospital death or ICU admission, 70%), (nonoccurrence of in-hospital death or ICU admission, 30%)} means that if the clinical data of one patient satisfy the compact antecedent of the rule, the patient will have in-hospital death or ICU admission with 70% certainty and 30% certainty of eliminating the two adverse events. In total, 32 belief rules in the BRB are listed in Table 1
                           
                           , where A1 represents body temperature, A2 is the respiration rate, A3 is the pulse rate, A4 is the systolic blood pressure, and A5 represents the level of consciousness.

Inference with the BRB in the RIMER system is implemented using the ER algorithm [31,43].

First, transform numerical values or subjective judgments associated with antecedent clinical variables to belief distributions on corresponding reference categories used in the BRB. This transformation can be implemented by rule- or utility-based equivalence transformation techniques [32]. For example, set the input value for the ith antecedent attribute as Ui
                            along with a belief degree ɛ
                              i
                           . The input value can be transformed as

                              
                                 (2)
                                 
                                    
                                       S
                                       
                                          (
                                          
                                             
                                                U
                                                i
                                             
                                             ,
                                             
                                                
                                                   ɛ
                                                
                                                i
                                             
                                          
                                          )
                                       
                                       =
                                       
                                          {
                                          
                                             
                                                (
                                                
                                                   
                                                      A
                                                      
                                                         i
                                                         j
                                                      
                                                   
                                                   ,
                                                   
                                                      α
                                                      
                                                         i
                                                         j
                                                      
                                                   
                                                
                                                )
                                             
                                             ;
                                             j
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             
                                                J
                                                i
                                             
                                          
                                          }
                                       
                                       ,
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       T
                                    
                                 
                              
                           where Aij
                            is the jth referential category of the ith antecedent attribute, αij
                            is the degree to which the input Ui
                            with belief degree ɛ
                              i
                            belongs to the referential category Aij
                            with αij
                            ≥ 0 and 
                              
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    
                                       J
                                       i
                                    
                                 
                                 
                                    α
                                    
                                       i
                                       j
                                    
                                 
                                 ≤
                                 1
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       T
                                    
                                    )
                                 
                              
                           , and Ji
                            is the number of all referential categories of the ith antecedent attribute.

In this study, the degree of “N” or “AN” associated with each vital sign variable is calculated from the severity score assigned to the corresponding vital sign on the basis of physician observation or instrumental measurement. The criteria for the severity score assignment are based on the early warning score, as introduced by Smith et al. [12]. Details of the scoring criteria are shown in Table 2.
                        

In Step One of this input transformation, a severity score equal to 0, 1, 2, or 3 is assigned to a patient. This score pertains to his or her vital signs on the basis of physician observations or the numerical values (exact numerical values for body temperature, respiration rate, pulse rate, and systolic blood pressure, and physician observations for level of consciousness). The assignment is based on the early warning score criteria, where a score of 0 means normal status and the scores 1, 2, and 3 mean abnormal status. The degree of abnormality increases with the score. Step Two involves transforming a numerical severity score to a distribution on the referential grades “N” and “AN” based on the following transformation rule. With pulse rate as an example, the pulse rate of a patient is set as “N” with 100% certainty if its associated severity score is 0, “AN” with 100% certainty if its associated severity score is 3, {(N, 66.67%), (AN, 33.33%)} if its associated severity score is 1, and {(N, 33.33%), (AN, 66.67%)} if its associated severity score is 2. For the other four vital signs, that is, body temperature, respiration rate, systolic blood pressure, and level of consciousness, we used the same rules as discussed above for input transformation.

Second, calculate the activation weight of each belief rule in the BRB based on the weight associated with each rule and the degrees of belief in various reference categories after input transformation. Suppose 
                              
                                 
                                    ω
                                    k
                                 
                                 
                                    (
                                    
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                            is the rule activation weight, which measures the degree to which the packet antecedent Ak
                            in the kth rule is activated by the inputs. It can be calculated by

                              
                                 (3)
                                 
                                    
                                       
                                          ω
                                          k
                                       
                                       =
                                       
                                          
                                             
                                                θ
                                                k
                                             
                                             
                                                α
                                                k
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                L
                                             
                                             
                                                θ
                                                j
                                             
                                             
                                                α
                                                j
                                             
                                          
                                       
                                       =
                                       
                                          
                                             
                                                θ
                                                k
                                             
                                             
                                                ∏
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                
                                                   T
                                                   k
                                                
                                             
                                             
                                                
                                                   
                                                      (
                                                      
                                                         α
                                                         l
                                                         k
                                                      
                                                      )
                                                   
                                                
                                                
                                                   
                                                      δ
                                                      ¯
                                                   
                                                   
                                                      k
                                                      l
                                                   
                                                
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                L
                                             
                                             
                                                [
                                                
                                                   
                                                      θ
                                                      j
                                                   
                                                   
                                                      ∏
                                                      
                                                         l
                                                         =
                                                         1
                                                      
                                                      
                                                         T
                                                         k
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               α
                                                               l
                                                               j
                                                            
                                                            )
                                                         
                                                      
                                                      
                                                         
                                                            δ
                                                            ¯
                                                         
                                                         
                                                            j
                                                            l
                                                         
                                                      
                                                   
                                                
                                                ]
                                             
                                          
                                       
                                       ,
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                 
                              
                           where 
                              
                                 
                                    
                                       δ
                                       ¯
                                    
                                    
                                       k
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       δ
                                       
                                          k
                                          i
                                       
                                    
                                    
                                       
                                          max
                                          
                                             i
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             
                                                T
                                                k
                                             
                                          
                                       
                                       
                                          {
                                          
                                             δ
                                             
                                                k
                                                i
                                             
                                          
                                          }
                                       
                                    
                                 
                                 
                                    (
                                    
                                       0
                                       ≤
                                       
                                          
                                             δ
                                             ¯
                                          
                                          
                                             k
                                             i
                                          
                                       
                                       ≤
                                       1
                                    
                                    )
                                 
                              
                            is transformed from the antecedent attribute weight 
                              
                                 
                                    δ
                                    
                                       k
                                       i
                                    
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                       ;
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                            representing the relative importance of the ith antecedent attribute in the kth rule [29]. 
                              
                                 
                                    α
                                    i
                                    k
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                    
                                    )
                                 
                              
                            is the individual matching degree to which the input 
                              
                                 
                                    U
                                    i
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                    
                                    )
                                 
                              
                            belongs to 
                              
                                 
                                    A
                                    i
                                    k
                                 
                                 
                                    (
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       
                                          T
                                          k
                                       
                                       ;
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                           , which is the referential category of the ith antecedent attribute in the kth rule, and it is generated from the input transformation as described by (2), with 
                              
                                 
                                    α
                                    i
                                    k
                                 
                                 ≥
                                 0
                              
                            and 
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       T
                                       k
                                    
                                 
                                 
                                    α
                                    i
                                    k
                                 
                                 ≤
                                 1
                              
                           . 
                              
                                 
                                    α
                                    k
                                 
                                 =
                                 
                                    ∏
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       T
                                       k
                                    
                                 
                                 
                                    
                                       (
                                       
                                          α
                                          i
                                          k
                                       
                                       )
                                    
                                    
                                       
                                          δ
                                          ¯
                                       
                                       
                                          k
                                          i
                                       
                                    
                                 
                                 
                                    (
                                    
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                            is the combined matching degree to which the input vector matches the packet antecedent Ak
                            in the kth rule. Tk
                            is the total number of antecedent attributes in the kth rule. L is the total number of belief rules in the BRB.

Third, use the ER algorithm to aggregate all the activated belief rules in the BRB, thereby generating a distributed trauma outcome prediction with combined belief degrees distributed on all possible consequents or outcomes. The analytic ER algorithm [44] is given as follows:

                              
                                 (4)
                                 
                                    
                                       
                                          β
                                          j
                                       
                                       =
                                       
                                          
                                             μ
                                             ×
                                             
                                                [
                                                
                                                   
                                                      ∏
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      L
                                                   
                                                   
                                                      (
                                                      
                                                         
                                                            ω
                                                            k
                                                         
                                                         
                                                            β
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                         +
                                                         1
                                                         −
                                                         
                                                            ω
                                                            k
                                                         
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            β
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                   −
                                                   
                                                      ∏
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      L
                                                   
                                                   
                                                      (
                                                      
                                                         1
                                                         −
                                                         
                                                            ω
                                                            k
                                                         
                                                         
                                                            ∑
                                                            
                                                               j
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            β
                                                            
                                                               j
                                                               k
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                
                                                ]
                                             
                                          
                                          
                                             1
                                             −
                                             μ
                                             ×
                                             
                                                [
                                                
                                                   
                                                      ∏
                                                      
                                                         k
                                                         =
                                                         1
                                                      
                                                      L
                                                   
                                                   
                                                      (
                                                      
                                                         1
                                                         −
                                                         
                                                            ω
                                                            k
                                                         
                                                      
                                                      )
                                                   
                                                
                                                ]
                                             
                                          
                                       
                                       ,
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                 
                              
                           where 
                              
                                 μ
                                 =
                                 
                                    
                                       [
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             ∏
                                             
                                                k
                                                =
                                                1
                                             
                                             L
                                          
                                          
                                             (
                                             
                                                
                                                   ω
                                                   k
                                                
                                                
                                                   β
                                                   
                                                      j
                                                      k
                                                   
                                                
                                                +
                                                1
                                                −
                                                
                                                   ω
                                                   k
                                                
                                                
                                                   ∑
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   β
                                                   
                                                      j
                                                      k
                                                   
                                                
                                             
                                             )
                                          
                                          −
                                          
                                             (
                                             
                                                N
                                                −
                                                1
                                             
                                             )
                                          
                                          
                                          ×
                                          
                                       
                                       w
                                       
                                          
                                             ∏
                                             
                                                k
                                                =
                                                1
                                             
                                             L
                                          
                                          
                                             (
                                             
                                                1
                                                −
                                                
                                                   ω
                                                   k
                                                
                                                
                                                   ∑
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   β
                                                   
                                                      j
                                                      k
                                                   
                                                
                                             
                                             )
                                          
                                       
                                       ]
                                    
                                    
                                       −
                                       1
                                    
                                 
                              
                           , ωk
                            is the rule activation weight calculated by (3), and 
                              
                                 
                                    β
                                    j
                                 
                                 
                                    (
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                    )
                                 
                              
                            is the final combined belief degree associated with the corresponding consequent 
                              
                                 
                                    D
                                    j
                                 
                                 
                                    (
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                    )
                                 
                              
                           .

In this study, all rule weights and antecedent attribute weights are assumed to be equal, and a final combined outcome prediction with belief degrees distributed on “occurrence of in-hospital death or ICU admission” and “nonoccurrence of in-hospital death or ICU admission” was generated for each case that was included for analysis.

Note that in this study, all recorded clinical values or clinician judgments were certain values and could be transformed to early warning scores without uncertainty. Therefore, those early warning scores could be further transformed into precise distributed assessments on “N” and “AN” using the previously discussed transformation rules. In other disease diagnoses, there may be ambiguous judgements or missing values of some clinical variables that cannot be measurable at a certain time point.

If clinician judgements contain ambiguity and we cannot decide whether the patient is normal or abnormal with 100% certainty, we can convert the uncertain judgments to some degree (α) of normal and some degree (β) of abnormal. If α+β=1, then the inputted information is complete and the transformed inputs are complete distributed assessments on “N” and “AN”, which is the same as the transformation of those early warning scores. Thus the inference is the same as what were discussed above. If α+β<1, it brings ignorance to the inputs and the incomplete inputs would cause incomplete assessments on different consequents. Although the procedures of inference with incomplete inputs are the same as that for the complete inputs, the final distributed assessments on different consequents after aggregating all triggered belief rules should not be the inferred certain belief degrees, because there is also ignorance in the consequents. In the latter situation, the final distributed assessments on different consequents would be interval belief degrees.

If missing values for the input clinical variables exist, the BRB with certain consequent belief degrees (Table 1) can be extended to a BRB with interval belief degrees. A belief rule with interval belief degrees can be something like “IF body temperature is AN, respiratory rate is AN, systolic blood pressure is AN, pulse rate is AN, and level of consciousness is unknown, THEN {(occurrence of in-hospital death or ICU admission, [60–70%]), (nonoccurrence of in-hospital death or ICU admission, [30–40%])}.” Inference with this type of BRB with interval belief degrees needs to be implemented using the ER approach for combining multiple independent assessments with interval belief degrees, as proposed by Wang et al. [33]. The inference steps of the BRB with interval belief degrees are similar to the aforementioned steps. All sample data included in this study are certain data; thus, the details of the uncertainty handling capability of the RIMER model will not be discussed. Readers can refer to [33] for details of using the ER approach to deal with interval belief degrees.

The belief rules in the initial BRB are provided by domain experts and may not represent the real situation with 100% accuracy. A change in the knowledge representation parameters can lead to changes in the performance of a RIMER-based prediction model. Thus, the knowledge representation parameters need to be fine-tuned or trained using accumulated historical data. Suppose 
                              
                                 
                                    (
                                    
                                       
                                          
                                             x
                                             ^
                                          
                                          m
                                       
                                       ,
                                       
                                          
                                             y
                                             ^
                                          
                                          m
                                       
                                    
                                    )
                                 
                                 
                                    (
                                    
                                       m
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       M
                                    
                                    )
                                 
                              
                            is used to denote input–output pairs of M clinical cases in the training dataset. The process of training BRB from these M datasets can be depicted as in Fig. 1
                           , where 
                              
                                 
                                    x
                                    ^
                                 
                                 m
                              
                            is the clinical inputs of the mth case, ym
                            is the combined degree of belief generated by the RIMER-based model (implemented using Eqs. (2), (3), and (4)) in “occurrence of in-hospital death or ICU admission” with the inputs 
                              
                                 
                                    x
                                    ^
                                 
                                 m
                              
                           , 
                              
                                 
                                    y
                                    ^
                                 
                                 m
                              
                            is the actual or observed output of the mth case (a binary value), and ξ(P) represents the difference between the observed output and the system-generated output.

The objective of BRB training is to determine an optimal set of knowledge representation parameters (βjk, δi, θk
                           ) for the BRB by minimizing the discrepancies between system-generated outputs and the observed outcomes for all cases in the training dataset. In this study, all rule weights and antecedent attribute weights were set to be equal, and only consequent belief degrees βjk
                            were set as training parameters in the BRB training process. The constraints of the training model are given as 
                              
                                 0
                                 ≤
                                 
                                    β
                                    
                                       j
                                       k
                                    
                                 
                                 ≤
                                 1
                                 
                                    (
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       N
                                       ;
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                    )
                                 
                              
                            and 
                              
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    β
                                    
                                       j
                                       k
                                    
                                 
                                 =
                                 1
                              
                           , where L is the number of belief rules, and N is the number of all possible consequents in the BRB. The fmincon function in MATLAB was used to solve the single-objective optimization model. Except for MaxIter set at 60 and TolX at 0.00001, all other options of the function were set to the default values in MATLAB. The fine-tuned consequent belief degrees of each belief rule in the BRB after each training round are presented in the Results section.

LR measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities. LR is a maximum-likelihood method that has been used in many trauma outcome studies [21,22,25,45,46]. The binary LR model is used in this study. The binary logistic model is used to predict a binary outcome based on one or more predictor variables. In the model, the logit transformation of the probability pi
                         linked to a particular outcome of the ith case is expressed as a linear prediction function of the independent or predictor variables

                           
                              (5)
                              
                                 
                                    logit
                                    
                                       (
                                       
                                          p
                                          i
                                       
                                       )
                                    
                                    =
                                    ln
                                    
                                       (
                                       
                                          
                                             p
                                             i
                                          
                                          
                                             1
                                             −
                                             
                                                p
                                                i
                                             
                                          
                                       
                                       )
                                    
                                    =
                                    
                                       β
                                       0
                                    
                                    +
                                    
                                       β
                                       1
                                    
                                    
                                       x
                                       
                                          1
                                          ,
                                          i
                                       
                                    
                                    +
                                    ⋯
                                    +
                                    
                                       β
                                       j
                                    
                                    
                                       x
                                       
                                          j
                                          ,
                                          i
                                       
                                    
                                    +
                                    ⋯
                                    +
                                    
                                       β
                                       m
                                    
                                    
                                       x
                                       
                                          m
                                          ,
                                          i
                                       
                                    
                                 
                              
                           
                        where 
                           
                              j
                              =
                              1
                              ,
                              …
                              ,
                              m
                           
                        , and m is the number of predictor variables. The predictors can be categorical dummy variables or continuous variables. The coefficient βj
                         represents the change in the logit for each unit change in the associated predictor.

Solving for pi
                         results in the individual probability of the particular outcome as

                           
                              (6)
                              
                                 
                                    
                                       p
                                       i
                                    
                                    =
                                    
                                       
                                          exp
                                          
                                             [
                                             
                                                
                                                   β
                                                   0
                                                
                                                +
                                                
                                                   β
                                                   1
                                                
                                                
                                                   x
                                                   
                                                      1
                                                      ,
                                                      i
                                                   
                                                
                                                +
                                                ⋯
                                                +
                                                
                                                   β
                                                   j
                                                
                                                
                                                   x
                                                   
                                                      j
                                                      ,
                                                      i
                                                   
                                                
                                                +
                                                ⋯
                                                +
                                                
                                                   β
                                                   m
                                                
                                                
                                                   x
                                                   
                                                      m
                                                      ,
                                                      i
                                                   
                                                
                                             
                                             ]
                                          
                                       
                                       
                                          1
                                          +
                                          exp
                                          
                                             [
                                             
                                                
                                                   β
                                                   0
                                                
                                                +
                                                
                                                   β
                                                   1
                                                
                                                
                                                   x
                                                   
                                                      1
                                                      ,
                                                      i
                                                   
                                                
                                                +
                                                ⋯
                                                +
                                                
                                                   β
                                                   j
                                                
                                                
                                                   x
                                                   
                                                      j
                                                      ,
                                                      i
                                                   
                                                
                                                +
                                                ⋯
                                                +
                                                
                                                   β
                                                   m
                                                
                                                
                                                   x
                                                   
                                                      m
                                                      ,
                                                      i
                                                   
                                                
                                             
                                             ]
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Models derived using LR analysis typically employ only variables that are statistically significant predictors of a particular outcome. In LR analysis, a backward stepwise method can be used to eliminate variables without statistical significance from the model in an iterative process, whereas the fit of the model is tested after each variable is eliminated to ensure that the model still adequately fits the training data.

For deriving LR models, we have attempted to transform continuous variables, such as body temperature, pulse rate, respiration rate, and systolic blood pressure, to categorical variables in accordance with the early warning score criteria used in the RIMER methodology for input transformation. However, the LR model derived using transformed categorical predictor values obtained a worse prediction performance than the LR model that was derived using original continuous predictor values. Thus, the continuous values of the five vital signs, except level of consciousness, were used in the LR model derivation; only the value pertaining to level of consciousness was categorical like that in the RIMER model. In terms of the predictor variables in the LR model, we used both the backward stepwise method and the simple entering method. The latter method used all available predictors without considering corresponding statistical significance in model derivation. We found that the two LR models constructed with different independent predictor variables showed similar prediction performance. As the RIMER model employed all the five vital signs as antecedent attributes in its BRB, we also used a saturated LR model with the five vital signs as predictors in the LR model to compare the prediction performance of both models in the same prediction environment.

In this study, the same dataset used for RIMER training and testing was used for LR analysis. SPSS was employed for LR analysis.

SVM [47] is a supervised learning method used to perform dichotomy classification of multidimensional feature vectors. The basic idea under the SVM method is to transform the input features into a higher-dimensional space where the two classes can be linearly separated by a high-dimensional surface known as hyperplane. Given a training dataset 
                           
                              
                                 {
                                 
                                    
                                       (
                                       
                                          
                                             x
                                             i
                                          
                                          ,
                                          
                                             y
                                             i
                                          
                                       
                                       )
                                    
                                    
                                       |
                                    
                                    
                                       x
                                       i
                                    
                                    ∈
                                    
                                       R
                                       L
                                    
                                    ,
                                    
                                    
                                       y
                                       i
                                    
                                    ∈
                                    
                                       {
                                       
                                          −
                                          1
                                          ,
                                          +
                                          1
                                       
                                       }
                                    
                                 
                                 }
                              
                              
                                 i
                                 =
                                 1
                              
                              N
                           
                         with N samples, where yi
                         is either 1 or −1, indicating the class to which the data point xi
                         belongs. Each xi
                         is one L-dimensional real vector. The decision function of SVM is described as

                           
                              (7)
                              
                                 
                                    h
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       
                                          w
                                       
                                       T
                                    
                                    φ
                                    
                                       (
                                       x
                                       )
                                    
                                    +
                                    b
                                 
                              
                           
                        where φ(x) represents a mapping of sample x from the input space to a high-dimensional feature space, w denotes the normal vector to the learned hyperplane, and b is the model bias.

An SVM classifier needs to satisfy the following conditions:

                           
                              (8)
                              
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      w
                                                   
                                                   T
                                                
                                                φ
                                                
                                                   (
                                                   
                                                      x
                                                      i
                                                   
                                                   )
                                                
                                                +
                                                b
                                                ≥
                                                1
                                                
                                                i
                                                f
                                                
                                                
                                                
                                                   y
                                                   
                                                      i
                                                      
                                                   
                                                
                                                =
                                                +
                                                1
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      w
                                                   
                                                   T
                                                
                                                φ
                                                
                                                   (
                                                   
                                                      x
                                                      i
                                                   
                                                   )
                                                
                                                +
                                                b
                                                ≤
                                                −
                                                1
                                                
                                                i
                                                f
                                                
                                                
                                                
                                                   y
                                                   
                                                      i
                                                      
                                                   
                                                
                                                =
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The equation 
                           
                              
                                 
                                    w
                                 
                                 T
                              
                              φ
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 )
                              
                              +
                              b
                              =
                              0
                           
                         constructs a hyperplane that discriminates between the two classes, where |b|/w is the perpendicular distance from the hyperplane to the origin, and 1/w is the shortest distance from the hyperplane to the closest positive (negative) sample. A typical two-class problem classified using SVM is shown in Fig. 2
                        . Line H represents the separating hyperplane, and each of the two half spaces separated by H corresponds to one class, H1
                         for 
                           
                              
                                 y
                                 i
                              
                              =
                              +
                              1
                           
                        , and H2
                         for 
                           
                              
                                 y
                                 i
                              
                              =
                              −
                              1
                           
                        . The SVM determines a hyperplane with the maximal margin. The margin of an SVM classifier is the minimal distance of any training point to the hyperplane, which is the distance between the dotted lines H1
                         and H2
                         and the solid line H, as shown in Fig. 2
                        . Therefore, the margin of a hyperplane will be 
                           
                              1
                              /
                              w
                              +
                              1
                              /
                              w
                           
                        . Calculating the optimal separating hyperplane is equivalent to maximizing the separation margin or distance between the two dotted lines H1
                         and H2
                         
                        [48]. The training points that lie on the dotted lines H1
                         and H2
                         are referred to as support vectors and are colored in gray in Fig. 2.
                     

In practice, a separating hyperplane may not exist. To allow for the possibility of training samples violating the edges of the margin, slack variables 
                           
                              
                                 ξ
                                 i
                              
                              
                                 (
                                 
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    N
                                 
                                 )
                              
                           
                         with ξi
                         ≥ 0 are introduced. We can optimize the values of w and b by solving the following optimization problem:

                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             
                                                minimize
                                                
                                                   w
                                                   ,
                                                   b
                                                   ,
                                                   
                                                      ξ
                                                      i
                                                   
                                                
                                             
                                             
                                             
                                                
                                                   1
                                                   2
                                                
                                             
                                             
                                                
                                                   w
                                                
                                                T
                                             
                                             w
                                             +
                                             C
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                ξ
                                                i
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             subject
                                             
                                             to
                                             
                                             
                                                y
                                                i
                                             
                                             
                                                (
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      T
                                                   
                                                   φ
                                                   
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      )
                                                   
                                                   +
                                                   b
                                                
                                                )
                                             
                                             ≥
                                             1
                                             −
                                             
                                                ξ
                                                i
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                             
                                             
                                             
                                             
                                             
                                                ξ
                                                i
                                             
                                             ≥
                                             0
                                             ,
                                             
                                             i
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             N
                                          
                                       
                                    
                                 
                              
                           
                        where C (>0) is the regularization parameter (penalty factor) that regulates the relationship between training accuracy and model generalization, slack variables ξi
                         are used to achieve a soft margin, and φ is a non-linear mapping from an input space into a feature space. By introducing the Lagrange multiplier αi
                        , a corresponding dual problem can be derived as the following quadratic programming problem:

                           
                              (10)
                              
                                 
                                    
                                       
                                          
                                             
                                                maxmize
                                                
                                                   α
                                                   i
                                                
                                             
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                α
                                                i
                                             
                                             −
                                             
                                                
                                                   1
                                                   2
                                                
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                α
                                                i
                                             
                                             
                                                α
                                                j
                                             
                                             
                                                y
                                                i
                                             
                                             
                                                y
                                                j
                                             
                                             k
                                             
                                                (
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   ,
                                                   
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             subject
                                             
                                             to
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                α
                                                i
                                             
                                             
                                                y
                                                i
                                             
                                             =
                                             0
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                             
                                             
                                             
                                             
                                             0
                                             ≤
                                             
                                                α
                                                i
                                             
                                             ≤
                                             C
                                             ,
                                             
                                             i
                                             =
                                             1
                                             ,
                                             2
                                             ,
                                             …
                                             ,
                                             N
                                          
                                       
                                    
                                 
                              
                           
                        where k is a kernel function with 
                           
                              k
                              
                                 (
                                 
                                    x
                                    i
                                 
                                 ,
                                 
                                    x
                                    j
                                 
                                 )
                              
                              =
                              
                                 〈
                                 φ
                                 
                                    (
                                    
                                       x
                                       i
                                    
                                    )
                                 
                                 ,
                                 φ
                                 
                                    (
                                    
                                       x
                                       j
                                    
                                    )
                                 
                                 〉
                              
                           
                        , which maps the input vectors into a suitable feature space. Commonly used kernel functions in SVM include linear kernel, polynomial kernel, and radial basis function kernel. Once the dual quadratic programming problem is solved, the resulting decision function at any test data point x is as follows:

                           
                              (11)
                              
                                 
                                    h
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       
                                          w
                                       
                                       T
                                    
                                    φ
                                    
                                       (
                                       x
                                       )
                                    
                                    +
                                    b
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       N
                                    
                                    
                                       α
                                       i
                                    
                                    
                                       y
                                       i
                                    
                                    k
                                    
                                       (
                                       
                                          
                                             x
                                             i
                                          
                                          ,
                                          x
                                       
                                       )
                                    
                                    +
                                    b
                                    =
                                    
                                       ∑
                                       
                                          i
                                          ∈
                                          s
                                          v
                                       
                                    
                                    
                                       α
                                       i
                                    
                                    
                                       y
                                       i
                                    
                                    k
                                    
                                       (
                                       
                                          
                                             x
                                             i
                                          
                                          ,
                                          x
                                       
                                       )
                                    
                                    +
                                    b
                                 
                              
                           
                        
                     

Only those data points for which αi
                         is nonzero are referred to as support vectors, and they define the decision function.

In the test phase, to obtain a binary outcome, we estimate the class of the test data point x based on sign(h(x)). To obtain a binary outcome together with probability information, we need to extend the SVM to provide probabilities. Details of probability estimates obtained using SVM can be found in [49].

The present study employed the LIBSVM toolbox (for MATLAB environment) developed by Chang and Lin [50]. The svmtrain and svmpredict functions in the LIBSVM toolbox were used for SVM model training and testing. The procedures of employing svmtrain and svmpredict to obtain an optimal SVM model are as follows. First, we used the general and default kernel function (radial basis function) of LIBSVM to build SVM. Second, we established training samples and called svmtrain in LIBSVM to train SVM. Third, we called svmpredict to predict the samples in the training set using well-trained SVM models. To find an optimal set of parameters C and γ for the radial basis function kernel SVM, we tested different sets of C and γ using a five-round model training method. In this method, the whole dataset was split into five folds (roughly similar data distribution in each fold) and used any four folds for model training in each training round. The ranges of C and γ were set as [1,  24] and 
                           
                              [
                              
                                 
                                    2
                                    
                                       −
                                       5
                                    
                                 
                                 ,
                                 
                                 
                                 
                                    2
                                    
                                       −
                                       1
                                    
                                 
                              
                              ]
                           
                        , respectively, and their initial values were set to be 1 and 
                           
                              2
                              
                                 −
                                 5
                              
                           
                        , respectively. The value assignments of C and γ in the parameter searching process were set as (20, 
                           
                              
                              
                                 2
                                 
                                    0
                                    +
                                    s
                                    t
                                    e
                                    p
                                 
                              
                           
                        , 
                           
                              2
                              
                                 0
                                 +
                                 s
                                 t
                                 e
                                 p
                                 +
                                 s
                                 t
                                 e
                                 p
                              
                           
                        ,……,  24) and (
                           
                              2
                              
                                 −
                                 5
                              
                           
                        , 
                           
                              
                              
                                 2
                                 
                                    −
                                    5
                                    +
                                    s
                                    t
                                    e
                                    p
                                 
                              
                           
                        , 
                           
                              2
                              
                                 −
                                 5
                                 +
                                 s
                                 t
                                 e
                                 p
                                 +
                                 s
                                 t
                                 e
                                 p
                              
                           
                        ,……, 
                           
                              
                              
                                 2
                                 
                                    −
                                    1
                                 
                              
                           
                        ) (step=1) respectively. Finally, we selected the pair of parameters C and γ with the best average mean squared error (MSE) in the training dataset after five rounds of model training. After the parameters C and γ were determined, the same dataset for LR model training and testing was used for SVM model analysis. Instead of using the originally recorded values of body temperature, respiration rate, pulse rate, systolic blood pressure, and the numerical score of the level of consciousness, we normalized the input values to [0, 1] in the SVM model analysis, as recommended by Hsu et al. [51]. The outcome of the SVM model included two values ranging from 0 to 1, which indicate the probabilities linked to the occurrence and nonoccurrence of ICU admission or in-hospital death, respectively.

ANN has different types of structures [52]. One of the most common ANN structures is the multi-layer perceptron network, which is a feedforward type of the neural network [48,53]. A multi-layer perceptron with a back-propagation algorithm was used in the current study. A multi-layer perceptron network consists of multiple layers of neurons: one input layer receiving external inputs, one output layer generating the classification results, and one or more hidden layers. Each layer is fully connected to the next one. A typical multi-layer perceptron network structure with an input layer, a hidden layer, and an output layer is shown in Fig. 3.
                        
                     

Except for the input layer, each neuron in the network is a computational element that receives information from neurons of the previous layer, produces an output signal by an activation or transfer function, and passes it on to neurons of the next layer. The principle of the network is that when data are presented at the input layer, the neurons in the consecutive layers run computations until an output value is obtained at each of the output neurons. This output will indicate the appropriate outcome for the input data.

Each neuron in the hidden layer receives an activation signal, which is the weighted sum of all inputs that enter into the neuron. The resulting sum is used to generate an output of the neuron through an activation function. This process is defined as follows:

                           
                              (12)
                              
                                 
                                    
                                       v
                                       j
                                    
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       p
                                    
                                    
                                       x
                                       i
                                    
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (13)
                              
                                 
                                    
                                       y
                                       j
                                    
                                    =
                                    f
                                    
                                       (
                                       
                                          v
                                          j
                                       
                                       )
                                    
                                 
                              
                           
                        where vj
                         is the linear combination of inputs 
                           
                              
                                 x
                                 1
                              
                              ,
                              
                              
                                 x
                                 2
                              
                              ,
                              …
                              ,
                              
                              
                                 x
                                 n
                              
                           
                        , wij
                         is the connection weight between the input xi
                         and the jth neuron, f is the activation function used for the neuron, and yj
                         is the output of the neuron. The most commonly used activation function is the sigmoid function, and its general form is expressed as

                           
                              (14)
                              
                                 
                                    f
                                    
                                       (
                                       t
                                       )
                                    
                                    =
                                    
                                       1
                                       
                                          1
                                          +
                                          
                                             e
                                             
                                                −
                                                t
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The neurons in the output layer receive the following activation signals from the hidden neurons:

                           
                              (15)
                              
                                 
                                    
                                       h
                                       k
                                    
                                    =
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       y
                                       j
                                    
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                 
                              
                           
                        where wjk
                         is the weight of the connection between neuron j in the hidden layer and neuron k in the output layer. These activation signals are then transformed again to generate the outputs of the network as follows:

                           
                              (16)
                              
                                 
                                    
                                       o
                                       k
                                    
                                    =
                                    f
                                    
                                       (
                                       
                                          h
                                          k
                                       
                                       )
                                    
                                    =
                                    
                                       1
                                       
                                          1
                                          +
                                          
                                             e
                                             
                                                −
                                                
                                                   h
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where ok
                         is the output generated by the network.

Different algorithms have been developed to learn a multi-layer perceptron network using a set of training samples. The most popular algorithm is the backpropagation algorithm, a gradient descent method that adjusts the weights of interconnections to minimize output error. The error function of the output neuron is defined as

                           
                              (17)
                              
                                 
                                    E
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       ∑
                                       k
                                    
                                    
                                       
                                          (
                                          
                                             
                                                d
                                                k
                                             
                                             −
                                             
                                                o
                                                k
                                             
                                          
                                          )
                                       
                                       2
                                    
                                 
                              
                           
                        where dk
                         and ok
                         are the observed and network-generated values of the outputs, respectively. The objective of network learning is to minimize the error E for the network to achieve the best performance.

All weight vectors w are initialized with small random values from a pseudorandom sequence generator. The following steps are repeated until the convergence (i.e., when the error E is below a preset value).

The weights between the hidden layer and the output layer wjk
                         are updated by

                           
                              (18)
                              
                                 
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       
                                          t
                                          +
                                          1
                                       
                                       )
                                    
                                    =
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    +
                                    Δ
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                 
                              
                           
                        where

                           
                              (19)
                              
                                 
                                    Δ
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    =
                                    −
                                    η
                                    
                                       
                                          ∂
                                          E
                                          
                                             (
                                             t
                                             )
                                          
                                       
                                       
                                          ∂
                                          
                                             w
                                             
                                                j
                                                k
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (20)
                              
                                 
                                    Δ
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    =
                                    −
                                    η
                                    
                                       
                                          ∂
                                          E
                                       
                                       
                                          ∂
                                          
                                             o
                                             k
                                          
                                       
                                    
                                    
                                       
                                          ∂
                                          
                                             o
                                             k
                                          
                                       
                                       
                                          ∂
                                          
                                             h
                                             k
                                          
                                       
                                    
                                    
                                       
                                          ∂
                                          
                                             h
                                             k
                                          
                                       
                                       
                                          ∂
                                          
                                             w
                                             
                                                j
                                                k
                                             
                                          
                                       
                                    
                                    =
                                    η
                                    
                                       (
                                       
                                          
                                             d
                                             k
                                          
                                          −
                                          
                                             o
                                             k
                                          
                                       
                                       )
                                    
                                    
                                       f
                                       ′
                                    
                                    
                                       (
                                       
                                          h
                                          k
                                       
                                       )
                                    
                                    
                                       y
                                       j
                                    
                                    =
                                    η
                                    
                                       δ
                                       
                                          o
                                          k
                                       
                                    
                                    
                                       y
                                       j
                                    
                                 
                              
                           
                        where η is the learning rate, and δok
                         is the error signal of the neuron k in the output layer given by

                           
                              (21)
                              
                                 
                                    
                                       δ
                                       
                                          o
                                          k
                                       
                                    
                                    =
                                    
                                       (
                                       
                                          
                                             d
                                             k
                                          
                                          −
                                          
                                             o
                                             k
                                          
                                       
                                       )
                                    
                                    
                                       f
                                       ′
                                    
                                    
                                       (
                                       
                                          h
                                          k
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

To avoid oscillation at large η, the changes in the weights are made to depend on the past changes by adding a momentum term α:

                           
                              (22)
                              
                                 
                                    Δ
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       
                                          t
                                          +
                                          1
                                       
                                       )
                                    
                                    =
                                    η
                                    
                                       δ
                                       
                                          o
                                          k
                                       
                                    
                                    
                                       y
                                       j
                                    
                                    +
                                    α
                                    Δ
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                 
                              
                           
                        
                     

Similarly, the changes in the weights between the neurons in the input and hidden layer, Δwij
                        (t), are given by

                           
                              (23)
                              
                                 
                                    Δ
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                    =
                                    −
                                    η
                                    
                                       
                                          ∂
                                          E
                                       
                                       
                                          ∂
                                          
                                             w
                                             
                                                i
                                                j
                                             
                                          
                                       
                                    
                                    =
                                    −
                                    η
                                    
                                       ∑
                                       k
                                    
                                    
                                       (
                                       
                                          
                                             
                                                ∂
                                                E
                                             
                                             
                                                ∂
                                                
                                                   o
                                                   k
                                                
                                             
                                          
                                          
                                             
                                                ∂
                                                
                                                   o
                                                   k
                                                
                                             
                                             
                                                ∂
                                                
                                                   h
                                                   k
                                                
                                             
                                          
                                          
                                             
                                                ∂
                                                
                                                   h
                                                   k
                                                
                                             
                                             
                                                ∂
                                                
                                                   y
                                                   j
                                                
                                             
                                          
                                          
                                             
                                                ∂
                                                
                                                   y
                                                   j
                                                
                                             
                                             
                                                ∂
                                                
                                                   v
                                                   j
                                                
                                             
                                          
                                          
                                             
                                                ∂
                                                
                                                   v
                                                   j
                                                
                                             
                                             
                                                ∂
                                                
                                                   w
                                                   
                                                      i
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                       )
                                    
                                    =
                                    η
                                    
                                       δ
                                       
                                          y
                                          j
                                       
                                    
                                    
                                       x
                                       i
                                    
                                 
                              
                           
                        where δyj
                         is the error signal of the neuron j in the hidden layer and is given by

                           
                              (24)
                              
                                 
                                    
                                       δ
                                       
                                          y
                                          j
                                       
                                    
                                    =
                                    
                                       f
                                       ′
                                    
                                    
                                       (
                                       
                                          v
                                          j
                                       
                                       )
                                    
                                    
                                       ∑
                                       k
                                    
                                    
                                       δ
                                       
                                          o
                                          k
                                       
                                    
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                 
                              
                           
                        
                     

Similarly, a momentum term can be added to prevent oscillation.

Through the learning process, a set of optimal weights can ensure that the resulting vector generated by the network is the same or sufficiently close to the observed output vector for each input vector.

A previous study [52] showed that an ANN with a single hidden layer with a sufficiently large number of neurons can relate any given set of inputs to outputs. Therefore, a three-layer ANN was constructed in this study.

The input variables of the ANN were the same as the inputs of the LR models. The only output of the ANN is a value ranging from 0 to 1, which may represent the probability of the primary outcome for each studied sample. Meanwhile, numerous thumb rules are used for determining the number of neurons in the hidden layer. An empirical equation used in this study is as follows.

                           
                              (25)
                              
                                 
                                    h
                                    =
                                    
                                       
                                          m
                                          +
                                          n
                                       
                                    
                                    +
                                    a
                                 
                              
                           
                        where h is the target number, m is the number of neurons in the output layer, n is the number of variables in the input layer, and a is an integer constant with a ∈ [1, 10]. According to the above formula, the number of neurons in the hidden layer may be between 3 and 12.

The feedforwardnet, train, and sim functions in MATLAB were employed to create, train, and test ANN models. In creating and training the ANN, the training function was set as traingdm, the transfer function was set as logsig, and all other parameters in the ANN models were set to their default values in MATLAB. To find an optimal network structure, we used the trial-and-error method to train and test different ANN models with various numbers (ranging from 3 to 12) of neurons in the hidden layer. Similar to optimal parameter searching in SVM model analysis, the five-round model training method was used to train different ANN models. An ANN model with the best average MSE in the training dataset was selected after five rounds of ANN training. After the ANN model structure was determined, the same dataset used for SVM model analysis was employed for ANN model training and testing.

The five-fold cross-validation method was employed in this study to train and validate all constructed prediction models. The studied dataset was split into five folds with equal cases (with each fold containing roughly the same proportions of the two types of outcome). A single fold out of the five folds is retained as the validation set for model testing, and the remaining four folds are used as the training set for model derivation. Thus, the four constructed models were trained and tested five times using any four folds as the training set and the remaining fold as the test set.

Plotting the ROC curve is a commonly used method of illustrating the discriminatory accuracy of a diagnostic tool for detecting or predicting whether a patient has a disease or outcome [54]. In medicine, a person is assessed as diseased (positive) or healthy (negative) depending on whether the corresponding test value is greater than, less than, or equal to a given threshold value. Associated with any threshold value are the probability of a true positive (sensitivity) and the probability of a true negative (specificity). The theoretical ROC curve is a plot of sensitivity versus 1-specificity for all possible threshold values. The most commonly used global index of diagnostic accuracy is the AUC [54]. The AUC has also been employed to measure the performance of prediction models in many trauma studies [25,45,46,55,56].

With the observed outcome as the gold standard, the following were used to plot the ROC curves: the final combined belief degree distributed on “occurrence of in-hospital death or ICU admission” generated by the RIMER model, the predicted probabilities of in-hospital death or ICU admission generated by the LR model, the SVM model, and the ANN model in each test fold. The average AUC value was used as a measure to compare the prediction performance of the four different models.

@&#RESULTS@&#

The consequent belief degree in the “occurrence of in-hospital death or ICU admission” of each belief rule in the RIMER model before and after each training round is shown in Table 3
                     , where R1, R2, R3, R4, and R5 represent the first, second, third, fourth, and fifth training rounds, respectively. The sum of consequent belief degrees in “occurrence” and “nonoccurrence” of in-hospital death or ICU admission in each belief rule is always equal to 1 in the RIMER model constructed in this study.
                     
                  


                     Table 3 shows that the difference between fine-tuned consequent belief degrees and initial values is not large in each training round. This information indicates that the trained BRB has not significantly departed from the initial BRB provided by domain experts. The small variation also reveals that the fine-tuned consequent belief degrees are reasonable and reflect the real situation of patient outcomes in the corresponding training dataset.

Coefficients in the derived LR model in different training rounds are shown in Table 4. β
                     0 represents the constant; β
                     1, β
                     2, β
                     3, and β
                     4 represent coefficients associated with the continuous variables body temperature, respiration rate, pulse rate, and systolic blood pressure, respectively; and β
                     5, β
                     6, β
                     7, and β
                     8 represent coefficients associated with four different levels of consciousness, which is a categorical predictor in different LR models derived in this study.


                     Table 4 indicates that coefficients in LR models after training with different datasets vary significantly, and the values of coefficients in each model are completely determined by data characteristics in the corresponding training dataset.

Regarding SVM models, we found through five rounds of training that the parameter pair 
                        
                           [
                           
                              C
                              =
                              8
                              ,
                              
                              
                              γ
                              =
                              0.25
                           
                           ]
                        
                      for the radial basis function kernel SVM could help achieve the best average MSE in the training dataset. Therefore, we chose the radial basis function kernel SVM model with 
                        
                           C
                           =
                           8
                        
                      and 
                        
                           γ
                           =
                           0.25
                        
                      to perform SVM model training and testing.

As discussed in Section 2.5, we employed an ANN model with one hidden layer and tested different ANN structures with 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12 neurons in the hidden layer. To find an optimal ANN structure, we used both originally recorded data and normalized data as in SVM analysis to perform ANN model training and testing. We found that ANN models performed much better with originally recorded values. The ANN model that could achieve the best average MSE in the training dataset was an ANN model with five neurons in the hidden layer.

The AUCs that represent the prediction performance of the RIMER model, the LR model, the optimal SVM model, and the optimal ANN model in different training and testing rounds are shown in Table 5.

As shown in Table 5, the prediction performance of the RIMER model before BRB training is stable, which shows that the BRB model can represent medical knowledge and mimic medical reasoning as an open-box simulator in a robust way. Its performance can be further improved after fine-tuning its parameters. This learning ability of the BRB model differentiates itself from a traditional rule-based system that is also an open-box simulator. Among the other three data-driven models, the models showing performances from the best to the worst are as follows: the LR model, SVM model, and ANN model. The prediction performance of the three data-driven models (LR, SVM, and ANN) are clearly not as stable as the RIMER model and may differ significantly when they are learned from different training datasets. For instance, the LR model may provide a perfect prediction performance such as that in the fourth training round but the prediction performance of the learned LR model may not be good enough in the first training round. This finding is expected because the LR model is a simulator with an assumed model structure; its parameters are completely determined by the training dataset. The same reasons apply to the SVM and ANN models.

@&#DISCUSSION@&#

This study is the first to employ the RIMER methodology to develop a trauma outcome prediction tool. It is the first comparison study in which the prediction performance of the RIMER methodology is compared with the three most commonly used data-driven modeling methods LR, SVM, and ANN. Based on the study results, the prediction performance of the RIMER model is stable and can be improved after training. The initial BRB in the RIMER-based prediction tool is provided by domain experts, and its accuracy directly affects the prediction performance of the model.

LR analysis, SVM, and ANN, the three most commonly employed tools to derive outcome prediction tools in trauma studies, are completely data-driven. Data-driven methods have advantages in model derivation because they require no prior knowledge about a concrete relationship between independent predictors and a particular dependent outcome. However, the prediction performance of the derived LR, SVM, and ANN models may widely vary in different training rounds despite having the same model structure. This variation is attributed to the fact that the prediction performance of a model completely derived from historical data is determined by the training dataset.

Among the three data-driven models, LR analysis exhibits its own characteristics. Through LR analysis, we cannot only obtain an outcome prediction model, but also know which predictor shows a statistically significant correlation with the particular outcome. Only predictors with statistical significance are typically used to construct LR models. However, to compare the four models using the same predictive variables, we employed the same variables that were used as antecedent attributes in the RIMER methodology to construct LR models. We found that the LR model constructed with all five vital signs as predictors and the LR model with only statistical significant variables as predictors showed similar prediction performance.

Meanwhile, SVM and ANN models exhibit similar features. The final structure of either model is determined by the training dataset. Nevertheless, the optimal parameters and internal functions of both models need to be determined using a trial-and-error method, and the initial values of those parameters need to be set by system designers based on their domain knowledge and experiences. Therefore, different studies may yield different SVM or ANN models even though the same modelling methodology and dataset are used. Moreover, to system users, the LR, SVM, and ANN models are completely black boxes, and clinicians may be reluctant to use these prediction tools in their practice because they do not know what clinical rules have been applied in these tools.

As to the RIMER methodology, the results indicate that the initial BRB is robust, and fine-tuning the initial BRB using a historical dataset can help to make consequent belief degrees in the initial BRB more accurately reflect the real situation in the training dataset. The performance improvement of the RIMER model through training is not that significant because the initial BRB is already very close to reality and can already provide very good prediction performance. Alternatively, if the initial BRB is not provided by domain experts and deviates far from reality, the initial prediction performance could be poor, and the differences of consequent belief degrees in the BRB before and after training can be large. Thus, in such situations, the performance improvement may be obvious and significant, depending on the initial BRB and the training and testing datasets.

Compared with the LR, SVM, and ANN models, the RIMER model uses both historical datasets and domain expert knowledge. Due to the fact that the learned model performs less well on a new dataset than on the dataset used for model training [57], the performance of a completely data-driven model, such as the LR, SVM, and ANN models derived in this study, is not ensured. In a model developed by combining the knowledge-based method and the data training method, such as the RIMER-based model in this study, the prediction performance can be secured to a certain degree. In detail, the initial knowledge base in the RIMER model is provided by domain experts, and it is based on expert knowledge and clinical experiences that have been proven correct by numerous clinical cases, thereby assuring its clinical robustness. Furthermore, fine-tuning the initial knowledge base (BRB) using a historical dataset improves the accuracy of the knowledge representation parameters to fit the specific data characteristics in the training dataset. The method also enhances the knowledge base to better represent the relationship between independent predictors and the particular dependent outcome. It may explain why the RIMER model provided a more robust and better prediction performance than the LR, SVM, and ANN models.

However, the RIMER methodology has its limitations. In other disease areas in which a concrete relationship between predictive variables and outcome variable is unavailable, an initial knowledge base will be difficult to construct. In such cases, the performance of the RIMER methodology will depend on data only, similar to the LR, SVM, and ANN modeling methodologies. Under the circumstances, machine learning methods such as decision tree learning can be employed to learn traditional “IF-THEN” rules from historical data first, and then those learned traditional rules can be extended to belief rules according to the distribution of real medical outcome in the training dataset. In such cases, it is necessary to train the initial belief rules using accumulated historical data before the knowledge base is put into practice.

In real implementation, the fine-tuned or trained consequent belief degrees should not be directly applied to infer with input clinical data immediately after training. All trained belief rules need to be approved by domain experts prior to their real application. This procedure helps ensure that only rational and approved knowledge is used in the knowledge-based prediction model. This method also guarantees the accuracy of the embedded knowledge base.

@&#CONCLUSIONS@&#

This study contributes to the research by developing and validating a RIMER-based outcome prediction model to assist ED physicians to predict the probability of in-hospital death and ICU admission among trauma patients. The RIMER model is compared to the most commonly used methods in deriving trauma outcome prediction models, which include LR analysis, SVM, and ANN. The five-fold cross-validation method is employed in this study to validate the RIMER-based, LR-based, SVM-based, and ANN-based prediction models. To compare the prediction performance of the newly developed RIMER model with those of the other three commonly used data-driven models, the AUC values that represent the prediction performance of the four models were obtained. The results show that the RIMER model performs the best. Meanwhile, its initial BRB provided by trauma experts exhibits robust prediction performance, which can be further improved after fine-tuning through historical trauma data. The LR model performs better than the SVM and ANN models. Among all models, the ANN model shows the least AUC.

To conclude, the RIMER methodology provides an innovative way for clinical decision science researchers to fully benefit from both expert knowledge and historical patient data to develop a decision support tool to assess illness severity and predict patient outcome. Compared with LR analysis, SVM, and ANN, the RIMER-based model provides the best prediction performance. The RIMER tool exhibits strong potential to help ED physicians to better triage trauma, optimally utilize hospital resources, and achieve better patient outcomes. In our future work, we plan to implement the RIMER-based outcome prediction model in real practice and generalize the RIMER-based outcome prediction model to other diseases and departments.

@&#ACKNOWLEDGMENTS@&#

This study was supported by a grant from the National Natural Science Foundation of China (NSFC) under Grant No.: 81301296. The study was also supported by a humanities and social sciences project funded by the Ministry of Education of China under Grant No.: 13YJC630066. This study was also supported by a grant from the National Health and Family Planning Commission of China under Grant No. 201002014.

@&#REFERENCES@&#


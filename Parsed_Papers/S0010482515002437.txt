@&#MAIN-TITLE@&#Stabilizing 3D in vivo intravital microscopy images with an iteratively refined soft-tissue model for immunology experiments

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Software for stabilizing in vivo two-photon microscopy images with tissue movements.


                        
                        
                           
                           Pixel weighted registration algorithm that explicitly treats inter and intrastack motion errors.


                        
                        
                           
                           A nonlinear soft-tissue deformation alignment correction called the poor man׳s diffeomorphic map.


                        
                        
                           
                           A method for detecting and removing multiple exposure errors caused by undersampling.


                        
                        
                           
                           A globally stabilization method using a constrained optimization method.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Bioimaging

Biomedical image stabilization

Image registration

Soft-tissue deformations

In vivo two photon microscopy

Lymphocyte tracking

@&#ABSTRACT@&#


               
               
                  We describe a set of new algorithms and a software tool, StabiTissue, for stabilizing in vivo intravital microscopy images that suffer from soft-tissue background movement. Because these images lack predetermined anchors and are dominated by noise, we use a pixel weighted image alignment together with a correction for nonlinear tissue deformations. We call this correction a poor man׳s diffeomorphic map since it ascertains the nonlinear regions of the image without resorting to a full integral equation method. To determine the quality of the image stabilization, we developed an ensemble sampling method that quantifies the coincidence between image pairs from randomly distributed image regions. We obtain global stabilization alignment through an iterative constrained simulated annealing optimization procedure. To show the accuracy of our algorithm with existing software, we measured the misalignment error rate in datasets taken from two different organs and compared the results to a similar and popular open-source solution. Present open-source stabilization software tools perform poorly because they do not treat the specific needs of the IV-2pM datasets with soft-tissue deformation, speckle noise, full 5D inter- and intra-stack motion error correction, and undefined anchors. In contrast, the results of our tests demonstrate that our method is more immune to noise and provides better performance for datasets’ possessing nonlinear tissue deformations. As a practical application of our software, we show how our stabilization improves cell tracking, where the presence of background movement would degrade track information. We also provide a qualitative comparison of our software with other open-source libraries/applications. Our software is freely available at the open source repository http://sourceforge.net/projects/stabitissue/.
               
            

@&#INTRODUCTION@&#

In vivo intravital imaging microscopy (IVM) is used to extract quantitative cell information, such as location, motility, adhesion and interactions [46], that best resemble the actual cellular behavior within an organ [43]. Volume data in intravital two photon microscopy (2pM) imaging is acquired from planar images (i.e., z-stacks) obtained by successively changing the 
                        z
                     -focal length, and subsequently repeating the volume acquisition over time. Thus, a five-dimensional image is represented as 
                        I
                        (
                        x
                        ,
                        y
                        ,
                        z
                        ,
                        c
                        ,
                        t
                        )
                     , with a set of z-stacked 2D 
                        (
                        x
                        ,
                        y
                        ,
                        z
                        )
                      images, a set of color channel 
                        (
                        c
                        )
                     , and time 
                        (
                        t
                        )
                     . The acquisition of deeper volumes and higher resolution is limited by the finite acquisition time of the microscope. This time to obtain an image for an image stack volume directly impacts the time-resolution associated with capturing cell behavior in the live tissue.

Image acquisition times depend upon the laser microscopy and fluorescent marker parameters in a complex way. Nonetheless, typical acquisition times 
                        (
                        Δ
                        
                           
                              t
                           
                           
                              s
                           
                        
                        )
                      are approximately 3s/slice and, therefore, 30s or more for a practical tissue volume (for 10 image slices or more). As an example, the image acquisition time needed to resolve lymphocytes motility in typical immunology experiments is limited by the average lymphocyte speed of 
                        10
                        –
                        25
                        
                        μ
                        m
                        /
                        min
                      
                     [39]. Thus, if the volume acquisition is 30s 
                        (
                        Δ
                        
                           
                              t
                           
                           
                              s
                           
                        
                        =
                        3
                        s
                        /
                        slice
                        ×
                        10
                        
                        slices
                        )
                     , the lymphocytes travel approximately their diameter between volume acquisitions. During this time to acquire an image volume, background tissue movements could corrupt image quality, thereby compromising quantitative measurement required to answer biological questions. Background motion can also accentuate errors due to undersampling, introducing multiple exposure artifacts.

These fundamental technical problems of IVM technology limit both the possible spatio-temporal resolution as well as the ability to attain deeper tissue volumes. Thus, practitioners invest considerable efforts in specialized microscope staging to reduce tissue motion in the live animal under study. Even with experimental precautions, the background motion of organs during image acquisition cannot be entirely eliminated. These movements cause relative displacements between successive image stacks over time, degrading the final quality of the dataset. To remove these displacements, image stacks are aligned, or registered.

Alignment in this context means that for a particular image I
                     
                        t
                      along the timeline, we determine the relative displacement vector 
                        Δ
                        u
                      with its predecessor, 
                        
                           
                              I
                           
                           
                              t
                              −
                              1
                           
                        
                     , such that the overlap between the images is maximal. This procedure is repeated for all image pairs, using the vectors to translate images so as to obtain maximum pixel coincidence. We refer to this process of aligning all image stacks relative to one another as stabilization. Moreover, fluorescent two-photon microscopy is not only three-dimensional but also multi-channel. Different wavelengths correspond to different reporter proteins, and hence can distinguish biologic cells and tissue of interest. In channels that tag specific cells, all other biologic tissue is transparent. Thus, once the alignment from this color channel is obtained, the results are applied to the other color channels.

Most registration/stabilization algorithms were designed to align images or image sequences using well-defined anatomic landmarks. Such algorithms employ scale invariant feature vectors (e.g. SIFT (scale invariant feature transform
                     [37]) or other similar techniques, that allow a comparison of key points between successive images. In the case of IV-2pM, predefined anchor structures are often not available. Instead, the only landmarks may be blood vessels or other soft vessels that are neither fixed, nor maintain their shape over time. Also, IV-2pM datasets are dominated by speckle noise, rendering them poor candidates for feature-based registration methods. As a result, the specialized registration algorithm must use these approximate anchors to infer the best alignment solution for this particular application.

ImageJ [51] and the parallel development branch, Fiji [50], are popular general purpose (open-source) tools for microscopy analysis, which have active third party software contributions through plugin support. In both platforms, plugins are available for performing image registration and stabilization. Nonetheless, the specific needs of the IV-2pM datasets with soft-tissue deformation, speckle noise, full 5D inter- and intra-stack motion error correction, and undefined anchors, are not well treated in these more general purpose plugins. To this end, we developed a set of specialized algorithms for stabilizing IV-2pM datasets that we have packaged into a software tool, called StabiTissue, that is freely available at http://sourceforge.net/projects/stabitissue/.


                     Fig. 1
                      shows a top-level workflow of the principle steps StabiTissue for stabilizing IV-2PM image datasets. In the next section, we provide a brief background of previous work and the problem context. In the Methods section, we describe the technical details of the algorithms employed by our software: (1) a pixel weighted registration algorithm that explicitly treats inter- and intra-stack motion errors, (2) a nonlinear soft-tissue deformation alignment correction process, we call the poor man׳s diffeomorphic map, (3) a method for detecting and removing multiple exposure errors caused by undersampling, and (4) a global stabilization method that selects the optimal internal parameters of our method using a constrained optimization method based upon simulated annealing.

Intravital imaging has become a mainstream technology in the biological sciences that is used in various ways to study the spatial location, motility, adhesion and interaction of cells within their natural environment, or ecological niche. While in widespread use, advances are continually pushing the envelope of time/spatial performance and even more are promised on the horizon. Developments in dynamic intravital multiphoton microscopy have been described in recent reviews [41,46], while high resolution intravital microscopy techniques are treated in [3]. A discussion of intravital imaging used in dynamic biological systems can be found in [28].

The field of Immunology has particularly benefited from IVM [4], where many processes of the adaptive immune system have been revealed, despite still being poorly understood due to the complex interplay between different lymphocyte types and other cells of the immune system. IVM has been made possible with the discovery and implementation of multiphoton microscopy, first described by [25]. Early work applying IVM to immunology can be found in [26,20]. The development of two-photon microscopy (2pM) facilitated the ability to probe live tissue at greater depths, representing a considerable improvement over traditional confocal microscopy. Because two-photon excitation use lower-energy photons (i.e., employing the concept of two-photon absorption that subsequently results in the spontaneous emission of a photon of higher energy at the fluorescent wavelength), 2pM produces lower backscatter and also lower photobleaching damage to tissue. Since the probability that a two-photon absorption events occurs is exceedingly small, the photon density must be high. Such high densities can be achieved with short-pulse (femtosecond) and high powered lasers, sufficient photon–photon interactions can take place.

Practical issues involved in using IVM in conjunction with two-photon microscopy (2pM) for immunological research is described in [44], while a review of immunoimaging techniques is described by [59]. From many different studies using IV-2pM, lymphocyte function in the adaptive immune system is being elucidated. With respect to the location and motility: B cell migration has been extensively studied in germinal centers to understand details of the maturation process, possibly involving a recycling process in two spatially distinct regions, the dark and light zones: [13,61,24,2,6,63,7]. More complex motility of leukocytes has been studied using 2pM IVM in a beating heart [34].

We have recently used IV-2pM to study lymphocytes interactions in the presence of malaria [16]. In other work, we used IVM to reveal the complex behavior of regulatory T cells (Tregs) and dendritic cell (DC)/lymphocyte contacts in the uterus and placenta [65,66] in order to uncover the role of Tregs in pregnancy. Lymphocyte cell-cell contact interactions have been studied with IV-2pM to understand the basic process of lymphocyte activation, through the so-called immunological synapse [17]. A recent review has discussed the techniques for visualization of cell–cell contact at the fetal–maternal interface, [43,42].

IV-2pM has also made its way into clinical uses. Deep intravital tissue imaging for clinical research using IV-2pM is discussed in [63,64]. IVM is also being used for revealing new insights into metastasis of tumors [5], who suggest that intravital real-time microscopic imaging of living organs, such as through endomicroscopy and surgical imaging shall be important in the future. The IV-2pM methods are also used in neuroscience applications [55], where stringent resolutions are required [54].

A technical problem that affects the quality of IV-2pM images is the background tissue movement associated with the living animal and the natural peristaltic movement of the organ under study. Several researchers have described specialized experimental stands whose objective is to reduce the source of movement. [32] showed that by measuring the respiration with a piezoelectric device, the background respiration induced motion could be subtracted out from the final image acquisition. Others have developed special staging structures for studying abdominal cavities [10] and lungs [36], where background movements are particularly pronounced. Physical movement compensation methods, such as suctioning stabilization are described by [62]. Adaptive movement compensation [31] and motion correction [11,12], which feedback systems have been described to improve resolution of cellular level dynamics in the presence of large background tissue movement. Recently, a fully integrated open source hardware/software co-design solution using bead tracking with feedback compensation has been developed [50,45,21].

Despite these experimental methods to reduce movement, image sequences can benefit from post-processing image alignment. As described previously, image registration is the process of finding the mapping between one image and another, whether it is a linear displacement or involving some nonlinear warping, by using common features as landmarks. Such features could be elementary geometric entities in the image (e.g., edges, contours, or lines) that constitute distinguishing control points (e.g., as in the SIFT method, or scale invariant feature transform 
                        [37]) for performing similarity comparisons between two images. The spatial mapping between the set of images can be either linear (e.g., translational or purely rotational) or nonlinear that take into account local diffeomorphic mappings between points, as for example in the elastix software library [30].

The choice of the basic image registration technique is driven by the problem to be solved and there is no universal technique that can work in all cases. For example, the choice of features and matching will depend upon whether there are rigid or known landmarks and features, or the extent of alignment; i.e., if it consists of a set of images or is pairwise. Reviews of image registration can be found in [67,49]. Complete treatment of image registration, and other computer vision topics, are covered in the recent book by Szeliski [57] and another by Modersitzki [40]. We used a form of the Fourier based algorithms for registration [53,47,15], together with a pixel weighting [57] method.

As can be seen in these references, the field of image registration is mature particularly for images where landmark features are well defined and features are easily determined. In such cases, many sophisticated algorithms have been developed, especially for medical applications, to handle challenging situations, such as obtaining globally consistent alignment, different exposure levels, to remove object movement, and to determine a nonlinear (diffeomorphic) warping between images. When no such landmarks are available, however, as in the case of IV-2pM, effective algorithms are still in their infancy. Our software fills this gap and provides a solution for the specific problems faced by full 5D IV-2pM motion errors.

@&#METHODS@&#

In this section, we describe the principal algorithms of our method. The registration technique we employ assumes cases for which rigid anchors are not available, thereby rendering feature based methods less effective. We discuss the registration technique, nonlinear corrections, undersampling error correction, and a global stabilization procedure.


                     Images and time. Intravital two-photon excitation fluorescence microscopy obtains volume information by constructing successive images at different focal depths 
                        {
                        
                           
                              z
                           
                           
                              1
                           
                        
                        …
                        
                           
                              z
                           
                           
                              n
                           
                        
                        }
                      (referred to as the z-stack), and in different color channels. Each image in this z-stack can be represented as 
                        I
                        (
                        x
                        ,
                        y
                        ,
                        c
                        ,
                        t
                        )
                     . A finite time transpires between image acquisition of each planar image in a stack, given by 
                        Δ
                        
                           
                              t
                           
                           
                              z
                           
                        
                      (z-stack acquisition time). This time (
                        ~
                        3
                        
                        s
                      for 
                        512
                        ×
                        512
                      images) is a function of the image resolution, fluorescence intensity desired, and mechanical x–y scanning rate of the microscope. Since 
                        Δ
                        
                           
                              t
                           
                           
                              z
                           
                        
                      should be fast enough to image cell displacements that are approximately the size of a cell diameter, there is a practical upper limit on the tissue depths that can be imaged while still retaining sufficient time resolution [39].

When reconstructing the 3-dimensional volume images over time, it is common among practitioners, but erroneous, to consider the stack volumes as occurring at an instantaneous time t
                     
                        j
                     . However, there are really two times: inter-frame time difference 
                        Δ
                        
                           
                              t
                           
                           
                              z
                           
                        
                     , defined previously as the finite time between images in the same stack, and the intra-frame difference 
                        Δ
                        
                           
                              t
                           
                           
                              intra
                           
                        
                     , which is the time between stack volumes (when the microscope returns to cycle over a stack volume in the z-direction). Thus, to reconstruct a stabilized volume, both times must be considered and alignments must be performed within the same stack and between stack volumes.

The following definitions shall aid the description of the algorithms. We define mth image slice of the nth stack volume as 
                           I
                           
                              
                                 (
                                 x
                                 )
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                        . For each 
                           I
                           
                              
                                 (
                                 x
                                 )
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                        , the mean pixel intensity threshold, 
                           
                              
                                 θ
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                         is used to extract a set of contours, 
                           
                              
                                 γ
                              
                              
                                 j
                              
                           
                           
                              
                                 (
                                 θ
                                 )
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                         for the image slice (definitions are illustrated in Fig. 2
                        ), which are used to convert the original image into a reduced binary image, I
                        
                           γ
                        . A different value of the threshold 
                           
                              
                                 θ
                              
                              
                                 ′
                              
                           
                        , will change the contour size, as shown in Fig. 2. While several contours may exist, to simplify the discussion, Fig. 2, shows one contour superimposed on the image slice m at time t
                        
                           n
                        .

Since each acquisition 
                           I
                           
                              
                                 (
                                 x
                                 )
                              
                              
                                 m
                                 ,
                                 n
                              
                           
                         (even within the same stack) can have a different mean pixel intensity and contrast, each 
                           
                              
                                 θ
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                         will have a different effect, producing a different contour γ
                        
                           j
                         on each (n,m). Each contour will depend upon the value of θ; a small change in 
                           
                              
                                 θ
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                         will produce a change in the contour given by 
                           
                              
                                 (
                                 ∂
                                 
                                    
                                       γ
                                    
                                    
                                       j
                                    
                                 
                                 /
                                 ∂
                                 θ
                                 )
                              
                              
                                 (
                                 n
                                 ,
                                 m
                                 )
                              
                           
                        . In general, the mean pixel intensity will increase during the acquisition, resulting in a progressively brighter image due to photobleaching (because there is an accumulation of excited fluorescent atoms in the tissue volume that produces a larger fraction of de-excitation; increasing the overall light emission). This effect can be removed image in the post-processing stage using a histogram equalization process.


                        Fig. 3
                         shows 
                           (
                           ∂
                           
                              
                                 γ
                              
                              
                                 j
                              
                           
                           /
                           ∂
                           θ
                           )
                         and the dependency of the size (area) of the contour 
                           γ
                           (
                           θ
                           )
                         with different thresholds θ for a set of image slices processed with histogram normalization. Even from different datasets, the normalized area as a function of θ is approximately the same and has a constant gradient (i.e., 
                           
                              
                                 dA
                              
                              
                                 γ
                              
                           
                           /
                           d
                           θ
                           ≈
                           const
                        ). This simplifies the optimization procedure we use to determine the optimal parameter 
                           
                              
                                 θ
                              
                              
                                 n
                                 ,
                                 m
                              
                           
                        .

For aligning images, we use a pixel weighting given by the function 
                           w
                           (
                           x
                           )
                         
                        [57]. The relative linear displacement, 
                           Δ
                           u
                        , between two successive images, I
                        
                           t
                        and 
                           
                              
                                 I
                              
                              
                                 t
                                 +
                                 1
                              
                           
                        , is found by minimizing the cross correlation functional 
                           E
                         (Fig. 4
                        ):
                           
                              (1)
                              
                                 min
                                 (
                                 
                                    E
                                    [
                                    u
                                    ]
                                 
                                 )
                                 =
                                 min
                                 [
                                 
                                    ∑
                                    w
                                    (
                                    x
                                    )
                                    
                                       
                                          I
                                       
                                       
                                          t
                                       
                                    
                                    (
                                    x
                                    )
                                    −
                                    w
                                    (
                                    x
                                    −
                                    u
                                    )
                                    I
                                    (
                                    x
                                    −
                                    u
                                    )
                                 
                                 ]
                              
                           
                        
                     

In our algorithm, the pixel weights are those pixels bounded by the contours, 
                           
                              
                                 γ
                              
                              
                                 j
                              
                           
                           (
                           θ
                           )
                         on 
                           n
                           ,
                           m
                        . Practically, we obtain the contours and form a binarized image mask. Thus, the original image is replaced by its binarized version 
                           
                              
                                 I
                              
                              
                                 γ
                              
                           
                           =
                           G
                           (
                           ρ
                           (
                           x
                           )
                           I
                           (
                           x
                           )
                           )
                        . Then, the pixel weighted cross correlation function is given by
                           
                              (2)
                              
                                 
                                    
                                       E
                                    
                                    
                                       ˜
                                    
                                 
                                 [
                                 u
                                 ]
                                 =
                                 ∑
                                 
                                    
                                       I
                                    
                                    
                                       γ
                                    
                                 
                                 (
                                 x
                                 )
                                 −
                                 
                                    
                                       I
                                    
                                    
                                       γ
                                    
                                 
                                 (
                                 x
                                 −
                                 u
                                 )
                              
                           
                        The optimal displacement, 
                           Δ
                           
                              
                                 u
                              
                              
                                 ⁎
                              
                           
                        , is the one that minimizes 
                           
                              
                                 E
                              
                              
                                 ˜
                              
                           
                        .

Obtaining 
                           
                              
                                 E
                              
                              
                                 ˜
                              
                           
                         from Eq. (2) is equivalent to the convolution transform, which can be performed efficiently in Fourier space. Taking the Fourier transform, 
                           F
                           (
                           E
                           )
                        , the phase correlation between the two successive images is given by
                           
                              (3)
                              
                                 F
                                 [
                                 
                                    
                                       
                                          E
                                       
                                       
                                          ˜
                                       
                                    
                                    [
                                    u
                                    ]
                                 
                                 ]
                                 =
                                 F
                                 (
                                 
                                    
                                       I
                                    
                                    
                                       γ
                                    
                                 
                                 (
                                 x
                                 )
                                 )
                              
                           
                        
                     

The displacement 
                           Δ
                           u
                         is found by determining the location of the maximal correlation peak in the complex Fourier plane, given by the δ-function 
                           δ
                           (
                           x
                           +
                           Δ
                           x
                           ,
                           y
                           +
                           Δ
                           y
                           )
                        . Thus,
                           
                              (4)
                              
                                 Ψ
                                 =
                                 F
                                 (
                                 
                                    
                                       I
                                    
                                    
                                       ˜
                                    
                                 
                                 
                                    
                                       (
                                       x
                                       |
                                       θ
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                                 )
                                 ⁎
                                 F
                                 (
                                 
                                    
                                       I
                                    
                                    
                                       ˜
                                    
                                 
                                 
                                    
                                       (
                                       x
                                       |
                                       θ
                                       )
                                    
                                    
                                       
                                          
                                             t
                                          
                                          
                                             prime
                                          
                                       
                                       ,
                                       
                                          
                                             s
                                          
                                          
                                             ′
                                          
                                       
                                    
                                 
                                 )
                              
                           
                        
                        
                           
                              (5)
                              
                                 u
                                 (
                                 x
                                 +
                                 Δ
                                 x
                                 )
                                 =
                                 δ
                                 (
                                 x
                                 +
                                 Δ
                                 x
                                 ,
                                 y
                                 +
                                 Δ
                                 y
                                 )
                              
                           
                        
                        
                           
                              (6)
                              
                                 =
                                 
                                    
                                       max
                                    
                                    
                                       δ
                                       (
                                       Δ
                                       x
                                       )
                                    
                                 
                                 
                                    
                                       F
                                    
                                    
                                       −
                                       1
                                    
                                 
                                 {
                                 
                                    
                                       
                                          Ψ
                                       
                                       
                                          |
                                          Ψ
                                          |
                                       
                                    
                                 
                                 }
                              
                           
                        We then applying the set of vectors, 
                           Δ
                           u
                        , to all images in the image stacks for all cycles.

After aligning the images, we need a quantitative measure of the resulting stabilization. For this, we developed an ensemble sampling method that sums the correlated pixels between two images found from randomly distributed and coincident ROI (region of interest) patches. By summing ensemble contribution from these patches over all cycles, we obtain a probabilistic measure of the alignment process. In the following discussion, we formalize these ideas.

A detailed description of our ensemble metric is as follows. Consider a random distribution of image patches, 
                           
                              
                                 r
                              
                              
                                 j
                              
                           
                           (
                           x
                           ,
                           y
                           )
                        , with dimension (h,w) and centered on the point (x,y) coincident with two image I
                        1 and I
                        2, as shown in Fig. 5
                        . The similarity of two coincident patches, from I
                        1 and I
                        2 respectively, is found by enumerating similar pixels with a Gaussian membership function for the 
                           k
                         th patch, 
                           
                              
                                 r
                              
                              
                                 k
                              
                           
                           (
                           x
                           ,
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                           )
                           =
                           exp
                           [
                           
                              
                                 (
                                 x
                                 −
                                 
                                    
                                       x
                                    
                                    
                                       ′
                                    
                                 
                                 )
                              
                              
                                 2
                              
                           
                        , where 
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                         is from image I
                        1 and x from image I
                        2. If 
                           
                              
                                 r
                              
                              
                                 k
                              
                           
                           (
                           x
                           ,
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                           )
                           ≥
                           
                              
                                 t
                              
                              
                                 p
                              
                           
                         (i.e., t
                        
                           p
                         a pixel threshold), then the patch is considered aligned, otherwise the patch is misaligned. We define the overall pairwise alignment, 
                           R
                         as
                           
                              (7)
                              
                                 R
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       
                                          
                                             x
                                          
                                          
                                             ′
                                          
                                       
                                       ,
                                       x
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                    
                                 
                                 
                                    
                                       r
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       ′
                                    
                                 
                                 |
                                 x
                                 )
                              
                           
                        so that only aligned patches (i.e. 
                           
                              
                                 r
                              
                              
                                 k
                              
                           
                           (
                           x
                           ,
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                           )
                           ≥
                           
                              
                                 t
                              
                              
                                 p
                              
                           
                           )
                         contribute to the sum.

Because the metric depends upon a random distribution of samples, we refer to 
                           R
                         of Eq. (7) as the ensemble pixel overlap metric. This quantity is normalized to unity when the two compared images are identical and coincident. The spatial distribution of the aligned and misaligned patches define an ensemble pixel overlap distribution 
                           Q
                           (
                           x
                           )
                        .

As described, Fig. 2 shows the contour and threshold definitions involved in the pixel weighting alignment of z-stacks. For each image s in the z-stacks at time t, the threshold values are assigned that gives rise to a set of contours 
                           {
                           γ
                           }
                        , such that the initial set is: 
                           {
                           
                              
                                 
                                    θ
                                 
                                 
                                    t
                                    ,
                                    s
                                 
                              
                           
                           }
                           →
                           
                              
                                 γ
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                        . From each contour, we construct a binarized images I
                        
                           γ
                        , which are used for the pixel weights w in the registration algorithm. We define
                           
                              (8)
                              
                                 I
                                 
                                    
                                       (
                                       x
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                                 ⟶
                                 
                                    
                                       I
                                    
                                    
                                       γ
                                    
                                 
                                 
                                    
                                       (
                                       x
                                       ;
                                       θ
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                              
                           
                        
                     

With respect to the pixel weighted registration algorithm, nonlinear background tissue deformations (i.e., contractions, dilations, or shearing) produce unwanted bias that can degrade the final alignment. Thus, by determining these nonlinear deformation regions, we can remove the corresponding pixel weights that would otherwise contribute erroneously. For this, we define the nonlinear background tissue model, ρ, which we subtract from the binarized image I
                        
                           γ
                         of Eq. (8). Thus, the modified image is given as
                           
                              (9)
                              
                                 
                                    
                                       I
                                    
                                    
                                       ˜
                                    
                                 
                                 
                                    
                                       (
                                       x
                                       |
                                       θ
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                                 =
                                 ρ
                                 
                                    
                                       I
                                    
                                    
                                       γ
                                    
                                 
                                 
                                    
                                       (
                                       x
                                       ;
                                       θ
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                              
                           
                        where ρ is defined for each image in the z-stacks. We obtain the ρ regions with a data-driven iterative procedure, described below and in Fig. 6
                        .

Deformed regions could be determined by calculating the diffeomorphic integral transform between the two images. In this way, the kernel of the integral defines the precise map required to warp one image into the other. Nonetheless, after obtaining the map 
                           M
                           (
                           x
                           ,
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                           )
                        , another calculation (involving 
                           ∇
                           M
                        ) would be required to identify the border of ρ. Apart from the implementation complexity, integral methods are computationally demanding, especially for the large number of images to be processed. Moreover, our method would not take advantage of the level of detail provided by diffeomorphic maps; we are only interested in determining nonlinear regions to subtract the corresponding pixel weights.

Instead of a full integral method, we developed a Monte Carlo re-sampling approach we call the Poor Man׳s Diffeomorphic Map (PMDM), which is easy to implement and computationally efficient. By successive resampling, we can determine the nonlinear distortion regions corresponding to the consistently misaligned areas. To find these areas, we used our ensemble pixel overlap metric developed in the previous section.


                        Fig. 7
                         shows the steps of the PMDM algorithm. The iterative procedure achieves the asymptotic value of ρ of Eq. (9) through successively updates. Thus, after the kth resampling step, further refinements have little effect; i.e., 
                           |
                           
                              
                                 ρ
                              
                              
                                 k
                              
                           
                           −
                           
                              
                                 ρ
                              
                              
                                 k
                                 −
                                 1
                              
                           
                           |
                           <
                           ϵ
                        . In particular, at the iteration step k, we find the displacement vector 
                           u
                           (
                           Δ
                           x
                           )
                         using the model 
                           
                              
                                 ρ
                              
                              
                                 (
                                 k
                                 −
                                 1
                                 )
                              
                           
                         and proceed to align the images. To find the new updated model at step k, we choose a set of random distribution of ROIs and calculate the ensemble pixel overlap metric. Formally, this is given by a stochastic integral
                           
                              (10)
                              
                                 
                                    
                                       ρ
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                                 =
                                 ∫
                                 R
                                 
                                    
                                       (
                                       
                                          
                                             u
                                          
                                          
                                             (
                                             k
                                             −
                                             1
                                             )
                                          
                                       
                                       ;
                                       x
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             ′
                                          
                                       
                                       )
                                    
                                    
                                       t
                                       ,
                                       s
                                    
                                 
                                 d
                                 
                                    
                                       x
                                    
                                    
                                       ′
                                    
                                 
                              
                           
                        where the kernel 
                           R
                         expresses the fact that we are comparing 
                           x
                         and 
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                        , given the displacement 
                           u
                           (
                           Δ
                           x
                           )
                         from the values of 
                           (
                           k
                           −
                           1
                           )
                         th model. With this procedure, we obtain the ρ
                        
                           k
                         contour regions, as shown in Fig. 7. The iteration terminates when successive updates do not produce appreciable changes in the ρ
                        
                           k
                         regions. A stopping condition is obtained as follows: we sum the area of annular regions between the solution of ρ at k and 
                           (
                           k
                           −
                           1
                           )
                        , forming the quantity:
                           
                              (11)
                              
                                 H
                                 (
                                 ρ
                                 )
                                 =
                                 ∑
                                 |
                                 
                                    
                                       A
                                    
                                    
                                       ρ
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                                 −
                                 
                                    
                                       A
                                    
                                    
                                       ρ
                                    
                                    
                                       (
                                       k
                                       −
                                       1
                                       )
                                    
                                 
                                 
                                    
                                       |
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        Thus, the asymptotic limit for ρ
                        
                           k
                         is when 
                           H
                           (
                           ρ
                           )
                           <
                           ϵ
                        , for some arbitrarily small ϵ.


                        Fig. 8
                         shows an example of a slice analyzed with the PMDM algorithm in order to illustrate the meaning of the quantities in the method. In particular, Fig. 8a is the image 
                           
                              
                                 I
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                           (
                           x
                           )
                         at time t. The original image is converted to its binarized form, 
                           
                              
                                 I
                              
                              
                                 γ
                              
                              
                                 (
                                 t
                                 ,
                                 s
                                 )
                              
                           
                         (Fig. 8b) by applying a threshold value, 
                           
                              
                                 θ
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                        . The Monte Carlo (or resampling) step allows us to determine the asymptotic value of the background model 
                           
                              
                                 ρ
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                         (Fig. 8c), which we use to subtract the pixels contained in ρ from 
                           
                              
                                 I
                              
                              
                                 γ
                              
                              
                                 (
                                 t
                                 ,
                                 s
                                 )
                              
                           
                        . Thus, the final pixel weights used in the registration algorithm are defined by the binarized image mask 
                           
                              
                                 
                                    
                                       I
                                    
                                    
                                       ˜
                                    
                                 
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                           =
                           
                              
                                 ρ
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                           
                              
                                 I
                              
                              
                                 γ
                              
                              
                                 (
                                 t
                                 ,
                                 s
                                 )
                              
                           
                         (Fig. 8d).

The nonlinear deformation regions obtained from our resampling method reveal two types of nonlinear tissue movements: compression and stretching. These two orthogonal modes can be distinguished by their characteristic spatial distributions and be used to define a degree of nonlinearity metric. In this way, we can compare the stabilization results obtained from different datasets having varying amount of nonlinear deformations.


                        Fig. 9
                         shows an example of the background tissue undergoing compression. In this case, a periodic crease, or pinch, is formed in the aligned pixel overlap distribution, 
                           Q
                           (
                           x
                           )
                        , characterized by a conserved aligned zone, with two misaligned lobes. As a result of this pinch distribution, 
                           ρ
                           (
                           x
                           )
                         is approximately bimodal. In this particular case, when the tissue relaxes to its uncompressed state, there is less (or no) nonlinearity, and the distribution of 
                           ρ
                           (
                           x
                           )
                         is sparse and random.

A different situation is seen in Fig. 10
                        , where the tissue undergoes stretching. In this case, the distribution of 
                           ρ
                           (
                           x
                           )
                         oscillates between very large single regions of nonlinearity, to the unstretched state, where the distribution of 
                           ρ
                           (
                           x
                           )
                         is sparse and random.


                        Fig. 11
                         illustrates these ideas from different planar cuts of the distributions 
                           Q
                           (
                           x
                           )
                         from images representative of the two deformation modes (i.e., compression and stretching). The degree of nonlinear deformation metric, ϕ, is defined by taking distribution moments of 
                           ρ
                           (
                           x
                           ;
                           t
                           )
                        . Thus, the nonlinearity is found by treating 
                           ρ
                           (
                           x
                           )
                         as a multivariate sample distribution and applying a standard normality test, such as the Anderson–Darling and Shapiro–Wilks tests (available in the python statistical modules scipy.stats.anderson or scipy.stats.shapiro). We also studied other relevant multivariate normality tests such as the Friedman–Rafsky [19] and Smith–Jain [52] techniques. In order to distinguish between the two types of distributions, we used Hartigan׳s Dip bimodality test [22,23]. This test quantifies how much a given distribution deviates from a unimodal distribution.

The procedure to obtain the degree of nonlinear deformation is as follows: (1) for each image stack at t, perform the multivariate normality test of the sample distribution 
                           
                              
                                 ρ
                              
                              
                                 t
                              
                           
                           (
                           x
                           )
                        , (2) select the time t
                        ⁎ when ρ is maximum, and (3) finally, integrate the distribution to obtain the entire area and normalize by the total area in the image: 
                           ϕ
                           (
                           
                              
                                 t
                              
                              
                                 ⁎
                              
                           
                           )
                           =
                           ∫
                           ρ
                           (
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                           ;
                           
                              
                                 t
                              
                              
                                 ⁎
                              
                           
                           )
                           d
                           
                              
                                 x
                              
                              
                                 ′
                              
                           
                        . We can further distinguish the degree of nonlinearity depending upon the type of deformation from tests of the distribution described above.

A globally stable solution is one with a minimum cumulative root mean square misalignment error, measured from images in each stack and over the entire video timeline. The heuristic for our globally consistent alignment algorithm is to favor time averaged stability as opposed to absolute pairwise stability between subsequent stacks.

Our pixel weighted contour algorithm can be optimized by tuning the pixel intensity thresholds 
                           {
                           
                              
                                 θ
                              
                              
                                 t
                                 ,
                                 s
                              
                           
                           }
                         that control the size of the contour regions. If these thresholds are free parameters, then the optimization problem is large, rendering any brute force intractable. For example, for a dataset with 60 cycles and six discrete threshold values, the number of combinations that must be tested is 
                           
                              
                                 6
                              
                              
                                 60
                              
                           
                           ≈
                           
                              
                                 10
                              
                              
                                 46
                              
                           
                        . Thus, we implemented a Simulated Annealing [29] constrained optimization method.

The steps of the constrained optimization algorithm are shown in Fig. 12
                        (a), using definition of quantities described previously. The algorithm searches the solution space for optimal thresholds 
                           {
                           
                              
                                 θ
                              
                              
                                 n
                              
                           
                           }
                         at each iteration step n, such that the global alignment is maximum. The condition is met by minimizing the objective function, 
                           L
                           (
                           
                              
                                 θ
                              
                              
                                 n
                              
                              
                                 (
                                 t
                                 ,
                                 s
                                 )
                              
                           
                           )
                        . For this, we seek a solution so that 
                           |
                           L
                           (
                           
                              
                                 θ
                              
                              
                                 n
                              
                              
                                 (
                                 t
                                 ,
                                 s
                                 )
                              
                           
                           )
                           −
                           L
                           (
                           
                              
                                 θ
                              
                              
                                 
                                    
                                       ⁎
                                    
                                    
                                       n
                                    
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                 
                              
                           
                           )
                           |
                           <
                           ϵ
                         A general update step for the nth iteration 
                           
                              
                                 θ
                              
                              
                                 n
                              
                           
                           −
                           
                              
                                 θ
                              
                              
                                 n
                                 −
                                 1
                              
                           
                         is given by
                           
                              (12)
                              
                                 
                                    
                                       θ
                                    
                                    
                                       n
                                    
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                 
                                 =
                                 G
                                 (
                                 
                                    
                                       θ
                                    
                                    
                                       n
                                       −
                                       1
                                    
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                 
                                 )
                              
                           
                        where the function G is a model that depends upon the free parameters of the problem.

An expression for H can be obtained intuitively: a globally stable solution would be the one such that on a particular slice, the contour areas are approximately conserved throughout time, consistent with the ideas of stable anchors. We can define the average area of the all contours for each slice s at the nth iteration of our optimization algorithm:
                           
                              (13)
                              
                                 
                                    
                                       
                                          
                                             A
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    
                                       γ
                                    
                                    
                                       (
                                       n
                                       )
                                    
                                 
                                 (
                                 s
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       M
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       t
                                       =
                                       0
                                    
                                    
                                       M
                                    
                                 
                                 
                                    
                                       A
                                    
                                    
                                       γ
                                    
                                 
                                 
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                    
                                       (
                                       n
                                       )
                                    
                                 
                              
                           
                        where we shall suppress writing the slice s, and the total number of slices is M.

The optimization algorithm chooses 
                           {
                           
                              
                                 θ
                              
                              
                                 t
                              
                           
                           }
                         that conserves the mean area 
                           
                              
                                 
                                    
                                       A
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 γ
                              
                              
                                 (
                                 n
                                 )
                              
                           
                           (
                           s
                           )
                         of Eq. (13). As shown in Fig. 12(b), the contours 
                           {
                           
                              
                                 γ
                              
                              
                                 t
                              
                           
                           }
                         of each image slice for all time cycles can be imagined as tracing out the surface of a membrane. In this way, the global stabilization constraint acts like the restoring surface tension of an elastic membrane, maintaining equilibrium throughout time through the update step. From this, we develop an intuitive expression for the update step.
                           
                              (14)
                              
                                 Δ
                                 
                                    
                                       A
                                    
                                    
                                       γ
                                    
                                 
                                 =
                                 
                                    
                                       A
                                    
                                    
                                       
                                          
                                             γ
                                          
                                          
                                             t
                                          
                                       
                                    
                                 
                                 −
                                 
                                    
                                       
                                          
                                             A
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    
                                       γ
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             dA
                                          
                                          
                                             γ
                                          
                                       
                                    
                                    
                                       d
                                       
                                          
                                             θ
                                          
                                          
                                             t
                                          
                                       
                                    
                                 
                                 Δ
                                 θ
                              
                           
                        where 
                           d
                           θ
                           /
                           d
                           γ
                        , expresses how a change in θ can affect the size of the area of the contour. Also, 
                           Δ
                           θ
                           =
                           
                              
                                 θ
                              
                              
                                 t
                              
                              
                                 (
                                 n
                                 +
                                 1
                                 )
                              
                           
                           −
                           
                              
                                 θ
                              
                              
                                 t
                              
                              
                                 n
                              
                           
                        . The update step is
                           
                              (15)
                              
                                 
                                    
                                       θ
                                    
                                    
                                       n
                                    
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                 
                                 =
                                 −
                                 α
                                 
                                    
                                       d
                                       θ
                                       /
                                       d
                                       γ
                                    
                                    
                                       
                                          
                                             T
                                          
                                          
                                             n
                                          
                                       
                                    
                                 
                                 Δ
                                 
                                    
                                       A
                                    
                                    
                                       γ
                                    
                                 
                                 +
                                 
                                    
                                       θ
                                    
                                    
                                       n
                                       −
                                       1
                                    
                                    
                                       (
                                       t
                                       ,
                                       s
                                       )
                                    
                                 
                              
                           
                        where T
                        
                           n
                         is the simulated annealing control parameter. This is accomplished through the function G of Eq. (12), by varying values of θ and using the control parameter T to reduce the search space once a local minimum is found.

The time scale difference between endogenous tissue movement and the time to acquire microscopy images can lead to multiple exposed objects, or ghosts; one cell could appear in several different z-planes of an image stack. Fig. 13
                         illustrates how undersampling in the presence of tissue movement could gives rise to the multiple exposures. In practice, these multiple exposed images are removed in tedious manual process. Our stabilization method identifies and remove these ghosts images.

To remove the ghost images, we define a normalized metric ρ that measures the similarity between pairs of z slices on the same z-stack by using a pixel overlap criteria. The ghost removal algorithm is as follows: (1) set the an image index j=1 to the top image of the stack, I
                        
                           j
                        , (2) perform pairwise similarity comparisons with all subsequent images in the stack 
                           
                              
                                 I
                              
                              
                                 k
                                 ≠
                                 j
                              
                           
                        ; if ρ is close to unity, the images are the same and the bottom-most image is removed. Finally, (3) the image index is incremented 
                           j
                           =
                           j
                           +
                           1
                         and the process is repeated until all pairs with 
                           k
                           >
                           j
                         are processed.

We implemented our stabilization algorithms in python, creating a graphical interface driven application called StabiTissue. This software is freely available with an open source license, at the public repository (http://sourceforge.net/projects/stabitissue/). The graphical user interface (GUI) was written in PyQt and provides tools for manipulating image stacks and selecting final output. Low level image operations utilize the OpenCV [9] library, while the microscopy formats are aided with the Bio-Formats library [56], used to read which provides support for most microscopy image formats. A set of custom script provide basic image support to free the user from utility tasks. Examples of some of the principal windows from the application are shown in Fig. 14
                     . Also, a brief demonstration video is provided in Supplementary Materials 1 that shows the interface and some of the functionality of our software.


                        Table 1
                         shows a comparison of our software and other open source platforms and libraries with respect to relevant features required for linear and nonlinear registration. We found that only specialized ImageJ and Fiji plugins provide a turnkey solution to stabilizing 3D stack images over time similar to our software. All other open-source software solutions that we evaluated were either frameworks or libraries, that would require software development (either with code extensions or with plugins) to stabilize a set of images.

Apart from the brief set of characteristics of each software system/library that we evaluated (Table 1), the following are short descriptions of each system:
                           
                              •
                              
                                 ImageJ 
                                 [51] is a general purpose software for analysis of microscopy images. An ImageJ plugin for stabilization [33] provides the closest direct comparison to our software. This plugin uses a Lucas–Kanade algorithm for aligning images. We compared our software to this the results of this software are in the next section.


                                 TurboReg 
                                 [60] is an ImageJ plugin that performs image alignment with a pyramid algorithm. This software is similar to the ImageJ plugin of [33].


                                 Fiji 
                                 [50] is a separate development branch of ImageJ and provides general purpose analysis of microscopy images. New plugins contain elastic volume reconstruction [48] with diffeomorphic warping of images for registration. To use this software for stabilization, we would still need to extract the iso-contours of the nonlinear registration maps to exclude pixels from registration weights.


                                 OpenSPIM 
                                 [45,21] is an open-source integrated microscopy platform that includes specialized hardware and control software. Stabilization is performed with a bead tracking system.


                                 Elastix 
                                 [30] is a nonlinear registration library that performs diffeomorphic transforms. This library is an interesting candidate to use instead of our PDMD. Nonetheless, for each image pair, we would require costly computations for deriving the full diffeomorphic map, and then determining maximal nonlinearity iso-contours that define the pixels to be excluded from the pixel overlap alignment.


                                 Omero 
                                 [1] from the OpenMicroscopy project. This is a full client/server microscopy system with anlaysis applications and possibility for plugin extensions. At present there are no stabilization algorithms that can be directly used.


                                 BioImageXD 
                                 [27] is a pure-python based general purpose software for analysis of microscopy images. It contains algorithms for linear/nonlinear registration, but no direct application exists for stabilizing images over many cycles between stacks.


                                 ITK 
                                 [38] National Library of Medicine Insight Segmentation and Registration Toolkit (ITK). This is a cross platform system that provides library routines for image analysis of microscopy images. It contains several registration routines. Stabilization would require a separate development.

@&#RESULTS@&#

We tested our software with different datasets from different organs and against another open-source software that performs stabilization. The datasets used to test our algorithms were taken from two separate studies [58]: in vivo studies of the blood flow through the vascular structure of the placenta [65] and the uterus [66]. The two datasets are representative of linear and nonlinear stabilization problems that would be encountered with in vivo imaging of any other organ. These datasets were extra image acquisitions taken during the experiments, not included in our previously published work, cited above.

For the experiments, we used CD11c-YFP transgenic [35] and C57Bl/10.PL animals. We also used Foxp3-GFP-Knock-in (KIgfp) mice [8] to evaluate biological questions of Treg motility. These animals have normal amounts of Tregs and they express GFP inside the cytoplasm of the Foxp3+ cells. All animals were produced in Instituto Gulbenkian de Ciencia animal facility, backcrossed to B10.PL background and used after they reach 6 weeks old. Further details of the experimental procedures and animal preparation we used for in vivo microscopy imaging can be found in [58,43,42,65,66].

We acquired sequential images of the placenta and uterine structures with a Zeiss Stereo Lumar stereoscope (Zeiss, Inc., Chester, VA, USA), in an Apo Lumar S1.29 FWD 47-mm objective. We used a two-photon microscope consisting of a Chameleon Ti:Sapphire laser (Coherent, Inc., Santa Clara, CA, USA), four photomultiplier tubes (PMT) to determine four channel simultaneous color channels, and a water immersion objective (Olympus Inc., Center Valley, PA, USA). We provide details of the optical configuration and laser excitation wavelengths in [58,65,66], used to reveal specific biological questions of interest.

Sequential images of a 
                        50
                        
                        μ
                        m
                     -depth tissue volume, divided into 4.0μm z-steps constituting the 5D (
                        x
                        ,
                        y
                        ,
                        z
                        ,
                        t
                     , and color), were acquired to allow observation of iRBC-GFP inside placental blood vessels. Each acquisition volume took approximately 30s to be scanned by the laser microscope.

For nonlinear tissue, we applied our PDMD algorithm under different situations. Fig. 15
                        (a) and (b) shows the results of our stabilization algorithm having different degrees of nonlinearity. As can be seen, applying the nonlinear correction improves the results. Fig. 15(c) shows comparisons of the normalized cumulative pixel alignment 
                           〈
                           R
                           〉
                         for three datasets with different degrees of nonlinearity, for the stabilization with/without the nonlinear PMDM background correction. As can be seen, for modest values of nonlinearity, the correction is similar to the linear case, while for datasets with more nonlinear deformations, the correction improves the overall stabilization by approximately 10%.

We compared the performance of our algorithm against the ImageJ stabilization plugin for datasets acquired from of two different organs (i.e., the placenta and the uterus) using IV-2pM. Cases were chosen possessing large movements, z-stack motion, and nonlinear movements to show the effectiveness of our software. Using these same datasets, we also compared the performance of the algorithms in the presence of artificially injected speckle-like noise.


                        Figs. 16
                         (left) and 17
                         (left) show the percentage overlap pixel error vs. time for datasets of the placenta and the uterus, respectively. The top left plots (of Figs. 16 and 17) show comparisons between our software (StabiTissue) and ImageJ by measuring the pixel overlap after stabilization (using our metric defined in Methods). The error is defined as the sum of all non-coincident ROIs. The bottom-left plots (of Figs. 16 and 17) show selected slices at different timepoints, where the sampled ROIs indicate error (red) or coincidence (green). Videos of these sequences can be found in the Supplementary Materials.

Speckle noise is random granular noise due to the interference of coherent laser light from surfaces (in this case biological tissue). Because the noise is disjoint, the contour sizes are unconnected and small. Since we impose a minimum contour size threshold, our pixel contour registration algorithm is less subject to the deleterious effects of speckle-like noise.


                        Comparison with speckle-like noise: To compare our algorithm between datasets with/without noise and with another software method, such as ImageJ, we artificially introduced random granular noise (similar to speckle noise). In this way, we could determine if the performance is degraded in the presence of random noise. Figs. 16 (right) and 17 (right) show the percentage overlap pixel error vs. time for datasets of the placenta and the uterus, respectively, but with artificial noise injected in each image for all image stacks throughout the acquisition time. The bottom-right plots (of Figs. 16 and 17) show selected slices at different timepoints, where the sampled ROIs indicate error (red) or coincidence (green). As before, videos of the stabilization of these datasets are provided in the Supplementary Materials.

The results show that the StabiTissue software outperforms the results of the ImageJ stabilization plugin both with and without noise in these datasets. In the results without noise, the datasets are dominated by 
                           z
                        -plane motion and nonlinear movements. Our algorithm treats both types of motion, while the stabilization in the ImageJ stabilization plugin only aligns images across the same 
                           z
                        -planes and makes no special provision for the nonlinear tissue movements; the result is poorer stabilization performance throughout the timeline.

An important area of in vivo imaging is observing cell motility in their natural habitats. To demonstrate the utility of our software tool, we processed IV-2pM image datasets to extract the motility of regulatory T lymphocytes (Tregs) in the uterus of mice. For example, by having accurate Treg motility information, relevant biological questions can be addressed concerning the activation and/or suppression role of Tregs [14] during pregnancy.

However, the IV-2pM of the uterus can contain endogenous background tissue motion that degrade the quality of the cell tracking. We applied our stabilization algorithm to subtract the background motion from the cell trajectories, obtained with a cell tracking software. Fig. 18
                         shows an example result of the cell motility before and after the application of our stabilization algorithm.

@&#DISCUSSION AND CONCLUSIONS@&#

Ideally, a stabilization algorithm registers each frame of an image sequence using well-defined anatomic landmarks, which remain constant over the entire image set. Many examples exist among other biomedical imaging (e.g., CT and MRI) where image registration of anatomical structures (e.g., cranial images, thorax) is guided by well defined landmarks. In general, however, IV-2pM datasets lack such predefined anchor structures. Instead, a potential landmark may be a blood vessel, or other soft vessel, which is neither fixed, nor maintains an exact shape over time. Therefore, the registration algorithm must handle this type of anchor that only approximates an ideal fixed shape over the entire image sequence. Moreover, IV-2pM images are dominated by speckle noise, rendering them poor candidates for feature-based registration methods, such as SIFT (scale invariant feature transform
                     [37]), that tend to work well in situations with rigid objects and sharp edges. Here we described a set of algorithms and a software to treat each of the problems described above, foremost a pixel weighting alignment method that corrects for nonlinear deformations.

Throughout this paper, we described several advantages of our algorithm and showed these ideas with real datasets. First, our method stabilizes the full 3D stack, aligning images within and across stacks; other software solutions we tested stabilize only across the same slice plane. Next, we correct our linear stabilization algorithm against nonlinear deformations that could bias the results by subtracting their contributions from the alignment weights. The final solution still remains a linear translation, only it is not biased by the nonlinear distortions. To determine the nonlinear background deformations in each image slice along time, we use a data-driven iterative procedure. We also described a global optimization procedure that constrains the displacements of images in a time averaged manner. Finally, since our algorithm is not based upon keypoint features, it is more immune to noise.

As with any method, there are disadvantages that limit the performance of our algorithms. With respect to the pixel weighted alignment algorithm, despite the nonlinear corrections, it is still a linear transformation. Moreover, there is a complex relationship between the pixel threshold and the number and size of contours. Selecting the proper pixel and contour size thresholds that will yield acceptable stabilization results is still an art. Because these internal free parameters are central to the method, these limitations are difficult to remediate without resorting to trial and error or a computationally demanding optimization procedure.

With respect to the nonlinear soft tissue movements, the intention of our PDMD algorithm was to remove unwanted bias from the pixel weights originating from regions undergoing nonlinear deformations, while retaining a linear stabilization. The reason we maintained the linear stabilization is to correct cell tracking trajectories from tissue movement with respect to the global coordinate system. While the PDMD correction does improve the stabilization, it does not explicitly address the nonlinear deformations. A future direction for this work shall investigate the diffeomorphic mappings between image of the 3D stacks and subsequently the appropriate affine transforms that can flatten the deformed regions.

Finally, our implementation as a stand-alone application provides an easy to use interface for the specific problem of stabilization. Nonetheless, it is not a general purpose image analysis tool. For this reason, our algorithm could be more widely accepted if it were incorporated as a plugin into a popular general purpose microscopy analysis systems, such as ImageJ, Fiji or Omero. Another future direction for this work is to implement our algorithms within one of these more widely accepted platforms.

None declared.

Supplementary data associated with this paper can be found in the online version at doi:10.1016/j.compbiomed.2015.07.001.


                     
                        
                           Video 1
                           
                              Video demonstration of the StabiTissue application. The StabiTissue program is a multiplatform application that was developed in Python using the Qt framework. The following tasks are shown in the video: importing data, partial data selection, selecting a slice along the timeline, stabilization of a dataset, parameter tuning, and visualization of the stabilization along the Z-axis.
                           
                           
                        
                     
                     
                        
                           Video 2
                           
                              Stabilization of intravital placenta data. The video sequence shows a set of sequential intravital images of the placenta obtained using a microscopy system consisting of the following: a stereoscope Zeiss Lumar Stereo (Zeiss, Inc., Chester, VA, USA) with an Apo Lumar S1.29 FWD 47-mm objective, a Chameleon Ti:Sapphire laser (Coherent, Inc., Santa Clara, CA, USA) used in conjunction with four photomultiplier tubes (PMT) for separate monitoring of the color channels, and a water immersion objective (Olympus Inc., Center Valley, PA, USA). Images were acquired with a tissue volume having a 50μ depth, divided into 4.0μ z-steps (60 cycles, 3 channels). Further details of the experimental procedures and animal preparation for in vivo imaging microscopy can be found in [?,?,?,?,?]. The first part of the video shows the original data stabilized and unstabilized, while the second part of the video shows the same data ”cropped” to the maximum viewable area over all time points time. The last part of the video shows a screenshot of StabiTissue stabilization results along the Z-axis for all time cycles.
                           
                           
                        
                     
                     
                        
                           Video 3
                           
                              Stabilization of intravital data from the uterus. Sequential intravital images of the uterus obtained using a microscopy system consisting of the following: a stereoscope Zeiss Lumar Stereo (Zeiss, Inc., Chester, VA, USA) with an Apo Lumar S1.29 FWD 47-mm objective, a Chameleon Ti:Sapphire laser (Coherent, Inc., Santa Clara, CA, USA) used in conjunction with four photomultiplier tubes (PMT) for separate monitoring of the color channels, and a water immersion objective (Olympus Inc., Center Valley, PA, USA). Images were acquired with a tissue volume having a 50μ depth, divided into 4.0μ z-steps (60 cycles, 3 channels). Further details of the experimental procedures and animal preparation for in vivo imaging microscopy can be found in [?,?,?,?,?]. The first part of the video shows the original data stabilized and unstabilized, while the second part of the video shows the same data “cropped” to the maximum viewable area over all time points time. The last part of the video shows a screenshot of StabiTissue stabilization results along the Z-axis for all time cycles.
                           
                           
                        
                     
                  

@&#REFERENCES@&#


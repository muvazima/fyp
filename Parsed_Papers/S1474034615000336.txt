@&#MAIN-TITLE@&#Status quo and open challenges in vision-based sensing and tracking of temporary resources on infrastructure construction sites

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Potential impact of data collection and processing in construction is highlighted.


                        
                        
                           
                           Benefits and current limitations of vision-based sensors is explained.


                        
                        
                           
                           Vision-based sensing framework from raw data to information to knowledge presented.


                        
                        
                           
                           Various applications of vision-based resource detection and tracking are shown.


                        
                        
                           
                           Challenges in academic research and development environment are identified.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Building information modeling

Computer vision and machine learning

Resource location tracking and progress monitoring

Safety and health

Sensors: photo and video cameras, unmanned aerial vehicles

Surveying: laser scanning, photo- and videogrammetry

@&#ABSTRACT@&#


               
               
                  Modern construction projects require sufficient planning and management of resources to become successful. Core issues are tasks that deal with maintaining the schedule, such as procuring materials, guaranteeing the supply chain, controlling the work status, and monitoring safety and quality. Timely feedback of project status aids project management by providing accurate percentages of task completions and appropriately allocating resources (workforce, equipment, material) to coordinate the next work packages. However, current methods for measuring project status or progress, especially on large infrastructure projects, are mostly based on manual assessments. Recent academic research and commercial development has focused on semi- or fully-automated approaches to collect and process images of evolving worksites. Preliminary results are promising and show capturing, analyzing, and documenting construction progress and linking to information models is possible. This article presents first an overview to vision-based sensing technology available for temporary resource tracking at infrastructure construction sites. Second, it provides the status quo of research applications by highlighting exemplary case. Third, a discussion follows on existing advantages and current limitations of vision based sensing and tracking. Open challenges that need to be addressed in future research efforts conclude this paper.
               
            

@&#INTRODUCTION@&#

In a broader sense, temporary construction resources (personnel, equipment, and materials) “aid the construction process by delivering man- or machine power, and the required material components to assemble or build a structure” [1]. Temporary structures (e.g., scaffolding, formwork, shoring systems) can also be defined as “any structure that assists the creation of a permanent part of a construction project” [2]. Their impact in construction is high as they are frequently used on most projects, impact safety, quality, speed, and profitability of construction, but are also a major cause of spatial conflicts and many disasters [1]. An industry-led study [3] on leading industry practices for estimating, controlling, and managing indirect construction costs identified project management, field supervision, material handling and scaffolding as the top most challenging and wasteful tasks in construction of large capital facilities and infrastructure. Subsequently, the topic deserves attention in research and development, i.e. using technological methods to advance the field of practice.

Construction sites associated to capital intensive infrastructure projects involve significant quantities of resources, including multiple levels of manpower, equipment, and materials. Proper coordination of these temporary entities positively impacts on-site productivity, which in turn influences construction safety, costs, and schedule [4–6]. However, leading industry practices in estimating, control, and management are based on frequent manual observations and often still rely on text-based, labor-intensive, time-consuming, inefficient documentation and reporting methods [2]. As such, the task of measuring the progress of construction site activities has often been a subjective and intensive manual process that is prone to error and, in real operations, frequently out-of-date [13].

Camera- or video-based monitoring technology in combination with processing algorithms typically provide a non-intrusive, easy, inexpensive, and rapid mechanism for generating a body of operational information and knowledge which, when made publicly available to project stakeholders, enable secure inquiry into construction operations that is currently not possible [12]. Longer term, vision-based research can serve as a valuable aid to project management by enabling tighter control and greater efficiency.

Demonstrating that an active vision system can effectively analyze and assess work-site progress will assist project managers by reducing the time spent monitoring and interpreting project status and performance, thus enabling increased attention to control of cost and schedule. By making project management and workforce more aware of the performance status of their project and their work environment, potential savings to the industry are envisioned by researchers and developers. Since benefits in construction often advance a broader theme of issues, they are likely to impact schedule, cost, safety, and quality at the same time.

Recent research efforts in this area seek to prove the hypothesis that it is possible to reliably track multiple resources with images (video, still and/or time-lapse) in order to reproduce the daily workflow of activities associated to a worksite. The main purpose behind the research is to understand the temporal and spatial nature of critical work packages on a worksite. The intent behind such monitoring and analysis is to automatically provide critical information on construction operations for improved decision making in construction engineering and management [6].

The information obtained from such desired semi- or fully-automated systems generates knowledge about worksite operations. In an information-based framework, much effort is spent acquiring and interpreting information. In a knowledge-based framework, efforts are allocated to making decisions based on the interpreted information. If successful, computer-vision based methods will transform the review of construction operations from being information-based to knowledge-based, thus saving human resources and improving decision effectiveness [7]. Given that current research seeks to demonstrate and validate reliable localization of construction resources (personnel, equipment, and materials), accompanying concepts reviewed within the scope of this article consist of two major components: (1) the derivation of algorithms suited to tracking temporary resources; and (2) the validation and analysis of the algorithm outputs with regards to pre-determined activities or work packages.

For the first research component (algorithms), research focuses on fusion of computer vision, machine learning, and methods derived for arriving at robust and adaptive tracking algorithms, which are directly suited for tracking the distinct classes of temporary worksite resources (personnel, heavy or mobile equipment, and temporary material aids, such as formwork, scaffolding) [8]. Heavy equipment and materials detection and tracking algorithms, for example, require investigation into classification and detector-based learning for classifying equipment and identifying bulk materials on the worksite.

For the second research component (validation and analysis), research proposes algorithms that are quantitatively compared against ground truth measurements obtained through alternative positioning technologies [9,10]. Existing and new photo or video data of actual construction site operations and work packages are annotated for validation of the algorithms and of the inferences produced from said algorithms. A review of existing academic research approaches verifies that the combination of vision-based tracking information with operational information modeling can provide knowledge about the state of operations of temporary resources on an infrastructure worksite [11].

@&#BACKGROUND@&#

The first goal of this paper is to provide a state-of-the-art synthesis review that lays the foundation for a scalable deployment of a vision-based sensing and tracking concept for site operations analysis and validation of temporary entities through field experiments. Fig. 1
                      shows the core focus within the context of site operations analysis and feedback. In essence, the project level information available for supporting progress tracking and resource utilization tracking, in conjunction with the data produced by other sensing modules, form the basis for vision-based sensing and tracking for site operations analysis. Typically, project level information exists before the start of construction, but is hardly tracked frequently and without error during the project execution phase. (Semi-) or automating the observation processes assisted through sensing technology, however, requires effective and robust algorithms than can process the data. Once outcome and processes are assessed, existing knowledge management and decision making and feedback processes can advance resource and time allocation, subsequently adding new project level information to decision makers.

As several case studies related to resource sensing and tracking will be explained in much further detail, technology is then integrated in the daily work flow in construction if it comes at acceptable cost (hardware installation, data storage and processing, and operation and maintenance). Although vision based sensing of site operations is applied on several thousand jobsites every day and the technology generally comes at low cost and yields high benefits [12,14], the complexity of handling large data sets has prevented significant progress. Field applications so far have mostly focused on recording site status and data archiving [14]. Little to no research has focused on sensing or tracking temporary resources needed for construction [15].

While a core sensing infrastructure may include a variety of existing sensors to track temporary resources in construction, fundamental work in vision-based research concentrates on the creation of algorithms for video and time-lapse image signals to perform site operation analysis. Following the concept architecture (see Fig. 1), updated project level information, i.e., schedule, computer-aided design (CAD) site layout plan, geographical information system (GIS), and building information models (BIM) form a base for progress evaluation. They can be geospatially linked to sensing data from resource tracking. This can be precisely interpreted by relating the spatial source of these data to an as-built model. These contain rich planning and execution information of the ongoing activities to be measured. Also, information on construction methods provides the ground for measuring detailed work hour utilization of a construction activity in addition to the total work hours consumed, resembling the connection between as-built model and progress tracking.

Progress and resource utilization tracking constitute two distinct components of productivity measurement. Specifically, progress tracking measures quantities installed while resource utilization tracking measures consumed work hours as well as the way by which such work hours were spent [4]. Current techniques for site operation analysis, as described by [5], focus on the monitoring of construction progress and the measurement of work task productivity, but are heavily based on manual efforts or are at best partially automated. Recent advances in the construction industry and applied research for sensing and tracking resources or the built environment have been focusing on the utilization of commercially existing technology, for example: Radio Frequency Identification (RFID) [15–17] and Ultra Wideband technology (UWB) [18–20], Global Positioning System (GPS) [21,22], laser scanning [23–26], range imaging [27,28], unmanned aerial vehicles [29,30]. Several case studies have demonstrated the successful application of these technologies in construction. To name a few that also contain some vision based sensing or tracking: defect detection [25,31–33], rapid 3D and 4D CAD modeling [34–36], progress monitoring [38–42], geo-referencing existing project level information [37,39,42], simulation [22,43], visualization [44,45], real-time resource tracking and data visualization [46–50], virtual design and augmented reality [45,51], and worker safety [52] and performance [53–55].

The applications of vision based sensing and tracking in construction vary widely based on the data that can be collected and processed (see Fig. 2
                        ). The timescale and value determine the selection and use of vision based monitoring technology. For example, site level project management may require only local, but detailed access to data while off-site employees may demand less frequent, high level visual overviews of a project’s status. As sensing technology becomes readily available, some project stakeholders likely require pan-tilt-zoom (PTZ) video cameras with small or large field-of-views (FOV), while others may find infrequent still photos from terrestrial time-lapse or airborne cameras more useful. As such, the specific infrastructure construction application sets a demand that drives the selection of data capturing technology, for example, type (terrestrial, air- or space borne, photo, video, or point cloud), frequency (real-time, near real-time, or less frequent) and size (wide or narrow FOV, few or multiple view angles).

One of the most economical ways to track progress automatically is by recording video or taking images. This approach is not new to construction. Diekman et al. [57], for example, used manual video recording and interpretation to successfully demonstrate non-value-adding worker and material paths for steel-assembly at height. Unfortunately, manual efforts that go into accurate recording and precise interpretation of the collected visual data can be very high, especially over long time periods. Automated methods would positively benefit this research area; however, the main challenge in vision-based approaches is precisely the automated extraction of progress information from extended time-lapse photographs or (see highlighted box in Fig. 1).

The increased need for and use of advanced sensors on the construction worksite, coupled with the massive amount of data collection associated with the sensors, a fortiori demands the use of automated or, minimally, semi-automated methods [58]. Otherwise it can easily overwhelm companies or individuals. Fig. 3
                         illustrates four dimensions of data: volume, velocity, variety, and value. Volume refers to the size of data, variety to the number of types of data, velocity to the speed of data gathering or processing, value to an information- or knowledge-based application in an enterprise. The challenge in large and complex infrastructure construction projects is that the expansion of all four properties is required, rather than focusing on volume alone. Instead, a true meaningful approach for project stakeholders exists when value is integrated through technology into the operation of construction processes.

The field of computer vision specifically deals with the collection, processing, and visualization of data associated with the three-dimensional world [60]. Depending on the sensor and intended data, a variety of techniques exist for successfully processing imagery and video [61–67]. General computer vision based framework architectures rely on three generic components: detection, tracking, and assessment. The detection component seeks to identify objects of interest in the FOV. To date, the principal methods involve background modeling, target modeling and matching, and machine learning based methods [62–69]. Once detected, tracking algorithms can then be applied to obtain an estimation of the motion of the target in space and time. For small, relatively consistent targets, non-rigid template-based methods are ideal. For larger, non-rigid, or variable targets, segmentation-based on feature-based tracking methods tend to work better [70–74]. The primary segmentation-based techniques are Bayesian segmentation, active contours, and graph-cuts [73–76]. In contrast to the non-rigid template-based methods, segmentation-based methods can provide bounding contours of the track objects, meaning that pose, intent, or other geometry-based assessments can be made regarding the track object [77,78]. Feature-based methods key on small image patches or regions of the target that have a unique signature relative to the local image content [79–81], then track these patches over time.

The aforementioned computer vision algorithms play an important role in persistent visual sensing systems and related systems. Current active visual sensor system research details spatial awareness of construction job site conditions [31,40,51], but focuses few times on accurate monitoring of construction environment dynamics (incl. temporary resources) such as labor, material, temporary structures, and equipment positions. Model-based 3D scene analysis tools are used to determine the best fit of the existing model with the imaged work project [39,82].

@&#SUMMARY@&#

What is lacking from this body of research, however, is long-term temporal tracking of temporary construction assets for the analysis of site operations and progress monitoring. While research in construction has focused on specific subsets of the overall procedure regarding automated or semi-automated operations analysis, both an architecture for generating more complete analysis of construction site operations through visual sensors, and the selection, validation, and verification of the appropriate computer vision algorithms are missing.

The objective of multiple research groups has been to automate the vision-based detection and tracking of worksite resources (personnel, equipment, tools, and as-built or bulk materials) and to tie the collected data to critical information and tasks associated to the work plan.

The characteristics of the recording equipment to be used, e.g. video, time-lapse and aerial photography, are known, which includes camera intrinsic and extrinsic parameters. Site characteristics of typical infrastructure construction operations vary widely. Many include initial ground clearing or demolition, site preparation operations, initial foundation work, and so on. Road or bridge infrastructure projects, for example, are sites with quite open areas and line-of-sight access. Waste or fresh water are projects that rely on underground pipelines, and sometimes include even larger underground storage tunnels or tanks. These are the conditions where it is typical to have heavy machinery working alongside personnel, or to see collections of bulk materials on the premises awaiting integration into an as-built structure.

Due to the limitations of line-of-sight visual sensors, this review does not cover interior work or other similar construction operations with massive occlusions arising from the built structure or dynamics of resources itself. It also does not seek to handle adverse visual conditions due to poor weather. Dirt, dust, and precipitation such as rain and snow are known to affect vision based sensors; however, the construction operations of interest may also typically halt under such circumstances.

The outlined path for automated real-time vision-based sensing and tracking of temporary construction resources can be achieved if research provides algorithms and validation that solve the following issues:
                           
                              1.
                              Prioritization of high pay-off application scenarios that justify the investment.

Algorithms for robust tracking of personnel (large numbers with identification preferably by trade).

Algorithms for tracking of construction equipment (e.g., heavy and mobile).

Algorithms for tracking temporary structures (e.g., scaffolding, formwork, shoring systems containers).

Algorithms for tracking bulk materials temporarily occupying site spaces (e.g., prefabricated concrete elements, lumber, steel).

Algorithms for tracking change in site layout (e.g., site access, temporary roads, laydown areas).

Algorithms for automated, preferably real-time analysis for moving from data, to information, to knowledge.

Validation of research approach using alternative sensing technologies as ground truth.

Knowledge dissemination and tracking of successful integration in project applications elsewhere.

The following section demonstrates already existing and successfully working applications of vision based sensing and tracking specifically of temporary resources in infrastructure construction environments. They show that research has already started addressing the aforementioned issues.

The list of topics that computer vision-based sensing and tracking of temporary construction resources might at some point in time solve is long. Table 1
                         lists several temporary resources that generally are present on construction sites. Few of them are currently part of research efforts or have successful commercial tracking processes in place. So far, vision based sensing and tracking has been focusing on the following main categories: construction personnel, large machinery, presence of containers, change in construction site layout and roads, lay down areas, supportive structures like fencing and guardrails [84,85].

Plenty applications exist that could benefit from semi- or fully-automated vision based sensing and tracking methods. The following therefore limits the scope to three important ‘temporary’ construction resources: (a) personnel, (b) equipment, and (c) bulk materials and structures. Each one of them is explained in more detail by describing some major research benefits and challenges.

As discussed earlier, preliminary research efforts have led to moderate success in tracking personnel on the construction site using (wide FOV) cameras. Due to the large intended visual footprint, they do not provide detailed information regarding sufficiently small track entities such as personnel. The low resolution of cameras might as well be a benefit as the identity of workers is protected in some countries [87]. In order to track small targets in such a large visual FOV, algorithms have to improve upon existing tracking algorithms. Figs. 4 and 5
                        
                         depict recent results on tracking individual workforce under such conditions [84–86]. The camera produced lower resolution images once it is applied from a far distance. Open problems that still need resolution and validation include long-term tracking of personnel, both as well-separated individuals and as multiple interacting personnel [50].

Long term tracking of objects Often requires modification of a given tracking algorithm. The primary cause is that the appearance model of an object may not remain consistent over time due to variable imaging conditions. While the derived algorithm is robust to moderate variation, it cannot handle large changes in model appearance. In order to be robust to such variation on a larger time scale, many existing algorithms are modified to adapt the target model over time based on the time history of the tracked target’s appearance [88]. One aspect to carefully consider is that these models indiscriminately update the model based on information contained within the track window, which may not be optimal, and can also lead to loss of track due to incorrect model updates.


                        Fig. 6
                         depicts scenes common on large infrastructure projects. Using a panning camera, early research used track signals generated from two separate algorithms, the mean-shift and Bayesian segmentation. Preliminary studies have shown that the Bayesian algorithm [7] provide a more accurate and smoother tracker signal than the mean-shift. Furthermore, being a segmentation-based method, it can adaptively re-sample the track object appearance model and therefore accommodate any time-varying elements associated with the appearance model.


                        Robust tracking of personnel interacting over a long term, e.g. assembling or disassembling temporary structures like scaffolding or formwork, can contribute to much needed task- and activity-level analysis. While a few personnel interacting over short time periods did not lead to track loss nor confusion, sustained interaction and occlusion of multiple personnel do cause problems. Especially if the personnel appearance models are similar, which is highly likely given the use of safety vests. Resolution of the problem requires either trajectory linking and Bayesian analysis [62] or a sufficiently robust filtering strategy [90].

An approach could be to adaptively monitor and update the measurement and prediction uncertainties associated to the tracked personnel. The concept will be amplified and accomplished for the case of multiple personnel. The same techniques proposed for adapting the target information can be used for identifying measurement uncertainty. In particular, density estimation techniques can be used to statistically compare the interacting personnel models to identify track confusion potential. The measurement uncertainty then is a function of the statistical overlap with neighboring personnel and background content, while the prediction uncertainty is a measure of the shifting foreground likelihoods estimated from the background model. The former influences the detector confidence measure, whereas the latter influences the tracker confidence measure. Fig. 6 shows preliminary examples of the author’s work for tracking multiple construction workers at the same time over an extended period of time.

The assessment or analysis of the visual scene can be performed by processing the tracked trajectory information, or through gross, non-specific methodologies, such as optical flow or image differencing. These latter methods identify changes in the visual scene given a video sequence. Methods for extracting trajectory information have been developed and applied to, for example, small groups, to large crowds [86,89]. Alternatively, a subfield within computer vision seeks to develop model-based algorithms for matching existing 3D models with digital photos of an object, or using multiple photos to reconstitute the 3D structure of the object [23,27,34,40,50].

Machines found on a construction worksite exist at many size scales relative to humans, from small (i.e., skid steer loaders), to medium (i.e., excavators), to large (i.e., pile drivers and cranes) (see also Table 1). Given the distinct dimensions and appearances of temporary entities, fundamentally different strategies can be utilized for tracking equipment. Nevertheless, the principal concepts regarding machine learning and density matching learned from personnel tracking can also serve to inform equipment tracking algorithms.


                        Tracking of equipment, e.g. cranes that lift temporary material during assembly or disassembly [91] or excavators and dump trucks that move earth for temporary shoring (see Figs. 7 and 8
                        
                        ) [50], requires temporal tracking of large objects (relative to the camera’s FOV). This is most effectively performed by tracking features associated to the temporary object and, when possible, by tracking regions of uniform appearance (i.e., segmentation-based tracking). Research considers joint feature-based and segmentation based algorithms for achieving the tracking of construction equipment. While it is currently possible to track a single piece of equipment, a major difficulty is that of occlusions when pieces of equipment are in close proximity or occlude each other, much as with personnel. The effect of self-occlusion on the feature tracking of construction equipment leads typically to feature loss. By maintaining the track of the segmentation, the correct features can be reestablished after the self-occlusion ceases. Similar results will hold when two machines occlude each other temporarily.

The kernel covariance tracker used in a case study that is illustrated in Fig. 7 is an improvement on the tracker proposed by [84]. Several improvements are made: (1) reduction of data before tracking and (2) introduction of a scale space search with upper limits and lower limits. The data reduction step saves memory and lowers the computational cost of tracking. The scale space search allows the tracker to handle changes in scale. While many research effort involve manual seeding to begin the tracking [7], to initialize this tracker, the target’s color and spatial information are learned through kernel principal component analysis (KPCA) with a Gaussian kernel. For every frame and each target, a gradient ascent procedure localizes the target by comparing the foreground image data with the targets’ learned model. Fig. 7 depicts the tracking results for a short segment of time. The three targets are outlined by a bounding box and their trajectories over time are depicted.

The activity status of equipment building temporary structures follows that of [50], where the machine activity is decomposed into static, moving, or within a region of interest. Each region of interest has specific meaning as derived from the probabilistic graph model of the potential activity states of each machine. An additional activity check is performed when an excavator and a dump truck are in close proximity. Then, much like in [92], the movement of the excavator in the proximity zone of a static dump truck establishes when an excavator begins filling a dump truck.

Event detection processors generate the statistics to determine the timespan and state the excavators and dumps are in. It uses the trajectory information from the tracker and the results from the activity status estimation to determine the activity. The computed results are: (a) how many dump trucks entered the scene, (b) how much time they spent in the FOV for loading, (c) how many bucket loads filled each dump truck, and (d) and how long the machines spent idle. Fig. 8 depicts some sample results to the construction of temporary shoring walls.

Classification of equipment is to reason about the machines detected and tracked on site. It is necessary to know the equipment class or type for connection to a work activity. Given the variety of equipment on construction sites, developing a one-size-fits-all classifier for identifying the type of equipment detected would be inefficient and inaccurate. Recent research on classification metrics and inter- versus intra-class determination provides critical clues as to how one should proceed [93–95]. Other approaches focused on vision-based equipment action recognition using support vector machine classifiers [92].

It is common for large infrastructure construction projects to contain pre-built materials or large volumes of bulk materials, as well as temporary materials, onsite for installation. The supply and depletion rate or visible existence of these materials provide time-stamped evidence regarding the state of construction activities, their location and occupancy of laydown areas, and trajectories used. Identifying and tracking temporary resource existence and/or volume over time will enable awareness of the completion rate associated to work packages. To successfully track the changing supply levels of bulk materials requires algorithms capable of detecting and segmenting these materials in sensed images. While detection algorithms are needed to identify the existence of these materials, segmentation algorithms are proposed to maintain track of the time-varying material supply.

Generating and maintaining a database for determination of bulk or temporary materials for detection and tracking is beyond the scope of many existing research projects, however, the generation of an algorithm for rapidly and automatically learning how to detect a given material from sample images is a feasible endeavor. The feasibility of such an approach is high by targeting a collection of progress relevant bulk materials (resources that are associated to work activities on the critical path) in an image library. Candidate materials include pre-fabricated rebar cages, concrete piles, steel girders, formwork, etc.; others can be assessed for viability also. The materials noted above directly relate to work packages in a Work Breakdown Structure (WBS). Although some materials previously were tracked using barcodes or RFID technology [16,96], visual information where these materials are temporarily stored on site or in a laydown yard would add additional confidence to task scheduling and reduce risk during the resource allocation process. More recently, vision based approaches in research have focused on tracking multiple pieces of equipment at the same time while tracking quantities of earthwork material or concrete placing [49,50,91,97]. Similar approaches can be used for specific temporary objects, for example, scaffolding, shoring panels, timber lagging walls [98].

Moving from detection to segmentation of materials many detection algorithms identify approximate regions where the target object or material is located, but do not pinpoint accurately the associated region [99]. At this point, if one desires a more accurate measurement of the region associated to the detected material, segmentation algorithms will be required, or at least geo-referenced in other, a priori available project level information (see Fig. 1). Fig. 9
                         shows preliminary results of tracking temporary material resources on a bridge and highway construction site using active contours. Active contours are a segmentation-based tracking algorithm, utilizing gradient-descent to minimize an image-matching energy functional. They require initialization, either by some detection method or by a human operator. In a first example, the temporary construction material to track was selected by hand, while the active contour algorithm automatically tracked the remaining frames.

In a second example using low resolution imagery, see Fig. 10
                        , preliminary results of tracking temporary safety equipment on the same highway construction site using active contours and geospatial referencing are shown. These can be useful aids in compliance checking, tracking, or documentation. In general, moving from a detection-based strategy to a segmentation-based strategy is not commonly done as the two methods are considered to be distinct. Note that 10 safety drums in the far distance of Fig. 10b were not detected probably due to distance and partial occlusions. Within the context of temporary safety equipment detection and tracking, however, once a material is detected, an accurate estimation of its bonding contour is possible to infer quantity, geometry, and potentially location.

Utilizing the characteristics of sensing technologies will enable the collection of productivity and safety data from site activities. Some can be more easily measured than others. Depending on the complexity level, the resources determine how critical they are to the overall project productivity and their connection to visually salient content. Each selected work site activity can also be assessed comparing the available project level and work task information (i.e., who performs, what task, how long, how many units) with the information that the effective and robust data processing algorithms generate. Often, technical limitations exist on the hardware end. Range cameras, for example, have shown early impact on safety and health research related to workers and equipment used in infrastructure construction (see Fig. 11
                        ), however, they have not been adopted widely due to the harsh construction environments and the technical boundaries of the sensing equipment [27,99].

Research performed on work space utilization is illustrated in Fig. 12
                         
                        [100]. It shows the feasibility of automatically monitoring construction site activities (here: workers disassembling temporary structures, e.g. formwork) fusing vision and GPS tracking technology and generating and visualizing the activity-based workspace of the workers in Building Information Modeling (BIM). Such data gathering and information modeling enabled a 4D simulation of activities in progress, where workspaces at selected time intervals were visualized and referenced to building elements in BIM. For example, building elements that were scheduled for construction are shown in blue in Fig. 12. The workspace occupied for stripping the formwork from one concrete column (in orange color) is illustrated using pink (50% of the workers’ time spent), green (75%), and yellow (100%) cubes. The percentage indicates the spatial–temporal relationship of occupied workspace and time required for both of the construction workers that completed the work task.

Several applications are possible, once tracking data of temporary resources becomes available in addition to already available geometric data of building elements. For example, the trajectory and space occupied by equipment could be gathered, analyzed, and modelled since it largely depends on the procured type and geometry of the lifting equipment. Fig. 13
                         shows the analysis once robust resource location tracking is performed long-term. Statistics to a loader are presented (idle, moving, working) although a semi-automated signal processing approach was chosen. Data analysis can then focus on value-adding information to project decision making. For example, the two neighboring columns shown in Fig. 13 limit the space that is available to the work crew stripping the formwork off the concrete column. Visualization can simplify communication to other work crews, i.e. keep spaces unobstructed from other material, equipment, or tools, therefore yielding safer and more productive activity completion.

The following thoughts highlight a few challenges that are important to researchers: data collection, validation, and spatial–temporal analysis.

Many construction sites employ site managers and staff that rely on software tools to assist in keeping track of personnel, equipment, and material presence. Recent management tools combine the use of tracking and analysis technology [101]. Data management has been commercially available, but most site data is still entered manually. Little automated site data collection and analysis is performed when using vision based images. Although monitoring cameras have been widely applied, large and wide construction sites mostly rely on inspections of field management or superintendents on both the owner and contractor side. To collect high quality data a multi-tiered data collection effort can be approached:

Optimal laboratory environment large scale equipment exists in few laboratory-like settings. Among them are indoor or outdoor test grounds of large equipment manufacturers. An alternative are highly detailed articulated construction models, including construction workers, heavy equipment, and bulk materials can be articulated to collect still and video images. In particular performing ground truth measurement in safe and controlled laboratory environments aids in the validation process to rapidly achieve progress on algorithm design and testing.

Controlled and complex outdoor environments time-lapse, pan-tilt-zoom, wide FOV, aerial, and other camera technology is state-of-the-art equipment for collecting vision data. Significant experience with cameras is needed to design, measure and test the effectiveness of the proposed algorithms. Initial research plans typically foresee the use of large construction environments that contain few resources in the FOV of the camera(s). Robust algorithms are finally tested in larger construction areas with multiple acting resources, and scenarios that range from few resources to crowded scenes.

Construction operations data collaborations with contractors and construction camera providers grant easier access to very large image and video data sets of multiple construction projects that are completed or are under construction. Furthermore, information to construction as-planned vs. as-built information, including data to construction schedules, BIM, WBS, resource allocation, weather, safety records, activity reports, or other data that is generally available, should be collected. Analysis can then be performed by cross-referencing the information generated by the algorithms with existing archival data records.

It is important in the designing and testing of algorithms to validate their performance. For instance, the performance of the output of the proposed algorithms vs. its underlying ground truth needs to be measured. Given the static position and dynamic motion of some resources on the construction site, the resources’ positions and trajectories need to be precisely recorded before they can be compared to the results of the developed algorithms. A standard practice or near optimal method to validate the effectiveness of algorithms is measuring location errors. Considering the distance from camera to target, additional remote sensing technology that can be precisely calibrated and aligned to the boundaries of the observation space can be utilized. Technologies to measure the ground truth to single and multiple resources have been tested in experiments of various researchers, for example [8–10,102]. Research is required that expands these efforts to design novel methods for measuring the ground truth of vision based algorithms.

Validation of ground truth several proof-of-concept studies [8–10,102] utilized a Robotic Total Station, UWB, or GPSto track a single resource (see Fig. 14
                        ). Comparison of time-stamped tracking locations generated to video became possible. Although preliminary field tests showed promising results of positioning errors less than 0.5 meters, many research questions remain to be addressed, for example: (a) what technologies can be utilized for ground truth measurements to validate vision based algorithms; (b) what are underlying and standardized experimental characteristics to track multiple resources with low error rates; and (c) how are data sets from multiple technologies fused and compared?

Logic applied to other construction data to ensure that the algorithms operate correctly and provide useful data, logic must be applied. Research typically includes standard tests that are based on format or picture check (template check to track individual resources), data type check (match same data points), range check (within range of values, i.e., quantity), limit and presence check (upper and lower limits, i.e., number of resources present), quantity check (missing data), control check (progress monitoring), consistency check (robustness of algorithm), and others.

Exemplary data interfaces between the contractor information and the information the algorithms produce have been created that allow automated reporting functions to support decision making of field construction personnel [100]. Although a fully automated information system based on vision data is within near reach of completion, proof-of-concept and feasibility can lead to future research and development.

Comparison of as-planned vs. as-built information previous research efforts exist that have shown that progress tracking is feasible based on vision data [40,51]. Resources that are dynamic in nature and contribute to an as-built structure requires tracking them over time as they are used and eventually (e.g., material) become part of the as-built structure.

Automating the record keeping of resource presence and utilization spatial–temporal understanding of resources will be achieved by tracking how many resources were on site and in which space personnel or equipment was working in and for how long. Such automatically generated information significantly transforms and simplifies many of the current manual work tasks of superintendents and field engineers. The gained information will be linked to construction drawings and schedules to visualize the area of activity. Resource tracking information can be integrated into building information models (main contributions) to reason workspace availability and utilization [104].

Understanding the activity level on job site and/or work area for many project stakeholders having information on the level of job site or work area activity is important to allocate resources. Knowing, for example, no, low, medium, or high activity gives valuable understanding as to which project tasks are on track and which are not. Detailed tracking of specific work areas requires the linkage to existing work task scheduling. Manual (as-planned) vs. automated (based on vision algorithms) operations analysis is a goal in many research efforts.

Definition of histories to resource availability and quantities the output of the algorithms can be used to identify the depletion ratio of resources. Although it may not be feasible to track very small sized materials with cameras far away, providing the depletion ratio will play an essential role to assist construction procurement when to replenish materials. This is in particular needed for temporary objects and bulk materials. In the long-term, automated jobsite productivity measurement will be possible knowing when resources arrive on site, where they are stored, and when they are installed. A combination of technologies will assist in this task. Using the entire construction sequence (from as-planned to as-built) will establish construction histories from which knowledge can be created. Visual information along with measureable project engineering and management data will assist in particular young engineers in understanding and evaluating the construction process. Scenarios will be created that give engineers the tools at hand to judge on situation based events.

Considering worker feedback and rights in the design and use of algorithms the research environment adapts widely used rules to gather and analyze data of personnel (called Human Subject Research). Although the feedback of construction personnel is typically mixed about the use of vision cameras, the US National Labor Relations Act (NLRA: 29 U.S.C. §§151-169) in 1935 does not permit the use of high resolution video surveillance to monitor workers organizing themselves or workers which intend to join labor unions or collectively bargain their terms and conditions of employment [87]. However, due to the low resolution of many commercially-available camera technology the identification of faces from workers is rather difficult. Among other reasons, the NLRA nor any collective bargaining agreements will likely pose any legal obstacles for a client to use video cameras. No other federal or state laws were found that would prohibit or limit the use of camera monitoring in the US. In fact, several thousand construction cameras operate on a daily basis. The legislation abroad, in particular in countries of the EU, is different as more strict regulations apply.

@&#CONCLUSION@&#

This work outlines early results for sensing and tracking of temporary assets on construction sites. Several examples related to infrastructure construction were presented. A state-of-the-art literature review presented accomplishments of academic research and practical industry applications. It demonstrates promising work towards automated visual recording and processing of temporary construction resources. Since technology advances rapidly, automatically extracted tracking information from vision based sensors is likely to soon provide essential project related information regarding the spatial–temporal utilization of the worksite for inferring onsite activities and work packages.

Similarly, as computing hard- and software is becoming more advanced, research is expected to fill an existing gap regarding the automated sensing, tracking and interpretation of temporary construction resources, of which the following specific advances will be enabled: (a) (semi-)automated sensing and tracking of construction assets, (b) automated tracking of construction workforce, (c) analysis tools for understanding overall site work flow, (d) generation of a rich body of ground truth for evaluating the proposed and future algorithms, and (e) data analysis and interpretation of the collected field data (actual and simulated).

To accomplish these identified goals, researchers in this area need to have an extensive background in construction, remote sensing, image processing, machine learning, and computer vision. Future research programs need to derive robust and fast algorithms for long-term asset detection and tracking on construction sites. In order to verify the accuracy and correctness of the derived algorithms, the concept of simulated and realistic experiments comprised of simultaneous measurement of the tracked assets using other sensing technology to serve as ground truth, has been introduced.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Anaglyph video smell presentation using micro-porous piezoelectric film olfactory display

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We implemented an olfactory display based on a novel approach.


                        
                        
                           
                           We developed a novel data hiding technique in 3D video with high robustness.


                        
                        
                           
                           Both novel techniques are combined to provide smell data to the users.


                        
                        
                           
                           A high control over smell data digitization and scene synchronization has been achieved.


                        
                        
                           
                           The system is scalable, efficient and applicable to existing 3D video files.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Smell

3D video

Olfactory display

Anaglyph

@&#ABSTRACT@&#


               
               
                  Anaglyph video (i.e., 3D video) is a recent trend in movies and multimedia; the method has also been recently developed for conversion of such videos from traditional 2D screens or by rendering stereoscopic media into 3D video. There have also been many studies regarding movie playing and other types of entertainment that uses olfactory displays or smell generators. These devices are capable of generating a considerable number of different odors with different intensities yet still have some limitations and are not ready for commercial use. In this study, a complete solution is presented for a user to experience olfactory sensations with a displayed video on a PC with auditory and 3D visual effects using a novel olfactory display device based on a micro-porous piezoelectric film that is capable of digitally producing fine particles of scent material with precision, quantity and speed.
               
            

@&#INTRODUCTION@&#

Many studies have investigated olfactory displays but have focused on building the display itself and the associated implications and challenges that might arise; others have introduced a novel approaches of smell generation and delivery using a piezoelectric transducer film with a fine mesh to generate a droplet that can be controlled digitally, providing a discrete (i.e., digital) amount of smell. This allowed the smell to travel from the container holding the smell to the nose of the user in a minimum time on the order of a second or less.

@&#RELATED WORKS@&#

There are many studies in the literature in the field of olfactory displays that use different technologies to provide a better and fast delivery of scent material to the user. These attempts have had good results yet are incomplete and have certain drawbacks. The problems arise from successfully building a scent-providing element that is capable of transforming the scented material state, which is primarily liquid, to a state can be intercepted by human olfactory sense (i.e., air borne molecules). Another problem is providing a robust mechanism to digitize the concentration of the scented material. Additionally, the response time must be sufficient to the desired application considering the human olfactory system’s response to the projected scent. It is important to state that these attempts have been considered as the foundation of olfactory displays. In [1,2], a projection device was proposed to eject scent based on a nose tracking feature; this ejection was accomplished using an air cannon that contracts when scent delivery is desired; the scent is delivered inside the cannon and ejected. These systems in their final improved prototype provided minimal amount of scent material by injecting scented air so that the scent is diffused quickly after it is presented it minimized the level of residual scent after it suffered from residual scent problem in their early prototypes but still inherited all the problems of scented air delivery which requires an external air pump and a number of electromagnetic valves as stated by the author in the final third version, four scent inputs each one controlled with two valves and one air input valve in addition to fresh air input valve which are in total 10 valves. In addition a pan and tilt motors are used to direct the air cannon and a motor to drive the bellow for ejection impact. All these components requires significant amount of power for all prototypes hindering its evolution for a standalone computer powered equipment. Finally it is obvious that the residual scent in the system is high for early prototypes and where reduced significantly in the final prototype after improving the delivery mechanism but still required an external air supply equipment. This technique is focused on scent delivery and spatial control technique, which is almost independent of scent generation techniques. In [3–5], the same olfactory display was used to disperse scented material toward the user using solenoids valves and an air compressor to create airflow. This concept is based on bubbling air into the liquid scented material to create an evaporated scent mixed with air (i.e., an airborne scent) and controlling the flow of that air/scent mixture among other types of scents produced in the same way to be directed to the user’s nose. Because solenoids are electromagnetic devices with mechanical movements, they require a significant amount of energy while operating. The authors used a 3-way rapidly switching solenoid valves which these electromagnet components draws at least 200mA, yet they are a little bit quiet and produce almost no sound according to author’s claim; an air pump must also be used to provide airflow to the olfactory display. The author used (Contec, PIO-48D (CB) H) obsolete (according to manufacturer) control card it has only handle 8mA via each pin, therefore the author used a transistor amplification circuit for each solenoid valve (used 32) hence there are 32 solenoid valves. Also the author stated that it requires some labor to change the scent component which diminishes the interchangeable cartridge property which the author recommends and the proposed system contains such feature. It is fair to say that even the display was in basic in design and have some drawbacks but still the authors provided a paved roadmap to others to follow their steps in olfactory displays design. Refs. [6–8], another approach was applied that used an electro-osmotic micro pump to deliver a predefined amount of scented material to be dispersed using a surface acoustic wave (SAW) device that is capable of producing a vapor rapidly; however, the hardware setup needed voltage levels as high as 100V for the driving circuit but produced the vapor instantaneously and efficiently. Other techniques such as [9] used a solid/gel scent material and a Peltier module; the module produced heat to transform the solid/gel material into vapor and deliver it to the user. Such systems require a high current supply to heat the Peltier module to a sufficient evaporation temperature; the time required to achieve such a temperature is also typically relatively high. Using this technique, olfactory display devices have been limited to desktop systems connected to a personal computer and other supportive devices, such as high current supply, air pump and frequency generators. In [10–12], olfactory displays were worn by the user, and the scent ejection point is placed near the user’s nose. This approach is suitable for virtual reality applications when the user is mobile rather than sitting at a desk. This technique solved some problems of scent delivery but still has limitations in terms of intensity control. In [13], a more precise technique is used based on inkjet cartridge technology, where an ink cartridge was modified to eject liquid scent rather than ink using the same principles of ink level control, mixture and evaporation. In [14], a more advanced model of olfactory display was included in a real-world application of sensing smell in a certain device and sending primitive olfactory data merged with a captured image through an ADSL connection via the Internet. Nakamoto et al. have produced the most mature studies in the field of olfactory displays, but the smell projection device they used is based on [4,5]. Hirose et al. introduced many head-mounted olfactory displays, including a scent generation and blending mechanism that was controlled by computer [15,16]; they also recently developed a wearable olfactory display system [17] that allows users to move freely without being tied to the system by tubes and wires regardless of its complexity and size.

Many olfactory display technologies exist, and some provide promising roadmaps for commercial and personal use of such displays that might initiate significant interest in more techniques to build such devices. Some provided a foundation for how to introduce and integrate such a new field into the computer science world, as shown in [18,19], where interesting and various concepts are presented to researchers for ideas and guidelines. The claim is that a complete system for olfactory display in a practical system must satisfy requirements for compactness, efficiency, durability and usability that do not require an engineer or scientist to maintain and operate or a lab or other external equipment in a special environment to be successfully used; a user with a PC and a selection of any aromatic material (water or oil based) that the user desires or an anaglyph 3D video should be the only requirements of such a system. Table 1
                      shows a comparison between the proposed scent element and the performance and issues of other olfactory displays that are the most popular in recent literature.

A micro-porous piezoelectric film that is composed of a piezoelectric film with a steel mesh in the center of the transducer was used in this study. When connected to a certain frequency, this film vibrates, creating small airborne droplets that are projected toward a user’s nose.

A piezoelectric film with micro sized holes in the center (Figs. 1 and 2
                        
                        ) was mounted in front of a transparent plastic cartridge with a silicone washer to prevent leakage of the scented material to prevent inaccurate results. The plastic cartridge has two opposing openings: one is used to mount the piezoelectric film to extrude the scented material, and the other hole is used to fill the cartridge with the scent material. Two silicone seals (upper and lower) are used as covers (Fig. 3
                        (a) and (b)) and enclose the piezoelectric film. This assembly is then fastened under the scent cartridge by screws to create an air tight chamber to prevent the scented material from leaking into the olfactory display as vapor or liquid. Fig. 4
                         shows a diagram of the scent element cartridge assembly.

The piezoelectric film is enclosed inside of the upper and lower silicone gaskets with a small gap between the film and the silicon. The film vibrates due to an applied frequency, causing the scented material to be extruded out of the micro sized holes; the backward movement of the opposite phase of the signal repels the scented material, creating a micro-sized airborne droplet that rushes out of the scent element (Figs. 6–8
                        
                        
                        
                        ), producing the desired scent.

The micro porous piezoelectric film has the following characteristics:
                           
                              1.
                              Diameter: 13.8mm.

Low driving voltage: 3–12V.

High conversion efficiency, spray volume.

Exit aperture: 4μm.

Frequency: 113kHz±5kHz.

Capacitance: 2700pF±15%.

Power: 1.5–2.0W.

Spray volume: 30ml/h.

Can atomize essential oils, perfume, water-based perfumes or mixtures of the above materials

Life span: more than 3000h

Considering that most of these characteristics are suitable for use in computer applications that require low energy consumption and high efficiency operation. The size of the droplet is approximately 4μm, which is sufficiently small to be airborne. The movement of the atomizer is continuous to produce these droplets continuously, forcing them to be repelled from the exit hole of the scent delivery cartridge and into the mixing chamber of the olfactory display; if the input signal is continuous, then the fine mist production is also continuous. Fig. 5 shows the implementation of six scent elements that are used in the proposed olfactory display.

As shown in the characteristics of the transducer, the input frequency is large, and an external circuit is required to produce this frequency; this is essential for the activation of the transducer film to produce the required mist volume. This frequency ranges from 108kHz to 118kHz.

In early experiments, an attempt was made to manipulate the transducers’ supplied frequency to control the amount of the generated scent material. This attempt was somewhat successful but did have significant variation; if the frequency was reduced to 68% or lower, then droplets were not produced correctly, and only a single mass of droplets fell into the mixing chamber; if the frequency was higher than 110%, the droplets were also deformed and not produced correctly. For values in between 68% and 90%, no noticeable difference in the volume of mist produced was noted. As a result, timed pulses were used to produce the required scent intensities instead of altering the frequencies.

As mentioned before, the operation of the transducer film requires an applied frequency to function correctly, and that frequency makes the film vibrate at that frequency. The film consists of two plates that bend back and forth according to the frequency variation of the applied frequency. When the value of the supplied signal is zero, then the plate is in a “resting” state and produces no droplets or mist; in addition, the holes in the center are sufficiently small that liquid material cannot pass (Fig. 6).

As the voltage becomes negative, the piezoelectric film begins bending upwards, creating a pressure inside the cartridge; in addition, this sudden contraction creates a force on the scented material directly surrounding the micro holes so that it is forced through the holes. As stated, these holes are small and required the scented material to pass through in small amounts (6μL), producing fine droplets (Fig. 7).

When the voltage becomes positive again, the piezoelectric transducer begins to bend outwards, and because this occurs shortly after the upwards bending when the voltage was negative, the accumulated fine droplets are repelled and forced away from the micro holes, allowing new droplets to be produced and droplets produced on the last cycle to be emitted away from the piezoelectric transducer (Fig. 8).

The circuit board used was built using a 18F2550 microcontroller that is USB capable and has 3 digital I/O ports; it runs on an 8MHz oscillator, and each scent elements’ piezoelectric film is connected to a dedicated frequency generator that is supplied with 5V via USB directly and is grounded by a ULN2003 Darlington array chip activated by a digital I/O pin from PORT B. The USB connector is connected via data+ and data− pins and supplies the voltage to the microcontroller. Two DC fans are used to deliver the produced scent droplets to the user, and both are connected to a step-up circuit to produce the required 12V from the USB-supplied 5V. The speed of these fans is controlled via a pulse width modulation pin from the microcontroller connected to an NPN transistor. In addition, a Li-ion battery with a charging circuit is used as a power buffer to support the circuit because the USB amperage is not sufficient to support all components working simultaneously at full power, which is rare but possible. Fig. 9
                         shows a circuit block diagram of the system.

The software implementation of the system contains 4 major components that work together to achieve the goal of the proposed system and is described as follows:

The scented anaglyph video generator is an implementation of a common anaglyph 3D video generation from a single 2D video using a color channel manipulation to generate 3D video from 2D video. A 2D video stream was divided into a number of frames; each frame was then converted into 3D frame using channel separation (i.e., red, blue and green channels) using a predefined offset between each channel; the red channel was shifted by half the offset to the left, while the blue and green channels were shifted to the right by half the offset, where the offset was the depth of the scene. This process was repeated for all n frames in the video, ultimately creating the effect of depth when the user wears a spectacle with a red filter in front of their left eye and a blue filter in front of their right eye.

In this component, the user sets and modifies the scent data that are going to be embedded in the specific frames in the target anaglyph video. These settings are programmed by clicking the timeline of the video or by setting a duration of time/fames for the specific scent data to be presented. The interface contains six channels with six different scent intensities for each channel; each intensity is marked on the video timeline with its own channel, which is indicated by a distinctive color so that the user can understand the scent intensity level and its location. The proposed system then generates corresponding binary image patterns, each of which contains a different dither density.

Using dithering, six different intensities of each scent data were created, which are useful to withstand a given level of robustness for the scent data to persist throughout different disturbances such as noise and compression (Fig. 10
                        ). Although a certain level of robustness was achieved in the embedding process, the focus of this study was not to address this issue but was rather to ensure that scent data would be extracted successfully in the proposed olfactory-based video player. The final embedded data are constructed as a single binary bitmap with six regions, where each region represents a single data instruction that corresponds to a particular scent element. If the frame does not contain any scent data, then the image will contain a solid white color (i.e., the scent element will remain active during the display of that frame).

The generated bitmapped image is shown in Fig. 11
                        . Each of these six regions carries a given scent intensity to the corresponding scent element; also, a strip of half the region contains all of the intensity levels used in the system to use later in the qualification process of the extracted scent bitmap. This image is embedded in each selected frame to carry scent intensity information as well as the selection of the scent element itself.

The embedding system uses the blue channel to embed real data (i.e., scent data) because blue color variation is difficult to perceive by humans. To embed the scent bitmap image, a discrete wavelet transform was performed on the blue channel.

Scent bitmap information is embedded in the high frequency bands (HH1) of that channel because they are robust against various image processing operations and disturbances. Additionally, the size of HH1 is large compared with other high frequency bands in other levels; this allows a large amount of embedded scent information with less influence on the resulting image [20] noticing that the embedding can be also done according to [21–23]. The following algorithm shows the embedding process:
                           
                              
                                 
                                 
                                    
                                       Algorithm 1
                                    
                                 
                                 
                                    
                                       
                                          Step 1: Collect scent bitmaps marked in the work area by the software
                                    
                                    
                                       
                                          Step 2: Vectorize each binary bitmap image into a vector W
                                          ={w
                                          1, w
                                          2, …, wm
                                          } of binaries.
                                    
                                    
                                       
                                          Step 3: Extract the blue channel from each RGB frame and decompose it into the discrete wavelet domain with four levels.
                                    
                                    
                                       
                                          Step 4: Split HH1 into non-overlapping blocks of dimension 8×8, H
                                          1, H
                                          2, …, Hb
                                          , where b is the number of blocks.
                                    
                                    
                                       
                                          Step 5: Apply the binary image bits W onto the HH1 blocks. The embedding process for each image bit is done by replacing the first coefficient in the first column in the block with the maximum coefficient+
                                          α in the same column if the embedded bit equal to 1; otherwise, the replacement is done with the minimum coefficient−
                                          β, where α and β are the diversity strength factor parameters for the embedded image.
                                    
                                    
                                       
                                          For each block Hi:
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                (
                                                1
                                                ,
                                                1
                                                )
                                                =
                                                maximum
                                                
                                                (
                                                
                                                   
                                                      H
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                r
                                                ,
                                                1
                                                )
                                                )
                                                +
                                                α
                                                
                                                if
                                                
                                                (
                                                image
                                                
                                                bit
                                                )
                                                
                                                
                                                   
                                                      W
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                1
                                                ,
                                                
                                                
                                                
                                                (
                                                1
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                (
                                                1
                                                ,
                                                1
                                                )
                                                =
                                                minimum
                                                
                                                (
                                                
                                                   
                                                      H
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                r
                                                ,
                                                1
                                                )
                                                )
                                                -
                                                β
                                                
                                                if
                                                
                                                (
                                                image
                                                
                                                bit
                                                )
                                                
                                                
                                                   
                                                      W
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                0
                                                .
                                             
                                          
                                       
                                    
                                    
                                       
                                          Step 6: Reconstruct the embedded blocks into HH1 and perform inverse DWT to obtain the embedded blue channel, and combine the blue channel with the red and green channels to make the 3D embedded frame.
                                    
                                    
                                       
                                          Step 7: The 3D embedded frames should then be consolidated to produce the anaglyph 3D video containing embedded scent data.
                                    
                                 
                              
                           
                        The overall process of the embedding algorithm is shown in Fig. 12
                        .

This software component uses the video resulting from the embedding process and plays the video information along with the scent data. The player starts by extracting scent information from the video frames, creating a scent data array that is synchronized with each frame; when the player displays a specific frame, it simultaneously sends the associated scent data to the proposed olfactory display via USB connection using six bytes for only the scent information.

In the extraction process, the proposed system extracts the embedded informational image according to [20] and calculates the density of one’s (i.e., black pixels) in a 48×48 image region; these values are then qualified according to a predefined threshold to successfully determine the amount of scent material to be produced with that frame. The embedded image is typically immune to noise because it does not carry visual or discrete information but rather a statistical appearance of ones and zeros in a specific region; this statistical information (i.e., a density value) states that its difference property remains static even though its value changes rapidly. Any of the extraction processed found in [21–23] that correspond to the embedding processes can be used in the same sense.

The original 3D video is not required during the extraction process. For successful extraction of the embedded scent bitmap, these steps are followed (Fig. 13
                        ):
                           
                              
                                 
                                 
                                    
                                       Algorithm 2
                                    
                                 
                                 
                                    
                                       
                                          Step 1: Convert the embedded anaglyph 3D video into a number of frames.
                                    
                                    
                                       
                                          Step 2: Extract the blue channel from each RGB embedded frame and decompose it into the discrete wavelet domain with four levels.
                                    
                                    
                                       
                                          Step 3: Split the HH1 into blocks with dimension 8×8.
                                    
                                    
                                       
                                          Step 4: The extraction process is completed by computing the average of the first column of each embedded block; if the average is greater than the first coefficient in the first column, then the embedded bit is equal to 0; otherwise, the embedded bit is equal to 1.
                                    
                                    
                                       
                                          For each block Hi′:
                                       
                                    
                                    
                                       
                                          
                                             
                                                (
                                                Extracted
                                                
                                                embedded
                                                
                                                bit
                                                )
                                                
                                                
                                                   
                                                      Wi
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                =
                                                1
                                                ,
                                                
                                                if
                                                
                                                
                                                   
                                                      Hi
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                (
                                                1
                                                ,
                                                1
                                                )
                                                >
                                                =
                                                Average
                                                ,
                                                
                                                
                                                
                                                (
                                                2
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                (
                                                Extracted
                                                
                                                embedded
                                                
                                                bit
                                                )
                                                
                                                   
                                                      Wi
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                =
                                                0
                                                ,
                                                
                                                if
                                                
                                                
                                                   
                                                      Hi
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                (
                                                1
                                                ,
                                                1
                                                )
                                                <
                                                Average
                                                .
                                             
                                          
                                       
                                    
                                    
                                       
                                          Step 5: All frames that contain scent data, whether a white bitmap with no scent data or another bitmap with arbitrary data, it is assumed that there are n scented frames; thus, there are n scent bitmaps. These bitmaps are qualified to verify their values due to noise and disturbances. This qualification process will be explained later in this paper.
                                    
                                 
                              
                           
                        
                     

Once the bitmap has been extracted successfully, there are some issues that must be considered, including noise and data disturbances. In ideal conditions, the extracted scent bitmap is not affected by variations of compression, noise and other processes; however, unfortunately, this is a rare condition in the real world. Additionally, the intent of this study is to maintain scent information throughout the lifetime of the anaglyph video file. As a result, each region is checked against a threshold that describes that region’s level of intensity. The usage of a dithering process yields a scent bitmap with a high robustness against virtually all types of disturbances.

The stripe of intensities is used as a guideline for the threshold construction and will withstand the same amount of deformation applied to the scent bitmap by a disturbance. The qualification process is shown in Algorithm 3 below:
                           
                              
                                 
                                 
                                    
                                       Algorithm 3
                                    
                                 
                                 
                                    
                                       
                                          Step 1: For each region, calculate the real density of black pixels:
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      Region
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      x
                                                      =
                                                      1
                                                   
                                                   
                                                      48
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      y
                                                      =
                                                      1
                                                   
                                                   
                                                      48
                                                   
                                                
                                                
                                                   
                                                      Ds
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                
                                                   
                                                      Ds
                                                   
                                                   
                                                      i
                                                   
                                                
                                                +
                                                
                                                   
                                                      Rgn
                                                   
                                                   
                                                      x
                                                      ,
                                                      y
                                                   
                                                
                                                
                                                
                                                
                                                (
                                                3
                                                )
                                             
                                          
                                       
                                    
                                    
                                       where Ds is the density of region i and Rgn is the region being processed.
                                    
                                    
                                       
                                          Step 2: For each region in the qualification stripe, calculate the standard density threshold:
                                    
                                    
                                       
                                          
                                             
                                                stripe
                                                
                                                
                                                   
                                                      region
                                                   
                                                   
                                                      i
                                                   
                                                
                                                =
                                                2
                                                x
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      x
                                                      =
                                                      1
                                                   
                                                   
                                                      24
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      y
                                                      =
                                                      1
                                                   
                                                   
                                                      24
                                                   
                                                
                                                
                                                   
                                                      Stds
                                                   
                                                   
                                                      i
                                                   
                                                
                                                +
                                                
                                                   
                                                      Stds
                                                   
                                                   
                                                      i
                                                   
                                                
                                                +
                                                
                                                   
                                                      Srgn
                                                   
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                
                                                
                                                
                                                
                                                (
                                                4
                                                )
                                             
                                          
                                       
                                    
                                    
                                       where Stds is the stripe density of stripe region i and Srgn is the stripe region being processed.
                                    
                                    
                                       
                                          Step 3: Map each density value acquired from the regions to the closest value acquired from the qualification stripes.
                                    
                                    
                                       
                                          Step 4: Insert the qualified values to the scent values array of the olfactory-based video player.
                                    
                                 
                              
                           
                        
                     

The firmware of the olfactory display uses a USB-protocol-based communication system with a 64-byte transfer rate. The primary data sent via USB is real information about the scent element that will be activated and how long it will activate; other supporting data such as fan speeds and synchronization data are also sent via USB.

The olfactory display takes the six scent information values and begins activating each scent element accordingly; note that more than one scent element might be activated at the same time to mix two or more scent materials. To achieve the intensity values received at the olfactory display, the value will be decreased by 1 after each iteration while examining the values repeatedly; if the value reaches zero (i.e., “no output”), then the decrement stops for that scent element, deactivating the corresponding scent element. The process is repeated until all values are exhausted. The following algorithm describes this process:
                           
                              
                                 
                                 
                                    
                                       Algorithm 4: Scent information processing
                                    
                                 
                                 
                                    
                                       
                                          Step 1: Loop until all values are exhausted.
                                    
                                    
                                       
                                          Step 2: For each scent element value, if value >0, then decrement and send a signal to the scent element.
                                    
                                    
                                       
                                          Step 3: Wait for a predefined time. The maximum delay of the highest intensity should not exceed the frame duration because the subsequent frame data will be received shortly.
                                    
                                 
                              
                           
                        
                     

First, the user selects a video file to be loaded into the software. The system then calculates the frame duration by dividing the total video time by the number of frames in the video file:
                        
                           (5)
                           
                              Frame
                              
                              duration
                              =
                              total
                              
                              video
                              
                              time
                              /
                              number
                              
                              of
                              
                              frames
                           
                        
                     
                  

The system then prepares a set of working areas sampled by the frame duration for the user to use the mouse to mark up the frames to carry the scent elements; each channel is dedicated to one scent, and in this experiment, six scent channels were used. The system thus provides six stripes for marking, where the position of the mark represents the time (i.e., frame) that the scent will be produced while the specific stripe represents the desired scent element; the intensity (i.e., color) selected by the user represents the intensity (i.e., amount) of scent will be produced by the olfactory display.

As the user starts to move through the markup stripes, selecting different intensities and marking the stripes, the system stores these values into an array that is synchronized with the frame positions in the video file. After finishing this process, the user press a button to start the markup embedding process in conjunction with the anaglyph process.

Up to this point, the user can test his markups by playing the video by pressing the play button; this will allow him the ability to test the values he added to the video. If the user is satisfied, then the next step in the operation is converting the video file to anaglyph 3D video; the system begins by applying the described anaglyph conversion process to the first frame and then converting the selections of the first stripe array to a bitmap image containing the intensities of the scent material corresponding to the location of each value to each scent element. The described embedding process is then used with the bitmapped image, which is merged with the frame data. This process continues with subsequent frames.

The resulting anaglyph 3D video file contains olfactory information recognized by the developed olfactory-based video player, which allows the user to load the file produced and play 3D scenes with their associated scents. The player extracts the embedded bitmap images and qualifies its values, preparing the same array that was used in the embedding process. When the video is played, the current frame is displayed on the screen while its corresponding scent is sent over the USB connection to the olfactory display control board that processes the data and signals for each scent element to produce the corresponding scent. Figs. 27 and 28 show the full olfactory display design and real picture.

@&#EXPERIMENTAL RESULTS@&#

The experimental results were obtained with certain parameters to obtain the described results; an MQ-3 sensor was used to detect the output of the olfactory display to measure the speed of the output and the intensity level of the scented material. Ethanol was used as a detecting material and was diluted in water with different concentrations to find the effect of concentration with respect to detection time.

The temperature used was 23–25 degrees Celsius, and the humidity was 50–55g/m3 with the humidity sensor 70cm away from the olfactory display’s ejection point. Each intensity value of the bitmap was sent to the olfactory display in sequence, and the intensity was measured by the sensor and displayed using Matlab. Distinctive measures were obtained, and the response to each intensity was identified because the levels are distinctly recognizable with a mixture of 6:100 of alcohol to water (Fig. 14
                     ).

The results from testing a random scent data bitmap embedded into an real frame, which was then extracted by the olfactory-based anaglyph 3D video player using the same alcohol-to-water mixture ratio, are shown in Fig. 15
                     .

The reason behind selecting this dilution ratio of alcohol to water was because lower ratios yielded worse detection for the sensor and because higher dilution ratios yielded more ppm (particles per million) of alcohol than reside on the sensor, decreasing its sensitivity to later ejections; this was similar in effect to what the human olfactory system would experience (i.e., adaptation to smell), which is a well-known phenomenon in the smell industry. This phenomenon can also result in the cancellation of such phenomena as inhaling the smell of coffee beans. Fig. 16
                      shows the effect of different dilution ratios to the detection speed. The size of the circle shows the number of ppm response output by the sensor with respect to the response time and the dilution ratios; Table 2
                      shows the real values.

In the experimental results, some disturbances were applied along with a number of deformations to the scent bitmap to test the resulting values that were extracted. In each case, the values yielded good results and were decoded successfully. According to the following test results, cohesive correlations were found between the region data and the strip threshold reference data (Figs. 17–19
                     
                     
                     ).

After applying the disturbances, extracting the bitmap image data and sending these data to the olfactory display, the result was tested and measured to determine the output of the display and the corresponding effect of the damaged data. The scented data were found to have survived the disturbances even when severe data corruption took place (Fig. 20
                     ).

The proposed algorithm is applied to a given 7 frames of the selected scene (e.g., frames 1, 5, 10, 15, 20, 25, 30) of four video samples titled ‘rose.avi,’ which consists of 412 frames; ‘daisy.avi,’ which consists of 972 frames; ‘apple.avi,’ which consists of 868 frames; and ‘lemon.avi,’ which consists of 388 frames. All videos had resolutions of 1920×1080 and frame rates of 24 frames/s. The scent bitmap image was a binary image of size 144×144 that contains the scent information embedded into the anaglyph 3D video frames using the algorithm described in the previous section.

Because the magnitudes of the high frequency coefficients of the DWT increases at higher levels of decomposition, smaller scaling factors can be used during the embedding process (i.e., a lower level of decomposition). In the experiments, scaling factors were between 0.9 and 1.9; the best result was obtained when α
                     =1.8 and β
                     =1.5 to obtain a tradeoff between imperceptibility and robustness.

The PSNR was 67–70dB for the test videos. These values indicated that visual degradations were acceptable and highly imperceptible for HVS. Fig. 21
                      shows the plots of PSNR versus frame number for different video samples after the embedding process. The performance of the algorithm has been measured in terms of its imperceptibility and robustness against salt and pepper noise, Gaussian noise with a mean=0 and a variance=0.0005, histogram equalization, gamma correction, intensity adjustment, JPEG compression (with quality factor=50) and a Gaussian low pass filter (Figs. 22–25
                     
                     
                     
                     ). When using a Gaussian low pass filter that was 9×9, 5×5, 3×3, the NC was equal to 1 for all anaglyph 3D videos; for a size of 2×2, the NC was 0.79–0.84. Finally, Fig. 26
                     
                     
                      shows the effect of disturbances on PSNR values.

To include the human factor in this study, 20 participants were involved in this test to determine the smell delivery method and speed. Each participant was placed 70cm away from the olfactory display’s ejection point and given two switches, one in each hand. When the user pressed the first switch, the olfactory display ejected a smell and started a timer simultaneously; when the user detected the smell, he pressed the other switch to stop the timer. Table 3
                      shows the average times recorded for 6 types of scented materials.

@&#CONCLUSIONS@&#

In conclusion, after implementing the proposed olfactory display, it was clear that using piezoelectric micro-porous film produce good response times and intensity control of the amount and state of the ejected scent material; these three factors are particularly important in olfactory displays, satisfying the claims described in Section 2. Additionally, the low voltage system resulted in a device that does not require external power; an internal Li-ion battery was used as a backup for the system, which is required in rare cases of the proposed olfactory display operation.

The scent bitmap in the proposed design provided a robust system for embedding data and was shown to be relatively immune to disturbances and data corruption. The qualification strip was found to be somewhat mandatory because a successful qualification threshold depended on such additional information; otherwise, the extracted data were quantified successfully but could not be mapped accurately due to the absence of guiding data from the qualification stripe.

In addition, the embedding process provided a high capacity, immunity and efficiency in the embedding technique and was able to hold much more data than was required for the proposed system; this allows for possible future expansion of the technique for additional scent elements.

Utilizing the blue channel of the anaglyph video was shown to provide an effective data embedding method to avoid affecting the anaglyph video because the impurities of blue colors are difficult to perceive when using HVS.

In the implementation, a large common chamber that all scent elements share is important for mixing scented material before ejection to be sensed by the human olfactory system as a mixture rather than a number of varying odors in time. The system implementation provided a low level of total noise that was less than 55dB, which is hardly noticeable by HAS sitting within 0.5m from the olfactory display; this is an important feature when implementing peripheral devices.

Additionally, the obtained results of NC and PSNR values showed a reasonable tradeoff between imperceptibility and robustness, showing that the proposed technique describes an effective data embedding scheme for merging anaglyph 3D videos with scent information for the proposed olfactory display.

@&#ACKNOWLEDGMENTS@&#

This work was partially supported by the National Natural Science Foundation of China (Grant No. 61173107), the National High Technology Research and Development Program of China (Grant No. 2012AA01A301-01), the Special Project on the Integration of Industry, Education and Research of Guangdong Province, China (Grant No. 2011A091000027) and the Project on the Integration of Industry, Education and Research of Huizhou, Guangdong Province, China (Grant No. 2012C050012012).

@&#REFERENCES@&#


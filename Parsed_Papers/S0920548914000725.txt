@&#MAIN-TITLE@&#Modular design of an open-source, networked embedded system

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The paper shows how to design an open-source, networked embedded system.


                        
                        
                           
                           It integrates a real-time fieldbus, TCP/IP connectivity and USB mass storage.


                        
                        
                           
                           The design emphasizes modularity and ease of portability to similar systems.


                        
                        
                           
                           The software easily fits into the internal memory of low-cost microcontrollers.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Open-source software

Embedded systems

Distributed systems

@&#ABSTRACT@&#


               
               
                  The ever increasing hardware capabilities typical of modern microcontrollers make it easier to add more and more functions to embedded systems, even for relatively low-end ones. In turn, this raises new requirements on their ﬁrmware, focusing on aspects like adherence to international and industrial standards, modularity, portability, fast time to market, and integration of diverse software components.
                  This paper shows, by means of a case study, how to design a full-ﬂedged networked embedded system using only open-source components, including a small-scale real-time operating system. In addition, it highlights how different components addressed key design issues, like inter-task synchronization and communication.
               
            

@&#MOTIVATION@&#

The complexity of modern embedded systems is constantly increasing, especially for what concerns their firmware, as they must perform more sophisticated functions than in the past. For instance, Internet connectivity and data logging on commodity devices—for example, a USB flash drive—are becoming widespread requirements, even on relatively low-end equipment.

Although, on the one hand, this process is made smoother by the substantial hardware capabilities nowadays provided by most microcontrollers, it raises new challenges for software development, too. As a consequence, topics like software modularity, portability, as well as the ability to conveniently reuse software components in multiple projects, are no longer relevant only for niche, high-end products. On the contrary, they will be of more and more widespread importance in the near future.

This paper shows, by means of a case study, how a fully functional networked embedded system, including its associated software development tools, can be designed and implemented only out of open-source components. Modularity and portability are emphasized by the use of a real-time operating system as foundation, while the adoption of open-source components maximizes re-usability and keeps software development cost and time low.

At the same time, contrasting the ways in which distinct components address the same design issues (like, for instance, the operating system interface for what concerns synchronization and communication among concurrent code) is helpful to better appreciate the trade-offs between them and their relative merits.

The paper is structured as follows: Section 2 outlines the general structure of the system and its foundation, that is, the open-source software development toolchain and a small-scale, real-time operating system. Sections 3 through 5 discuss in more details the most important system components, namely, the TCP/IP protocol stack, the USB-based mass storage system, and fieldbus connectivity, respectively. In Section 6 more information is given on the memory requirements and performance of the components discussed in the previous sections, which are often the most severe constraints in a small-scale embedded system. Section 7 concludes the paper.

This section outlines the main hardware and software components of the system being considered in the case study. In addition, it provides some information about the software development toolchain used to build the executable form of the application software and the underlying system components. Neither the software development toolchain nor the real-time operating system will be discussed in detail in this paper, because they are readily available for many popular platforms, and hence, they can nowadays be considered a commodity item.

The hardware platform considered in the case study is built around a LPC2468 microcontroller [1,2]. It embeds an ARM7TDMI [3] processor core, running at a maximum speed of 72MHz, and a variety of other peripherals, including an Ethernet controller and several asynchronous serial ports. The only external components required to gain Ethernet and TIA/EIA-485 (formerly RS485) [4] connectivity are an Ethernet physical layer interface (PHY) and a TIA/EIA-485 transceiver, respectively. The TIA/EIA-485 interface has been considered because it is the physical-level medium used by several widespread fieldbuses, for instance PROFIBUS [5] and Modbus [6,7].

A limited amount of flash memory and static RAM is available on chip, and more can be added by means of an external memory interface. Due to its characteristics and price tag, this microcontroller can be seen as a typical component for low-cost, embedded systems.

From the software point of view, the aim was to design a full-fledged embedded system comprising Internet and fieldbus connectivity, as well as access to a mass storage system based upon inexpensive USB memory sticks. The design emphasizes modularity as a means to achieve better code portability and make it easier to reuse it in different projects. The resulting system architecture is shown in Fig. 1
                        . In the figure, reusable system code modules are represented by gray boxes and amount to a significant part of the total software load in typical applications.

The most natural choice for an open-source software development toolchain revolves around the GNU Compiler Collection [8] and related components, namely:
                           
                              1.
                              The binutils 
                                 [9] package provides an ample set of tools to build, examine, and manipulate object and executable files. Most importantly, it also contains the assembler and the link editor.

The gcc 
                                 [8] component includes compilers for many popular programming languages. In this case, it has been configured to build only the compiler for the C programming language [10], which is the programming language used by all the open-source components considered in the project.

The newlib 
                                 [11] package contains a runtime library for the C programming language, including mathematical functions, specially tailored for embedded systems.

The gdb 
                                 [12] component provides a command-line based debugger.


                        Table 1
                         lists the exact version of the components used in the case study. It should be noted that, although it is quite possible to build all toolchain components starting from their source code—like it has been done in the case study—it is often faster and easier to acquire them directly in binary form. As an example, at the time of this writing, Mentor Graphics offers a free, lite edition of their Sourcery CodeBench toolchain [14], which is able to generate code for a variety of contemporary processor architectures.

A wide choice of real-time operating systems for embedded applications is nowadays available, for instance [15,13,16]. Basically, they represent different trade-offs between the extent of their application programming interface (API) and their memory and processor requirements. For this case study, the choice fell on the FreeRTOS real-time operating system [13,17]. This was done in order to minimize memory occupation, because memory is often a scarce resource in small embedded systems. At the same time, as it will be better detailed in the rest of the paper, this operating system still provides all the functions needed to effectively support all the other modules.

The adoption of a small real-time operating system like FreeRTOS on the embedded system platform of choice is usually not an issue. This is because these operating systems are designed to be extremely portable—also thanks to their limited size/complexity—and their source code package is likely to already support the selected architecture with no modifications required. In this case, a working C compiler is all what is needed to build and use them.

The TCP/IP protocol stack used for the case study is lwIP [18]. With respect to other competing open-source projects, lwIP was chosen because it is a good trade-off between tiny protocol stacks, like uIP [19], and feature-rich, Berkeley BSD-derived protocol stacks [20]. In fact, at one end of the spectrum, uIP aims at the absolute minimum memory footprint, even at the cost of sacrificing some useful features—most notably full reentrancy—to that purpose. On the other hand, the BSD protocol stack was originally designed for workstation-class machines and its footprint is often unsuitable for small embedded systems, as it is also pointed out in [19].

In addition, lwIP has already been used successfully for distributed computing with embedded systems [21] and its UDP protocol performance has recently been thoroughly evaluated in an embedded computing environment, with satisfactory results [22]. Last, but not least, another advantage of choosing a simple, streamlined protocol stack is that its internal structure is relatively easy to understand and well documented [19,23]. Hence, its adaptation to new processor architectures and network devices is faster, easier, and produces more reliable code.

As shown in Fig. 2
                     , the lwIP code can be informally divided into four hierarchical levels. When lwIP is configured to support a single Ethernet interface, as in the case study being described here, the code is executed concurrently by (at least) three distinct tasks, listed in bottom-up order:
                        
                           1.
                           A low-level receive task associated with the Ethernet interface pulls the incoming frames from the network interface itself and pushes them into the main lwIP processing path.

The main lwIP task (called “tcpip” task in the lwIP documentation although, strictly speaking, it is quite unrelated to the TCP/IP protocol itself) accepts incoming frames from the receive task described above, as well as timer expiration events and application-layer requests, by means of a message passing interface. The reception of these messages triggers the execution of the Finite State Machines (FSMs) for all supported protocols, and the transmission of appropriate responses to the other tasks.

The application task(s) convey network requests to, and get responses from, the main lwIP task by means of an Application Programming Interface (API) invoked through function calls.

One of the strong points of this architecture is that the API, offered to and used by, the application tasks is relatively independent of the main lwIP task interface. Different tasks can even use different APIs on the same system at the same time. Two main APIs are defined and provided in the lwIP package:
                        
                           1.
                           The native lwIP API, sometimes called netconn, is heavily tailored to the lwIP architecture to achieve a better efficiency.

When compatibility with existing software is of paramount importance, an optional API largely compatible with POSIX sockets 
                              [24] and layered on top of the netconn API is also made available.

In this case study, both the netconn and the POSIX sockets API have been included in the system for the sake of completeness, although the netconn has the advantage of being smaller, simpler, and more efficient. Moreover, the netconn API is often expressive and powerful enough for the range of network applications typically found in small embedded systems. On the other hand, a clear shortcoming of the netconn API is that it makes the port of existing software based on the POSIX sockets API more difficult.

The vast majority of the lwIP code is completely platform-independent. The main platform-dependent components, shown in gray in Fig. 2, are the Ethernet interface driver (further divided into a low-level Ethernet controller driver and a high-level module, comprising the receive task and a transmit function) and the RTOS adaptation layer. They will be presented in Sections 3.1 and 3.2, respectively.

In addition, a couple of modules contain platform-dependent data type definitions and the lwIP configuration. The data type definitions are fairly simple and the lwIP source code distribution already contains several examples related to popular platforms. Due to lack of space, readers are instead referred to [23] for a full description of the (relatively complex) lwIP configuration process.

The Ethernet interface driver consists of two distinct source modules, with different degrees of platform-dependency:
                           
                              1.
                              The controller driver deals with the low-level details of the Ethernet controller. It contains, first of all, a set of functions to initialize both the controller itself and its PHY, preparing them for use.

The EMAC controller embedded in the LPC2468 [2] supports two lock-free ring buffers—allocated in a bank of dedicated shared RAM—to transfer network frames to/from the controller. Accordingly, the device driver implements a set of functions to move frames between the lwIP frame storage data structures and these device-dependent buffers, executing the lock-free access protocol in the correct way. The same functions also provide useful information about ring buffer status, for instance, whether they are empty or full.

Finally, the device driver contains an interrupt handling function. In order to minimize the potential priority inversion condition associated with interrupt handler execution in a monolithic real-time kernel like FreeRTOS, interrupt handling activities have been shrunk to the bare minimum. They only consist of several instructions aimed at determining the device status and the reason of the interrupt, followed by a single V() synchronization primitive on the appropriate transmit or receive synchronization semaphore. These two semaphores constitute the synchronization interface with the transmit function and the receive task, respectively, to be discussed next.

The second module contains higher-level (and thus, less platform-dependent) components, namely, a receive task and a transmit function.

The transmit function is invoked from the main lwIP task, by means of a function call, to enqueue a frame to be transmitted. It blocks until space is available in the transmit ring buffer, by means of the transmit synchronization semaphore, and then moves the frame into it. The frame transmission proceeds asynchronously.

The receive task, once initialized, blocks on the receive synchronization semaphore until a frame is available in the receive ring buffer. At this point, it passes the frame to the main lwIP task after extracting it from the receive ring buffer. Due to the lwIP design, inter-task communication is carried out by means of a mix of message passing and shared memory. Namely, the pointer to a shared data structure, containing the received frame, is given to the main lwIP task within a message.

To enhance its portability to different operating systems and platforms, lwIP specifies and makes use of a thin software layer, called operating system emulation layer in [23], and uses it exclusively to access any operating system functions it needs. Table 2
                         summarizes the main interfaces that the operating system emulation layer must provide, according to the lwIP specification, as well as the corresponding FreeRTOS and newlib functions their implementation is based upon.

The sys_thread_new interface, invoked by lwIP to create a new task, has been directly mapped onto the corresponding FreeRTOS function xTaskCreate.

Of the three synchronization objects required by lwIP—namely, fast critical regions, binary semaphores, and mailboxes—the last two have been implemented in terms of their most intuitive FreeRTOS counterparts. As shown in Table 2, the only interface discrepancy worth noting is that, on the one hand, lwIP specifies two distinct interfaces for blocking and non-blocking operations on a mailbox, for instance, sys_mbox_post for a blocking send and sys_mbox_trypost for a non-blocking one. Instead, FreeRTOS provides both of them in terms of a single function, comprising a timeout parameter that sets an upper limit on the waiting time.

The output of lwIP trace and debugging messages, performed by means of the sys_debug interface, has been delegated to the standard C library function vprintf, provided by newlib.

One part of the adaptation layer worth considering in greater detail is how critical regions have been implemented. In fact, the most appropriate method to protect critical regions depends on how much time is spent within them, with respect to the time needed to execute the critical region entry and exit code. In the case of lwIP, they are called fast critical regions because they delineate and enforce mutual exclusion among very short regions of code, typically less than 100 machine instructions long, which do not contain any other blocking primitive.

If a critical region is so short, the usual approach of using a mutual exclusion semaphore would be inefficient, because more time would be spent entering and exiting the critical region than executing within it. For this reason, lwIP critical regions have been mapped directly on the most basic and efficient mutual exclusion mechanism of FreeRTOS, based on disabling interrupts at the beginning of the critical region, and enabling them again at the end. Obviously, this is adequate only on a single-processor system, but multi-core or multi-processor systems would not be supported anyway by FreeRTOS.

The USB-based mass storage subsystem is composed of four layers, shown in Fig. 3
                      and better described in the following. As before, the platform-dependent components—that is, the components that must be either specifically developed for, or adapted to, every combination of toolchain, operating system, and mass storage device type—are highlighted in gray.

Unlike other kinds of controller—for instance the Ethernet controller discussed in Section 3—the USB host controller interface is mostly uniform across different kinds of systems and vendors. In particular, most host controllers currently available adhere to the UHCI [25], OHCI [26], EHCI [27] or, more recently, xHCI [28] standards.

Only several minor aspects of the interface are not covered by the standards and are therefore platform-dependent. They correspond to the gray box visible in the bottom-center part of Fig. 3. For instance:
                           
                              •
                              the exact location of the bank of host controller operational registers in the address space;

the way USB controller signals are routed to the microcontroller's I/O ports;

the clock source to be used by the USB controller;

how USB controller interrupts are routed to the processor and associated with their software handler.

As a consequence, the development of a USB device driver is a relatively easy task. Furthermore, many microcontroller vendors provide the source code of an exemplar driver that works with their products and can be further extended by system developers according to their specific needs.

The LPC2468 microcontroller [2] includes an OHCI-compliant [26] USB 2.0 [29] host controller. The vendor itself provides an extremely simplified, polling-based driver as part of a larger software package fully described in [30]. In this kind of controller, all interactions between the device driver and the controller itself, after initialization, take place by reading from and writing into the controller's operational registers and by exchanging data through a shared memory area called Host Controller Communication Area (HCCA). Both the register and memory layouts are fixed and completely defined in [26].

With respect to a full-fledged host controller driver, the main limitation concerns the device enumeration algorithm, which lacks the capability of crossing USB hubs. As a consequence the driver is capable of handling only one device, directly connected to the host controller port. On the other hand, dynamic device insertion and removal are supported, so that the driver is, for instance, more than adequate to support a USB mass-storage device for data-logging purposes.

The main improvement required to make the driver work efficiently in an RTOS-based environment was to replace the polling-based, busy waiting loops provided by the original driver with a passive, interrupt-based synchronization for the two main sources of events of the controller, namely:
                           
                              1.
                              The Root Hub Status Change (RHSC) event.

The Writeback Done Head (WDH) event.

The main reason of an RHSC event is the connection or disconnection of a USB device. When a device connection is detected, the device driver reacts by issuing, first of all, a port reset command. After that, device initialization is completed by assigning an address to it and retrieving its configuration descriptor. After confirming that the device is indeed a mass storage device—an operation accomplished by the USB mass storage interface module—it is configured for use.

The WDH event is instead triggered when the USB controller has finished processing one or more Transmit Descriptors (TDs), has linked them to the Done Queue, and has successfully updated the pointer to the head of the Done Queue accessible to the device driver. This event therefore provides a convenient way for the device driver to be notified of the completion of the transfer described by a certain TD and reuse the TD for further transfers.

The main interfaces exported by the device driver are summarized in Table 3
                        . The two initialization functions listed at the top of the table prepare the host controller for use and wait for the insertion of a mass storage device, respectively. After device initialization, the other interfaces allow the caller to:
                           
                              1.
                              Send and receive control information through the device's control Endpoint Descriptor;

Send data to the device's bulk output Endpoint Descriptor;

Receive data from the device's bulk input Endpoint Descriptor.

This minimal set of capabilities corresponds to what is required by the USB mass storage interface module, to be discussed next.

A device belonging to the USB mass storage class must obey to the specifications, which are fully enumerated in are fully enumerated in [31]. Although, in principle, multiple mechanisms are specified to transport command, data, and status information to/from the device, software development was focused on the so-called bulk-only transport 
                        [32]. This is because, at least for USB flash drives, this is the simplest and most commonly supported transport.

Similarly, even if a given transport mechanism can be used with multiple command sets, depending on the kind of device and its capabilities, the most widespread choice for USB flash drives is to implement a subset of the SCSI command set 
                        [33], and hence, only this option is currently supported by the USB Mass Storage Interface layer being described. As a side note, this is also the transport/command set combination specified for use with USB floppy drives [34] and other removable USB mass storage devices, such as hard disks.


                        Table 4
                         lists the main entry points of the mass storage interface module. The first two functions are used during device initialization. Namely, the first one parses the configuration information retrieved from the device by the host controller interface driver, to check whether or not the device is supported. The main checks performed at this stage are aimed at ensuring that the device is indeed a mass storage device that understands the transport mechanism and command set discussed above.

The second function makes sure that the device is ready for use by issuing the SCSI command Test Unit Ready and waiting if necessary. The same capability is also made available to the upper software layers by means of a dedicated function (the third one in Table 4). In this way, the same check can also be performed at that level, for instance, before issuing additional commands to the device. During initialization, the block size and the total storage capacity of the device are also retrieved and returned to the caller, since this information is required by the Filesystem module.

After device initialization, the main purpose of the USB mass storage interface is to encapsulate the SCSI commands Read 10 and Write 10 into bulk-only transport messages and perform data transfer to the device by means of the Host_ProcessTD function of the host controller driver. As their names imply, these two commands are used to read and write, respectively, a number of contiguous storage blocks. These crucial functions are made available to the upper software layer by means of the last two functions listed in Table 4.

For flash drives and other kinds of removable mass storage devices, the FAT (File Allocation Table) filesystem [35] is currently the most popular choice, due to its implementation simplicity and widespread availability on a variety of operating systems and computing environments.

Accordingly, there are several open-source, portable implementations currently available, for instance [36–38], with similar characteristics and capabilities. Among them, FatFs [36] was chosen for the case study, due to its small footprint and its little requirements on the lower software layers.

Besides the main interface towards the mass storage device and the operating system, which will be discussed in Section 4.4, only two more platform-dependent modules are required to configure the filesystem module (ffconf.h) and provide appropriate type definitions for signed and unsigned 8-, 16-, and 32-bit integers (integer.h).

The main FatFs configuration options, listed in Table 5
                        , can be divided into several groups:
                           
                              1.
                              The options in the features/capabilities group make available different trade-offs between the capabilities of the Filesystem module and its speed, with respect to code/data footprint and memory requirements.

The mass storage device support option group determines how many logical drives at a time the Filesystem module can handle, the maximum sector size to be supported, and whether or not it is possible to access multiple partitions on the same device.

The system interface option group controls whether or not the Filesystem modules shall be reentrant and optionally enables file locking. Moreover, on processor architectures that support them, it is possible to enable unaligned word accesses in the Filesystem code, thus achieving a higher speed.

The last option group deserves special attention because it affects not only the footprint of FatFs itself, but also the complexity of its adaptation layer—the operating system interface in particular—and the operating system memory requirements. This is because, when reentrancy support is enabled, FatFs relies on the underlying operating system for proper synchronization among concurrent Filesystem requests. Accordingly, several additional operating system interfaces are required to declare, create, delete, and use mutual exclusion locks—called synchronization objects by FatFs.

For this specific case study, the main purpose of the mass storage subsystem is data logging, performed by a single task after collecting information from other components of the real-time system. For this reason, FatFs reentrancy has been disabled to speed up the development of the adaptation layer. On the other hand, the full set of FatFs features/capabilities has been enabled, at a small footprint cost, to make data logger development more convenient.

The purpose of the disk I/O and RTOS adaptation layers is to act as a bridge between the Filesystem module (discussed in Section 4.3), the disk input/output interfaces exported by the USB mass storage interface module (Section 4.2), and the underlying operating system services (Section 2.2). This is done in the modules diskio.c and syscall.c, respectively.


                        Table 6
                         lists the mandatory requirements of the Filesystem module and outlines how they have been mapped onto the other layers. The actual Filesystem requirements depend on its configuration and may comprise additional interfaces. The table lists the requirements corresponding to the minimal configuration described in Section 4.3.

As shown in the table, in most cases the mapping is fairly simple, because there is a one-to-one relationship between the function required by the Filesystem and what is offered by the other software modules. The main duty of the adaptation layer is, therefore, to perform argument and return code conversion.

The only exception, that is, the only operating system function required by FatFs, but not provided by FreeRTOS, is get_fattime. The Filesystem module invokes this function whenever it needs to know the current, absolute time of the day, in order to update some Filesystem information, such as the last modification time of a file.

Although FreeRTOS provides a quite accurate time base relative to the boot-up time, it does not directly support the notion of absolute time; most notably, absolute time is not kept across reboots. As a consequence, the get_fattime has been implemented directly and based upon the Real-Time Clock (RTC) hardware module of the LPC2468. This module keeps the correct time of the day even when the main power to the processor is switched off, by means of a backup power source, without operating system intervention.

Despite past and ongoing standardization efforts, many different fieldbus technologies are nowadays in use for industrial applications. It must therefore be taken into account that discussing just one of them—in order to be concise—may not provide a thoroughly complete and accurate scenario. In this case study, the well-known Modbus RTU fieldbus [6,7], using TIA/EIA-485 [4] at the physical layer, has been considered for two reasons:
                        
                           1.
                           At least one open-source implementation of the slave protocol stack, FreeMODBUS [39], is readily available. A commercial counterpart, implementing the master protocol stack, also exists and is very similar to FreeMODBUS in terms of internal architecture. Taken together, these components allow system integrators to build a complete Modbus network.

The TIA/EIA-485 physical layer is common to other kinds of fieldbus as well, most notably PROFIBUS [5]. Therefore, at least part of the portability topics that will be discussed about Modbus is very likely applicable to them as well.

The FreeMODBUS protocol stack is divided into several layers, sketched out in Fig. 4
                     . Individual layers are discussed in bottom-up order in the following sections. Platform-dependent layers are shown in gray.

The module portserial.c contains the serial port device driver. It shall implement the functions listed in Table 7
                         and must support exactly one port. Its main interfaces are:
                           
                              •
                              The xMBPortSerialInit function initializes the serial port using the communication parameters (for instance, the baud rate) passed as input arguments. The return value indicates whether or not the initialization was successful.

The vMBPortSerialClose function shuts down the serial port. It is also responsible of freeing any port-specific data structure previously allocated by xMBPortSerialInit.

The vMBPortSerialEnable function is called to selectively enable or disable the transmitting and receiving parts of the serial port. It should be noted that, as soon as the transmitter is enabled, the transmit callback function, to be discussed next, shall be immediately scheduled for execution if the transmit buffer is empty.

The two functions xMBPortSerialPutByte and xMBPortSerialGetByte interact with the serial port to start the transmission of a character and to retrieve a character that has been received, respectively. It should be noted that the first function shall return to the caller asynchronously with respect to character transmission, that is, as soon as the transmission has been scheduled. In both cases, the return value indicates whether or not the requested operation was performed successfully.

Moreover, the serial port driver must invoke two callback functions provided by the upper layer of the protocol stack when certain conditions are met. They are specified by means of the function pointers listed at the bottom of Table 7. Namely:
                           
                              1.
                              The pxMBFrameCBTransmitterEmpty callback is invoked when the serial port is ready for the transmission of a character. The callback function is supposed to either start the transmission of a new character (by calling xMBPortSerialPutByte) or disable the transmitter to avoid further notifications (when transmission is over).

The pxMBFrameCBByteReceived callback is invoked when a character has been received from the serial port. The callback function is supposed to retrieve the character (by means of xMBPortSerialGetByte) and handle it as appropriate.

The callback mechanism is used throughout the code whenever it is necessary to execute a piece of code when an event of interest occurs. Two important aspects must be considered when working with callback functions:
                           
                              1.
                              The invocation context of a callback function may not be the same as other cases. For example, when a device driver invokes a callback function, it will probably do it from an interrupt handling context, rather than a normal task context. In many operating systems—most notably, monolithic ones—this entails extra constraints on how the callback function can interact with the operating system itself. Many system calls, for instance, the ones that may block the caller, are probably unavailable in such a context.

It is also possible that the same function is invoked from different contexts on different occasions. For instance, vMBPortSerialEnable may invoke the transmit callback function directly, in order to retrieve the first character to be transmitted, whereas subsequent invocations of the same callback may take place from the serial port interrupt handler.

Callback functions are executed concurrently with respect to each other and tasks. Due to the fact that callback functions may be invoked from (possibly nested) interrupt handlers, this may happen even on a single-processor system. Therefore, a suitable mutual exclusion mechanism or lock-free data structure is required for a proper interaction between these components. For this reason, a simple critical region mechanism must be provided by the Modbus port layer, to be discussed in Section 5.2.

The two middle layers of the protocol stack, to be discussed in Sections 5.3 and 5.4, are synchronized by means of a simple event system, implemented in the module portevent.c. The main purpose of the event system, in its most general form, is to allow the upper layer to wait for an event, which is generated by the lower layer. Either active or passive wait is supported, the latter relying on operating system assistance.

It should also be noted that the event system implicitly defines a boundary between the code that consumes events (and possibly waits in the attempt) and the code that generates events (and never waits). The boundary must be considered, for instance, when designing a new data link layer for the protocol stack. Unless a separate task is introduced, the data link layer is not allowed to block internally.

The top part of Table 8
                         lists the event system interfaces, which shall implement a single event stream. In particular:
                           
                              •
                              The two functions xMBPortEventInit and xMBPortEventClose initialize and shut down the event system, respectively. They are responsible for allocating and releasing any internal data structure needed by the event system itself.

The function xMBPortEventPost is called to post an event into the event stream. Each event has an identifier of type eMBEventType attached to it, which is passed as an argument to this function in order to distinguish one class of events from another.

The function xMBPortEventGet looks for, and possibly consumes, an event. It may be implemented in two different ways, depending on whether or not the operating system supports passive wait:
                                    
                                       1.
                                       If passive wait is not available, xMBPortEventGet simply polls the event stream and returns a Boolean flag to indicate whether or not an event is present. No polling loop is required within this function, because the caller must provide it already.

Else, xMBPortEventGet shall either block the caller until an event arrives, or return immediately if an event is already in the stream.

In both cases, when an event is available, it is removed from the stream and its identifier is returned to the caller. It is important to note that the event system must be capable of storing just one pending event, before it is handled. Trying to post a new event when another one is still pending must not be flagged as an error. The event system requirements are quite flexible and it is permissible to “lose” events in this case. When we are in the situation that a new event is generated by the lower layer while there is already a pending event in the event system, it can be handled in two different ways, namely:
                           
                              1.
                              keep the pending event and ignore the new one, or

replace the pending event with the new one.

Due to the rather large degree of freedom in how the event system may be implemented, the upper layer must at least consider the following two scenarios and handle them properly:
                           
                              •
                              The xMBPortEventGet function may return to the caller (with or without waiting) and signal that no events are available. This must not be considered an error condition and the operation shall be retried.

The same function may return less events than were generated. In fact, some events may be lost when they appear close to each other. In this case, it is not specified which events are kept and which are lost with respect to their generation time. Then, the upper layer needs to rely on extra information, usually provided by the lower layer, to properly handle the events.

When using FreeRTOS, the event system can be implemented in a straightforward way by means of a message queue with a buffer capacity of one message. It provides both the required synchronization and the ability to transfer event identifiers (as message contents) between the event generation and consumption functions.

The module porttimer.c implements a single timer, exporting the interfaces listed in the middle part of Table 8. It is used to detect the end of the Modbus frame being received and corresponds to the t
                        3.5 timer defined in the Modbus RTU specification [7]. The required time granularity is 50
                        μs according to the port layer specification. This timer cannot be implemented using the FreeRTOS timer facility, because the tick frequency would need to be increased from the default of 1kHz to 20kHz and tick interrupt handling overheads would become inordinate. Instead, a direct implementation on top of one of the hardware timers has been carried out.

The timer is initialized and shut down by means of xMBPortTimersInit and vMBPortTimerClose, respectively. The timeout value is specified upon initialization and cannot be changed later. When the timer is started with vMBPortTimersEnable, it starts counting down from its timeout value. If the timer is already counting down when vMBPortTimersEnable is called—because it was started in the past and it has not expired yet—the count restarts from the original timeout value.

The function vMBPortTimersDisable can be invoked to prematurely stop a timer, that is, before its expiration. Calling vMBPortTimersDisable on a timer that is already stopped—either because of a previous call to the same function or due to expiration—is not an error, but has no effect.

It should be noted that, as in most other timeout mechanisms, there is an inherent race condition between the invocation of the premature stop function and timer expiration. Namely, it cannot be guaranteed that the timer will not expire (and its timeout function will not be invoked) during the execution of vMBPortTimersDisable.

Upon expiration, the callback function specified by the function pointer pxMBPortCBTimerExpired is invoked, possibly from an interrupt context. The timer is one-shot and stops after expiration, until it is started again.

Critical regions in the FreeMODBUS code are surrounded by the ENTER_CRITICAL_SECTION and EXIT_CRITICAL_SECTION macros, which are responsible for mutual exclusion. The code of critical region entry and exit—invoked by the above-mentioned macros—is found either in the portother.c source module or (when it is simple and short enough) directly in one of the port layer header files.

A single mutual exclusion domain is supported for the whole protocol stack. This implies unnecessary blocking but it is still acceptable, for the sake of simplicity, because critical regions are kept very short. For the same reason, in the FreeRTOS port, the two macros have been mapped to the vPortEnterCritical and vPortExitCritical system calls, respectively, like it has been done for the fast critical regions of lwIP (see Section 3.2).

A notable special case that could not happen in lwIP is when the mutual exclusion macros are invoked from an interrupt context (like it happens for most callback functions). The two system calls vPortEnterCritical and vPortExitCritical system calls are not supported in the last case, so they must not be invoked.

The issue can be solved by checking whether or not ENTER_CRITICAL_SECTION and EXIT_CRITICAL_SECTION have been invoked from an interrupt handling context by querying the CPU status register. If this is the case, the macros simply do nothing.

Since mutual exclusion is implemented by disabling interrupts, mutual exclusion with respect to both regular tasks and interrupt handlers (as well as any callback function invoked by them) is guaranteed anyway, on a single-processor system. Mutual exclusion between callback functions invoked from an interrupt handler is also implicitly enforced in the same way, as long as interrupt handlers are not themselves interruptible.

It is worth mentioning that this way of protecting critical regions may have some unforeseen interactions with other parts of the protocol stack. In particular, passive wait (for instance, within an event system function) within a critical region may not be supported in some operating systems. This is the case, for example, of FreeRTOS on Cortex-M3 processors, due to the way rescheduling is implemented.

This module implements the slave side of the Modbus RTU data link layer specified in [7]. Its main functions are:
                           
                              •
                              The eMBRTUInit function initializes the data link layer. It also calls the port layer initialization function to set up the serial port and timer, whereas the event system is initialized by the application layer initialization function, to be discussed next. Neither the serial port nor the timer is enabled yet by this function.

The functions eMBRTUStart and eMBRTUStop start up and shut down the data link layer, respectively. As part of their job, they call the port layer start and stop functions related to the serial port and timer.

The eMBRTUReceive function checks the last data link frame that has been received and is currently in the receive buffer. If the frame is valid, the function stores the data link layer information about it (destination address, length, and start of application layer data) into its output parameters. Otherwise, it returns an error indication to the caller.

The eMBRTUSend function completes the Modbus frame currently in the buffer with data link layer header and trailer information (for instance, the CRC) and starts the transmission. It returns immediately to the caller, without waiting for the transmission to finish.

The xMBRTUReceiveFSM and xMBRTUTransmitFSM functions are callback functions invoked by the serial port driver to handle the character-by-character receive and transmit process of a Modbus frame.

The xMBRTUTimerT35Expired function is called back by the port-layer timer when no characters are received from the serial port for more that 3.5 character times. The Modbus RTU protocol uses this inter-character space length to detect the end of the current frame.

An additional interface between the data link layer and the application layer (see Section 5.4) is the event system (Section 5.2). Namely:
                           
                              •
                              The eMBPoll function, residing in the application layer, either polls or waits for an event coming from the data link layer.

The data link layer functions generate events of interest for the application layer. For instance, the xMBRTUTimerT35Expired function posts the EV_FRAME_RECEIVED event to inform the application layer that a complete frame has been received and is ready for use.

As in other cases, race conditions within and between layers are avoided by means of critical regions.

This module contains code to initialize the Modbus protocol stack, configure it for a certain combination of data link and physical layers, and prepare it for use. In addition, it contains the main event handling function, a function that—invoked by the task responsible of handling Modbus transactions after protocol stack initialization—looks for incoming requests and handles them by means of the appropriate application callback function, to be discussed in Section 5.5.

The function eMBInit initializes the protocol stack as a whole, when it is configured for a TIA/EIA-485 interface bus at the physical level. In this configuration, the communication protocol can be either Modbus ASCII or Modbus RTU. As part of the initialization process, it calls the appropriate data link layer initialization function. For instance, it calls eMBRTUInit in the RTU data link layer for the Modbus RTU operating mode.

A different initialization function, eMBTCPInit, initializes the protocol stack when it is configured to work on top of TCP/IP connections (Modbus TCP), but this operating mode is beyond the scope of this discussion.

The initialization functions also set up the interface between the application, data link, and port layers. Table 9
                         lists the names of the function pointers used at the application and port layers, and gives a terse description of the function they correspond to in the Modbus RTU data link layer.

Using function pointers instead of hardwired function names for most of the interface helps to accommodate different data link layers transparently and efficiently. As a side note, referring back to Table 9, the vMBPortClose function should technically be part of the port layer, and not the data link layer. It is a shortcut to shut down all the components of the porting layer: serial port, event system, and timer.

Conversely, the eMBClose function shuts down the protocol stack, by simply invoking the corresponding port layer function through its function pointer. Similarly, the eMBEnable and eMBDisable functions enable and disable the protocol stack, respectively. They do very little by themselves, except invoking the corresponding data link functions through their function pointers.

The eMBPoll function contains the application layer protocol state machine. The protocol state machine is driven by events taken from the event system. Events are generated either by the state machine itself or by the data link layer. It should be noted that eMBPoll does not necessarily wait for events (whether or not that happens depends on the event system implementation), and hence, it can return to the caller without doing anything. This is not considered an error condition, and the function will return MB_ENOERR in this case. It is expected that calls to eMBPoll will be enclosed within a polling loop in a layer above the protocol stack.

The application callback functions are responsible of implementing Modbus requests coming from the master node and provide appropriate replies to them. They inherently depend on the application, because their contents, behavior, and interface with the other parts of the system depend on what the embedded system is supposed to do.

These functions are invoked in a peculiar way, that is, they are called back from the Modbus application layer, discussed in Section 5.4, when there is an incoming Modbus request. They must carry out the transaction on the slave node and then return to the caller with its results.

All application callback functions have a uniform interface, consisting of two arguments. For improved efficiency, those arguments are used both as inputs to the function and outputs from it. The first argument is a pointer to a message buffer. The callback function finds the incoming request there, and it must use the same buffer to store the reply. The second argument points to an integer variable. Upon callback invocation this variable contains the length of the incoming message, and the callback function shall store into it the length of the reply before returning.

To avoid multiple PDU copies through the protocol stack, callback functions are trusted to fill the message buffer starting at a fixed index. The buffer elements before that index are reserved for data link headers.

The link between the application layer and the callback functions is configurable, by means of the xFuncHandlers array. Each element of this array, of type xMBFunctionHandler, associates a Modbus function code with the callback function to be called when there is an incoming request bearing that function code. Besides static initialization, the array can also be modified by means of the eMBRegisterCB application layer function. This function is able to remove an existing association between a function code and a callback function or to establish a new one.

The experimental evaluation took place on a prototype implementation of the embedded system described in the previous sections, realized on an Embedded Artists' LPC2468 OEM board [40]. It was focused on memory requirements and achieved performance, two important performance indicators in embedded system design.

Memory requirements represent an important design constraint in small-scale embedded systems, often even more than performance requirements. In fact, many low-cost microcontrollers lack an external memory interface, and hence, the whole software load must necessarily fit in the on-chip Flash and RAM memories.

Even when an external memory interface is indeed available—as it is the case for the microcontroller considered in this case study—the cost, size, and complexity of the additional components needed to implement an external memory, as well as their interconnection through the printed circuit board, are likely to be a significant drawback.

For this reason, the memory footprint of the components discussed in Sections 3–5 and the FreeRTOS operating system has been evaluated to check whether or not it is acceptable in practice. The results are shown in Table 10
                        . They have been obtained by building the components from their source code, by means of the toolchain described in Section 2.2.

The footprint has been evaluated by means of the size command of binutils and is broken down into three categories, or segments: text (executable code), data (initialized data), and bss (uninitialized data). This distinction is especially important in an embedded system because the three categories correspond to different kinds of memory. Namely, the text segment must be stored in a (nonvolatile) Flash memory, while the bss segment takes space in RAM. The data segment must be allocated both in Flash and RAM, because the Flash memory holds the initial contents of the segment, which is copied into RAM during system initialization. The RAM memory image of the segment is used as read–write storage thereafter.

As it can be seen, the memory requirements are quite acceptable and well within the amount of on-chip memory of the LPC2468. Overall, the components discussed in this paper take about 150kB of Flash memory out of 512kB (29%) and about 37kB of RAM memory out of 96kB (38%), so that plenty of space is still available to the application code without resorting to external memory.

The rather large bss space taken by the “tcpip” task and utility modules of lwIP, as well as the FreeRTOS platform-independent modules, can be easily justified by observing that:
                           
                              •
                              The lwIP utility modules allocate the memory pools used by both lwIP itself and network applications for network buffers and other network-related data structures, like connection descriptors and protocol state vectors. The configuration used in the case study is adequate to support an embedded web server.

The platform-independent FreeRTOS modules contain the heap from which the operating system allocates its internal data structures, for instance, task descriptors. The required heap size mainly depends on the number of tasks, because the largest object allocated there is the per-task stack. The configuration used in the case study supports a minimum of 6 tasks.

Moreover, it is often possible to further reduce the footprint of the components by means of an appropriate configuration. For instance, the lwIP configuration used in the case study includes support for both TCP and UDP for generality. If one of these protocols is not used by the application, it can be removed from the configuration and the memory required by it can be put for other uses.

It should also be noted that the amount of memory required by the C language library has not been quantified, because it strongly depends on the application code. In fact, the library modules are included in the executable image only on-demand and the system components discussed in Sections 3–5 by themselves require only a few of them, whereas the library usage by the application code is usually much heavier. Just listing the memory requirements of the library modules needed by the system components would have been misleadingly optimistic.

The performance of the major components of the embedded system considered in the case study has been evaluated individually, by means of synthetic test programs representing realistic workloads. Preliminary experiments carried out on the Modbus RTU fieldbus software module, described in Section 5, have shown that the speed of that subsystem is limited by the maximum speed of the TIA/EIA-485 physical layer interface used in the experiments (38,400b/s) and not by software overheads. For this reason, no further software performance information will be provided about that module.

It is common to see that Modbus RTU segments are connected to a Modbus TCP backbone in various application areas, for instance, factory and building automation. At the same time, with this kind of system, it is quite convenient to perform remote configuration, firmware update, maintenance and so on. As a result, the performance of the TCP/IP protocol stack, described in Section 3, has been evaluated by means of a testbed implementing the Modbus TCP application-layer protocol on two identical embedded boards. The Modbus protocol stack used for the experiments is layered on the POSIX sockets API. The average round-trip time RTT(n) obtained when exercising a typical Modbus application-layer primitive (write multiple registers) was evaluated for a varying number of registers n. The results are shown in Table 11
                           .

As shown in the table, the RTT exhibits a linear dependency on the number of registers being written. The overall performance of the communication delay is around 7ms for all legitimate values of n. This is considered to be adequate for networked embedded systems [41].

The RTT is dominated by software processing time, as the Ethernet data transfer time never exceeds 30
                           μs, even for the longest Modbus PDU. This is two orders of magnitude smaller than the measured RTT. The software processing time can be easily justified by the complexity of the communication software which includes the Modbus TCP protocol stacks (both the Master and the Slave sides) and an lwIP-specific adaptation layer, which makes use of the POSIX sockets API, the lwIP protocol stack as well as FreeRTOS. Since, for each write multiple registers command issued by the Modbus master, a reply from the slave is expected, it indicates that the RTT comprises two receive-path delays and two transmit-path delays through the whole protocol stacks.

The worst-case communication jitter encountered is around 1.2ms in all experiments. It can be easily reduced to 900
                           μs by an improved priority assignment to existing tasks so that the Ethernet receive task and the main lwIP task will interfere as little as possible with Modbus TCP message processing. Among the remaining jitter, it is found that about 450
                           μs is contributed by the non-deterministic choice between the transmission of a pure acknowledgment (ACK) and a piggybacked ACK on a TCP data segment.

Since the USB-based mass storage subsystem discussed in Section 4 will presumably be used for data logging, its performance was evaluated by considering sequential read and append operations with different data chunk sizes. Table 12
                            shows the read and append rates r(d) and a(d), respectively, as a function of the data chunk size d. The rates have been calculated by averaging the time needed to transfer 100MB of data.

The first three values of d are a sub-multiple of the sector size used by the filesystem, that is, 512B. This ensures that read and append operations never cross a sector boundary and makes the measurement adequate to determine the relative contribution of software overheads, which are inversely proportional to d, with respect to the total number of USB I/O operations, which are constant across the experiments.

The experimental results in this group exhibit a strong dependency on d for what concerns both read and append rates. Namely, the ratio between whole-sector operations (d
                           =512) and operations typical of fine-grained data logging (d
                           =16) is about one order of magnitude and is likely to affect application-level software design. The lower performance of append with respect to read (from -2% to -15% depending on d) can easily be justified by considering that appending to a file incurs extra overhead because it is necessary to update the file allocation table information on the Filesystem as new blocks are linked to the file being appended to. In addition, write operations on a flash drive may be slower than reads due to the significant amount of time needed to erase flash memory blocks before writing.

The fourth value of d is the smallest prime number greater than the sector size. The value has been chosen in this way to keep software overheads related to I/O requests from the application program as close as possible to the case d
                           =512 and, at the same time, maximize the probability that read and append operations cross a sector boundary. In this way, it was possible to evaluate the extra overhead introduced in this scenario. The experimental results show that the additional overhead does not exceed 2%, thus confirming the satisfactory behavior of the Filesystem module.

The challenging requirements typical of contemporary embedded systems put a renewed emphasis on several important software design aspects like adherence to standards, portability, and fast time to market. At the same time, their ever increasing complexity demands modularity, reuse, and easiness of integration among software components.

In this respect, open-source software has the potential of addressing most of those concerns, as testified by its success in office automation. However, it is not yet in widespread use elsewhere—like in the embedded system domain—because the internal structure of open-source software components is often little known and software developers are not familiar with it.

In this case study, we have shown that it is possible—with limited effort—to build a full-fledged embedded system ready to be connected to the Internet, a real-time fieldbus, and a commodity USB mass-storage device, by using only readily-available, open-source components. The overall memory requirements have been measured, too, and they are well within what can be accommodated on-chip on a low-cost microcontroller.

Possible areas of applications for this kind of embedded devices include, for instance, monitoring instruments for power generators [42], data acquisition systems [43], brain–computer interfaces [44] and, more in general, control systems for consumer electronic products. For many of these application areas, other researchers highlighted the benefits stemming from remote diagnostic and firmware upgrade capabilities through an Internet connection [45].

The results can be used as a design guideline for other similar projects and as a reference to the internal structure and external interfaces of the components being discussed. In addition, they represent a starting point to look at how other open-source components addressed the same design issues in several key areas—like portability, synchronization and communication among concurrent code.

@&#REFERENCES@&#


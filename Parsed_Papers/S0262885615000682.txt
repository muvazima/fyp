@&#MAIN-TITLE@&#Approaches for automatic low-dimensional human shape refinement with priors or generic cues using RGB-D data

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel and accurate method to refine low dimensional human shape using RGB-D data is proposed.


                        
                        
                           
                           Uses of multiple modalities do not carry any features from the shape provider.


                        
                        
                           
                           Combines low and high level observations jointly in multi-layer graph structure


                        
                        
                           
                           Extensive experiments showed that it outperforms compared suitable algorithms.


                        
                        
                           
                           Also, an existing method is extended by fusing more generic cues for this purpose.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Human shape refinement using RGB-D data

Multi-layer graph cut

Human body shape descriptor

Random decision forests

Refinement of low-dimensional representations

RGB-D

@&#ABSTRACT@&#


               
               
                  Some human detection or tracking algorithms output a low-dimensional representation of the human body, such as a bounding box. Even though this representation is enough for some tasks, a more accurate and detailed point-wise representation of the human body is more useful for pose estimation and action recognition. The refinement process can produce a point-wise mask of the human body from its low-dimensional representation. In this paper, we tackle the problem of refining low-dimensional human shapes using RGB-D data with a novel and accurate method for this purpose. This algorithm combines low-level cues such as shape and color, and high level observations such as the estimated ground plane, in a multi-layer graph cut framework. In our algorithm, shape prior information is learned by training a classifier. Unlike some existing work, our method does not utilize or carry features from the internal steps of the methods which provide the bounding box, so our method can work on the outputs of any similar shape providers. Extensive experiments demonstrate that the proposed technique significantly outperforms other suitable methods. Moreover, a previously published refinement method is extended by incorporating more generic cues to serve this purpose.
               
            

@&#INTRODUCTION@&#

Detecting and tracking humans are important tasks for a wide range of computer vision applications, such as human behavior understanding, surveillance systems, autonomous driving, interactive games, and gesture recognition. A rough low-dimensional representation of the human, such as a bounding box, is commonly output by human detection and tracking algorithms [1–14].

Even though this representation is enough for some tasks, a more accurate and detailed point-wise representation is useful to obtain better object descriptors which could be more beneficial for action recognition [15,16] and pose estimation tasks [17,18]. It is possible to obtain a point-wise representation of a human from a low-dimensional representation, a process which can be called shape refinement. An illustration of this process using color and depth images can be seen in Fig. 1
                     .

The refinement of a low-dimensional human shape representation is a challenging problem. Several reasons make this process difficult. Representation of the human, most commonly a bounding box in an image, B(x,y,w,h), where x and y is the top left point, w is the width, and h the height of the box, not only contains the human points, but it also includes some background points. The background in the bounding box might have colors, texture, or 3-D geometric features which are similar to those of the human. Additionally, the human might be standing in any position, which causes pose variance and possible self-occlusion of body parts. All of these factors make the refinement process complicated. On the other hand, the bounding box representation provides some hints about the appearance and color of the object. Also, a smaller search space is given to label the points as foreground/background, and the existence of a human in the box is guaranteed. These hints and advantages do not exist if the human body points need to be found and segmented in the entire image space.

In this paper, a novel algorithm which combines low- and high-level observations obtained from RGB-D data in a multi-layer graph cut framework is proposed for refining a low-dimensional representation of the human shape—a bounding box B(x,y,w,h). We assume that this representation is provided by some other human detection or tracking method. The proposed algorithm does not leverage the internal computations of the methods which provide the bounding box. Hence, it is generic and applicable on the output of any kind of method which produces a similar low-dimensional human shape. A point-wise descriptor is built to employ the shape information of the point neighborhood. This powerful descriptor utilizes the depth data of the scene by generating three cues that are (1) relative geodesic and (2) vectorial spatial distances of a point to the middle point of B(x,y,w,h), and (3) the local structure information encoded as the normal. The descriptors are used to train a Random Forest machine learning algorithm [19] which favors the most important cues in the descriptor. Multiple low- and high-level observations–e.g. the point-wise confidence scores output by the classifier, the color, and estimated ground plane–are combined jointly in a multi-layer graph. The proposed method outperforms existing comparable algorithms in our experiments.

Moreover, a previously published graph cut-based refinement algorithm [20] is extended to serve the same purpose. This method does not incorporate any prior information which must be learned by a classifier as in our first proposed technique. It fuses three generic cues: the color, the depth, and the normal of the points obtained from a single color and depth (RGB-D) image.

A review of related work is summarized in the next section. The human shape descriptor, the proposed classifier, and integration of low- and high-level observations in the multi-layer graph are described in Section 3. The generic cues, and the details of the extended graph cut-based method are explained in Section 4. Experimental results of the proposed and extended methods are analyzed in Section 5. Finally, the proposed work is summarized and possible extensions of this work are drawn in the last section.

@&#RELATED WORK@&#


                     GrabCut 
                     [21] can be considered as one of the most suitable methods which obtains features from a color image for the refinement of a low-dimensional human shape estimate. GrabCut is designed as a semi-automatic segmentation algorithm which takes a box surrounding the object as the input. Gaussian Mixture Models of the object and background are formed by using the regions inside and outside of the input box. Graph cut [22,23] is applied iteratively by feeding the models. At the end of each iteration, border matting is performed to achieve smooth and more accurate results.

The algorithm explained in [24] does not particularly aim to refine the low-dimensional human shape, but it simultaneously detects and obtains person silhouette by integrating top-down and bottom-up approaches in a balanced way. In this method, the pedestrians are simultaneously detected and segmented by integrating appearance and motion cues. It learns the silhouette information from the training data.

Some refinement methods leverage features or confidence scores taken from the internal steps of the methods which provide the low-dimensional human shape [25–29]. These methods do not follow a generic way to refine any given low-dimensional human shape. Hence, they depend on their rough shape estimators. The human silhouette cue computed by the HOG classifier [1] builds the essential parts of the human model used in [27–29]. The faces of the humans are detected by Haar-like features [34] and help to initialize the seed points of GrabCut in [28,29]. The method explained in [25] uses some features obtained by applying a human body part detector. A pre-processing step which utilizes Edgelet features defines the region of the interest in [26]. Then, the points of the human body are segmented in this region [26]. Humanising GrabCut 
                     [30] is a specialized version of GrabCut method to refine the low-dimensional human shape. The predictions of the HOG detector are used to build the appearance models to initialize GrabCut.

Applying background subtraction techniques is another common approach to segment human body points. The main disadvantage of these methods is that they cannot readily be deployed on moving platforms such as autonomous vehicles. [32,31] introduce multimodal background models for labeling the human points in the scene. They combine the features obtained from thermal and color cameras, where a Gaussian distribution forms a temperature model for the human body and the background models of each pixel in the color image are described by a list of codewords. In [33], the texture and color of each pixel in the image are modeled to segment the humans in indoor scenes. In addition to the image-based features, [35] integrates the shape and height of the human, and the camera model.

The evaluation of methods which are specifically designed for low-dimensional human shape refinement or suitable for this purpose according to different criteria is shown in Table 1
                     . The second column in this table indicates the methods which take a bounding box to refine.

The method proposed in this section combines in one joint graph cut framework the low-level observations that are the point neighborhood shape and the color information of the point, and a high-level observation that is the estimated ground plane. The point neighborhood shape information of the human body is learned by training a classifier.

A point-wise descriptor is formed for each point in the image. The point-wise descriptor, f
                        
                           s
                        , utilizes the 3-D point cloud of the scene, so the depth image of the scene is converted to a 3-D point cloud. f
                        
                           s
                         includes the following shape-related cues:
                           
                              1)
                              Normals: A cue about the local shape information surrounding the point, p
                                 
                                    i
                                 , can be encoded in the descriptor, f
                                 
                                    s
                                 , by calculating the normal, η
                                 
                                    i
                                 , of the point, p
                                 
                                    i
                                 . It is computed for all three dimensions of the point cloud space, η
                                 
                                    i
                                 
                                 =(η
                                 
                                    x
                                 ,
                                 η
                                 
                                    y
                                 ,
                                 η
                                 
                                    z
                                 ). The neighborhood search of the points is performed by building a FLANN-based Kd-tree [36] to reduce the computation time.

Vectorial Spatial Distance: First, the middle point, mid
                                 
                                    B
                                 
                                 =(mid
                                 
                                    x
                                 ,
                                 mid
                                 
                                    y
                                 ,
                                 mid
                                 
                                    z
                                 ), of the bounding box, B(x,y,w,h), is calculated as formulated in the following equations:
                                    
                                       (1)
                                       
                                          m
                                          i
                                          
                                             d
                                             B
                                             
                                                2
                                                D
                                             
                                          
                                          =
                                          
                                             
                                                x
                                                +
                                                w
                                                /
                                                2
                                                ,
                                                y
                                                +
                                                h
                                                /
                                                2
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       (2)
                                       
                                          m
                                          i
                                          
                                             d
                                             B
                                          
                                          ←
                                          T
                                          
                                             
                                                m
                                                i
                                                
                                                   d
                                                   B
                                                   
                                                      2
                                                      D
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where T is the function which gives the corresponding 3-D location of a pixel in the image. The vectorial distance relative to the middle point of B(x,y,w,h), Δ
                                 
                                    v
                                 
                                 =(Δ
                                 
                                    x
                                 ,
                                 Δ
                                 
                                    y
                                 ,
                                 Δ
                                 
                                    z
                                 ), is computed for the point p
                                 
                                    i
                                 
                                 =(p
                                 
                                    x
                                 ,
                                 p
                                 
                                    y
                                 ,
                                 p
                                 
                                    z
                                 ). This computation can be formulated as:
                                    
                                       (3)
                                       
                                          
                                             Δ
                                             v
                                          
                                          =
                                          
                                             
                                                
                                                   p
                                                   x
                                                
                                                −
                                                m
                                                i
                                                
                                                   d
                                                   x
                                                
                                                ,
                                                
                                                   p
                                                   y
                                                
                                                −
                                                m
                                                i
                                                
                                                   d
                                                   y
                                                
                                                ,
                                                
                                                   p
                                                   z
                                                
                                                −
                                                m
                                                i
                                                
                                                   d
                                                   z
                                                
                                             
                                          
                                          .
                                       
                                    
                                 
                              

Geodesic Distance: As mentioned in [37], the geodesic distance between two points on the human body is constant in different poses. This cue is incorporated into our descriptor, f
                                 
                                    s
                                 . The relative geodesic distance, GD
                                 
                                    i
                                 , to the middle point, mid
                                 
                                    B
                                 , of the point, p
                                 
                                    i
                                 , is computed by Dijkstra's Shortest Path Algorithm. The image is converted to a graph, G(V,
                                 E), where V is the graph nodes, and E is the edges between the nodes. Each point, p
                                 
                                    i
                                 , in the image is represented as a node in the graph, G(V,
                                 E). The neighbors of each node in the graph are restricted to 4pixels. The edge weight, w
                                 
                                    ij
                                 , between two points is set to the Euclidean distance between p
                                 
                                    i
                                  and p
                                 
                                    j
                                  in the corresponding point cloud of the scene as in Eq. (4).
                                    
                                       (4)
                                       
                                          
                                             w
                                             
                                                i
                                                j
                                             
                                          
                                          =
                                          
                                             
                                                |
                                                
                                                   p
                                                   
                                                      i
                                                      x
                                                   
                                                
                                                −
                                                
                                                   p
                                                   
                                                      j
                                                      x
                                                   
                                                
                                                |
                                                
                                                   
                                                   2
                                                
                                                +
                                                |
                                                
                                                   p
                                                   
                                                      i
                                                      y
                                                   
                                                
                                                −
                                                
                                                   p
                                                   
                                                      j
                                                      y
                                                   
                                                
                                                |
                                                
                                                   
                                                   2
                                                
                                                +
                                                |
                                                
                                                   p
                                                   
                                                      i
                                                      z
                                                   
                                                
                                                −
                                                
                                                   p
                                                   
                                                      j
                                                      z
                                                   
                                                
                                                |
                                                
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              

If there is no depth data is available for the neighbor, the edge weight, w
                                 
                                    ij
                                  is assigned a large distance.

A sample geodesic distance map for the given image can be seen in Fig. 2
                                 .

The proposed point-wise human shape descriptor, f
                                 
                                    s
                                 , is the combination of the normal, η
                                 
                                    i
                                 , vectorial distance, Δ
                                 
                                    v
                                 , and geodesic distance, GD
                                 
                                    i
                                  of a point p
                                 
                                    i
                                 . Then, fs becomes:
                                    
                                       (5)
                                       
                                          
                                             f
                                             s
                                          
                                          =
                                          
                                             
                                                
                                                   
                                                      η
                                                      x
                                                   
                                                   
                                                   
                                                      η
                                                      y
                                                   
                                                   
                                                   
                                                      η
                                                      z
                                                   
                                                   
                                                   
                                                      Δ
                                                      x
                                                   
                                                   
                                                   
                                                      Δ
                                                      y
                                                   
                                                   
                                                   
                                                      Δ
                                                      z
                                                   
                                                   
                                                   G
                                                   
                                                      D
                                                      i
                                                   
                                                
                                             
                                             T
                                          
                                          .
                                       
                                    
                                 
                              

The human refinement task can be considered as a 2-label classification problem. In short, the label of the first class is “human”, while the other label is for the non-human points and is called “background”. In order to train a point-wise human classifier, H-Classifier, positive human descriptors, f
                        
                           s
                        
                        +, and negative human descriptors, f
                        
                           s
                        
                        −, are necessary. The samples of f
                        
                           s
                        
                        − are chosen from the non-human body points of the scene.

Randomized Decision Forests are a state of the art, fast, and effective machine learning technique [38,19,39,40] which are suitable and applicable for wide range of different tasks and problems [41–43]. Therefore, it is used to train H-Classifier. A Decision Forest consists of some number, T, of decision trees. A tree includes split and leaf nodes. Each split node consists of an axis, f
                        
                           s
                        (x), of f
                        
                           s
                        , and a threshold τ. To classify the given descriptor of a point, f
                        
                           s
                        , the split nodes of the decision tree are evaluated by starting from the root of the tree. Whenever a leaf node is hit in a tree, t, a decision distribution, P
                        
                           t
                        (d|f
                        
                           s
                        ), is obtained.

In the case of low-dimensional human shape refinement problem, P
                        
                           t
                        (d|f
                        
                           s
                        ) can be considered as a 2-bin histogram. The labels of this histogram are the human and background. The result label of the randomized decision forest classifier can be the average of all distributions given by the trees in the forest:
                           
                              (6)
                              
                                 P
                                 
                                    
                                       d
                                       |
                                       
                                          f
                                          s
                                       
                                    
                                 
                                 =
                                 
                                    1
                                    T
                                 
                                 
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       T
                                    
                                    
                                 
                                 
                                    P
                                    t
                                 
                                 
                                    
                                       d
                                       |
                                       
                                          f
                                          s
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Or the result can be the label with the maximum number of votes by each decision tree, t, in the forest as formulated in the following equations:
                           
                              (7)
                              
                                 
                                    L
                                    t
                                 
                                 
                                    
                                       
                                          P
                                          t
                                       
                                       
                                          
                                             d
                                             |
                                             
                                                f
                                                s
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             
                                             if
                                             
                                             
                                                P
                                                t
                                             
                                             
                                                
                                                   
                                                      d
                                                      H
                                                   
                                                   |
                                                   
                                                      f
                                                      s
                                                   
                                                
                                             
                                             ≥
                                             
                                                P
                                                t
                                             
                                             
                                                
                                                   
                                                      d
                                                      B
                                                   
                                                   |
                                                   
                                                      f
                                                      s
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             −
                                             1
                                          
                                          
                                             
                                             otherwise
                                          
                                       
                                    
                                 
                              
                           
                        where L
                        
                           t
                        (x) is the decision label function of a given decision distribution of a tree, and t. d
                        
                           H
                         and d
                        
                           B
                         are the bin values of the human and background labels in the distribution. The normalized confidence score of a point which belongs to the human region becomes:
                           
                              (8)
                              
                                 
                                    C
                                    i
                                 
                                 =
                                 0.5
                                 +
                                 
                                    1
                                    T
                                 
                                 
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       T
                                    
                                    
                                 
                                 L
                                 
                                    
                                       
                                          P
                                          t
                                       
                                       
                                          
                                             d
                                             |
                                             
                                                f
                                                s
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Then, the final decision label of the forest, L(P(d|f
                        
                           s
                        )) becomes:
                           
                              (9)
                              
                                 L
                                 
                                    
                                       P
                                       
                                          
                                             d
                                             |
                                             
                                                f
                                                s
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             
                                             if
                                             
                                             
                                                C
                                                i
                                             
                                             ≥
                                             0.5
                                          
                                       
                                       
                                          
                                             −
                                             1
                                          
                                          
                                             
                                             otherwise
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Each tree is trained on a different set of randomly selected positive and negative samples using the following algorithm [42]:
                           
                              1)
                              Randomly obtain a set of splitting candidates for a tree node, Φ=(f
                                 
                                    s
                                 (x),
                                 τ). f
                                 
                                    s
                                 (x) is an axis of a point-wise descriptor, and τ is the split threshold.

The set of training points, S
                                 ={p
                                 
                                    i
                                 }, are divided into two sets, S
                                 
                                    l
                                  and S
                                 
                                    r
                                 , for left and right leaves of the node by each Φ:
                                    
                                       (10)
                                       
                                          
                                             S
                                             l
                                          
                                          
                                             Φ
                                          
                                          =
                                          
                                             
                                                
                                                   p
                                                   i
                                                
                                                
                                                |
                                                
                                                
                                                   f
                                                   s
                                                
                                                
                                                   x
                                                
                                                ≤
                                                τ
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       (11)
                                       
                                          
                                             S
                                             r
                                          
                                          
                                             Φ
                                          
                                          =
                                          S
                                          
                                          −
                                          
                                          
                                             S
                                             l
                                          
                                          
                                             Φ
                                          
                                          .
                                       
                                    
                                 
                              

Find the best splitting candidate, Φ*, which produces the largest information gain:
                                    
                                       (12)
                                       
                                          
                                             Φ
                                             *
                                          
                                          =
                                          
                                             
                                                argmax
                                                G
                                                
                                                   Φ
                                                
                                             
                                             Φ
                                          
                                       
                                    
                                 
                                 
                                    
                                       (13)
                                       
                                          G
                                          
                                             Φ
                                          
                                          =
                                          H
                                          
                                             S
                                          
                                          −
                                          
                                             
                                                ∑
                                                
                                                   ψ
                                                   ∈
                                                   
                                                      
                                                         l
                                                         ,
                                                         
                                                         r
                                                      
                                                   
                                                
                                             
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      S
                                                      w
                                                   
                                                   
                                                      Φ
                                                   
                                                
                                             
                                             
                                                S
                                             
                                          
                                          H
                                          
                                             
                                                
                                                   S
                                                   w
                                                
                                                
                                                   Φ
                                                
                                             
                                          
                                       
                                    
                                 where H(S) is the Shannon Entropy. It is computed on the normalized distribution of the labels of the points in the set of S as in the following equation:
                                    
                                       (14)
                                       
                                          H
                                          
                                             S
                                          
                                          =
                                          −
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                          
                                          Pr
                                          
                                             
                                                
                                                   l
                                                   i
                                                
                                                |
                                                
                                                   P
                                                   L
                                                
                                             
                                          
                                          
                                          l
                                          o
                                          
                                             g
                                             2
                                          
                                          Pr
                                          
                                             
                                                
                                                   l
                                                   i
                                                
                                                |
                                                
                                                   P
                                                   L
                                                
                                             
                                          
                                       
                                    
                                 where P
                                 
                                    L
                                  is the label distribution in the set S, and l
                                 
                                    i
                                  is the label name.

If the current depth of the tree is under a maximum threshold, create left and right children of the current node by using left and right subsets, S
                                 
                                    l
                                 (Φ*) and S
                                 
                                    r
                                 (Φ*).

Graph cut [44,22,23,45] provides a powerful framework to produce globally optimal segmentation results. Its graph structure enables the combination of multiple different kinds of features in one joint framework. In our approach, graph cut is chosen as the infrastructure to incorporate the cues for a joint final solution.

It is difficult to generalize the color models of the human and background for all possible scenes. The point-wise descriptor, f
                        
                           s
                        , described in the previous section does not include the color cue of the human body. However, the refinement procedure can utilize the discontinuity of the color between points in the scene. This can be achieved by employing the color discontinuity in the graph cut framework.

The idea of putting high-level observations into graph cut was first introduced in [46]. In order to incorporate high-level observations, a second layer of nodes are added to the standard first layer of the nodes. Each node in the second layer represents a high-level observation defined by a group of the points in the first layer. In our case, one node is added to the second layer to represent the estimated ground plane points. The interactions between the first and second layers are established in a way that a second-layer node is connected to some of the nodes in the first level. These connected nodes in the first level define the high-level observation.

All points of a high-level observation could be treated as the background. However, there is an important drawback of this assumption. If the high-level observation is obtained by some estimation process, they might include some foreground points. For example, some points of the foot are estimated as the ground plane points as can be seen in Fig. 3
                        . In the graph cut framework, it is desirable to state two attributes of these points. First, they all together define an observation. Second, some of the points within this observation might be misclassified by the estimator, and these are subject to modification of their labels.

A multi-layer undirected graph, G
                           
                              Multi
                           
                           =(V,
                           
                              E
                           ), is defined by a set of nodes, V, and a set of edges, 
                              E
                           . The set of nodes consists of two subsets. The first subset of the nodes, V
                           
                              L
                           , are the first-layer nodes which represent the low-level observations. Each point in the scene is defined by a node, n
                           
                              i
                           , where n
                           
                              i
                           
                           ∈
                           V
                           
                              L
                           . The second subset of the nodes, V
                           
                              H
                           , represents the high-level observations employed in the second layer of the graph G. In our case, V
                           
                              H
                            consists of a single node, n
                           
                              H
                           , which is for the estimated ground plane. Thus, the set of the nodes, V, becomes V
                           ={n
                           1,…,
                           n
                           
                              k
                           }∪{n
                           
                              H
                           }, where k is the number of the points in the image.

The set of edges, 
                              E
                           , consists of two types. The low-level interactions between the points in the first layer are formed by a subset of the edges, denoted by 
                              E
                           
                           
                              L
                           . 
                              E
                           
                           
                              L
                            consists of the edges, e
                           
                              i,j
                           , between two neighbor nodes, n
                           
                              i
                            and n
                           
                              j
                           , in V
                           
                              L
                           . The connections between the low- and high-level observations are established by the edges, 
                              E
                           
                           
                              H
                           . Each node, n
                           
                              i
                           
                           ∈
                           V
                           
                              L
                           , in the low-level, is connected to the node, n
                           
                              H
                           
                           ∈
                           V
                           
                              H
                           , in the second level by the edges, e
                           
                              i,H
                           . Thus, 
                              E
                            becomes 
                              E
                           
                           ={e
                           1,2,…,
                           e
                           
                              i,j
                           ,…,
                           e
                           
                              k
                              −1,k
                           }∪{e
                           1,H
                           ,…,
                           e
                           
                              k,H
                           }. The structure of the multi-layer graph is illustrated in Fig. 4
                           .

Segmentation of the multi-layer graph, G
                           
                              Multi
                           
                           =(V,
                           
                              E
                           ), is equivalent to assigning a label l
                           
                              i
                           , from a set of labels, {l
                           
                              H
                           ,
                           l
                           
                              B
                           }, to each node, n
                           
                              i
                           , in V. In this case, l
                           
                              B
                            refers to the background, and l
                           
                              H
                            refers to human points. The set of all labels assigned to the nodes in V is denoted by 
                              
                                 L
                                 ˜
                              
                           . The final mask of the human is formed by the points whose labels are assigned to l
                           
                              H
                            by the graph cut algorithm.

The energy function of the multi-layer graph cut consists of two terms, namely the regional term, R, and the boundary term, B, as in the standard graph cut energy equation:
                              
                                 (15)
                                 
                                    E
                                    
                                       
                                          L
                                          ˜
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             i
                                             ∈
                                             V
                                          
                                       
                                       
                                    
                                    R
                                    
                                       
                                          l
                                          i
                                       
                                    
                                    +
                                    
                                       
                                          ∑
                                          
                                             
                                                i
                                                j
                                             
                                             ∈
                                             V
                                          
                                       
                                       
                                    
                                    
                                       B
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    
                                       
                                          l
                                          i
                                       
                                       
                                          l
                                          j
                                       
                                    
                                 
                              
                           where i and j are the nodes of any edge, e
                           
                              i,j
                           , in 
                              E
                           .

The regional term of the multi-layer graph cut employs the confidence score of the H
                           −
                           Classifier, 
                              
                                 C
                                 i
                              
                           , for each point as defined in Eq. (8). Also, the high-level observation which is the ground plane estimation is incorporated into the regional term. More precisely, the regional term of the multi-layer graph cut energy function becomes:
                              
                                 (16)
                                 
                                    
                                       
                                          ∑
                                          
                                             i
                                             ∈
                                             V
                                          
                                       
                                       
                                    
                                    R
                                    
                                       
                                          l
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             i
                                             ∈
                                             
                                                V
                                                L
                                             
                                          
                                       
                                       
                                    
                                    −
                                    ln
                                    
                                       
                                          
                                             p
                                             c
                                          
                                          
                                             
                                                l
                                                i
                                             
                                          
                                       
                                    
                                    +
                                    α
                                    
                                       
                                          
                                             H
                                             L
                                          
                                          
                                             
                                                l
                                                H
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

The first term in the above equation describes the confidence score of H
                           −
                           Classifier. The second term defines the high-level observation. α sets the relative influence between the two terms.

The likelihood of being in the object region of a point, p
                           
                              c
                           , is formulated using the confidence score, 
                              
                                 C
                                 i
                              
                           , produced by H
                           −
                           Classifier as following:
                              
                                 (17)
                                 
                                    
                                       p
                                       c
                                    
                                    
                                       
                                          l
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   C
                                                   i
                                                
                                             
                                             
                                                
                                                if
                                                
                                                l
                                                =
                                                "
                                                human
                                                "
                                             
                                          
                                          
                                             
                                                1
                                                −
                                                
                                                   C
                                                   i
                                                
                                             
                                             
                                                
                                                if
                                                
                                                l
                                                =
                                                "
                                                background
                                                "
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        


                           
                              H
                           
                           
                              L
                            defines the likelihood function of the high-level observation node for a given label, l
                           
                              H
                           . 
                              H
                           
                           
                              L
                           (l
                           
                              H
                           ) is set to 1 if l
                           
                              H
                            is background and 0 if l
                           
                              H
                            is foreground. In our case, the estimated ground plane is considered simply as the background.

The color discontinuity and the interactions between low- and high-level observations are defined in the boundary term of the energy function, 
                              E
                              
                                 
                                    L
                                    ˜
                                 
                              
                           . As in [47], the color discontinuity between neighbor points in the first layer of the graph is formed by the following equation:
                              
                                 (18)
                                 
                                    B
                                    −
                                    Colo
                                    
                                       r
                                       
                                          i
                                          ,
                                          j
                                          ∈
                                          
                                             V
                                             L
                                          
                                       
                                    
                                    =
                                    
                                       λ
                                       1
                                    
                                    
                                       1
                                       
                                          dist
                                          
                                             i
                                             j
                                          
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          
                                             
                                                |
                                                |
                                                
                                                   c
                                                   i
                                                
                                                −
                                                
                                                   c
                                                   j
                                                
                                                
                                                   
                                                      |
                                                      |
                                                   
                                                   2
                                                
                                             
                                          
                                          /
                                          2
                                          
                                             σ
                                             2
                                          
                                       
                                    
                                 
                              
                           where c
                           
                              i
                            and c
                           
                              j
                            are the colors of the points i and j, dist(i,
                           j) is the standard L
                           2 Euclidean norm yielding point distance, and σ
                           2 is the average squared norm in the image.

The graph edge between one node of the first layer and the high-level observation node depends on the distance between the normal of the point, η
                           
                              i
                           
                           =(η
                           
                              x
                           ,
                           η
                           
                              y
                           ,
                           η
                           
                              z
                           ), in the estimated ground plane and the estimated normal of the ground plane, 
                              
                                 
                                    η
                                    H
                                 
                                 ¯
                              
                           . It is defined by:
                              
                                 (19)
                                 
                                    B
                                    −
                                    H
                                    i
                                    g
                                    
                                       h
                                       
                                          i
                                          ∈
                                          
                                             V
                                             L
                                          
                                       
                                    
                                    =
                                    
                                       λ
                                       2
                                    
                                    
                                       e
                                       
                                          −
                                          
                                             
                                                |
                                                |
                                                
                                                   η
                                                   i
                                                
                                                −
                                                
                                                   
                                                      η
                                                      H
                                                   
                                                   ¯
                                                
                                                
                                                   
                                                      |
                                                      |
                                                   
                                                   2
                                                
                                             
                                          
                                          /
                                          2
                                          
                                             
                                                σ
                                                H
                                             
                                             2
                                          
                                       
                                    
                                 
                              
                           where σ
                           
                              H
                            is the averaged squared distance between the normal of the points, η
                           
                              i
                           , and estimated normal of the ground plane, 
                              
                                 
                                    η
                                    H
                                 
                                 ¯
                              
                           . λ1 and λ2 are to weight these two boundary terms.

The final labeling, 
                              
                                 
                                    L
                                    F
                                 
                                 ˜
                              
                           , can be achieved by minimizing the energy function in Eq. (15):
                              
                                 (20)
                                 
                                    
                                       
                                          L
                                          F
                                       
                                       ˜
                                    
                                    =
                                    
                                       
                                          argmin
                                          E
                                          
                                             
                                                L
                                                ˜
                                             
                                          
                                       
                                       
                                          L
                                          ˜
                                       
                                    
                                    .
                                 
                              
                           
                        

The graph cut algorithm in [45] is used to minimize this equation. The proposed refinement process which utilizes the multi-layer graph cuts and H
                           −
                           Classifier is called H
                           −
                           Classifier
                           
                              Multi
                              −
                              GC
                            after this point.

It is possible to develop some point-wise human refinement algorithms without incorporating any learned prior information. In these approaches, the models of the human and background are obtained from a single input image. The models can include some generic cues, such as the color, depth, normals, and edges. All points inside of the bounding box can be used to form the foreground model. Or some pre-processing steps can be applied to remove some of the background points from the inside of the given bounding box. Applying pre-processing steps can produce more reliable foreground model.

The algorithm explained in [20] is a previously published graph cut-based refinement method. It takes the low-dimensional shape of any object and outputs its point-wise representation. This method uses only a monocular color camera data source. The foreground/background models are constructed by using the regions which are obtained by scaling the given initial low-dimensional shape. These models incorporate color and shape distance terms. We extended this method to serve as a low-dimensional human shape refinement algorithm. In addition to the color, we incorporated raw depth and normal information to build the models of this algorithm. Algorithm 1 outlines the steps of the extended method.
                        Algorithm 1
                        
                           GC-Refine.
                              
                                 
                              
                           
                        

Finding a good scale factor plays an important role in constructing discriminative foreground and background models. Using a small scale factor causes the inclusion of some background points in the human model. On the other hand, choosing a large scale factor can erroneously eliminate some of the human body points. In order to reduce the number of the background pixels in the human model, some pre-processing steps can be applied. Therefore, the ground plane is estimated and excluded from the foreground model.

Removing the ground plane points from the foreground model is helpful only at the foot level of the human. However, there might remain some other background points in the foreground model, e.g. the points of a wall, an object, or another human. In order to remove these points, it is assumed that a human (modeled roughly as an upright cylinder) has a maximum radius of d
                     
                        H
                     . A slice of region which is perpendicular to the ground and whose radius is d
                     
                        H
                      is searched to extract the region of interest within B(x,y,w,h). The slice which holds the maximum number of points is selected to form the foreground model. This slice can be estimated by a Random Sample Consensus (RANSAC) procedure as outlined in Algorithm 2. The method which includes these pre-processing steps is called GC-Refine-Pre.
                        Algorithm 2
                        Extracting ROI.
                              
                                 
                              
                           
                        

@&#EXPERIMENTS@&#

Several experiments were conducted to quantify and analyze the performance of the proposed methods H
                     −
                     Classifier, H
                     −
                     Classifier
                     
                        Multi
                        −
                        GC
                     , GC-Refine, and GC-Refine-Pre. For these experiments, a subset dataset of DontHitMe, called as DontHitMe-Refine, was collected. The details of DontHitMe are explained in [10]. Briefly, this dataset includes low-dimensional (a bounding box) ground truths of 3600 humans both in color and registered depth images. In addition to these low-dimensional representations, DontHitMe-Refine contains point-wise ground truths of 1016 human images which were manually annotated.

The positive samples are obtained from the ground truth masks of DontHitMe-Refine dataset to train the classifier. All points inside a ground truth mask are used to generate the positive samples. However, not all points outside of the ground truth region are selected as negative samples. Only one of every two pixels in a row of the image is added to the set of the negative samples. In this way, the training time of the classifiers is aimed to be reduced. Also, the points which do not have valid depth data are not included in the training set. 5 decision trees were trained.

We performed a set of tests to analyze the performance of H
                        −
                        Classifier when it is trained with the point-wise descriptors, f
                        
                           s
                        , which includes different combination of the cues. The normal, η, vectorial spatial distance, Δ
                        
                           v
                        , and the geodesic distance, GD cues were combined in f
                        
                           s
                         in 7 different possible ways. A different H
                        −
                        Classifier was trained for each of these combinations using the same training set. In order to reduce the variability in the testing scores, we performed multiple rounds of 5-fold cross-validation. The following polygon area overlap formula is used to measure the overlap between the ground-truth and the result of the classifier suggested by [48]:
                           
                              (21)
                              
                                 O
                                 
                                    
                                       R
                                       1
                                    
                                    
                                       R
                                       2
                                    
                                 
                                 =
                                 A
                                 
                                    
                                       
                                          
                                             R
                                             1
                                          
                                          ∩
                                          
                                             R
                                             2
                                          
                                       
                                    
                                    2
                                 
                                 /
                                 
                                    
                                       A
                                       
                                          
                                             R
                                             1
                                          
                                       
                                       A
                                       
                                          
                                             R
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           R
                        
                        1 and 
                           R
                        
                        2 are the two regions to calculate the overlap between.

The results of this experiment can be seen in Table 2
                        . The best performance, for which the median overlap score is 0.89, was achieved when all of three cues were included in f
                        
                           s
                        . In the case of removing one of the cues from f
                        
                           s
                        , the scores dropped down. Also, the classifier which uses only the normals, η, was unable to distinguish between background and human points. Thus, the normal, η, alone is not capable of representing the human body points. However, when it is associated with the vectorial spatial distance, Δ
                        
                           v
                        , they both performed well by achieving the overlap score of 0.81.

In addition to three cues related to the shape, two more tests were conducted to see the effect of incorporating the color of the points into the point-wise descriptor, f
                        
                           s
                        . Simply, the three channels of RGB color of the points are included in f
                        
                           s
                         as additional dimensions. The same test was also performed over converting to LAB color space. The median overlap scores of these two classifiers which include the color information are shown in the last two rows of Table 2. Adding the color information reduced the performance of the classifier from 0.89 to 0.83. This is mainly because of the color variation of the human skin, clothes, background and different illumination conditions. No performance difference between different color spaces was observed. They both dropped the overlap scores by the same amount.

Furthermore, the images of DontHitMe-Refine were refined by H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                        . The confidence scores of H
                        −
                        Classifier which produced the best median overlap score in Table 2 by combining three shape-related cues, Δ
                        
                           v
                        , η, and GD, in f
                        
                           s
                         were used in the multi-layer graph cut framework. This process can be considered as a second stage in the refinement process. The median overlap scores of H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         is listed in Table 3
                        . A remarkable improvement was achieved by this step. Incorporating the estimated ground plane as a high-level observation, utilizing the shape confidence score of H
                        −
                        Classifier, and employing the color information jointly in a multi-layer graph took the median overlap score from 0.89 to 0.95. Fig. 5
                         displays some examples refined by H
                        −
                        Classifier and H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                        . (a) and (c) of this figure show the results of H
                        −
                        Classifier. (b) and (d) display the refinements results of H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         for the same input images. In both of these results, the proposed multi-layer graph cut approach helped to remove some ground points and also background points classified as the human by H
                        −
                        Classifier. The color discontinuity term in the graph cut enabled the segmentation of points where there is no depth data is available. For example, some of the hair points on the left side of the neck of the woman in Fig. 5(a) do not have valid depth information. Hence, H
                        −
                        Classifier was unable to classify those points. Yet, H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         included them into the final refined region as shown in Fig. 5(b), because of the color similarity to other hair points which have valid depth.

The proposed H
                        −
                        Classifier and H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         are compared to the following methods:
                           
                              1)
                              
                                 Baseline Method: We implemented a simple baseline approach. It centers a cylinder of a fixed radius 0.5m and height 2m at the 3-D center of the human determined via the bounding box. The ground plane points are removed from inside the cylinder and all other points are taken as the object.


                                 GrabCut 
                                 [21] which is naturally suitable for the refinement of low-dimensional human shape representation. It uses only the color image.

The method explained in [49,50] was developed originally for labeling different body parts. We used the depth difference features of this method to classify points as human or background. The same set of images from DontHitMe-Refine-Train and samples are used to train this classifier. In this case, the human body part labeling problem is reduced to a simple human/background labeling problem.

The proposed H
                        −
                        Classifier and H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         methods performed better than all compared methods. The overlap scores of the methods can be seen in Table 3. Fig. 6
                         displays a gallery of the results of the methods. In our tests, the poor performance of GrabCut can be explained by the color similarities between the fore/background models, the lack of structural information, and possible background points inside the human model. Also, our proposed descriptor, f
                        
                           s
                        , is more successful than the depth similarity features of [49,50] at distinguishing the human points from the background points for the same training and test sets.

We observed that the clustering method of GC-Refine is not able to weight the cues according to their importance in different parts of the scene. Since it does not employ a learning technique which favors the important cue in the places where it is more discriminative than other cues, H
                        −
                        Classifier outperformed its classification results. Fig. 7
                         shows some results of GrabCut, Baseline method and the proposed H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         for direct comparison.

In order to analyze the performance difference between Random Decision Forests and SVMs, another point-wise human classifier, H
                        −
                        Classifier
                        −
                        SVMs, was trained using SVMs [51]. A Radial Basis Function (RBF) was used as the kernel function of the SVM. The same set of point-wise descriptors, f
                        
                           s
                        , to build H
                        −
                        Classifier, were used to train H
                        −
                        Classifier
                        −
                        SVMs. Also, all dimensions of f
                        
                           s
                         are scaled between 0 and 1 to assign the same weight to different cues in f
                        
                           s
                        . In this way, the same conditions were established to analyze and compare their performances. SVMs performed worse than Random Forests in the experiments. The poorer performance of SVMs is related to its decision function. SVMs measure the distance to the hyperplane which is the decision margin of the space to classify a point. In this decision function, even though some of the dimensions of f
                        
                           s
                         are less discriminative than others, all cues in f
                        
                           s
                         take the same amount of importance, so they still affect the distance to the hyperplane. However, our descriptor includes different types of cues which may require different weights or pruning in the training and testing phases of the classifiers. SVMs does not contain a mechanism to balance the weights between different cues or to prune some of them in a decision tree way. Fortunately, Random Decision Forests supply these features. Some sample results of H
                        −
                        Classifier
                        −
                        SVMs can be seen in Fig. 8
                        .

Several tests which incorporate different combinations of the generic cues were performed to see the results of GC-Refine. Seven different combinations of three generic cues that are the color, depth and normal were used in the experiments. GC-Refine was separately tested with each possible combination of the cues. All images in DontHitMe-Refine dataset were refined in these tests. The median overlap scores of these experiments can be seen in Table 5
                        
                        . The highest performance was achieved when the feature vector of GC-Refine included all cues. Its median overlap score is 0.64. The combination of the depth and normal cues produced the second-best results.

In order to analyze the performance of extracting the non-region of interest from the human model, we experimented with GC-Refine-Pre in the same way. As in the previous tests of GC-Refine, all different combinations of the cues were analyzed. As it can be foreseen, providing cleaner models yielded better refinement results. The median overlap scores of this experiment are summarized in Table 6
                        . The best score was achieved if all cues are used. The score went up to 0.70 from 0.64 which was achieved by GC-Refine.

A machine which has 32GB RAM and Intel i7-2760QM quad processor was used in the experiments. The methods were implemented in C++. The implementations do not contain thread-level parallel processing. 5 decision trees were trained for H
                        −
                        Classifier. Since we performed 5-fold cross-validation, about 800 ground truths were trained for each test. It took about 7.5h to train H
                        −
                        Classifier including the time to compute the features. The training time of H
                        −
                        Classifier
                        −
                        SVMs using SVMs took longer, or about 12h. Training the classifier which uses depth difference features from [49,50] took about 8.5h.

The running times of the methods to classify the human points in one bounding box can be seen in Table 4. The size of the images was not scaled to reduce the computational time. The image size is 640×480 for all experiments. The classifier which uses depth difference features from [49,50] was the fastest. Since H
                        −
                        Classifier, H
                        −
                        Classifier
                        −
                        SVMs and H
                        −
                        Classifier
                        
                           Multi
                           −
                           GC
                         include the steps to compute the normal of the points and their relative geodesic distances, they are slower than other methods. We believe that a parallel implementation of the proposed method can decrease the required computational time.

@&#CONCLUSION@&#

In this paper, we tackled the problem of low-dimensional human shape refinement in two different ways: by combining shape prior information learned by training a classifier, or by using only some generic cues obtained from given single image. We presented a novel and accurate method to refine the low-dimensional shape representation of a human. This method, H
                     −
                     Classifier
                     
                        Multi
                        −
                        GC
                     , combines low- and high-level observations obtained from the image and depth images of the scene jointly in a multi-layer graph framework. Unlike some existing work, our approach does not use or carry any features from the internal steps of the low-dimensional shape provider, so it is applicable to the output of any methods which provides such a shape. Also, it works on moving platforms and integrates multiple modalities by obtaining cues from the color and depth images. On the other hand, we extended a previously-published and graph cut-based refinement technique for this purpose. In addition to the color, we incorporated more generic cues that are the depth and normal of the points into this method.

Our extensive experiments showed that the proposed H
                     −
                     Classifier
                     
                        Multi
                        −
                        GC
                      outperforms other suitable refinement algorithms. It achieves a 0.92 overlap score while GrabCut stays at 0.57. As future work, other high-level observations, such as estimated walls, or detected objects can be incorporated into the multi-layer graph framework in addition to the estimated ground plane.

@&#REFERENCES@&#


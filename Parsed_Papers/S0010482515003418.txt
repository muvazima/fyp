@&#MAIN-TITLE@&#Segmentation of liver and spleen based on computational anatomy models

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Propose a novel framework for multi-organs segmentation.


                        
                        
                           
                           Incorporate an atlas concept within an organ bounding box construction.


                        
                        
                           
                           Iterative probabilistic atlas overcome a bias toward the specific patient study.


                        
                        
                           
                           Adaptive select reference bone for accurate alignment of the given data.


                        
                        
                           
                           Achieve the promising performance (
                                 p
                                 <
                                 0.00001
                              ) compared with conventional method.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multiple organs segmentation

Template matching

Organ bounding box

Iterative probabilistic atlas

Computational anatomy model

@&#ABSTRACT@&#


               
               
                  Accurate segmentation of abdominal organs is a key step in developing a computer-aided diagnosis (CAD) system. Probabilistic atlas based on human anatomical structure, used as a priori information in a Bayes framework, has been widely used for organ segmentation. How to register the probabilistic atlas to the patient volume is the main challenge. Additionally, there is the disadvantage that the conventional probabilistic atlas may cause a bias toward the specific patient study because of the single reference. Taking these into consideration, a template matching framework based on an iterative probabilistic atlas for liver and spleen segmentation is presented in this paper. First, a bounding box based on human anatomical localization, which refers to the statistical geometric location of the organ, is detected for the candidate organ. Then, the probabilistic atlas is used as a template to find the organ in this bounding box by using template matching technology. We applied our method to 60 datasets including normal and pathological cases. For the liver, the Dice/Tanimoto volume overlaps were 0.930/0.870, the root-mean-squared error (RMSE) was 2.906mm. For the spleen, quantification led to 0.922 Dice/0.857 Tanimoto overlaps, 1.992mm RMSE. The algorithm is robust in segmenting normal and abnormal spleens and livers, such as the presence of tumors and large morphological changes. Comparing our method with conventional and recently developed atlas-based methods, our results show an improvement in the segmentation accuracy for multi-organs (
                        p
                        <
                        0.00001
                     ).
               
            

@&#INTRODUCTION@&#

Organ segmentation refers to the process of separating the organ of interest from its surroundings for clinical medical images. Manual segmentation of organ structures by an expert is a laborious and time-consuming task. Therefore, automatic or semiautomatic organ segmentation methods have been developed to provide a reproducible, accurate and robust alternative. In order to segment the organs from their medical images, a variety of sophisticated methods of segmenting organs have been proposed [1–4]. This methodological explosion reflects the difficulty of organ segmentation for clinical applications. These methods can be summarized as classification-based [5–7], region-based [8,9], contour-based [10,11], graph cut-based [12,13] and random walks-based [14,15] segmentations. However, these segmentation methods depend solely on gradient or intensity analysis, and omit the use of anatomical information. Hence, their performance is insufficient when the image contains noise or the contrast between object and background is low.

Recently, significant effort has been focused on the development of anatomical model-based methods, such as probabilistic atlas [16–24] and statistical shape model [25,26] for organ segmentation. In anatomical model based methods, the anatomical model can be used as a priori location and shape information of organs. These methods are robust against noise, but they are sensitive to initialization of their parameters, such as pose and initial contour. Our research focused on the probabilistic atlas-based segmentation method. Most of the work has involved the construction of atlases for organ segmentation [27–31]. Probabilistic atlas-based organ segmentation, however, poses a number of challenges. Accurate mapping of the probabilistic atlas onto the input CT volumes is difficult because of the variability in organ shape. To resolve this problem, we investigated utilizing an automatic registration method for this application. Park et al. [16] first proposed using probabilistic atlases to model the multiple organs, by manually extracting landmark points on each organ for registering probabilistic atlases based on thin plate spline (TPS). Using a similar principle, the priori information from probabilistic atlases was used to initialize the segmentation of abdominal organs in [17,18]. Both methods used measures of relationship and hierarchy between organs and manual landmarks. Meanwhile, in [19], Zhou et al. constructed the liver atlas for improved liver segmentation that controlled the points of diaphragm surface according to TPS. Linguraru et al. [20] suggested to segment the liver and the spleen from the CT images using the position of the xiphoid to register the probabilistic atlas based on affine transformation. Yamaguchi et al. [21] applied the region-growing method and the probabilistic atlas to segment the liver from the CT images by registering the usage of the anatomical landmarks of the liver based on TPS. Notably, the construction of these abdominal atlases required manual landmarks through user interaction. On a different note, Okada et al. [22,23] developed a hierarchical statistical atlas of the liver normalized to the abdominal cavity as part of a process of automatically segmenting the liver. Recently, Li et al. [24] also proposed an automated liver segmentation method using the rib cage to map the probabilistic atlas onto the input volume. They only considered one type of rib cage as the reference for registration.

However, there are two limitations to these segmentation methods: (1) Errors in landmark extraction may cause incorrect estimation of the transformation. (2) Eventhough the transformation of landmarks can be accurately estimated, it is difficult to achieve the accurate transformation of the organ because of the large variation of anatomical structure.

Taking these two points into consideration, we propose a template matching framework based on a probabilistic atlas for organ segmentation. In our proposed method, we first need to construct a bounding box around the organ based on human anatomical structure, which complies to the relatively rigid characteristics of organ position; and then the probabilistic atlas is used as a template to find the organ in this bounding box by the use of template matching.

Additionally, as described in [16], the main disadvantage of the conventional probabilistic atlas is that it may cause a bias for the specific patient studies due to the single reference. Numerous investigations showed that an iterative atlas construction can reduce the dependence on the reference patient [24]. Hence, in this paper, we construct an iterative probabilistic atlas for our proposed method to address this bias issue.

The rest of this paper is organized as follows: In Section 2, we describe our proposed method, which explains how to construct the organ bounding box, how to realize the Gaussian intensity model, how to build the iterative probabilistic atlas model, and how to segment the organ. Extensive evaluation of our method is presented in Section 3. Section 4 is devoted to the discussion of performance and Section 5 concludes the paper.

The proposed method segments an abdominal organ based on a set of priori information. Priori information includes the approximate location of an organ, histogram of the organ׳s intensities, and a probabilistic atlas of the organ. The organ bounding box is employed to estimate the approximate location of an organ for the observed data. The histogram of the organ׳s intensity is used to build the Gaussian intensity model (likelihood map). The likelihood map together with the probabilistic atlas is employed in the template matching technique. Template matching aims to estimate an initial segmentation of the organ. In the estimation of the organ bounding box, construction of the probabilistic atlas and template matching, the affine registration method is employed. Furthermore, the Geodesic Active Contour (GAC) algorithm [10] is used to refine the initial segmentation results so that they can guarantee the smoothness of the final result. The framework of our proposed method is shown in Fig. 1
                        .

The basic idea of our proposed method is based on Bayes framework. To estimate the organ label 
                           L
                         we can follow the principle of the maximum a posteriori probability (MAP) estimation. The posteriori probability can be estimated as:
                           
                              (1)
                              
                                 
                                    
                                       P
                                    
                                    
                                       i
                                       ,
                                       j
                                       ,
                                       k
                                    
                                 
                                 (
                                 L
                                 |
                                 
                                    A
                                 
                                 )
                                 ∝
                                 
                                    
                                       P
                                    
                                    
                                       i
                                       ,
                                       j
                                       ,
                                       k
                                    
                                 
                                 (
                                 A
                                 |
                                 
                                    L
                                 
                                 )
                                 
                                    
                                       P
                                    
                                    
                                       i
                                       ,
                                       j
                                       ,
                                       k
                                    
                                 
                                 (
                                 L
                                 )
                                 {
                                 
                                    
                                       
                                          
                                             Liver
                                          
                                          
                                             L
                                             =
                                             1
                                          
                                       
                                       
                                          
                                             Spleen
                                          
                                          
                                             L
                                             =
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           A
                           (
                           i
                           ,
                           j
                           ,
                           k
                           )
                         and 
                           L
                           (
                           i
                           ,
                           j
                           ,
                           k
                           )
                         are the intensity values and organ labels of voxel 
                           (
                           i
                           ,
                           j
                           ,
                           k
                           )
                         in the CT volume, where 
                           (
                           i
                           ,
                           j
                           ,
                           k
                           )
                         is the coordinate for each voxel. 
                           P
                           (
                           A
                           |
                           
                              L
                           
                           )
                         is the likelihood map for an organ, 
                           P
                           (
                           L
                           )
                         is the iterative probabilistic atlas which is used as a prior probability map. In the following sections, we describe how to segment the multiple organs in the abdominal region.

The development of the bounding box-based method is a new trend for organ segmentation that allows easy extraction from CT volumes. An abundance of literature has been published on the bounding box for the estimation region of organs [32–38]. These methods can automatically detect the localization of organs within 3D CT scans, and they can be summarized as follows: regression-based [32–34], classification-based [35,36], registration-based [37,38]. The first two methods usually need to deal with large amounts of data and consequently need the longest computation times for the training process.

However, the registration-based approaches are more efficient and can roughly align the organs in only a few seconds. For registration-based approaches, atlas-based methods have enjoyed much popularity for their conceptual simplicity. Our algorithm incorporates the atlas concept within a bounding box construction. Since the bone of the body is considered as a rigid part, we perform affine registration to transform the bones in our work. A scheme of the organ bounding box construction is shown in Fig. 2
                        , which contains the bone segmentation, the bone registration and the bounding box construction for one organ.

Several methods have been proposed for bone extraction [39,40]. The main approach of these methods was to estimate the intensity range of the bone and apply the region-growing technique to find the bone. Following a similar approach to these methods, our method׳s first step is to find the abdominal region using Otsu thresholding [41]. Then, we model the intensity range of bones (
                              [
                              
                                 
                                    
                                       T
                                    
                                    
                                       low
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       high
                                    
                                 
                              
                              ]
                           ) and a seed point was automatically selected. Finally, after the estimation of the intensity range of the bones and the seed point, the region-growing algorithm [8] is employed to segment bone and the morphological operators were used to refine the results. The flowchart of our bone extraction method is shown in Fig. 3
                           .

In order to reduce the computation demands of our algorithm, we firstly extract the abdominal region as a ROI using Otsu thresholding technique. The high threshold value (
                              
                                 
                                    T
                                 
                                 
                                    high
                                 
                              
                           ) of the bone׳s intensity is defined as the largest intensity value in the abdominal region, as shown in Fig. 4
                           .

We use one slice image to find the low threshold (
                              
                                 
                                    T
                                 
                                 
                                    low
                                 
                              
                           ) for bone segmentation. Though the selection of the slice is not very critical, we select the third slice for this task because the first several slices usually do not include the kidney, which has an overlapped intensity range with the bone. In the abdominal region, there are several tissues which make estimation of the bone intensity range difficult. However, regions that include less tissues cause estimation of bone intensities more accurate. Thus, the estimation of the bone intensity range will be more accurate. One example of the third slice image is shown in Fig. 6(a). Subsequently, an iterative search approach is applied to find the bone׳s low threshold, as shown in the left-hand side of Fig. 3. First, we assume an intensity distribution of the selected slice as a Gaussian model (Fig. 4). Then we can estimate the parameters of the corresponding Gaussian distribution (
                              G
                              (
                              μ
                              ,
                              σ
                              )
                           ). In order to segment the bone in CT data, we need to calculate a threshold value 
                              
                                 
                                    T
                                 
                                 
                                    low
                                 
                              
                            by using the parameters of the assumed Gaussian distribution. With the initial threshold value 
                              
                                 
                                    T
                                 
                                 
                                    low
                                 
                              
                              =
                              μ
                            (the mean value μ), we iteratively increase 
                              
                                 
                                    T
                                 
                                 
                                    low
                                 
                              
                            with a fixed value (
                              0.2
                              ⁎
                              σ
                           ) until a ratio of the segmented bone volume to whole volume is less than a predefined value (
                              ∑
                           ). Fig. 5
                            shows the bone segmentation results with different thresholds (percentages). Lowering the threshold value for the bone segmentation results in the loss of bone regions; conversely, with the higher threshold value for the bone, it may include multiple organs. According to our experimental results (the mean Dice measure), we set the predefined value 
                              ∑
                              =
                              2
                              %
                            as the optimum threshold value to prevent the inclusion of the intestine, colon and blood vessel in the segmentation results in our work. By this dynamic threshold method, the low threshold 
                              
                                 
                                    T
                                 
                                 
                                    low
                                 
                              
                            for the bone is obtained.

Next, a seed point is automatically selected after the input image is thresholded (
                              [
                              
                                 
                                    
                                       T
                                    
                                    
                                       low
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       high
                                    
                                 
                              
                              ]
                           ). The whole procedure of the seed point estimation is shown in Fig. 6
                           . It consists of the following: (1) Definition of the central zone (Fig. 6(c)) in the extracted abdominal region. We define the central zone, whose area is 25% of the abdominal region, as a ROI. (2) Generating the thresholded image (Fig. 6(d)) by thresholding the third slice of CT volume with 
                              [
                              
                                 
                                    
                                       T
                                    
                                    
                                       low
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       high
                                    
                                 
                              
                              ]
                           . (3) Obtaining the largest segmented object in the central zone. (4) Defining the central point of this largest object as a seed point (Fig. 6(e)). If the central point (the estimated seed point) is located within empty space, the nearest point to the central point of this largest object is defined as the seed point (Fig. 6(f)).

After estimating a seed point and the bone׳s intensity range 
                              [
                              
                                 
                                    
                                       T
                                    
                                    
                                       low
                                    
                                 
                                 ,
                                 
                                    
                                       T
                                    
                                    
                                       high
                                    
                                 
                              
                              ]
                           , we apply a seed region-growing algorithm [8] to segment the bone.

Registration is an important step in the whole process due to its primary influence on the overall accuracy of the bounding box. Since bones are considered as the rigid frameworks in the human body, the affine transform is used for the registration in our work. Empirically, the selected reference data have to approximately resemble the whole set of input images. However, due to variations in the abdominal region, which is scanned during the imaging procedure, the bone shape/size shows variation. Hence, only using one type of bone is not sufficient for registration. Taking this into consideration, we utilize four different reference bones for the registration. We select one training data which includes shoulder to leg region. Then we extract four different regions of the body to serve as four references, as shown in Fig. 7
                           . The first reference data includes shoulder to legs. The second reference data includes from the liver region towards legs. The third reference data includes the liver region and pelvis. The fourth data includes only the liver region.

The root mean squares (RMS) metric is used to adaptively select the appropriate bone reference when we want to register a new data. Initially, the extracted bone for the new data is registered to all four reference bones, separately. Then, we calculate the RMS value between the new data and each reference as a measurement of the accuracy of the registration result. The four RMS values are compared and the extracted bone is registered to the reference bone corresponding to the lowest RMS value. Wherein, the RMS measurement is calculated based on the binary image of the segmented bone.

Considering the variations in anatomical structure, the positions of organs will differ for all the data. Hence, to build a bounding box for an organ, we use the various organ data as training data. Firstly, we extract the bone from one data. Next, using the adaptive selection of the appropriate reference bone, the extracted bone is registered to the corresponding reference by using an affine transform. Then, the same transformation is used to transform the segmented organ mask of this data. Finally, after registration of all the training data, we find the volume of interest (VOI) of the ensemble of the organs and use it as the organ bounding box. Fig. 8
                            illustrates an example of the spleen bounding box based on six samples.

For the test data, according to the adaptive selection of bone reference, once the reference bone is registered to the bone of the observed data, the organ bounding box is automatically transformed onto this observed data using the same transformation. Thus, the candidate organ region is extracted based on this registered organ bounding box.

A Gaussian intensity model (or likelihood map) of an organ refers to an image in which the intensity of a voxel corresponds to the probability of belonging to that organ. To reduce the irrelevant neighboring tissues from the input candidate organ region and to improve the segmentation accuracy, the Gaussian model is applied for analyzing the input organ intensity distribution, and can be described as:
                           
                              (2)
                              
                                 
                                    
                                       P
                                    
                                    
                                       i
                                       ,
                                       j
                                       ,
                                       k
                                    
                                 
                                 (
                                 A
                                 |
                                 
                                    L
                                 
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             2
                                             π
                                             
                                                
                                                   σ
                                                
                                                
                                                   L
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                 exp
                                 
                                 (
                                 
                                    
                                       
                                          −
                                          
                                             
                                                (
                                                A
                                                (
                                                i
                                                ,
                                                j
                                                ,
                                                k
                                                )
                                                −
                                                
                                                   
                                                      μ
                                                   
                                                   
                                                      L
                                                   
                                                
                                                )
                                             
                                             
                                                2
                                             
                                          
                                       
                                       
                                          2
                                          
                                             
                                                σ
                                             
                                             
                                                L
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                                 )
                              
                           
                        
                     

The Gaussian parameters mean 
                           
                              
                                 μ
                              
                              
                                 L
                              
                           
                         and variance 
                           
                              
                                 σ
                              
                              
                                 L
                              
                              
                                 2
                              
                           
                         can be estimated by observing the density histogram of the organ. In our paper, 
                           L
                           =
                           1
                         is the liver and 
                           L
                           =
                           2
                         is the spleen. We only construct the Gaussian intensity model for the organ of interest. We do not model the background tissues since it includes several tissues which cannot be modeled by a single Gaussian distribution. A Gaussian distribution 
                           N
                           (
                           μ
                           ,
                           σ
                           )
                         which has the same FWHM (full width half maximum) with the observed density histogram is decided [19]. In dealing with the large range of organ intensities, we follow a non-parametric scheme and use training data to build the histogram of the voxels׳ intensities. For the gray scale distribution of an organ, the 100 bin histogram was made to closely approximate the true distribution.

We convert the intensity value (
                           A
                           (
                           i
                           ,
                           j
                           ,
                           k
                           )
                        ) of each voxel into a probability (a likelihood 
                           
                              
                                 P
                              
                              
                                 i
                                 ,
                                 j
                                 ,
                                 k
                              
                           
                           (
                           A
                           |
                           
                              L
                           
                           )
                        ) for the organ (L) using Eq. (2). A typical case of the spleen is shown in Fig. 9
                        , in which the original image is converted into a likelihood map for spleen. Comparing the original CT image (Fig. 9(a)) with the likelihood map (Fig. 9(b)) reveals that the spleen can be more easily distinguished from other tissues in the likelihood map, since the spleen region has a higher probability. Additionally, it can be found that distinguishing the spleen from several tissues with similar intensity is a little difficult if we use only intensity information (likelihood).

An organ probabilistic atlas can serve as a prior probability image of the organ. The segmented organ masks in the training data are used to construct a probabilistic atlas for the candidate organ. In conventional construction of a probabilistic atlas, a single training data is arbitrarily chosen as the reference image, and the rest of the data are considered as the moving images and registered to this reference. However, as identified by Park et al. [16], the main disadvantage of the conventional atlas is that a single reference is limited in representing the whole population of potential target cases. Hence, only mapping to a single reference may cause a bias toward that specific patient study. According to surveys on this problem, this issue can be addressed by an iterative atlas construction that reduces the dependence on the reference patient [16,24].

The construction process of our iterative atlas is illustrated in Fig. 10
                        . Registration of the organ masks is the most important step in the atlas construction process, which is performed using a rigid scheme in our method. In the initial step we register the organ mask in different CT cases onto the reference volume, and then the resulting atlas from the previous iteration is used as the reference for the following construction phase (as explained in Algorithm 1). The mapping result is the atlas that shows the probability of a given voxel belonging to the organ. Hence, the atlas is a composite and reflects variations in organ shape and size. To accurately build the atlas, although we do not use any bone as the reference image, the corresponding bone still needs to be used to normalize the organ mask in the same physical coordinate since the spacing and origin of training data are not the same. 
                           Algorithm 1
                           Iterative probabilistic atlas algorithm. 
                                 
                                    
                                       
                                       
                                          
                                             
                                                Initialization:
                                             
                                          
                                          
                                             
                                                Reference 
                                                   _
                                                 OrganMask(RO), Registered 
                                                   _
                                                 Reference 
                                                   _
                                                 OrganMask(
                                                   Reg
                                                   _
                                                   RO
                                                ),
                                          
                                          
                                             
                                                Training 
                                                   _
                                                 OrganMask(TO), Registered 
                                                   _
                                                 Training 
                                                   _
                                                 OrganMask(
                                                   Reg
                                                   _
                                                   TO
                                                ),
                                          
                                          
                                             
                                                Reference 
                                                   _
                                                 Bone(RB), Training 
                                                   _
                                                 Bone(TB), Number 
                                                   _
                                                 TrainingData(K),
                                          
                                          
                                             
                                                
                                                J=1, S=1;
                                          
                                          
                                             
                                                Iteration:
                                             
                                          
                                          
                                             
                                                
                                                while
                                                 
                                                
                                                   J
                                                   ≤
                                                   K
                                                   
                                                   do
                                                
                                             
                                          
                                          
                                             
                                                
                                                
                                                   J
                                                   ==
                                                   1
                                                 
                                                 
                                                then
                                             
                                          
                                          
                                             
                                                
                                                Step1: Extracting the bone from 
                                                   Training
                                                   _
                                                   Data
                                                   (
                                                   J
                                                   )
                                                 and adaptive selecting RB;
                                          
                                          
                                             Step2: Normalizing the TO(J) by using the TB(J) and RB;
                                          
                                          
                                             Step3: Registering the TO(J) onto the RO, as 
                                                   Reg
                                                   _
                                                   TO
                                                   (
                                                   J
                                                   )
                                                ;
                                          
                                          
                                             Step4: Obtaining the 
                                                   Atlas
                                                   _
                                                   Data
                                                   =
                                                   
                                                      
                                                         1
                                                      
                                                      
                                                         J
                                                         +
                                                         1
                                                      
                                                   
                                                   (
                                                   
                                                      RO
                                                      +
                                                      Reg
                                                      _
                                                      TO
                                                      (
                                                      J
                                                      )
                                                   
                                                   )
                                                ;
                                          
                                          
                                             
                                                
                                                
                                                else
                                             
                                          
                                          
                                             
                                                
                                                Repeat Step1–Step2;
                                          
                                          
                                             
                                                
                                                Step5: Registering the RO onto the 
                                                   Atlas
                                                   _
                                                   Data
                                                , as 
                                                   Reg
                                                   _
                                                   RO
                                                ;
                                          
                                          
                                             
                                                
                                                
                                                while
                                                 
                                                
                                                   S
                                                   ≤
                                                   J
                                                 
                                                 
                                                do
                                             
                                          
                                          
                                             
                                                
                                                Step6: Registering the TO(S) onto the RO, as 
                                                   Reg
                                                   _
                                                   TO
                                                   (
                                                   S
                                                   )
                                                ;
                                          
                                          
                                             
                                                
                                                
                                                
                                                   S
                                                   ←
                                                   S
                                                   +
                                                   1
                                                ;
                                          
                                          
                                             
                                                
                                                end while
                                             
                                          
                                          
                                             
                                                
                                                Step7: Updating the 
                                                   Atlas
                                                   _
                                                   Data
                                                   =
                                                   
                                                      
                                                         1
                                                      
                                                      
                                                         J
                                                         +
                                                         1
                                                      
                                                   
                                                   (
                                                   
                                                      Reg
                                                      _
                                                      RO
                                                      +
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            J
                                                         
                                                      
                                                      Reg
                                                      _
                                                      TO
                                                      (
                                                      i
                                                      )
                                                   
                                                   )
                                                ;
                                          
                                          
                                             
                                                
                                                
                                                end
                                                
                                                if
                                             
                                          
                                          
                                             
                                                
                                                
                                                
                                                   J
                                                   ←
                                                   J
                                                   +
                                                   1
                                                ; S=1;
                                          
                                          
                                             
                                                
                                                
                                                end
                                                
                                                while
                                             
                                          
                                       
                                    
                                 
                              
                           

In our proposed segmentation method, the probabilistic atlas is used as a template to detect the organ in the organ bounding box by the use of template matching technology. Hence, when the iterative probabilistic atlas is constructed, we select the largest region (VOI) containing all the organ masks as our atlas template 
                           P
                           (
                           L
                           )
                        .

Template matching is one of the key innovations of our algorithm. Template matching is based on the idea that those voxels which belong to the organ have similar intensities to the organ׳s histogram and their locations are the parts of the image where the organ may be found with a higher probability. The aim of this step is to build a probability image, which assigns to each voxel the probability of belonging to the organ of interest. To build such a probability image, we use two probability images: a Gaussian intensity model (a likelihood map) and a probabilistic atlas. Our algorithm incorporates a template matching concept within a Bayes framework, according to the definition of Eq. (1). 
                           P
                           (
                           A
                           |
                           
                              L
                           
                           )
                         is the likelihood map which can be obtained using the organ histogram and 
                           P
                           (
                           L
                           )
                         is estimated by using the organ probabilistic atlas. We use the constructed organ bounding box, described in previous step, to restrict the processing region in template matching. The size of likelihood map is the same as the original CT image. However, considering the probabilistic atlas can be regarded as a template in the matching process, the size of probabilistic atlas is usually smaller than the likelihood map.

The search range for atlas matching is the bounding box, in which the organ is located. A sub-volume that has the same size and location with the probabilistic atlas is extracted from the likelihood map. Then a probability image is generated by voxel-wise multiplication of the sub-volume with the probabilistic atlas. For this generated probability image, the total probabilities (the summation of the probability image) are used as a similarity measure. We search from the bottom-left voxel (start point) of the bounding box to the top-right voxel (end point) of the bounding box to find the best object location 
                           (
                           
                              
                                 a
                              
                              
                                 opt
                              
                           
                           ,
                           
                              
                                 b
                              
                              
                                 opt
                              
                           
                           ,
                           
                              
                                 c
                              
                              
                                 opt
                              
                           
                           )
                         that maximizes the similarity (the summation of the probability image). At this location the sub-volume of the likelihood map will reach the highest matching with the probabilistic atlas. This procedure can be formulated as:
                           
                              (3)
                              
                                 (
                                 
                                    
                                       a
                                    
                                    
                                       opt
                                    
                                 
                                 ,
                                 
                                    
                                       b
                                    
                                    
                                       opt
                                    
                                 
                                 ,
                                 
                                    
                                       c
                                    
                                    
                                       opt
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          arg
                                          
                                          max
                                       
                                       
                                          (
                                          a
                                          ,
                                          b
                                          ,
                                          c
                                          )
                                          ∈
                                          
                                             
                                                Ω
                                             
                                             
                                                B
                                             
                                          
                                       
                                    
                                 
                                 [
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             ,
                                             j
                                             ,
                                             k
                                          
                                       
                                    
                                    
                                       
                                          P
                                       
                                       
                                          i
                                          +
                                          a
                                          ,
                                          j
                                          +
                                          b
                                          ,
                                          k
                                          +
                                          c
                                       
                                    
                                    (
                                    A
                                    |
                                    
                                       L
                                    
                                    )
                                    ×
                                    
                                       
                                          P
                                       
                                       
                                          i
                                          ,
                                          j
                                          ,
                                          k
                                       
                                    
                                    (
                                    L
                                    )
                                 
                                 ]
                              
                           
                        where 
                           
                              
                                 Ω
                              
                              
                                 B
                              
                           
                         is the bounding box for the organ and 
                           (
                           a
                           ,
                           b
                           ,
                           c
                           )
                         represents the location of atlas in the bounding box (
                           (
                           a
                           ,
                           b
                           ,
                           c
                           )
                           ∈
                           
                              
                                 Ω
                              
                              
                                 B
                              
                           
                        ). Furthermore, the generated probability image at location 
                           (
                           
                              
                                 a
                              
                              
                                 opt
                              
                           
                           ,
                           
                              
                                 b
                              
                              
                                 opt
                              
                           
                           ,
                           
                              
                                 c
                              
                              
                                 opt
                              
                           
                           )
                         is padded into the corresponding location of a empty volume that has the same size with the likelihood map. This volume serves as the output of template matching, which contains trivial non-organ structures. In order to remove trivial objects, we firstly threshold this output volume and then smoothed its surface using an opening morphology operator. The generated results for the candidate organ can be regarded as the initial segmentation results.

The final step of organ segmentation is to refine the initial segmentation result by using a Geodesic active contour (GAC) algorithm [10].

GAC is an active contour method which tries to solve a differential equation using an iterative method. The differential equation is the result of minimization of an energy function which moves a contour toward the true boundary of the object [10]. For the GAC segmentation algorithm, an initial contour is required. Its segmentation results are sensitive to the initial position. As explained in the previous section, after template matching, we can achieve an atlas-based segmented organ. Hence, in our work, the generated atlas-based segmented organ was used as an initial contour of the GAC algorithm to achieve a more accurate final segmentation result.

@&#RESULTS@&#

Our dataset comprised of 60 CT images, including 55 data of the abdominal region with a resolution of 
                        0.683
                        ×
                        0.683
                        ×
                        1
                        
                        
                           
                              mm
                           
                           
                              3
                           
                        
                      and a size of 
                        512
                        ×
                        512
                        ×
                     (159-263) and the other 5 data with a resolution of 
                        0.663
                        ×
                        0.663
                        ×
                        1.2
                        
                        
                           
                              mm
                           
                           
                              3
                           
                        
                      and a size of 
                        512
                        ×
                        512
                        ×
                     (309–607). All of the data were stored in DICOM image format with a depth of 12 bits per pixel. The first 55 data were acquired by Light Speed Ultra GE scanners with eight detectors. All the CT data we used included different contrast-phases (the phase-ART, phase-PV or phase-DL). Data were acquired from normal and pathological cases between 20 and 75 years old. Patients (pathological cases) were those who were suspected of having a disease, such as metastatic liver cancer or chronic liver disease, and were scanned in the course of diagnosis. The use of the data obtained from the patient scans was approved by the University Ethics Committee. In order to make a quantitative evaluation for our proposed method, the liver and spleen were segmented for each CT data manually as the ground truth. The segmentation was performed under the guidance of a physician in order to obtain accurate liver and spleen volumes. Of the 60 CT images, data of 38 were randomly chosen as the training data for constructing the liver and spleen bounding box, the probabilistic atlas and the likelihood map. The data of the remaining 22 were used for testing the performance. For all of the test CT dataset, phase-ART has 6 samples, phase-PV has 12 samples and phase-DL has 4 samples.

The algorithm was run using MS-Windows-based personal computer (
                        
                           
                              Intel
                           
                           
                              ®
                           
                        
                      CoreTM-i7 3770QM 3.40GHz and 16GB-DRAM). The programming environment was coded both in C++ language based on ITK [42] and MATLAB. Visualization of the shapes was performed using VTK [43].

For the assessment of our method, we evaluated the bone segmentation and registration results, the accuracy of organ bounding box, and compared our results to the other state-of-the-art segmentation algorithms.

All the CT data we used included different contrast-phases (the phase-ART, phase-PV or phase-DL). For bone segmentation, the biggest difficulty was faced to various threshold range for different contrast phases. To investigate the robustness of bone segmentation for various contrast phases, we applied our bone segmentation method to 60 clinical CT volumes. The segmentation results of 6 typical cases (2 phase-ART, 2 phase-PV and 2 phase-DL) are shown in Fig. 11
                        . The results show that the performance of our method to segment the bones gives us accurate results for phase-ART and phase-DL. It confirms that our bone segmentation method is robust to phase-ART and phase-DL. However, in some contrast phase-PV CT images, the intestines and colon (such as the blood vessels) may have overlapped intensities with the bones. Hence, some of our segmented bones contained trivial non-bone structures, as shown in the second row of Fig. 11.

As described in the previous section, probabilistic atlas-based organ segmentation poses a number of challenges. Accurate mapping of the probabilistic atlas onto the input CT volumes is difficult because of the variability of anatomical structures. In our proposed method, we used the bone as the landmark to estimate only an approximate region for the organ (the organ bounding box). Then the accurate registration of the atlas was performed by the use of template matching in the bounding box. The advantage of our proposed method is that the atlas is not registered onto the CT volumes directly based on the bones registration. Even though some errors exist in the segmented bone, it did not affect the whole organ segmentation result. The segmentation results of liver and spleen from phase-PV CT volumes were shown in Fig. 12
                        . It can be seen that even the bone segmentation was not very accurate (the case of second row), we still can obtain accurate segmentation results for both liver and spleen. Our method was robust to bone segmentation.

Registration was a vital step in the whole process due to the large influence on the overall accuracy of the bounding box. Since the bone of the body is considered as a rigid part in the human body, we perform the affine registration to transform the bones.

The conventional atlas-based segmentation method only used a single reference. Since the region of the CT volume varies greatly (some volumes will have a region from shoulder to leg, while some volumes will have a region with only the liver), it was difficult to register a bone to a reference accurately for the different regions. Taking this into consideration, we prepared four different reference bones for bone registration (as described in Section 2.2.2). In order to validate the effectiveness and the feasibility of our four references, the comparison registration results of four typical bone data are shown in Fig. 13
                        . The first row was the conventional method which used only one single reference bone (Reference 1). The second row was our method which used four different reference bones for bone registration. The gray areas correspond to the reference bone, the blue to the moving bone before registration and the red to the moving bone after registration. Fig. 13(b) demonstrates that the moving bone is inaccurately registered onto the reference bone by the conventional method (the first row) due to the large difference between the reference and moving bone, while it can be accurately registered by our method (the second row). It shows that improper selection of the reference results in incorrect estimation of the organ location. Various reference bones were necessary to accurately transform bones to get the desired effect.

Another factor, which may effect bone registration, is bone segmentation. Fig. 12 shows two typical examples of bone registration in phase-PV. As we described in the previous section, some non-bone structures were included in the segmented bone in phase-PV. However, as shown in Fig. 12, the inclusion of small non-bone structures had little effect on the bone registration due to the lower percentage of the non-bone structures among the segmented bone.

The strong correlation between the organ bounding box and organ segmentation has been explained in [19]. The accuracy of bounding box played an immediate decisive role in the process of organ segmentation. To accurately segment the organ, we need to estimate the candidate region of one organ based on the constructed bounding box. The constructed bounding box for each organ was trained separately and independently in our method. For the test data, using adaptive selection of appropriate reference bone, the transformation between the extracted bone of the test data and the reference bone can be computed by using affine registration. Then the organ bounding box can be transformed onto the test volume. Thus, we can estimate the candidate region of organ for the test data.

As shown in Figs. 14 and 15
                        
                        , two typical cases were chosen to validate our method. They can be used for the objective evaluation of detection accuracy about the organ bounding box. The estimated bounding box can be observed from three directions: axial, coronal and sagital. In our work, the detected location was considered to be correct if most of the detected 3D rectangle contained the ground truth CT. As can be seen in Figs. 14 and 15, the organs (liver and spleen) were correctly located inside the estimated region in each of the CT cases. Three slices that pass through the detected position of the target organ are shown. The rectangle indicated the detected organ location (bounding rectangle of liver and spleen). These results show that the proposed approach can perform localization tasks successfully.

For the accuracy assessment of our method, we compared it with conventional and recently developed atlas-based segmentation algorithms by different metrics.


                        Dice coefficient (Dice). The dice coefficient is one of the most popular methods to evaluate segmentation accuracy. This metric is given in percent and based on the voxels of two binary 3D volumes, with 
                           
                              
                                 V
                              
                              
                                 manual
                              
                           
                         as the manually and 
                           
                              
                                 V
                              
                              
                                 auto
                              
                           
                         as the automatically segmented organ:
                           
                              (4)
                              
                                 Dice
                                 =
                                 
                                    
                                       2
                                       |
                                       
                                          
                                             
                                                V
                                             
                                             
                                                manual
                                             
                                          
                                          ∩
                                          
                                             
                                                V
                                             
                                             
                                                auto
                                             
                                          
                                       
                                       |
                                    
                                    
                                       |
                                       
                                          
                                             
                                                V
                                             
                                             
                                                manual
                                             
                                          
                                       
                                       |
                                       +
                                       |
                                       
                                          
                                             
                                                V
                                             
                                             
                                                auto
                                             
                                          
                                       
                                       |
                                    
                                 
                                 ×
                                 100
                                 %
                              
                           
                        
                     


                        Tanimoto volume overlap (VO). The Tanimoto volume overlap between two sets of voxels 
                           
                              
                                 V
                              
                              
                                 manual
                              
                           
                         and 
                           
                              
                                 V
                              
                              
                                 auto
                              
                           
                         is given in percent:
                           
                              (5)
                              
                                 VO
                                 =
                                 
                                    
                                       |
                                       
                                          
                                             
                                                V
                                             
                                             
                                                manual
                                             
                                          
                                          ∩
                                          
                                             
                                                V
                                             
                                             
                                                auto
                                             
                                          
                                       
                                       |
                                    
                                    
                                       |
                                       
                                          
                                             
                                                V
                                             
                                             
                                                manual
                                             
                                          
                                          ∪
                                          
                                             
                                                V
                                             
                                             
                                                auto
                                             
                                          
                                       
                                       |
                                    
                                 
                                 ×
                                 100
                                 %
                              
                           
                        
                     


                        Root mean square error (RMSE). The root mean square error is given in millimeters and based on the surface points of two 3D images 
                           
                              
                                 V
                              
                              
                                 manual
                              
                           
                         and 
                           
                              
                                 V
                              
                              
                                 auto
                              
                           
                        :
                           
                              (6)
                              
                                 RMSE
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             N
                                          
                                       
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             N
                                          
                                       
                                       
                                          
                                             [
                                             
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            
                                                               V
                                                            
                                                            
                                                               manual
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                   
                                                      i
                                                   
                                                
                                                −
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            
                                                               V
                                                            
                                                            
                                                               auto
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             ]
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           N
                         represents the total number of surface points.

In order to make a comparison, we compared the results using the conventional method (ConSeg–ConAtlas), in which the transformation between the reference bone and the patient bone was directly applied to the conventional atlas, according to [19]. In addition, we compared our organ segmentation method with the iterative probabilistic atlas based on the Gaussian distribution analysis (ConSeg–IterAtlas) to remove irrelevant tissues [24].

To investigate the performance of our segmentation method, we randomly selected one real case in our dataset to be performed on liver and spleen segmentation. Comparison the original CT image (Fig. 16
                           (a)) with the corresponding likelihood map (Fig. 16(c)) revealed that the liver can be more easily distinguished from other tissues in the likelihood map. However, if we applied the atlas information on the likelihood map, the other tissues with similar intensity can be significantly reduced, as shown in Fig. 16(d)–(f). Wherein, a brighter voxel indicates a higher probability of being liver. The black region corresponds to the non-liver region. Compared with Fig. 16(d)–(f), we can see that the false positives (other tissues with similar intensity) can be significantly reduced by the use of the conventional atlas in Fig. 17
                           . Moreover, it can be seen that there were still a lot of false positives in the conventional method despite using an iterative atlas, because we cannot align the iterative atlas to the patient volume accurately, unlike our proposed method that can achieve more accurate alignment. Template matching in our method was utilized to improve the accuracy of the registration.

The template matching was aimed to estimate an initial segmentation of the liver. If we threshold the output of template matching, it can give an initial segmentation of the liver. Furthermore, in order to obtain an accurate result, we refined the initial segmentation result using the GAC algorithm. The final segmentation result of the two cases is shown in Fig. 18
                           . The red results are segmented liver slice, which are overlaid with the original CT slices. The results demonstrate that accurate segmentations have been achieved.

Quantitative and comparative results of applying different methods to liver segmentation with different phases are presented in Fig. 19
                           . The first 6 data corresponds to ART-phase cases (with the average Dice׳s similarity coefficient =0.944), the next 12 data corresponds to PV-phase cases (with Dice=0.929) and the remaining 4 data is phase-DL cases (with Dice=0.912). It reveals that our proposed method was robust to the liver segmentation with different CT phases. Table 1
                            listed the average of Dice, VO and RMSE between automated and manual segmentations with different segmentation methods for all test CT scans. The results indicated that comparison of the conventional segmentation method (ConSeg) with our proposed segmentation method (OurSeg) results indicate a significant improvement. The simulation verified that the performance of OurSeg (
                              Dice
                              >
                              0.93
                           ) was much better than ConSeg for segmenting the liver.

Moreover, we compared our proposed method with the state-of-the-art segmentation methods from the MICCAI 2007 competition: constrained convex variational model [44], iterative mesh transformation [45], heuristic intensity model [46], automatic level-set method [47], normalized probabilistic atlas [20], statistical deformable model [48] and global-to-local shape matching [49]. We also validated our proposed method with the MICCAI training dataset. Our method was trained with our database which was described in the beginning of Section 3 and tested on the MICCAI test dataset. The quantitative validation utilizes five metrics [50] including two volume errors: volumetric overlap error (VOE) and relative volume difference (RVD) and three surface errors: average symmetric surface distance (ASD), root mean square symmetric surface distance (RSD) and maximum symmetric surface distance (MSD). The average errors for the five metrics are summarized in Table 2
                           . Our algorithm achieved a score of 77.1 point for the MICCAI data using the validation tools provided by the organizers of the MICCAI competition. The score of our method was observed to be slightly higher than the 75 point of average manual segmentation. The results demonstrated that our proposed approach yields the high precision results with respect to liver segmentation. The accuracy of our automatic method was higher in comparison with the state-of-the-art automatic segmentation methods such as Kainmller et al. (2007) 73 point, Lee et al. (2007) 75 point, Heimann et al. (2007) 67 point and slightly lower with interactive segmentation methods such as Peng et al. (2014) 80.6 point and Lee et al. (2015) 77.9 point. Fig. 20
                            shows the accuracy of our segmentation results with different number of training samples. It can be seen that the segmentation accuracy of our proposed method can be significantly improved by increasing the training samples.

The different spleen segmentation methods were compared in Fig. 21
                           . It can be seen from Fig. 21(c) that the spleen can be more easily distinguished from other tissues in the likelihood map. The other tissues with similar intensity can be significantly reduced using conventional atlas (Fig. 21(d)).

Due to the spleen atlas can not be registered accurately, it remains a lot of other tissues in the conventional method despite using an iterative atlas (Fig. 21(e)). As shown in Fig. 21(f), using our proposed method, the spleen׳s location can be found more accurately based on the template matching. The accuracy of the estimated spleen probability is described previously by the characteristic curve analysis which is similar to the ROC analysis (Fig. 22
                           ). OurSeg–IterAtlas method had significant differences for the ROC curve (with the threshold change) compared with ConSeg–ConAtlas and ConSeg–IterAtlas methods. Fig. 23
                            presents the final segmentation result for the spleen by the GAC algorithm.


                           Fig. 24
                            shows quantitative and comparative results from applying different methods to segment the spleen on 26 test cases. The first 6 data corresponds to ART-phase cases (the average Dice is 0.933), the data 7–data 18 correspond to PV-phase cases (Dice is 0.922) and the remaining 4 data are phase-DL cases (Dice is 0.906). Regarding the result of applying our method to different contrast-phases, we can conclude that our proposed method was robust for the spleen segmentation. Table 1 gives a clearer depiction of the corresponding accurate results. It lists the average of Dice to be 0.922, VO is 0.857 and RMSE is 1.992mm for our proposed method. It can be seen that OurSeg–IterAtlas method had better performance for segmenting the spleen.

@&#DISCUSSION@&#

In this paper, we proposed an automatic segmentation algorithm based on the anatomical model to segment multiple organs. The basic idea of our method was motivated by the Bayes framework. However, our proposed algorithm incorporates a template matching concept within a Bayes framework. We firstly found a bounding box of the organ based on human anatomic structure, which was the relatively rigid characteristics of organ position; and then the iterative probabilistic atlas was used as a template to find the organ in this bounding box by the use of template matching. As explained above, the proposed method segmented an organ based on a set of priori information. Priori information included the approximate location of an organ, the histogram of the organ׳s intensities, and a probabilistic atlas of the organ. The priori information for each organ was trained separately and independently in our method.

To construct an iterative probabilistic atlas, we employed large variations of liver shapes in the training data. With the atlas information, we had a very reliable prior knowledge where the organ was located. Fig. 25
                         shows the segmentation results for different thresholds of atlas using our proposed method. Lowering the threshold for the VOI results in better robustness, but it may also bias the estimates, e.g., lowered threshold VOI might include multiple organs; conversely, with the higher threshold for the VOI, it may result in the loss of regions for the organ. Based on the mean Dice measure of the available datasets, we concluded a selection of 30% as the optimum threshold value to generate a new probabilistic atlas image. Hence, in all the above experiments, a regional threshold of over 30% was used for specifying the atlas for the desired organ.

The organ bounding box was employed to estimate the approximate location of an organ for the observed data. We found the volume of interest (VOI) of the ensemble of the registered training organs and used it as the organ bounding box. Our constructed organ bounding box was large enough to contain all organ shapes/sizes in the training dataset. In our work, the search range is the organ bounding box. Empirically, a larger searching ranges lead to more computational time, while yielding possibly better performances. For the liver, the searching range was 
                           285.753
                           ×
                           216.138
                           ×
                           199.200
                           
                           
                              
                                 mm
                              
                              
                                 3
                              
                           
                         (
                           431
                           ×
                           326
                           ×
                           166
                         voxels); the average of computation time was about 142.85s. For the spleen, the searching range was 
                           130.611
                           ×
                           147.849
                           ×
                           133.200
                           
                           
                              
                                 mm
                              
                              
                                 3
                              
                           
                         (
                           197
                           ×
                           223
                           ×
                           111
                         voxels); the average of computation time was about 150.89s. Currently, the organs (liver and spleen) were correctly located inside the estimated searching range (the estimated bounding box) for all test CT cases. From Figs. 14 and 15, it can be seen that the proposed approach can find the approximate central position and determine the size of the bounding rectangle of the target organ regions. The accuracy of bounding box plays an immediate decisive role in the process of organ segmentation.

We validated our results by the analysis of the pathological cases with large morphological changes. A common difficulty for computer-aided liver segmentation is the erroneous inclusion of the liver tumor, which our method consistently avoided. Additional challenges come from enlarged livers, where the liver has large shape variations which made it very difficult to be segmented by the conventional method. We presented three examples of segmentations from pathological cases, which exhibited the tumor, enlarged livers with unusual liver shapes, as seen in Fig. 26
                        . The results demonstrated that our proposed method can segment pathological livers with a precision segmentation result.

The segmentation of the spleen has been seldom addressed in medical imaging. However, the morphological analysis of the spleen was as important as that of the liver for diagnosis. While the segmentation of the spleen may be less challenging than that of the liver, it can still suffer from errors induced by adjacent organs, tumor effects and variations in contrast during enhancement. Additionally, pathological spleens are segmented in Fig. 27
                        . This reveals the robustness of our proposed algorithm in the presence of tumors. The combination of visualization and experimental identifications will facilitate the understanding of the performance of our proposed method. Fig. 28
                         illustrates the surface renderings of 3D segmentation results of the manual (left) and our automatic method (right). There were several visual differences between the manual and the automatic segmentations, especially in the hepatic left lobe area, which have been highlighted by an orange circle in Fig. 28. That means the segmentation accuracy was not very high in the hepatic left lobe area. The reason is that the hepatic left lobe has a large shape variation, while our method is based on the liver probability atlas (the probability of the liver shape and position).

As illustrated in Table 3
                        , our proposed method (OurSeg–IterAtlas) was compared with conventional atlas-based (ConSeg–ConAtlas) and recently developed atlas-based (ConSeg–IterAtlas) methods. The accuracy of ConSeg was observed to have a significantly lower Dice/VO and a higher RMSE than OurSeg method. To directly demonstrate the performance of our proposed method, in respect to the statistical significance analysis, the p-value was the probability of obtaining a test statistic result that was actually observed. The p-value of t-test was used because the calculation is relatively simply and more efficient, and it is widely used in the medical field. We achieved the results of statistical tests (p-value) for liver and spleen in two series, listed in Table 3. In series 1, OurSeg–IterAtlas and ConSeg–ConAtlas were compared with three metrics: Dice, VO and RMSE. In series 2, OurSeg–IterAtlas and ConSeg–IterAtlas were compared. It was found that using shape information from an iterative probabilistic atlas improved significantly (
                           p
                           <
                           0.00001
                        ) the liver volume estimations (see the upper part of Table 3). This may be explained partly by the iterative reference used to construct the atlas. However, the improvement brought by the template matching was significant for all metrics used in the bottom part of Table 3 (
                           p
                           <
                           0.00001
                        ) in comparison to OurSeg–IterAtlas segmentation. Template matching was utilized to improve the accuracy of the registration for registering the atlas. These statistics proved that the improved results were obtained with respect to all metrics in our proposed method, as opposed to those in the conventional and recently developed atlas-based methods (
                           p
                           <
                           0.00001
                        ).

@&#CONCLUSION@&#

In this paper, we proposed a template matching framework based on an iterative probabilistic atlas for liver and spleen segmentation. First of all, a bounding box based on human anatomical localization, which is referred to the statistical geometric location of the organ, was detected for the candidate organ. Then the iterative probabilistic atlas was used as a template to find the organ in the bounding box using template matching technology. At the same time, our algorithm incorporated an atlas concept within a bounding box construction. For the iterative probabilistic organ models, the analysis of abdominal atlases could provide information about organ location and shapes, in addition, it can overcome the drawback of conventional atlas in respect to a specific patient because of the single reference. Compared with the conventional and recently developed atlas-based methods, our proposed method can significantly improve both segmentation accuracy and robustness. Our automated technique has the potential to offer complementary imaging to assist and improve the diagnosis. As for future work, the proposed method could be extended to segment other organs, such as the kidneys or the lungs.

None declared.

@&#ACKNOWLEDGEMENT@&#

This research was supported in part by the Grant-in Aid for Scientific Research from the Japanese Ministry for Education, Science, Culture and Sports (MEXT) under the Grant No. 2430076 and No. 15H01130, in part by the MEXT Support Program for the Strategic Research Foundation at Private Universities (2013-2017), in part by the R-GIRO Research Fund from Ritsumeikan University, in part by National Science and Technology Support Program of China under the Grant no. 2013BAF02B10, and in part by the Recruitment Program of Global Experts (HAIOU Program) from Zhejiang Province, China.

@&#REFERENCES@&#


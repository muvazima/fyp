@&#MAIN-TITLE@&#Obtaining optic disc center and pixel region by automatic thresholding methods on morphologically processed fundus images

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A method for OD segmentation and center-location on fundus images is presented.


                        
                        
                           
                           The methodology was tested on 1890 fundus images acquired from diabetic patients.


                        
                        
                           
                           Estimated and real OD center distance remained below 1/4 OD radius in 96% of cases.


                        
                        
                           
                           OD segmentation estimations outperform all the reviewed methods in literature.


                        
                        
                           
                           The method is suitable to be integrated into a system for retinal-disease diagnosis.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optic disc

Fundus image

Diabetic retinopathy

Medical image analysis

@&#ABSTRACT@&#


               
               
                  Development of automatic retinal disease diagnosis systems based on retinal image computer analysis can provide remarkably quicker screening programs for early detection. Such systems are mainly focused on the detection of the earliest ophthalmic signs of illness and require previous identification of fundal landmark features such as optic disc (OD), fovea or blood vessels. A methodology for accurate center-position location and OD retinal region segmentation on digital fundus images is presented in this paper. The methodology performs a set of iterative opening–closing morphological operations on the original retinography intensity channel to produce a bright region-enhanced image. Taking blood vessel confluence at the OD into account, a 2-step automatic thresholding procedure is then applied to obtain a reduced region of interest, where the center and the OD pixel region are finally obtained by performing the circular Hough transform on a set of OD boundary candidates generated through the application of the Prewitt edge detector. The methodology was evaluated on 1200 and 1748 fundus images from the publicly available MESSIDOR and MESSIDOR-2 databases, acquired from diabetic patients and thus being clinical cases of interest within the framework of automated diagnosis of retinal diseases associated to diabetes mellitus. This methodology proved highly accurate in OD-center location: average Euclidean distance between the methodology-provided and actual OD-center position was 6.08, 9.22 and 9.72 pixels for retinas of 910, 1380 and 1455 pixels in size, respectively. On the other hand, OD segmentation evaluation was performed in terms of Jaccard and Dice coefficients, as well as the mean average distance between estimated and actual OD boundaries. Comparison with the results reported by other reviewed OD segmentation methodologies shows our proposal renders better overall performance. Its effectiveness and robustness make this proposed automated OD location and segmentation method a suitable tool to be integrated into a complete prescreening system for early diagnosis of retinal diseases.
               
            

@&#INTRODUCTION@&#

Diabetic Retinopathy (DR) is a retinal disease derived from complications caused by the abnormally high levels of glucose in blood produced by diabetes mellitus (DM). Closely associated with DR is the diabetic Macular Edema (ME), a swelling of the retina due to fluid leaking from blood vessels within the macula. DR and ME constitute the main cause of blindness in diabetic patients: although diabetes does not necessarily involve vision impairment, about 2% of patients are blind, and 10% undergo vision degradation after 15 years of diabetes as a consequence of these complications [1] and [2].

The main problem involved by DR and ME diagnosis is that these disorders are usually asymptomatic in their early stages, when medical treatment is more effective and disease progression can be prevented. Therefore, to ensure treatment is received on time, diabetic patients need annual eye-fundus examination [3]. However, this preventive action means a huge challenge for health services, since the number of potential patients is very high (DM affects around 6% of the general population and its total number of patients is forecasted to reach 366 million in 2030 [4]). In this framework, development of automatic DR and ME diagnosis systems based on retinal image computer analysis may provide a remarkably quicker screening programs for early detection of these disorders. Such systems are mainly focused on the detection of early ophthalmic signs of illness (i.e., microaneurysms, hemorrhages, exudates). This way, much effort has been focused on the development of algorithms for these early DR- and ME-related lesions in recent years [5–7].

Regarding ME, one of the earliest possible ophthalmic signs of illness is the presence of exudates in the retina. Exudates are lipid and lipoprotein deposits appearing as white or yellowish regions on fundus image retinography. Although the presence of exudates is not always a strong surrogate for ME (they are present in roughly 90% of ME patients), their detection – specifically their number and position in the retina relative to the fovea – can be used for automatic graduation of the risk of future disease development [8,9].

This task requires previous identification of fundal landmark features such as the optic disc (OD). Like exudates, the OD usually appears in eye fundus images as a yellowish region and its segmentation is particularly important to reduce false positives in the detection of regions of retinal exudates [10]. On the other hand, OD segmentation can also be useful as valuable information to detect other fundus features such as the fovea [11], whose location is used for disorder-grade determination (the distance at which exudates are located from it influences the clinical relevance of ME). This way, OD center position can be used for fovea center estimation, since both points are separated on average a relatively constant distance of 2.5 OD diameters [12].

Numerous automated methods for retinal OD detection on eye fundus images have been reported over the last years. They can be mainly grouped into location and segmentation methods, depending on whether they are focused on finding an OD pixel, [13–19] or estimating its boundary and thus segmenting its pixel region [20–25].

Regarding the most recent methodologies, an OD segmentation methodology using three independent location methods and a voting procedure is presented in [26]. In [27], a circular transformation evaluates image variation along multiple evenly oriented radial line segments of specific length. The pixels with maximum variation along all radial line segments are determined, as they can be further exploited for both OD center and boundary location. A method for OD location based on clustering and histogram techniques is proposed in [28]. In this method, candidate regions are firstly determined by clustering the brightest pixels in the red plane of the fundus image. Then, three pixels are determined within the candidate region in the green plane by using three independent methods for OD location. In [29], OD location candidates are identified using template matching. The template is designed to adapt itself to different image resolutions. Then, vessel features (patterns) on the OD are used to determine OD location. Using the detected OD center and estimated OD radius, a hybrid levelset model, combining region and local gradient information is applied to OD boundary segmentation. The method proposed in [30] is mainly based on mathematical morphology, along with principal component analysis (PCA). It makes use of different operations such as the generalized distance function (GDF), a variant of the watershed transformation, the stochastic watershed, and geodesic transformations. The input of the segmentation method is obtained through PCA. Finally, to the best of our knowledge, the most recent studies on OD detection are the methodologies presented in [31] and [32]. In [31], blood vessel network-extracted information is combined with intensity data. In [32], OD is located exclusively according to brightness criteria. The OD pixel is detected through the centroid of the highest intensity pixels on a morphologically processed fundus image.

This paper presents a new methodology for automatic identification of the OD pixel region and its center position on retinal images. On one hand, this methodology is based on exploiting OD visual appearance. This region is recognizable on fundus images as a round bright area. Thus, a set of morphological opening and closing operations are applied to enhance this kind of structures. On the other hand, it also exploits the fact that the OD is the entry point for the major blood vessels that supply the retina. In this sense, as shown in Section 3, the main vessels from the vascular arch play an important role, and their segmentation is also proposed.

It should be pointed out that this work is specifically aimed at contributing to the development of a system for automated DR detection that is currently being implemented by the Health Ministry of the Andalusian Regional Government (Spain) with the purpose of enhancing the effectiveness of its DR screening program. Although other published solutions for OD segmentation may be used, this system's proven effectiveness and robustness, together with its simplicity, make our proposed method a suitable tool to be integrated into the mentioned automated prescreening system.

The rest of the paper is organized as follows. The testing material used in this study is described in Section 2, while the proposed method is explained and illustrated in Section 3. Section 4 presents the obtained results and compares them to those obtained with other available methods. Finally, the authors’ conclusions put an end to this paper.

To evaluate the OD location and segmentation methodology described in the next section, the publicly available MESSIDOR [33] and MESSIDOR-2 [34,35] databases were used. These databases contain 1200 and 1748 eye fundus color images of the posterior pole, respectively. All fundus images were captured using a Topcon TRC NW6 non-mydriatic retinograph with 45° field-of-view (FOV) digitalized to 1440×960, 2240×1488 or 2304×1536 pixels, and are 8 bits per color plane.

The images in the MESSIDOR database were acquired by the Paris Hôpital Lariboisière, the Faculté de Médecine St. Etienne, and the LaTIM at Brest (France). 800 images were captured with pupil dilation (Lariboisière and St. Etienne subsets), and 400 without dilation (LaTIM subset). All fundus images from this database were diagnosed by medical experts attending to a classification designed within the framework of the Messidor – Techno-Vision Project. This classification grades DR into four stages (on a scale of 0–3, with 0 being normal retina) and evaluates the ME risk into three grades (on a scale of 0–2, with 0 being no risk). According to this classification, the whole set of MESSIDOR images includes 540 cases of healthy retinas (DR grade = 0; ME risk = 0), 660 cases of pathological retinas showing some DR or ME sign (DR grade ≠ 0 or ME risk ≠ 0) and 229 cases of retinas with presence of hard exudates and thus showing ME signs (ME risk ≠ 0). Therefore, the choice of this database allows evaluating the methodology under ME-related retinas where the presence of exudates may hinder OD location (as OD, exudates appear as bright yellowish regions in fundus images).

MESSIDOR-2 database includes 874 two macula-centered eye fundus images (one per eye): 529 pairs of these images (1058 images) were obtained from the original MESSIDOR database. The remaining images (345 pairs, 680 images) consist of previously unpublished examinations acquired from diabetic patients by LaTIM at Brest (France). This set was imaged with no pharmacological dilation.

On the other hand, MESSIDOR and MESSIDOR-2 databases provide no binary masks delineating retina pixels for the images (FOV masks). The use of these masks allows the application of algorithms exclusively within the retina, as well as obtaining outstanding information. For instance, for a given fundus image, retina diameter can be easily determined by measuring the diameter of the FOV mask. This fact is especially relevant in this paper, as the OD radius can be estimated from this retina size. Therefore, a FOV mask was generated for each fundus image.

@&#METHODOLOGY@&#

This work is aimed at introducing a methodology for OD segmentation and location through its center position on fundus images. The following general process stages may be identified: (1) resizing for standardizing retinal size of different resolution images, (2) segmentation of the main retinal vessels from the OD, (3) morphological processing for enhancing round bright regions, and (4) obtaining the center and the OD pixel region by applying feature extraction techniques on an OD-containing region of interest.

Before describing the proposed methodology, notice that all parameters used were set by experiments carried out on a local database comprising 118 digital retinal images aimed at minimizing the Euclidean distance between methodology-obtained and actual OD center position, the latter being manually determined by an ophthalmologist. This training database was provided for this study by the Health Ministry of the Andalusian Regional Government (Spain).

As commented, MESSIDOR and MESSIDOR-2 fundus images are 1440×960, 2240×1488 or 2304×1536 pixels in size, corresponding to retinal diameters, D
                        
                           FOV
                        , of approximately 910, 1380 and 1455 pixels, respectively. In order to standardize retinal size, the original color fundus image is firstly resized to a 540-pixel D
                        
                           FOV
                        . Therefore, the remaining methodology processes are performed on this retina size and all parameters given below refer to 540 pixel-diameter retinas. The application of the methodology without resizing input color images or confronting with different resolution images demands proportional adaptation of the whole set of parameters to the operating retina size.

This first resizing step – apart from guaranteeing the method's suitability to be applied on any resolution fundus image – allows a reduction in computational time with no performance loss. Tests on image resolution were completed by scaling down our training database images and measuring location and segmentation results. These tests revealed that results are independent and stable in spite of reducing image resolution down to the selected 540-pixel retinal diameter.

The methodology for segmenting the main retinal vessels firstly applies a shade-correction method for removing possible background lighting variations in the fundus image. Next, morphological processing is carried out to produce a blood vessel-enhanced image, which is then thresholded to obtain a first estimation of the vascular tree. Finally, this vessel-segmented binary image is post-processed with the aim of detecting just the main vessels from the vascularity arch.

Input to this methodology are monochrome images obtained by extracting the green band from resized original RGB fundus images. The green channel provides the best vessel-background contrast of the RGB representation, and blood containing elements in the retinal layer such as vessels are those represented best. Let us denote this input image as G.

Next, a brief description of the procedure is illustrated through its application to a MESSIDOR image (Fig. 1
                        ).

Fundus images often contain background intensity variations due to non-uniform illumination. Consequently, background pixels may have different intensity for the same image and, although their gray levels are usually higher than those of vessel pixels (relative to the green channel or intensity fundus images), the values of some background pixels is comparable to those of brighter vessel pixels. Since a global thresholding technique is used to estimate the vascular tree, this effect may worsen its detection.

With the purpose of removing these background lightening variations, the shade-correction method proposed in [36] is applied. Basically, a background estimate, G
                           
                              B
                           , is firstly obtained by filtering G with a 69×69 arithmetic mean kernel. As stated above, note that the whole set of methodology parameters are referred to 540 pixel-diameter retinas. Next, the difference between G and G
                           
                              B
                            is calculated for every pixel (pixel values being converted to real numbers, thus allowing negative values). Finally, a shade-corrected image, G
                           
                              SD
                           , is obtained by transforming linearly these difference values into integers covering the whole range of possible gray-levels ([0-255], referred to 8-bit images). The shade-correction algorithm is observed to reduce background intensity variations and enhance contrast in relation to the input green channel image (see Fig. 1, images (a) and (b)).

Firstly, this step generates a vessel-enhanced image, G
                           
                              VE
                           , that proves more suitable for further vascular tree segmentation. Vessel enhancement is performed by estimating the complementary image of the shade-corrected G
                           
                              SD
                            image, 
                              
                                 G
                                 SD
                                 C
                              
                           , and subsequently applying the morphological Top-Hat transformation:


                           
                              
                                 (1)
                                 
                                    
                                       G
                                       VE
                                    
                                    =
                                    
                                       G
                                       SD
                                       C
                                    
                                    −
                                    
                                       γ
                                       
                                          8
                                          D
                                       
                                    
                                    (
                                    
                                       G
                                       SD
                                       C
                                    
                                    )
                                 
                              
                           where γ
                           8D
                            is a morphological opening operation using a disc of 8 pixels in radius. As observed in Fig. 1, image (c), while bright retinal structures are removed (i.e., OD, possible presence of exudates or reflection artifacts), the darker structures remaining after the opening operation become enhanced (i.e., blood vessels, fovea, possible presence of microaneurysms or hemorrhages). Thus, images G
                           
                              VE
                            contain two classes of pixels (e.g. background, corresponding to bright pixels, and foreground, corresponding to the darkest ones), being suitable to perform clustering-based thresholding methods. In this paper the widely used Otsu method [37] was applied to decide an optimum global threshold (Th
                           0) adapted for the fundus image under consideration.

Secondly, a vascular tree-estimated binary image, 
                              
                                 VT
                                 0
                                 b
                              
                           , is produced by globally thresholding G
                           
                              VE
                            according to the following equation
                              1
                           
                           
                              1
                              In this paper, binary images are distinguished by superscript 
                                    b
                                 . In addition, their possible pixel values will be 0 or 255, as we always deal with 8-bit images.
                           :


                           
                              
                                 (2)
                                 
                                    
                                       VT
                                       0
                                       b
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                         
                                                      
                                                         G
                                                         VE
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      >
                                                      
                                                         Th
                                                         0
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Finally, two-step postprocessing is applied to 
                              
                                 VT
                                 0
                                 b
                              
                            to segment just the main vessels from the vascular arch. Firstly, a morphological opening operation using a 3 pixel-wide square structuring element is performed. Thus, narrow vessels too small to contain the structuring element are broken or even eliminated if they appear as isolated regions. Secondly, the resulting 8-connected regions with less than 750 pixels are eliminated to obtain our final main vessel-segmented image, VT
                           
                              b
                            (see Fig. 1, image(d)). The set of high-level pixels in VT
                           
                              b
                            will be required in next stages of the methodology as input data. Let us denote this set as S(VT
                           
                              b
                           ) 
                              2
                           
                           
                              2
                              This notation will be used in the rest of this paper: in general, S(Initials
                                 
                                    b
                                 ) stands for the set of coordinates identified with value 255 in the binary image Initials
                                 
                                    b
                                 , excluding thus the set of background pixels.
                           :


                           
                              
                                 (3)
                                 
                                    S
                                    (
                                    
                                       VT
                                       b
                                    
                                    )
                                    =
                                    {
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    :
                                       
                                    
                                       VT
                                       b
                                    
                                    =
                                    255
                                    }
                                 
                              
                           
                        


                        
                           Algorithm 1
                           Pseudocode for the application of the morphological procedure to enhance round bright regions.


                              
                                 
                                    
                                       
                                       
                                       
                                          
                                             1:
                                             
                                                input: 
                                                I
                                                
                                                   MInput
                                                
                                             
                                          
                                          
                                             2:
                                             
                                                output: 
                                                I
                                                
                                                   Morph
                                                
                                             
                                          
                                          
                                             3:
                                             
                                                begin
                                             
                                          
                                          
                                             4:
                                             
                                                I
                                                
                                                   closed
                                                
                                                =
                                                I
                                                
                                                   HSI
                                                
                                             
                                          
                                          
                                             5:
                                             
                                                for 
                                                radius
                                                =4, 8, 12, 16
                                          
                                          
                                             6:
                                             
                                                
                                                se
                                                =
                                                structuralElement(disk, radius)
                                          
                                          
                                             7:
                                             
                                                
                                                I
                                                
                                                   opened
                                                
                                                ←
                                                opening(se, I
                                                
                                                   closed
                                                )
                                          
                                          
                                             8:
                                             
                                                
                                                I
                                                
                                                   closed
                                                
                                                ←
                                                closing(se, I
                                                
                                                   opened
                                                )
                                          
                                          
                                             9:
                                             
                                                end for
                                             
                                          
                                          
                                             10:
                                             
                                                return 
                                                I
                                                
                                                   closed
                                                
                                             
                                          
                                          
                                             11:
                                             
                                                end
                                             
                                          
                                       
                                    
                                 
                              
                           

The OD may be distinguished on eye fundus images as a rounded shape with high intensity values. To produce a suitable image for further stages of the methodology, morphological processing is performed to obtain a smoothed image where the largest bright regions are enhanced. Specifically, a set of morphological opening and closing operations are iteratively applied four times to an intensity image obtained as described below. The selected structural element is a disc whose radius increases in each iteration (r
                        =4, 8, 12, 16), as presented in Algorithm 1. Let us denote the input and output images of this process as I
                        
                           MInput
                         and I
                        
                           Morph
                        , respectively.

Concerning I
                        
                           MInput
                         generation, intensity images are firstly obtained by finding the average of the red, green and blue channels, which are extracted from the resized color fundus image (see Fig. 2
                        , image (a)). In this respect, performed tests revealed that intensity images provide better performance for our methodology than green channel images. Then, the shade-correction method described in Section 3.2.1 of this paper is applied for intensity homogenization. This shade-corrected image is the input image I
                        
                           MInput
                         (Fig. 2, image (b)).

The resultant images of each of the 4-iterations comprised in this morphological procedure are shown in Fig. 2, images (c–f). Small bright structures that may appear in the fundus image (i.e., hard exudates) can be observed to be progressively removed. On the other hand, the OD region is observed to belong to the cluster of brightest pixels in output I
                        
                           Morph
                         images, its boundary being clearly distinguished (see Fig. 2, image (f)). These facts allow OD segmentation by using the thresholding and feature extraction scheme described next.

This methodology consists on firstly obtaining an OD-containing region of interest. This way, increased robustness and efficiency is obtained due to reduced space for search and thus also the reduced number of artifacts and distracters present in the whole image. The generation of this region of interest is performed by a 2-step automatic thresholding procedure applied on images I
                        
                           Morph
                        : the first step is aimed at finding a pixel within or near enough the OD (Section 3.4.1), while the second step is aimed at discarding the darkest values of a neighborhood window centered on it (Section 3.4.2). In both cases, the threshold was automatically set by applying the Otsu method. Finally, the OD is segmented by applying the circular Hough transform on a binary mask of OD boundary candidates (Section 3.4.3).

As stated above, the OD is observed as a homogenized region of high intensity pixels on images I
                           
                              Morph
                           . On the other hand, main blood vessels converge on the OD, thus vessel pixels given by S(VT
                           
                              b
                           ) include pixels within the OD and its vicinity. Therefore, the set of I
                           
                              Morph
                            values on S(VT
                           
                              b
                           ) can be assumed to be representative of the OD and its background surroundings. Let us stand for this set of I
                           
                              Morph
                            values defined on S(VT
                           
                              b
                           ) coordinates as I
                           
                              Morph
                           (S(VT
                           
                              b
                           )):


                           
                              
                                 (4)
                                 
                                    
                                       I
                                       Morph
                                    
                                    (
                                    S
                                    (
                                    
                                       VT
                                       b
                                    
                                    )
                                    )
                                    =
                                    {
                                    
                                       I
                                       Morph
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    :
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    ∈
                                    S
                                    (
                                    
                                       VT
                                       b
                                    
                                    )
                                    }
                                 
                              
                           
                        

In this way, image I
                           
                              Morph
                            is globally thresholded using a threshold Th
                           1 that is computed exclusively taking I
                           
                              Morph
                           (S(VT
                           
                              b
                           )) values into account:


                           
                              
                                 (5)
                                 
                                    
                                       HIP
                                       b
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                         
                                                      
                                                         I
                                                         Morph
                                                      
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      >
                                                      
                                                         Th
                                                         1
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where HIP
                           
                              b
                            denotes the output binary image that identifies the cluster of high intensity pixels in I
                           
                              Morph
                           . This cluster may include, in addition to OD pixels, possible remains of exudates or other bright structures. In these cases, the connected component in HIP
                           
                              b
                            corresponding to the OD has to be extracted. This is done as follows. Every 8-connected region in HIP
                           
                              b
                            is characterized by means of its blood vessel confluence, BVC, that is computed by counting its number of pixels included in S(VT
                           
                              b
                           ). Mathematically, the blood vessel confluence of the ith-connected region can be expressed as
                              
                                 (6)
                                 
                                    
                                       BVC
                                       i
                                    
                                    =
                                    #
                                    {
                                    S
                                    (
                                    
                                       HIP
                                       i
                                       b
                                    
                                    )
                                    ∩
                                    S
                                    (
                                    
                                       VT
                                       b
                                    
                                    )
                                    }
                                 
                              
                           where i
                           =1, …, N
                           
                              c
                            and 
                              S
                              (
                              
                                 HIP
                                 i
                                 b
                              
                              )
                            denote the high-level coordinates of the binary image associated to the ith connected region, 
                              
                                 HIP
                                 i
                                 b
                              
                           , N
                           
                              c
                            is the number of detected connected components, and # refers to the cardinality of the coordinate set passed as an argument. Then, the binary image linked to the connected region providing the maximum BVC value, denoted by 
                              
                                 OD
                                 Cand
                                 b
                              
                           , is selected to identify a first set of potential OD pixel candidates:


                           
                              
                                 (7)
                                 
                                    
                                       OD
                                       Cand
                                       b
                                    
                                    =
                                    
                                       HIP
                                       
                                          
                                             i
                                             0
                                          
                                       
                                       b
                                    
                                 
                              
                           where 
                              
                                 i
                                 0
                              
                              =
                              
                                 arg
                                 i
                              
                              (
                              max
                              {
                              
                                 BVC
                                 i
                              
                              ,
                                 
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 N
                                 c
                              
                              }
                              )
                           
                        

Finally, a pixel located within the OD is obtained as the centroid of the 
                              S
                              (
                              
                                 OD
                                 Cand
                                 b
                              
                              )
                            coordinates included in S(VT
                           
                              b
                           ):


                           
                              
                                 (8)
                                 
                                    
                                       px
                                       OD
                                    
                                    =
                                    round
                                    (
                                    mean
                                    (
                                    S
                                    (
                                    
                                       OD
                                       Cand
                                       b
                                    
                                    )
                                    ∩
                                    S
                                    (
                                    
                                       VT
                                       b
                                    
                                    )
                                    )
                                    )
                                 
                              
                           where px
                           
                              OD
                           
                           =(x
                           
                              OD
                           , y
                           
                              OD
                           ) stands for the coordinates of the detected OD pixel. A sample of both 
                              
                                 OD
                                 Cand
                                 b
                              
                            binary image and the detected OD pixel is presented in Fig. 2, image (f).

This process also works on bright region-enhanced I
                           
                              Morph
                            images. It benefits from the coordinates of the previously-obtained OD pixel px
                           
                              OD
                           , as well as from the image of OD-pixel candidates 
                              
                                 OD
                                 Cand
                                 b
                              
                           .

Firstly, an initial region of interest, 
                              
                                 ROI
                                 1
                                 b
                              
                           , is produced by centering on px
                           
                              OD
                            with size fixed to 161×161 (black squared boundary in Fig. 2, image (f)):


                           
                              
                                 (9)
                                 
                                    
                                       ROI
                                       1
                                       b
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                         
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ∈
                                                      
                                                         N
                                                         
                                                            
                                                               px
                                                               OD
                                                            
                                                         
                                                         161
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 N
                                 p
                                 W
                              
                            stands for the set of coordinates in the W
                           ×
                           W sized squared neighborhood window centered on point p.

Taking into account that the methodology is confronted to 540 pixel-diameter retinas, this squared-window size corresponds to approximately 2D
                           
                              OD
                           
                           ×2D
                           
                              OD
                           , D
                           
                              OD
                            being OD diameter (D
                           
                              OD
                            has been estimated as 0.15 times FOV mask diameter). Therefore, this selection is wide enough to include the whole OD region and allows meeting this requirement although px
                           
                              OD
                            does not belong to the OD (yet being nearby is enough).

Next, for further reduction of space for search, a new thresholding of I
                           
                              Morph
                            is carried out on 
                              S
                              (
                              
                                 ROI
                                 1
                                 b
                              
                              )
                            pixels to discard the darkest values:


                           
                              
                                 (10)
                                 
                                    
                                       ROI
                                       b
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        (
                                                                        x
                                                                        ,
                                                                        y
                                                                        )
                                                                        ∈
                                                                        S
                                                                        (
                                                                        
                                                                           ROI
                                                                           1
                                                                           b
                                                                        
                                                                        )
                                                                           
                                                                        and
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        
                                                                           I
                                                                           Morph
                                                                        
                                                                        (
                                                                        x
                                                                        ,
                                                                        y
                                                                        )
                                                                        >
                                                                        
                                                                           Th
                                                                           2
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Threshold Th
                           2 is decided considering a set of I
                           
                              Morph
                           (x, y) values defined at coordinates (x, y) of 
                              S
                              (
                              
                                 ROI
                                 1
                                 b
                              
                              )
                              ∩
                              S
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      OD
                                                      Cand
                                                      b
                                                   
                                                
                                             
                                          
                                          C
                                       
                                    
                                 
                              
                           , where 
                              S
                              
                                 
                                    
                                       
                                          
                                             OD
                                             Cand
                                             b
                                          
                                       
                                    
                                 
                                 C
                              
                            denotes the set of high-level coordinates in the complementary image of 
                              
                                 OD
                                 Cand
                                 b
                              
                           . Note that the brightest OD-pixel values, detected through 
                              
                                 OD
                                 Cand
                                 b
                              
                           , are excluded in Th
                           2 computation. This way, we try to assess the inclusion of the whole OD region in our final region of interest, even when the OD cup, with the brightest values in I
                           
                              Morph
                           , is wide enough.

This resultant binary mask, ROI
                           
                              b
                           , will mark our final space search for OD segmentation and center location (black boundary in Fig. 2, image (g)).

In this final step of the methodology, the Circular Hough Transform [38] is applied with the purpose of finding the circular OD boundary approximation according to the following considerations:
                              
                                 •
                                 It is performed on a set of OD boundary candidates, S(EDGE
                                    
                                       b
                                    ), generated after the application of the Prewitt edge detector [39]. This edge detection operation is applied on a set of I
                                    
                                       Morph
                                     pixels obtained by morphologically dilating our region of interest ROI
                                    
                                       b
                                    . Mathematically:


                                    
                                       
                                          (11)
                                          
                                             
                                                EDGE
                                                b
                                             
                                             =
                                             prewitt
                                             (
                                             
                                                I
                                                Morph
                                             
                                             ,
                                             
                                                γ
                                                
                                                   7
                                                   S
                                                
                                             
                                             (
                                             
                                                ROI
                                                b
                                             
                                             )
                                             )
                                          
                                       
                                    where EDGE
                                    
                                       b
                                     denotes the output edge binary image and γ
                                    7S
                                     is the dilation operation using a 7-pixel square.

Attending to typical OD sizes (according to [40], OD may vary from 1/10 and 1/5 of retina size), radius r was restricted within r
                                    
                                       min
                                     and r
                                    
                                       max
                                    , fixed to 27 and 54, respectively. These sizes represent 1/20 and 1/10 of our 540-pixel retinal diameter. The minimum radius restriction reduces the probability of considering the OD cup, while the maximum radius restriction eliminates candidates with too wide areas.

The procedure can be mathematically summarized by the following equation:


                           
                              
                                 (12)
                                 
                                    (
                                    
                                       x
                                       c
                                    
                                    ,
                                    
                                       y
                                       c
                                    
                                    ,
                                    
                                       r
                                       c
                                    
                                    )
                                    =
                                    CHT
                                    (
                                    S
                                    (
                                    
                                       EDGE
                                       b
                                    
                                    )
                                    ;
                                    
                                       r
                                       min
                                    
                                    ;
                                    
                                       r
                                       max
                                    
                                    )
                                 
                              
                           where (x
                           
                              c
                           , y
                           
                              c
                           ) and r
                           
                              c
                           , respectively, stand for the center position coordinates and the radius that define the circular shape with the highest score in the CHT-implemented Circular Hough Transform.

Therefore, the application of [38] provides OD segmentation according to its circular boundary approximation (contour in white colour in Fig. 2, image (g)). Denoting this resultant binary image as 
                              
                                 OD
                                 Circ
                                 b
                              
                           , our final OD segmentation is defined as:


                           
                              
                                 (13)
                                 
                                    
                                       OD
                                       b
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      255
                                                   
                                                   
                                                      if
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      ∈
                                                      (
                                                      S
                                                      (
                                                      
                                                         OD
                                                         Circ
                                                         b
                                                      
                                                      )
                                                      ∩
                                                      S
                                                      (
                                                      
                                                         ROI
                                                         b
                                                      
                                                      )
                                                      )
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           and final OD center position coordinates, p
                           
                              Exp
                           , as:
                              
                                 (14)
                                 
                                    (
                                    
                                       x
                                       
                                          
                                             OD
                                             c
                                          
                                       
                                    
                                    ,
                                    
                                       y
                                       
                                          
                                             OD
                                             c
                                          
                                       
                                    
                                    )
                                    =
                                    round
                                    (
                                    mean
                                    (
                                    S
                                    (
                                    
                                       OD
                                       Circ
                                       b
                                    
                                    )
                                    ∩
                                    S
                                    (
                                    
                                       ROI
                                       b
                                    
                                    )
                                    )
                                    )
                                 
                              
                           where 
                              S
                              (
                              
                                 OD
                                 Circ
                                 b
                              
                              )
                            and S(ROI
                           
                              b
                           ) are the high-level pixels in 
                              
                                 OD
                                 Circ
                                 b
                              
                            and ROI
                           
                              b
                           , respectively (find an example in Fig. 2, image (h)).

It is important to point out that OD center location and segmentation results are finally adapted to original image size, thus keeping and working with original resolutions for quantifying the algorithmic performance of the methodology.

@&#EXPERIMENTAL RESULTS@&#

To quantify the algorithmic performance of the proposed method on a fundus image, the method-estimated OD-center pixel, denoted by p
                        
                           Exp
                        , and the resulting OD segmentation, denoted by S
                        
                           Exp
                         (set of high-level coordinates in OD
                        
                           b
                        ), are compared to their corresponding ground-truth sets. These sets were built for each of the MESSIDOR and MESSIDOR-2 fundus images from the OD region boundaries that were manually marked with the help of a local ophthalmic specialist. Let us stand for these actual center position and coordinates of the OD pixel region p
                        
                           Real
                         and S
                        
                           Real
                        , respectively.

In this paper, OD-center location is evaluated in terms of the Euclidean distance between p
                        
                           Exp
                         and p
                        
                           Real
                        , while OD segmentation is quantified by the Jaccard [47] and Dice [48] coefficients, as well as the mean absolute distance between estimated and true OD boundaries [49].
                           
                              •
                              Based-distance criteria ((1/8)R (1/4)R, (1/2)R, 1R and D
                                 *) for evaluating OD-center location:

If D(p
                                 
                                    Exp
                                 , p
                                 
                                    Real
                                 ) denotes the Euclidean distance between p
                                 
                                    Exp
                                  and p
                                 
                                    Real
                                 , (1/8)R, (1/4)R, (1/2)R and 1R criteria are based on counting the number of cases where D(p
                                 
                                    exp
                                 , p
                                 
                                    Real
                                 ) is below (1/8), (1/4), (1/2) and 1 OD radius, respectively. Since OD may vary substantially in different equal-sized fundus images (according to [40], from 0.1 to 0.2 of retinal size), OD radius, R, was fixed to its middle value to avoid distortion in result evaluation:


                                 
                                    
                                       (15)
                                       
                                          R
                                          =
                                          (
                                          0.15
                                          ·
                                          
                                             D
                                             FOV
                                          
                                          )
                                          /
                                          2
                                       
                                    
                                 where D
                                 
                                    FOV
                                  approximates retinal diameter. Thus, R is set to the same value of images the same retinal size. In our case, this value was fixed to 68, 103 and 109 pixels depending on the resolution of the analyzed MESSIDOR image: 1140×960, 2240×1488 or 2304×1536 pixels, which correspond to retinas of approximately 910, 1380 and 1455 pixels in size, respectively.

In addition, normalized distance D
                                 *(p
                                 
                                    exp
                                 , p
                                 
                                    Real
                                 ) is defined as:


                                 
                                    
                                       (16)
                                       
                                          
                                             D
                                             *
                                          
                                          (
                                          
                                             p
                                             exp
                                          
                                          ,
                                          
                                             p
                                             Real
                                          
                                          )
                                          =
                                          
                                             
                                                D
                                                (
                                                
                                                   p
                                                   exp
                                                
                                                ,
                                                
                                                   p
                                                   Real
                                                
                                                )
                                             
                                             R
                                          
                                          ·
                                          100
                                       
                                    
                                 
                              

Jaccard and Dice coefficients (JC and DC, respectively) are used to evaluate OD segmentation:


                                 JC(S
                                 
                                    exp
                                 , S
                                 
                                    Real
                                 ) is defined as the ratio between the intersection and union of the automatically-obtained OD segmentation (S
                                 
                                    exp
                                 ) and the one considered as ground truth (S
                                 
                                    Real
                                 ):


                                 
                                    
                                       (17)
                                       
                                          JC
                                          (
                                          
                                             S
                                             exp
                                          
                                          ,
                                          
                                             S
                                             Real
                                          
                                          )
                                          =
                                          
                                             
                                                #
                                                (
                                                
                                                   S
                                                   exp
                                                
                                                ∩
                                                
                                                   S
                                                   Real
                                                
                                                )
                                             
                                             
                                                #
                                                (
                                                
                                                   S
                                                   exp
                                                
                                                ∪
                                                
                                                   S
                                                   Real
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              

On the other hand, DC(S
                                 
                                    exp
                                 , S
                                 
                                    Real
                                 ) is defined as the size of the intersection of S
                                 
                                    exp
                                  and S
                                 
                                    Real
                                  divided by their average size:


                                 
                                    
                                       (18)
                                       
                                          DC
                                          (
                                          
                                             S
                                             exp
                                          
                                          ,
                                          
                                             S
                                             Real
                                          
                                          )
                                          =
                                          
                                             
                                                2
                                                ·
                                                #
                                                (
                                                
                                                   S
                                                   exp
                                                
                                                ∩
                                                
                                                   S
                                                   Real
                                                
                                                )
                                             
                                             
                                                (
                                                #
                                                (
                                                
                                                   S
                                                   exp
                                                
                                                )
                                                +
                                                #
                                                (
                                                
                                                   S
                                                   real
                                                
                                                )
                                                )
                                             
                                          
                                       
                                    
                                 
                              

Normalized mean average distance (MAD
                                 *) is used to evaluate OD boundary segmentation:

Let us denote B
                                 
                                    exp
                                 
                                 ={a
                                 
                                    i
                                 
                                 :
                                 i
                                 =1, …, N
                                 
                                    exp
                                 } and B
                                 
                                    real
                                 
                                 ={b
                                 
                                    i
                                 
                                 :
                                 i
                                 =1, …, N
                                 
                                    real
                                 } as the coordinate sets of the S
                                 
                                    real
                                  and S
                                 
                                    exp
                                  boundaries, respectively, where each a
                                 
                                    i
                                  and b
                                 
                                    i
                                  is an ordered pair of the x and y coordinates of a point in the set.

Then, the normalized mean average distance between B
                                 
                                    exp
                                  and B
                                 
                                    real
                                 , MAD
                                 *(B
                                 
                                    exp
                                 , B
                                 
                                    real
                                 ), is defined as:


                                 
                                    
                                       (19)
                                       
                                          
                                             MAD
                                             *
                                          
                                          (
                                          
                                             B
                                             exp
                                          
                                          ,
                                          
                                             B
                                             real
                                          
                                          )
                                          =
                                          MAD
                                          (
                                          
                                             B
                                             exp
                                          
                                          ,
                                          
                                             B
                                             real
                                          
                                          )
                                          /
                                          R
                                       
                                    
                                 where


                                 
                                    
                                       (20)
                                       
                                          MAD
                                          (
                                          
                                             B
                                             exp
                                          
                                          ,
                                          
                                             B
                                             real
                                          
                                          )
                                          =
                                          
                                             1
                                             2
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            
                                                               
                                                                  N
                                                                  exp
                                                               
                                                            
                                                         
                                                         d
                                                         (
                                                         
                                                            a
                                                            i
                                                         
                                                         ,
                                                         
                                                            B
                                                            real
                                                         
                                                         )
                                                      
                                                      
                                                         
                                                            N
                                                            exp
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   +
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            
                                                               
                                                                  N
                                                                  real
                                                               
                                                            
                                                         
                                                         d
                                                         (
                                                         
                                                            b
                                                            i
                                                         
                                                         ,
                                                         
                                                            B
                                                            exp
                                                         
                                                         )
                                                      
                                                      
                                                         
                                                            N
                                                            real
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 with 
                                    d
                                    (
                                    
                                       a
                                       i
                                    
                                    ,
                                    
                                       B
                                       real
                                    
                                    )
                                    =
                                    
                                       min
                                       j
                                    
                                    ∥
                                    
                                       b
                                       j
                                    
                                    −
                                    
                                       a
                                       i
                                    
                                    ∥
                                  and 
                                    d
                                    (
                                    
                                       b
                                       i
                                    
                                    ,
                                    
                                       B
                                       exp
                                    
                                    )
                                    =
                                    
                                       min
                                       j
                                    
                                    ∥
                                    
                                       a
                                       j
                                    
                                    −
                                    
                                       b
                                       i
                                    
                                    ∥
                                 
                              

The methodology presented in this paper for OD detection is based on exploiting the following facts relative to this retinal region: blood vessels are originated from it and it is recognizable on fundus images as a bright area. This way, its general process stages include segmentation of the main retinal vessels from the vascular arch – as well as morphological processing to enhance bright regions. Both of these stages consist on generating our main blood vessel-segmented binary images and bright region-enhanced images, and applying, as a previous step, a shade-correction algorithm to correct non-uniform illumination. The approach used in this work is based on the subtraction of a background estimate from the original image, this background estimate being accomplished through a filtering operation with a large arithmetic mean kernel. This procedure may have the effect of reducing contrast between the retinal structures of our interest (major blood vessels and OD) and the background. This could involve a disadvantage, especially for further OD detection, since the operating kernel size (69 pixels for retinas of approx. 540 pixels in diameter) is comparable to the size of this retinal region. To this respect, although literature reports shade-correction methods intended to preserve large anatomical structures [41–43], we have opted for applying the simple above-mentioned subtractive approach first, followed by specific morphological processes aimed at enhancing the retinal region under consideration.

Regarding the generation of our blood vessel-segmented binary images, it should be mentioned that numerous methods for retinal vessel segmentation have been reported (a complete survey can be found in [44]. Vascular arch assessment proves essential to develop automatic retinal disease screening systems. Knowledge on blood vessel location improves microaneurysm, hemorrhage and exudate detection [5,6,45], and allows identifying the growth of abnormal new vessels or neovascularisation [46]. In addition, vascular tree is also useful as valuable information to locate other fundus features such as OD or fovea. For example, Foracchia et al. [15] extracted the vascular skeleton to measure vessel diameter, centre point and direction. The main blood vessels were modelled using parabolas and used to identify OD center position. In the methodology presented in this paper, vessel segmentation is also used as a support for obtaining the OD center and pixel region. In our case, this stage of the methodology is not aimed at segmenting the whole vascular tree as accurately as possible. For our purpose, detecting the pixels corresponding to the main retinal vessels originating from the OD is enough. These pixels are observed to have the brightest values on our vessel-enhanced images and the selected global thresholding technique assesses their detection in a fast and simple way.

On the other hand, our bright region-enhanced images are produced by an iterative process of morphological opening and closing operations with a disc-shaped structuring element whose radius increases in each iteration. Specifically, four iterations with 4-, 8-, 12- and 16-pixel radius, referred to 540 pixel-diameter retinas, are applied. At this operating retina size, OD radius may typically range from about 27 to 54 pixels, thus exceeding the maximum radius of the structuring element. Therefore, this parameter setting makes OD remain, enhancing it after each opening–closing operation, other bright smaller structures being smoothed or even removed (i.e., possible presence of exudates, reflection artifacts). In this respect, tests were performed to find the number of iterations and their corresponding structuring element sizes that provides the best performance for our methodology. Thus, different sets of OD-center locations and OD segmentations were produced through the application of the iterative morphological procedure with different total number of iterations on the 118 fundus images in our training database. We tested 1–6 iterations and structuring element radius was increased by 4 pixels in each iteration (4-pixel radius was used in the first iteration). Thus, the location and segmentation metrics described above (D
                        *, JC, DC and MAD
                        *) were obtained for each image. Average results are shown in Table 1
                        . As expected, better overall performance can be observed when the opening–closing operations are applied four times, as results between three and five iterations are very close.

The methodology was tested on the 1200 and 1748 fundus images from the MESSIDOR and MESSIDOR-2 databases using the previously defined performance measures. Since these measurements were performed by other authors, this choice facilitates comparing our and their results. The following methods were considered for comparison purposes: Aquino et al. [26], Lu [27], Sekar and Nagarakan [28], Yu et al. [29], Morales et al. [30], Mendonça et al. [31], and Suero et al. [32] (all these methods are briefly commented in Section 1). To the best of our knowledge, these are the most-recent OD location and segmentation algorithms reporting performance on MESSIDOR database images (no methodology providing results on MESSIDOR-2 database was found in literature). Their values are presented as reported by their authors, appearing in tables as gaps when unavailable for a specific measure.

The evaluation of the methodology-rendered OD center locations is presented in Table 2
                           . Concerning MESSIDOR database (top table), results are divided according to their medical center acquisition. Since diagnosis of these fundus images is provided (see Section 2), they are also presented on sets of ME-unrelated retinas and pathological retinas with ME signs. On the other hand, the results corresponding to the MESSIDOR-2 database (bottom table) are divided into the images coming from MESSIDOR and the set of new added images, all of them acquired from diabetic patients.

The methodology proves very accurate locating the center of the OD region. Considering the most exigent criteria (1/8)R and (1/4)R, which are of major interest in this framework of developing methodologies for accurate OD-center position location on a fundus image, distance D(p
                           
                              exp
                           , p
                           
                              real
                           ) remained below (1/8) and (1/4) of one standard OD radius in 87.33 and 97.75% of the cases for MESSIDOR images, and in 80.38 and 95.42% of the cases for MESSIDOR-2 images. Notice that (1/8)R means 9, 13 and 14 pixels for retinas of 910, 1380 and 1455 pixels in size, respectively.

In addition, the methodology shows no significant performance differences when compared to fundus images acquired in different medical centers (average distance D(p
                           
                              exp
                           , p
                           
                              real
                           ) varies between 0.065R and 0.122R depending on the considered subset of images). It should be noted that MESSIDOR images from the Paris Hôpital Lariboisière and the Faculté de Médecine St. Etienne were captured with pupil dilation, while those from LaTIM at Brest were taken without dilation. According to the values shown in Table 1 (last column, top panel), the corresponding average distances reported for every subset (each one composed by 400 images) are very close, the methodology thus showing robustness to the quality variations that may suffer the images of non-dilated eyes. Moreover, OD location performance does not decrease when yellowish retinal exudates are present on the fundus image (methodology achieves average D(p
                           
                              exp
                           , p
                           
                              real
                           ) values between 0.071R and 0.069R for sets of ME and ME-unrelated retinas, respectively).

On the other hand, Table 3
                            shows the performance comparison between these results and those provided by other published solutions. It should be pointed out that the reviewed methodologies locate OD by providing any pixel within this retinal region, without searching for its center position. Thus, they consider that OD is successfully located in a single image if the distance between the methodology-provided OD pixel and the actual OD-center position remains below one standard OD radius (criterion 1R). From this point of view, our proposed method renders better performance than most of the other methods, being comparable to that achieved by the OD location techniques proposed by Lu [27] and Mendonça et al. [31]. These proposals, as the one presented in this paper, do not succeed locating OD in only 3 cases of the whole set of 1200 MESSIDOR fundus images (in our case, these failures were due to the fact that OD was affected by posterior staphyloma). Anyway, it is worth mentioning that our methodology tends to keep this high performance even when more exigent criteria are considered: the OD is successfully located in 97.75 and 99.5% of the cases for (1/4)R and (1/2)R criteria, respectively.


                           Fig. 3
                            shows application examples of the proposed methodology to identify OD center position in 4 MESSIDOR fundus images. The methodology-estimated pixel as the OD center position and the true ophthalmologist-established OD center are marked in each image, as well as the initial OD-containing regions where accurate segmentation is achieved. Fundus images can be observed to have been selected to correspond to example cases of resulting OD-center pixel categorized in different levels of the considered based-distance quality scale (R criteria). The proposed methodology can be observed to have failed to locate the OD region in image (d) (this fundus image corresponds to one of the three commented failed OD-location cases).

The evaluation of methodology-estimated OD segmentations is presented in Tables 4
                            (JC and DC coefficients) and 5
                            (MAD levels). Besides the average values reached in the whole set of 1200-MESSIDOR and 1748-MESSIDOR-2 fundus images, the ratio of images with JC and DC values over 0.95, 0.90, 0.80 and 0.70, as well as the ratio of cases with MAD values below (1/20), (1/10), (1/5) and (1/3) OD radius, is also reported in Tables 4 and 5, respectively. The methodology proves stable and robust when confronted to different databases composed by dilated or non-dilated photographs, as well as to different ME-grade diagnosed fundus images. This way, JC, DC and MAD results are comparable for sets of fundus images acquired with or without pupil dilation from different medical centers (Lariboisière and St. Etienne centers captured fundus images with dilation, while LaTIM did it without dilation) or corresponding to ME-related and ME-unrelated retinas, their average values for MESSIDOR and MESSIDOR-2 databases being, respectively, 0.87 and 0.85 for 
                              
                                 JC
                                 ¯
                              
                           , 0.92 in both databases for 
                              
                                 DC
                                 ¯
                              
                           , and 0.062R and 0.080R for 
                              
                                 MAD
                                 ¯
                              
                           . Fig. 3 shows samples of methodology-provided OD boundaries (green lines) and the corresponding actual boundaries manually established by an ophthalmologic specialist (black lines). The selected fundus images illustrate example cases of different values of these metrics used to quantify OD segmentations. Thus, JC/DC values are 0.96/0.98 (image (a)), 0.86/0.92 (image (b)), 0.49/0.66 (image (c)) and 0/0 (image (d)), while MAD
                           * ranges from 2.74 (image (a)) to 183.54 (image (d)), being 11.68 and 28.07 for images (b) and (c) respectively. The worst results correspond to the image (d) for which there is no overlap between the estimated OD region and the one considered as ground-truth.

An overview of the segmentation results provided by other techniques, presented in Table 6
                           , shows our proposed method renders better overall performance. The corresponding average 
                              
                                 JC
                                 ¯
                              
                            value achieved with our algorithm slightly outperform those reported by Aquino et al. [26], Yu et al. [29] and Morales et al. [30]. Regarding performance comparison in terms of DC and MAD, our proposal provides a higher average DC value than Morales et al. [30], as well as a higher number of images included in the considered MAD levels than Yu et al. [29] (methodologies by Morales et al. [30] and Yu et al. [29] are the only ones found to report these measures on the MESSIDOR database).

@&#CONCLUSIONS@&#

Automated diabetic retinopathy (DR) screening or pre-screening carried out by systems focused on the detection of early ophthalmic signs of illness can have a major impact in the near future. Since the number of potential patients is very high, development of automatic DR diagnosis systems based on retinal image computer analysis may provide remarkably quicker screening programs for early detection of these disorders. The development of such systems require to detect anatomical structures such as optic disc (OD), fovea or vascular arch.

A methodology for locating the center and segmenting the OD retinal region on digital fundus images is presented in this paper. The methodology firstly searches for a pixel within the OD to extract an OD-containing region of interest where accurate segmentation and center-position location have to be performed. For this purpose, an automatic thresholding procedure is applied on bright region-enhanced images, which are obtained after processing the retinography intensity channel by a set of morphological opening and closing operations. In this thresholding scheme, the main blood vessels originating from the OD play an important role and their detection has also been proposed.

This methodology was tested on the publicly available MESSIDOR and MESSIDOR-2 databases. The MESSIDOR database was selected because it is composed by a large number of retinographies acquired from three different sources (Paris Hôpital Lariboisière, the Faculté de Médecine St. Etienne and the LaTIM at Brest, France), all of them diagnosed according to Diabetic Retinopathy (DR) grade and Macular Edema (ME) risk. Specifically, the whole set of 1200 fundus images includes 229 and 660 cases with ME and DR signs, respectively. On the other hand, MESSIDOR-2 images were included in our testing material to extend experimentation, since this database offers a set of new 690 images from diabetic patients. Therefore, the methodology was evaluated on a huge number of clinical cases of interest within the framework of automated diagnosis of these retinal diseases.

Regarding the evaluation criterion, OD locations were quantified by measuring the Euclidean distance between the estimated and the actual OD center for each fundus image. Specifically, referential distances 1/8, 1/4, 1/2 and 1 times the OD radius (measured from the actual OD center position) were selected to set a quality scale. On the other hand, OD segmentation evaluation was performed in terms of Jaccard and Dice coefficients, as well as the mean average distance between the methodology-provided OD pixel region and the actual one, established with the help of an experienced ophthalmologist.

The methodology proves very accurate locating the center of the OD region (results are presented in Table 2). The distance between the methodology-provided pixel and the actual OD center position remains below (1/8)R, (1/4)R, (1/2)R and 1R in 80.85, 95.5, 98.99 and 99.68%, respectively, of the 1890 different fundus images under consideration. These data lead to an average distance of 6.08, 9.22 and 9.72 pixels for retinas of 910, 1380 and 1455 pixels in size, respectively. Concerning OD segmentation results (Tables 4 and 5), the methodological comparison presented in Table 6 shows that methodology-rendered results systematically exceed those reported by the reviewed, most-recent OD-segmentation approaches available in literature.

On the other hand, it should be pointed out that methodology-estimated OD location and segmentation results show no significant differences when sets of dilated and non-dilated fundus images acquired from different medical centers are independently considered. Thus, the methodology proves its stability relative to the quality variations that the images of non-dilated eyes may suffer. This is important for practical application, since OD detection tools must work on retinal images from multiple origins that may have been captured with or without pharmacological dilation. Moreover, no decreasing performance is observed when strong distracters such as yellowish exudates (ME signs) or bright reflects (common in MESSIDOR-2 LaTIM subset) are present on the fundus image. Therefore, the methodology also proves stable when confronted to different ME-grade diagnosed fundus images.

In addition, method simplicity should also be highlighted. The performance results obtained on a massive digital retinal database indicate that simple methods based on basic image processing techniques seem to suffice for OD detection. Dealing with high resolutions images (1440×960, 2240×1488 and 2304×1536), average computational time to process a single image was 5.425s (SD = 0.981s) running on a PC with a dual-Intel Xeon CPU at 32Ghz and 32 GB of RAM capacity. Since our implementation is experimental, this performance might still be improved. The algorithms were implemented in Matlab (version R2012a).

This fact, together with its proven effectiveness and robustness, makes this proposed OD location and segmentation method a suitable tool to be integrated into a complete system for automated retinal-disease diagnosis. This way, it should be pointed out that this work has specifically contributed to the development of the system for automated DR detection implemented by the Health Ministry of the Andalusian Regional Government (Spain) with the purpose of improving effectiveness in its DR screening program.

Finally, it is worth mentioning that for the sake of rigorousness in future performance comparison between OD detection methods, the sets of methodology-estimated OD-center coordinates and OD-pixel region binary masks, as well as the corresponding ones used in this paper as ground truth, for each of the MESSIDOR and MESSIDOR-2 fundus images are available at [50] (in Images/Results subsection of the Downloads section). Moreover, researchers can generate the results of the proposed methodology on any fundus image online at [50] (in Methods section).

@&#ACKNOWLEDGEMENTS@&#

The authors would like to thank the MESSIDOR and MESSIDOR-2 programs partners for making their databases publicly available.

This work is part of the Project Expert System for Early Automated Detection of Diabetic Retinopathy by Analysis of Digital Retinal Images, supported and funded by the Health Ministry of the Andalusian Regional Government (Spain).

@&#REFERENCES@&#

